[
  {
    "id": "concepts-clustering2",
    "title": "ch8.pdf",
    "content": "\n# ch8.pdf\n\n\n\n8\nCluster Analysis:\nBasic Concepts and\nAlgorithms\nCluster analysis divides data into groups (clusters) that are meaningful, useful,\nor both. If meaningful groups are the goal, then the clusters should capture the\nnatural structure of the data. In some cases, however, cluster analysis is only a\nuseful starting point for other purposes, such as data summarization. Whether\nfor understanding or utility,  cluster analysis has long played an important\nrole in a wide variety of fields:  psychology and other social sciences, biology,\nstatistics,  pattern recognition,  information retrieval, machine learning,  and\ndata mining.\nThere have been many applications of cluster analysis to practical prob-\nlems.  We provide some specific examples, organized by whether the purpose\nof the clustering is understanding or utility.\nClustering for UnderstandingClasses, or conceptually meaningful groups\nof objects that share common characteristics, play an important role in how\npeople analyze and describe the world.  Indeed, human beings are skilled at\ndividing objects into groups (clustering) and assigning particular objects to\nthese groups (classification). For example, even relatively young children can\nquickly label the objects in a photograph as buildings, vehicles, people, ani-\nmals, plants, etc. In the context of understanding data, clusters are potential\nclasses and cluster analysis is the study of techniques for automatically finding\nclasses. The following are some examples:\n\n488   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n•Biology.Biologists have spent many years creating a taxonomy (hi-\nerarchical classification) of all living things:  kingdom,  phylum,  class,\norder, family, genus, and species. Thus, it is perhaps not surprising that\nmuch of the early work in cluster analysis sought to create a discipline\nof mathematical taxonomy that could automatically find such classifi-\ncation structures.  More recently, biologists have applied clustering to\nanalyze the large amounts of genetic information that are now available.\nFor example, clustering has been used to find groups of genes that have\nsimilar functions.\n•Information Retrieval.The World Wide Web consists of billions of\nWeb pages, and the results of a query to a search engine can return\nthousands of pages.  Clustering can be used to group these search re-\nsults into a small number of clusters, each of which captures a particular\naspect of the query.   For instance,  a query of “movie” might return\nWeb pages grouped into categories such as reviews, trailers, stars, and\ntheaters. Each category (cluster) can be broken into subcategories (sub-\nclusters), producing a hierarchical structure that further assists a user’s\nexploration of the query results.\n•Climate.Understanding the Earth’s climate requires finding patterns\nin the atmosphere and ocean.  To that end, cluster analysis has been\napplied to find patterns in the atmospheric pressure of polar regions and\nareas of the ocean that have a significant impact on land climate.\n•Psychology and Medicine.An illness or condition frequently has a\nnumber of variations, and cluster analysis can be used to identify these\ndifferent subcategories. For example, clustering has been used to identify\ndifferent types of depression. Cluster analysis can also be used to detect\npatterns in the spatial or temporal distribution of a disease.\n•Business.Businesses collect large amounts of information on current\nand potential customers.  Clustering can be used to segment customers\ninto a small number of groups for additional analysis and marketing\nactivities.\nClustering for UtilityCluster analysis provides an abstraction from in-\ndividual data objects to the clusters in which those data objects reside.  Ad-\nditionally, some clustering techniques characterize each cluster in terms of a\ncluster prototype; i.e., a data object that is representative of the other ob-\njects in the cluster.  These cluster prototypes can be used as the basis for a\n\n489\nnumber of data analysis or data processing techniques. Therefore, in the con-\ntext of utility, cluster analysis is the study of techniques for finding the most\nrepresentative cluster prototypes.\n•Summarization.Many data analysis techniques, such as regression or\nPCA, have a time or space complexity ofO(m\n2\n) or higher (wheremis\nthe number of objects), and thus, are not practical for large data sets.\nHowever, instead of applying the algorithm to the entire data set, it can\nbe applied to a reduced data set consisting only of cluster prototypes.\nDepending on the type of analysis, the number of prototypes, and the\naccuracy with which the prototypes represent the data, the results can\nbe comparable to those that would have been obtained if all the data\ncould have been used.\n•Compression.Cluster prototypes can also be used for data compres-\nsion. In particular, a table is created that consists of the prototypes for\neach cluster; i.e., each prototype is assigned an integer value that is its\nposition (index) in the table.  Each object is represented by the index\nof the prototype associated with its cluster. This type of compression is\nknown asvector quantizationand is often applied to image, sound,\nand video data, where (1) many of the data objects are highly similar\nto one another, (2) some loss of information is acceptable, and (3) a\nsubstantial reduction in the data size is desired.\n•Efficiently Finding Nearest Neighbors.Finding nearest neighbors\ncan require computing the pairwise distance between all points.  Often\nclusters and their cluster prototypes can be found much more efficiently.\nIf objects are relatively close to the prototype of their cluster, then we can\nuse the prototypes to reduce the number of distance computations that\nare necessary to find the nearest neighbors of an object. Intuitively, if two\ncluster prototypes are far apart, then the objects in the corresponding\nclusters cannot be nearest neighbors of each other.  Consequently, to\nfind an object’s nearest neighbors it is only necessary to compute the\ndistance to objects in nearby clusters, where the nearness of two clusters\nis measured by the distance between their prototypes. This idea is made\nmore precise in Exercise 25 on page 94.\nThis chapter provides an introduction to cluster analysis.  We begin with\na high-level overview of clustering, including a discussion of the various ap-\nproaches to dividing objects into sets of clusters and the different types of\nclusters.  We then describe three specific clustering techniques that represent\n\n490   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nbroad categories of algorithms and illustrate a variety of concepts: K-means,\nagglomerative hierarchical clustering, and DBSCAN. The final section of this\nchapter is devoted to cluster validity—methods for evaluating the goodness\nof the clusters produced by a clustering algorithm. More advanced clustering\nconcepts and algorithms will be discussed in Chapter 9.  Whenever possible,\nwe discuss the strengths and weaknesses of different schemes.  In addition,\nthe bibliographic notes provide references to relevant books and papers that\nexplore cluster analysis in greater depth.\n8.1   Overview\nBefore discussing specific clustering techniques,  we provide some necessary\nbackground.  First, we further define cluster analysis, illustrating why it is\ndifficult and explaining its relationship to other techniques that group data.\nThen we explore two important topics:  (1) different ways to group a set of\nobjects into a set of clusters, and (2) types of clusters.\n8.1.1   What Is Cluster Analysis?\nCluster analysis groups data objects based only on information found in the\ndata that describes the objects and their relationships.  The goal is that the\nobjects within a group be similar (or related) to one another and different from\n(or unrelated to) the objects in other groups.  The greater the similarity (or\nhomogeneity) within a group and the greater the difference between groups,\nthe better or more distinct the clustering.\nIn many applications, the notion of a cluster is not well defined. To better\nunderstand the difficulty of deciding what constitutes a cluster, consider Figure\n8.1, which shows twenty points and three different ways of dividing them into\nclusters.  The shapes of the markers indicate cluster membership.  Figures\n8.1(b) and 8.1(d) divide the data into two and six parts, respectively. However,\nthe apparent division of each of the two larger clusters into three subclusters\nmay simply be an artifact of the human visual system.  Also, it may not be\nunreasonable to say that the points form four clusters, as shown in Figure\n8.1(c).  This figure illustrates that the definition of a cluster is imprecise and\nthat the best definition depends on the nature of data and the desired results.\nCluster analysis is related to other techniques that are used to divide data\nobjects into groups.  For instance, clustering can be regarded as a form of\nclassification in that it creates a labeling of objects with class (cluster) labels.\nHowever, it derives these labels only from the data. In contrast, classification\n\n8.1Overview491\n(a) Original points.(b) Two clusters.\n(c) Four clusters.(d) Six clusters.\nFigure 8.1.Different ways of clustering the same set of points.\nin the sense of Chapter 4 issupervised classification; i.e., new, unlabeled\nobjects are assigned a class label using a model developed from objects with\nknown class labels.   For this reason,  cluster analysis is sometimes referred\nto asunsupervised classification.   When the term classification is used\nwithout any qualification within data mining, it typically refers to supervised\nclassification.\nAlso,  while the termssegmentationandpartitioningare sometimes\nused as synonyms for clustering, these terms are frequently used for approaches\noutside the traditional bounds of cluster analysis.   For example,  the term\npartitioning is often used in connection with techniques that divide graphs into\nsubgraphs and that are not strongly connected to clustering.  Segmentation\noften refers to the division of data into groups using simple techniques; e.g.,\nan image can be split into segments based only on pixel intensity and color, or\npeople can be divided into groups based on their income.  Nonetheless, some\nwork in graph partitioning and in image and market segmentation is related\nto cluster analysis.\n8.1.2   Different Types of Clusterings\nAn entire collection of clusters is commonly referred to as aclustering, and in\nthis section, we distinguish various types of clusterings: hierarchical (nested)\nversus partitional (unnested), exclusive versus overlapping versus fuzzy, and\ncomplete versus partial.\nHierarchical versus PartitionalThe most commonly discussed distinc-\ntion among different types of clusterings is whether the set of clusters is nested\n\n492   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nor unnested, or in more traditional terminology, hierarchical or partitional. A\npartitional clusteringis simply a division of the set of data objects into\nnon-overlapping subsets (clusters) such that each data object is in exactly one\nsubset.  Taken individually, each collection of clusters in Figures 8.1 (b–d) is\na partitional clustering.\nIf we permit clusters to have subclusters, then we obtain ahierarchical\nclustering, which is a set of nested clusters that are organized as a tree. Each\nnode (cluster) in the tree (except for the leaf nodes) is the union of its children\n(subclusters), and the root of the tree is the cluster containing all the objects.\nOften, but not always, the leaves of the tree are singleton clusters of individual\ndata objects.  If we allow clusters to be nested, then one interpretation of\nFigure 8.1(a) is that it has two subclusters (Figure 8.1(b)), each of which, in\nturn, has three subclusters (Figure 8.1(d)). The clusters shown in Figures 8.1\n(a–d), when taken in that order, also form a hierarchical (nested) clustering\nwith, respectively, 1, 2, 4, and 6 clusters on each level.  Finally, note that a\nhierarchical clustering can be viewed as a sequence of partitional clusterings\nand a partitional clustering can be obtained by taking any member of that\nsequence; i.e., by cutting the hierarchical tree at a particular level.\nExclusive versus Overlapping versus FuzzyThe clusterings shown in\nFigure 8.1 are allexclusive, as they assign each object to a single cluster.\nThere are many situations in which a point could reasonably be placed in more\nthan one cluster, and these situations are better addressed by non-exclusive\nclustering.   In the most general sense,  anoverlappingornon-exclusive\nclusteringis used to reflect the fact that an object cansimultaneouslybelong\nto more than one group (class). For instance, a person at a university can be\nboth an enrolled student and an employee of the university.  A non-exclusive\nclustering is also often used when, for example, an object is “between” two\nor more clusters and could reasonably be assigned to any of these clusters.\nImagine a point halfway between two of the clusters of Figure 8.1.  Rather\nthan make a somewhat arbitrary assignment of the object to a single cluster,\nit is placed in all of the “equally good” clusters.\nIn afuzzy clustering, every object belongs to every cluster with a mem-\nbership weight that is between 0 (absolutely doesn’t belong) and 1 (absolutely\nbelongs). In other words, clusters are treated as fuzzy sets. (Mathematically,\na fuzzy set is one in which an object belongs to any set with a weight that\nis between 0 and 1.  In fuzzy clustering, we often impose the additional con-\nstraint that the sum of the weights for each object must equal 1.)  Similarly,\nprobabilistic clustering techniques compute the probability with which each\n\n8.1Overview493\npoint belongs to each cluster, and these probabilities must also sum to 1. Be-\ncause the membership weights or probabilities for any object sum to 1, a fuzzy\nor probabilistic clustering does not address true multiclass situations, such as\nthe case of a student employee, where an object belongs to multiple classes.\nInstead, these approaches are most appropriate for avoiding the arbitrariness\nof assigning an object to only one cluster when it may be close to several. In\npractice, a fuzzy or probabilistic clustering is often converted to an exclusive\nclustering by assigning each object to the cluster in which its membership\nweight or probability is highest.\nComplete versus PartialAcomplete clusteringassigns every object to\na cluster, whereas apartial clusteringdoes not. The motivation for a partial\nclustering is that some objects in a data set may not belong to well-defined\ngroups.  Many times objects in the data set may represent noise, outliers, or\n“uninteresting background.” For example, some newspaper stories may share\na common theme, such as global warming, while other stories are more generic\nor one-of-a-kind. Thus, to find the important topics in last month’s stories, we\nmay want to search only for clusters of documents that are tightly related by a\ncommon theme. In other cases, a complete clustering of the objects is desired.\nFor example, an application that uses clustering to organize documents for\nbrowsing needs to guarantee that all documents can be browsed.\n8.1.3   Different Types of Clusters\nClustering aims to find useful groups of objects (clusters), where usefulness is\ndefined by the goals of the data analysis.  Not surprisingly, there are several\ndifferent notions of a cluster that prove useful in practice. In order to visually\nillustrate the differences among these types of clusters, we use two-dimensional\npoints, as shown in Figure 8.2, as our data objects. We stress, however, that\nthe types of clusters described here are equally valid for other kinds of data.\nWell-SeparatedA cluster is a set of objects in which each object is closer\n(or more similar) to every other object in the cluster than to any object not\nin the cluster. Sometimes a threshold is used to specify that all the objects in\na cluster must be sufficiently close (or similar) to one another. This idealistic\ndefinition of a cluster is satisfied only when the data contains natural clusters\nthat are quite far from each other.  Figure 8.2(a) gives an example of well-\nseparated clusters that consists of two groups of points in a two-dimensional\nspace. The distance between any two points in different groups is larger than\n\n494   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nthe distance between any two points within a group.  Well-separated clusters\ndo not need to be globular, but can have any shape.\nPrototype-BasedA cluster is a set of objects in which each object is closer\n(more similar) to the prototype that defines the cluster than to the prototype\nof any other cluster.  For data with continuous attributes, the prototype of a\ncluster is often a centroid, i.e., the average (mean) of all the points in the clus-\nter. When a centroid is not meaningful, such as when the data has categorical\nattributes, the prototype is often a medoid, i.e., the most representative point\nof a cluster.  For many types of data, the prototype can be regarded as the\nmost central point, and in such instances, we commonly refer to prototype-\nbased clusters ascenter-based clusters. Not surprisingly, such clusters tend\nto be globular. Figure 8.2(b) shows an example of center-based clusters.\nGraph-BasedIf the data is represented as a graph, where the nodes are\nobjects and the links represent connections among objects (see Section 2.1.2),\nthen a cluster can be defined as aconnected component; i.e., a group of\nobjects that are connected to one another, but that have no connection to\nobjects outside the group. An important example of graph-based clusters are\ncontiguity-based clusters, where two objects are connected only if they are\nwithin a specified distance of each other.  This implies that each object in a\ncontiguity-based cluster is closer to some other object in the cluster than to\nany point in a different cluster. Figure 8.2(c) shows an example of such clusters\nfor two-dimensional points. This definition of a cluster is useful when clusters\nare irregular or intertwined, but can have trouble when noise is present since,\nas illustrated by the two spherical clusters of Figure 8.2(c), a small bridge of\npoints can merge two distinct clusters.\nOther types of graph-based clusters are also possible. One such approach\n(Section 8.3.2) defines a cluster as aclique; i.e., a set of nodes in a graph that\nare completely connected to each other.  Specifically, if we add connections\nbetween objects in the order of their distance from one another, a cluster is\nformed when a set of objects forms a clique.  Like prototype-based clusters,\nsuch clusters tend to be globular.\nDensity-BasedA cluster is a dense region of objects that is surrounded by\na region of low density.  Figure 8.2(d) shows some density-based clusters for\ndata created by adding noise to the data of Figure 8.2(c).  The two circular\nclusters are not merged, as in Figure 8.2(c), because the bridge between them\nfades into the noise.  Likewise, the curve that is present in Figure 8.2(c) also\n\n8.1Overview495\nfades into the noise and does not form a cluster in Figure 8.2(d).  A density-\nbased definition of a cluster is often employed when the clusters are irregular or\nintertwined, and when noise and outliers are present. By contrast, a contiguity-\nbased definition of a cluster would not work well for the data of Figure 8.2(d)\nsince the noise would tend to form bridges between clusters.\nShared-Property (Conceptual Clusters)More generally, we can define\na cluster as a set of objects that share some property. This definition encom-\npasses all the previous definitions of a cluster; e.g., objects in a center-based\ncluster share the property that they are all closest to the same centroid or\nmedoid.  However, the shared-property approach also includes new types of\nclusters.   Consider the clusters shown in Figure 8.2(e).   A triangular area\n(cluster) is adjacent to a rectangular one, and there are two intertwined circles\n(clusters).  In both cases, a clustering algorithm would need a very specific\nconcept of a cluster to successfully detect these clusters. The process of find-\ning such clusters is called conceptual clustering.  However, too sophisticated\na notion of a cluster would take us into the area of pattern recognition, and\nthus, we only consider simpler types of clusters in this book.\nRoad Map\nIn this chapter, we use the following three simple, but important techniques\nto introduce many of the concepts involved in cluster analysis.\n•K-means.  This is a prototype-based, partitional clustering technique\nthat attempts to find a user-specified number of clusters (K), which are\nrepresented by their centroids.\n•Agglomerative Hierarchical Clustering.This clustering approach\nrefers to a collection of closely related clustering techniques that produce\na hierarchical clustering by starting with each point as a singleton cluster\nand then repeatedly merging the two closest clusters until a single, all-\nencompassing cluster remains. Some of these techniques have a natural\ninterpretation in terms of graph-based clustering, while others have an\ninterpretation in terms of a prototype-based approach.\n•DBSCAN. This is a density-based clustering algorithm that produces\na partitional clustering, in which the number of clusters is automatically\ndetermined by the algorithm.  Points in low-density regions are classi-\nfied as noise and omitted; thus, DBSCAN does not produce a complete\nclustering.\n\n496   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a)  Well-separated  clusters.Each\npoint is closer to all of the points in its\ncluster than to any point in another\ncluster.\n(b)  Center-based  clusters.Each\npoint is closer to the center of its\ncluster  than  to  the  center  of  any\nother cluster.\n(c) Contiguity-based clusters. Each\npointisclosertoatleastonepoint\nin its cluster than to any point in\nanother cluster.\n(d)  Density-based  clusters.   Clus-\nters are regions of high density sep-\narated by regions of low density.\n(e) Conceptual clusters.   Points in a cluster share some general\nproperty that derives from the entire set of points.  (Points in the\nintersection of the circles belong to both.)\nFigure 8.2.Different types of clusters as illustrated by sets of two-dimensional points.\n8.2   K-means\nPrototype-based clustering techniques create a one-level partitioning of the\ndata objects.  There are a number of such techniques, but two of the most\nprominent are K-means and K-medoid. K-means defines a prototype in terms\nof a centroid, which is usually the mean of a group of points, and is typically\n\n8.2K-means497\napplied to objects in a continuousn-dimensional space.  K-medoid defines a\nprototype in terms of a medoid, which is the most representative point for a\ngroup of points, and can be applied to a wide range of data since it requires\nonly a proximity measure for a pair of objects. While a centroid almost never\ncorresponds to an actual data point, a medoid, by its definition, must be an\nactual data point.  In this section, we will focus solely on K-means, which is\none of the oldest and most widely used clustering algorithms.\n8.2.1   The Basic K-means Algorithm\nThe K-means clustering technique is simple, and we begin with a description\nof the basic algorithm. We first chooseKinitial centroids, whereKis a user-\nspecified parameter, namely, the number of clusters desired.  Each point is\nthen assigned to the closest centroid, and each collection of points assigned to\na centroid is a cluster. The centroid of each cluster is then updated based on\nthe points assigned to the cluster. We repeat the assignment and update steps\nuntil no point changes clusters, or equivalently, until the centroids remain the\nsame.\nK-means is formally described by Algorithm 8.1. The operation of K-means\nis illustrated in Figure 8.3, which shows how, starting from three centroids, the\nfinal clusters are found in four assignment-update steps.  In these and other\nfigures displaying K-means clustering, each subfigure shows (1) the centroids\nat the start of the iteration and (2) the assignment of the points to those\ncentroids. The centroids are indicated by the “+” symbol; all points belonging\nto the same cluster have the same marker shape.\nAlgorithm 8.1Basic K-means algorithm.\n1:SelectKpoints as initial centroids.\n2:repeat\n3:FormKclusters by assigning each point to its closest centroid.\n4:Recompute the centroid of each cluster.\n5:untilCentroids do not change.\nIn the first step, shown in Figure 8.3(a), points are assigned to the initial\ncentroids, which are all in the larger group of points. For this example, we use\nthe mean as the centroid. After points are assigned to a centroid, the centroid\nis then updated.  Again, the figure for each step shows the centroid at the\nbeginning of the step and the assignment of points to those centroids. In the\nsecond step, points are assigned to the updated centroids, and the centroids\n\n498   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a) Iteration 1.(b) Iteration 2.(c) Iteration 3.(d) Iteration 4.\nFigure 8.3.Using the K-means algorithm to find three clusters in sample data.\nare updated again.  In steps 2, 3, and 4, which are shown in Figures 8.3 (b),\n(c), and (d), respectively, two of the centroids move to the two small groups of\npoints at the bottom of the figures. When the K-means algorithm terminates\nin Figure 8.3(d), because no more changes occur, the centroids have identified\nthe natural groupings of points.\nFor some combinations of proximity functions and types of centroids, K-\nmeans always converges to a solution; i.e., K-means reaches a state in which no\npoints are shifting from one cluster to another, and hence, the centroids don’t\nchange.  Because most of the convergence occurs in the early steps, however,\nthe condition on line 5 of Algorithm 8.1 is often replaced by a weaker condition,\ne.g., repeat until only 1% of the points change clusters.\nWe consider each of the steps in the basic K-means algorithm in more detail\nand then provide an analysis of the algorithm’s space and time complexity.\nAssigning Points to the Closest Centroid\nTo assign a point to the closest centroid, we need a proximity measure that\nquantifies the notion of “closest” for the specific data under consideration.\nEuclidean (L\n2\n) distance is often used for data points in Euclidean space, while\ncosine similarity is more appropriate for documents.  However, there may be\nseveral types of proximity measures that are appropriate for a given type of\ndata. For example, Manhattan (L\n1\n) distance can be used for Euclidean data,\nwhile the Jaccard measure is often employed for documents.\nUsually, the similarity measures used for K-means are relatively simple\nsince the algorithm repeatedly calculates the similarity of each point to each\ncentroid. In some cases, however, such as when the data is in low-dimensional\n\n8.2K-means499\nTable 8.1.Table of notation.\nSymbolDescription\nxAn object.\nC\ni\nThei\nth\ncluster.\nc\ni\nThe centroid of clusterC\ni\n.\ncThe centroid of all points.\nm\ni\nThenumberofobjectsinthei\nth\ncluster.\nmThenumberofobjectsinthedataset.\nKThe number of clusters.\nEuclidean space, it is possible to avoid computing many of the similarities,\nthus significantly speeding up the K-means algorithm.   Bisecting K-means\n(described in Section 8.2.3) is another approach that speeds up K-means by\nreducing the number of similarities computed.\nCentroids and Objective Functions\nStep 4 of the K-means algorithm was stated rather generally as “recompute\nthe centroid of each cluster,” since the centroid can vary, depending on the\nproximity measure for the data and the goal of the clustering.  The goal of\nthe clustering is typically expressed by an objective function that depends on\nthe proximities of the points to one another or to the cluster centroids; e.g.,\nminimize the squared distance of each point to its closest centroid.  We illus-\ntrate this with two examples.  However, the key point is this:  once we have\nspecified a proximity measure and an objective function, the centroid that we\nshould choose can often be determined mathematically.  We provide mathe-\nmatical details in Section 8.2.6, and provide a non-mathematical discussion of\nthis observation here.\nData in Euclidean SpaceConsider data whose proximity measure is Eu-\nclidean distance.  For our objective function, which measures the quality of a\nclustering, we use thesum of the squared error (SSE), which is also known\nas scatter.  In other words, we calculate the error of each data point, i.e., its\nEuclidean distance to the closest centroid, and then compute the total sum\nof the squared errors.  Given two different sets of clusters that are produced\nby two different runs of K-means, we prefer the one with the smallest squared\nerror since this means that the prototypes (centroids) of this clustering are\na better representation of the points in their cluster.  Using the notation in\nTable 8.1, the SSE is formally defined as follows:\n\n500   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nSSE =\nK\n∑\ni=1\n∑\nx∈C\ni\ndist(c\ni\n,x)\n2\n(8.1)\nwheredistis the standard Euclidean (L\n2\n) distance between two objects in\nEuclidean space.\nGiven these assumptions,  it can be shown (see Section 8.2.6) that the\ncentroid that minimizes the SSE of the cluster is the mean. Using the notation\nin Table 8.1, the centroid (mean) of thei\nth\ncluster is defined by Equation 8.2.\nc\ni\n=\n1\nm\ni\n∑\nx∈C\ni\nx(8.2)\nTo illustrate, the centroid of a cluster containing the three two-dimensional\npoints, (1,1), (2,3), and (6,2), is ((1 + 2 + 6)/3,((1+3+2)/3) = (3,2).\nSteps 3 and 4 of the K-means algorithm directly attempt to minimize\nthe SSE (or more generally, the objective function).  Step 3 forms clusters\nby assigning points to their nearest centroid, which minimizes the SSE for\nthe given set of centroids.  Step 4 recomputes the centroids so as to further\nminimize the SSE. However, the actions of K-means in Steps 3 and 4 are only\nguaranteed to find a local minimum with respect to the SSE since they are\nbased on optimizing the SSE for specific choices of the centroids and clusters,\nrather than for all possible choices. We will later see an example in which this\nleads to a suboptimal clustering.\nDocument DataTo illustrate that K-means is not restricted to data in\nEuclidean space, we consider document data and the cosine similarity measure.\nHere we assume that the document data is represented as a document-term\nmatrix as described on page 31.  Our objective is to maximize the similarity\nof the documents in a cluster to the cluster centroid; this quantity is known\nas thecohesionof the cluster.  For this objective it can be shown that the\ncluster centroid is, as for Euclidean data, the mean.  The analogous quantity\nto the total SSE is the total cohesion, which is given by Equation 8.3.\nTotal Cohesion =\nK\n∑\ni=1\n∑\nx∈C\ni\ncosine(x,c\ni\n)(8.3)\nThe General CaseThere are a number of choices for the proximity func-\ntion, centroid, and objective function that can be used in the basic K-means\n\n8.2K-means501\nTable 8.2.K-means: Common choices for proximity, centroids, and objective functions.\nProximity FunctionCentroidObjective Function\nManhattan (L\n1\n)medianMinimize sum of the L\n1\ndistance of an ob-\nject to its cluster centroid\nSquared Euclidean (L\n2\n2\n)meanMinimize sum of the squared L\n2\ndistance\nof an object to its cluster centroid\ncosinemeanMaximize sum of the cosine similarity of\nan object to its cluster centroid\nBregman divergencemeanMinimize sum of the Bregman divergence\nof an object to its cluster centroid\nalgorithm and that are guaranteed to converge. Table 8.2 shows some possible\nchoices, including the two that we have just discussed.  Notice that for Man-\nhattan (L\n1\n) distance and the objective of minimizing the sum of the distances,\nthe appropriate centroid is the median of the points in a cluster.\nThe last entry in the table, Bregman divergence (Section 2.4.5), is actually\na class of proximity measures that includes the squared Euclidean distance, L\n2\n2\n,\nthe Mahalanobis distance, and cosine similarity. The importance of Bregman\ndivergence functions is that any such function can be used as the basis of a K-\nmeans style clustering algorithm with the mean as the centroid.  Specifically,\nif we use a Bregman divergence as our proximity function, then the result-\ning clustering algorithm has the usual properties of K-means with respect to\nconvergence, local minima, etc. Furthermore, the properties of such a cluster-\ning algorithm can be developed for all possible Bregman divergences. Indeed,\nK-means algorithms that use cosine similarity or squared Euclidean distance\nare particular instances of a general clustering algorithm based on Bregman\ndivergences.\nFor the rest our K-means discussion, we use two-dimensional data since\nit is easy to explain K-means and its properties for this type of data.  But,\nas suggested by the last few paragraphs, K-means is a very general clustering\nalgorithm and can be used with a wide variety of data types, such as documents\nand time series.\nChoosing Initial Centroids\nWhen random initialization of centroids is used, different runs of K-means\ntypically produce different total SSEs. We illustrate this with the set of two-\ndimensional points shown in Figure 8.3, which has three natural clusters of\npoints. Figure 8.4(a) shows a clustering solution that is the global minimum of\n\n502   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a) Optimal clustering.(b) Suboptimal clustering.\nFigure 8.4.Three optimal and non-optimal clusters.\nthe SSE for three clusters, while Figure 8.4(b) shows a suboptimal clustering\nthat is only a local minimum.\nChoosing the proper initial centroids is the key step of the basic K-means\nprocedure.  A common approach is to choose the initial centroids randomly,\nbut the resulting clusters are often poor.\nExample 8.1 (Poor Initial Centroids).Randomly selected initial cen-\ntroids may be poor.  We provide an example of this using the same data set\nused in Figures 8.3 and 8.4.  Figures 8.3 and 8.5 show the clusters that re-\nsult from two particular choices of initial centroids.  (For both figures, the\npositions of the cluster centroids in the various iterations are indicated by\ncrosses.) In Figure 8.3, even though all the initial centroids are from one natu-\nral cluster, the minimum SSE clustering is still found. In Figure 8.5, however,\neven though the initial centroids seem to be better distributed, we obtain a\nsuboptimal clustering, with higher squared error.\nExample 8.2 (Limits of Random Initialization).One technique that\nis commonly used to address the problem of choosing initial centroids is to\nperform multiple runs, each with a different set of randomly chosen initial\ncentroids, and then select the set of clusters with the minimum SSE. While\nsimple, this strategy may not work very well, depending on the data set and\nthe number of clusters sought. We demonstrate this using the sample data set\nshown in Figure 8.6(a).  The data consists of two pairs of clusters, where the\nclusters in each (top-bottom) pair are closer to each other than to the clusters\nin the other pair.  Figure 8.6 (b–d) shows that if we start with two initial\ncentroids per pair of clusters, then even when both centroids are in a single\n\n8.2K-means503\n(a) Iteration 1.(b) Iteration 2.(c) Iteration 3.(d) Iteration 4.\nFigure 8.5.Poor starting centroids for K-means.\ncluster, the centroids will redistribute themselves so that the “true” clusters\nare found.  However, Figure 8.7 shows that if a pair of clusters has only one\ninitial centroid and the other pair has three, then two of the true clusters will\nbe combined and one true cluster will be split.\nNote that an optimal clustering will be obtained as long as two initial\ncentroids fall anywhere in a pair of clusters, since the centroids will redistribute\nthemselves,  one to each cluster.   Unfortunately,  as the number of clusters\nbecomes larger, it is increasingly likely that at least one pair of clusters will\nhave only one initial centroid.  (See Exercise 4 on page 559.)  In this case,\nbecause the pairs of clusters are farther apart than clusters within a pair, the\nK-means algorithm will not redistribute the centroids between pairs of clusters,\nand thus, only a local minimum will be achieved.\nBecause of the problems with using randomly selected initial centroids,\nwhich even repeated runs may not overcome, other techniques are often em-\nployed for initialization.  One effective approach is to take a sample of points\nand cluster them using a hierarchical clustering technique.Kclusters are ex-\ntracted from the hierarchical clustering, and the centroids of those clusters are\nused as the initial centroids. This approach often works well, but is practical\nonly if (1) the sample is relatively small, e.g., a few hundred to a few thousand\n(hierarchical clustering is expensive), and (2)Kis relatively small compared\nto the sample size.\nThe following procedure is another approach to selecting initial centroids.\nSelect the first point at random or take the centroid of all points.  Then, for\neach successive initial centroid, select the point that is farthest from any of\nthe initial centroids already selected.  In this way, we obtain a set of initial\n\n504   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a) Initial points.(b) Iteration 1.\n(c) Iteration 2.(d) Iteration 3.\nFigure 8.6.Two pairs of clusters with a pair of initial centroids within each pair of clusters.\ncentroids that is guaranteed to be not only randomly selected but also well\nseparated.  Unfortunately, such an approach can select outliers, rather than\npoints in dense regions (clusters). Also, it is expensive to compute the farthest\npoint from the current set of initial centroids.  To overcome these problems,\nthis approach is often applied to a sample of the points.  Since outliers are\nrare,  they tend  not  to  show up  in a random sample.   In contrast,  points\nfrom every dense region are likely to be included unless the sample size is very\nsmall. Also, the computation involved in finding the initial centroids is greatly\nreduced because the sample size is typically much smaller than the number of\npoints.\nLater on, we will discuss two other approaches that are useful for produc-\ning better-quality (lower SSE) clusterings:  using a variant of K-means that\n\n8.2K-means505\n(a) Iteration 1.(b) Iteration 2.\n(c) Iteration 3.(d) Iteration 4.\nFigure 8.7.Two pairs of clusters with more or fewer than two initial centroids within a pair of clusters.\nis less susceptible to initialization problems (bisecting K-means) and using\npostprocessing to “fixup” the set of clusters produced.\nTime and Space Complexity\nThe space requirements for K-means are modest because only the data points\nand centroids are stored.  Specifically, the storage required isO((m+K)n),\nwheremis the number of points andnis the number of attributes. The time\nrequirements for K-means are also modest—basically linear in the number of\ndata points. In particular, the time required isO(I∗K∗m∗n), whereIis the\nnumber of iterations required for convergence. As mentioned,Iis often small\nand can usually be safely bounded, as most changes typically occur in the\n\n506   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nfirst few iterations. Therefore, K-means is linear inm, the number of points,\nand is efficient as well as simple provided thatK, the number of clusters, is\nsignificantly less thanm.\n8.2.2   K-means: Additional Issues\nHandling Empty Clusters\nOne of the problems with the basic K-means algorithm given earlier is that\nempty clusters can be obtained if no points are allocated to a cluster during\nthe assignment step.  If this happens, then a strategy is needed to choose a\nreplacement centroid, since otherwise, the squared error will be larger than\nnecessary.  One approach is to choose the point that is farthest away from\nany current centroid. If nothing else, this eliminates the point that currently\ncontributes most to the total squared error.  Another approach is to choose\nthe replacement centroid from the cluster that has the highest SSE. This will\ntypically split the cluster and reduce the overall SSE of the clustering. If there\nare several empty clusters, then this process can be repeated several times.\nOutliers\nWhen the squared error criterion is used, outliers can unduly influence the\nclusters that are found. In particular, when outliers are present, the resulting\ncluster centroids (prototypes) may not be as representative as they otherwise\nwould be and thus, the SSE will be higher as well. Because of this, it is often\nuseful to discover outliers and eliminate them beforehand.  It is important,\nhowever, to appreciate that there are certain clustering applications for which\noutliers should not be eliminated.   When clustering is used for data com-\npression, every point must be clustered, and in some cases, such as financial\nanalysis, apparent outliers, e.g., unusually profitable customers, can be the\nmost interesting points.\nAn obvious issue is how to identify outliers.  A number of techniques for\nidentifying outliers will be discussed in Chapter 10. If we use approaches that\nremove outliers before clustering, we avoid clustering points that will not clus-\nter well. Alternatively, outliers can also be identified in a postprocessing step.\nFor instance, we can keep track of the SSE contributed by each point, and\neliminate those points with unusually high contributions, especially over mul-\ntiple runs. Also, we may want to eliminate small clusters since they frequently\nrepresent groups of outliers.\n\n8.2K-means507\nReducing the SSE with Postprocessing\nAn obvious way to reduce the SSE is to find more clusters, i.e., to use a larger\nK.  However, in many cases, we would like to improve the SSE, but don’t\nwant to increase the number of clusters.  This is often possible because K-\nmeans typically converges to a local minimum.  Various techniques are used\nto “fix up” the resulting clusters in order to produce a clustering that has\nlower SSE. The strategy is to focus on individual clusters since the total SSE\nis simply the sum of the SSE contributed by each cluster.  (We will use the\nterminologytotal SSEandcluster SSE, respectively, to avoid any potential\nconfusion.)  We can change the total SSE by performing various operations\non the clusters, such as splitting or merging clusters.  One commonly used\napproach is to use alternate cluster splitting and merging phases.  During a\nsplitting phase, clusters are divided, while during a merging phase, clusters\nare combined. In this way, it is often possible to escape local SSE minima and\nstill produce a clustering solution with the desired number of clusters.  The\nfollowing are some techniques used in the splitting and merging phases.\nTwo strategies that decrease the total SSE by increasing the number of\nclusters are the following:\nSplit a cluster:The cluster with the largest SSE is usually chosen, but we\ncould also split the cluster with the largest standard deviation for one\nparticular attribute.\nIntroduce a new cluster centroid:Often the point that is farthest from\nany cluster center is chosen.  We can easily determine this if we keep\ntrack of the SSE contributed by each point.  Another approach is to\nchoose randomly from all points or from the points with the highest\nSSE.\nTwo strategies that decrease the number of clusters, while trying to mini-\nmize the increase in total SSE, are the following:\nDisperse a cluster:This is accomplished by removing the centroid that cor-\nresponds to the cluster and reassigning the points to other clusters. Ide-\nally, the cluster that is dispersed should be the one that increases the\ntotal SSE the least.\nMerge two clusters:The clusters with the closest centroids are typically\nchosen, although another, perhaps better, approach is to merge the two\nclusters that result in the smallest increase in total  SSE.  These two\nmerging strategies are the same ones that are used in the hierarchical\n\n508   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nclustering techniques known as the centroid method and Ward’s method,\nrespectively. Both methods are discussed in Section 8.3.\nUpdating Centroids Incrementally\nInstead of updating cluster centroids after all points have been assigned to a\ncluster, the centroids can be updated incrementally, after each assignment of\na point to a cluster.  Notice that this requires either zero or two updates to\ncluster centroids at each step, since a point either moves to a new cluster (two\nupdates) or stays in its current cluster (zero updates).  Using an incremental\nupdate strategy guarantees that empty clusters are not produced since all\nclusters start with a single point, and if a cluster ever has only one point, then\nthat point will always be reassigned to the same cluster.\nIn addition, if incremental updating is used, the relative weight of the point\nbeing added may be adjusted; e.g., the weight of points is often decreased as\nthe clustering proceeds.  While this can result in better accuracy and faster\nconvergence, it can be difficult to make a good choice for the relative weight,\nespecially in a wide variety of situations.  These update issues are similar to\nthose involved in updating weights for artificial neural networks.\nYet another benefit of incremental updates has to do with using objectives\nother than “minimize SSE.” Suppose that we are given an arbitrary objective\nfunction to measure the goodness of a set of clusters.  When we process an\nindividual point, we can compute the value of the objective function for each\npossible cluster assignment, and then choose the one that optimizes the objec-\ntive.  Specific examples of alternative objective functions are given in Section\n8.5.2.\nOn the negative side, updating centroids incrementally introduces an or-\nder dependency.  In other words, the clusters produced may depend on the\norder in which the points are processed.  Although this can be addressed by\nrandomizing the order in which the points are processed, the basic K-means\napproach of updating the centroids after all points have been assigned to clus-\nters has no order dependency.  Also, incremental updates are slightly more\nexpensive.   However,  K-means converges rather quickly,  and therefore,  the\nnumber of points switching clusters quickly becomes relatively small.\n8.2.3   Bisecting K-means\nThe bisecting K-means algorithm is a straightforward extension of the basic\nK-means algorithm that is based on a simple idea: to obtainKclusters, split\nthe set of all points into two clusters, select one of these clusters to split, and\n\n8.2K-means509\nso on, untilKclusters have been produced. The details of bisecting K-means\nare given by Algorithm 8.2.\nAlgorithm 8.2Bisecting K-means algorithm.\n1:Initialize the list of clusters to contain the cluster consisting of all points.\n2:repeat\n3:Remove a cluster from the list of clusters.\n4:{Perform several “trial” bisections of the chosen cluster.}\n5:fori=1tonumber of trialsdo\n6:Bisect the selected cluster using basic K-means.\n7:end for\n8:Select the two clusters from the bisection with the lowest total SSE.\n9:Add these two clusters to the list of clusters.\n10:untilUntil the list of clusters containsKclusters.\nThere are a number of different ways to choose which cluster to split. We\ncan choose the largest cluster at each step, choose the one with the largest\nSSE, or use a criterion based on both size and SSE. Different choices result in\ndifferent clusters.\nWe often refine the resulting clusters by using their centroids as the initial\ncentroids for the basic K-means algorithm. This is necessary because, although\nthe K-means algorithm is guaranteed to find a clustering that represents a local\nminimum with respect to the SSE, in bisecting K-means we are using the K-\nmeans algorithm “locally,” i.e., to bisect individual clusters.  Therefore, the\nfinal set of clusters does not represent a clustering that is a local minimum\nwith respect to the total SSE.\nExample 8.3 (Bisecting K-means and Initialization).To illustrate that\nbisecting K-means is less susceptible to initialization problems, we show, in\nFigure 8.8, how bisecting K-means finds four clusters in the data set originally\nshown in Figure 8.6(a).   In iteration 1, two pairs of clusters are found;  in\niteration 2, the rightmost pair of clusters is split; and in iteration 3, the leftmost\npair of clusters is split. Bisecting K-means has less trouble with initialization\nbecause it performs several trial bisections and takes the one with the lowest\nSSE, and because there are only two centroids at each step.\nFinally,  by recording the sequence of clusterings produced as K-means\nbisects clusters, we can also use bisecting K-means to produce a hierarchical\nclustering.\n\n510   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a) Iteration 1.(b) Iteration 2.(c) Iteration 3.\nFigure 8.8.Bisecting K-means on the four clusters example.\n8.2.4   K-means and Different Types of Clusters\nK-means and its variations have a number of limitations with respect to finding\ndifferent types of clusters. In particular, K-means has difficulty detecting the\n“natural” clusters, when clusters have non-spherical shapes or widely different\nsizes or densities. This is illustrated by Figures 8.9, 8.10, and 8.11. In Figure\n8.9, K-means cannot find the three natural clusters because one of the clusters\nis much larger than the other two, and hence, the larger cluster is broken, while\none of the smaller clusters is combined with a portion of the larger cluster. In\nFigure 8.10, K-means fails to find the three natural clusters because the two\nsmaller clusters are much denser than the larger cluster.  Finally, in Figure\n8.11, K-means finds two clusters that mix portions of the two natural clusters\nbecause the shape of the natural clusters is not globular.\nThe difficulty in these three situations is that the K-means objective func-\ntion is a mismatch for the kinds of clusters we are trying to find since it is\nminimized by globular clusters of equal size and density or by clusters that are\nwell separated. However, these limitations can be overcome, in some sense, if\nthe user is willing to accept a clustering that breaks the natural clusters into a\nnumber of subclusters. Figure 8.12 shows what happens to the three previous\ndata sets if we find six clusters instead of two or three. Each smaller cluster is\npure in the sense that it contains only points from one of the natural clusters.\n8.2.5   Strengths and Weaknesses\nK-means is simple and can be used for a wide variety of data types. It is also\nquite efficient, even though multiple runs are often performed. Some variants,\nincluding bisecting K-means, are even more efficient, and are less suscepti-\nble to initialization problems.  K-means is not suitable for all types of data,\n\n8.2K-means511\n(a) Original points.(b) Three K-means clusters.\nFigure 8.9.K-means with clusters of different size.\n(a) Original points.(b) Three K-means clusters.\nFigure 8.10.K-means with clusters of different density.\n(a) Original points.(b) Two K-means clusters.\nFigure 8.11.K-means with non-globular clusters.\n\n512   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a) Unequal sizes.\n(b) Unequal densities.\n(c) Non-spherical shapes.\nFigure 8.12.Using K-means to find clusters that are subclusters of the natural clusters.\n\n8.2K-means513\nhowever.  It cannot handle non-globular clusters or clusters of different sizes\nand densities, although it can typically find pure subclusters if a large enough\nnumber of clusters is specified. K-means also has trouble clustering data that\ncontains outliers. Outlier detection and removal can help significantly in such\nsituations. Finally, K-means is restricted to data for which there is a notion of\na center (centroid).  A related technique, K-medoid clustering, does not have\nthis restriction, but is more expensive.\n8.2.6   K-means as an Optimization Problem\nHere, we delve into the mathematics behind K-means. This section, which can\nbe skipped without loss of continuity, requires knowledge of calculus through\npartial derivatives. Familiarity with optimization techniques, especially those\nbased on gradient descent, may also be helpful.\nAs mentioned earlier, given an objective function such as “minimize SSE,”\nclustering can be treated as an optimization problem.  One way to solve this\nproblem—to find a global optimum—is to enumerate all possible ways of di-\nviding the points into clusters and then choose the set of clusters that best\nsatisfies the objective function, e.g., that minimizes the total SSE. Of course,\nthis exhaustive strategy is computationally infeasible and as a result, a more\npractical approach is needed, even if such an approach finds solutions that are\nnot guaranteed to be optimal.  One technique, which is known asgradient\ndescent, is based on picking an initial solution and then repeating the fol-\nlowing two steps: compute the change to the solution that best optimizes the\nobjective function and then update the solution.\nWe assume that the data is one-dimensional, i.e.,dist(x, y)=(x−y)\n2\n.\nThis does not change anything essential, but greatly simplifies the notation.\nDerivation of K-means as an Algorithm to Minimize the SSE\nIn this section, we show how the centroid for the K-means algorithm can be\nmathematically derived when the proximity function is Euclidean distance\nand the objective is to minimize the SSE. Specifically, we investigate how we\ncan best update a cluster centroid so that the cluster SSE is minimized.  In\nmathematical terms, we seek to minimize Equation 8.1, which we repeat here,\nspecialized for one-dimensional data.\nSSE =\nK\n∑\ni=1\n∑\nx∈C\ni\n(c\ni\n−x)\n2\n(8.4)\n\n514   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nHere,C\ni\nis thei\nth\ncluster,xis a point inC\ni\n, andc\ni\nis the mean of thei\nth\ncluster. See Table 8.1 for a complete list of notation.\nWe can solve for thek\nth\ncentroidc\nk\n, which minimizes Equation 8.4, by\ndifferentiating the SSE, setting it equal to 0, and solving, as indicated below.\n∂\n∂c\nk\nSSE   =\n∂\n∂c\nk\nK\n∑\ni=1\n∑\nx∈C\ni\n(c\ni\n−x)\n2\n=\nK\n∑\ni=1\n∑\nx∈C\ni\n∂\n∂c\nk\n(c\ni\n−x)\n2\n=\n∑\nx∈C\nk\n2∗(c\nk\n−x\nk\n)=0\n∑\nx∈C\nk\n2∗(c\nk\n−x\nk\n)=0⇒m\nk\nc\nk\n=\n∑\nx∈C\nk\nx\nk\n⇒c\nk\n=\n1\nm\nk\n∑\nx∈C\nk\nx\nk\nThus, as previously indicated, the best centroid for minimizing the SSE of\na cluster is the mean of the points in the cluster.\nDerivation of K-means for SAE\nTo demonstrate that the K-means algorithm can be applied to a variety of\ndifferent objective functions, we consider how to partition the data intoK\nclusters such that the sum of the Manhattan (L\n1\n) distances of points from the\ncenter of their clusters is minimized.  We are seeking to minimize the sum of\nthe L\n1\nabsolute errors (SAE) as given by the following equation, wheredist\nL\n1\nis the L\n1\ndistance.  Again, for notational simplicity, we use one-dimensional\ndata, i.e.,dist\nL\n1\n=|c\ni\n−x|.\nSAE =\nK\n∑\ni=1\n∑\nx∈C\ni\ndist\nL\n1\n(c\ni\n,x)(8.5)\nWe can solve for thek\nth\ncentroidc\nk\n, which minimizes Equation 8.5, by\ndifferentiating the SAE, setting it equal to 0, and solving.\n\n8.3Agglomerative Hierarchical Clustering515\n∂\n∂c\nk\nSAE   =\n∂\n∂c\nk\nK\n∑\ni=1\n∑\nx∈C\ni\n|c\ni\n−x|\n=\nK\n∑\ni=1\n∑\nx∈C\ni\n∂\n∂c\nk\n|c\ni\n−x|\n=\n∑\nx∈C\nk\n∂\n∂c\nk\n|c\nk\n−x|=0\n∑\nx∈C\nk\n∂\n∂c\nk\n|c\nk\n−x|=0⇒\n∑\nx∈C\nk\nsign(x−c\nk\n)=0\nIf we solve forc\nk\n, we find thatc\nk\n=median{x∈C\nk\n}, the median of the\npoints in the cluster.  The median of a group of points is straightforward to\ncompute and less susceptible to distortion by outliers.\n8.3   Agglomerative Hierarchical Clustering\nHierarchical clustering techniques are a second important category of cluster-\ning methods. As with K-means, these approaches are relatively old compared\nto many clustering algorithms, but they still enjoy widespread use. There are\ntwo basic approaches for generating a hierarchical clustering:\nAgglomerative:Start with the points as individual clusters and,  at each\nstep, merge the closest pair of clusters.  This requires defining a notion\nof cluster proximity.\nDivisive:Start with one, all-inclusive cluster and, at each step, split a cluster\nuntil only singleton clusters of individual points remain. In this case, we\nneed to decide which cluster to split at each step and how to do the\nsplitting.\nAgglomerative hierarchical clustering techniques are by far the most common,\nand, in this section, we will focus exclusively on these methods.  A divisive\nhierarchical clustering technique is described in Section 9.4.2.\nA hierarchical clustering is often displayed graphically using a tree-like\ndiagram called adendrogram,  which displays both the cluster-subcluster\n\n516   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\np1   p2   p3 p4\n(a) Dendrogram.\np1\np2\np3\np4\n(b) Nested cluster diagram.\nFigure 8.13.A hierarchical clustering of four points shown as a dendrogram and as nested clusters.\nrelationships and the order in which the clusters were merged (agglomerative\nview) or split (divisive view). For sets of two-dimensional points, such as those\nthat we will use as examples, a hierarchical clustering can also be graphically\nrepresented using a nested cluster diagram. Figure 8.13 shows an example of\nthese two types of figures for a set of four two-dimensional points. These points\nwere clustered using the single-link technique that is described in Section 8.3.2.\n8.3.1   Basic Agglomerative Hierarchical Clustering Algorithm\nMany agglomerative hierarchical clustering techniques are variations on a sin-\ngle approach:  starting with individual points as clusters, successively merge\nthe two closest clusters until only one cluster remains.  This approach is ex-\npressed more formally in Algorithm 8.3.\nAlgorithm 8.3Basic agglomerative hierarchical clustering algorithm.\n1:Compute the proximity matrix, if necessary.\n2:repeat\n3:Merge the closest two clusters.\n4:Update the proximity matrix to reflect the proximity between the new\ncluster and the original clusters.\n5:untilOnly one cluster remains.\n\n8.3Agglomerative Hierarchical Clustering517\nDefining Proximity between Clusters\nThe key operation of Algorithm 8.3 is the computation of the proximity be-\ntween two clusters, and it is the definition of cluster proximity that differ-\nentiates the various agglomerative hierarchical techniques that we will dis-\ncuss.  Cluster proximity is typically defined with a particular type of cluster\nin mind—see Section 8.1.2.   For example,  many agglomerative hierarchical\nclustering techniques, such as MIN, MAX, and Group Average, come from\na graph-based view of clusters.MINdefines cluster proximity as the prox-\nimity between the closest two points that are in different clusters, or using\ngraph terms, the shortest edge between two nodes in different subsets of nodes.\nThis yields contiguity-based clusters as shown in Figure 8.2(c). Alternatively,\nMAXtakes the proximity between the farthest two points in different clusters\nto be the cluster proximity, or using graph terms, the longest edge between\ntwo nodes in different subsets of nodes. (If our proximities are distances, then\nthe names, MIN and MAX, are short and suggestive. For similarities, however,\nwhere higher values indicate closer points, the names seem reversed. For that\nreason, we usually prefer to use the alternative names,single linkandcom-\nplete link, respectively.) Another graph-based approach, thegroup average\ntechnique, defines cluster proximity to be the average pairwise proximities (av-\nerage length of edges) of all pairs of points from different clusters. Figure 8.14\nillustrates these three approaches.\n(a) MIN (single link.)(b) MAX (complete link.)(c) Group average.\nFigure 8.14.Graph-based definitions of cluster proximity\nIf, instead, we take a prototype-based view, in which each cluster is repre-\nsented by a centroid, different definitions of cluster proximity are more natural.\nWhen using centroids, the cluster proximity is commonly defined as the prox-\nimity between cluster centroids.  An alternative technique,Ward’smethod,\nalso assumes that a cluster is represented by its centroid, but it measures the\nproximity between two clusters in terms of the increase in the SSE that re-\n\n518   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nsults from merging the two clusters. Like K-means, Ward’s method attempts\nto minimize the sum of the squared distances of points from their cluster\ncentroids.\nTime and Space Complexity\nThe basic agglomerative hierarchical clustering algorithm just presented uses\na proximity matrix.  This requires the storage of\n1\n2\nm\n2\nproximities (assuming\nthe proximity matrix is symmetric) wheremis the number of data points.\nThe space needed to keep track of the clusters is proportional to the number\nof clusters, which ism−1, excluding singleton clusters. Hence, the total space\ncomplexity isO(m\n2\n).\nThe analysis of the basic agglomerative hierarchical clustering algorithm\nis also straightforward with respect to computational complexity.O(m\n2\n)time\nis required to compute the proximity matrix. After that step, there arem−1\niterations involving steps 3 and 4 because there aremclusters at the start and\ntwo clusters are merged during each iteration. If performed as a linear search of\nthe proximity matrix, then for thei\nth\niteration, step 3 requiresO((m−i+1)\n2\n)\ntime, which is proportional to the current number of clusters squared.  Step\n4 only requiresO(m−i+ 1) time to update the proximity matrix after the\nmerger of two clusters. (A cluster merger affects onlyO(m−i+ 1) proximities\nfor the techniques that we consider.)  Without modification, this would yield\na time complexity ofO(m\n3\n).  If the distances from each cluster to all other\nclusters are stored as a sorted list (or heap), it is possible to reduce the cost\nof finding the two closest clusters toO(m−i+ 1).  However, because of the\nadditional complexity of keeping data in a sorted list or heap, the overall time\nrequired for a hierarchical clustering based on Algorithm 8.3 isO(m\n2\nlogm).\nThe space and time complexity of hierarchical clustering severely limits the\nsize of data sets that can be processed. We discuss scalability approaches for\nclustering algorithms, including hierarchical clustering techniques, in Section\n9.5.\n8.3.2   Specific Techniques\nSample Data\nTo illustrate the behavior of the various hierarchical clustering algorithms,\nwe shall use sample data that consists of 6 two-dimensional points, which are\nshown in Figure 8.15. Thexandycoordinates of the points and the Euclidean\ndistances between them are shown in Tables 8.3 and 8.4, respectively.\n\n8.3Agglomerative Hierarchical Clustering519\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n5\n2\n3\n4\n6\n1\n00.10.20.30.40.50.6\nFigure 8.15.Set of 6 two-dimensional points.\nPointxCoordinateyCoordinate\np10.400.53\np20.220.38\np30.350.32\np40.260.19\np50.080.41\np60.450.30\nTable 8.3.xycoordinates of 6 points.\np1p2p3p4p5p6\np10.000.240.220.370.340.23\np20.240.000.150.200.140.25\np30.220.150.000.150.280.11\np40.370.200.150.000.290.22\np50.340.140.280.290.000.39\np60.230.250.110.220.390.00\nTable 8.4.Euclidean distance matrix for 6 points.\nSingle Link or MIN\nFor the single link or MIN version of hierarchical clustering, the proximity\nof two clusters is defined as the minimum of the distance (maximum of the\nsimilarity) between any two points in the two different clusters.  Using graph\nterminology, if you start with all points as singleton clusters and add links\nbetween points one at a time, shortest links first, then these single links com-\nbine the points into clusters.  The single link technique is good at handling\nnon-elliptical shapes, but is sensitive to noise and outliers.\nExample 8.4 (Single Link).Figure 8.16 shows the result of applying the\nsingle link technique to our example data set of six points.  Figure 8.16(a)\nshows the nested clusters as a sequence of nested ellipses, where the numbers\nassociated with the ellipses indicate the order of the clustering. Figure 8.16(b)\nshows the same information, but as a dendrogram.  The height at which two\nclusters are merged in the dendrogram reflects the distance of the two clusters.\nFor instance, from Table 8.4, we see that the distance between points 3 and 6\n\n520   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n6\n4\n5\n2\n1\n3\n3\n2\n4\n5\n1\n(a) Single link clustering.\n0.2\n0.15\n0.1\n0.05\n0\n362541\n(b) Single link dendrogram.\nFigure 8.16.Single link clustering of the six points shown in Figure 8.15.\nis 0.11, and that is the height at which they are joined into one cluster in the\ndendrogram.  As another example, the distance between clusters{3,6}and\n{2,5}is given by\ndist({3,6},{2,5})=min(dist(3,2),dist(6,2),dist(3,5),dist(6,5))\n=   min(0.15,0.25,0.28,0.39)\n=0.15.\nComplete Link or MAX or CLIQUE\nFor the complete link or MAX version of hierarchical clustering, the proximity\nof two clusters is defined as the maximum of the distance (minimum of the\nsimilarity) between any two points in the two different clusters.  Using graph\nterminology, if you start with all points as singleton clusters and add links\nbetween points one at a time, shortest links first, then a group of points is\nnot a cluster until all the points in it are completely linked, i.e., form aclique.\nComplete link is less susceptible to noise and outliers, but it can break large\nclusters and it favors globular shapes.\nExample 8.5 (Complete Link).Figure 8.17 shows the results of applying\nMAX to the sample data set of six points. As with single link, points 3 and 6\n\n8.3Agglomerative Hierarchical Clustering521\n6\n4\n5\n2\n1\n3\n3\n2\n4\n5\n1\n(a) Complete link clustering.\n0.4\n0.3\n0.2\n0.1\n0\n364125\n(b) Complete link dendrogram.\nFigure 8.17.Complete link clustering of the six points shown in Figure 8.15.\nare merged first. However,{3,6}is merged with{4}, instead of{2,5}or{1}\nbecause\ndist({3,6},{4})=max(dist(3,4),dist(6,4))\n=   max(0.15,0.22)\n=0.22.\ndist({3,6},{2,5})=max(dist(3,2),dist(6,2),dist(3,5),dist(6,5))\n=   max(0.15,0.25,0.28,0.39)\n=0.39.\ndist({3,6},{1})=max(dist(3,1),dist(6,1))\n=   max(0.22,0.23)\n=0.23.\nGroup Average\nFor the group average version of hierarchical clustering, the proximity of two\nclusters is defined as the average pairwise proximity among all pairs of points\nin the different clusters. This is an intermediate approach between the single\nand complete link approaches.  Thus, for group average, the cluster proxim-\n\n522   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n6\n4\n5\n2\n1\n3\n3\n2\n4\n5\n1\n(a) Group average clustering.\n0.2\n0.25\n0.1\n0\n0.15\n0.05\n364251\n(b) Group average dendrogram.\nFigure 8.18.Group average clustering of the six points shown in Figure 8.15.\nityproximity(C\ni\n,C\nj\n) of clustersC\ni\nandC\nj\n, which are of sizem\ni\nandm\nj\n,\nrespectively, is expressed by the following equation:\nproximity(C\ni\n,C\nj\n)=\n∑\nx∈C\ni\ny∈C\nj\nproximity(x,y)\nm\ni\n∗m\nj\n.(8.6)\nExample 8.6 (Group Average).Figure 8.18 shows the results of applying\nthe group average approach to the sample data set of six points. To illustrate\nhow group average works, we calculate the distance between some clusters.\ndist({3,6,4},{1})=(0.22 + 0.37 + 0.23)/(3∗1)\n=0.28\ndist({2,5},{1})=(0.2357 + 0.3421)/(2∗1)\n=0.2889\ndist({3,6,4},{2,5})=(0.15 + 0.28 + 0.25 + 0.39 + 0.20 + 0.29)/(6∗2)\n=0.26\nBecausedist({3,6,4}\n,{2,5}) is smaller thandist({3,6,4},{1}) anddist({2,5},{1}),\nclusters{3,6,4}and{2,5}are merged at the fourth stage.\n\n8.3Agglomerative Hierarchical Clustering523\n6\n5\n2\n1\n3\n3\n2\n4\n5\n1\n4\n(a) Ward’s clustering.\n0.2\n0.25\n0.1\n0\n0.15\n0.05\n364125\n(b) Ward’s dendrogram.\nFigure 8.19.Ward’s clustering of the six points shown in Figure 8.15.\nWard’s Method and Centroid Methods\nFor Ward’s method, the proximity between two clusters is defined as the in-\ncrease in the squared error that results when two clusters are merged.  Thus,\nthis method uses the same objective function as K-means clustering.  While\nit may seem that this feature makes Ward’s method somewhat distinct from\nother hierarchical techniques, it can be shown mathematically that Ward’s\nmethod is very similar to the group average method when the proximity be-\ntween two points is taken to be the square of the distance between them.\nExample 8.7 (Ward’s Method).Figure 8.19 shows the results of applying\nWard’s method to the sample data set of six points.  The clustering that is\nproduced is different from those produced by single link, complete link, and\ngroup average.\nCentroid methods calculate the proximity between two clusters by calcu-\nlating the distance between the centroids of clusters.  These techniques may\nseem similar to K-means, but as we have remarked, Ward’s method is the\ncorrect hierarchical analog.\nCentroid methods also have a characteristic—often considered bad—that\nis not possessed by the other hierarchical clustering techniques that we have\ndiscussed:  the possibility ofinversions.  Specifically, two clusters that are\nmerged may be more similar (less distant) than the pair of clusters that were\nmerged  in  a  previous  step.   For  the  other  methods,  the  distance  between\n\n524   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nTable 8.5.Table of Lance-Williams coefficients for common hierarchical clustering approaches.\nClustering Methodα\nA\nα\nB\nβγ\nSingle Link1/21/20−1/2\nComplete Link1/21/201/2\nGroup Average\nm\nA\nm\nA\n+m\nB\nm\nB\nm\nA\n+m\nB\n00\nCentroid\nm\nA\nm\nA\n+m\nB\nm\nB\nm\nA\n+m\nB\n−m\nA\nm\nB\n(m\nA\n+m\nB\n)\n2\n0\nWard’s\nm\nA\n+m\nQ\nm\nA\n+m\nB\n+m\nQ\nm\nB\n+m\nQ\nm\nA\n+m\nB\n+m\nQ\n−m\nQ\nm\nA\n+m\nB\n+m\nQ\n0\nmerged clusters monotonically increases (or is, at worst, non-increasing) as\nwe proceed from singleton clusters to one all-inclusive cluster.\n8.3.3   The Lance-Williams Formula for Cluster Proximity\nAny of the cluster proximities that we have discussed in this section can be\nviewed as a choice of different parameters (in the Lance-Williams formula\nshown below in Equation 8.7) for the proximity between clustersQandR,\nwhereRis formed by merging clustersAandB.  In this equation,p(., .)is\na proximity function, whilem\nA\n,m\nB\n, andm\nQ\nare the number of points in\nclustersA,B, andQ, respectively. In other words, after we merge clustersA\nandBto form clusterR, the proximity of the new cluster,R,toanexisting\ncluster,Q, is a linear function of the proximities ofQwith respect to the\noriginal clustersAandB. Table 8.5 shows the values of these coefficients for\nthe techniques that we have discussed.\np(R, Q)=α\nA\np(A, Q)+α\nB\np(B, Q)+βp(A, B)+γ|p(A, Q)−p(B, Q)|(8.7)\nAny  hierarchical  clustering  technique  that  can  be  expressed  using  the\nLance-Williams formula does not need to keep the original data points.  In-\nstead, the proximity matrix is updated as clustering occurs.  While a general\nformula is appealing, especially for implementation, it is easier to understand\nthe different hierarchical methods by looking directly at the definition of clus-\nter proximity that each method uses.\n8.3.4   Key Issues in Hierarchical Clustering\nLack of a Global Objective Function\nWe previously mentioned that agglomerative hierarchical clustering cannot be\nviewed as globally optimizing an objective function.  Instead, agglomerative\nhierarchical clustering techniques use various criteria to decide locally, at each\n\n8.3Agglomerative Hierarchical Clustering525\nstep, which clusters should be merged (or split for divisive approaches). This\napproach yields clustering algorithms that avoid the difficulty of attempting\nto solve a hard combinatorial optimization problem.  (It can be shown that\nthe general clustering problem for an objective function such as “minimize\nSSE” is computationally infeasible.)  Furthermore, such approaches do not\nhave problems with local minima or difficulties in choosing initial points.  Of\ncourse, the time complexity ofO(m\n2\nlogm) and the space complexity ofO(m\n2\n)\nare prohibitive in many cases.\nAbility to Handle Different Cluster Sizes\nOne aspect of agglomerative hierarchical clustering that we have not yet dis-\ncussed is how to treat the relative sizes of the pairs of clusters that are merged.\n(This discussion applies only to cluster proximity schemes that involve sums,\nsuch as centroid,  Ward’s,  and group average.)   There are two approaches:\nweighted, which treats all clusters equally, andunweighted, which takes\nthe number of points in each cluster into account. Note that the terminology\nof weighted or unweighted refers to the data points, not the clusters. In other\nwords, treating clusters of unequal size equally gives different weights to the\npoints in different clusters, while taking the cluster size into account gives\npoints in different clusters the same weight.\nWe will illustrate this using the group average technique discussed in Sec-\ntion 8.3.2, which is the unweighted version of the group average technique.\nIn the clustering literature, the full name of this approach is the Unweighted\nPair Group Method using Arithmetic averages (UPGMA). In Table 8.5, which\ngives the formula for updating cluster similarity, the coefficients for UPGMA\ninvolve the size of each of the clusters that were merged:α\nA\n=\nm\nA\nm\nA\n+m\nB\n,α\nB\n=\nm\nB\nm\nA\n+m\nB\n,β=0,γ= 0.  For the weighted version of group average—known as\nWPGMA—the coefficients are constants:α\nA\n=1/2,α\nB\n=1/2,β=0,γ=0.\nIn general, unweighted approaches are preferred unless there is reason to be-\nlieve that individual points should have different weights; e.g., perhaps classes\nof objects have been unevenly sampled.\nMerging Decisions Are Final\nAgglomerative hierarchical clustering algorithms tend to make good local de-\ncisions about combining two clusters since they can use information about the\npairwise similarity of all points.  However, once a decision is made to merge\ntwo clusters, it cannot be undone at a later time.  This approach prevents\na local optimization criterion from becoming a global optimization criterion.\n\n526   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nFor example, although the “minimize squared error” criterion from K-means\nis used in deciding which clusters to merge in Ward’s method, the clusters at\neach level do not represent local minima with respect to the total SSE. Indeed,\nthe clusters are not even stable, in the sense that a point in one cluster may\nbe closer to the centroid of some other cluster than it is to the centroid of its\ncurrent cluster. Nonetheless, Ward’s method is often used as a robust method\nof initializing a K-means clustering, indicating that a local “minimize squared\nerror” objective function does have a connection to a global “minimize squared\nerror” objective function.\nThere are some techniques that attempt to overcome the limitation that\nmerges are final. One approach attempts to fix up the hierarchical clustering\nby moving branches of the tree around so as to improve a global objective\nfunction. Another approach uses a partitional clustering technique such as K-\nmeans to create many small clusters, and then performs hierarchical clustering\nusing these small clusters as the starting point.\n8.3.5   Strengths and Weaknesses\nThe strengths and weakness of specific agglomerative hierarchical clustering\nalgorithms were discussed above.  More generally, such algorithms are typi-\ncally used because the underlying application, e.g., creation of a taxonomy,\nrequires a hierarchy.  Also, there have been some studies that suggest that\nthese algorithms can produce better-quality clusters. However, agglomerative\nhierarchical clustering algorithms are expensive in terms of their computa-\ntional and storage requirements.  The fact that all merges are final can also\ncause trouble for noisy, high-dimensional data, such as document data.  In\nturn, these two problems can be addressed to some degree by first partially\nclustering the data using another technique, such as K-means.\n8.4   DBSCAN\nDensity-based clustering locates regions of high density that are separated\nfrom one another by regions of low density.  DBSCAN is a simple and effec-\ntive density-based clustering algorithm that illustrates a number of important\nconcepts that are important for any density-based clustering approach. In this\nsection, we focus solely on DBSCAN after first considering the key notion of\ndensity.  Other algorithms for finding density-based clusters are described in\nthe next chapter.\n\n8.4DBSCAN527\n8.4.1   Traditional Density: Center-Based Approach\nAlthough there are not as many approaches for defining density as there are for\ndefining similarity, there are several distinct methods.  In this section we dis-\ncuss the center-based approach on which DBSCAN is based. Other definitions\nof density will be presented in Chapter 9.\nIn the center-based approach, density is estimated for a particular point in\nthe data set by counting the number of points within a specified radius,Eps,\nof that point.  This includes the point itself.  This technique is graphically\nillustrated by Figure 8.20.  The number of points within a radius ofEpsof\npointAis 7, includingAitself.\nThis method is simple to implement, but the density of any point will\ndepend on the specified radius.  For instance, if the radius is large enough,\nthen all points will have a density ofm, the number of points in the data set.\nLikewise, if the radius is too small, then all points will have a density of 1.\nAn approach for deciding on the appropriate radius for low-dimensional data\nis given in the next section in the context of our discussion of DBSCAN.\nClassification of Points According to Center-Based Density\nThe center-based approach to density allows us to classify a point as being (1)\nin the interior of a dense region (a core point), (2) on the edge of a dense region\n(a border point), or (3) in a sparsely occupied region (a noise or background\npoint).  Figure 8.21 graphically illustrates the concepts of core, border, and\nnoise points using a collection of two-dimensional points.  The following text\nprovides a more precise description.\nCore points:These points are in the interior of a density-based cluster.  A\npoint is a core point if the number of points within a given neighborhood\naround the point as determined by the distance function and a user-\nspecified distance parameter,Eps, exceeds a certain threshold,M inP ts,\nwhich is also a user-specified parameter.  In Figure 8.21, pointAis a\ncore point, for the indicated radius (Eps)ifM inP ts≤7.\nBorder points:A border point is not a core point, but falls within the neigh-\nborhood of a core point.  In Figure 8.21, pointBis a border point.  A\nborder point can fall within the neighborhoods of several core points.\nNoise points:A noise point is any point that is neither a core point nor a\nborder point. In Figure 8.21, pointCis a noise point.\n\n528   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nA\nEps\nFigure 8.20.Center-based\ndensity.\nC\nnoise point\nB\nborder point\nA\ncore point\nEps\nEps\nEps\nFigure 8.21.Core, border, and noise points.\n8.4.2   The DBSCAN Algorithm\nGiven the previous definitions of core points, border points, and noise points,\nthe DBSCAN algorithm can be informally described as follows. Any two core\npoints that are close enough—within a distanceEpsof one another—are put\nin the same cluster. Likewise, any border point that is close enough to a core\npoint is put in the same cluster as the core point. (Ties may need to be resolved\nif a border point is close to core points from different clusters.)  Noise points\nare discarded. The formal details are given in Algorithm 8.4. This algorithm\nuses the same concepts and finds the same clusters as the original DBSCAN,\nbut is optimized for simplicity, not efficiency.\nAlgorithm 8.4DBSCAN algorithm.\n1:Label all points as core, border, or noise points.\n2:Eliminate noise points.\n3:Put an edge between all core points that are withinEpsof each other.\n4:Make each group of connected core points into a separate cluster.\n5:Assign each border point to one of the clusters of its associated core points.\nTime and Space Complexity\nThe basic time complexity of the DBSCAN algorithm isO(m×time to find\npoints in theEps-neighborhood), wheremis the number of points.  In the\nworst case, this complexity isO(m\n2\n).  However, in low-dimensional spaces,\nthere are data structures, such as kd-trees, that allow efficient retrieval of all\n\n8.4DBSCAN529\npoints within a given distance of a specified point, and the time complexity\ncan be as low asO(mlogm).  The space requirement of DBSCAN, even for\nhigh-dimensional data, isO(m) because it is only necessary to keep a small\namount of data for each point, i.e., the cluster label and the identification of\neach point as a core, border, or noise point.\nSelection of DBSCAN Parameters\nThere is, of course, the issue of how to determine the parametersEpsand\nM inP ts.  The basic approach is to look at the behavior of the distance from\na point to itsk\nth\nnearest neighbor, which we will call thek-dist.  For points\nthat belong to some cluster, the value ofk-dist will be small ifkis not larger\nthan the cluster size. Note that there will be some variation, depending on the\ndensity of the cluster and the random distribution of points, but on average,\nthe range of variation will not be huge if the cluster densities are not radically\ndifferent.  However, for points that are not in a cluster, such as noise points,\nthek-dist will be relatively large.  Therefore, if we compute thek-dist for\nall the data points for somek, sort them in increasing order, and then plot\nthe sorted values, we expect to see a sharp change at the value ofk-dist that\ncorresponds to a suitable value ofEps.  If we select this distance as theEps\nparameter and take the value ofkas theM inP tsparameter, then points for\nwhichk-dist is less thanEpswill be labeled as core points, while other points\nwill be labeled as noise or border points.\nFigure 8.22 shows a sample data set, while thek-dist graph for the data is\ngiven in Figure 8.23. The value ofEpsthat is determined in this way depends\nonk, but does not change dramatically askchanges.  If the value ofkis too\nsmall, then even a small number of closely spaced points that are noise or\noutliers will be incorrectly labeled as clusters.  If the value ofkis too large,\nthen small clusters (of size less thank) are likely to be labeled as noise. The\noriginal DBSCAN algorithm used a value ofk= 4, which appears to be a\nreasonable value for most two-dimensional data sets.\nClusters of Varying Density\nDBSCAN can have trouble with density if the density of clusters varies widely.\nConsider Figure 8.24, which shows four clusters embedded in noise. The den-\nsity of the clusters and noise regions is indicated by their darkness. The noise\naround the pair of denser clusters,AandB, has the same density as clusters\nCandD. If theEpsthreshold is low enough that DBSCAN findsCandDas\nclusters, thenAandBand the points surrounding them will become a single\n\n530   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nFigure 8.22.Sample data.\n50\n40\n30\n20\n10\n0\n050010001500200025003000\nPoints Sorted by Distance to 4th Nearest Neighbor\n4th Nearest Neighbor Distance\nFigure 8.23.K-dist plot for sample data.\nCluster CCluster BCluster ACluster D\nNoiseNoise\nFigure 8.24.Four clusters embedded in noise.\ncluster. If theEpsthreshold is high enough that DBSCAN findsAandBas\nseparate clusters, and the points surrounding them are marked as noise, then\nCandDand the points surrounding them will also be marked as noise.\nAn Example\nTo illustrate the use of DBSCAN, we show the clusters that it finds in the\nrelatively complicated two-dimensional data set shown in Figure 8.22.  This\ndata set consists of 3000 two-dimensional points.  TheEpsthreshold for this\ndata was found by plotting the sorted distances of the fourth nearest neighbor\nof each point (Figure 8.23) and identifying the value at which there is a sharp\nincrease.  We selectedEps= 10, which corresponds to the knee of the curve.\nThe clusters found by DBSCAN using these parameters, i.e.,M inP ts= 4 and\nEps= 10, are shown in Figure 8.25(a).  The core points, border points, and\nnoise points are displayed in Figure 8.25(b).\n8.4.3   Strengths and Weaknesses\nBecause DBSCAN uses a density-based definition of a cluster, it is relatively\nresistant to noise and can handle clusters of arbitrary shapes and sizes. Thus,\n\n8.4DBSCAN531\n(a) Clusters found by DBSCAN.\nx – Noise Point          + – Border Point             – Core Point\n(b) Core, border, and noise points.\nFigure 8.25.DBSCAN clustering of 3000 two-dimensional points.\n\n532   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nDBSCAN can find many clusters that could not be found using K-means,\nsuch as those in Figure 8.22. As indicated previously, however, DBSCAN has\ntrouble when the clusters have widely varying densities.  It also has trouble\nwith high-dimensional data because density is more difficult to define for such\ndata.  One possible approach to dealing with such issues is given in Section\n9.4.8.  Finally, DBSCAN can be expensive when the computation of nearest\nneighbors requires computing all pairwise proximities, as is usually the case\nfor high-dimensional data.\n8.5   Cluster Evaluation\nIn supervised classification, the evaluation of the resulting classification model\nis an integral part of the process of developing a classification model,  and\nthere are well-accepted evaluation measures and procedures,  e.g.,  accuracy\nand cross-validation, respectively. However, because of its very nature, cluster\nevaluation is not a well-developed or commonly used part of cluster analysis.\nNonetheless, cluster evaluation, orcluster validationas it is more tradition-\nally called, is important, and this section will review some of the most common\nand easily applied approaches.\nThere might be some confusion as to why cluster evaluation is necessary.\nMany times, cluster analysis is conducted as a part of an exploratory data\nanalysis.  Hence, evaluation seems like an unnecessarily complicated addition\nto  what  is supposed  to  be  an  informal  process.   Furthermore,  since there\nare a number of different types of clusters—in some sense,  each clustering\nalgorithm defines its own type of cluster—it may seem that each situation\nmight require a different evaluation measure.  For instance, K-means clusters\nmight be evaluated in terms of the SSE, but for density-based clusters, which\nneed not be globular, SSE would not work well at all.\nNonetheless, cluster evaluation should be a part of any cluster analysis.\nA key motivation is that almost every clustering algorithm will find clusters\nin a data set,  even if that data set has no natural cluster structure.   For\ninstance, consider Figure 8.26, which shows the result of clustering 100 points\nthat are randomly (uniformly) distributed on the unit square.  The original\npoints are shown in Figure 8.26(a), while the clusters found by DBSCAN, K-\nmeans, and complete link are shown in Figures 8.26(b), 8.26(c), and 8.26(d),\nrespectively. Since DBSCAN found three clusters (after we setEpsby looking\nat the distances of the fourth nearest neighbors), we set K-means and complete\nlink to find three clusters as well.  (In Figure 8.26(b) the noise is shown by\nthe small markers.)  However, the clusters do not look compelling for any of\n\n8.5Cluster Evaluation533\nthe three methods.  In higher dimensions, such problems cannot be so easily\ndetected.\n8.5.1   Overview\nBeing able to distinguish whether there is non-random structure in the data\nis just one important aspect of cluster validation.  The following is a list of\nseveral important issues for cluster validation.\n1.  Determining theclustering tendencyof a set of data, i.e., distinguish-\ning whether non-random structure actually exists in the data.\n2.  Determining the correct number of clusters.\n3.  Evaluating how well the results of a cluster analysis fit the datawithout\nreference to external information.\n4.  Comparing the results of a cluster analysis to externally known results,\nsuch as externally provided class labels.\n5.  Comparing two sets of clusters to determine which is better.\nNotice that items 1, 2, and 3 do not make use of any external information—\nthey are unsupervised techniques—while item 4 requires external information.\nItem 5 can be performed in either a supervised or an unsupervised manner. A\nfurther distinction can be made with respect to items 3, 4, and 5: Do we want\nto evaluate the entire clustering or just individual clusters?\nWhile it is possible to develop various numerical measures to assess the\ndifferent aspects of cluster validity mentioned above, there are a number of\nchallenges.  First, a measure of cluster validity may be quite limited in the\nscope of its applicability.  For example, most work on measures of clustering\ntendency has been done for two- or three-dimensional spatial data.  Second,\nwe need a framework to interpret any measure. If we obtain a value of 10 for a\nmeasure that evaluates how well cluster labels match externally provided class\nlabels, does this value represent a good, fair, or poor match?  The goodness\nof a match often can be measured by looking at the statistical distribution of\nthis value, i.e., how likely it is that such a value occurs by chance. Finally, if\na measure is too complicated to apply or to understand, then few will use it.\nThe evaluation measures,  or indices,  that are applied to judge various\naspects of cluster validity are traditionally classified into the following three\ntypes.\n\n534   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n(a) Original points.(b) Three clusters found by DBSCAN.\n(c) Three clusters found by K-means.(d)  Three  clusters  found  by  complete\nlink.\nFigure 8.26.Clustering of 100 uniformly distributed points.\n\n8.5Cluster Evaluation535\nUnsupervised.Measures the goodness of a clustering structure without re-\nspect to external information.  An example of this is the SSE. Unsu-\npervised measures of cluster validity are often further divided into two\nclasses: measures ofcluster cohesion(compactness, tightness), which\ndetermine how closely related the objects in a cluster are, and measures\nofcluster separation(isolation), which determine how distinct or well-\nseparated a cluster is from other clusters.  Unsupervised measures are\noften calledinternal indicesbecause they use only information present\nin the data set.\nSupervised.Measures the extent to which the clustering structure discovered\nby a clustering algorithm matches some external structure. An example\nof a supervised index is entropy, which measures how well cluster labels\nmatch externally supplied class labels.  Supervised measures are often\ncalledexternal indicesbecause they use information not present in\nthe data set.\nRelative.Compares different clusterings or clusters. A relative cluster eval-\nuation measure is a supervised or unsupervised evaluation measure that\nis used for the purpose of comparison.  Thus, relative measures are not\nactually a separate type of cluster evaluation measure, but are instead a\nspecific use of such measures.  As an example, two K-means clusterings\ncan be compared using either the SSE or entropy.\nIn the remainder of this section, we provide specific details concerning clus-\nter validity. We first describe topics related to unsupervised cluster evaluation,\nbeginning with (1) measures based on cohesion and separation, and (2) two\ntechniques based on the proximity matrix.  Since these approaches are useful\nonly for partitional sets of clusters, we also describe the popular cophenetic\ncorrelation coefficient, which can be used for the unsupervised evaluation of\na hierarchical clustering.  We end our discussion of unsupervised evaluation\nwith brief discussions about finding the correct number of clusters and evalu-\nating clustering tendency. We then consider supervised approaches to cluster\nvalidity, such as entropy, purity, and the Jaccard measure.  We conclude this\nsection with a short discussion of how to interpret the values of (unsupervised\nor supervised) validity measures.\n\n536   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n8.5.2   Unsupervised  Cluster  Evaluation  Using  Cohesion  and\nSeparation\nMany internal measures of cluster validity for partitional clustering schemes\nare based on the notions of cohesion or separation.  In this section, we use\ncluster validity measures for prototype- and graph-based clustering techniques\nto explore these notions in some detail.  In the process, we will also see some\ninteresting relationships between prototype- and graph-based clustering.\nIn general, we can consider expressing overall cluster validity for a set of\nKclusters as a weighted sum of the validity of individual clusters,\noverall validity=\nK\n∑\ni=1\nw\ni\nvalidity(C\ni\n).(8.8)\nThevalidityfunction can be cohesion, separation, or some combination of these\nquantities.  The weights will vary depending on the cluster validity measure.\nIn some cases, the weights are simply 1 or the size of the cluster, while in other\ncases they reflect a more complicated property, such as the square root of the\ncohesion. See Table 8.6. If the validity function is cohesion, then higher values\nare better. If it is separation, then lower values are better.\nGraph-Based View of Cohesion and Separation\nFor graph-based clusters, the cohesion of a cluster can be defined as the sum of\nthe weights of the links in the proximity graph that connect points within the\ncluster. See Figure 8.27(a). (Recall that the proximity graph has data objects\nas nodes, a link between each pair of data objects, and a weight assigned to\neach link that is the proximity between the two data objects connected by the\nlink.)  Likewise, the separation between two clusters can be measured by the\nsum of the weights of the links from points in one cluster to points in the other\ncluster. This is illustrated in Figure 8.27(b).\nMathematically, cohesion and separation for a graph-based cluster can be\nexpressed using Equations 8.9 and 8.10, respectively. Theproximityfunction\ncan be a similarity, a dissimilarity, or a simple function of these quantities.\ncohesion(C\ni\n)=\n∑\nx∈C\ni\ny∈C\ni\nproximity(x,y)(8.9)\nseparation(C\ni\n,C\nj\n)=\n∑\nx∈C\ni\ny∈C\nj\nproximity(x,y)(8.10)\n\n8.5Cluster Evaluation537\n(a) Cohesion.(b) Separation.\nFigure 8.27.Graph-based view of cluster cohesion and separation.\nPrototype-Based View of Cohesion and Separation\nFor prototype-based clusters, the cohesion of a cluster can be defined as the\nsum of the proximities with respect to the prototype (centroid or medoid) of\nthe cluster.  Similarly, the separation between two clusters can be measured\nby the proximity of the two cluster prototypes.  This is illustrated in Figure\n8.28, where the centroid of a cluster is indicated by a “+”.\nCohesion for a prototype-based cluster is given in Equation 8.11, while\ntwo measures for separation are given in Equations 8.12 and 8.13,  respec-\ntively, wherec\ni\nis the prototype (centroid) of clusterC\ni\nandcis the overall\nprototype (centroid).  There are two measures for separation because, as we\nwill see shortly, the separation of cluster prototypes from an overall prototype\nis sometimes directly related to the separation of cluster prototypes from one\nanother. Note that Equation 8.11 is the cluster SSE if we let proximity be the\nsquared Euclidean distance.\ncohesion(C\ni\n)=\n∑\nx∈C\ni\nproximity(x,c\ni\n)(8.11)\nseparation(C\ni\n,C\nj\n)=proximity(c\ni\n,c\nj\n)(8.12)\nseparation(C\ni\n)=proximity(c\ni\n,c)(8.13)\nOverall Measures of Cohesion and Separation\nThe previous definitions of cluster cohesion and separation gave us some sim-\nple and well-defined measures of cluster validity that can be combined into\nan overall measure of cluster validity by using a weighted sum, as indicated\n\n538   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n+\n(a) Cohesion.\n+\n+\n(b) Separation.\nFigure 8.28.Prototype-based view of cluster cohesion and separation.\nin Equation 8.8.  However, we need to decide what weights to use.  Not sur-\nprisingly, the weights used can vary widely, although typically they are some\nmeasure of cluster size.\nTable 8.6 provides examples of validity measures based on cohesion and\nseparation.I\n1\nis a measure of cohesion in terms of the pairwise proximity of\nobjects in the cluster divided by the cluster size.I\n2\nis a measure of cohesion\nbased on the sum of the proximities of objects in the cluster to the cluster\ncentroid.E\n1\nis a measure of separation defined as the proximity of a cluster\ncentroid to the overall centroid multiplied by the number of objects in the\ncluster.G\n1\n, which is a measure based on both cohesion and separation, is\nthe sum of the pairwise proximity of all objects in the cluster with all objects\noutside the cluster—the total weight of the edges of the proximity graph that\nmust be cut to separate the cluster from all other clusters—divided by the\nsum of the pairwise proximity of objects in the cluster.\nTable 8.6.Table of graph-based cluster evaluation measures.\nNameCluster MeasureCluster WeightType\nI\n1\n∑\nx∈C\ni\ny∈C\ni\nproximity(x,y)\n1\nm\ni\ngraph-based\ncohesion\nI\n2\n∑\nx∈C\ni\nproximity(x,c\ni\n)\n1\nprototype-based\ncohesion\nE\n1\nproximity(c\ni\n,c)m\ni\nprototype-based\nseparation\nG\n1\n∑\nk\nj=1\nj\u0002=i\n∑\nx∈C\ni\ny∈C\nj\nproximity(x,y)\n1\n∑\nx∈C\ni\ny∈C\ni\nproximity(x,y)\ngraph-based\nseparation and\ncohesion\n\n8.5Cluster Evaluation539\nNote that any unsupervised measure of cluster validity potentially can be\nused as an objective function for a clustering algorithm and vice versa.  The\nCLUstering TOolkit (CLUTO) (see the bibliographic notes) uses the cluster\nevaluation measures described in Table 8.6, as well as some other evaluation\nmeasures not mentioned here, to drive the clustering process. It does this by\nusing an algorithm that is similar to the incremental K-means algorithm dis-\ncussed in Section 8.2.2. Specifically, each point is assigned to the cluster that\nproduces the best value for the cluster evaluation function.  The cluster eval-\nuation measureI\n2\ncorresponds to traditional K-means and produces clusters\nthat have good SSE values. The other measures produce clusters that are not\nas good with respect to SSE, but that are more optimal with respect to the\nspecified cluster validity measure.\nRelationship between Prototype-Based Cohesion and Graph-Based\nCohesion\nWhile the graph-based and prototype-based approaches to measuring the co-\nhesion and separation of a cluster seem distinct, for some proximity measures\nthey are equivalent. For instance, for the SSE and points in Euclidean space,\nit can be shown (Equation 8.14) that the average pairwise distance between\nthe points in a cluster is equivalent to the SSE of the cluster. See Exercise 27\non page 566.\nCluster SSE =\n∑\nx∈C\ni\ndist(c\ni\n,x)\n2\n=\n1\n2m\ni\n∑\nx∈C\ni\n∑\ny∈C\ni\ndist(x,y)\n2\n(8.14)\nTwo Approaches to Prototype-Based Separation\nWhen proximity is measured by Euclidean distance, the traditional measure of\nseparation between clusters is the between group sum of squares (SSB), which\nis the sum of the squared distance of a cluster centroid,c\ni\n, to the overall mean,\nc, of all the data points. By summing the SSB over all clusters, we obtain the\ntotal SSB, which is given by Equation 8.15, wherec\ni\nis the mean of thei\nth\ncluster andcis the overall mean.  The higher the total SSB of a clustering,\nthe more separated the clusters are from one another.\nTotal SSB =\nK\n∑\ni=1\nm\ni\ndist(c\ni\n,c)\n2\n(8.15)\nIt is straightforward to show that the total SSB is directly related to the\npairwise distances between the centroids. In particular, if the cluster sizes are\n\n540   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nequal, i.e.,m\ni\n=m/K, then this relationship takes the simple form given by\nEquation 8.16. (See Exercise 28 on page 566.) It is this type of equivalence that\nmotivates the definition of prototype separation in terms of both Equations\n8.12 and 8.13.\nTotal SSB =\n1\n2K\nK\n∑\ni=1\nK\n∑\nj=1\nm\nK\ndist(c\ni\n,c\nj\n)\n2\n(8.16)\nRelationship between Cohesion and Separation\nIn some cases, there is also a strong relationship between cohesion and separa-\ntion. Specifically, it is possible to show that the sum of the total SSE and the\ntotal SSB is a constant; i.e., that it is equal to the total sum of squares (TSS),\nwhich is the sum of squares of the distance of each point to the overall mean\nof the data. The importance of this result is that minimizing SSE (cohesion)\nis equivalent to maximizing SSB (separation).\nWe provide the proof of this fact below,  since the approach illustrates\ntechniques that are also applicable to proving the relationships stated in the\nlast two sections.  To simplify the notation, we assume that the data is one-\ndimensional, i.e.,dist(x, y)=(x−y)\n2\n. Also, we use the fact that the cross-term\n∑\nK\ni=1\n∑\nx∈C\ni\n(x−c\ni\n)(c−c\ni\n) is 0. (See Exercise 29 on page 566.)\nTSS   =\nK\n∑\ni=1\n∑\nx∈C\ni\n(x−c)\n2\n=\nK\n∑\ni=1\n∑\nx∈C\ni\n((x−c\ni\n)−(c−c\ni\n))\n2\n=\nK\n∑\ni=1\n∑\nx∈C\ni\n(x−c\ni\n)\n2\n−2\nK\n∑\ni=1\n∑\nx∈C\ni\n(x−c\ni\n)(c−c\ni\n)+\nK\n∑\ni=1\n∑\nx∈C\ni\n(c−c\ni\n)\n2\n=\nK\n∑\ni=1\n∑\nx∈C\ni\n(x−c\ni\n)\n2\n+\nK\n∑\ni=1\n∑\nx∈C\ni\n(c−c\ni\n)\n2\n=\nK\n∑\ni=1\n∑\nx∈C\ni\n(x−c\ni\n)\n2\n+\nK\n∑\ni=1\n|C\ni\n|(c−c\ni\n)\n2\n=   SSE + SSB\n\n8.5Cluster Evaluation541\nEvaluating Individual Clusters and Objects\nSo far, we have focused on using cohesion and separation in the overall eval-\nuation of a group of clusters.  Many of these measures of cluster validity also\ncan be used to evaluate individual clusters and objects. For example, we can\nrank individual clusters according to their specific value of cluster validity, i.e.,\ncluster cohesion or separation. A cluster that has a high value of cohesion may\nbe considered better than a cluster that has a lower value.  This information\noften can be used to improve the quality of a clustering.  If, for example, a\ncluster is not very cohesive, then we may want to split it into several subclus-\nters.  On the other hand, if two clusters are relatively cohesive, but not well\nseparated, we may want to merge them into a single cluster.\nWe can also evaluate the objects within a cluster in terms of their con-\ntribution to the overall cohesion or separation of the cluster.  Objects that\ncontribute more to the cohesion and separation are near the “interior” of the\ncluster.  Those objects for which the opposite is true are probably near the\n“edge” of the cluster.  In the following section, we consider a cluster evalua-\ntion measure that uses an approach based on these ideas to evaluate points,\nclusters, and the entire set of clusters.\nThe Silhouette Coefficient\nThe popular method of silhouette coefficients combines both cohesion and sep-\naration. The following steps explain how to compute the silhouette coefficient\nfor an individual point, a process that consists of the following three steps.\nWe use distances, but an analogous approach can be used for similarities.\n1.  For thei\nth\nobject, calculate its average distance to all other objects in\nits cluster. Call this valuea\ni\n.\n2.  For thei\nth\nobject and any cluster not containing the object, calculate\nthe object’s average distance to all the objects in the given cluster. Find\nthe minimum such value with respect to all clusters; call this valueb\ni\n.\n3.  For thei\nth\nobject, the silhouette coefficient iss\ni\n=(b\ni\n−a\ni\n)/max(a\ni\n,b\ni\n).\nThe value of the silhouette coefficient can vary between−1 and 1.   A\nnegative value is undesirable because this corresponds to a case in whicha\ni\n,\nthe average distance to points in the cluster, is greater thanb\ni\n, the minimum\naverage distance to points in another cluster. We want the silhouette coefficient\nto be positive (a\ni\n<b\ni\n), and fora\ni\nto be as close to 0 as possible, since the\ncoefficient assumes its maximum value of 1 whena\ni\n=0.\n\n542   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n00.10.20.30.40.50.60.70.80.91\nSilhouette Coefficient\nFigure 8.29.Silhouette coefficients for points in ten clusters.\nWe can compute the average silhouette coefficient of a cluster by simply\ntaking the average of the silhouette coefficients of points belonging to the\ncluster. An overall measure of the goodness of a clustering can be obtained by\ncomputing the average silhouette coefficient of all points.\nExample 8.8 (Silhouette Coefficient).Figure 8.29 shows a plot of the\nsilhouette coefficients for points in 10 clusters.  Darker shades indicate lower\nsilhouette coefficients.\n8.5.3   Unsupervised Cluster Evaluation Using the Proximity\nMatrix\nIn this section, we examine a couple of unsupervised approaches for assessing\ncluster validity that are based on the proximity matrix. The first compares an\nactual and idealized proximity matrix, while the second uses visualization.\nMeasuring Cluster Validity via Correlation\nIf we are given the similarity matrix for a data set and the cluster labels from\na cluster analysis of the data set,  then we can evaluate the “goodness” of\nthe clustering by looking at the correlation between the similarity matrix and\nan ideal version of the similarity matrix based on the cluster labels.  (With\nminor changes, the following applies to proximity matrices, but for simplicity,\nwe discuss only similarity matrices.) More specifically, an ideal cluster is one\nwhose points have a similarity of 1 to all points in the cluster, and a similarity\nof 0 to all points in other clusters.  Thus, if we sort the rows and columns\nof the similarity matrix so that all objects belonging to the same class are\ntogether, then an ideal similarity matrix has ablock diagonalstructure. In\nother words, the similarity is non-zero, i.e., 1, inside the blocks of the similarity\n\n8.5Cluster Evaluation543\nmatrix whose entries represent intra-cluster similarity, and 0 elsewhere.  The\nideal similarity matrix is constructed by creating a matrix that has one row\nand one column for each data point—just like an actual similarity matrix—\nand assigning a 1 to an entry if the associated pair of points belongs to the\nsame cluster. All other entries are 0.\nHigh correlation between the ideal and actual similarity matrices indicates\nthat the points that belong to the same cluster are close to each other, while\nlow correlation indicates the opposite.  (Since the actual and ideal similarity\nmatrices are symmetric, the correlation is calculated only among then(n−1)/2\nentries below or above the diagonal of the matrices.) Consequently, this is not\na good measure for many density- or contiguity-based clusters, because they\nare not globular and may be closely intertwined with other clusters.\nExample 8.9 (Correlation of Actual and Ideal Similarity Matrices).\nTo illustrate this measure, we calculated the correlation between the ideal and\nactual similarity matrices for the K-means clusters shown in Figure 8.26(c)\n(random data) and Figure 8.30(a) (data with three well-separated clusters).\nThe correlations were 0.5810 and 0.9235, respectively, which reflects the ex-\npected result that the clusters found by K-means in the random data are worse\nthan the clusters found by K-means in data with well-separated clusters.\nJudging a Clustering Visually by Its Similarity Matrix\nThe previous technique suggests a more general, qualitative approach to judg-\ning a set of clusters: Order the similarity matrix with respect to cluster labels\nand then plot it.  In theory, if we have well-separated clusters, then the simi-\nlarity matrix should be roughly block-diagonal. If not, then the patterns dis-\nplayed in the similarity matrix can reveal the relationships between clusters.\nAgain, all of this can be applied to dissimilarity matrices, but for simplicity,\nwe will only discuss similarity matrices.\nExample 8.10 (Visualizing a Similarity Matrix).Consider the points in\nFigure 8.30(a), which form three well-separated clusters. If we use K-means to\ngroup these points into three clusters, then we should have no trouble finding\nthese clusters since they are well-separated.  The separation of these clusters\nis illustrated by the reordered similarity matrix shown in Figure 8.30(b). (For\nuniformity, we have transformed the distances into similarities using the for-\nmulas=1−(d−min\nd)/(maxd−mind).) Figure 8.31 shows the reordered\nsimilarity matrices for clusters found in the random data set of Figure 8.26 by\nDBSCAN, K-means, and complete link.\n\n544   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n00.20.40.60.81\n0\n0.2\n0.4\n0.6\n0.8\n1\nx\ny\n(a) Well-separated clusters.\nPoints\nPoints\n20406080100\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nSimilarity\n0\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n(b) Similarity matrix sorted by K-means\ncluster labels.\nFigure 8.30.Similarity matrix for well-separated clusters.\nThe  well-separated  clusters  in  Figure  8.30  show  a  very  strong,  block-\ndiagonal pattern in the reordered similarity matrix.  However, there are also\nweak block diagonal patterns—see Figure 8.31—in the reordered similarity\nmatrices of the clusterings found by K-means, DBSCAN, and complete link\nin the random data.  Just as people can find patterns in clouds, data mining\nalgorithms can find clusters in random data.  While it is entertaining to find\npatterns in clouds, it is pointless and perhaps embarrassing to find clusters in\nnoise.\nThis approach may seem hopelessly expensive for large data sets, since\nthe computation of the proximity matrix takesO(m\n2\n) time, wheremis the\nnumber of objects, but with sampling, this method can still be used. We can\ntake a sample of data points from each cluster, compute the similarity between\nthese points, and plot the result.  It may be necessary to oversample small\nclusters and undersample large ones to obtain an adequate representation of\nall clusters.\n8.5.4   Unsupervised Evaluation of Hierarchical Clustering\nThe previous approaches to cluster evaluation are intended for partitional\nclusterings.  Here we discuss the cophenetic correlation, a popular evaluation\nmeasure for hierarchical clusterings. Thecophenetic distancebetween two\nobjects is the proximity at which an agglomerative hierarchical clustering tech-\n\n8.5Cluster Evaluation545\nPoints\nPoints\n20406080100\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nSimilarity\n0\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n(a)  Similarity  matrix\nsorted   by   DBSCAN\ncluster labels.\nPoints\nPoints\n20406080100\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nSimilarity\n0\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n(b)  Similarity  matrix\nsorted    by    K-means\ncluster labels.\nPoints\nPoints\n20406080100\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nSimilarity\n0\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n(c)  Similarity  matrix\nsorted by complete link\ncluster labels.\nFigure 8.31.Similarity matrices for clusters from random data.\nnique puts the objects in the same cluster for the first time. For example, if at\nsome point in the agglomerative hierarchical clustering process, the smallest\ndistance between the two clusters that are merged is 0.1, then all points in\none cluster have a cophenetic distance of 0.1 with respect to the points in the\nother cluster. In a cophenetic distance matrix, the entries are the cophenetic\ndistances between each pair of objects.  The cophenetic distance is different\nfor each hierarchical clustering of a set of points.\nExample 8.11 (Cophenetic Distance Matrix).Table 8.7 shows the cophen-\ntic distance matrix for the single link clustering shown in Figure 8.16.  (The\ndata for this figure consists of the 6 two-dimensional points given in Table\n8.3.)\nTable 8.7.Cophenetic distance matrix for single link and data in table 8.3\nPointP1P2P3P4P5P6\nP100.2220.2220.2220.2220.222\nP20.22200.1480.1510.1390.148\nP30.2220.14800.1510.1480.110\nP40.2220.1510.15100.1510.151\nP50.2220.1390.1480.15100.148\nP60.2220.1480.1100.1510.1480\nTheCoPhenetic Correlation Coefficient(CPCC) is the correlation\nbetween the entries of this matrix and the original dissimilarity matrix and is\n\n546   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\na standard measure of how well a hierarchical clustering (of a particular type)\nfits the data.  One of the most common uses of this measure is to evaluate\nwhich type of hierarchical clustering is best for a particular type of data.\nExample 8.12 (Cophenetic Correlation Coefficient).We calculated the\nCPCC for the hierarchical clusterings shown in Figures 8.16–8.19.These values\nare shown in Table 8.8.  The hierarchical clustering produced by the single\nlink technique seems to fit the data less well than the clusterings produced by\ncomplete link, group average, and Ward’s method.\nTable 8.8.Cophenetic correlation coefficient for data of Table 8.3 and four agglomerative hierarchical\nclustering techniques.\nTechniqueCPCC\nSingle Link0.44\nComplete Link0.63\nGroup Average0.66\nWard’s0.64\n8.5.5   Determining the Correct Number of Clusters\nVarious  unsupervised  cluster  evaluation  measures  can  be  used  to  approxi-\nmately determine the correct or natural number of clusters.\nExample 8.13 (Number of Clusters).The data set of Figure 8.29 has 10\nnatural clusters.  Figure 8.32 shows a plot of the SSE versus the number of\nclusters for a (bisecting) K-means clustering of the data set, while Figure 8.33\nshows the average silhouette coefficient versus the number of clusters for the\nsame data.  There is a distinct knee in the SSE and a distinct peak in the\nsilhouette coefficient when the number of clusters is equal to 10.\nThus, we can try to find the natural number of clusters in a data set by\nlooking for the number of clusters at which there is a knee, peak, or dip in\nthe plot of the evaluation measure when it is plotted against the number of\nclusters. Of course, such an approach does not always work well. Clusters may\nbe considerably more intertwined or overlapping than those shown in Figure\n8.29.  Also, the data may consist of nested clusters.  Actually, the clusters in\nFigure 8.29 are somewhat nested; i.e., there are 5 pairs of clusters since the\nclusters are closer top to bottom than they are left to right.  There is a knee\nthat indicates this in the SSE curve, but the silhouette coefficient curve is not\n\n8.5Cluster Evaluation547\n10\n8\n6\n4\n2\n0\n051015202530\nNumber of Clusters\nSSE\nFigure 8.32.SSE versus number of clusters for\nthe data of Figure 8.29.\n0.75\n0.7\n0.55\n0.4\n0.35\n0.3\n051015202530\nNumber of Clusters\nSilhouette Coefficient\n0.65\n0.6\n0.45\n0.5\nFigure 8.33.Average silhouette coefficient ver-\nsus number of clusters for the data of Figure\n8.29.\nas clear.  In summary, while caution is needed, the technique we have just\ndescribed can provide insight into the number of clusters in the data.\n8.5.6   Clustering Tendency\nOne obvious way to determine if a data set has clusters is to try to cluster\nit. However, almost all clustering algorithms will dutifully find clusters when\ngiven data. To address this issue, we could evaluate the resulting clusters and\nonly claim that a data set has clusters if at least some of the clusters are of good\nquality.  However, this approach does not address the fact the clusters in the\ndata can be of a different type than those sought by our clustering algorithm.\nTo handle this additional problem, we could use multiple algorithms and again\nevaluate the quality of the resulting clusters. If the clusters are uniformly poor,\nthen this may indeed indicate that there are no clusters in the data.\nAlternatively, and this is the focus of measures of clustering tendency, we\ncan try to evaluate whether a data set has clusters without clustering.  The\nmost common approach, especially for data in Euclidean space, has been to\nuse statistical tests for spatial randomness.  Unfortunately, choosing the cor-\nrect model, estimating the parameters, and evaluating the statistical signifi-\ncance of the hypothesis that the data is non-random can be quite challenging.\nNonetheless, many approaches have been developed, most of them for points\nin low-dimensional Euclidean space.\nExample 8.14 (Hopkins Statistic).For this approach, we generateppoints\nthat are randomly distributed across the data space and also samplepactual\n\n548   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\ndata points. For both sets of points we find the distance to the nearest neigh-\nbor in the original data set. Let theu\ni\nbe the nearest neighbor distances of the\nartificially generated points, while thew\ni\nare the nearest neighbor distances\nof the sample of points from the original data set. The Hopkins statisticHis\nthen defined by Equation 8.17.\nH=\n∑\np\ni=1\nw\ni\n∑\np\ni=1\nu\ni\n+\n∑\np\ni=1\nw\ni\n(8.17)\nIf  the  randomly  generated  points  and  the  sample  of  data  points  have\nroughly the same nearest neighbor distances, thenHwill be near 0.5. Values\nofHnear 0 and 1 indicate, respectively, data that is highly clustered and\ndata that is regularly distributed in the data space.  To give an example, the\nHopkins statistic for the data of Figure 8.26 was computed forp= 20 and 100\ndifferent trials.  The average value ofHwas 0.56 with a standard deviation\nof 0.03. The same experiment was performed for the well-separated points of\nFigure 8.30.  The average value ofHwas 0.95 with a standard deviation of\n0.006.\n8.5.7   Supervised Measures of Cluster Validity\nWhen we have external information about data, it is typically in the form of\nexternally derived class labels for the data objects.  In such cases, the usual\nprocedure is to measure the degree of correspondence between the cluster labels\nand the class labels. But why is this of interest? After all, if we have the class\nlabels, then what is the point in performing a cluster analysis? Motivations for\nsuch an analysis are the comparison of clustering techniques with the “ground\ntruth” or the evaluation of the extent to which a manual classification process\ncan be automatically produced by cluster analysis.\nWe consider two different kinds of approaches. The first set of techniques\nuse measures from classification, such as entropy, purity, and the F-measure.\nThese measures evaluate the extent to which a cluster contains objects of a\nsingle class. The second group of methods is related to the similarity measures\nfor binary data, such as the Jaccard measure that we saw in Chapter 2. These\napproaches measure the extent to which two objects that are in the same class\nare in the same cluster and vice versa. For convenience, we will refer to these\ntwo types of measures asclassification-orientedandsimilarity-oriented,\nrespectively.\n\n8.5Cluster Evaluation549\nClassification-Oriented Measures of Cluster Validity\nThere are a number of measures—entropy, purity, precision, recall, and the\nF-measure—that are commonly used to evaluate the performance of a classi-\nfication model.  In the case of classification, we measure the degree to which\npredicted class labels correspond to actual class labels, but for the measures\njust mentioned, nothing fundamental is changed by using cluster labels in-\nstead of predicted class labels. Next, we quickly review the definitions of these\nmeasures, which were discussed in Chapter 4.\nEntropy:The degree to which each cluster consists of objects of a single class.\nFor each cluster, the class distribution of the data is calculated first, i.e.,\nfor clusterjwe computep\nij\n, the probability that a member of clusteri\nbelongs to classjasp\nij\n=m\nij\n/m\ni\n, wherem\ni\nis the number of objects in\nclusteriandm\nij\nis the number of objects of classjin clusteri.Using\nthis class distribution, the entropy of each clusteriis calculated using\nthe standard formula,e\ni\n=−\n∑\nL\nj=1\np\nij\nlog\n2\np\nij\n, whereLis the number of\nclasses.  The total entropy for a set of clusters is calculated as the sum\nof the entropies of each cluster weighted by the size of each cluster, i.e.,\ne=\n∑\nK\ni=1\nm\ni\nm\ne\ni\n, whereKis the number of clusters andmis the total\nnumber of data points.\nPurity:Another measure of the extent to which a cluster contains objects of\na single class.  Using the previous terminology, the purity of clusteriis\np\ni\n=max\nj\np\nij\n, the overall purity of a clustering ispurity=\n∑\nK\ni=1\nm\ni\nm\np\ni\n.\nPrecision:The fraction of a cluster that consists of objects of a specified class.\nThe precision of clusteriwith respect to classjisprecision(i, j)=p\nij\n.\nRecall:The extent to which a cluster contains all objects of a specified class.\nThe recall of clusteriwith respect to classjisrecall(i, j)=m\nij\n/m\nj\n,\nwherem\nj\nis the number of objects in classj.\nF-measureA combination of both precision and recall that measures the\nextent to which a cluster containsonlyobjects of a particular class andall\nobjects of that class. The F-measure of clusteriwith respect to classjis\nF(i, j)=(2×precision(i, j)×recall(i, j))/(precision(i, j)+recall(i, j)).\nExample 8.15 (Supervised Evaluation Measures).We present an exam-\nple to illustrate these measures. Specifically, we use K-means with the cosine\nsimilarity measure to cluster 3204 newspaper articles from theLos Angeles\n\n550   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nTable 8.9.K-means clustering results for theLA Timesdocument data set.\nClusterEnter-\ntainment\nFinancialForeignMetroNationalSportsEntropyPurity\n1354050696271.22700.7474\n247280293921.14720.7756\n3111746710.18130.9796\n41016231197321.74870.4390\n53312257013231.39760.7134\n653581221248131.55230.5525\nTotal3545553419432737381.14500.7203\nTimes.  These articles come from six different classes: Entertainment, Finan-\ncial, Foreign, Metro, National, and Sports.  Table 8.9 shows the results of a\nK-means clustering to find six clusters.  The first column indicates the clus-\nter, while the next six columns together form the confusion matrix; i.e., these\ncolumns indicate how the documents of each category are distributed among\nthe clusters. The last two columns are the entropy and purity of each cluster,\nrespectively.\nIdeally, each cluster will contain documents from only one class. In reality,\neach cluster contains documents from many classes. Nevertheless, many clus-\nters contain documents primarily from just one class.  In particular, cluster\n3, which contains mostly documents from the Sports section, is exceptionally\ngood, both in terms of purity and entropy.  The purity and entropy of the\nother clusters is not as good, but can typically be greatly improved if the data\nis partitioned into a larger number of clusters.\nPrecision, recall, and the F-measure can be calculated for each cluster. To\ngive a concrete example, we consider cluster 1 and the Metro class of Table\n8.9. The precision is 506/677 = 0.75, recall is 506/943 = 0.26, and hence, the\nF value is 0.39. In contrast, the F value for cluster 3 and Sports is 0.94.\nSimilarity-Oriented Measures of Cluster Validity\nThe measures that we discuss in this section are all based on the premise\nthat any two objects that are in the same cluster should be in the same class\nand vice versa.  We can view this approach to cluster validity as involving\nthe comparison of two matrices:  (1) theideal cluster similarity matrix\ndiscussed previously, which has a 1 in theij\nth\nentry if two objects,iandj,\nare in the same cluster and 0, otherwise, and (2) anideal class similarity\nmatrixdefined with respect to class labels, which has a 1 in theij\nth\nentry if\n\n8.5Cluster Evaluation551\ntwo objects,iandj, belong to the same class, and a 0 otherwise. As before, we\ncan take the correlation of these two matrices as the measure of cluster validity.\nThis measure is known as the Γ statistic in clustering validation literature.\nExample 8.16 (Correlation between Cluster and Class Matrices).To\ndemonstrate this idea more concretely, we give an example involving five data\npoints,p\n1\n,p\n2\n,p\n3\n,p\n4\n,p\n5\n, two clusters,C\n1\n={p\n1\n,p\n2\n,p\n3\n}andC\n2\n={p\n4\n,p\n5\n}, and\ntwo classes,L\n1\n={p\n1\n,p\n2\n}andL2={p\n3\n,p\n4\n,p\n5\n}.  The ideal cluster and class\nsimilarity matrices are given in Tables 8.10 and 8.11. The correlation between\nthe entries of these two matrices is 0.359.\nTable 8.10.Ideal cluster similarity matrix.\nPointp1    p2    p3    p4    p5\np111100\np211100\np311100\np400011\np500011\nTable 8.11.Ideal class similarity matrix.\nPointp1    p2    p3    p4    p5\np111000\np211000\np300111\np400111\np500111\nMore generally, we can use any of the measures for binary similarity that\nwe saw in Section 2.4.5. (For example, we can convert these two matrices into\nbinary vectors by appending the rows.) We repeat the definitions of the four\nquantities used to define those similarity measures, but modify our descriptive\ntext to fit the current context. Specifically, we need to compute the following\nfour quantities for all pairs of distinct objects.  (There arem(m−1)/2 such\npairs, ifmis the number of objects.)\nf\n00\n= number of pairs of objects having a different class and a different cluster\nf\n01\n= number of pairs of objects having a different class and the same cluster\nf\n10\n= number of pairs of objects having the same class and a different cluster\nf\n11\n= number of pairs of objects having the same class and the same cluster\nIn particular, the simple matching coefficient, which is known as the Rand\nstatistic in this context, and the Jaccard coefficient are two of the most fre-\nquently used cluster validity measures.\nRand statistic =\nf\n00\n+f\n11\nf\n00\n+f\n01\n+f\n10\n+f\n11\n(8.18)\n\n552   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nJaccard coefficient =\nf\n11\nf\n01\n+f\n10\n+f\n11\n(8.19)\nExample 8.17 (Rand and Jaccard Measures).Based on these formulas,\nwe can readily compute the Rand statistic and Jaccard coefficient for the\nexample based on Tables 8.10 and 8.11. Noting thatf\n00\n=4,f\n01\n=2,f\n10\n=2,\nandf\n11\n= 2, the Rand statistic = (2 + 4)/10 = 0.6 and the Jaccard coefficient\n= 2/(2+2+2 ) = 0.33.\nWe also note that the four quantities,f\n00\n,f\n01\n,f\n10\n, andf\n11\n, define acon-\ntingencytable as shown in Table 8.12.\nTable 8.12.Two-way contingency table for determining whether pairs of objects are in the same class\nand same cluster.\nSame ClusterDifferent Cluster\nSame Classf\n11\nf\n10\nDifferent Classf\n01\nf\n00\nPreviously, in the context of association analysis—see Section 6.7.1—we\npresented an extensive discussion of measures of association that can be used\nfor this type of contingency table. (Compare Table 8.12 with Table 6.7.) Those\nmeasures can also be applied to cluster validity.\nCluster Validity for Hierarchical Clusterings\nSo far in this section, we have discussed supervised measures of cluster va-\nlidity only for partitional clusterings.  Supervised evaluation of a hierarchical\nclustering is more difficult for a variety of reasons, including the fact that a\npreexisting hierarchical structure often does not exist.  Here, we will give an\nexample of an approach for evaluating a hierarchical clustering in terms of a\n(flat) set of class labels, which are more likely to be available than a preexisting\nhierarchical structure.\nThe key idea of this approach is to evaluate whether a hierarchical clus-\ntering contains, for each class, at least one cluster that is relatively pure and\nincludes most of the objects of that class.  To evaluate a hierarchical cluster-\ning with respect to this goal, we compute, for each class, the F-measure for\neach cluster in the cluster hierarchy. For each class, we take the maximum F-\nmeasure attained for any cluster. Finally, we calculate an overall F-measure for\nthe hierarchical clustering by computing the weighted average of all per-class\nF-measures, where the weights are based on the class sizes.  More formally,\n\n8.5Cluster Evaluation553\nthis hierarchical F-measure is defined as follows:\nF=\n∑\nj\nm\nj\nm\nmax\ni\nF(i, j)\nwhere the maximum is taken over all clustersiat all levels,m\nj\nis the number\nof objects in classj, andmis the total number of objects.\n8.5.8   Assessing the Significance of Cluster Validity Measures\nCluster validity measures are intended to help us measure the goodness of the\nclusters that we have obtained. Indeed, they typically give us a single number\nas a measure of that goodness. However, we are then faced with the problem\nof interpreting the significance of this number, a task that may be even more\ndifficult.\nThe minimum and maximum values of cluster evaluation measures may\nprovide some guidance in many cases. For instance, by definition, a purity of\n0 is bad, while a purity of 1 is good, at least if we trust our class labels and\nwant our cluster structure to reflect the class structure. Likewise, an entropy\nof 0 is good, as is an SSE of 0.\nSometimes, however, there may not be a minimum or maximum value,\nor the scale of the data may affect the interpretation.   Also,  even if there\nare minimum and maximum values with obvious interpretations, intermediate\nvalues still need to be interpreted.  In some cases, we can use an absolute\nstandard.  If, for example, we are clustering for utility, we may be willing to\ntolerate only a certain level of error in the approximation of our points by a\ncluster centroid.\nBut if this is not the case, then we must do something else.  A common\napproach is to interpret the value of our validity measure in statistical terms.\nSpecifically, we attempt to judge how likely it is that our observed value may\nbe achieved by random chance. The value is good if it is unusual; i.e., if it is\nunlikely to be the result of random chance. The motivation for this approach\nis that we are only interested in clusters that reflect non-random structure in\nthe data, and such structures should generate unusually high (low) values of\nour cluster validity measure, at least if the validity measures are designed to\nreflect the presence of strong cluster structure.\nExample 8.18 (Significance of SSE).To show how this works, we present\nan example based on K-means and the SSE. Suppose that we want a measure of\nhow good the well-separated clusters of Figure 8.30 are with respect to random\ndata. We generate many random sets of 100 points having the same range as\n\n554   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n0.0150.020.0250.030.0350.04\n0\n10\n20\n30\n40\n50\nSSE\nCount\nFigure 8.34.Histogram of SSE for 500 random data sets.\nthe points in the three clusters, find three clusters in each data set using K-\nmeans, and accumulate the distribution of SSE values for these clusterings. By\nusing this distribution of the SSE values, we can then estimate the probability\nof the SSE value for the original clusters. Figure 8.34 shows the histogram of\nthe SSE from 500 random runs. The lowest SSE shown in Figure 8.34 is 0.0173.\nFor the three clusters of Figure 8.30, the SSE is 0.0050.  We could therefore\nconservatively claim that there is less than a 1% chance that a clustering such\nas that of Figure 8.30 could occur by chance.\nTo conclude, we stress that there is more to cluster evaluation—supervised\nor unsupervised—than obtaining a numerical measure of cluster validity. Un-\nless this value has a natural interpretation based on the definition of the mea-\nsure, we need to interpret this value in some way.  If our cluster evaluation\nmeasure is defined such that lower values indicate stronger clusters, then we\ncan use statistics to evaluate whether the value we have obtained is unusually\nlow, provided we have a distribution for the evaluation measure. We have pre-\nsented an example of how to find such a distribution, but there is considerably\nmore to this topic, and we refer the reader to the bibliographic notes for more\npointers.\nFinally, even when an evaluation measure is used as a relative measure,\ni.e., to compare two clusterings, we still need to assess the significance in the\ndifference between the evaluation measures of the two clusterings.  Although\none value will almost always be better than another, it can be difficult to\ndetermine if the difference is significant.  Note that there are two aspects to\nthis significance: whether the difference is statistically significant (repeatable)\n\n8.6Bibliographic Notes555\nand whether the magnitude of the difference is meaningful with respect to the\napplication. Many would not regard a difference of 0.1% as significant, even if\nit is consistently reproducible.\n8.6   Bibliographic Notes\nDiscussion in this chapter has been most heavily influenced by the books on\ncluster analysis written by Jain and Dubes [396], Anderberg [374], and Kauf-\nman and Rousseeuw [400].  Additional clustering books that may also be of\ninterest include those by Aldenderfer and Blashfield [373], Everitt et al. [388],\nHartigan [394], Mirkin [405], Murtagh [407], Romesburg [409], and Sp ̈ath [413].\nA more statistically oriented approach to clustering is given by the pattern\nrecognition book of Duda et al.  [385], the machine learning book of Mitchell\n[406], and the book on statistical learning by Hastie et al.  [395].  A general\nsurvey of clustering is given by Jain et al. [397], while a survey of spatial data\nmining techniques is provided by Han et al.  [393].  Behrkin [379] provides a\nsurvey of clustering techniques for data mining.  A good source of references\nto clustering outside of the data mining field is the article by Arabie and Hu-\nbert [376].  A paper by Kleinberg [401] provides a discussion of some of the\ntrade-offs that clustering algorithms make and proves that it is impossible to\nfor a clustering algorithm to simultaneously possess three simple properties.\nThe K-means algorithm has a long history, but is still the subject of current\nresearch.  The original K-means algorithm was proposed by MacQueen [403].\nThe ISODATA algorithm by Ball and Hall [377] was an early, but sophisticated\nversion of K-means that employed various pre- and postprocessing techniques\nto improve on the basic algorithm.  The K-means algorithm and many of its\nvariations are described in detail in the books by Anderberg [374] and Jain\nand Dubes [396].  The bisecting K-means algorithm discussed in this chapter\nwas described in a paper by Steinbach et al.  [414], and an implementation\nof this and other clustering approaches is freely available for academic use in\nthe CLUTO (CLUstering TOolkit) package created by Karypis [382].  Boley\n[380] has created a divisive partitioning clustering algorithm (PDDP) based\non finding the first principal direction (component) of the data, and Savaresi\nand Boley [411] have explored its relationship to bisecting K-means.  Recent\nvariations of K-means are a new incremental version of K-means (Dhillon et al.\n[383]), X-means (Pelleg and Moore [408]), and K-harmonic means (Zhang et al\n[416]). Hamerly and Elkan [392] discuss some clustering algorithms that pro-\nduce better results than K-means.  While some of the previously mentioned\napproaches address the initialization problem of K-means in some manner,\n\n556   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nother approaches to improving K-means initialization can also be found in the\nwork of Bradley and Fayyad [381].  Dhillon and Modha [384] present a gen-\neralization of K-means, called spherical K-means, that works with commonly\nused similarity functions.  A general framework for K-means clustering that\nuses dissimilarity functions based on Bregman divergences was constructed by\nBanerjee et al. [378].\nHierarchical clustering techniques also have a long history.  Much of the\ninitial activity was in the area of taxonomy and is covered in books by Jardine\nand Sibson [398] and Sneath and Sokal [412].  General-purpose discussions of\nhierarchical clustering are also available in most of the clustering books men-\ntioned above. Agglomerative hierarchical clustering is the focus of most work\nin the area of hierarchical clustering, but divisive approaches have also received\nsome attention. For example, Zahn [415] describes a divisive hierarchical tech-\nnique that uses the minimum spanning tree of a graph.  While both divisive\nand agglomerative approaches typically take the view that merging (splitting)\ndecisions are final, there has been some work by Fisher [389] and Karypis et\nal. [399] to overcome these limitations.\nEster et al.  proposed DBSCAN [387], which was later generalized to the\nGDBSCAN algorithm by Sander et al.  [410] in order to handle more general\ntypes of data and distance measures, such as polygons whose closeness is mea-\nsured by the degree of intersection.  An incremental version of DBSCAN was\ndeveloped by Kriegel et al.  [386].  One interesting outgrowth of DBSCAN is\nOPTICS (Ordering Points To Identify the Clustering Structure) (Ankerst et\nal.  [375]), which allows the visualization of cluster structure and can also be\nused for hierarchical clustering.\nAn authoritative discussion of cluster validity, which strongly influenced\nthe discussion in this chapter, is provided in Chapter 4 of Jain and Dubes’\nclustering book [396].   More recent reviews of cluster validity are those of\nHalkidi et al. [390, 391] and Milligan [404]. Silhouette coefficients are described\nin Kaufman and Rousseeuw’s clustering book [400]. The source of the cohesion\nand separation measures in Table 8.6 is a paper by Zhao and Karypis [417],\nwhich also contains a discussion of entropy, purity, and the hierarchical F-\nmeasure.  The original source of the hierarchical F-measure is an article by\nLarsen and Aone [402].\nBibliography\n[373]  M. S. Aldenderfer and R. K. Blashfield.Cluster Analysis.  Sage Publications, Los\nAngeles, 1985.\n[374]  M. R. Anderberg.Cluster Analysis for Applications.   Academic Press,  New York,\nDecember 1973.\n\nBibliography557\n[375]  M. Ankerst, M. M. Breunig, H.-P. Kriegel, and J. Sander. OPTICS: Ordering Points\nTo Identify the Clustering Structure.  InProc. of 1999 ACM-SIGMOD Intl. Conf. on\nManagement of Data, pages 49–60, Philadelphia, Pennsylvania, June 1999. ACM Press.\n[376]  P. Arabie, L. Hubert, and G. D. Soete.   An overview of combinatorial data analysis.\nIn P. Arabie, L. Hubert, and G. D. Soete, editors,Clustering and Classification, pages\n188–217. World Scientific, Singapore, January 1996.\n[377]  G. Ball and D. Hall.  A Clustering Technique for Summarizing Multivariate Data.\nBehavior Science, 12:153–155, March 1967.\n[378]  A. Banerjee, S. Merugu, I. S. Dhillon, and J. Ghosh. Clustering with Bregman Diver-\ngences.  InProc. of the 2004 SIAM Intl. Conf. on Data Mining, pages 234–245, Lake\nBuena Vista, FL, April 2004.\n[379]  P. Berkhin. Survey Of Clustering Data Mining Techniques. Technical report, Accrue\nSoftware, San Jose, CA, 2002.\n[380]  D. Boley.   Principal Direction Divisive Partitioning.Data Mining and Knowledge\nDiscovery, 2(4):325–344, 1998.\n[381]  P. S. Bradley and U. M. Fayyad.  Refining Initial Points for K-Means Clustering.  In\nProc. of the 15th Intl. Conf. on Machine Learning, pages 91–99, Madison, WI, July\n1998. Morgan Kaufmann Publishers Inc.\n[382]  CLUTO2.1.1:SoftwareforClusteringHigh-DimensionalDatasets.\n/www.cs.umn.edu/∼karypis, November 2003.\n[383]  I. S. Dhillon, Y. Guan, and J. Kogan.  Iterative Clustering of High Dimensional Text\nData Augmented by Local Search.  InProc. of the 2002 IEEE Intl. Conf. on Data\nMining, pages 131–138. IEEE Computer Society, 2002.\n[384]  I. S. Dhillon and D. S. Modha.  Concept Decompositions for Large Sparse Text Data\nUsing Clustering.Machine Learning, 42(1/2):143–175, 2001.\n[385]  R. O. Duda, P. E. Hart, and D. G. Stork.Pattern Classification. John Wiley & Sons,\nInc., New York, second edition, 2001.\n[386]  M. Ester, H.-P. Kriegel, J. Sander, M. Wimmer, and X. Xu.  Incremental Clustering\nfor Mining in a Data Warehousing Environment.  InProc. of the 24th VLDB Conf.,\npages 323–333, New York City, August 1998. Morgan Kaufmann.\n[387]  M. Ester, H.-P. Kriegel, J. Sander, and X. Xu.  A Density-Based Algorithm for Dis-\ncovering Clusters in Large Spatial Databases with Noise. InProc. of the 2nd Intl. Conf.\non Knowledge Discovery and Data Mining, pages 226–231, Portland, Oregon, August\n1996. AAAI Press.\n[388]  B. S. Everitt, S. Landau, and M. Leese.Cluster Analysis. Arnold Publishers, London,\nfourth edition, May 2001.\n[389]  D. Fisher. Iterative Optimization and Simplification of Hierarchical Clusterings.Jour-\nnal of Artificial Intelligence Research, 4:147–179, 1996.\n[390]  M. Halkidi, Y. Batistakis, and M. Vazirgiannis.   Cluster validity methods:  part I.\nSIGMOD Record (ACM Special Interest Group on Management of Data), 31(2):40–45,\nJune 2002.\n[391]  M. Halkidi, Y. Batistakis, and M. Vazirgiannis. Clustering validity checking methods:\npart II.SIGMOD Record (ACM Special Interest Group on Management of Data),31\n(3):19–27, Sept. 2002.\n[392]  G. Hamerly and C. Elkan.  Alternatives to the k-means algorithm that find better\nclusterings. InProc. of the 11th Intl. Conf. on Information and Knowledge Management,\npages 600–607, McLean, Virginia, 2002. ACM Press.\n\n558   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n[393]  J. Han, M. Kamber, and A. Tung.   Spatial Clustering Methods in Data Mining:  A\nreview.  In H. J. Miller and J. Han, editors,Geographic Data Mining and Knowledge\nDiscovery, pages 188–217. Taylor and Francis, London, December 2001.\n[394]  J. Hartigan.Clustering Algorithms. Wiley, New York, 1975.\n[395]  T. Hastie, R. Tibshirani, and J. H. Friedman.The Elements of Statistical Learning:\nData Mining, Inference, Prediction. Springer, New York, 2001.\n[396]  A.  K.  Jain  and  R.  C.  Dubes.Algorithms for Clustering Data.    Prentice  Hall\nAdvanced  Reference  Series.  Prentice  Hall,  March  1988.   Book  available  online  at\nhttp://www.cse.msu.edu/∼jain/Clustering\nJainDubes.pdf.\n[397]  A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: A review.ACM Computing\nSurveys, 31(3):264–323, September 1999.\n[398]  N. Jardine and R. Sibson.Mathematical Taxonomy. Wiley, New York, 1971.\n[399]  G. Karypis, E.-H. Han, and V. Kumar.  Multilevel Refinement for Hierarchical Clus-\ntering. Technical Report TR 99-020, University of Minnesota, Minneapolis, MN, 1999.\n[400]  L. Kaufman and P. J. Rousseeuw.Finding Groups in Data: An Introduction to Cluster\nAnalysis.  Wiley Series in Probability and Statistics. John Wiley and Sons, New York,\nNovember 1990.\n[401]  J. M. Kleinberg. An Impossibility Theorem for Clustering. InProc. of the 16th Annual\nConf. on Neural Information Processing Systems, December, 9–14 2002.\n[402]  B. Larsen and C. Aone. Fast and Effective Text Mining Using Linear-Time Document\nClustering.  InProc. of the 5th Intl. Conf. on Knowledge Discovery and Data Mining,\npages 16–22, San Diego, California, 1999. ACM Press.\n[403]  J. MacQueen.  Some methods for classification and analysis of multivariate observa-\ntions.  InProc. of the 5th Berkeley Symp. on Mathematical Statistics and Probability,\npages 281–297. University of California Press, 1967.\n[404]  G. W. Milligan.  Clustering Validation: Results and Implications for Applied Analyses.\nIn P. Arabie, L. Hubert, and G. D. Soete, editors,Clustering and Classification, pages\n345–375. World Scientific, Singapore, January 1996.\n[405]  B. Mirkin.Mathematical Classification and Clustering, volume 11 ofNonconvex Opti-\nmization and Its Applications. Kluwer Academic Publishers, August 1996.\n[406]  T. Mitchell.Machine Learning. McGraw-Hill, Boston, MA, 1997.\n[407]  F. Murtagh.Multidimensional Clustering Algorithms. Physica-Verlag, Heidelberg and\nVienna, 1985.\n[408]  D. Pelleg and A. W. Moore.X-means: ExtendingK-means with Efficient Estimation\nof the Number of Clusters. InProc. of the 17th Intl. Conf. on Machine Learning, pages\n727–734. Morgan Kaufmann, San Francisco, CA, 2000.\n[409]  C. Romesburg.Cluster Analysis for Researchers.  Life Time Learning, Belmont, CA,\n1984.\n[410]  J. Sander, M. Ester, H.-P. Kriegel, and X. Xu.  Density-Based Clustering in Spatial\nDatabases: The Algorithm GDBSCAN and its Applications.Data Mining and Knowl-\nedge Discovery, 2(2):169–194, 1998.\n[411]  S. M. Savaresi and D. Boley.  A comparative analysis on the bisecting K-means and\nthe PDDP clustering algorithms.Intelligent Data Analysis, 8(4):345–362, 2004.\n[412]  P. H. A. Sneath and R. R. Sokal.Numerical Taxonomy. Freeman, San Francisco, 1971.\n[413]  H. Sp ̈ath.Cluster Analysis Algorithms for Data Reduction and Classification of Ob-\njects, volume 4 ofComputers and Their Application. Ellis Horwood Publishers, Chich-\nester, 1980. ISBN 0-85312-141-9.\n\n8.7Exercises559\n[414]  M. Steinbach, G. Karypis, and V. Kumar.  A Comparison of Document Clustering\nTechniques.  InProc. of KDD Workshop on Text Mining, Proc. of the 6th Intl. Conf.\non Knowledge Discovery and Data Mining, Boston, MA, August 2000.\n[415]  C. T. Zahn. Graph-Theoretical Methods for Detecting and Describing Gestalt Clusters.\nIEEE Transactions on Computers, C-20(1):68–86, Jan. 1971.\n[416]  B. Zhang, M. Hsu, and U. Dayal. K-Harmonic Means—A Data Clustering Algorithm.\nTechnical Report HPL-1999-124, Hewlett Packard Laboratories, Oct. 29 1999.\n[417]  Y. Zhao and G. Karypis.  Empirical and theoretical comparisons of selected criterion\nfunctions for document clustering.Machine Learning, 55(3):311–331, 2004.\n8.7   Exercises\n1.  Consider a data set consisting of 2\n20\ndata vectors, where each vector has 32\ncomponents and each component is a 4-byte value. Suppose that vector quan-\ntization is used for compression and that 2\n16\nprototype vectors are used. How\nmany bytes of storage does that data set take before and after compression and\nwhat is the compression ratio?\n2.  Find all well-separated clusters in the set of points shown in Figure 8.35.\nFigure 8.35.Points for Exercise 2.\n3.  Many partitional clustering algorithms that automatically determine the num-\nber of clusters claim that this is an advantage. List two situations in which this\nis not the case.\n4.  GivenKequally sized clusters, the probability that a randomly chosen initial\ncentroid will come from any given cluster is 1/K, but the probability that each\ncluster will have exactly one initial centroid is much lower. (It should be clear\nthat having one initial centroid in each cluster is a good starting situation for\nK-means.) In general, if there areKclusters and each cluster hasnpoints, then\nthe probability,p, of selecting in a sample of sizeKone initial centroid from each\ncluster is given by Equation 8.20.  (This assumes sampling with replacement.)\nFrom this formula we can calculate, for example, that the chance of having one\ninitial centroid from each of four clusters is 4!/4\n4\n=0.0938.\n\n560   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\np=\nnumber of ways to select one centroid from each cluster\nnumber of ways to selectKcentroids\n=\nK!n\nK\n(Kn)\nK\n=\nK!\nK\nK\n(8.20)\n(a)  Plot the probability of obtaining one point from each cluster in a sample\nof sizeKfor values ofKbetween 2 and 100.\n(b)  ForKclusters,K=10,100,and 1000, find the probability that a sample\nof size 2Kcontains at least one point from each cluster.  You can use\neither mathematical methods or statistical simulation to determine the\nanswer.\n5.  Identify the clusters in Figure 8.36 using the center-, contiguity-, and density-\nbased definitions.  Also indicate the number of clusters for each case and give\na brief indication of your reasoning. Note that darkness or the number of dots\nindicates density. If it helps, assume center-based means K-means, contiguity-\nbased means single link, and density-based means DBSCAN.\n(a)(b)(c)(d)\nFigure 8.36.Clusters for Exercise 5.\n6.  For the following sets of two-dimensional points, (1) provide a sketch of how\nthey would be split into clusters by K-means for the given number of clusters\nand (2) indicate approximately where the resulting centroids would be. Assume\nthat we are using the squared error objective function. If you think that there\nis more than one possible solution, then please indicate whether each solution\nis a global or local minimum.  Note that the label of each diagram in Figure\n8.37 matches the corresponding part of this question, e.g., Figure 8.37(a) goes\nwith part (a).\n(a)K= 2. Assuming that the points are uniformly distributed in the circle,\nhow many possible ways are there (in theory) to partition  the points\ninto two clusters?   What can you  say about the positions of the two\ncentroids?  (Again, you don’t need to provide exact centroid locations,\njust a qualitative description.)\n\n8.7Exercises561\n(a)(b)(c)(d)(e)\nFigure 8.37.Diagrams for Exercise 6.\n(b)K= 3.  The distance between the edges of the circles is slightly greater\nthan the radii of the circles.\n(c)K= 3.  The distance between the edges of the circles is much less than\nthe radii of the circles.\n(d)K=2.\n(e)K= 3.  Hint:  Use the symmetry of the situation and remember that we\nare looking for a rough sketch of what the result would be.\n7.  Suppose that for a data set\n•there arempoints andKclusters,\n•half the points and clusters are in “more dense” regions,\n•half the points and clusters are in “less dense” regions, and\n•the two regions are well-separated from each other.\nFor the given data set, which of the following should occur in order to minimize\nthe squared error when findingKclusters:\n(a)  Centroids should be equally distributed between more dense and less dense\nregions.\n(b)  More centroids should be allocated to the less dense region.\n(c)  More centroids should be allocated to the denser region.\nNote:  Do not get distracted by special cases or bring in factors other than\ndensity. However, if you feel the true answer is different from any given above,\njustify your response.\n8.  Consider the mean of a cluster of objects from a binary transaction data set.\nWhat are the minimum and maximum values of the components of the mean?\nWhat is the interpretation of components of the cluster mean? Which compo-\nnents most accurately characterize the objects in the cluster?\n9.  Give an example of a data set consisting of three natural clusters, for which\n(almost always) K-means would likely find the correct clusters, but bisecting\nK-means would not.\n\n562   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n10.  Would the cosine measure be the appropriate similarity measure to use with K-\nmeans clustering for time series data? Why or why not? If not, what similarity\nmeasure would be more appropriate?\n11.  Total SSE is the sum of the SSE for each separate attribute. What does it mean\nif the SSE for one variable is low for all clusters? Low for just one cluster? High\nfor all clusters? High for just one cluster? How could you use the per variable\nSSE information to improve your clustering?\n12.  The leader algorithm (Hartigan [394]) represents each cluster using a point,\nknown as aleader, and assigns each point to the cluster corresponding to the\nclosest leader, unless this distance is above a user-specified threshold.  In that\ncase, the point becomes the leader of a new cluster.\n(a)  What are the advantages and disadvantages of the leader algorithm as\ncompared to K-means?\n(b)  Suggest ways in which the leader algorithm might be improved.\n13.  The Voronoi diagram for a set ofKpoints in the plane is a partition of all\nthe points of the plane intoKregions, such that every point (of the plane)\nis assigned to the closest point among theKspecified points.   (See Figure\n8.38.)  What is the relationship between Voronoi diagrams and K-means clus-\nters? What do Voronoi diagrams tell us about the possible shapes of K-means\nclusters?\nFigure 8.38.Voronoi diagram for Exercise 13.\n14.  You are given a data set with 100 records and are asked to cluster the data.\nYou use K-means to cluster the data, but for all values ofK,1≤K≤100,\nthe K-means algorithm returns only one non-empty cluster.  You then apply\nan incremental version of K-means, but obtain exactly the same result. How is\nthis possible? How would single link or DBSCAN handle such data?\n15.  Traditional agglomerative hierarchical clustering routines merge two clusters at\neach step.  Does it seem likely that such an approach accurately captures the\n\n8.7Exercises563\n(nested) cluster structure of a set of data points? If not, explain how you might\npostprocess the data to obtain a more accurate view of the cluster structure.\n16.  Use the similarity matrix in Table 8.13 to perform single and complete link\nhierarchical clustering. Show your results by drawing a dendrogram. The den-\ndrogram should clearly show the order in which the points are merged.\nTable 8.13.Similarity matrix for Exercise 16.\np1p2p3p4p5\np11.000.100.410.550.35\np20.101.000.640.470.98\np30.410.641.000.440.85\np40.550.470.441.000.76\np50.350.980.850.761.00\n17.  Hierarchical clustering is sometimes used to generateKclusters,K>1by\ntaking the clusters at theK\nth\nlevel of the dendrogram. (Root is at level 1.) By\nlooking at the clusters produced in this way, we can evaluate the behavior of\nhierarchical clustering on different types of data and clusters, and also compare\nhierarchical approaches to K-means.\nThe following is a set of one-dimensional points:{6,12,18,24,30,42,48}.\n(a)  For each of the following sets of initial centroids, create two clusters by\nassigning each point to the nearest centroid, and then calculate the total\nsquared error for each set of two clusters. Show both the clusters and the\ntotal squared error for each set of centroids.\ni.{18,45}\nii.{15,40}\n(b)  Do both sets of centroids represent stable solutions; i.e., if the K-means\nalgorithm was run on this set of points using the given centroids as the\nstarting centroids, would there be any change in the clusters generated?\n(c)  What are the two clusters produced by single link?\n(d)  Which technique, K-means or single link, seems to produce the “most\nnatural” clustering in this situation?  (For K-means, take the clustering\nwith the lowest squared error.)\n(e)  What definition(s) of clustering does this natural clustering correspond\nto? (Well-separated, center-based, contiguous, or density.)\n(f)  What well-known characteristic of the K-means algorithm explains the\nprevious behavior?\n\n564   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n18.  Suppose we findKclusters using Ward’s method, bisecting K-means, and ordi-\nnary K-means. Which of these solutions represents a local or global minimum?\nExplain.\n19.  Hierarchical clustering algorithms requireO(m\n2\nlog(m)) time, and consequently,\nare impractical to use directly on larger data sets.  One possible technique for\nreducing the time required is to sample the data set. For example, ifKclusters\nare desired and\n√\nmpoints are sampled from thempoints, then a hierarchi-\ncal clustering algorithm will produce a hierarchical clustering in roughlyO(m)\ntime.Kclusters can be extracted from this hierarchical clustering by taking\nthe clusters on theK\nth\nlevel of the dendrogram.  The remaining points can\nthen be assigned to a cluster in linear time, by using various strategies. To give\na specific example, the centroids of theKclusters can be computed, and then\neach of them−\n√\nmremaining points can be assigned to the cluster associated\nwith the closest centroid.\nFor each of the following types of data or clusters, discuss briefly if (1) sampling\nwill cause problems for this approach and (2) what those problems are. Assume\nthat the sampling technique randomly chooses points from the total set ofm\npoints and that any unmentioned characteristics of the data or clusters are as\noptimal as possible.  In other words, focus only on problems caused by the\nparticular characteristic mentioned.  Finally, assume thatKis very much less\nthanm.\n(a)  Data with very different sized clusters.\n(b)  High-dimensional data.\n(c)  Data with outliers, i.e., atypical points.\n(d)  Data with highly irregular regions.\n(e)  Data with globular clusters.\n(f)  Data with widely different densities.\n(g)  Data with a small percentage of noise points.\n(h)  Non-Euclidean data.\n(i)  Euclidean data.\n(j)  Data with many and mixed attribute types.\n20.  Consider the following four faces shown in Figure 8.39.  Again, darkness or\nnumber of dots represents density.  Lines are used only to distinguish regions\nand do not represent points.\n(a)  For each figure, could you use single link to find the patterns represented\nby the nose, eyes, and mouth? Explain.\n(b)  For each figure, could you use K-means to find the patterns represented\nby the nose, eyes, and mouth? Explain.\n\n8.7Exercises565\n(a)(b)(c)(d)\nFigure 8.39.Figure for Exercise 20.\n(c)  What limitation does clustering have in detecting all the patterns formed\nby the points in Figure 8.39(c)?\n21.  Compute the entropy and purity for the confusion matrix in Table 8.14.\nTable 8.14.Confusion matrix for Exercise 21.\nClusterEntertainmentFinancialForeignMetroNationalSportsTotal\n#1110114676693\n#22789333827253331562\n#332646581051629949\nTotal3545553419432737383204\n22.  You are given two sets of 100 points that fall within the unit square.  One set\nof points is arranged so that the points are uniformly spaced. The other set of\npoints is generated from a uniform distribution over the unit square.\n(a)  Is there a difference between the two sets of points?\n(b)  If so,  which set of points will typically have a smaller SSE for K=10\nclusters?\n(c)  What will be the behavior of DBSCAN on the uniform data set?  The\nrandom data set?\n23.  Using the data in Exercise 24, compute the silhouette coefficient for each point,\neach of the two clusters, and the overall clustering.\n24.  Given the set of cluster labels and similarity matrix shown in Tables 8.15 and\n8.16, respectively, compute the correlation between the similarity matrix and\nthe ideal similarity matrix, i.e., the matrix whoseij\nth\nentry is 1 if two objects\nbelong to the same cluster, and 0 otherwise.\n\n566   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\nTable 8.15.Table of cluster labels for Exercise 24.\nPointCluster Label\nP11\nP21\nP32\nP42\nTable 8.16.Similarity matrix for Exercise 24.\nPointP1P2P3P4\nP110.80.650.55\nP20.810.70.6\nP30.650.710.9\nP40.550.60.91\n25.  Compute the hierarchical F-measure for the eight objects{p1, p2, p3, p4, p5,\np6, p7, p8}and hierarchical clustering shown in Figure 8.40. Class A contains\npoints p1, p2, and p3, while p4, p5, p6, p7, and p8 belong to class B.\n{p1, p2, p3, p4, p5, p6, p7, p8}\n{p3, p6, p7, p8}\n{p1, p2}{p4, p5}{p3, p6}{p7, p8}\n{p1, p2, p4, p5,}\nFigure 8.40.Hierarchical clustering for Exercise 25.\n26.  Compute the cophenetic correlation coefficient for the hierarchical clusterings\nin Exercise 16. (You will need to convert the similarities into dissimilarities.)\n27.  Prove Equation 8.14.\n28.  Prove Equation 8.16.\n29.  Prove that\n∑\nK\ni=1\n∑\nx∈C\ni\n(x−m\ni\n)(m−m\ni\n) = 0. This fact was used in the proof\nthat TSS = SSE + SSB in Section 8.5.2.\n30.  Clusters of documents can be summarized by finding the top terms (words) for\nthe documents in the cluster, e.g., by taking the most frequentkterms, where\nkis a constant, say 10, or by taking all terms that occur more frequently than\na specified threshold.  Suppose that K-means is used to find clusters of both\ndocuments and words for a document data set.\n(a)  How might a set of term clusters defined by the top terms in a document\ncluster differ from the word clusters found by clustering the terms with\nK-means?\n(b)  How could term clustering be used to define clusters of documents?\n31.  We can represent a data set as a collection of object nodes and a collection of\nattribute nodes, where there is a link between each object and each attribute,\n\n8.7Exercises567\nand where the weight of that link is the value of the object for that attribute. For\nsparse data, if the value is 0, the link is omitted. Bipartite clustering attempts\nto partition this graph into disjoint clusters, where each cluster consists of a\nset of object nodes and a set of attribute nodes. The objective is to maximize\nthe weight of links between the object and attribute nodes of a cluster, while\nminimizing the weight of links between object and attribute links in different\nclusters.   This type of clustering is also known asco-clusteringsince the\nobjects and attributes are clustered at the same time.\n(a)  How is bipartite clustering (co-clustering) different from clustering the\nsets of objects and attributes separately?\n(b)  Are there any cases in which these approaches yield the same clusters?\n(c)  What are the strengths and weaknesses of co-clustering as compared to\nordinary clustering?\n32.  In Figure 8.41, match the similarity matrices, which are sorted according to\ncluster labels, with the sets of points. Differences in shading and marker shape\ndistinguish between clusters, and each set of points contains 100 points and\nthree clusters. In the set of points labeled 2, there are three very tight, equal-\nsized clusters.\n\n568   Chapter 8Cluster Analysis: Basic Concepts and Algorithms\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n00.20.40.60.81\nx\ny\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n00.20.40.60.81\nx\ny\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n00.20.40.60.81\nx\ny\n1\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n00.20.40.60.81\nx\ny\n1\n3\n2\n4\nFigure 8.41.Points and similarity matrices for Exercise 32.\n\n## Document Information\n- **Source**: PDF Document (82 pages)\n- **Category**: lab-material\n- **Difficulty**: intermediate\n- **Relevant Labs**: lab5\n- **Topics**: classification, clustering, gis, machine learning, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain ch8.pdf\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- clustering\n- gis\n- machine learning\n- vector\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "intermediate",
      "lab": "lab5",
      "topics": [
        "classification",
        "clustering",
        "gis",
        "machine learning",
        "vector"
      ],
      "source": "concepts\\clustering2.md",
      "filename": "clustering2.md"
    }
  },
  {
    "id": "concepts-common_gis_problems",
    "title": "common_gis_problems",
    "content": "# Common GIS Problems and Solutions\n\n# Common GIS Problems and How to Fix Them\n\n## Data Loading Issues\n\n### Problem: \"Layer won't load\" or \"No data appears\"\n**Possible causes:**\n1. **File corruption**: Data file is damaged\n2. **Wrong file path**: File moved or renamed\n3. **Unsupported format**: GIS can't read the file type\n4. **Coordinate system mismatch**: Data projects incorrectly\n\n**Solutions:**\n1. **Check file integrity**: Try opening in different software\n2. **Verify file path**: Browse to file location manually\n3. **Convert format**: Use data conversion tools\n4. **Set/check CRS**: Ensure coordinate systems match\n\n### Problem: \"Data appears in wrong location\"\n**Cause**: Coordinate Reference System (CRS) mismatch\n\n**Solutions:**\n1. **Check layer CRS**: Right-click layer → Properties → Source\n2. **Set correct CRS**: Layer Properties → Source → Assign CRS\n3. **Enable on-the-fly projection**: Project Properties → CRS\n4. **Reproject data**: Use \"Reproject Layer\" tool\n\n## QGIS-Specific Issues\n\n### Problem: \"QGIS crashes or freezes\"\n**Possible causes:**\n1. **Large datasets**: Too much data for available memory\n2. **Complex symbology**: Rendering takes too long\n3. **Plugin conflicts**: Incompatible or buggy plugins\n4. **Corrupted preferences**: QGIS settings corrupted\n\n**Solutions:**\n1. **Simplify data**: Use data subsets or generalized versions\n2. **Simplify symbology**: Use basic symbols for large datasets\n3. **Disable plugins**: Settings → Plugins → uncheck problematic ones\n4. **Reset preferences**: Delete QGIS profile folder\n\n### Problem: \"Can't edit features\"\n**Possible causes:**\n1. **Layer not editable**: Edit mode not turned on\n2. **File permissions**: Read-only file or folder\n3. **Network location**: Editing remote files\n4. **File lock**: Another program has file open\n\n**Solutions:**\n1. **Toggle editing**: Click pencil icon or Layer → Toggle Editing\n2. **Check permissions**: Ensure you can write to file location\n3. **Copy locally**: Download file for editing\n4. **Close other programs**: Close Excel, other GIS software\n\n## Google Earth Engine Issues\n\n### Problem: \"Code won't run\" or \"Error messages\"\n**Common causes:**\n1. **Syntax errors**: Typos in function names\n2. **Memory limits**: Computation too large\n3. **Timeout errors**: Process takes too long\n4. **Authentication issues**: Not signed in properly\n\n**Solutions:**\n1. **Check syntax**: Look for typos, missing parentheses\n2. **Reduce computation**: Use smaller areas or fewer images\n3. **Add .aside()**: Force computation to complete step by step\n4. **Re-authenticate**: Run ee.Authenticate() again\n\n### Problem: \"No data appears on map\"\n**Possible causes:**\n1. **Wrong visualization parameters**: Min/max values incorrect\n2. **No data in area**: Study area has no data\n3. **Date filtering**: No images in specified date range\n4. **Cloud cover**: All images cloudy\n\n**Solutions:**\n1. **Check data values**: Use print() to see actual values\n2. **Expand area**: Check larger region\n3. **Expand dates**: Use longer time period\n4. **Relax cloud filter**: Allow higher cloud percentage\n\n## Data Quality Issues\n\n### Problem: \"Missing or incomplete data\"\n**Identification:**\n- Gaps in spatial coverage\n- Missing attribute values\n- Inconsistent data collection\n\n**Solutions:**\n1. **Document gaps**: Note where data is missing\n2. **Find alternative sources**: Look for supplementary datasets\n3. **Interpolation**: Estimate missing values from nearby data\n4. **Flag uncertainty**: Mark areas with poor data quality\n\n### Problem: \"Inconsistent coordinate systems\"\n**Symptoms:**\n- Layers don't align properly\n- Distance measurements incorrect\n- Analysis results questionable\n\n**Solutions:**\n1. **Standardize CRS**: Choose one CRS for entire project\n2. **Reproject all layers**: Use consistent coordinate system\n3. **Document CRS**: Record which CRS you're using\n4. **Validate alignment**: Check that layers overlay correctly\n\n## Performance Issues\n\n### Problem: \"Slow rendering or analysis\"\n**Causes:**\n1. **Large datasets**: Too many features or high resolution\n2. **Complex operations**: Computationally intensive analysis\n3. **Inefficient workflows**: Unnecessary processing steps\n\n**Solutions:**\n1. **Simplify data**: Generalize geometries, reduce resolution\n2. **Use spatial indices**: Speed up spatial queries\n3. **Process in chunks**: Break large operations into smaller parts\n4. **Optimize workflows**: Remove unnecessary steps\n\n## Getting Help\n\n### When Stuck:\n1. **Check documentation**: Official software documentation\n2. **Search forums**: GIS Stack Exchange, software forums\n3. **Ask community**: Post detailed questions with error messages\n4. **Try simple examples**: Test with basic data first\n\n### Best Practices:\n1. **Save frequently**: Backup work regularly\n2. **Document workflow**: Record steps taken\n3. **Test with sample data**: Verify methods work before full analysis\n4. **Keep software updated**: Use latest stable versions\n\n## Key Information\n- **Category**: troubleshooting\n- **Difficulty**: beginner\n- **Source**: QGIS Documentation + GEE Community + Common Experience\n\n## Keywords\n- problems\n- errors\n- troubleshooting\n- solutions\n- debugging\n- fixes\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "concepts\\common_gis_problems.md",
      "filename": "common_gis_problems.md"
    }
  },
  {
    "id": "concepts-complete-guide-to-accessing-google-earth-engine---workshop-setup",
    "title": "Complete Guide to Accessing Google Earth Engine - Workshop Setup",
    "content": "\n# Complete Guide to Accessing Google Earth Engine - Workshop Setup\n\n\n\nComplete Guide to Accessing Google Earth Engine\nPre-Workshop Setup Instructions\nOverview\nGoogle Earth Engine (GEE) is a cloud-based platform for planetary-scale environmental data analysis.\nBefore the workshop, all participants must complete these setup steps.\nTime Requirements:\nApplication process: 30-45 minutes\nGEE approval wait: 1-3 business days\n⚠ IMPORTANT: Complete Steps 1-3 at least ONE WEEK before the workshop to ensure approval!\nStep 1: Prerequisites\nRequired:\nModern web browser (Chrome, Firefox, Edge, or Safari)\nStable internet connection\nGoogle account (Gmail or Google Workspace)\nCheck your browser:\n1. Open your browser\n2. Navigate to: chrome://version (Chrome) or about:support (Firefox)\n3. Ensure you're using a version from the last 2 years\n4. If your browser is older, please update it before proceeding\nStep 2: Create or Verify Google Account\nIf you already have a Google account:\n1. Go to https://accounts.google.com\n2. Click \"Sign in\"\n3. Enter your email and password\n4. Verify you can access your account\n\nIf you need a Google account:\n1. Go to https://accounts.google.com/signup\n2. Fill in the form:\nFirst and last name\nUsername (this will be your email)\nPassword (use a strong password)\nConfirm password\n3. Add recovery information:\nPhone number (recommended)\nRecovery email (optional)\n4. Complete verification:\nEnter the code sent to your phone\nAccept terms and conditions\n5. Important: Write down your login credentials and keep them in a safe, private place!\nStep 3: Sign Up for Google Earth Engine\nAccess the signup page:\n1. Open a new browser tab\n2. Navigate to: https://earthengine.google.com/signup/\n3. You should see \"Sign up for Earth Engine\" page\nComplete the registration form:\nSection 1: Account Type\nSelect the account type that best fits your use. For this workshop, common choices are:\n\"Non-commercial / research project\": If you are using GEE for personal projects, NGO work, or\nnon-degree research (most common choice)\n\"Education\": If you are a student using GEE for coursework or a university educator\n\"Government\": If you work for a government agency\nNote: The exact wording on the GEE form may differ slightly. Choose the option that best describes your\nparticipation in this non-commercial, educational/research-focused workshop.\n\nSection 2: Your Information\nFill in all required fields:\nEmail: Use your Google account email\nName: Your full name\nOrganization: Your institution/company name\nCountry: Select from dropdown\nIntended use: Select \"Research\" or \"Education\"\nSection 3: Project Details\nBe specific but concise:\nProject description:\nGeographic area: \"Uganda, East Africa\"\nTime period: \"2024-2025\"\nSection 4: Agreement\nCheck the box: \"I agree to the terms of service\"\nClick \"Submit\"\nWait for approval:\nTypical wait time: 1-3 business days\nYou'll receive an email to your registered address\nSubject line: \"Welcome to Google Earth Engine\"\nIf urgent: Contact the workshop organizer for expedited approval\n⚠ CRITICAL: Please complete Steps 1-3 (submitting your GEE application) AT LEAST ONE WEEK before\nthe workshop to allow ample time for approval. If you sign up later, approval before the workshop cannot\nbe guaranteed.\nStep 4: First Access to Code Editor\n\"Participating in a workshop on using GIS and AI for public health \n\"Participating in a workshop on using GIS and AI for public health \nmapping in Uganda, focusing on malaria risk assessment using \nmapping in Uganda, focusing on malaria risk assessment using \nenvironmental variables\"\nenvironmental variables\"\n\nOnce approved, access the Code Editor:\n1. Direct URL: https://code.earthengine.google.com/\n2. Alternative path:\nGo to https://earthengine.google.com/\nClick \"Platform\" → \"Code Editor\"\nFirst-time login:\n1. Click \"Sign in with Google\"\n2. Select your Google account\n3. Grant permissions:\n\"View your email address\" → Allow\n\"View your basic profile info\" → Allow\n4. You should see the Code Editor interface\nStep 5: Understanding the Code Editor Interface\nMain Components:\n Tip: An annotated screenshot of the interface would be helpful here. Ask your instructor if one is\navailable.\nTop Section:\nScripts tab (left panel): Your saved scripts\nDocs tab (left panel): API documentation\nAssets tab (left panel): Your uploaded data\nMiddle Section:\nCode Editor: Where you write JavaScript code\nLine numbers on the left\nSyntax highlighting for easier reading\nRight Section:\nInspector tab: Click map features to inspect\nConsole tab: View print outputs and errors\n\nTasks tab: Monitor exports and long-running tasks\nBottom Section:\nMap: Interactive map display\nGeometry tools: Draw points, lines, polygons\nLayer manager: Toggle map layers on/off\nStep 6: Initial Configuration\nSet up your workspace:\n1. Create a repository for workshop scripts:\n2. Configure map settings: In the central Code Editor panel, you can type or paste JavaScript code.\nThis first script will set your default map view:\n3. Test your setup with this simple script:\n4. Run the test:\nClick the \"Run\" button (top of code editor)\njavascript\n// Click \"NEW\" → \"Repository\" in Scripts panel\n// Click \"NEW\" → \"Repository\" in Scripts panel\n// Name it: \"Uganda_Health_Workshop_2024\"\n// Name it: \"Uganda_Health_Workshop_2024\"\njavascript\n// Add this to your first script:\n// Add this to your first script:\nMap\nMap\n.\n.\nsetOptions\nsetOptions\n(\n(\n'SATELLITE'\n'SATELLITE'\n)\n)\n;\n;\n  \n  \n// or 'TERRAIN', 'ROADMAP'\n// or 'TERRAIN', 'ROADMAP'\nMap\nMap\n.\n.\nsetCenter\nsetCenter\n(\n(\n32.5\n32.5\n,\n,\n \n \n1.3\n1.3\n,\n,\n \n \n7\n7\n)\n)\n;\n;\n  \n  \n// Center on Uganda\n// Center on Uganda\njavascript\n// Hello Earth Engine\n// Hello Earth Engine\nprint\nprint\n(\n(\n'Hello Earth Engine!'\n'Hello Earth Engine!'\n)\n)\n;\n;\n// Load and display Uganda boundaries\n// Load and display Uganda boundaries\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n\"USDOS/LSIB_SIMPLE/2017\"\n\"USDOS/LSIB_SIMPLE/2017\"\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'country_na'\n'country_na'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nuganda\nuganda\n,\n,\n \n \n{\n{\ncolor\ncolor\n:\n:\n \n \n'red'\n'red'\n}\n}\n,\n,\n \n \n'Uganda Boundary'\n'Uganda Boundary'\n)\n)\n;\n;\nMap\nMap\n.\n.\ncenterObject\ncenterObject\n(\n(\nuganda\nuganda\n,\n,\n \n \n7\n7\n)\n)\n;\n;\n// If you see Uganda outlined in red, your setup is complete!\n// If you see Uganda outlined in red, your setup is complete!\n\nCheck the map for a red outline of Uganda\nLook for \"Hello Earth Engine!\" in the Console\nStep 7: Troubleshooting Common Issues\n\"Access Denied\" or \"Not Authorized\"\nSolution:\nEnsure you're logged into the correct Google account\nCheck if your Earth Engine registration is approved\nTry incognito/private browsing mode\nClear browser cache and cookies for earthengine.google.com\n\"Script error\" when running code\nSolution:\nCheck for typos (JavaScript is case-sensitive)\nEnsure all parentheses and brackets are closed\nLook for red underlines in the code editor\nCheck the Console tab for specific error messages\nMap doesn't load or is blank\nSolution:\nCheck internet connection\nDisable browser extensions (especially ad blockers)\nTry a different browser\nZoom out to global view and look for layers\n\"Computation timed out\"\nSolution:\nThis is normal for complex operations\nReduce the geographic extent\nSimplify your analysis\nWill cover optimization in the workshop\n\nCan't find the Code Editor\nSolution:\nDirect link: https://code.earthengine.google.com/\nBookmark this URL!\nEnsure you're signed in to Google first\nStep 8: Pre-Workshop Checklist\nComplete these tasks before the workshop:\n Google account created and password saved\n Earth Engine signup submitted\n Approval email received\n Successfully accessed Code Editor\n Run the test script (Uganda boundary)\n Created workshop repository\n Bookmarked Code Editor URL\n Tested in your preferred browser\nRecommended preparation:\n Watch \"Introduction to Google Earth Engine\" (YouTube)\n Review JavaScript basics (optional but helpful - see GEE's JavaScript intro)\n Install a text editor (VS Code, Notepad++) for offline notes\nStep 9: Workshop Day Setup\n15 minutes before the workshop:\n1. Open required tabs:\nTab 1: Google Earth Engine Code Editor\nTab 2: ChatGPT (https://chat.openai.com)\nTab 3: Workshop materials (Google Drive/website)\nTab 4: Email (for sharing/receiving files)\n2. Check your environment:\n\n3. Create Day 2 folder:\nIn Scripts panel: Right-click your repository\nSelect \"New Folder\" → Name it \"Day2_GEE_AI\"\nStep 10: Alternative Access Methods\nDataset Consistency Note:\nThroughout this workshop, we use the USDOS/LSIB_SIMPLE/2017 dataset for Uganda boundaries. This\nensures consistency across all exercises and is a reliable, globally-available dataset.\nIf Code Editor is blocked:\nOption 1: Python API (Colab)\n1. Go to https://colab.research.google.com\n2. Create new notebook\n3. Run:\nOption 2: QGIS Plugin\n1. In QGIS: Plugins → Manage and Install Plugins\n2. Search for \"Google Earth Engine\"\n3. Install and configure with your credentials\nOption 3: JavaScript API (local)\n1. Requires Node.js installation\njavascript\n// Run this script to verify everything works:\n// Run this script to verify everything works:\nprint\nprint\n(\n(\n'Earth Engine Version:'\n'Earth Engine Version:'\n,\n,\n ee\n ee\n.\n.\nversion\nversion\n(\n(\n)\n)\n)\n)\n;\n;\nprint\nprint\n(\n(\n'Current Date:'\n'Current Date:'\n,\n,\n ee\n ee\n.\n.\nDate\nDate\n(\n(\nDate\nDate\n.\n.\nnow\nnow\n(\n(\n)\n)\n)\n)\n)\n)\n;\n;\n// This line extracts your username - just copy and run it\n// This line extracts your username - just copy and run it\nprint\nprint\n(\n(\n'User:'\n'User:'\n,\n,\n ee\n ee\n.\n.\ndata\ndata\n.\n.\ngetAssetRoots\ngetAssetRoots\n(\n(\n)\n)\n[\n[\n0\n0\n]\n]\n.\n.\nid\nid\n.\n.\nsplit\nsplit\n(\n(\n'/'\n'/'\n)\n)\n[\n[\n1\n1\n]\n]\n)\n)\n;\n;\npython\nimport\nimport\n ee\n ee\nee\nee\n.\n.\nAuthenticate\nAuthenticate\n(\n(\n)\n)\nee\nee\n.\n.\nInitialize\nInitialize\n(\n(\n)\n)\n\n2. More complex setup (covered if needed)\nAdditional Resources\nEssential Links:\nEarth Engine Homepage: https://earthengine.google.com/\nCode Editor: https://code.earthengine.google.com/\nAPI Documentation: https://developers.google.com/earth-engine/\nDataset Catalog: https://developers.google.com/earth-engine/datasets/\nCommunity Forum: https://groups.google.com/g/google-earth-engine-developers\nHelp Contacts:\nWorkshop Instructor: [instructor email]\nEarth Engine Support: earth-engine-support@google.com\nWorkshop Slack/WhatsApp: [group link]\nBackup Plan:\nIf you cannot get Earth Engine access by workshop date:\n1. Notify the instructor immediately\n2. You can still participate by:\nPairing with another participant\nUsing the instructor's shared screen\nWorking with exported datasets in QGIS\nQuick Reference Card\nMost Used Code Snippets:\n\nKeyboard Shortcuts:\nRun script: Ctrl + Enter (Cmd + Enter on Mac)\nSave script: Ctrl + S (Cmd + S on Mac)\nComment line: Ctrl + / (Cmd + / on Mac)\nAuto-complete: Ctrl + Space\nNew script: Ctrl + Alt + N\nNotes for Instructors\nCommon Bottlenecks:\n1. Earth Engine approval delay\nHave a list of approved \"guest accounts\" as backup\nContact GEE team 2 weeks before workshop for bulk approval\n2. Slow internet\nPrepare offline alternatives\nHave key datasets pre-exported\njavascript\n// Center map on Uganda\n// Center map on Uganda\nMap\nMap\n.\n.\nsetCenter\nsetCenter\n(\n(\n32.5\n32.5\n,\n,\n \n \n1.3\n1.3\n,\n,\n \n \n7\n7\n)\n)\n;\n;\n// Load Uganda boundaries\n// Load Uganda boundaries\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n\"USDOS/LSIB_SIMPLE/2017\"\n\"USDOS/LSIB_SIMPLE/2017\"\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'country_na'\n'country_na'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\n// Print to console\n// Print to console\nprint\nprint\n(\n(\n'Debug info:'\n'Debug info:'\n,\n,\n variable\n variable\n)\n)\n;\n;\n// Add layer to map\n// Add layer to map\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nimage\nimage\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'brown'\n'brown'\n,\n,\n \n \n'yellow'\n'yellow'\n,\n,\n \n \n'green'\n'green'\n]\n]\n}\n}\n,\n,\n \n \n'Layer name'\n'Layer name'\n)\n)\n;\n;\n// Common visualizations\n// Common visualizations\nvar\nvar\n visNDVI \n visNDVI \n=\n=\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'brown'\n'brown'\n,\n,\n \n \n'yellow'\n'yellow'\n,\n,\n \n \n'green'\n'green'\n]\n]\n}\n}\n;\n;\n  \n  \n// For scaled NDVI (0-1\n// For scaled NDVI (0-1\nvar\nvar\n visRain \n visRain \n=\n=\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n500\n500\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'white'\n'white'\n,\n,\n \n \n'blue'\n'blue'\n,\n,\n \n \n'darkblue'\n'darkblue'\n]\n]\n}\n}\n;\n;\n  \n  \n// For rainfall in m\n// For rainfall in m\n// Note: Raw MODIS NDVI values need scaling (divide by 10000)\n// Note: Raw MODIS NDVI values need scaling (divide by 10000)\n\nUse mobile hotspots as backup\n3. Browser compatibility\nChrome works best\nFirefox is good alternative\nSafari sometimes has issues with pop-ups\nSuccess Metrics:\nAll participants can log in within 10 minutes\nTest script runs successfully for everyone\nParticipants can navigate the interface\nBasic comfort with running provided code\nPost-Access Next Steps\nOnce everyone has access:\n1. Brief interface tour (10 min)\n2. Run 2-3 simple examples together\n3. Ensure everyone has the same view\n4. Begin Lab 3 exercises\nRemember: The goal is not to become JavaScript experts, but to use Earth Engine as a tool for\npublic health analysis!\n\n## Document Information\n- **Source**: PDF Document (11 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: lab1\n- **Topics**: gee, gis, google earth engine, malaria, mapping, public health, python, qgis, satellite\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain complete guide to accessing google earth engine - workshop setup\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- gee\n- gis\n- google earth engine\n- malaria\n- mapping\n- public health\n- python\n- qgis\n- satellite\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "lab1",
      "topics": [
        "gee",
        "gis",
        "google earth engine",
        "malaria",
        "mapping",
        "public health",
        "python",
        "qgis",
        "satellite"
      ],
      "source": "concepts\\complete-guide-to-accessing-google-earth-engine---workshop-setup.md",
      "filename": "complete-guide-to-accessing-google-earth-engine---workshop-setup.md"
    }
  },
  {
    "id": "concepts-day-2_-gee-&-ai-workshop---instructor-guide-with-code-snippets",
    "title": "Day 2: GEE & AI Workshop - Instructor Guide with Code Snippets",
    "content": "\n# Day 2: GEE & AI Workshop - Instructor Guide with Code Snippets\n\n\n\nDay 2: Earth Observation and Generative AI – Complete\nInstructor Guide\nOverview & Timing Adjustments\n09:00–09:30: Recap + Earth Observation for Health\n09:30–10:30: Lab 3 - NDVI & Rainfall Visualization\n10:30–11:00: Break\n11:00–12:00: Lab 4 - ChatGPT for GEE (15 min lecture + 45 min hands-on)\n12:00–13:00: Lunch\n13:00–14:30: Lab 5 - K-means Clustering (includes 10 min coffee stretch)\n14:30–15:30: Export and Visualize in QGIS\n15:30–16:00: Reflection and Discussion\nLab 3: Visualizing NDVI and Rainfall in GEE (09:30-10:30)\nPre-Lab Setup\nExercise 1: Basic NDVI Visualization (15 min)\nStep 1: Load and filter MODIS NDVI\njavascript\n// Instructor should have this ready to share\n// Instructor should have this ready to share\n// Base setup code for all participants\n// Base setup code for all participants\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_3'\n'UCSB-CHG/GADM/gadm36_3'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\nvar\nvar\n ugandaBounds \n ugandaBounds \n=\n=\n uganda\n uganda\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n.\n.\nbounds\nbounds\n(\n(\n)\n)\n;\n;\nMap\nMap\n.\n.\ncenterObject\ncenterObject\n(\n(\nuganda\nuganda\n,\n,\n \n \n7\n7\n)\n)\n;\n;\n\nStep 2: Apply preset palettes (Enhancement)\njavascript\n// Load MODIS NDVI data\n// Load MODIS NDVI data\nvar\nvar\n modis \n modis \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'MODIS/006/MOD13Q1'\n'MODIS/006/MOD13Q1'\n)\n)\n  \n  \n.\n.\nfilterDate\nfilterDate\n(\n(\n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-12-31'\n'2024-12-31'\n)\n)\n  \n  \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nuganda\nuganda\n)\n)\n  \n  \n.\n.\nselect\nselect\n(\n(\n'NDVI'\n'NDVI'\n)\n)\n;\n;\n// Scale NDVI values (MODIS uses scale factor of 0.0001)\n// Scale NDVI values (MODIS uses scale factor of 0.0001)\nvar\nvar\n ndviScaled \n ndviScaled \n=\n=\n modis\n modis\n.\n.\nmap\nmap\n(\n(\nfunction\nfunction\n(\n(\nimg\nimg\n)\n)\n \n \n{\n{\n  \n  \nreturn\nreturn\n img\n img\n.\n.\nmultiply\nmultiply\n(\n(\n0.0001\n0.0001\n)\n)\n    \n    \n.\n.\ncopyProperties\ncopyProperties\n(\n(\nimg\nimg\n,\n,\n \n \n[\n[\n'system:time_start'\n'system:time_start'\n]\n]\n)\n)\n;\n;\n}\n}\n)\n)\n;\n;\n// Get median NDVI for the year\n// Get median NDVI for the year\nvar\nvar\n ndviMedian \n ndviMedian \n=\n=\n ndviScaled\n ndviScaled\n.\n.\nmedian\nmedian\n(\n(\n)\n)\n.\n.\nclip\nclip\n(\n(\nuganda\nuganda\n)\n)\n;\n;\n\nExercise 2: Rainfall Integration (15 min)\nStep 3: Load CHIRPS rainfall data\njavascript\n// Preset palette options\n// Preset palette options\nvar\nvar\n palettes \n palettes \n=\n=\n \n \n{\n{\n  \n  \nvegetation\nvegetation\n:\n:\n \n \n[\n[\n'FFFFFF'\n'FFFFFF'\n,\n,\n \n \n'CE7E45'\n'CE7E45'\n,\n,\n \n \n'DF923D'\n'DF923D'\n,\n,\n \n \n'F1B555'\n'F1B555'\n,\n,\n \n \n'FCD163'\n'FCD163'\n,\n,\n \n \n                \n                \n'99B718'\n'99B718'\n,\n,\n \n \n'74A901'\n'74A901'\n,\n,\n \n \n'66A000'\n'66A000'\n,\n,\n \n \n'529400'\n'529400'\n,\n,\n \n \n'3E8601'\n'3E8601'\n,\n,\n \n \n                \n                \n'207401'\n'207401'\n,\n,\n \n \n'056201'\n'056201'\n,\n,\n \n \n'004C00'\n'004C00'\n,\n,\n \n \n'023B01'\n'023B01'\n,\n,\n \n \n'012E01'\n'012E01'\n,\n,\n \n \n'011D01'\n'011D01'\n]\n]\n,\n,\n  \n  \nrisk\nrisk\n:\n:\n \n \n[\n[\n'2166AC'\n'2166AC'\n,\n,\n \n \n'4393C3'\n'4393C3'\n,\n,\n \n \n'92C5DE'\n'92C5DE'\n,\n,\n \n \n'D1E5F0'\n'D1E5F0'\n,\n,\n \n \n'F7F7F7'\n'F7F7F7'\n,\n,\n \n \n         \n         \n'FDDBC7'\n'FDDBC7'\n,\n,\n \n \n'F4A582'\n'F4A582'\n,\n,\n \n \n'D6604D'\n'D6604D'\n,\n,\n \n \n'B2182B'\n'B2182B'\n]\n]\n,\n,\n  \n  \nsimple\nsimple\n:\n:\n \n \n[\n[\n'brown'\n'brown'\n,\n,\n \n \n'yellow'\n'yellow'\n,\n,\n \n \n'green'\n'green'\n]\n]\n}\n}\n;\n;\n// Create UI selector for palettes\n// Create UI selector for palettes\nvar\nvar\n paletteSelect \n paletteSelect \n=\n=\n ui\n ui\n.\n.\nSelect\nSelect\n(\n(\n{\n{\n  \n  \nitems\nitems\n:\n:\n \n \nObject\nObject\n.\n.\nkeys\nkeys\n(\n(\npalettes\npalettes\n)\n)\n,\n,\n  \n  \nvalue\nvalue\n:\n:\n \n \n'vegetation'\n'vegetation'\n,\n,\n  \n  \nonChange\nonChange\n:\n:\n \n \nfunction\nfunction\n(\n(\nkey\nkey\n)\n)\n \n \n{\n{\n    \n    \nMap\nMap\n.\n.\nlayers\nlayers\n(\n(\n)\n)\n.\n.\nget\nget\n(\n(\n0\n0\n)\n)\n.\n.\nsetVisParams\nsetVisParams\n(\n(\n{\n{\n      \n      \nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n palettes\n palettes\n[\n[\nkey\nkey\n]\n]\n    \n    \n}\n}\n)\n)\n;\n;\n  \n  \n}\n}\n}\n}\n)\n)\n;\n;\n// Add to map\n// Add to map\nMap\nMap\n.\n.\nadd\nadd\n(\n(\npaletteSelect\npaletteSelect\n)\n)\n;\n;\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nndviMedian\nndviMedian\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n palettes\n palettes\n.\n.\nvegetation\nvegetation\n}\n}\n,\n,\n \n \n'NDVI'\n'NDVI'\n)\n)\n;\n;\n\nExercise 3: District Summary Export (10 min)\nStep 4: Calculate district statistics\njavascript\n// Load CHIRPS rainfall\n// Load CHIRPS rainfall\nvar\nvar\n chirps \n chirps \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'UCSB-CHG/CHIRPS/DAILY'\n'UCSB-CHG/CHIRPS/DAILY'\n)\n)\n  \n  \n.\n.\nfilterDate\nfilterDate\n(\n(\n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-12-31'\n'2024-12-31'\n)\n)\n  \n  \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nuganda\nuganda\n)\n)\n;\n;\n// Calculate total annual rainfall\n// Calculate total annual rainfall\nvar\nvar\n annualRainfall \n annualRainfall \n=\n=\n chirps\n chirps\n.\n.\nsum\nsum\n(\n(\n)\n)\n.\n.\nclip\nclip\n(\n(\nuganda\nuganda\n)\n)\n;\n;\n// Create split panel map\n// Create split panel map\nvar\nvar\n leftMap \n leftMap \n=\n=\n ui\n ui\n.\n.\nMap\nMap\n(\n(\n)\n)\n;\n;\nvar\nvar\n rightMap \n rightMap \n=\n=\n ui\n ui\n.\n.\nMap\nMap\n(\n(\n)\n)\n;\n;\n// Configure maps\n// Configure maps\nleftMap\nleftMap\n.\n.\naddLayer\naddLayer\n(\n(\nndviMedian\nndviMedian\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n palettes\n palettes\n.\n.\nvegetation\nvegetation\n}\n}\n,\n,\n \n \n'NDVI'\n'NDVI'\n)\n)\n;\n;\nrightMap\nrightMap\n.\n.\naddLayer\naddLayer\n(\n(\nannualRainfall\nannualRainfall\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n3000\n3000\n,\n,\n \n \npalette\npalette\n:\n:\n palettes\n palettes\n.\n.\nrisk\nrisk\n}\n}\n,\n,\n \n \n'Rainfall'\n'Rainfall'\n)\n)\n;\n;\n// Link the maps\n// Link the maps\nvar\nvar\n linker \n linker \n=\n=\n ui\n ui\n.\n.\nMap\nMap\n.\n.\nLinker\nLinker\n(\n(\n[\n[\nleftMap\nleftMap\n,\n,\n rightMap\n rightMap\n]\n]\n)\n)\n;\n;\nleftMap\nleftMap\n.\n.\ncenterObject\ncenterObject\n(\n(\nuganda\nuganda\n,\n,\n \n \n7\n7\n)\n)\n;\n;\n// Create split panel\n// Create split panel\nvar\nvar\n splitPanel \n splitPanel \n=\n=\n ui\n ui\n.\n.\nSplitPanel\nSplitPanel\n(\n(\n{\n{\n  \n  \nfirstPanel\nfirstPanel\n:\n:\n leftMap\n leftMap\n,\n,\n  \n  \nsecondPanel\nsecondPanel\n:\n:\n rightMap\n rightMap\n,\n,\n  \n  \norientation\norientation\n:\n:\n \n \n'horizontal'\n'horizontal'\n,\n,\n  \n  \nwipe\nwipe\n:\n:\n \n \ntrue\ntrue\n}\n}\n)\n)\n;\n;\n// Replace the root with split panel\n// Replace the root with split panel\nui\nui\n.\n.\nroot\nroot\n.\n.\nclear\nclear\n(\n(\n)\n)\n;\n;\nui\nui\n.\n.\nroot\nroot\n.\n.\nadd\nadd\n(\n(\nsplitPanel\nsplitPanel\n)\n)\n;\n;\n\nExercise 4: QA Visualization (10 min)\nStep 5: Create validation charts\njavascript\n// Load district boundaries\n// Load district boundaries\nvar\nvar\n districts \n districts \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_2'\n'UCSB-CHG/GADM/gadm36_2'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\n// Function to extract mean values per district\n// Function to extract mean values per district\nvar\nvar\n \n \nextractStats\nextractStats\n \n \n=\n=\n \n \nfunction\nfunction\n(\n(\nfeature\nfeature\n)\n)\n \n \n{\n{\n  \n  \nvar\nvar\n ndviMean \n ndviMean \n=\n=\n ndviMedian\n ndviMedian\n.\n.\nreduceRegion\nreduceRegion\n(\n(\n{\n{\n    \n    \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nmean\nmean\n(\n(\n)\n)\n,\n,\n    \n    \ngeometry\ngeometry\n:\n:\n feature\n feature\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n,\n,\n    \n    \nscale\nscale\n:\n:\n \n \n250\n250\n,\n,\n    \n    \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e9\n1e9\n  \n  \n}\n}\n)\n)\n;\n;\n  \n  \n  \n  \nvar\nvar\n rainfallMean \n rainfallMean \n=\n=\n annualRainfall\n annualRainfall\n.\n.\nreduceRegion\nreduceRegion\n(\n(\n{\n{\n    \n    \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nmean\nmean\n(\n(\n)\n)\n,\n,\n    \n    \ngeometry\ngeometry\n:\n:\n feature\n feature\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n,\n,\n    \n    \nscale\nscale\n:\n:\n \n \n5000\n5000\n,\n,\n    \n    \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e9\n1e9\n  \n  \n}\n}\n)\n)\n;\n;\n  \n  \n  \n  \nreturn\nreturn\n feature\n feature\n.\n.\nset\nset\n(\n(\n{\n{\n    \n    \n'ndvi_mean'\n'ndvi_mean'\n:\n:\n ndviMean\n ndviMean\n.\n.\nget\nget\n(\n(\n'NDVI'\n'NDVI'\n)\n)\n,\n,\n    \n    \n'rainfall_mean'\n'rainfall_mean'\n:\n:\n rainfallMean\n rainfallMean\n.\n.\nget\nget\n(\n(\n'precipitation'\n'precipitation'\n)\n)\n,\n,\n    \n    \n'district'\n'district'\n:\n:\n feature\n feature\n.\n.\nget\nget\n(\n(\n'NAME_2'\n'NAME_2'\n)\n)\n  \n  \n}\n}\n)\n)\n;\n;\n}\n}\n;\n;\n// Apply to all districts\n// Apply to all districts\nvar\nvar\n districtStats \n districtStats \n=\n=\n districts\n districts\n.\n.\nmap\nmap\n(\n(\nextractStats\nextractStats\n)\n)\n;\n;\n// Export to Drive\n// Export to Drive\nExport\nExport\n.\n.\ntable\ntable\n.\n.\ntoDrive\ntoDrive\n(\n(\n{\n{\n  \n  \ncollection\ncollection\n:\n:\n districtStats\n districtStats\n,\n,\n  \n  \ndescription\ndescription\n:\n:\n \n \n'Uganda_District_Environmental_Stats'\n'Uganda_District_Environmental_Stats'\n,\n,\n  \n  \nfileFormat\nfileFormat\n:\n:\n \n \n'CSV'\n'CSV'\n,\n,\n  \n  \nselectors\nselectors\n:\n:\n \n \n[\n[\n'district'\n'district'\n,\n,\n \n \n'ndvi_mean'\n'ndvi_mean'\n,\n,\n \n \n'rainfall_mean'\n'rainfall_mean'\n]\n]\n}\n}\n)\n)\n;\n;\n\nWhy These Variables? (5 min debrief)\nInstructor talking points:\nNDVI indicates vegetation density - higher values suggest more mosquito breeding habitat\nRainfall creates standing water - critical for mosquito larvae\nCombined, they predict malaria transmission potential\nTemporal patterns matter - lag between rainfall and cases\nLab 4: Using ChatGPT to Prompt and Write GEE Code (11:00-12:00)\nMini-Lecture: Prompt Patterns (15 min)\nDistribute this cheat sheet:\njavascript\n// Select two contrasting points\n// Select two contrasting points\nvar\nvar\n wetPoint \n wetPoint \n=\n=\n ee\n ee\n.\n.\nGeometry\nGeometry\n.\n.\nPoint\nPoint\n(\n(\n[\n[\n32.5\n32.5\n,\n,\n \n \n0.5\n0.5\n]\n]\n)\n)\n;\n;\n \n \n// Near Lake Victoria\n// Near Lake Victoria\nvar\nvar\n dryPoint \n dryPoint \n=\n=\n ee\n ee\n.\n.\nGeometry\nGeometry\n.\n.\nPoint\nPoint\n(\n(\n[\n[\n34.0\n34.0\n,\n,\n \n \n3.5\n3.5\n]\n]\n)\n)\n;\n;\n \n \n// Karamoja region\n// Karamoja region\n// Time series chart\n// Time series chart\nvar\nvar\n chart \n chart \n=\n=\n ui\n ui\n.\n.\nChart\nChart\n.\n.\nimage\nimage\n.\n.\nseries\nseries\n(\n(\n{\n{\n  \n  \nimageCollection\nimageCollection\n:\n:\n ndviScaled\n ndviScaled\n.\n.\nselect\nselect\n(\n(\n'NDVI'\n'NDVI'\n)\n)\n,\n,\n  \n  \nregion\nregion\n:\n:\n wetPoint\n wetPoint\n,\n,\n  \n  \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nmean\nmean\n(\n(\n)\n)\n,\n,\n  \n  \nscale\nscale\n:\n:\n \n \n250\n250\n}\n}\n)\n)\n.\n.\nsetOptions\nsetOptions\n(\n(\n{\n{\n  \n  \ntitle\ntitle\n:\n:\n \n \n'NDVI Time Series - Wet vs Dry Regions'\n'NDVI Time Series - Wet vs Dry Regions'\n,\n,\n  \n  \nvAxis\nvAxis\n:\n:\n \n \n{\n{\ntitle\ntitle\n:\n:\n \n \n'NDVI'\n'NDVI'\n}\n}\n,\n,\n  \n  \nhAxis\nhAxis\n:\n:\n \n \n{\n{\ntitle\ntitle\n:\n:\n \n \n'Date'\n'Date'\n}\n}\n,\n,\n  \n  \nseries\nseries\n:\n:\n \n \n{\n{\n    \n    \n0\n0\n:\n:\n \n \n{\n{\ncolor\ncolor\n:\n:\n \n \n'green'\n'green'\n,\n,\n \n \nlabel\nlabel\n:\n:\n \n \n'Wet Region'\n'Wet Region'\n}\n}\n,\n,\n    \n    \n1\n1\n:\n:\n \n \n{\n{\ncolor\ncolor\n:\n:\n \n \n'brown'\n'brown'\n,\n,\n \n \nlabel\nlabel\n:\n:\n \n \n'Dry Region'\n'Dry Region'\n}\n}\n  \n  \n}\n}\n}\n}\n)\n)\n;\n;\nprint\nprint\n(\n(\nchart\nchart\n)\n)\n;\n;\n\nHands-On Exercises (45 min)\nExercise 1: Debug a Broken Script (15 min)\nGive participants this broken code:\nmarkdown\n#\n#\n ChatGPT Prompt Patterns for GEE\n ChatGPT Prompt Patterns for GEE\n##\n##\n 1. Diagnose Pattern\n 1. Diagnose Pattern\n\"I'm getting this error in Google Earth Engine: [paste error]. \n\"I'm getting this error in Google Earth Engine: [paste error]. \nMy code is: [paste code]. What's wrong and how do I fix it?\"\nMy code is: [paste code]. What's wrong and how do I fix it?\"\n##\n##\n 2. Refactor Pattern\n 2. Refactor Pattern\n\"Optimize this GEE code for better performance: [paste code]. \n\"Optimize this GEE code for better performance: [paste code]. \nFocus on reducing computation time and memory usage.\"\nFocus on reducing computation time and memory usage.\"\n##\n##\n 3. Explain-as-Analogy Pattern\n 3. Explain-as-Analogy Pattern\n\"Explain how ee.Reducer.frequencyHistogram() works using \n\"Explain how ee.Reducer.frequencyHistogram() works using \na real-world analogy that health workers would understand.\"\na real-world analogy that health workers would understand.\"\n##\n##\n 4. Translate Pseudocode Pattern\n 4. Translate Pseudocode Pattern\n\"Convert this logic to GEE JavaScript:\n\"Convert this logic to GEE JavaScript:\n-\n-\n Load rainfall data for Uganda\n Load rainfall data for Uganda\n-\n-\n For each month, find areas with >100mm rain\n For each month, find areas with >100mm rain\n-\n-\n Count how many months each pixel exceeds threshold\"\n Count how many months each pixel exceeds threshold\"\n##\n##\n 5. Rate-Limit Aware Pattern\n 5. Rate-Limit Aware Pattern\n\"Rewrite this script to batch-export by district to avoid \n\"Rewrite this script to batch-export by district to avoid \nGEE computation timeouts: [paste code]\"\nGEE computation timeouts: [paste code]\"\n\nExpected ChatGPT fixes:\njavascript\n// BROKEN CODE - FIX WITH CHATGPT\n// BROKEN CODE - FIX WITH CHATGPT\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_3'\n'UCSB-CHG/GADM/gadm36_3'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n;\n;\n  \n  \n// Missing parenthesis\n// Missing parenthesis\nvar\nvar\n ndvi \n ndvi \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'MODIS/006/MOD13Q1'\n'MODIS/006/MOD13Q1'\n)\n)\n  \n  \n.\n.\nfilterdate\nfilterdate\n(\n(\n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-12-31'\n'2024-12-31'\n)\n)\n  \n  \n// Wrong case\n// Wrong case\n  \n  \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nuganda\nuganda\n)\n)\n  \n  \n.\n.\nselect\nselect\n(\n(\n[\n[\n'NDVI'\n'NDVI'\n]\n]\n)\n)\n;\n;\nvar\nvar\n mean_ndvi \n mean_ndvi \n=\n=\n ndvi\n ndvi\n.\n.\nmean\nmean\n(\n(\n)\n)\n;\n;\n  \n  \n// Forgot to scale\n// Forgot to scale\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nmean_ndvi\nmean_ndvi\n,\n,\n \n \n{\n{\n}\n}\n,\n,\n \n \n'NDVI'\n'NDVI'\n)\n)\n;\n;\n  \n  \n// No visualization parameters\n// No visualization parameters\n// Try to export without clipping\n// Try to export without clipping\nExport\nExport\n.\n.\nimage\nimage\n.\n.\ntoDrive\ntoDrive\n(\n(\n{\n{\n  \n  \nimage\nimage\n:\n:\n mean_ndvi\n mean_ndvi\n,\n,\n  \n  \ndescription\ndescription\n:\n:\n \n \n'Uganda_NDVI'\n'Uganda_NDVI'\n,\n,\n  \n  \nscale\nscale\n:\n:\n \n \n250\n250\n}\n}\n)\n)\n;\n;\n\nExercise 2: Build Mosquito Breeding Site Detector (15 min)\nPrompt sequence for participants:\n1. First prompt: \"Write a GEE script that identifies potential mosquito breeding sites by finding areas\nwith NDVI > 0.6 and rainfall > 50mm in the last month\"\n2. Second prompt: \"Add error handling for missing data and cloud masking to this script: [paste\nresult]\"\n3. Third prompt: \"Optimize this for large areas by using reduceRegions instead of pixel-wise\noperations\"\nExpected final code:\njavascript\n// FIXED CODE\n// FIXED CODE\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_3'\n'UCSB-CHG/GADM/gadm36_3'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\n \n \n// Fixed parenthesis\n// Fixed parenthesis\nvar\nvar\n ndvi \n ndvi \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'MODIS/006/MOD13Q1'\n'MODIS/006/MOD13Q1'\n)\n)\n  \n  \n.\n.\nfilterDate\nfilterDate\n(\n(\n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-12-31'\n'2024-12-31'\n)\n)\n  \n  \n// Fixed case\n// Fixed case\n  \n  \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nuganda\nuganda\n)\n)\n  \n  \n.\n.\nselect\nselect\n(\n(\n[\n[\n'NDVI'\n'NDVI'\n]\n]\n)\n)\n;\n;\n// Scale NDVI values\n// Scale NDVI values\nvar\nvar\n ndviScaled \n ndviScaled \n=\n=\n ndvi\n ndvi\n.\n.\nmap\nmap\n(\n(\nfunction\nfunction\n(\n(\nimage\nimage\n)\n)\n \n \n{\n{\n  \n  \nreturn\nreturn\n image\n image\n.\n.\nmultiply\nmultiply\n(\n(\n0.0001\n0.0001\n)\n)\n;\n;\n}\n}\n)\n)\n;\n;\nvar\nvar\n mean_ndvi \n mean_ndvi \n=\n=\n ndviScaled\n ndviScaled\n.\n.\nmean\nmean\n(\n(\n)\n)\n.\n.\nclip\nclip\n(\n(\nuganda\nuganda\n)\n)\n;\n;\n \n \n// Added clip\n// Added clip\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nmean_ndvi\nmean_ndvi\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'white'\n'white'\n,\n,\n \n \n'green'\n'green'\n]\n]\n}\n}\n,\n,\n \n \n'NDVI'\n'NDVI'\n)\n)\n;\n;\n// Export with region specified\n// Export with region specified\nExport\nExport\n.\n.\nimage\nimage\n.\n.\ntoDrive\ntoDrive\n(\n(\n{\n{\n  \n  \nimage\nimage\n:\n:\n mean_ndvi\n mean_ndvi\n,\n,\n  \n  \ndescription\ndescription\n:\n:\n \n \n'Uganda_NDVI'\n'Uganda_NDVI'\n,\n,\n  \n  \nscale\nscale\n:\n:\n \n \n250\n250\n,\n,\n  \n  \nregion\nregion\n:\n:\n uganda\n uganda\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n.\n.\nbounds\nbounds\n(\n(\n)\n)\n,\n,\n  \n  \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e13\n1e13\n}\n}\n)\n)\n;\n;\n\njavascript\n\n// Function to identify breeding sites\n// Function to identify breeding sites\nfunction\nfunction\n \n \nidentifyBreedingSites\nidentifyBreedingSites\n(\n(\nstartDate\nstartDate\n,\n,\n endDate\n endDate\n)\n)\n \n \n{\n{\n  \n  \n// Load data\n// Load data\n  \n  \nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_3'\n'UCSB-CHG/GADM/gadm36_3'\n)\n)\n    \n    \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\n  \n  \n  \n  \n// Get NDVI\n// Get NDVI\n  \n  \nvar\nvar\n ndvi \n ndvi \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'MODIS/006/MOD13Q1'\n'MODIS/006/MOD13Q1'\n)\n)\n    \n    \n.\n.\nfilterDate\nfilterDate\n(\n(\nstartDate\nstartDate\n,\n,\n endDate\n endDate\n)\n)\n    \n    \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nuganda\nuganda\n)\n)\n    \n    \n.\n.\nselect\nselect\n(\n(\n'NDVI'\n'NDVI'\n)\n)\n    \n    \n.\n.\nmap\nmap\n(\n(\nfunction\nfunction\n(\n(\nimg\nimg\n)\n)\n \n \n{\n{\n      \n      \nreturn\nreturn\n img\n img\n.\n.\nmultiply\nmultiply\n(\n(\n0.0001\n0.0001\n)\n)\n        \n        \n.\n.\nupdateMask\nupdateMask\n(\n(\nimg\nimg\n.\n.\nselect\nselect\n(\n(\n'NDVI'\n'NDVI'\n)\n)\n.\n.\ngt\ngt\n(\n(\n0\n0\n)\n)\n)\n)\n;\n;\n \n \n// Remove invalid pixels\n// Remove invalid pixels\n    \n    \n}\n}\n)\n)\n    \n    \n.\n.\nmedian\nmedian\n(\n(\n)\n)\n;\n;\n  \n  \n  \n  \n// Get rainfall\n// Get rainfall\n  \n  \nvar\nvar\n rainfall \n rainfall \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'UCSB-CHG/CHIRPS/DAILY'\n'UCSB-CHG/CHIRPS/DAILY'\n)\n)\n    \n    \n.\n.\nfilterDate\nfilterDate\n(\n(\nstartDate\nstartDate\n,\n,\n endDate\n endDate\n)\n)\n    \n    \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nuganda\nuganda\n)\n)\n    \n    \n.\n.\nsum\nsum\n(\n(\n)\n)\n;\n;\n  \n  \n  \n  \n// Identify high-risk areas\n// Identify high-risk areas\n  \n  \nvar\nvar\n highNDVI \n highNDVI \n=\n=\n ndvi\n ndvi\n.\n.\ngt\ngt\n(\n(\n0.6\n0.6\n)\n)\n;\n;\n  \n  \nvar\nvar\n highRainfall \n highRainfall \n=\n=\n rainfall\n rainfall\n.\n.\ngt\ngt\n(\n(\n50\n50\n)\n)\n;\n;\n  \n  \nvar\nvar\n breedingSites \n breedingSites \n=\n=\n highNDVI\n highNDVI\n.\n.\nand\nand\n(\n(\nhighRainfall\nhighRainfall\n)\n)\n;\n;\n  \n  \n  \n  \n// Calculate area by district\n// Calculate area by district\n  \n  \nvar\nvar\n districts \n districts \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_2'\n'UCSB-CHG/GADM/gadm36_2'\n)\n)\n    \n    \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\n  \n  \n  \n  \nvar\nvar\n areaByDistrict \n areaByDistrict \n=\n=\n breedingSites\n breedingSites\n.\n.\nmultiply\nmultiply\n(\n(\nee\nee\n.\n.\nImage\nImage\n.\n.\npixelArea\npixelArea\n(\n(\n)\n)\n)\n)\n    \n    \n.\n.\nreduceRegions\nreduceRegions\n(\n(\n{\n{\n      \n      \ncollection\ncollection\n:\n:\n districts\n districts\n,\n,\n      \n      \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nsum\nsum\n(\n(\n)\n)\n,\n,\n      \n      \nscale\nscale\n:\n:\n \n \n250\n250\n    \n    \n}\n}\n)\n)\n;\n;\n  \n  \n  \n  \nreturn\nreturn\n \n \n{\n{\n    \n    \nriskMap\nriskMap\n:\n:\n breedingSites\n breedingSites\n.\n.\nselfMask\nselfMask\n(\n(\n)\n)\n.\n.\nclip\nclip\n(\n(\nuganda\nuganda\n)\n)\n,\n,\n    \n    \nstatistics\nstatistics\n:\n:\n areaByDistrict\n areaByDistrict\n  \n  \n}\n}\n;\n;\n\nExercise 3: Create Reusable Functions (15 min)\nPrompt: \"Create a reusable function library for common GEE operations in health mapping:\ngetMedianNDVI, getTotalRainfall, and standardizeImage\"\nExpected result:\n}\n}\n// Run for last month\n// Run for last month\nvar\nvar\n endDate \n endDate \n=\n=\n ee\n ee\n.\n.\nDate\nDate\n(\n(\nDate\nDate\n.\n.\nnow\nnow\n(\n(\n)\n)\n)\n)\n;\n;\nvar\nvar\n startDate \n startDate \n=\n=\n endDate\n endDate\n.\n.\nadvance\nadvance\n(\n(\n-\n-\n1\n1\n,\n,\n \n \n'month'\n'month'\n)\n)\n;\n;\nvar\nvar\n results \n results \n=\n=\n \n \nidentifyBreedingSites\nidentifyBreedingSites\n(\n(\nstartDate\nstartDate\n,\n,\n endDate\n endDate\n)\n)\n;\n;\n// Visualize\n// Visualize\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nresults\nresults\n.\n.\nriskMap\nriskMap\n,\n,\n \n \n{\n{\npalette\npalette\n:\n:\n \n \n[\n[\n'red'\n'red'\n]\n]\n}\n}\n,\n,\n \n \n'Breeding Sites'\n'Breeding Sites'\n)\n)\n;\n;\nprint\nprint\n(\n(\n'Area by district:'\n'Area by district:'\n,\n,\n results\n results\n.\n.\nstatistics\nstatistics\n)\n)\n;\n;\n\njavascript\n\n// Reusable function library for health mapping\n// Reusable function library for health mapping\nvar\nvar\n healthMapUtils \n healthMapUtils \n=\n=\n \n \n{\n{\n  \n  \n// Get median NDVI for a region and time period\n// Get median NDVI for a region and time period\n  \n  \ngetMedianNDVI\ngetMedianNDVI\n:\n:\n \n \nfunction\nfunction\n(\n(\nregion\nregion\n,\n,\n startDate\n startDate\n,\n,\n endDate\n endDate\n)\n)\n \n \n{\n{\n    \n    \nreturn\nreturn\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'MODIS/006/MOD13Q1'\n'MODIS/006/MOD13Q1'\n)\n)\n      \n      \n.\n.\nfilterDate\nfilterDate\n(\n(\nstartDate\nstartDate\n,\n,\n endDate\n endDate\n)\n)\n      \n      \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nregion\nregion\n)\n)\n      \n      \n.\n.\nselect\nselect\n(\n(\n'NDVI'\n'NDVI'\n)\n)\n      \n      \n.\n.\nmap\nmap\n(\n(\nfunction\nfunction\n(\n(\nimg\nimg\n)\n)\n \n \n{\n{\n        \n        \nreturn\nreturn\n img\n img\n.\n.\nmultiply\nmultiply\n(\n(\n0.0001\n0.0001\n)\n)\n          \n          \n.\n.\ncopyProperties\ncopyProperties\n(\n(\nimg\nimg\n,\n,\n \n \n[\n[\n'system:time_start'\n'system:time_start'\n]\n]\n)\n)\n;\n;\n      \n      \n}\n}\n)\n)\n      \n      \n.\n.\nmedian\nmedian\n(\n(\n)\n)\n      \n      \n.\n.\nclip\nclip\n(\n(\nregion\nregion\n)\n)\n;\n;\n  \n  \n}\n}\n,\n,\n  \n  \n  \n  \n// Get total rainfall\n// Get total rainfall\n  \n  \ngetTotalRainfall\ngetTotalRainfall\n:\n:\n \n \nfunction\nfunction\n(\n(\nregion\nregion\n,\n,\n startDate\n startDate\n,\n,\n endDate\n endDate\n)\n)\n \n \n{\n{\n    \n    \nreturn\nreturn\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'UCSB-CHG/CHIRPS/DAILY'\n'UCSB-CHG/CHIRPS/DAILY'\n)\n)\n      \n      \n.\n.\nfilterDate\nfilterDate\n(\n(\nstartDate\nstartDate\n,\n,\n endDate\n endDate\n)\n)\n      \n      \n.\n.\nfilterBounds\nfilterBounds\n(\n(\nregion\nregion\n)\n)\n      \n      \n.\n.\nsum\nsum\n(\n(\n)\n)\n      \n      \n.\n.\nclip\nclip\n(\n(\nregion\nregion\n)\n)\n;\n;\n  \n  \n}\n}\n,\n,\n  \n  \n  \n  \n// Standardize image to 0-1 range\n// Standardize image to 0-1 range\n  \n  \nstandardizeImage\nstandardizeImage\n:\n:\n \n \nfunction\nfunction\n(\n(\nimage\nimage\n,\n,\n bandName\n bandName\n)\n)\n \n \n{\n{\n    \n    \nvar\nvar\n band \n band \n=\n=\n image\n image\n.\n.\nselect\nselect\n(\n(\nbandName\nbandName\n)\n)\n;\n;\n    \n    \nvar\nvar\n minMax \n minMax \n=\n=\n band\n band\n.\n.\nreduceRegion\nreduceRegion\n(\n(\n{\n{\n      \n      \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nminMax\nminMax\n(\n(\n)\n)\n,\n,\n      \n      \ngeometry\ngeometry\n:\n:\n image\n image\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n,\n,\n      \n      \nscale\nscale\n:\n:\n \n \n1000\n1000\n,\n,\n      \n      \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e9\n1e9\n    \n    \n}\n}\n)\n)\n;\n;\n    \n    \n    \n    \nvar\nvar\n min \n min \n=\n=\n ee\n ee\n.\n.\nNumber\nNumber\n(\n(\nminMax\nminMax\n.\n.\nget\nget\n(\n(\nbandName \nbandName \n+\n+\n \n \n'_min'\n'_min'\n)\n)\n)\n)\n;\n;\n    \n    \nvar\nvar\n max \n max \n=\n=\n ee\n ee\n.\n.\nNumber\nNumber\n(\n(\nminMax\nminMax\n.\n.\nget\nget\n(\n(\nbandName \nbandName \n+\n+\n \n \n'_max'\n'_max'\n)\n)\n)\n)\n;\n;\n    \n    \n    \n    \nreturn\nreturn\n band\n band\n.\n.\nsubtract\nsubtract\n(\n(\nmin\nmin\n)\n)\n.\n.\ndivide\ndivide\n(\n(\nmax\nmax\n.\n.\nsubtract\nsubtract\n(\n(\nmin\nmin\n)\n)\n)\n)\n      \n      \n.\n.\nrename\nrename\n(\n(\nbandName \nbandName \n+\n+\n \n \n'_normalized'\n'_normalized'\n)\n)\n;\n;\n  \n  \n}\n}\n}\n}\n;\n;\n\nLab 5: AI-Based Clustering for Malaria Risk Mapping (13:00-14:30)\nExercise 1: Prepare Multi-band Stack with Scaling (20 min)\nStep 1: Create properly scaled multi-band image\n// Example usage\n// Example usage\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_3'\n'UCSB-CHG/GADM/gadm36_3'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\nvar\nvar\n ndvi \n ndvi \n=\n=\n healthMapUtils\n healthMapUtils\n.\n.\ngetMedianNDVI\ngetMedianNDVI\n(\n(\nuganda\nuganda\n,\n,\n \n \n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-03-31'\n'2024-03-31'\n)\n)\n;\n;\nvar\nvar\n rainfall \n rainfall \n=\n=\n healthMapUtils\n healthMapUtils\n.\n.\ngetTotalRainfall\ngetTotalRainfall\n(\n(\nuganda\nuganda\n,\n,\n \n \n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-03-31'\n'2024-03-31'\n)\n)\n;\n;\nvar\nvar\n ndviNorm \n ndviNorm \n=\n=\n healthMapUtils\n healthMapUtils\n.\n.\nstandardizeImage\nstandardizeImage\n(\n(\nndvi\nndvi\n,\n,\n \n \n'NDVI'\n'NDVI'\n)\n)\n;\n;\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nndviNorm\nndviNorm\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n1\n1\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'brown'\n'brown'\n,\n,\n \n \n'yellow'\n'yellow'\n,\n,\n \n \n'green'\n'green'\n]\n]\n}\n}\n,\n,\n \n \n'NDVI Normalize\n'NDVI Normalize\n\njavascript\n\n// Load all required data\n// Load all required data\nvar\nvar\n uganda \n uganda \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_3'\n'UCSB-CHG/GADM/gadm36_3'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n;\n;\n// Environmental variables\n// Environmental variables\nvar\nvar\n ndvi \n ndvi \n=\n=\n healthMapUtils\n healthMapUtils\n.\n.\ngetMedianNDVI\ngetMedianNDVI\n(\n(\nuganda\nuganda\n,\n,\n \n \n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-03-31'\n'2024-03-31'\n)\n)\n;\n;\nvar\nvar\n rainfall \n rainfall \n=\n=\n healthMapUtils\n healthMapUtils\n.\n.\ngetTotalRainfall\ngetTotalRainfall\n(\n(\nuganda\nuganda\n,\n,\n \n \n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-03-31'\n'2024-03-31'\n)\n)\n;\n;\n// Add elevation\n// Add elevation\nvar\nvar\n elevation \n elevation \n=\n=\n ee\n ee\n.\n.\nImage\nImage\n(\n(\n'USGS/SRTMGL1_003'\n'USGS/SRTMGL1_003'\n)\n)\n.\n.\nselect\nselect\n(\n(\n'elevation'\n'elevation'\n)\n)\n.\n.\nclip\nclip\n(\n(\nuganda\nuganda\n)\n)\n;\n;\n// Add temperature (optional)\n// Add temperature (optional)\nvar\nvar\n temperature \n temperature \n=\n=\n ee\n ee\n.\n.\nImageCollection\nImageCollection\n(\n(\n'MODIS/006/MOD11A1'\n'MODIS/006/MOD11A1'\n)\n)\n  \n  \n.\n.\nfilterDate\nfilterDate\n(\n(\n'2024-01-01'\n'2024-01-01'\n,\n,\n \n \n'2024-03-31'\n'2024-03-31'\n)\n)\n  \n  \n.\n.\nselect\nselect\n(\n(\n'LST_Day_1km'\n'LST_Day_1km'\n)\n)\n  \n  \n.\n.\nmap\nmap\n(\n(\nfunction\nfunction\n(\n(\nimg\nimg\n)\n)\n \n \n{\n{\n    \n    \nreturn\nreturn\n img\n img\n.\n.\nmultiply\nmultiply\n(\n(\n0.02\n0.02\n)\n)\n.\n.\nsubtract\nsubtract\n(\n(\n273.15\n273.15\n)\n)\n;\n;\n \n \n// Convert to Celsius\n// Convert to Celsius\n  \n  \n}\n}\n)\n)\n  \n  \n.\n.\nmean\nmean\n(\n(\n)\n)\n  \n  \n.\n.\nclip\nclip\n(\n(\nuganda\nuganda\n)\n)\n;\n;\n// ChatGPT-assisted min-max scaling\n// ChatGPT-assisted min-max scaling\nvar\nvar\n \n \nscaleImage\nscaleImage\n \n \n=\n=\n \n \nfunction\nfunction\n(\n(\nimage\nimage\n,\n,\n bandName\n bandName\n)\n)\n \n \n{\n{\n  \n  \nvar\nvar\n band \n band \n=\n=\n image\n image\n.\n.\nselect\nselect\n(\n(\nbandName\nbandName\n)\n)\n;\n;\n  \n  \nvar\nvar\n minMax \n minMax \n=\n=\n band\n band\n.\n.\nreduceRegion\nreduceRegion\n(\n(\n{\n{\n    \n    \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nminMax\nminMax\n(\n(\n)\n)\n,\n,\n    \n    \ngeometry\ngeometry\n:\n:\n uganda\n uganda\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n,\n,\n    \n    \nscale\nscale\n:\n:\n \n \n1000\n1000\n,\n,\n    \n    \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e9\n1e9\n,\n,\n    \n    \nbestEffort\nbestEffort\n:\n:\n \n \ntrue\ntrue\n  \n  \n}\n}\n)\n)\n;\n;\n  \n  \n  \n  \nvar\nvar\n min \n min \n=\n=\n ee\n ee\n.\n.\nNumber\nNumber\n(\n(\nminMax\nminMax\n.\n.\nget\nget\n(\n(\nbandName \nbandName \n+\n+\n \n \n'_min'\n'_min'\n)\n)\n)\n)\n;\n;\n  \n  \nvar\nvar\n max \n max \n=\n=\n ee\n ee\n.\n.\nNumber\nNumber\n(\n(\nminMax\nminMax\n.\n.\nget\nget\n(\n(\nbandName \nbandName \n+\n+\n \n \n'_max'\n'_max'\n)\n)\n)\n)\n;\n;\n  \n  \n  \n  \nreturn\nreturn\n band\n band\n.\n.\nsubtract\nsubtract\n(\n(\nmin\nmin\n)\n)\n.\n.\ndivide\ndivide\n(\n(\nmax\nmax\n.\n.\nsubtract\nsubtract\n(\n(\nmin\nmin\n)\n)\n)\n)\n    \n    \n.\n.\nrename\nrename\n(\n(\nbandName \nbandName \n+\n+\n \n \n'_scaled'\n'_scaled'\n)\n)\n;\n;\n}\n}\n;\n;\n// Scale all bands\n// Scale all bands\nvar\nvar\n ndviScaled \n ndviScaled \n=\n=\n \n \nscaleImage\nscaleImage\n(\n(\nndvi\nndvi\n,\n,\n \n \n'NDVI'\n'NDVI'\n)\n)\n;\n;\nvar\nvar\n rainfallScaled \n rainfallScaled \n=\n=\n \n \nscaleImage\nscaleImage\n(\n(\nrainfall\nrainfall\n,\n,\n \n \n'precipitation'\n'precipitation'\n)\n)\n;\n;\nvar\nvar\n elevationScaled \n elevationScaled \n=\n=\n \n \nscaleImage\nscaleImage\n(\n(\nelevation\nelevation\n,\n,\n \n \n'elevation'\n'elevation'\n)\n)\n;\n;\n\nCoffee Break (10 min)\nExercise 2: K-means Clustering (30 min)\nStep 2: Implement clustering with validation\nvar\nvar\n tempScaled \n tempScaled \n=\n=\n \n \nscaleImage\nscaleImage\n(\n(\ntemperature\ntemperature\n,\n,\n \n \n'LST_Day_1km'\n'LST_Day_1km'\n)\n)\n;\n;\n// Create multi-band image\n// Create multi-band image\nvar\nvar\n composite \n composite \n=\n=\n ndviScaled\n ndviScaled\n  \n  \n.\n.\naddBands\naddBands\n(\n(\nrainfallScaled\nrainfallScaled\n)\n)\n  \n  \n.\n.\naddBands\naddBands\n(\n(\nelevationScaled\nelevationScaled\n)\n)\n  \n  \n.\n.\naddBands\naddBands\n(\n(\ntempScaled\ntempScaled\n)\n)\n;\n;\nprint\nprint\n(\n(\n'Composite bands:'\n'Composite bands:'\n,\n,\n composite\n composite\n.\n.\nbandNames\nbandNames\n(\n(\n)\n)\n)\n)\n;\n;\n\nExercise 3: Spatial Cross-Validation (20 min)\nStep 3: Hold-out validation\njavascript\n// Prepare training data\n// Prepare training data\nvar\nvar\n training \n training \n=\n=\n composite\n composite\n.\n.\nsample\nsample\n(\n(\n{\n{\n  \n  \nregion\nregion\n:\n:\n uganda\n uganda\n,\n,\n  \n  \nscale\nscale\n:\n:\n \n \n1000\n1000\n,\n,\n  \n  \nnumPixels\nnumPixels\n:\n:\n \n \n5000\n5000\n}\n}\n)\n)\n;\n;\n// Instantiate clusterer and train\n// Instantiate clusterer and train\nvar\nvar\n clusterer \n clusterer \n=\n=\n ee\n ee\n.\n.\nClusterer\nClusterer\n.\n.\nwekaKMeans\nwekaKMeans\n(\n(\n{\n{\n  \n  \nnClusters\nnClusters\n:\n:\n \n \n5\n5\n,\n,\n  \n  \nseed\nseed\n:\n:\n \n \n42\n42\n  \n  \n// For reproducibility\n// For reproducibility\n}\n}\n)\n)\n.\n.\ntrain\ntrain\n(\n(\ntraining\ntraining\n)\n)\n;\n;\n// Apply clusterer\n// Apply clusterer\nvar\nvar\n clustered \n clustered \n=\n=\n composite\n composite\n.\n.\ncluster\ncluster\n(\n(\nclusterer\nclusterer\n)\n)\n;\n;\n// Assign risk levels based on cluster characteristics\n// Assign risk levels based on cluster characteristics\nvar\nvar\n clusterMeans \n clusterMeans \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\nee\nee\n.\n.\nList\nList\n.\n.\nsequence\nsequence\n(\n(\n0\n0\n,\n,\n \n \n4\n4\n)\n)\n.\n.\nmap\nmap\n(\n(\nfunction\nfunction\n(\n(\ni\ni\n)\n)\n \n \n{\n{\n  \n  \nvar\nvar\n cluster \n cluster \n=\n=\n clustered\n clustered\n.\n.\nupdateMask\nupdateMask\n(\n(\nclustered\nclustered\n.\n.\neq\neq\n(\n(\ni\ni\n)\n)\n)\n)\n;\n;\n  \n  \nvar\nvar\n means \n means \n=\n=\n composite\n composite\n.\n.\nupdateMask\nupdateMask\n(\n(\ncluster\ncluster\n)\n)\n.\n.\nreduceRegion\nreduceRegion\n(\n(\n{\n{\n    \n    \nreducer\nreducer\n:\n:\n ee\n ee\n.\n.\nReducer\nReducer\n.\n.\nmean\nmean\n(\n(\n)\n)\n,\n,\n    \n    \ngeometry\ngeometry\n:\n:\n uganda\n uganda\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n,\n,\n    \n    \nscale\nscale\n:\n:\n \n \n5000\n5000\n,\n,\n    \n    \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e9\n1e9\n  \n  \n}\n}\n)\n)\n;\n;\n  \n  \n  \n  \nreturn\nreturn\n ee\n ee\n.\n.\nFeature\nFeature\n(\n(\nnull\nnull\n,\n,\n means\n means\n)\n)\n.\n.\nset\nset\n(\n(\n'cluster'\n'cluster'\n,\n,\n i\n i\n)\n)\n;\n;\n}\n}\n)\n)\n)\n)\n;\n;\nprint\nprint\n(\n(\n'Cluster characteristics:'\n'Cluster characteristics:'\n,\n,\n clusterMeans\n clusterMeans\n)\n)\n;\n;\n// Remap clusters to risk levels (0=lowest, 4=highest)\n// Remap clusters to risk levels (0=lowest, 4=highest)\n// This should be adjusted based on domain knowledge\n// This should be adjusted based on domain knowledge\nvar\nvar\n riskLevels \n riskLevels \n=\n=\n clustered\n clustered\n.\n.\nremap\nremap\n(\n(\n[\n[\n0\n0\n,\n,\n \n \n1\n1\n,\n,\n \n \n2\n2\n,\n,\n \n \n3\n3\n,\n,\n \n \n4\n4\n]\n]\n,\n,\n \n \n[\n[\n2\n2\n,\n,\n \n \n4\n4\n,\n,\n \n \n1\n1\n,\n,\n \n \n3\n3\n,\n,\n \n \n0\n0\n]\n]\n)\n)\n;\n;\n// Visualize with health-appropriate colors\n// Visualize with health-appropriate colors\nvar\nvar\n riskPalette \n riskPalette \n=\n=\n \n \n[\n[\n'2166AC'\n'2166AC'\n,\n,\n \n \n'67A9CF'\n'67A9CF'\n,\n,\n \n \n'F7F7F7'\n'F7F7F7'\n,\n,\n \n \n'FDDBC7'\n'FDDBC7'\n,\n,\n \n \n'B2182B'\n'B2182B'\n]\n]\n;\n;\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\nriskLevels\nriskLevels\n,\n,\n \n \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n4\n4\n,\n,\n \n \npalette\npalette\n:\n:\n riskPalette\n riskPalette\n}\n}\n,\n,\n \n \n'Malaria Risk Levels'\n'Malaria Risk Levels'\n)\n)\n;\n;\n\nExercise 4: Validate Against \"Ground Truth\" (20 min)\nStep 4: Load and compare with malaria prevalence data\njavascript\n// Define hold-out region (e.g., Northern Uganda)\n// Define hold-out region (e.g., Northern Uganda)\nvar\nvar\n northernRegion \n northernRegion \n=\n=\n ee\n ee\n.\n.\nFeatureCollection\nFeatureCollection\n(\n(\n'UCSB-CHG/GADM/gadm36_1'\n'UCSB-CHG/GADM/gadm36_1'\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_0'\n'NAME_0'\n,\n,\n \n \n'Uganda'\n'Uganda'\n)\n)\n)\n)\n  \n  \n.\n.\nfilter\nfilter\n(\n(\nee\nee\n.\n.\nFilter\nFilter\n.\n.\neq\neq\n(\n(\n'NAME_1'\n'NAME_1'\n,\n,\n \n \n'Northern'\n'Northern'\n)\n)\n)\n)\n;\n;\nvar\nvar\n trainingRegion \n trainingRegion \n=\n=\n uganda\n uganda\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n.\n.\ndifference\ndifference\n(\n(\nnorthernRegion\nnorthernRegion\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n)\n)\n;\n;\n// Retrain on subset\n// Retrain on subset\nvar\nvar\n trainingSubset \n trainingSubset \n=\n=\n composite\n composite\n.\n.\nsample\nsample\n(\n(\n{\n{\n  \n  \nregion\nregion\n:\n:\n trainingRegion\n trainingRegion\n,\n,\n  \n  \nscale\nscale\n:\n:\n \n \n1000\n1000\n,\n,\n  \n  \nnumPixels\nnumPixels\n:\n:\n \n \n5000\n5000\n}\n}\n)\n)\n;\n;\nvar\nvar\n clustererSubset \n clustererSubset \n=\n=\n ee\n ee\n.\n.\nClusterer\nClusterer\n.\n.\nwekaKMeans\nwekaKMeans\n(\n(\n{\n{\n  \n  \nnClusters\nnClusters\n:\n:\n \n \n5\n5\n,\n,\n  \n  \nseed\nseed\n:\n:\n \n \n42\n42\n}\n}\n)\n)\n.\n.\ntrain\ntrain\n(\n(\ntrainingSubset\ntrainingSubset\n)\n)\n;\n;\n// Apply to full area\n// Apply to full area\nvar\nvar\n clusteredValidation \n clusteredValidation \n=\n=\n composite\n composite\n.\n.\ncluster\ncluster\n(\n(\nclustererSubset\nclustererSubset\n)\n)\n;\n;\n// Compare clusters in hold-out region\n// Compare clusters in hold-out region\nvar\nvar\n comparisonMap \n comparisonMap \n=\n=\n clustered\n clustered\n.\n.\naddBands\naddBands\n(\n(\nclusteredValidation\nclusteredValidation\n)\n)\n  \n  \n.\n.\nselect\nselect\n(\n(\n[\n[\n'cluster'\n'cluster'\n,\n,\n \n \n'cluster_1'\n'cluster_1'\n]\n]\n,\n,\n \n \n[\n[\n'original'\n'original'\n,\n,\n \n \n'validated'\n'validated'\n]\n]\n)\n)\n;\n;\nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\ncomparisonMap\ncomparisonMap\n.\n.\nselect\nselect\n(\n(\n'original'\n'original'\n)\n)\n.\n.\nclip\nclip\n(\n(\nnorthernRegion\nnorthernRegion\n)\n)\n,\n,\n \n \n  \n  \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n4\n4\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'red'\n'red'\n,\n,\n \n \n'orange'\n'orange'\n,\n,\n \n \n'yellow'\n'yellow'\n,\n,\n \n \n'lightgreen'\n'lightgreen'\n,\n,\n \n \n'darkgreen'\n'darkgreen'\n]\n]\n}\n}\n,\n,\n \n \n  \n  \n'Original Clusters - North'\n'Original Clusters - North'\n)\n)\n;\n;\n  \n  \nMap\nMap\n.\n.\naddLayer\naddLayer\n(\n(\ncomparisonMap\ncomparisonMap\n.\n.\nselect\nselect\n(\n(\n'validated'\n'validated'\n)\n)\n.\n.\nclip\nclip\n(\n(\nnorthernRegion\nnorthernRegion\n)\n)\n,\n,\n \n \n  \n  \n{\n{\nmin\nmin\n:\n:\n \n \n0\n0\n,\n,\n \n \nmax\nmax\n:\n:\n \n \n4\n4\n,\n,\n \n \npalette\npalette\n:\n:\n \n \n[\n[\n'red'\n'red'\n,\n,\n \n \n'orange'\n'orange'\n,\n,\n \n \n'yellow'\n'yellow'\n,\n,\n \n \n'lightgreen'\n'lightgreen'\n,\n,\n \n \n'darkgreen'\n'darkgreen'\n]\n]\n}\n}\n,\n,\n \n \n  \n  \n'Validated Clusters - North'\n'Validated Clusters - North'\n)\n)\n;\n;\n\nWrap-up Sheet (10 min)\nTeams complete this summary:\njavascript\n// Simulated malaria prevalence data (in practice, use real data)\n// Simulated malaria prevalence data (in practice, use real data)\n// For workshop, create synthetic data based on environmental conditions\n// For workshop, create synthetic data based on environmental conditions\nvar\nvar\n \n \ncreateSyntheticPrevalence\ncreateSyntheticPrevalence\n \n \n=\n=\n \n \nfunction\nfunction\n(\n(\n)\n)\n \n \n{\n{\n  \n  \n// Higher risk where NDVI is moderate and rainfall is high\n// Higher risk where NDVI is moderate and rainfall is high\n  \n  \nvar\nvar\n prevalence \n prevalence \n=\n=\n ndvi\n ndvi\n.\n.\nmultiply\nmultiply\n(\n(\n2\n2\n)\n)\n    \n    \n.\n.\nadd\nadd\n(\n(\nrainfall\nrainfall\n.\n.\ndivide\ndivide\n(\n(\n1000\n1000\n)\n)\n)\n)\n    \n    \n.\n.\nadd\nadd\n(\n(\nelevation\nelevation\n.\n.\ndivide\ndivide\n(\n(\n-\n-\n2000\n2000\n)\n)\n)\n)\n  \n  \n// Lower elevation = higher risk\n// Lower elevation = higher risk\n    \n    \n.\n.\nadd\nadd\n(\n(\ntemperature\ntemperature\n.\n.\nmultiply\nmultiply\n(\n(\n-\n-\n0.05\n0.05\n)\n)\n)\n)\n  \n  \n// Optimal temp around 25°C\n// Optimal temp around 25°C\n    \n    \n.\n.\nunitScale\nunitScale\n(\n(\n0\n0\n,\n,\n \n \n3\n3\n)\n)\n  \n  \n// Scale to 0-1\n// Scale to 0-1\n    \n    \n.\n.\nrename\nrename\n(\n(\n'prevalence'\n'prevalence'\n)\n)\n;\n;\n  \n  \n  \n  \nreturn\nreturn\n prevalence\n prevalence\n;\n;\n}\n}\n;\n;\nvar\nvar\n malariaPrevalence \n malariaPrevalence \n=\n=\n \n \ncreateSyntheticPrevalence\ncreateSyntheticPrevalence\n(\n(\n)\n)\n;\n;\n// Sample prevalence at cluster centroids\n// Sample prevalence at cluster centroids\nvar\nvar\n validation \n validation \n=\n=\n clustered\n clustered\n.\n.\naddBands\naddBands\n(\n(\nmalariaPrevalence\nmalariaPrevalence\n)\n)\n  \n  \n.\n.\nstratifiedSample\nstratifiedSample\n(\n(\n{\n{\n    \n    \nnumPoints\nnumPoints\n:\n:\n \n \n100\n100\n,\n,\n    \n    \nclassBand\nclassBand\n:\n:\n \n \n'cluster'\n'cluster'\n,\n,\n    \n    \nregion\nregion\n:\n:\n uganda\n uganda\n,\n,\n    \n    \nscale\nscale\n:\n:\n \n \n1000\n1000\n  \n  \n}\n}\n)\n)\n;\n;\n// Create scatter plot\n// Create scatter plot\nvar\nvar\n chart \n chart \n=\n=\n ui\n ui\n.\n.\nChart\nChart\n.\n.\nfeature\nfeature\n.\n.\nbyFeature\nbyFeature\n(\n(\nvalidation\nvalidation\n,\n,\n \n \n'cluster'\n'cluster'\n,\n,\n \n \n'prevalence'\n'prevalence'\n)\n)\n  \n  \n.\n.\nsetChartType\nsetChartType\n(\n(\n'ColumnChart'\n'ColumnChart'\n)\n)\n  \n  \n.\n.\nsetOptions\nsetOptions\n(\n(\n{\n{\n    \n    \ntitle\ntitle\n:\n:\n \n \n'Mean Malaria Prevalence by Risk Cluster'\n'Mean Malaria Prevalence by Risk Cluster'\n,\n,\n    \n    \nhAxis\nhAxis\n:\n:\n \n \n{\n{\ntitle\ntitle\n:\n:\n \n \n'Cluster ID'\n'Cluster ID'\n}\n}\n,\n,\n    \n    \nvAxis\nvAxis\n:\n:\n \n \n{\n{\ntitle\ntitle\n:\n:\n \n \n'Prevalence'\n'Prevalence'\n}\n}\n,\n,\n    \n    \ncolors\ncolors\n:\n:\n riskPalette\n riskPalette\n  \n  \n}\n}\n)\n)\n;\n;\nprint\nprint\n(\n(\nchart\nchart\n)\n)\n;\n;\n\nExport Bridge: Storyboard Documentation (14:30-15:30)\nAuto-generate Documentation with ChatGPT\nPrompt for participants: \"Generate a markdown header for my GEE script that documents:\n1. Data sources with citations\n2. Processing steps\n3. Assumptions and limitations\n4. Export parameters\"\nExpected output:\nmarkdown\n#\n#\n Cluster Analysis Summary\n Cluster Analysis Summary\nTeam Members: _______________________\nTeam Members: _______________________\n##\n##\n Cluster Characteristics\n Cluster Characteristics\n|\n|\n Cluster \n Cluster \n|\n|\n NDVI \n NDVI \n|\n|\n Rainfall \n Rainfall \n|\n|\n Elevation \n Elevation \n|\n|\n Temperature \n Temperature \n|\n|\n Assigned Risk \n Assigned Risk \n|\n|\n|\n|\n---------\n---------\n|\n|\n------\n------\n|\n|\n----------\n----------\n|\n|\n-----------\n-----------\n|\n|\n-------------\n-------------\n|\n|\n---------------\n---------------\n|\n|\n|\n|\n 0       \n 0       \n|\n|\n      \n      \n|\n|\n          \n          \n|\n|\n           \n           \n|\n|\n             \n             \n|\n|\n               \n               \n|\n|\n|\n|\n 1       \n 1       \n|\n|\n      \n      \n|\n|\n          \n          \n|\n|\n           \n           \n|\n|\n             \n             \n|\n|\n               \n               \n|\n|\n|\n|\n 2       \n 2       \n|\n|\n      \n      \n|\n|\n          \n          \n|\n|\n           \n           \n|\n|\n             \n             \n|\n|\n               \n               \n|\n|\n|\n|\n 3       \n 3       \n|\n|\n      \n      \n|\n|\n          \n          \n|\n|\n           \n           \n|\n|\n             \n             \n|\n|\n               \n               \n|\n|\n|\n|\n 4       \n 4       \n|\n|\n      \n      \n|\n|\n          \n          \n|\n|\n           \n           \n|\n|\n             \n             \n|\n|\n               \n               \n|\n|\n##\n##\n Interpretation\n Interpretation\nHighest risk areas are characterized by: _______________________\nHighest risk areas are characterized by: _______________________\nLowest risk areas are characterized by: ________________________\nLowest risk areas are characterized by: ________________________\n##\n##\n Validation Results\n Validation Results\nCorrelation with prevalence data: _____________________________\nCorrelation with prevalence data: _____________________________\nSpatial stability (North vs. South): __________________________\nSpatial stability (North vs. South): __________________________\n\nFinal Export Code\njavascript\n/**\n/**\n * MALARIA RISK MAPPING - UGANDA\n * MALARIA RISK MAPPING - UGANDA\n * ==============================\n * ==============================\n * \n * \n * DATA SOURCES:\n * DATA SOURCES:\n * - MODIS NDVI (MOD13Q1): Didan, K. (2015). MOD13Q1 MODIS/Terra Vegetation Indices \n * - MODIS NDVI (MOD13Q1): Didan, K. (2015). MOD13Q1 MODIS/Terra Vegetation Indices \n *   16-Day L3 Global 250m SIN Grid V006. NASA EOSDIS Land Processes DAAC.\n *   16-Day L3 Global 250m SIN Grid V006. NASA EOSDIS Land Processes DAAC.\n * - CHIRPS Rainfall: Funk, et al. (2015). The climate hazards infrared precipitation \n * - CHIRPS Rainfall: Funk, et al. (2015). The climate hazards infrared precipitation \n *   with stations—a new environmental record for monitoring extremes. Scientific Data.\n *   with stations—a new environmental record for monitoring extremes. Scientific Data.\n * - SRTM Elevation: Farr, T.G., et al. (2007). The Shuttle Radar Topography Mission. \n * - SRTM Elevation: Farr, T.G., et al. (2007). The Shuttle Radar Topography Mission. \n *   Rev. Geophys., 45, RG2004.\n *   Rev. Geophys., 45, RG2004.\n * \n * \n * PROCESSING CHAIN:\n * PROCESSING CHAIN:\n * 1. Load environmental variables (NDVI, rainfall, elevation, temperature)\n * 1. Load environmental variables (NDVI, rainfall, elevation, temperature)\n * 2. Apply min-max scaling to standardize inputs\n * 2. Apply min-max scaling to standardize inputs\n * 3. Create multi-band composite\n * 3. Create multi-band composite\n * 4. Apply k-means clustering (k=5)\n * 4. Apply k-means clustering (k=5)\n * 5. Assign risk levels based on cluster characteristics\n * 5. Assign risk levels based on cluster characteristics\n * 6. Validate against synthetic prevalence data\n * 6. Validate against synthetic prevalence data\n * \n * \n * ASSUMPTIONS:\n * ASSUMPTIONS:\n * - Environmental conditions are primary drivers of malaria risk\n * - Environmental conditions are primary drivers of malaria risk\n * - 3-month average represents typical seasonal conditions\n * - 3-month average represents typical seasonal conditions\n * - Linear scaling preserves relative relationships\n * - Linear scaling preserves relative relationships\n * \n * \n * LIMITATIONS:\n * LIMITATIONS:\n * - Does not account for human factors (population density, interventions)\n * - Does not account for human factors (population density, interventions)\n * - Cluster assignments may vary with different initial conditions\n * - Cluster assignments may vary with different initial conditions\n * - Validation uses synthetic data for workshop purposes\n * - Validation uses synthetic data for workshop purposes\n * \n * \n * EXPORT:\n * EXPORT:\n * - Format: GeoTIFF\n * - Format: GeoTIFF\n * - Resolution: 250m\n * - Resolution: 250m\n * - Projection: EPSG:4326\n * - Projection: EPSG:4326\n * - Bands: risk_level (0-4, where 4 is highest risk)\n * - Bands: risk_level (0-4, where 4 is highest risk)\n */\n */\n// Main script starts here...\n// Main script starts here...\n\nOptional Stretch Tasks\n1. Auto-generate Interactive Leaflet Map\nChatGPT Prompt: \"Convert this GEE export URL to a Leaflet web map with popup showing risk level\"\nExpected HTML:\njavascript\n// Export risk map\n// Export risk map\nExport\nExport\n.\n.\nimage\nimage\n.\n.\ntoDrive\ntoDrive\n(\n(\n{\n{\n  \n  \nimage\nimage\n:\n:\n riskLevels\n riskLevels\n.\n.\nbyte\nbyte\n(\n(\n)\n)\n,\n,\n  \n  \n// Convert to byte for smaller file size\n// Convert to byte for smaller file size\n  \n  \ndescription\ndescription\n:\n:\n \n \n'Uganda_Malaria_Risk_Map_'\n'Uganda_Malaria_Risk_Map_'\n \n \n+\n+\n ee\n ee\n.\n.\nDate\nDate\n(\n(\nDate\nDate\n.\n.\nnow\nnow\n(\n(\n)\n)\n)\n)\n.\n.\nformat\nformat\n(\n(\n'YYYY_MM_dd'\n'YYYY_MM_dd'\n)\n)\n.\n.\ngetInfo\ngetInfo\n(\n(\n)\n)\n,\n,\n  \n  \nfolder\nfolder\n:\n:\n \n \n'GEE_Workshop'\n'GEE_Workshop'\n,\n,\n  \n  \nregion\nregion\n:\n:\n uganda\n uganda\n.\n.\ngeometry\ngeometry\n(\n(\n)\n)\n.\n.\nbounds\nbounds\n(\n(\n)\n)\n,\n,\n  \n  \nscale\nscale\n:\n:\n \n \n250\n250\n,\n,\n  \n  \ncrs\ncrs\n:\n:\n \n \n'EPSG:4326'\n'EPSG:4326'\n,\n,\n  \n  \nmaxPixels\nmaxPixels\n:\n:\n \n \n1e13\n1e13\n}\n}\n)\n)\n;\n;\n// Export cluster statistics\n// Export cluster statistics\nExport\nExport\n.\n.\ntable\ntable\n.\n.\ntoDrive\ntoDrive\n(\n(\n{\n{\n  \n  \ncollection\ncollection\n:\n:\n clusterMeans\n clusterMeans\n,\n,\n  \n  \ndescription\ndescription\n:\n:\n \n \n'Cluster_Statistics'\n'Cluster_Statistics'\n,\n,\n  \n  \nfileFormat\nfileFormat\n:\n:\n \n \n'CSV'\n'CSV'\n}\n}\n)\n)\n;\n;\n// Export validation points\n// Export validation points\nExport\nExport\n.\n.\ntable\ntable\n.\n.\ntoDrive\ntoDrive\n(\n(\n{\n{\n  \n  \ncollection\ncollection\n:\n:\n validation\n validation\n,\n,\n  \n  \ndescription\ndescription\n:\n:\n \n \n'Validation_Points'\n'Validation_Points'\n,\n,\n  \n  \nfileFormat\nfileFormat\n:\n:\n \n \n'CSV'\n'CSV'\n,\n,\n  \n  \nselectors\nselectors\n:\n:\n \n \n[\n[\n'cluster'\n'cluster'\n,\n,\n \n \n'prevalence'\n'prevalence'\n,\n,\n \n \n'.geo'\n'.geo'\n]\n]\n}\n}\n)\n)\n;\n;\n\nhtml\n\n<!\n<!\nDOCTYPE\nDOCTYPE\n \n \nhtml\nhtml\n>\n>\n<\n<\nhtml\nhtml\n>\n>\n<\n<\nhead\nhead\n>\n>\n  \n  \n<\n<\ntitle\ntitle\n>\n>\nUganda Malaria Risk Map\nUganda Malaria Risk Map\n</\n</\ntitle\ntitle\n>\n>\n  \n  \n<\n<\nlink\nlink\n \n \nrel\nrel\n=\n=\n\"\n\"\nstylesheet\nstylesheet\n\"\n\"\n \n \nhref\nhref\n=\n=\n\"\n\"\nhttps://unpkg.com/leaflet@1.7.1/dist/leaflet.css\nhttps://unpkg.com/leaflet@1.7.1/dist/leaflet.css\n\"\n\"\n \n \n/>\n/>\n  \n  \n<\n<\nscript\nscript\n \n \nsrc\nsrc\n=\n=\n\"\n\"\nhttps://unpkg.com/leaflet@1.7.1/dist/leaflet.js\nhttps://unpkg.com/leaflet@1.7.1/dist/leaflet.js\n\"\n\"\n>\n>\n</\n</\nscript\nscript\n>\n>\n  \n  \n<\n<\nscript\nscript\n \n \nsrc\nsrc\n=\n=\n\"\n\"\nhttps://unpkg.com/georaster\nhttps://unpkg.com/georaster\n\"\n\"\n>\n>\n</\n</\nscript\nscript\n>\n>\n  \n  \n<\n<\nscript\nscript\n \n \nsrc\nsrc\n=\n=\n\"\n\"\nhttps://unpkg.com/georaster-layer-for-leaflet\nhttps://unpkg.com/georaster-layer-for-leaflet\n\"\n\"\n>\n>\n</\n</\nscript\nscript\n>\n>\n  \n  \n<\n<\nstyle\nstyle\n>\n>\n    \n    \n#map\n#map\n \n \n{\n{\n \n \nheight\nheight\n:\n:\n \n \n600\n600\npx\npx\n;\n;\n \n \n}\n}\n    \n    \n.legend\n.legend\n \n \n{\n{\n      \n      \nbackground\nbackground\n:\n:\n \n \nwhite\nwhite\n;\n;\n      \n      \npadding\npadding\n:\n:\n \n \n10\n10\npx\npx\n;\n;\n      \n      \nborder-radius\nborder-radius\n:\n:\n \n \n5\n5\npx\npx\n;\n;\n      \n      \nbox-shadow\nbox-shadow\n:\n:\n \n \n0\n0\n \n \n1\n1\npx\npx\n \n \n5\n5\npx\npx\n \n \nrgba\nrgba\n(\n(\n0\n0\n,\n,\n0\n0\n,\n,\n0\n0\n,\n,\n0.4\n0.4\n)\n)\n;\n;\n    \n    \n}\n}\n  \n  \n</\n</\nstyle\nstyle\n>\n>\n</\n</\nhead\nhead\n>\n>\n<\n<\nbody\nbody\n>\n>\n  \n  \n<\n<\ndiv\ndiv\n \n \nid\nid\n=\n=\n\"\n\"\nmap\nmap\n\"\n\"\n>\n>\n</\n</\ndiv\ndiv\n>\n>\n  \n  \n<\n<\nscript\nscript\n>\n>\n    \n    \n// Initialize map\n// Initialize map\n    \n    \nvar\nvar\n map \n map \n=\n=\n \n \nL\nL\n.\n.\nmap\nmap\n(\n(\n'map'\n'map'\n)\n)\n.\n.\nsetView\nsetView\n(\n(\n[\n[\n1.373333\n1.373333\n,\n,\n \n \n32.290275\n32.290275\n]\n]\n,\n,\n \n \n7\n7\n)\n)\n;\n;\n    \n    \n    \n    \n// Add base layer\n// Add base layer\n    \n    \nL\nL\n.\n.\ntileLayer\ntileLayer\n(\n(\n'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png'\n'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png'\n,\n,\n \n \n{\n{\n      \n      \nattribution\nattribution\n:\n:\n \n \n'© OpenStreetMap contributors'\n'© OpenStreetMap contributors'\n    \n    \n}\n}\n)\n)\n.\n.\naddTo\naddTo\n(\n(\nmap\nmap\n)\n)\n;\n;\n    \n    \n    \n    \n// Load GeoTIFF (participants add their export URL)\n// Load GeoTIFF (participants add their export URL)\n    \n    \nfetch\nfetch\n(\n(\n'YOUR_GEOTIFF_URL'\n'YOUR_GEOTIFF_URL'\n)\n)\n      \n      \n.\n.\nthen\nthen\n(\n(\nresponse\nresponse\n \n \n=>\n=>\n response\n response\n.\n.\narrayBuffer\narrayBuffer\n(\n(\n)\n)\n)\n)\n      \n      \n.\n.\nthen\nthen\n(\n(\narrayBuffer\narrayBuffer\n \n \n=>\n=>\n \n \n{\n{\n        \n        \nparseGeoraster\nparseGeoraster\n(\n(\narrayBuffer\narrayBuffer\n)\n)\n.\n.\nthen\nthen\n(\n(\ngeoraster\ngeoraster\n \n \n=>\n=>\n \n \n{\n{\n          \n          \nconst\nconst\n layer \n layer \n=\n=\n \n \nnew\nnew\n \n \nGeoRasterLayer\nGeoRasterLayer\n(\n(\n{\n{\n            \n            \ngeoraster\ngeoraster\n:\n:\n georaster\n georaster\n,\n,\n            \n            \nopacity\nopacity\n:\n:\n \n \n0.7\n0.7\n,\n,\n            \n            \npixelValuesToColorFn\npixelValuesToColorFn\n:\n:\n \n \nvalues\nvalues\n \n \n=>\n=>\n \n \n{\n{\n              \n              \nconst\nconst\n riskColors \n riskColors \n=\n=\n \n \n[\n[\n'#2166AC'\n'#2166AC'\n,\n,\n \n \n'#67A9CF'\n'#67A9CF'\n,\n,\n \n \n'#F7F7F7'\n'#F7F7F7'\n,\n,\n \n \n'#FDDBC7'\n'#FDDBC7'\n,\n,\n \n \n'#B2182B'\n'#B2182B'\n]\n]\n;\n;\n              \n              \nconst\nconst\n value \n value \n=\n=\n values\n values\n[\n[\n0\n0\n]\n]\n;\n;\n              \n              \nreturn\nreturn\n value \n value \n>=\n>=\n \n \n0\n0\n \n \n&&\n&&\n value \n value \n<=\n<=\n \n \n4\n4\n \n \n?\n?\n riskColors\n riskColors\n[\n[\nvalue\nvalue\n]\n]\n \n \n:\n:\n \n \nnull\nnull\n;\n;\n            \n            \n}\n}\n,\n,\n            \n            \nresolution\nresolution\n:\n:\n \n \n256\n256\n\nInstructor Notes\nCommon Issues and Solutions\n1. GEE Computation Timeout\nSolution: Reduce scale parameter, use bestEffort: true, or batch by region\n2. ChatGPT Rate Limits\nSolution: Have participants work in pairs, prepare backup responses\n3. Visualization Not Showing\nSolution: Check geometry bounds, ensure clipping is applied\n4. Export Taking Too Long\nSolution: Reduce resolution or export smaller regions\nAssessment Rubric\n          \n          \n}\n}\n)\n)\n;\n;\n          layer\n          layer\n.\n.\naddTo\naddTo\n(\n(\nmap\nmap\n)\n)\n;\n;\n          map\n          map\n.\n.\nfitBounds\nfitBounds\n(\n(\nlayer\nlayer\n.\n.\ngetBounds\ngetBounds\n(\n(\n)\n)\n)\n)\n;\n;\n        \n        \n}\n}\n)\n)\n;\n;\n      \n      \n}\n}\n)\n)\n;\n;\n    \n    \n    \n    \n// Add legend\n// Add legend\n    \n    \nvar\nvar\n legend \n legend \n=\n=\n \n \nL\nL\n.\n.\ncontrol\ncontrol\n(\n(\n{\n{\nposition\nposition\n:\n:\n \n \n'bottomright'\n'bottomright'\n}\n}\n)\n)\n;\n;\n    legend\n    legend\n.\n.\nonAdd\nonAdd\n \n \n=\n=\n \n \nfunction\nfunction\n(\n(\nmap\nmap\n)\n)\n \n \n{\n{\n      \n      \nvar\nvar\n div \n div \n=\n=\n \n \nL\nL\n.\n.\nDomUtil\nDomUtil\n.\n.\ncreate\ncreate\n(\n(\n'div'\n'div'\n,\n,\n \n \n'legend'\n'legend'\n)\n)\n;\n;\n      div\n      div\n.\n.\ninnerHTML\ninnerHTML\n \n \n=\n=\n \n \n'<h4>Malaria Risk</h4>'\n'<h4>Malaria Risk</h4>'\n \n \n+\n+\n        \n        \n'<i style=\"background: #B2182B\"></i> Very High<br>'\n'<i style=\"background: #B2182B\"></i> Very High<br>'\n \n \n+\n+\n        \n        \n'<i style=\"background: #FDDBC7\"></i> High<br>'\n'<i style=\"background: #FDDBC7\"></i> High<br>'\n \n \n+\n+\n        \n        \n'<i style=\"background: #F7F7F7\"></i> Moderate<br>'\n'<i style=\"background: #F7F7F7\"></i> Moderate<br>'\n \n \n+\n+\n        \n        \n'<i style=\"background: #67A9CF\"></i> Low<br>'\n'<i style=\"background: #67A9CF\"></i> Low<br>'\n \n \n+\n+\n        \n        \n'<i style=\"background: #2166AC\"></i> Very Low'\n'<i style=\"background: #2166AC\"></i> Very Low'\n;\n;\n      \n      \nreturn\nreturn\n div\n div\n;\n;\n    \n    \n}\n}\n;\n;\n    legend\n    legend\n.\n.\naddTo\naddTo\n(\n(\nmap\nmap\n)\n)\n;\n;\n  \n  \n</\n</\nscript\nscript\n>\n>\n</\n</\nbody\nbody\n>\n>\n</\n</\nhtml\nhtml\n>\n>\n\nComponentExcellent (3)Good (2)\nNeeds Improvement\n(1)\nNDVI/Rainfall\nMap\nBoth layers properly scaled and\nvisualized\nOne layer has issuesMultiple errors\nChatGPT Usage\nEffective prompting, meaningful\niterations\nBasic promptingStruggled with prompts\nClusteringAll 5 clusters with clear interpretation\nClusters created but\nunclear\nFailed to complete\nDocumentationComplete storyboard with citationsPartial documentationMinimal documentation\nAdditional Resources\nGEE Datasets Catalog\nChatGPT Prompting Guide\nMalaria Atlas Project - For real prevalence data\n\n## Document Information\n- **Source**: PDF Document (28 pages)\n- **Category**: tutorial\n- **Difficulty**: beginner\n- **Relevant Labs**: lab1\n- **Topics**: buffer, clustering, crs, gee, gis, google earth engine, malaria, mapping, projection, qgis, raster\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain day 2: gee & ai workshop - instructor guide with code snippets\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- buffer\n- clustering\n- crs\n- gee\n- gis\n- google earth engine\n- malaria\n- mapping\n- projection\n- qgis\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "beginner",
      "lab": "lab1",
      "topics": [
        "buffer",
        "clustering",
        "crs",
        "gee",
        "gis",
        "google earth engine",
        "malaria",
        "mapping",
        "projection",
        "qgis",
        "raster"
      ],
      "source": "concepts\\day-2_-gee-&-ai-workshop---instructor-guide-with-code-snippets.md",
      "filename": "day-2_-gee-&-ai-workshop---instructor-guide-with-code-snippets.md"
    }
  },
  {
    "id": "concepts-day3_capstone_research_project_guide",
    "title": "Day 3: Capstone Research Project Guide - Independent GIS and AI-Assisted Spatial Health Analysis",
    "content": "\n# Day 3: Capstone Research Project Guide - Independent GIS and AI-Assisted Spatial Health Analysis\n\n\n\nDay 3: Capstone Research Project Guide\nResearch FrameworkSpatial AnalysisAI IntegrationProfessional Presentation\n\nWelcome to Your Capstone Research Project\nToday represents the culmination of your workshop experience.\nYou'll apply everything you've learned across the previous labs to\nconduct an independent research project that addresses real-\nworld public health challenges using cutting-edge geospatial\ntechnologies.\nProject Objectives\n• Apply scientific methodology to spatial health problems\n• Integrate QGIS, Google Earth Engine, and ChatGPT\neffectively\n• Develop professional research presentation skills\n• Create portfolio-worthy research outputs\nSpatial Analysis Workflow\n1. Research Project Framework\nScientific Method in Spatial HealthResearch Question Development\nStrong Research Questions:\n• Are spatially specific and measurable\n• Address public health significance\n• Can be answered with available data\n• Consider spatial scale appropriately\nExample Questions:\n• \"How does rainfall variation affect malaria prevalence across\nUgandan districts?\"\n• \"Which areas have high disease burden but poor facility\naccess?\"\n• \"What environmental conditions cluster together to create\ndisease risk?\"\n\nEthical Considerations in Health Research\nData Privacy\n• Use aggregated data only\n• Protect individual privacy\n• Follow data use agreements\nRepresentation\n• Avoid stigmatization\n• Present balanced findings\n• Consider social context\nInterpretation\n• Acknowledge limitations\n• Avoid causal overstatement\n• Consider alternative explanations\n2. Project Selection and Planning\n⛆\nProject 1: Malaria-Rainfall\nCorrelation\nObjective:\nAnalyze relationship between\nprecipitation patterns and malaria\nprevalence across Uganda\nKey Datasets:\nCHIRPS daily rainfall data\nDistrict malaria prevalence\nUganda administrative boundaries\nTools Required:\nGEEQGISChatGPT\n\nProject 2: Healthcare\nAccess Gaps\nObjective:\nIdentify high-burden areas with\ninadequate healthcare facility access\nKey Datasets:\nHealth facility coordinates\nDistrict health indicators\nPopulation density data\nTools Required:\nQGISGEEChatGPT\n\nProject 3: Environmental\nRisk Clustering\nObjective:\nUse machine learning to identify\nenvironmental risk zones for disease\ntransmission\nKey Datasets:\nMODIS NDVI time series\nCHIRPS precipitation\nElevation data (SRTM)\nTools Required:\nGEEChatGPTQGIS\nProject Design Template\n1. Project Title\n2. Research Question\n3. Hypothesis\n4. Required Datasets\n5. Main Tools\n6. Expected Output\n7. Intended Use\n8. Timeline & Milestones\n3. Technical Integration Workflow\n\nGoogle Earth Engine\n\nQGIS Desktop\n\nChatGPT Assistance\nData Management & Quality Control\nFile Organization\n Project_Name/\n 01_Data/\n raw_data.csv\n processed_data.gpkg\n 02_Scripts/\n gee_analysis.js\n qgis_project.qgs\n 03_Output/\n final_map.pdf\n results_table.csv\n 04_Documentation/\n methodology.md\n data_sources.txt\nQuality Control Checklist\nData sources documented with full citations\nCoordinate reference systems consistent\nProcessing steps recorded and reproducible\nIntermediate outputs validated\nError handling implemented\nResults cross-checked with alternative methods\nBackup copies created\n4. Research Methodology\nSpatial Analysis Design Principles\nScale Considerations\n• Match analysis scale to research question\n• Consider ecological fallacy risks\n• Account for modifiable areal unit problem\nTemporal Considerations\n• Align temporal scales of different datasets\n• Consider lag effects and seasonality\n• Account for data collection timing\nSpatial Dependencies\n• Test for spatial autocorrelation\n• Consider spatial spillover effects\n• Account for boundary effects\nStatistical Approaches\nDescriptive Analysis\n• Calculate summary statistics by region\n• Create distribution maps and histograms\n• Identify outliers and data quality issues\nCorrelation Analysis\n• Pearson/Spearman correlation coefficients\n• Scatter plots with spatial context\n• Consider non-linear relationships\nSpatial Statistics\n• Moran's I for spatial autocorrelation\n• Local indicators of spatial association\n• Hot spot analysis (Getis-Ord)\n\nValidation & Uncertainty Assessment\nData Validation\n• Cross-reference with ground truth data\n• Compare with published literature\n• Check for consistency across sources\n• Assess data completeness and coverage\nMethod Validation\n• Test alternative analytical approaches\n• Sensitivity analysis on parameters\n• Cross-validation techniques\n• Bootstrap confidence intervals\nUncertainty Quantification\n• Document data limitations\n• Propagate measurement errors\n• Report confidence intervals\n• Discuss interpretation caveats\nLiterature Review & Background Research\nKey Search Strategies\nAcademic Databases:\nPubMed, Web of Science, Google Scholar, PLoS ONE\nSearch Terms:\n\"spatial epidemiology\", \"disease mapping\", \"GIS health\", \"remote\nsensing malaria\"\nGrey Literature:\nWHO reports, government health statistics, NGO publications\nCritical Evaluation Framework\nStudy design appropriate for research question\nSample size and geographic scope adequate\nData sources clearly documented\nAnalytical methods properly described\nLimitations and biases acknowledged\nResults relevant to your context\n5. Implementation Guidelines\nStep-by-Step Technical Execution\n\nA. Google Earth Engine Workflow\n1. Environment Setup\n• Open https://code.earthengine.google.com/\n• Create new script with descriptive name\n• Define study area boundary\n2. Data Loading\n• Load required image collections\n• Apply date and spatial filters\n• Select relevant bands/variables\n3. Processing\n• Apply temporal reductions (mean, sum, median)\n• Clip to study area\n• Calculate zonal statistics if needed\n4. Visualization\n• Choose appropriate color palettes\n• Set min/max values for scaling\n• Add layers to map with descriptive names\n5. Export\n• Use Export.image.toDrive()\n• Set appropriate resolution and projection\n• Monitor task completion\n6. Quality Check\n• Verify export completed successfully\n• Check data ranges and distributions\n• Document any processing issues\n\nB. QGIS Desktop Workflow\n1. Project Setup\n• Create new project and save immediately\n• Set appropriate CRS for region\n• Organize layers in logical groups\n2. Data Import\n• Load vector data (shapefiles, GeoPackages)\n• Import raster data from GEE exports\n• Add CSV data as delimited text layers\n3. Data Integration\n• Join tables using common identifiers\n• Ensure data types are compatible\n• Handle missing or mismatched records\n4. Spatial Analysis\n• Perform buffer analysis for proximity\n• Use spatial selection tools\n• Calculate spatial statistics\n5. Visualization\n• Apply graduated symbology\n• Choose appropriate classification methods\n• Add labels and annotations\n6. Layout Design\n• Create print layout with map frame\n• Add legend, scale bar, north arrow\n• Export as PDF or high-resolution image\n\nC. AI-Assisted Problem Solving\nEffective ChatGPT Prompting for GIS Projects\nCode Generation Prompts:\n\"Write a GEE script to calculate annual mean NDVI for Uganda\nusing MODIS data\"\n\"Create QGIS Processing model for buffer analysis around health\nfacilities\"\n\"Generate Python script to export attribute table to CSV with\nspecific columns\"\nDebugging & Explanation:\n\"Explain this GEE error: 'Image.filter is not a function'\"\n\"Why is my QGIS join not working? Here's my data structure...\"\n\"How can I optimize this code for better performance?\"\n⚠\nCommon Integration Challenges & Solutions\nData Format Issues\nProblem: CRS mismatch between datasets\nSolution: Reproject all data to common CRS (e.g., WGS84)\nProblem: Table join fails\nSolution: Check field data types and clean text fields\nProblem: Large file export times out\nSolution: Reduce resolution or split into smaller regions\nAnalysis Errors\nProblem: Unexpected analysis results\nSolution: Validate with subset data and check calculations\nProblem: Missing data in results\nSolution: Check spatial and temporal filters\nProblem: Script runs slowly\nSolution: Optimize filters and reduce computational complexity\n6. Professional Presentation\nResearch Poster Design Principles\nLayout Structure\n• Title: Clear, descriptive, institution/author info\n• Introduction: Background, objectives, research questions\n• Methods: Data sources, analytical approach, tools used\n• Results: Key findings with maps and visualizations\n• Discussion: Interpretation, limitations, implications\n• Conclusion: Main takeaways and future directions\nVisual Design Guidelines\n• Use consistent fonts (max 3 different sizes)\n• Maintain white space for readability\n• Apply institution branding appropriately\n• Ensure text is readable from 3 feet away\nEffective Data Visualization\nMap Design\n• Choose appropriate classification method\n• Use colorblind-friendly color schemes\n• Include essential map elements (legend, scale, north arrow)\n• Ensure sufficient contrast for printing\nCharts & Graphs\n• Match chart type to data type and message\n• Label axes clearly with units\n• Highlight key patterns or outliers\n• Keep design simple and uncluttered\nColor Psychology\n• Red/Orange: High values, risk, heat\n• Blue: Water, cold, low values\n• Green: Vegetation, growth, positive\n• Gray: Neutral, no data, uncertainty\nStorytelling with Spatial Data\n1. Context Setting\nEstablish the public health\nproblem and why spatial\nanalysis matters\n2. Pattern Revelation\nShow spatial patterns clearly\nand guide viewer attention\n3. Insight Generation\nExplain what patterns mean\nand their implications\n4. Action Orientation\nConnect findings to concrete\nactions or recommendations\nPresentation Delivery Techniques\nPreparation\nPractice 2-minute elevator pitch\nPrepare for common questions\nTest all technology beforehand\nBring backup copies of materials\nDuring Presentation\nMaintain eye contact with audience\nUse pointer/gestures effectively\nSpeak clearly and at appropriate pace\nWelcome questions and interaction\nKey Messages\nState research question clearly\nHighlight novel findings\nAcknowledge limitations honestly\nConnect to broader implications\n7. Project Assessment\nEvaluation Criteria & Rubric\nCriteriaExcellent (4)Good (3)Satisfactory (2)\nNeeds Improvement\n(1)\nWeight\nResearch Question\nClear, specific, answerable,\nsignificant\nClear and answerableSomewhat clear\nVague or overly\nbroad\n20%\nTechnical\nImplementation\nSophisticated use of tools,\nerror-free\nCompetent use, minor\nerrors\nBasic use, some\nerrors\nLimited use, major\nerrors\n25%\nData Analysis\nAppropriate methods, well-\nexecuted\nMostly appropriateBasic analysis\nInappropriate or\nflawed\n20%\nVisualizationProfessional, clear, effectiveClear and readableBasic but functionalPoor or confusing15%\nInterpretation\nInsightful, well-supported\nconclusions\nSound interpretationBasic interpretation\nUnsupported or\nincorrect\n20%\nPeer Review Guidelines\nReview Structure\n• Summarize the project's main objective\n• Identify 2-3 strengths of the work\n• Suggest 2-3 areas for improvement\n• Provide constructive, specific feedback\nFocus Areas\n• Clarity of research question and methods\n• Appropriateness of analytical approach\n• Quality of visualizations and maps\n• Validity of conclusions drawn\nSelf-Reflection Framework\nLearning Assessment\n• What new skills did you develop?\n• What challenges did you overcome?\n• How did AI tools help your workflow?\n• What would you do differently next time?\nFuture Applications\n• How might you extend this analysis?\n• What additional data would be useful?\n• How could results inform policy?\n• What career opportunities connect to this work?\n\nBuilding Your Professional Portfolio\nTechnical Artifacts\nFinal project maps and visualizations\nCode scripts (GEE, Python, R)\nTechnical documentation\nData processing workflows\nCommunication Materials\nResearch poster or presentation\nProject summary/abstract\nVideo presentation (if created)\nBlog post or article draft\nReflection & Learning\nLearning reflection essay\nSkills inventory/checklist\nCertificate of completion\nFuture learning plan\n8. Real-World Applications\nPublic Health Practice Integration\nDisease Surveillance Systems\nYour skills directly apply to:\n• Real-time outbreak detection and monitoring\n• Environmental risk factor identification\n• Resource allocation optimization\n• Public health emergency response\nProgram Planning & Evaluation\nApplications include:\n• Intervention targeting and prioritization\n• Health facility planning and placement\n• Community health worker deployment\n• Program impact assessment\nPolicy & Decision Making\nEvidence-Based Policy\nYour analysis contributes to:\n• National health strategy development\n• Resource allocation decisions\n• Health system strengthening initiatives\n• International aid targeting\nStakeholder Communication\nSkills for engaging:\n• Government health officials\n• International development organizations\n• NGOs and community groups\n• Funding agencies and donors\nCareer Development Pathways\nPublic Health\n• Epidemiologist\n• Health Data Analyst\n• Disease Surveillance\nSpecialist\n• Health Program Manager\nData Science\n• Geospatial Data Scientist\n• Health Informatics Specialist\n• Research Analyst\n• Business Intelligence\nAnalyst\nAcademic Research\n• Graduate Student\n(MPH/PhD)\n• Research Assistant\n• Post-doctoral Researcher\n• Faculty Member\nConsulting\n• GIS Consultant\n• Health Systems Consultant\n• Environmental Health\nSpecialist\n• International Development\nAdvisor\nFuture Research & Technology Directions\nEmerging Technologies\nMachine Learning Integration:\nDeep learning for satellite image analysis,\nautomated disease prediction models\nReal-time Data Streams:\nSocial media health monitoring, mobile\nphone mobility data, IoT sensor networks\nData Integration\nMulti-source Fusion:\nCombining satellite, census, health, and\nsocial media data for comprehensive\nanalysis\nTemporal Dynamics:\nIncorporating climate change projections,\ndemographic transitions, urbanization\ntrends\nGlobal Health Applications\nClimate-Health Nexus:\nDisease risk under changing climate\nconditions, extreme weather health\nimpacts\nHealth Equity:\nMapping health disparities, social\ndeterminants, environmental justice\napplications\n\nProfessional Networking & Continued Learning\nProfessional Organizations\nInternational Association of Geographic Information Science (ICA-\nGIScience)\nGlobal network of GIS researchers and practitioners\nInternational Epidemiological Association (IEA)\nLeading organization for epidemiologists worldwide\nAmerican Public Health Association (APHA)\nLargest public health organization with GIS special interest groups\nContinuing Education Resources\nOnline Courses:\nCoursera, edX, ESRI Training, Google Earth Engine tutorials\nConferences & Workshops:\nAnnual GIS conferences, public health meetings, specialized\nworkshops\nOpen Source Communities:\nQGIS user groups, R spatial analysis community, Python geospatial\ndevelopers\nFinal Project Checklist & Next Steps\nFinal Deliverable Requirements\nClear project title and research question stated\nProfessional map/visualization created\n2-3 key findings clearly presented\nData sources and methods documented\nLimitations and uncertainties acknowledged\nPublic health implications discussed\nExport in presentable format (PDF/PNG)\nPrepared for 5-minute presentation\nBeyond the Workshop\nImmediate Actions (This Week)\n• Complete and refine your project\n• Share work with colleagues and mentors\n• Connect with other workshop participants\n• Save all materials to portfolio\nShort-term Goals (Next Month)\n• Explore advanced features of tools used\n• Join relevant professional communities\n• Apply skills to other projects or datasets\n• Consider presenting at local meetings\nLong-term Development (Next Year)\n• Pursue formal training or certification\n• Develop specialized expertise areas\n• Contribute to open source projects\n• Mentor others in these skills\nCongratulations on Completing Your Capstone Project!\nYou've successfully integrated GIS, remote sensing, and AI tools to address real-world public health challenges. These skills will serve you well in\nyour future academic and professional endeavors.\nTechnical Skills MasteredResearch Methods AppliedCareer-Ready Portfolio Created\nIndependent GIS and AI-Assisted Spatial Health Analysis\nObservation & Problem Identification\nIdentify spatial patterns in health data that require explanation\n1\nResearch Question Formulation\nDevelop testable questions about spatial relationships\n2\nHypothesis Development\nPropose explanations based on spatial theory\n3\nData Collection & Analysis\nGather and analyze spatial data using GIS/remote sensing\n4\nInterpretation & Conclusions\nDraw evidence-based conclusions about spatial relationships\n5\nData Access & Loading\nAccess satellite data collections and\nadministrative boundaries\nTemporal Filtering\nFilter data by date ranges relevant to\nyour research question\nSpatial Processing\nApply reductions, clipping, and zonal\nstatistics\nVisualization\nCreate appropriate visualizations with\ncolor palettes\nExport\nExport processed data to Google\nDrive for further analysis\nData Import\nLoad vector and raster data from\nmultiple sources\nTable Joins\nConnect spatial and attribute data\nusing common fields\nSpatial Analysis\nPerform buffer analysis, spatial\nqueries, and geoprocessing\nVisualization\nApply symbology and create\nprofessional map layouts\nOutput\nExport maps and analysis results in\nvarious formats\nCode Generation\nGenerate initial scripts for data\nprocessing tasks\nDebugging Support\nTroubleshoot errors and optimize\ncode performance\nMethod Explanation\nUnderstand complex functions and\nanalytical approaches\nLiterature Review\nResearch background information\nand best practices\nDocumentation\nCreate clear documentation and\nexplanations\n\n## Document Information\n- **Source**: PDF Document (1 pages)\n- **Category**: tutorial\n- **Difficulty**: intermediate\n- **Relevant Labs**: lab1\n- **Topics**: buffer, classification, clustering, crs, gee, gis, google earth engine, machine learning, malaria, mapping, projection, public health, python, qgis, raster, remote sensing, satellite, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain day 3: capstone research project guide - independent gis and ai-assisted spatial health analysis\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- buffer\n- classification\n- clustering\n- crs\n- gee\n- gis\n- google earth engine\n- machine learning\n- malaria\n- mapping\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [
        "buffer",
        "classification",
        "clustering",
        "crs",
        "gee",
        "gis",
        "google earth engine",
        "machine learning",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "python",
        "qgis",
        "raster",
        "remote sensing",
        "satellite",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\day3_capstone_research_project_guide.md",
      "filename": "day3_capstone_research_project_guide.md"
    }
  },
  {
    "id": "concepts-fundamentals_of_rs_edited_sc",
    "title": "Fundamentals Of RS Edited SC",
    "content": "\n# Fundamentals Of RS Edited SC\n\n\n\nNational Aeronautics and Space Administration\nFundamentals of Remote Sensing\nNASA ARSET\n\n2NASA’s Applied Remote Sensing Training Program\nOutline\n•Fundamentals of Remote Sensing\n•Satellites and Sensors\n⁃Types\n⁃Resolution\n•Satellite Data Processing Levels\n•Projections and Coordinate Systems\n•Advantages and Disadvantages of \nRemote Sensing\n•Remote Sensing Terminology\n\nFundamentals of Remote Sensing\n\nNASA’s Applied Remote Sensing Training Program4\nWhat is Remote Sensing?\nRemote sensingis obtaining information \nabout an object from a distance. \nPhotography is a very common form of \nremote sensing. \nThere are different ways to collect data, and \ndifferent sensors are used depending on the \napplication.\nSome methods collect ground-based data, \nothers airborne or spaceborne. \n•What information do you need? \n•How much detail? \n•How frequently do you need the data?\n\nNASA’s Applied Remote Sensing Training Program5\nWhat is Remote Sensing?\n•The energy Earth receives from the sun is \ncalled electromagnetic radiation. \n•Radiation is reflected, absorbed, and \nemitted by the Earth's atmosphere or surface, \nas shown by the figure on the left.\n•Satellites carry instruments or sensors that \nmeasure electromagnetic radiation reflected \nor emitted from both terrestrial and \natmospheric sources.\n•With calibrated instruments, scientists can \nmeasure the height, temperature, moisture \ncontent (and more) for nearly every feature \nof the Earth’s atmosphere, hydrosphere, \nlithosphere, and biosphere.\n\nNASA’s Applied Remote Sensing Training Program6\nWhat is Remote Sensing?\n•The electromagnetic \nspectrum is simply the full \nrange ofwave \nfrequenciesthat \ncharacterizes solar \nradiation. \n•Although we are talking \nabout light, most of the \nelectromagnetic \nspectrum cannot be \ndetected by the human \neye. Even satellite \ndetectors only capture a \nsmall portion of the entire \nelectromagnetic \nspectrum.\n\nNASA’s Applied Remote Sensing Training Program7\nWhat is Remote Sensing?\n•Different materials reflect \nand absorb different \nwavelengths of \nelectromagnetic radiation.\n•You can look at the \nreflected wavelengths \ndetected by a sensor and \ndetermine the type of \nmaterial it reflected from. \nThis is known as a spectral \nsignature.\n•In the graph on the left, \ncompare the relationship \nbetween percent \nreflectance and the \nreflective wavelengths of \ndifferent components of the \nEarth’s surface. \n\nNASA’s Applied Remote Sensing Training Program8\nWhat is Remote Sensing?\nVegetation\n•Certain pigments in plant \nleaves strongly absorb \nwavelengths of visible (red) \nlight. \n•The leaves themselves \nstrongly reflect wavelengths \nof near-infrared light, which \nis invisible to human eyes. \n•As a plant canopy changes \nfrom early spring growth to \nlate-season maturity and \nsenescence, these \nreflectance properties also \nchange.\n•Since we can't see infrared \nradiation, we see healthy \nvegetation as green.\n\nNASA’s Applied Remote Sensing Training Program9\nWhat is Remote Sensing?\nWater\n•Longer visible wavelengths \n(green and red) and near-\ninfrared radiation are \nabsorbed more by water \nthan shorter visible \nwavelengths (blue) –so \nwater usually looks blue or \nblue-green.\n•Satellites provide the \ncapability to map optically \nactive components of \nupper water column in \ninland and near-shore \nwaters.\nImage Credit: NASA Earth Observatory, using Landsat data courtesy of USGS.\n\nNASA’s Applied Remote Sensing Training Program10\nWhat is Remote Sensing?\nAtmosphere\n•From the sun to the Earth and back to \nthe sensor, electromagnetic energy \npasses through the atmosphere twice.\n•Much of the incident energy is \nabsorbed and scattered by gases \nand aerosols in the atmosphere \nbefore reaching the Earth’s surface.\n•Atmospheric correctionremoves the \nscattering and absorption effects from \nthe atmosphere to obtain the surface \nreflectance characterizing surface \nproperties.\n\nSatellites and Sensors\n\nNASA’s Applied Remote Sensing Training Program12\nSatellites and Sensors\nSatellites carry sensors or instruments. The names of sensors are usually acronyms that \ncan include the name of the satellite.\nLandsat 9\nOperational Land Imager 2\n(OLI-2)\nThermal Infrared Sensor 2\n(TIRS-2)\nSpacecraft Bus\nImage Credit: NASA\n\nNASA’s Applied Remote Sensing Training Program13\nSatellite Characteristics\n●Orbits: Polar/Non-Polar Orbit vs. Geostationary\n●Energy Source: Passive vs. Active\n●Solar and Terrestrial Spectra: Visible, UV, IR, Microwave...\n●Measurement Technique: Scanning; Non-Scanning; Imager; Sounders\n●Resolution Type and Quality: Spatial, Temporal, Spectral, Radiometric\n●Application: Weather, Ocean Color, Land Mapping, Air Quality, Radiation Budget, etc.\n\nNASA’s Applied Remote Sensing Training Program14\nSatellite Characteristics\nGeostationary Orbit\n•Geostationary satellites \ntypically orbit ~36,000 km \nover the equator with the \nsame rotation period as \nEarth.\n•Multiple observations/day\n•Limited spatial coverage—\nobservations are always of \nthe same area\n•Examples: Weather or \ncommunications satellites\nVideo Credit: NASA\n\nNASA’s Applied Remote Sensing Training Program15\nSatellite Characteristics\nLow Earth Orbit (LEO)\n•Orbit moving relative to \nEarth –can be polar or \nnonpolar\n•Less frequent \nmeasurements\n•Global (or near-global) \nspatial coverage\n•Examples:\n•Polar: Landsat or Terra\n•Nonpolar: ISS or GPM\nVideo Credit: NASA\n\nNASA’s Applied Remote Sensing Training Program16\nSatellite Characteristics\nPolar Orbit & Sun-Synchronous Orbit (SSO)\n•Global coverage\n•Varied measurement frequency (once per \nday to once per month)\n•Larger swath size means higher temporal \nresolution\n•Satellites in SSO traveling over the polar \nregions are synchronous with the sun—this \nmeans that the satellite always visits the \nsame spot at the same local time (e.g., \npassing the city of Paris every day at \nnoon).\nVideo Credit: NASA\n\nNASA’s Applied Remote Sensing Training Program17\nSatellite Characteristics\nSatellite Sensors: Passive\n•Passive remote sensors measure radiant \nenergy reflectedor emittedby the Earth-\natmosphere system or changes in gravity from \nthe Earth.\n•Radiant energy is converted to bio-\ngeophysical quantities such as temperature, \nprecipitation, and soil moisture.\n•Examples: Landsat OLI/TIRS, Terra MODIS, GPM \nGMI, GRACE, etc.\n•https://earthdata.nasa.gov/learn/remote-\nsensors/passive-sensors\nImage Credit: ARSET\n\nNASA’s Applied Remote Sensing Training Program18\nSatellite Characteristics\nSatellite Sensors: Active\n•Active sensors provide their own energy source \nfor illumination\n•Most active sensors operate in the microwave \nportion of the electromagnetic spectrum, which \nmakes them able to penetrate the atmosphere \nunder most conditions and can be used day or \nnight.\n•Have a variety of applications related to \nmeteorology and observation of the Earth's \nsurface and atmosphere.\n•Examples: Laser Altimeter, LiDAR, RADAR, \nScatterometer, Sounder\n•Missions: Sentinel-1 (C-SAR), ICESat-2 (ATLAS), \nGPM (DPR)\n•https://earthdata.nasa.gov/learn/remote-\nsensors/active-sensors\nImage Credit: ARSET\n\nNASA’s Applied Remote Sensing Training Program19\nSpectral Resolution\n•Resolution depends upon satellite orbit configuration and sensor design. Different \nsensors have different resolutions.\n•Signifies the number and width of spectral bands of the sensor. The higher the spectral \nresolution, the narrower the wavelength range for a given channel or band.\n•More and finer spectral channels enable remote sensing of different parts of the Earth’s \nsurface.\n•Typically, multispectral imagery refers to 3 to 10 bands, while hyperspectral imagery \nconsists of hundreds or thousands of (narrower) bands (i.e., higher spectral resolution). \nPanchromatic is a single broad band that collects a wide range of wavelengths.\n\nNASA’s Applied Remote Sensing Training Program20\nSpatial Resolution\n•Resolution depends upon satellite orbit configuration and sensor design. Different \nsensors have different resolutions.\n•Signifies the ground surface area that forms one pixel in the image. Sub-pixel objects \ncan sometimes be resolved.\n•It is usually presented as a single value representing the length of one side of a \nsquare.\n•The higher the spatial resolution, the less area is covered by a single pixel.\n•The image in the bottom right shows the same image at different spatial resolutions: \n(from left to right) 1 m, 10 m, and 30 m.\nSensorSpatial Resolution\nDigitalGlobe (and others)<1 m -4 m\nLandsat30 m\nMODIS250 m -1 km\nGPM IMERG~10 km\nImage Credit: csc.noaa.gov\n\nNASA’s Applied Remote Sensing Training Program21\nSpatial Resolution vs. Spatial Extent\n•Generally, the higher the spatial resolution, the less area is covered by a \nsingle image.\nMODIS (250 m -1 km)Landsat OLI (30 m)\n\nNASA’s Applied Remote Sensing Training Program22\nTemporal Resolution\n•The time it takes for a satellite to complete \none orbit cycle—also called “revisit time”\n•Depends on satellite/sensor capabilities, \nswath overlap, and latitude\n•Some satellites have greater temporal \nresolution because:\n–They can maneuver their sensors\n–They have increasing overlap at higher \nlatitudes\nSensorRevisit time\nLandsat16-days\nMODIS2-days\nCommercial (OrbView)1-2 days\n\nNASA’s Applied Remote Sensing Training Program23\nRadiometric Resolution\n•Describes a sensor's ability to discriminate \ndifferences in energy (or radiance). \n•The betterthe radiometric resolution, the \nmore sensitive the sensor is to small \ndifferences in energy. The larger this \nnumber, the higher the radiometric \nresolution, and the sharper the imagery.\n–12-bit sensor, 4,096 levels: Landsat OLI\n–10-bit sensor, 1,024 levels: AVHRR\n–8-bit sensor, 256 levels: Landsat TM\n–6-bit sensor, 64 levels: Landsat MSS\nThe images show what the same scene looks like at different \nlevels. From left to right: 2-bit, 4-bit, and 8-bit.\nImage Credit: NASA's Earth Observatory\n\nSatellite Data Processing Levels\n\nNASA’s Applied Remote Sensing Training Program25\nSatellite Data Processing Levels\n•Satellite data is available at different stages (or levels) of processing, going from raw data \ncollected from the satellite to polished products that visualize information.\n•NASA takes the data from satellites and processes it to make it more usable for a broad \narray of applications. There is a set of terminology that NASA uses to refer to the levels of \nprocessing it conducts:\n–Level 0 & 1is the raw instrument data that may be time-referenced. It is the most \ndifficult to use.\n–Level 2is Level 1 data that has been converted into a geophysical quantity through a \ncomputer algorithm (known as retrieval). This data is geo-referenced and calibrated. \n–Level 3is Level 2 data that has been mapped on a uniform space-time grid and \nquality controlled.\n–Level 4is Level 3 data that has been combined with models or other instrument data.\n–Level 3 & 4 data is the easiest to use.\n\nProjections and Coordinate Systems\n\nNASA’s Applied Remote Sensing Training Program27\nThe Shape of the Earth\n•Although it is commonly thought of as \na sphere, Earth is not perfectly \nspherical.\n•Its actual shape is what we refer to as \na “geoid.”\n•Geoid: The hypothetical shape of the \nEarth, coinciding with mean sea level \nand its imagined extension under (or \nover) land areas.\nImage Credit: European Space Agency (ESA)\n\nNASA’s Applied Remote Sensing Training Program28\nThe Shape of the Earth\n•For spatial data to be displayed in a \nspatially consistent way, we use an \nelliptical spheroidto approximate the \nsurface of the Earth.\n•No spheroid is a perfect fit, so many \ndifferent approximations are used.\n•Each approximation will fit one part of \nthe Earth’s surface better than others.\n•Each of these spheroids is calculated \nusing a specific datumas a reference \npoint.\nImage Credit: European Space Agency (ESA)\n\nNASA’s Applied Remote Sensing Training Program29\nDatums\n•A datumis a known point on Earth’s \nsurface or within its geometry that we \ncan use as a reference point for all \nother locations.\n•Because of the irregular shape of the \nplanet, the use of datums is necessary \nto portray spatial data as accurately \nas possible.\n•Example: NAD 83 (North American \nDatum 1983)\nImage Credit: ascelibrary.org\n\nNASA’s Applied Remote Sensing Training Program30\nCoordinate Reference Systems\n•All spatial data, including satellite \nimagery, must be indexed, or \ngeoreferenced, to a fixed point on \nEarth’s surface.\n•Pairing a data point or pixel with a \nspecific location on the ground \nrequires a coordinate reference \nsystem (CRS).\n•Two types of coordinate systems are \ncommonly used, geographicand \nprojected.\nImage Credit: GIS Stack Exchange\n\n31NASA’s Applied Remote Sensing Training Program\nTypes of Coordinate Reference Systems\n•Geographic Coordinate Systems\n•Pros:\n•Better for the entire Earth\n•Good for data with a large \nspatial extent\n•Cons:\n•Less accurate for specific \nregions\n•Bad for data with a small \nspatial extent\n•Example of a commonly-used \nGeographic Coordinate System:\nWGS84\nImage Credit: ArcGIS.com\n\n32NASA’s Applied Remote Sensing Training Program\n•Projected Coordinate Systems\n•Pros:\n•Better for specific locations\n•Good for data with a small \nspatial extent\n•Cons:\n•Accuracy is skewed to one \nspecific location\n•Not useful for data with a large \nspatial extent\n•Example of a commonly used \nProjected Coordinate System:\nUTM (Universal Transverse \nMercator)\nTypes of Coordinate Reference Systems\nImage Credit: Earth Data Science\n\n33NASA’s Applied Remote Sensing Training Program\nTypes of Projected Coordinate Systems\n•Cylindrical\n•Best for use in \nEquatorial Regions\n•Distortion occurs near \npoles\n•Great for medium \nspatial extents\n•Example: UTM\n•Planar\n•Also known as \n“Azimuthal”\n•Projects data onto a \nflat plane\n•Great for small spatial \nextents\n•Example: State Plane \nCoordinate System\n•Conical\n•Best for use in Polar \nregions\n•Distortion occurs \nfarther from pole\n•Example: Albers Equal \nArea Conic\nImage Credits: UN.org\n\nAdvantages and Disadvantages of Remote Sensing\n\nNASA’s Applied Remote Sensing Training Program35\nAdvantages of Remote Sensing\n•Provides information where there \nare no ground-based \nmeasurements.\n•Provides globally consistent \nobservations.\n•Provides continuous monitoring of \nour planet.\n•Earth systems models integrate \nsurface-based and remote \nsensing observations and provide \nuniformly gridded, frequent \ninformation of water resources \ndata parameters.\n•Data are freely available and \nthere are web-based tools for \ndata analysis.\nImage Credit: NASA GSFC\n\nNASA’s Applied Remote Sensing Training Program36\nDisadvantages of Remote Sensing\n•It is very difficult to obtain high \nspectral, spatial, temporal, and \nradiometric resolution all at the \nsame time.\n•Large amounts of data in a \nvariety of formats can lead to \nmore time and processing.\n•Applying satellite data may \nrequire additional processing, \nvisualization, and other tools.\n•While the data are generally \nvalidated with selected surface \nmeasurements, regional and \nlocal assessment is \nrecommended.\nImage Credit: NOAA\n\n37NASA’s Applied Remote Sensing Training Program\nRemote Sensing Terminology\nAmplitude: The “height” of a wave or its maximum \ndisplacement from equilibrium.\nCoordinate Reference System: A coordinate-based local, \nregional, or global system used to locate geographical \nentities.\nDatum: A known point that can be used as a reference \npoint for all other locations.\nElectromagnetic Radiation: The energy the Earth receives \nfrom the Sun.\nFrequency:The number of cycles of a wave passing a fixed \npoint per unit of time.\nGeodesy: The science of accurately measuring and \nunderstanding three fundamental properties of the Earth: its \ngeometric shape, its orientation in space, and its gravity \nfield.\nGeodetic: Relating to geodesy.\nGeoid: The hypothetical shape of the Earth, coinciding with \nmean sea level and its imagined extension under (or over) \nland areas.\nGeoreference: To link spatial data to its correct location.\nGeostationary: Remaining fixed over a specific location on \nEarth’s surface.\nGridded: Spatial data displayed over a uniform grid, often \ntied to specific locations.\nNadir: The point on the Earth’s surface directly below the \nobserving satellite.\nPolar: A type of orbit that crosses the poles.\nPolarization: The orientation of an electromagnetic wave.\nProjection: Themeans by which you display the coordinate \nsystem and your data on a flat surface.\nRadiometric Resolution: Describes a sensor's ability to \ndiscriminate differences in energy (or radiance). \nSpatial Extent: The overall surface area covered by a given \ndataset.\nSpatial Resolution: The ground surface area that forms one \npixel in the image. \nSpectral Resolution: The number and width of spectral \nbands of the sensor. The higher the spectral resolution, the \nnarrower the wavelength range for a given channel or \nband.\nSun-Synchronous: The satellite always visits the same spot at \nthe same local time.\nTemporal Resolution: The time it takes for a satellite to \ncomplete one orbit cycle—also called “revisit time.”\n\nNASA’s Applied Remote Sensing Training Program38\nContact Information\nContact: nasa.arset@gmail.com\nApplied Remote Sensing Training \n(ARSET) Program: \nhttps://appliedsciences.nasa.gov/wha\nt-we-do/capacity-building/arset\nTwitter: @NASAARSET\nYouTube: \nhttps://www.youtube.com/user/NASA\ngovVideo/playlists\n\n39NASA’s Applied Remote Sensing Training Program\nThank You!\n\n## Document Information\n- **Source**: PDF Document (39 pages)\n- **Category**: concepts\n- **Difficulty**: intermediate\n- **Relevant Labs**: general\n- **Topics**: arcgis, coordinate system, crs, gis, mapping, projection, remote sensing, satellite\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain fundamentals of rs edited sc\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- arcgis\n- coordinate system\n- crs\n- gis\n- mapping\n- projection\n- remote sensing\n- satellite\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "intermediate",
      "lab": "general",
      "topics": [
        "arcgis",
        "coordinate system",
        "crs",
        "gis",
        "mapping",
        "projection",
        "remote sensing",
        "satellite"
      ],
      "source": "concepts\\fundamentals_of_rs_edited_sc.md",
      "filename": "fundamentals_of_rs_edited_sc.md"
    }
  },
  {
    "id": "concepts-fundamentals_rs",
    "title": "http://pcmas1.ccrs.nrcan.gc.ca/fundam/chapter1/chapter1_1_e.htm",
    "content": "\n# http://pcmas1.ccrs.nrcan.gc.ca/fundam/chapter1/chapter1_1_e.htm\n\n\n\nFFuunnddaammeennttaallss\nof Remote Sensing\nNatural Resources    Ressources naturelles\nCanadaCanada\nA Canada Centre for Remote Sensing Remote Sensing Tutorial\n\n     Table of Contents \n1.  Introduction\n1.1  What is Remote Sensing? 5\n1.2  Electromagnetic Radiation 7\n1.3  Electromagnetic Spectrum 9\n1.4  Interactions with the Atmosphere 12\n1.5  Radiation - Target16\n1.6  Passive vs. Active Sensing19\n1.7  Characteristics of Images20\n1.8  Endnotes22\nDid You Know23\nWhiz Quiz and Answers27\n \n2.  Sensors\n2.1  On the Ground, In the Air, In Space 34\n2.2  Satellite Characteristics36\n2.3  Pixel Size, and Scale 39\n2.4  Spectral Resolution41\n2.5  Radiometric Resolution 43\n2.6  Temporal Resolution44\n2.7  Cameras and Aerial Photography 45\n2.8  Multispectral Scanning48\n2.9  Thermal Imaging50\n2.10  Geometric Distortion52\n2.11  Weather Satellites54\n2.12  Land Observation Satellites60\n2.13  Marine Observation Satellites67\n2.14  Other Sensors70\n2.15  Data Reception72\n2.16  Endnotes74\nDid You Know75\nWhiz Quiz and Answers83\n  \n  \nPage 2Fundamentals of Remote Sensing - Table of Contents\nCanada Centre for Remote Sensing\n\n  \n \n3.  Microwaves\n3.1  Introduction  92\n3.2  Radar Basic  96\n3.3  Viewing Geometry & Spatial Resolution  99\n3.4  Image distortion102\n3.5  Target interaction106\n3.6  Image Properties110\n3.7  Advanced Applications114\n3.8  Polarimetry117\n3.9  Airborne vs Spaceborne123\n3.10  Airborne & Spaceborne Systems125\n3.11  Endnotes129\nDid You Know131\nWhiz Quiz and Answers135\n \n4.  Image Analysis\n4.1  Introduction141\n4.2  Visual interpretation144\n4.3  Digital processing147\n4.4  Preprocessing149\n4.5  Enhancement154\n4.6  Transformations158\n4.7  Classification161\n4.8  Integration164\n4.9  Endnotes166\nDid You Know167\nWhiz Quiz and Answers170\n \n5.  Applications\n5.1  Introduction174\n5.2  Agriculture177\n\nCrop Type Mapping  \n\nCrop Monitoring  \n5.3  Forestry184\n\nClear cut Mapping  \n\nSpecies identification  \n\nBurn Mapping  \n  \n  \nPage 3Fundamentals of Remote Sensing - Table of Contents\nCanada Centre for Remote Sensing\n\n  \n5.4  Geology196\n\nStructural Mapping  \n\nGeologic Units  \n5.5  Hydrology203\n\nFlood Delineation  \n\nSoil Moisture  \n5.6  Sea Ice209\n\nType and Concentration  \n\nIce Motion  \n5.7  Land Cover215\n\nRural/Urban change  \n\nBiomass Mapping  \n5.8  Mapping222\n\nPlanimetry  \n\nDEMs  \n\nTopo Mapping  \n5.9  Oceans & Coastal232\n\nOcean Features  \n\nOcean Colour  \n\nOil Spill Detection  \n5.10  Endnotes240\nDid You Know241\nWhiz Quiz250\n \nCredits\n254\n \nPermissions\n256\n \nDownload\n257\n \nNotes for Teachers\n258\nPage 4Fundamentals of Remote Sensing - Table of Contents\nCanada Centre for Remote Sensing\n\n \n1. Introduction to Fundamentals\n \n \n1.1 What is Remote Sensing? \nSo, what exactly is \nremote sensing\n? For the purposes of this tutorial, we will use the \nfollowing definition: \n\"Remote sensing is the science (and to some extent, art) of acquiring \ninformation about the Earth's surface without actually being in contact \nwith it. This is done by sensing and recording reflected or emitted energy \nand processing, analyzing, and applying that information.\" \nIn much of remote sensing, \nthe process\n involves an interaction between incident radiation \nand the targets of interest. This is exemplified by the use of imaging systems where the \nfollowing seven elements are involved. Note, however that remote sensing also involves the \nsensing of emitted energy and the use of non-imaging sensors.  \n  \n1. Energy Source or Illumination (A)\n - the \nfirst requirement for remote sensing is to have \nan energy source which illuminates or \nprovides electromagnetic energy to the target \nof interest. \n2. Radiation and the Atmosphere (B)\n - as \nthe energy travels from its source to the \ntarget, it will come in contact with and interact \nwith the atmosphere it passes through. This \ninteraction may take place a second time as \nthe energy travels from the target to the \nsensor. \n  \n3. Interaction with the Target (C)\n - once the energy makes its way to the target through the \natmosphere, it interacts with the target depending on the properties of both the target and the \nradiation. \nPage 5Section 1.1 What is Remote Sensing?\nCanada Centre for Remote Sensing\n\n4. Recording of Energy by the Sensor (D)\n - after the energy has been scattered by, or \nemitted from the target, we require a sensor (remote - not in contact with the target) to collect \nand record the electromagnetic radiation. \n5. Transmission, Reception, and Processing (E)\n - the energy recorded by the sensor has \nto be transmitted, often in electronic form, to a receiving and processing station where the \ndata are processed into an image (hardcopy and/or digital). \n6. Interpretation and Analysis (F)\n - the processed image is interpreted, visually and/or \ndigitally or electronically, to extract information about the target which was illuminated. \n7. Application (G)\n - the final element of the remote sensing process is achieved when we \napply the information we have been able to extract from the imagery about the target in order \nto better understand it, reveal some new information, or assist in solving a particular problem. \nThese seven elements comprise the remote sensing process from beginning to end. We will \nbe covering all of these in sequential order throughout the five chapters of this tutorial, \nbuilding upon the information learned as we go. Enjoy the journey! \n  \nPage 6Section 1.1 What is Remote Sensing?\nCanada Centre for Remote Sensing\n\n1.2 Electromagnetic Radiation \nAs was noted in the previous section, the first \nrequirement for remote sensing is to have an \nenergy source to illuminate the target\n \n(unless the sensed energy is being emitted by \nthe target). This energy is in the form of \nelectromagnetic radiation.  \n  \n  \nAll electromagnetic radiation has fundamental \nproperties and behaves in predictable ways \naccording to the basics of wave theory. \nElectromagnetic radiation\n consists of an \nelectrical field(E) which varies in magnitude in \na direction perpendicular to the direction in \nwhich the radiation is traveling, and a \nmagnetic field (M) oriented at right angles to \nthe electrical field. Both these fields travel at \nthe speed of light (c). \nTwo characteristics of electromagnetic \nradiation are particularly important for understanding remote sensing. These are the \nwavelength and frequency.\n \n \nPage 7Section 1.2 Electromagnetic Radiation\nCanada Centre for Remote Sensing\n\nThe wavelength is the length of one wave cycle, which can be measured as the distance \nbetween successive wave crests. Wavelength is usually represented by the Greek letter \nlambda (\nλ\n). Wavelength is measured in metres (m) or some factor of metres such as \nnanometres\n (nm, 10\n-9\n metres), \nmicrometres\n (\nμ\nm, 10\n-6\n metres) (\nμ\nm, 10\n-6\n metres) or \ncentimetres (cm, 10\n-2\n metres). Frequency refers to the number of cycles of a wave passing a \nfixed point per unit of time. Frequency is normally measured in \nhertz\n (Hz), equivalent to one \ncycle per second, and various multiples of hertz.  \nWavelength and frequency are related by the following formula:  \n \nTherefore, the two are inversely related to each other. The shorter the wavelength, the higher \nthe frequency. The longer the wavelength, the lower the frequency. Understanding the \ncharacteristics of electromagnetic radiation in terms of their wavelength and frequency is \ncrucial to understanding the information to be extracted from remote sensing data. Next we \nwill be examining the way in which we categorize electromagnetic radiation for just that \npurpose. \nPage 8Section 1.2 Electromagnetic Radiation\nCanada Centre for Remote Sensing\n\n1.3 The Electromagnetic Spectrum \nThe \nelectromagnetic spectrum\n ranges from the shorter wavelengths (including gamma and \nx-rays) to the longer wavelengths (including microwaves and broadcast radio waves). There \nare several regions of the electromagnetic spectrum which are useful for remote sensing.  \n \nFor most purposes, the \nultraviolet or UV\n \nportion of the spectrum has the shortest \nwavelengths which are practical for remote \nsensing. This radiation is just beyond the \nviolet portion of the visible wavelengths, \nhence its name. Some Earth surface \nmaterials, primarily rocks and minerals, \nfluoresce or emit visible light when illuminated \nby UV radiation.  \n  \n  \nPage 9Section 1.3 The Electromagnetic Spectrum\nCanada Centre for Remote Sensing\n\n  \n \nThe light which our eyes - our \"remote \nsensors\" - can detect is part of the \nvisible \nspectrum\n. It is important to recognize how \nsmall the visible portion is relative to the rest \nof the spectrum. There is a lot of radiation \naround us which is \"invisible\" to our eyes, but \ncan be detected by other remote sensing \ninstruments and used to our advantage. The \nvisible wavelengths cover a range from \napproximately 0.4 to 0.7 \nμ\nm. The longest \nvisible wavelength is red and the shortest is \nviolet. Common wavelengths of what we \nperceive as particular colours from the visible \nportion of the spectrum are listed below. It is \nimportant to note that this is the only portion \nof the spectrum we can associate with the \nconcept of \ncolours\n. \n  \n  \n\nViolet:\n 0.4 - 0.446 \nμ\nm  \n\nBlue:\n 0.446 - 0.500 \nμ\nm  \n\nGreen:\n 0.500 - 0.578 \nμ\nm  \n\nYellow:\n 0.578 - 0.592 \nμ\nm  \n\nOrange:\n 0.592 - 0.620 \nμ\nm  \n\nRed:\n 0.620 - 0.7 \nμ\nm  \n   \nBlue\n, \ngreen\n, and \nred\n are the \nprimary \ncolours\n or wavelengths of the visible \nspectrum. They are defined as such because \nno single primary colour can be created from \nthe other two, but all other colours can be \nformed by combining blue, green, and red in \nvarious proportions. Although we see sunlight \nas a uniform or homogeneous colour, it is \nactually composed of various wavelengths of \nradiation in primarily the ultraviolet, visible \nand infrared portions of the spectrum. The visible portion of this radiation can be shown in its \nPage 10Section 1.3 The Electromagnetic Spectrum\nCanada Centre for Remote Sensing\n\ncomponent colours when sunlight is passed through a \nprism\n, which bends the light in differing \namounts according to wavelength.  \n  \nThe next portion of the spectrum of interest is \nthe infrared (IR) region which covers the \nwavelength range from approximately 0.7 \nμ\nm \nto 100 \nμ\nm - more than 100 times as wide as \nthe visible portion! The infrared region can be \ndivided into two categories based on their \nradiation properties - the \nreflected IR\n, and \nthe emitted or \nthermal IR\n. Radiation in the \nreflected IR region is used for remote sensing \npurposes in ways very similar to radiation in \nthe visible portion. The reflected IR covers \nwavelengths from approximately 0.7 \nμ\nm to \n3.0 \nμ\nm. The thermal IR region is quite \ndifferent than the visible and reflected IR \nportions, as this energy is essentially the \nradiation that is emitted from the Earth's \nsurface in the form of heat. The thermal IR \ncovers wavelengths from approximately 3.0 \nμ\nm to 100 \nμ\nm.  \nThe portion of the spectrum of more recent \ninterest to remote sensing is the \nmicrowave \nregion\n from about 1 mm to 1 m. This covers \nthe longest wavelengths used for remote \nsensing. The shorter wavelengths have \nproperties similar to the thermal infrared \nregion while the longer wavelengths approach \nthe wavelengths used for radio broadcasts. \nBecause of the special nature of this region \nand its importance to remote sensing in \nCanada, an entire chapter (Chapter 3) of the \ntutorial is dedicated to microwave sensing.  \nPage 11Section 1.3 The Electromagnetic Spectrum\nCanada Centre for Remote Sensing\n\n1.4 Interactions with the Atmosphere \nBefore radiation used for remote sensing reaches the Earth's surface it has to travel through \nsome distance of the Earth's atmosphere. Particles and gases in the atmosphere can affect \nthe incoming light and radiation. These effects are caused by the mechanisms of \nscattering\n \nand \nabsorption\n.  \n \nScattering\n occurs when particles or large gas molecules present in the atmosphere interact \nwith and cause the electromagnetic radiation to be redirected from its original path. How much \nscattering takes place depends on several factors including the wavelength of the radiation, \nthe abundance of particles or gases, and the distance the radiation travels through the \natmosphere. There are three (3) types of scattering which take place. \n  \n  \n  \nPage 12Section 1.4 Interactions with the Atmosphere\nCanada Centre for Remote Sensing\n\nRayleigh scattering\n occurs when particles are very small compared to the wavelength of the \nradiation. These could be particles such as small specks of dust or nitrogen and oxygen \nmolecules. Rayleigh scattering causes shorter wavelengths of energy to be scattered much \nmore than longer wavelengths. Rayleigh scattering is the dominant scattering mechanism in \nthe upper atmosphere. The fact that the sky appears \"blue\" during the day is because of this \nphenomenon. As sunlight passes through the atmosphere, the shorter wavelengths (i.e. blue) \nof the visible spectrum are scattered more than the other (longer) visible wavelengths. At \nsunrise and sunset\n the light has to travel farther through the atmosphere than at midday and \nthe scattering of the shorter wavelengths is more complete; this leaves a greater proportion of \nthe longer wavelengths to penetrate the atmosphere. \nMie scattering\n occurs when the particles are just about the same size as the wavelength of \nthe radiation. Dust, pollen, smoke and water vapour are common causes of Mie scattering \nwhich tends to affect longer wavelengths than those affected by Rayleigh scattering. Mie \nscattering occurs mostly in the lower portions of the atmosphere where larger particles are \nmore abundant, and dominates when cloud conditions are overcast. \n  \nThe final scattering mechanism of importance is \ncalled \nnonselective scattering\n. This occurs when \nthe particles are much larger than the wavelength of \nthe radiation. Water droplets and large dust \nparticles can cause this type of scattering. \nNonselective scattering gets its name from the fact \nthat all wavelengths are scattered about equally. \nThis type of scattering causes fog and clouds to \nappear white to our eyes because blue, green, and \nred light are all scattered in approximately equal \nquantities (blue+green+red light = white light). \n  \n  \nPage 13Section 1.4 Interactions with the Atmosphere\nCanada Centre for Remote Sensing\n\n  \nAbsorption\n is the other main mechanism at work \nwhen electromagnetic radiation interacts with the \natmosphere. In contrast to scattering, this \nphenomenon causes molecules in the atmosphere to \nabsorb energy at various wavelengths. Ozone, \ncarbon dioxide, and water vapour are the three main \natmospheric constituents which absorb radiation.  \nOzone\n serves to absorb the harmful (to most living \nthings) ultraviolet radiation from the sun. Without this \nprotective layer in the atmosphere our skin would \nburn when exposed to sunlight. \nYou may have heard \ncarbon dioxide\n referred to as \na greenhouse gas. This is because it tends to absorb radiation strongly in the far infrared \nportion of the spectrum - that area associated with thermal heating - which serves to trap this \nheat inside the atmosphere. Water vapour in the atmosphere absorbs much of the incoming \nlongwave infrared and shortwave microwave radiation (between 22μm and 1m). The \npresence of water vapour in the lower atmosphere varies greatly from location to location and \nat different times of the year. For example, the air mass above a desert would have very little \nwater vapour to absorb energy, while the tropics would have high concentrations of water \nvapour (i.e. high humidity). \n  \nBecause these gases absorb \nelectromagnetic energy in very \nspecific regions of the spectrum, they \ninfluence where (in the spectrum) we \ncan \"look\" for remote sensing \npurposes. Those areas of the \nspectrum which are not severely \ninfluenced by atmospheric absorption \nand thus, are useful to remote \nsensors, are called \natmospheric \nwindows\n. By comparing the \ncharacteristics of the two most \ncommon energy/radiation sources \n(the sun and the earth) with the \natmospheric windows available to us, we can define those wavelengths that we can \nuse \nmost effectively\n for remote sensing. The visible portion of the spectrum, to \nwhich our eyes are most sensitive, corresponds to both an atmospheric window and \nthe peak energy level of the sun. Note also that heat energy emitted by the Earth \ncorresponds to a window around 10 \nμ\nm in the thermal IR portion of the spectrum, \nwhile the large window at wavelengths beyond 1 mm is associated with the \nPage 14Section 1.4 Interactions with the Atmosphere\nCanada Centre for Remote Sensing\n\nmicrowave region. \n  \nNow that we understand how electromagnetic energy makes its journey from its source to the \nsurface (and it is a difficult journey, as you can see) we will next examine what happens to \nthat radiation when it does arrive at the Earth's surface.  \nPage 15Section 1.4 Interactions with the Atmosphere\nCanada Centre for Remote Sensing\n\n1.5 Radiation - Target Interactions \nRadiation that is not absorbed or scattered in \nthe atmosphere can reach and interact with \nthe Earth's surface. There are three (3) forms \nof interaction that can take place when energy \nstrikes, or is \nincident (I)\n upon the surface. \nThese are: \nabsorption (A)\n; \ntransmission \n(T)\n; and \nreflection (R)\n. The total incident \nenergy will interact with the surface in one or \nmore of these three ways. The proportions of \neach will depend on the wavelength of the \nenergy and the material and condition of the \nfeature. \n  \n  \nAbsorption (A) occurs when radiation (energy) is absorbed into the target while transmission \n(T) occurs when radiation passes through a target. Reflection (R) occurs when radiation \n\"bounces\" off the target and is redirected. In remote sensing, we are most interested in \nmeasuring the radiation reflected from targets. We refer to two types of reflection, which \nrepresent the two extreme ends of the way in which energy is reflected from a target: \nspecular reflection\n and \ndiffuse reflection\n. \nPage 16Section 1.5 Radiation - Target Interactions\nCanada Centre for Remote Sensing\n\nWhen a surface is smooth we get \nspecular\n or mirror-like reflection where all (or almost all) of \nthe energy is directed away from the surface in a single direction. \nDiffuse\n reflection occurs \nwhen the surface is rough and the energy is reflected almost uniformly in all directions. Most \nearth surface features lie somewhere between perfectly specular or perfectly diffuse \nreflectors. Whether a particular target reflects specularly or diffusely, or somewhere in \nbetween, depends on the surface roughness of the feature in comparison to the wavelength of \nthe incoming radiation. If the wavelengths are much smaller than the surface variations or the \nparticle sizes that make up the surface, diffuse reflection will dominate. For example, fine-\ngrained sand would appear fairly smooth to long wavelength microwaves but would appear \nquite rough to the visible wavelengths.   \nLet's take a look at a couple of examples of targets at the Earth's surface and how energy at \nthe visible and infrared wavelengths interacts with them. \nLeaves\n: A chemical compound in leaves \ncalled chlorophyll strongly absorbs \nradiation in the red and blue \nwavelengths but reflects green \nwavelengths. Leaves appear \"greenest\" \nto us in the summer, when chlorophyll \ncontent is at its maximum. In autumn, \nthere is less chlorophyll in the leaves, so \nthere is less absorption and \nproportionately more reflection of the red \nwavelengths, making the leaves appear \nred or yellow (yellow is a combination of \nred and green wavelengths). The \ninternal structure of healthy leaves act as excellent diffuse reflectors of near-infrared \nwavelengths. If our eyes were sensitive to near-infrared, trees would appear extremely bright \nto us at these wavelengths. In fact, measuring and monitoring the near-IR reflectance is one \nway that scientists can determine how healthy (or unhealthy) vegetation may be. \nWater\n: Longer wavelength visible and near \ninfrared radiation is absorbed more by water \nthan shorter visible wavelengths. Thus water \ntypically looks blue or blue-green due to \nstronger reflectance at these shorter \nwavelengths, and darker if viewed at red or \nnear infrared wavelengths. If there is \nsuspended sediment present in the upper \nlayers of the water body, then this will allow \nbetter reflectivity and a brighter appearance \nof the water. The apparent colour of the \nwater will show a slight shift to longer \nPage 17Section 1.5 Radiation - Target Interactions\nCanada Centre for Remote Sensing\n\nwavelengths. Suspended sediment (S) can \nbe easily confused with shallow (but clear) water, since these two phenomena appear very \nsimilar. Chlorophyll in algae absorbs more of the blue wavelengths and reflects the green, \nmaking the water appear more green in colour when algae is present. The topography of the \nwater surface (rough, smooth, floating materials, etc.) can also lead to complications for \nwater-related interpretation due to potential problems of specular reflection and other \ninfluences on colour and brightness. \n \nWe can see from these examples that, depending on the complex make-up of the target that \nis being looked at, and the wavelengths of radiation involved, we can observe very different \nresponses to the mechanisms of absorption, transmission, and reflection. By measuring the \nenergy that is reflected (or emitted) by targets on the Earth's surface over a variety of different \nwavelengths, we can build up a \nspectral response\n for that object. By comparing the \nresponse patterns of different features we may be able to distinguish between them, where \nwe might not be able to, if we only compared them at one wavelength. For example, water \nand vegetation may reflect somewhat similarly in the visible wavelengths but are almost \nalways separable in the infrared. Spectral response can be quite variable, even for the same \ntarget type, and can also vary with time (e.g. \"green-ness\" of leaves) and location. Knowing \nwhere to \"look\" spectrally and understanding the factors which influence the spectral response \nof the features of interest are critical to correctly interpreting the interaction of electromagnetic \nradiation with the surface. \nPage 18Section 1.5 Radiation - Target Interactions\nCanada Centre for Remote Sensing\n\n1.6 Passive vs. Active Sensing \nSo far, throughout this chapter, we have made \nvarious references to the sun as a source of \nenergy or radiation. The sun provides a very \nconvenient source of energy for remote sensing. \nThe sun's energy is either \nreflected\n, as it is for \nvisible wavelengths, or absorbed and then \nre-\nemitted\n, as it is for thermal infrared \nwavelengths. Remote sensing systems which \nmeasure energy that is naturally available are \ncalled \npassive sensors\n. Passive sensors can \nonly be used to detect energy when the naturally \noccurring energy is available. For all reflected \nenergy, this can only take place during the time \nwhen the sun is illuminating the Earth. There is \nno reflected energy available from the sun at night. Energy that is naturally emitted (such as \nthermal infrared) can be detected day or night, as long as the amount of energy is large \nenough to be recorded.  \nActive sensors\n, on the other hand, provide their own \nenergy source for illumination. The sensor emits radiation \nwhich is directed toward the target to be investigated. The \nradiation reflected from that target is detected and \nmeasured by the sensor. Advantages for active sensors \ninclude the ability to obtain measurements anytime, \nregardless of the time of day or season. Active sensors can \nbe used for examining wavelengths that are not sufficiently \nprovided by the sun, such as microwaves, or to better \ncontrol the way a target is illuminated. However, active \nsystems require the generation of a fairly large amount of \nenergy to adequately illuminate targets. Some examples of \nactive sensors are a laser fluorosensor and a synthetic \naperture radar (SAR). \nPage 19Section 1.6 Passive vs. Active Sensing\nCanada Centre for Remote Sensing\n\n1.7 Characteristics of Images \nBefore we go on to the next chapter, which looks in more detail at sensors and their \ncharacteristics, we need to define and understand a few fundamental terms and \nconcepts associated with remote sensing images. \nElectromagnetic energy may be detected either \nphotographically or electronically. The \nphotographic process uses chemical reactions \non the surface of light-sensitive film to detect \nand record energy variations. It is important to \ndistinguish between the terms \nimages\n and \nphotographs\n in remote sensing. An image \nrefers to any pictorial representation, regardless \nof what wavelengths or remote sensing device \nhas been used to detect and record the \nelectromagnetic energy. A \nphotograph\n refers \nspecifically to images that have been detected as well as recorded on photographic \nfilm. The black and white photo to the left, of part of the city of Ottawa, Canada was \ntaken in the visible part of the spectrum. Photos are normally recorded over the \nwavelength range from 0.3 \nμ\nm to 0.9 \nμ\nm - the visible and reflected infrared. Based \non these definitions, we can say that all photographs are images, but not all images \nare photographs. Therefore, unless we are talking specifically about an image \nrecorded photographically, we use the term image. \nA photograph could also be \nrepresented and displayed in a \ndigital\n format by subdividing the \nimage into small equal-sized and \nshaped areas, called picture \nelements or \npixels\n, and \nrepresenting the brightness of each \narea with a numeric value or \ndigital \nnumber\n. Indeed, that is exactly \nwhat has been done to the photo to \nthe left. In fact, using the definitions \nwe have just discussed, this is \nactually a \ndigital image\n of the \noriginal photograph! The photograph was scanned and subdivided into pixels with \neach pixel assigned a digital number representing its relative brightness. The \ncomputer displays each digital value as different brightness levels. Sensors that \nPage 20Section 1.7 Characteristics of Images\nCanada Centre for Remote Sensing\n\nrecord electromagnetic energy, electronically record the energy as an array of \nnumbers in digital format right from the start. These two different ways of \nrepresenting and displaying remote sensing data, either pictorially or digitally, are \ninterchangeable as they convey the same information (although some detail may be \nlost when converting back and forth).  \nIn previous sections we described the visible portion of the spectrum and the \nconcept of colours. We see colour because our eyes detect the entire visible range \nof wavelengths and our brains process the information into separate colours. Can \nyou imagine what the world would look like if we could only see very narrow ranges \nof wavelengths or colours? That is how many sensors work. The information from a \nnarrow wavelength range is gathered and stored in a \nchannel\n, also sometimes \nreferred to as a \nband\n. We can combine and display channels of information digitally \nusing the three primary colours (blue, green, and red). The data from each channel \nis represented as one of the primary colours and, depending on the relative \nbrightness (i.e. the digital value) of each pixel in each channel, the primary colours \ncombine in different proportions to represent different colours. \n \n \n \nWhen we use this method to display a single channel or range of wavelengths, we \nare actually displaying that channel through all three primary colours. Because the \nbrightness level of each pixel is the same for each primary colour, they combine to \nform a \nblack and white image\n, showing various shades of gray from black to white. \nWhen we display more than one channel each as a different primary colour, then the \nbrightness levels may be different for each channel/primary colour combination and \nthey will combine to form a \ncolour image\n.  \nPage 21Section 1.7 Characteristics of Images\nCanada Centre for Remote Sensing\n\n1.8 Endnotes \nYou have just completed \nChapter 1 - Fundamentals of Remote Sensing\n. You can continue \nto Chapter 2 - Satellites and Sensors or first browse the CCRS Web site\n1\n for other articles \nrelated to remote sensing fundamentals. \nFor instance, you may want to look at some conventional\n2\n or unconventional definitions\n3\n of \n\"remote sensing\" developed by experts and other rif-raf from around the world. \nWe have an explanation and calculation on just how much you need to worry about the effect \nof radiation\n4\n from Canada's first remote sensing satellite: RADARSAT.\n \nThe knowledge of how radiation interacts with the atmospheric is used by scientists in the \nEnvironmental Monitoring Section of CCRS to develop various \"radiation products\"\n5\n. Check \nthem out! \nLearn more on how various targets like water\n6\n, rocks\n7\n, ice\n8\n, man-made features\n9\n, and oil \nslicks\n10\n interact with microwave energy. \n \nOur Remote Sensing Glossary\n11\n can help fill out your knowledge of remote sensing \nfundamentals. Try searching for specific terms of interest or review the terms in the \n\"phenomena\" category. \n \n \n1\nhttp://www.ccrs.nrcan.gc.ca/\n \n2\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/terms/definition/convdef_e.html\n \n3\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/terms/definition/unconvdef_e.html\n \n4\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/fun/radiation/radiation_e.html\n \n5\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/apps/landcov/rad/emrad_e.html\n \n6\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/man/rman01_e.html\n \n7\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/nwt/rnwt01_e.html\n \n8\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/pei/rpei01_e.html\n \n9\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/ana/cnfdbrig/confed_e.html\n \n10\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/uk/ruk01_e.html\n \n11\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/terms/glossary/glossary_e.html\n \nPage 22Section 1.8 Endnotes\nCanada Centre for Remote Sensing\n\n \n1. Did You Know\n \n \n1.1 Did You Know? \n \nOf our five senses (sight, hearing, taste, smell, touch), three may be considered forms of \n\"remote sensing\", where the source of information is at some distance. The other two rely on \ndirect contact with the source of information - which are they? \nPage 23Section 1 Did you know?\nCanada Centre for Remote Sensing\n\n1.2 Did You Know? \n\"I've Gone Batty!\"  \n...that remote sensing, in its broadest definition, \nincludes ultrasounds, satellite weather maps, speed \nradar, graduation photos, and sonar - both for ships \nand for bats!. Hospitals use imaging technology, \nincluding CAT scans, magnetic resonance imaging (3-\nD imaging of soft tissue), and x-rays for examining our \nbodies. These are all examples of non-intrusive remote \nsensing methods. \n...you can use an oscilloscope, a special electronic device which displays waves similar to the \nelectromagnetic radiation waves you have seen here, to look at the wavelength and frequency \npatterns of your voice. High-pitched sounds have short wavelengths and high frequencies. \nLow sounds are the opposite. Scientists say that the Earth itself vibrates at a very low \nfrequency, making a sound far below the human hearing range. \n...that the concept of wavelength and frequency is an important principle behind something \ncalled the Doppler Shift, which explains how sound and light waves are perceived to be \ncompressed or expanded if the object producing them is moving relative to the sensor. As a \ntrain or race car advances towards us, our ears tend to hear progressively lower sounds or \nfrequencies (shorter wavelengths) until it reaches us, the original frequency of the object when \nit is broadside, then even lower frequencies as it moves further away. This same principle \n(applied to light) is used by astronomers to see how quickly stars are moving away from us \n(the Red shift).  \nPage 24Section 1 Did you know?\nCanada Centre for Remote Sensing\n1.3 Did You Know? \n \nHue\n and \nsaturation\n are independent characteristics of colour. Hue refers to the wavelength \nof light, which we commonly call \"colour\", while saturation indicates how pure the colour is, or \nhow much white is mixed in with it. For instance, \"pink\" can be considered a less saturated \nversion of \"red\". \n\n1.4 Did You Know? \n\"...sorry, no pot of gold at the end of this rainbow...\" \n \n...water droplets act as tiny, individual prisms. When sunlight passes through them, the \nconstituent wavelengths are bent in varying amounts according to wavelength. Individual \ncolours in the sunlight are made visible and a rainbow is the result, with shorter wavelengths \n(violet, blue) in the inner part of the arc, and longer wavelengths (orange, red) along the outer \narc.  \n...if scattering of radiation in the atmosphere did not take place, then shadows would appear \nas jet black instead of being various degrees of darkness. Scattering causes the atmosphere \nto have its own brightness (from the light scattered by particles in the path of sunlight) which \nhelps to illuminate the objects in the shadows.  \nPage 25Section 1 Did you know?\nCanada Centre for Remote Sensing\n1.5 Did You Know? \n\"...now, here's something to 'reflect' on...\"  \n \n... the colours we perceive are a combination of these radiation interactions (absorption, \ntransmission, reflection), and represent the wavelengths being reflected. If all visible \nwavelengths are reflected from an object, it will appear white, while an object absorbing all \nvisible wavelengths will appear colourless, or black.  \n\n1.6 Did You Know? \n\"...say 'Cheese'!...\" \n...a camera provides an excellent example of both passive and active sensors. During a bright \nsunny day, enough sunlight is illuminating the targets and then reflecting toward the camera \nlens, that the camera simply records the radiation provided (passive mode). On a cloudy day \nor inside a room, there is often not enough sunlight for the camera to record the targets \nadequately. Instead, it uses its own energy source - a flash - to illuminate the targets and \nrecord the radiation reflected from them (active mode). \n... radar used by police to measure the speed of \ntraveling vehicles is a use of active remote sensing. \nThe radar device is pointed at a vehicle, pulses of \nradiation are emitted, and the reflection of that radiation \nfrom the vehicle is detected and timed. The speed of \nthe vehicle is determined by calculating time delays \nbetween the repeated emissions and reception of the \npulses. This can be calculated very accurately because \nthe speed of the radiation is moving much, much faster than most vehicles...unless you're \ndriving at the speed of light!  \nPage 26Section 1 Did you know?\nCanada Centre for Remote Sensing\n1.7 Did You Know? \n \nPhotographic film has the clear advantage of \nrecording extremely fine spatial detail, since \nindividual silver halide molecules can record \nlight sensitivity differently than their \nneighbouring molecules. But when it comes \nto spectral and radiometric qualities, digital \nsensors outperform film, by being able to use \nextremely fine spectral bands (for spectral \n'fingerprinting' of targets), and recording up \nto many thousands of levels of brightness. \n\n \n1. Whiz Quiz and Answers \n \n \n1.1 Whiz Quiz \n \nCan \"remote sensing\" employ anything other than electromagnetic radiation?    \nPage 27Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.1 Whiz Quiz - Answer \nWhile the term 'remote sensing' typically assumes the use of electromagnetic radiation, the \nmore general definition of 'acquiring information at a distance', does not preclude other forms \nof energy. The use of sound is an obvious alternative; thus you can claim that your telephone \nconversation is indeed 'remote sensing'. \n\n1.2 Whiz Quiz \nThe first requirement for remote sensing is an energy source which can illuminate a target. \nWhat is the obvious source of electromagnetic energy that you can think of? What \"remote \nsensing device\" do you personally use to detect this energy?    \n  \nAssume the speed of light to be 3x10\n8\n m/s. If the frequency of an \nelectromagnetic wave is 500,000 GHz (GHz = gigahertz = 10\n9\n m/s), what is \nthe wavelength of that radiation? Express your answer in micrometres\n(\nμ\nm).  \n  \n  \nPage 28Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.2 Whiz Quiz - Answers \nAnswer 1:\n The most obvious source of electromagnetic energy and radiation is the sun. The \nsun provides the initial energy source for much of the remote sensing of the Earth surface. \nThe remote sensing device that we humans use to detect radiation from the sun is our eyes. \nYes, they can be considered remote sensors - and very good ones - as they detect the visible \nlight from the sun, which allows us to see. There are other types of light which are invisible to \nus...but more about that later. \nAnswer 2:\n Using the equation for the relationship between wavelength and frequency, let's \ncalculate the wavelength of radiation of a frequency of 500,000 GHz. \n\n1.3 Whiz Quiz \nThe infrared portion of the electromagnetic spectrum has two parts: the reflective and the \nemissive. Can you take photographs in these wavelength ranges?       \n \n  \nPage 29Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.3 Whiz Quiz - Answer \nYes and no. There are photographic films in black and white as well as colour emulsions, \nwhich are sensitive to the reflective portion of the infrared band and these are used for \nscientific and artistic purposes too. But no photographic films exist to directly record emissive \ninfrared (heat). If they did, then they would have to be cooled (and kept very cold during use), \nwhich would be very impractical. However there are a number of electronic devices which \ndetect and record thermal infrared images. \n\n1.4 Whiz Quiz \n1. Most remote sensing systems avoid detecting and recording \nwavelengths in the ultraviolet and blue portions of the \nspectrum. Explain why this would be the case.    \nis ... \n  \n2. What do you think would be some of the best atmospheric \nconditions for remote sensing in the visible portion of the \nspectrum?     \n  \nPage 30Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.4 Whiz Quiz - Answer \n1. Detecting and recording the ultraviolet and blue wavelengths \nof radiation is difficult because of scattering and absorption in \nthe atmosphere. Ozone gas in the upper atmosphere absorbs \nmost of the ultraviolet radiation of wavelengths shorter than \nabout 0.25 mm. This is actually a positive thing for us and most \nother living things, because of the harmful nature of ultraviolet \nradiation below these wavelengths. Rayleigh scattering, which \naffects the shorter wavelengths more severely than longer \nwavelengths, causes the remaining UV radiation and the \nshorter visible wavelengths (i.e. blue) to be scattered much \nmore than longer wavelengths, so that very little of this energy \nis able to reach and interact with the Earth's surface. In fact, \nblue light is scattered about 4 times as much as red light, while \nUV light is scattered 16 times as much as red light! \n  \n2. Around noon on a sunny, dry day with no clouds and \nno pollution would be very good for remote sensing in \nthe visible wavelengths. At noon the sun would be at \nits most directly overhead point, which would reduce \nthe distance the radiation has to travel and therefore \nthe effects of scattering, to a minimum. Cloud-free \nconditions would ensure that there will be uniform \nillumination and that there will be no shadows from clouds. Dry, pollutant-free conditions \nwould minimize the scattering and absorption that would take place due to water droplets and \nother particles in the atmosphere. \n\n1.5 Whiz Quiz \n \nOn a clear night with the crescent or half moon showing, it is possible to see the outline and \nperhaps very slight detail of the dark portion of the moon. Where is the light coming from, that \nilluminates the dark side of the moon? \nPage 31Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.5 Whiz Quiz - Answer \n \nThe light originates from the sun (of course), hits the earth, bounces up to the (dark side of \nthe) moon and then comes back to the earth and into your eye. A long way around - isn't it? \n\n1.6 Whiz Quiz \n \nIs there a passive equivalent to the radar sensor? \nPage 32Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.6 Whiz Quiz - Answer \nIndeed. The passive microwave radiometer, for instance, does not carry an illumination \nsource, relying instead on detecting naturally emitted microwave energy. Such an instrument \ncan be used for detecting, identifying and measuring marine oil slicks, for instance. \n\n1.7 Whiz Quiz \n \n1. If you wanted to map the deciduous (e.g. maple, birch) and the coniferous (e.g. pine, fir, \nspruce) trees in a forest in summer using remote sensing data, what would be the best way to \ngo about this and why? Use the reflectance curves illustrating the spectral response patterns \nof these two categories to help explain your answer. \n2. What would be the advantage of displaying various wavelength ranges, or channels, in \ncombination as colour images as opposed to examining each of the images individually? \n \nPage 33Section 1 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n1.7 Whiz Quiz - Answer \n1. Because both types of trees will appear as similar shades of green to the naked eye, \nimagery (or photography) using the visible portion of the spectrum may not be useful. Trying \nto distinguish the different types from aerial photographs based on tree crown shape or size \nmight also be difficult, particularly when the tree types are intermixed. Looking at the \nreflectance curves for the two types, it is clear that they would be difficult to distinguish using \nany of the visible wavelengths. However, in the near-infrared, although both types reflect a \nsignificant portion of the incident radiation, they are clearly separable. Thus, a remote sensing \nsystem, such as black and white infrared film, which detects the infrared reflectance around \n0.8 mm wavelength would be ideal for this purpose.  \n2. By combining different channels of imagery representing different wavelengths, we may be \nable to identify combinations of reflectance between the different channels which highlight \nfeatures that we would not otherwise be able to see, if we examine only one channel at a \ntime. Additionally, these combinations may manifest themselves as subtle variations in colour \n(which our eyes are more sensitive to), rather than variations in gray tone, as would be seen \nwhen examining only one image at a time. \n\n2. Satellites and Sensors\n \n \n2.1 On the Ground, In the Air, In Space \nIn Chapter 1 we learned some of the \nfundamental concepts required to understand \nthe process that encompasses remote \nsensing. We covered in some detail the first \nthree components of this process: the energy \nsource, interaction of energy with the \natmosphere, and interaction of energy with the \nsurface. We touched briefly on the fourth \ncomponent - \nrecording of energy by the \nsensor\n - when we discussed passive vs. \nactive sensors and characteristics of images. \nIn this chapter, we will take a closer look at \nthis component of the remote sensing process \nby examining in greater detail, the characteristics of remote sensing platforms and sensors \nand the data they collect. We will also touch briefly on how those data are processed once \nthey have been recorded by the sensor. \nIn order for a sensor to collect and record energy \nreflected or emitted from a target or surface, it must \nreside on a stable \nplatform\n removed from the target or \nsurface being observed. Platforms for remote sensors \nmay be situated on the ground, on an aircraft or balloon \n(or some other platform within the Earth's atmosphere), \nor on a spacecraft or satellite outside of the Earth's \natmosphere. \n  \nGround-based sensors\n are often used to record detailed information about the surface \nwhich is compared with information collected from aircraft or satellite sensors. In some cases, \nPage 34Section 2.1 On the Ground, In the Air, In Space\nCanada Centre for Remote Sensing\n\nthis can be used to better characterize the target which is being imaged by these other \nsensors, making it possible to better understand the information in the imagery. \n  \nSensors may be placed on a ladder, \nscaffolding, tall building, cherry-picker, crane, \netc. Aerial platforms are primarily stable wing \naircraft\n, although helicopters are occasionally \nused. Aircraft are often used to collect very \ndetailed images and facilitate the collection of \ndata over virtually any portion of the Earth's \nsurface at any time. \n  \nIn space, remote sensing is sometimes conducted \nfrom the \nspace shuttle\n or, more commonly, from \nsatellites. \nSatellites\n are objects which revolve around \nanother object - in this case, the Earth. For example, \nthe moon is a natural satellite, whereas man-made \nsatellites include those platforms launched for remote \nsensing, communication, and telemetry (location and \nnavigation) purposes. Because of their orbits, \nsatellites permit repetitive coverage of the Earth's \nsurface on a continuing basis. Cost is often a \nsignificant factor in choosing among the various platform options.  \n \nPage 35Section 2.1 On the Ground, In the Air, In Space\nCanada Centre for Remote Sensing\n\n2.2 Satellite Characteristics: Orbits and Swaths \nWe learned in the previous section that remote sensing instruments can be placed on a \nvariety of platforms to view and image targets. Although ground-based and aircraft platforms \nmay be used, satellites provide a great deal of the remote sensing imagery commonly used \ntoday. Satellites have several unique characteristics which make them particularly useful for \nremote sensing of the Earth's surface. \nThe path followed by a satellite is referred to as its \norbit\n. Satellite orbits are matched to the capability \nand objective of the sensor(s) they carry. Orbit \nselection can vary in terms of altitude (their height \nabove the Earth's surface) and their orientation and \nrotation relative to the Earth. Satellites at very high \naltitudes, which view the same portion of the \nEarth's surface at all times have \ngeostationary \norbits\n. These geostationary satellites, at altitudes \nof approximately 36,000 kilometres, revolve at \nspeeds which match the rotation of the Earth so \nthey seem stationary, relative to the Earth's \nsurface. This allows the satellites to observe and collect information continuously over specific \nareas. Weather and communications satellites commonly have these types of orbits. Due to \ntheir high altitude, some geostationary weather satellites can monitor weather and cloud \npatterns covering an entire hemisphere of the Earth. \nMany remote sensing platforms are designed to follow an \norbit (basically north-south) which, in conjunction with the \nEarth's rotation (west-east), allows them to cover most of the \nEarth's surface over a certain period of time. These are \nnear-\npolar orbits\n, so named for the inclination of the orbit relative \nto a line running between the North and South poles. Many of \nthese satellite orbits are also \nsun-synchronous\n such that \nthey cover each area of the world at a constant local time of \nday called \nlocal sun time\n. At any given latitude, the position \nof the sun in the sky as the satellite passes overhead will be \nthe same within the same season. This ensures consistent \nillumination conditions when acquiring images in a specific \nseason over successive years, or over a particular area over \na series of days. This is an important factor for monitoring \nchanges between images or for mosaicking adjacent images \ntogether, as they do not have to be corrected for different \nillumination conditions. \n  \nPage 36Section 2.2 Satellite Characteristics: Orbits and Swaths\nCanada Centre for Remote Sensing\n\n  \nMost of the remote sensing satellite platforms today \nare in near-polar orbits, which means that the satellite \ntravels northwards on one side of the Earth and then \ntoward the southern pole on the second half of its \norbit. These are called \nascending and descending \npasses\n, respectively. If the orbit is also sun-\nsynchronous, the ascending pass is most likely on the \nshadowed side of the Earth while the descending \npass is on the sunlit side. Sensors recording reflected \nsolar energy only image the surface on a descending \npass, when solar illumination is available. Active \nsensors which provide their own illumination or \npassive sensors that record emitted (e.g. thermal) \nradiation can also image the surface on ascending \npasses. \n  \n  \nAs a satellite revolves around the Earth, the sensor \n\"sees\" a certain portion of the Earth's surface. The area \nimaged on the surface, is referred to as the \nswath\n. \nImaging swaths for spaceborne sensors generally vary \nbetween tens and hundreds of kilometres wide. As the \nsatellite orbits the Earth from pole to pole, its east-west \nposition wouldn't change if the Earth didn't rotate. \nHowever, as seen from the Earth, it seems that the \nsatellite is shifting westward because the Earth is rotating \n(from west to east) beneath it. This apparent movement \nallows the satellite swath to cover a \nnew area with each \nconsecutive pass\n. The satellite's orbit and the rotation o\nf \nthe Earth work together to allow complete coverage of \nthe Earth's surface, after it has completed one complete cycle of orbits. \n  \n  \n  \n  \n \nPage 37Section 2.2 Satellite Characteristics: Orbits and Swaths\nCanada Centre for Remote Sensing\n\n \n \n \n \n \n \n \n  \n \n  \n  \nIf we start with any randomly selected pass \nin a satellite's orbit, an orbit cycle will be \ncompleted when the satellite retraces its \npath, passing over the same point on the \nEarth's surface directly below the satellite \n(called the \nnadir\n point) for a second time. \nThe exact length of time of the orbital cycle \nwill vary with each satellite. The interval of \ntime required for the satellite to complete its \norbit cycle is not the same as the \"\nrevisit \nperiod\n\". Using steerable sensors, an \nsatellite-borne instrument can view an area (off-nadir) before and after the orbit passes over a \ntarget, thus making the 'revisit' time less than the orbit cycle time. The revisit period is an \nimportant consideration for a number of monitoring applications, especially when frequent \nimaging is required (for example, to monitor the spread of an oil spill, or the extent of \nflooding). In near-polar orbits, areas at high latitudes will be imaged more frequently than the \nequatorial zone due to the increasing \noverlap in adjacent swaths\n as the orbit paths come \ncloser together near the poles. \n \nPage 38Section 2.2 Satellite Characteristics: Orbits and Swaths\nCanada Centre for Remote Sensing\n\n2.3 Spatial Resolution, Pixel Size, and Scale \nFor some remote sensing instruments, the distance between the target being imaged and the \nplatform, plays a large role in determining the detail of information obtained and the total area \nimaged by the sensor. Sensors onboard platforms far away from their targets, typically view a \nlarger area, but cannot provide great detail. Compare what an astronaut onboard the space \nshuttle sees of the Earth to what you can see from an airplane. The astronaut might see your \nwhole province or country in one glance, but couldn't distinguish individual houses. Flying ove\nr\na city or town, you would be able to see individual buildings and cars, but you would be \nviewing a much smaller area than the astronaut. There is a similar difference between satellite \nimages and airphotos. \nThe detail discernible in an image is dependent on the \nspatial resolution\n of the sensor and refers to the size of \nthe smallest possible feature that can be detected. \nSpatial resolution of passive sensors (we will look at the \nspecial case of active microwave sensors later) depends \nprimarily on their \nInstantaneous Field of View (IFOV)\n. \nThe IFOV is the angular cone of visibility of the sensor (A) \nand determines the area on the Earth's surface which is \n\"seen\" from a given altitude at one particular moment in \ntime (B). The size of the area viewed is determined by \nmultiplying the IFOV by the distance from the ground to \nthe sensor (C). This area on the ground is called the \nresolution cell\n and determines a sensor's maximum \nspatial resolution. For a homogeneous feature to be \ndetected, its size generally has to be equal to or larger than the resolution cell. If the feature is \nsmaller than this, it may not be detectable as the average brightness of all features in that \nresolution cell will be recorded. However, smaller features may sometimes be detectable if \ntheir reflectance dominates within a articular resolution cell allowing sub-pixel or resolution cell \ndetection. \nAs we mentioned in Chapter 1, most remote sensing images are composed of a matrix of \npicture elements, or \npixels\n, which are the smallest units of an image. Image pixels are \nnormally square and represent a certain area on an image. It is important to distinguish \nbetween pixel size and spatial resolution - they are not interchangeable. If a sensor has a \nspatial resolution of 20 metres and an image from that sensor is displayed at full resolution, \neach pixel represents an area of 20m x 20m on the ground. In this case the pixel size and \nresolution are the same. However, it is possible to display an image with a pixel size different \nthan the resolution. Many posters of satellite images of the Earth have their pixels averaged to \nrepresent larger areas, although the original spatial resolution of the sensor that collected the \nimagery remains the same. \n  \nPage 39Section 2.3 Spatial Resolution, Pixel Size, and Scale\nCanada Centre for Remote Sensing\n\n  \n  \n  \n  \nImages where only large features are visible are said to have \ncoarse or low resolution.\n In \nfine or high resolution\n images, small objects can be detected. Military sensors for example, \nare designed to view as much detail as possible, and therefore have very fine resolution. \nCommercial satellites provide imagery with resolutions varying from a few metres to several \nkilometres. Generally speaking, the finer the resolution, the less total ground area can be \nseen.  \nThe ratio of distance on an image or map, to actual ground distance is referred to as scale. If \nyou had a map with a scale of 1:100,000, an object of 1cm length on the map would actually \nbe an object 100,000cm (1km) long on the ground. Maps or images with small \"map-to-ground \nratios\" are referred to as small scale (e.g. 1:100,000), and those with larger ratios (e.g. \n1:5,000) are called large scale. \nPage 40Section 2.3 Spatial Resolution, Pixel Size, and Scale\nCanada Centre for Remote Sensing\n\n2.4 Spectral Resolution \n \nIn Chapter 1, we learned about \nspectral response\n and \nspectral emissivity curves\n which \ncharacterize the reflectance and/or emittance of a feature or target over a variety of \nwavelengths. Different classes of features and details in an image can often be distinguished \nby comparing their responses over distinct wavelength ranges. Broad classes, such as water \nand vegetation, can usually be separated using very broad wavelength ranges - the visible \nand near infrared - as we learned in section 1.5. Other more specific classes, such as \ndifferent rock types\n, may not be easily distinguishable using either of these broad \nwavelength ranges and would require comparison at much finer wavelength ranges to \nseparate them. Thus, we would require a sensor with higher \nspectral resolution\n. Spectral \nresolution describes the ability of a sensor to define fine wavelength intervals. The finer the \nspectral resolution, the narrower the wavelength range for a particular channel or band. \n  \nBlack and white film records wavelengths extending over much, or all of the visible portion of \nthe electromagnetic spectrum. Its \nspectral resolution\n is fairly coarse, as the various \nwavelengths of the visible spectrum are not individually distinguished and the overall \nPage 41Section 2.4 Spectral Resolution\nCanada Centre for Remote Sensing\n\nreflectance in the entire visible portion is recorded. Colour film is also sensitive to the reflected \nenergy over the visible portion of the spectrum, but has higher spectral resolution, as it is \nindividually sensitive to the reflected energy at the blue, green, and red wavelengths of the \nspectrum. Thus, it can represent features of various colours based on their reflectance in each \nof these distinct wavelength ranges. \nMany remote sensing systems record energy over several separate wavelength ranges at \nvarious spectral resolutions. These are referred to as \nmulti-spectral sensors\n and will be \ndescribed in some detail in following sections. Advanced multi-spectral sensors called \nhyperspectral\n sensors, detect hundreds of very narrow spectral bands throughout the visible, \nnear-infrared, and mid-infrared portions of the electromagnetic spectrum. Their very high \nspectral resolution facilitates fine discrimination between different targets based on their \nspectral response in each of the narrow bands. \nPage 42Section 2.4 Spectral Resolution\nCanada Centre for Remote Sensing\n\n2.5 Radiometric Resolution \nWhile the arrangement of pixels describes the spatial structure of an image, the radiometric \ncharacteristics describe the actual information content in an image. Every time an image is \nacquired on film or by a sensor, its sensitivity to the magnitude of the electromagnetic energy \ndetermines the \nradiometric resolution\n. The radiometric resolution of an imaging system \ndescribes its ability to discriminate very slight differences in energy The finer the radiometric \nresolution of a sensor, the more sensitive it is to detecting small differences in reflected or \nemitted energy. \n \nImagery data are represented by positive digital numbers which vary from 0 to (one less than) \na selected power of 2. This range corresponds to the number of bits used for coding numbers \nin binary format. Each bit records an exponent of power 2 (e.g. 1 bit=2 \n1\n=2). The maximum \nnumber of brightness levels available depends on the number of bits used in representing the \nenergy recorded. Thus, if a sensor used 8 bits to record the data, there would be 2\n8\n=256 \ndigital values available, ranging from 0 to 255. However, if only 4 bits were used, then only \n2\n4\n=16 values ranging from 0 to 15 would be available. Thus, the radiometric resolution would \nbe much less. Image data are generally displayed in a range of grey tones, with black \nrepresenting a digital number of 0 and white representing the maximum value (for example, \n255 in 8-bit data). By \ncomparing a 2-bit image with an 8-bit image\n, we can see that there is \na large difference in the level of detail discernible depending on their radiometric resolutions. \nPage 43Section 2.5 Radiometric Resolution\nCanada Centre for Remote Sensing\n\n2.6 Temporal Resolution \nIn addition to spatial, spectral, and radiometric resolution, the concept of \ntemporal resolution\nis also important to consider in a remote sensing system. We alluded to this idea in section \n2.2 when we discussed the concept of revisit period, which refers to the length of time it takes \nfor a satellite to complete one entire orbit cycle. The revisit period of a satellite sensor is \nusually several days. Therefore the absolute temporal resolution of a remote sensing system \nto image the exact same area at the same viewing angle a second time is equal to this period. \nHowever, because of some degree of overlap in the imaging swaths of adjacent orbits for \nmost satellites and the increase in this overlap with increasing latitude, some areas of the \nEarth tend to be re-imaged more frequently. Also, some satellite systems are able to \npoint \ntheir sensors to image the same area\n between different satellite passes separated by \nperiods from one to five days. Thus, the actual temporal resolution of a sensor depends on a \nvariety of factors, including the satellite/sensor capabilities, the swath overlap, and latitude.  \n  \nThe ability to collect imagery of the same area of the Earth's surface at different periods of \ntime is one of the most important elements for applying remote sensing data. Spectral \ncharacteristics of features may change over time and these changes can be detected by \ncollecting and comparing \nmulti-temporal\n imagery. For example, during the growing season, \nmost species of vegetation are in a continual state of change and our ability to monitor those \nsubtle changes using remote sensing is dependent on when and how frequently we collect \nimagery. By imaging on a continuing basis at different times we are able to monitor the \nchanges that take place on the Earth's surface, whether they are naturally occurring (such as \nchanges in natural vegetation cover or flooding) or induced by humans (such as urban \ndevelopment or deforestation). The time factor in imaging is important when: \n\npersistent clouds offer limited clear views of the Earth's surface (often in the tropics)  \n\nshort-lived phenomena (floods, oil slicks, etc.) need to be imaged  \n\nmulti-temporal comparisons are required (e.g. the spread of a forest disease from one \nyear to the next)  \n\nthe changing appearance of a feature over time can be used to distinguish it from near-\nsimilar features (wheat / maize)  \nPage 44Section 2.6 Temporal Resolution\nCanada Centre for Remote Sensing\n\n2.7 Cameras and Aerial Photography \nCameras and their use for aerial photography are the simplest and \noldest of sensors used for remote sensing of the Earth's surface. \nCameras are \nframing systems\n which acquire a near-instantaneous \n\"snapshot\" of an \narea (A)\n, of the surface. Camera systems are \npassive optical sensors that use a \nlens (B)\n (or system of lenses \ncollectively referred to as the optics) to form an image at the focal \nplane (C), the plane at which an image is sharply defined.  \nPhotographic films are sensitive to light from 0.3 \nμ\nm to 0.9 \nμ\nm in \nwavelength covering the ultraviolet (UV), visible, and near-infrared \n(NIR). \nPanchromatic\n films are sensitive to the UV and the visible \nportions of the spectrum. Panchromatic film produces black and white \nimages and is the most common type of film used for aerial \nphotography. UV photography also uses panchromatic film, but a filter is used with the \ncamera to absorb and block the visible energy from reaching the film. As a result, only the UV \nreflectance from targets is recorded. UV photography is not widely used, because of the \natmospheric scattering and absorption that occurs in this region of the spectrum. Black and \nwhite infrared photography uses film sensitive to the entire 0.3 to 0.9 \nμ\nm wavelength range \nand is useful for detecting differences in vegetation cover, due to its sensitivity to IR \nreflectance. \n  \n  \nColour and false colour (or colour infrared, CIR) photography involves the use of a three layer \nfilm with each layer sensitive to different ranges of light. For a \nnormal colour photograph\n, \nthe layers are sensitive to blue, green, and red light - the same as our eyes. These photos \nappear to us the same way that our eyes see the environment, as the colours resemble those \nwhich would appear to us as \"normal\" (i.e. trees appear green, etc.). In colour infrared (CIR) \nphotography, the three emulsion layers are sensitive to green, red, and the photographic \nportion of near-infrared radiation, which are processed to appear as blue, green, and red, \nPage 45Section 2.7 Cameras and Aerial Photography\nCanada Centre for Remote Sensing\n\nrespectively. In a \nfalse colour photograph\n, targets with high near-infrared reflectance appear \nred, those with a high red reflectance appear green, and those with a high green reflectance \nappear blue, thus giving us a \"false\" presentation of the targets relative to the colour we \nnormally perceive them to be. \n  \nCameras can be used on a variety of platforms including ground-based stages, helicopters, \naircraft, and spacecraft. Very detailed photographs taken from aircraft are useful for many \napplications where identification of detail or small targets is required. The ground coverage of \na photo depends on several factors, including the focal length of the lens, the platform \naltitude, and the format and size of the film. The focal length effectively controls the \nangular \nfield of view\n of the lens (similar to the concept of instantaneous field of view discussed in \nsection 2.3) and determines the area \"seen\" by the camera. Typical focal lengths used are \n90mm, 210mm, and most commonly, 152mm. The longer the focal length, the smaller the \narea covered on the ground, but with greater detail (i.e. larger scale). The area covered also \ndepends on the altitude of the platform. At high altitudes, a camera will \"see\" a larger area on \nthe ground than at lower altitudes, but with reduced detail (i.e. smaller scale). Aerial photos \ncan provide fine detail down to spatial resolutions of less than 50 cm. A photo's exact spatial \nresolution varies as a complex function of many factors which vary with each acquisition of \ndata. \nMost aerial photographs are classified as either \noblique\n or \nvertical\n, depending on the \norientation of the camera relative to the ground \nduring acquisition. \nOblique aerial \nphotographs\n are taken with the camera \npointed to the side of the aircraft. High oblique \nphotographs usually include the horizon while \nlow oblique photographs do not. Oblique \nphotographs can be useful for covering very \nlarge areas in a single image and for depicting \nterrain relief and scale. However, they are not widely used for mapping as distortions in scale \nfrom the foreground to the background preclude easy measurements of distance, area, and \nelevation. \nVertical photographs\n taken with a single-lens frame camera is the most common use of \naerial photography for remote sensing and mapping purposes. These cameras are specifically \nbuilt for capturing a rapid sequence of photographs while limiting geometric distortion. They \nare often linked with navigation systems onboard the aircraft platform, to allow for accurate \ngeographic coordinates to be instantly assigned to each photograph. Most camera systems \nalso include mechanisms which compensate for the effect of the aircraft motion relative to the \nground, in order to limit distortion as much as possible. \n  \nPage 46Section 2.7 Cameras and Aerial Photography\nCanada Centre for Remote Sensing\n\nsystems, but typically ranges between 512 x 512 to 2048 x 2048.  When obtaining vertical aerial photographs, \nthe aircraft normally flies in a series of \nlines, each called a \nflight line\n. Photos are \ntaken in rapid succession looking straight \ndown at the ground, often with a 50-60 \npercent overlap (A) between successive \nphotos. The overlap ensures total coverage \nalong a flight line and also facilitates \nstereoscopic viewing\n. Successive photo \npairs display the overlap region from \ndifferent perspectives and can be viewed \nthrough a device called a \nstereoscope\n to \nsee a three-dimensional view of the area, \ncalled a \nstereo model\n. Many applications \nof aerial photography use stereoscopic coverage and stereo viewing. \nAerial photographs are most useful when fine spatial detail is more critical than spectral \ninformation, as their spectral resolution is generally coarse when compared to data captured \nwith electronic sensing devices. The geometry of vertical photographs is well understood and \nit is possible to make very accurate measurements from them, for a variety of different \napplications (geology, forestry, mapping, etc.). The science of making measurements from \nphotographs is called \nphotogrammetry\n and has been performed extensively since the very \nbeginnings of aerial photography. Photos are most often interpreted manually by a human \nanalyst (often viewed stereoscopically). They can also be scanned to create a digital image \nand then analyzed in a digital computer environment. In Chapter 4, we will discuss in greater \ndetail, various methods (manually and by computer) for interpreting different types of remote \nsensing images. \nMultiband photography\n uses multi-lens systems with different film-filter combinations to \nacquire photos simultaneously in a number of different spectral ranges. The advantage of \nthese types of cameras is their ability to record reflected energy separately in discrete \nwavelength ranges, thus providing potentially better separation and identification of various \nfeatures. However, simultaneous analysis of these multiple photographs can be problematic. \nDigital cameras\n, which record electromagnetic radiation electronically, differ significantly from \ntheir counterparts which use film. Instead of using film, digital cameras use a gridded array of \nsilicon coated CCDs (charge-coupled devices) that individually respond to electromagnetic \nradiation. Energy reaching the surface of the CCDs causes the generation of an electronic \ncharge which is proportional in magnitude to the \"brightness\" of the ground area. A digital \nnumber for each spectral band is assigned to each pixel based on the magnitude of the \nelectronic charge. The digital format of the output image is amenable to digital analysis and \narchiving in a computer environment, as well as output as a hardcopy product similar to \nregular photos. Digital cameras also provide quicker turn-around for acquisition and retrieval \nof data and allow greater control of the spectral resolution. Although parameters vary, digital \nimaging systems are capable of collecting data with a spatial resolution of 0.3m, and with a \nspectral resolution of 0.012 mm to 0.3 mm. The size of the pixel arrays varies between \nPage 47Section 2.7 Cameras and Aerial Photography\nCanada Centre for Remote Sensing\nsystems, but typically ranges between 512 x 512 to 2048 x 2048.  \n\n2.8 Multispectral Scanning \nMany electronic (as opposed to photographic) remote sensors acquire data using \nscanning \nsystems\n, which employ a sensor with a narrow field of view (i.e. IFOV) that sweeps over the \nterrain to build up and produce a two-dimensional image of the surface. Scanning systems \ncan be used on both aircraft and satellite platforms and have essentially the same operating \nprinciples. A scanning system used to collect data over a variety of different wavelength \nranges is called a \nmultispectral scanner (MSS)\n, and is the most commonly used scanning \nsystem. There are two main modes or methods of scanning employed to acquire multispectral \nimage data - \nacross-track scanning\n, and \nalong-track scanning\n. \nAcross-track scanners\n scan the Earth in a \nseries of lines. The lines are oriented \nperpendicular to the direction of motion of the \nsensor platform (i.e. across the swath). Each line \nis scanned from one side of the sensor to the \nother, using a \nrotating mirror (A)\n. As the \nplatform moves forward over the Earth, \nsuccessive scans build up a two-dimensional \nimage of the Earth ́s surface. The incoming \nreflected or emitted radiation is separated into \nseveral spectral components that are detected \nindependently. The UV, visible, near-infrared, \nand thermal radiation are dispersed into their \nconstituent wavelengths. A bank of internal \ndetectors (B)\n, each sensitive to a specific range \nof wavelengths, detects and measures the energy for each spectral band and then, as an \nelectrical signal, they are converted to digital data and recorded for subsequent computer \nprocessing. \n  \nThe \nIFOV (C)\n of the sensor and the altitude of the platform determine the \nground resolution \ncell viewed (D)\n, and thus the spatial resolution. The \nangular field of view (E)\n is the sweep of \nthe mirror, measured in degrees, used to record a scan line, and determines the width of the \nimaged \nswath (F)\n. Airborne scanners typically sweep large angles (between 90º and 120º), \nwhile satellites, because of their higher altitude need only to sweep fairly small angles (10-\n20º) to cover a broad region. Because the distance from the sensor to the target increases \ntowards the edges of the swath, the ground resolution cells also become larger and introduce \ngeometric distortions to the images. Also, the length of time the IFOV \"sees\" a ground \nresolution cell as the rotating mirror scans (called the \ndwell time\n), is generally quite short and \ninfluences the design of the spatial, spectral, and radiometric resolution of the sensor. \n  \n  \nPage 48Section 2.8 Multispectral Scanning\nCanada Centre for Remote Sensing\n\n  \nAlong-track scanners\n also use the forward motion \nof the platform to record successive scan lines and \nbuild up a two-dimensional image, perpendicular to \nthe flight direction. However, instead of a scanning \nmirror, they use a linear array of detectors (A) \nlocated at the focal plane of the image (B) formed \nby lens systems (C), which are \"pushed\" along in \nthe flight track direction (i.e. along track). These \nsystems are also referred to as \npushbroom \nscanners\n, as the motion of the detector array is \nanalogous to the bristles of a broom being pushed \nalong a floor. Each individual detector measures the \nenergy for a single ground resolution cell (D) and \nthus the size and IFOV of the detectors determines \nthe spatial resolution of the system. A separate linear array is required to measure each \nspectral band or channel. For each scan line, the energy detected by each detector of each \nlinear array is sampled electronically and digitally recorded. \nAlong-track scanners with linear arrays have several advantages over across-track mirror \nscanners. The array of detectors combined with the pushbroom motion allows each detector \nto \"see\" and measure the energy from each ground resolution cell for a longer period of time \n(dwell time). This allows more energy to be detected and improves the radiometric resolution. \nThe increased dwell time also facilitates smaller IFOVs and narrower bandwidths for each \ndetector. Thus, finer spatial and spectral resolution can be achieved without impacting \nradiometric resolution. Because detectors are usually solid-state microelectronic devices, they \nare generally smaller, lighter, require less power, and are more reliable and last longer \nbecause they have no moving parts. On the other hand, cross-calibrating thousands of \ndetectors to achieve uniform sensitivity across the array is necessary and complicated. \nRegardless of whether the scanning system used is either of these two types, it has several \nadvantages over photographic systems. The spectral range of photographic systems is \nrestricted to the visible and near-infrared regions while MSS systems can extend this range \ninto the thermal infrared. They are also capable of much higher spectral resolution than \nphotographic systems. Multi-band or multispectral photographic systems use separate lens \nsystems to acquire each spectral band. This may cause problems in ensuring that the \ndifferent bands are comparable both spatially and radiometrically and with registration of the \nmultiple images. MSS systems acquire all spectral bands simultaneously through the same \noptical system to alleviate these problems. Photographic systems record the energy detected \nby means of a photochemical process which is difficult to measure and to make consistent. \nBecause MSS data are recorded electronically, it is easier to determine the specific amount of \nenergy measured, and they can record over a greater range of values in a digital format. \nPhotographic systems require a continuous supply of film and processing on the ground after \nthe photos have been taken. The digital recording in MSS systems facilitates transmission of \nPage 49Section 2.8 Multispectral Scanning\nCanada Centre for Remote Sensing\ndata to receiving stations on the ground and immediate processing of data in a computer \nenvironment. \n\n2.9 Thermal Imaging \nMany multispectral (MSS) systems sense radiation in the thermal infrared as well as the \nvisible and reflected infrared portions of the spectrum. However, remote sensing of energy \nemitted from the Earth's surface in the thermal infrared (3 \nμ\nm to 15 \nμ\nm) is different than the \nsensing of reflected energy. \nThermal sensors\n use photo detectors sensitive to the direct \ncontact of photons on their surface, to detect emitted thermal radiation. The detectors are \ncooled to temperatures close to absolute zero in order to limit their own thermal emissions. \nThermal sensors essentially measure the surface temperature and thermal properties of \ntargets. \n \nThermal imagers\n are typically across-track \nscanners (like those described in the previous \nsection) that detect emitted radiation in only the \nthermal portion of the spectrum. Thermal sensors \nemploy one or more internal temperature \nreferences for comparison with the detected \nradiation, so they can be related to absolute radiant \ntemperature. The data are generally recorded on \nfilm and/or magnetic tape and the temperature \nresolution of current sensors can reach 0.1 °C. For \nanalysis, an image of relative radiant temperatures \n(\na thermogram\n) is depicted in grey levels, with warmer temperatures shown in light tones, \nand cooler temperatures in dark tones. Imagery which portrays relative temperature \ndifferences in their relative spatial locations are sufficient for most applications. Absolute \ntemperature measurements may be calculated but require accurate calibration and \nmeasurement of the temperature references and detailed knowledge of the thermal properties \nof the target, geometric distortions, and radiometric effects. \nBecause of the relatively long wavelength of thermal radiation (compared to visible radiation), \natmospheric scattering is minimal. However, absorption by atmospheric gases normally \nPage 50Section 2.9 Thermal Imaging\nCanada Centre for Remote Sensing\n\nrestricts thermal sensing to two specific regions - 3 to 5 \nμ\nm and 8 to 14 \nμ\nm. Because energy \ndecreases as the wavelength increases, thermal sensors generally have large IFOVs to \nensure that enough energy reaches the detector in order to make a reliable measurement. \nTherefore the spatial resolution of thermal sensors is usually fairly coarse, relative to the \nspatial resolution possible in the visible and reflected infrared. Thermal imagery can be \nacquired during the day or night (because the radiation is emitted not reflected) and is used \nfor a variety of applications such as military reconnaissance, disaster management (forest fire \nmapping), and heat loss monitoring. \nPage 51Section 2.9 Thermal Imaging\nCanada Centre for Remote Sensing\n\n2.10 Geometric Distortion in Imagery \nAny remote sensing image, regardless of whether it is acquired by a multispectral scanner on \nboard a satellite, a photographic system in an aircraft, or any other platform/sensor \ncombination, will have various geometric distortions. This problem is inherent in remote \nsensing, as we attempt to accurately represent the three-dimensional surface of the Earth as \na two-dimensional image. All remote sensing images are subject to some form of geometric \ndistortions, depending on the manner in which the data are acquired. These errors may be \ndue to a variety of factors, including one or more of the following, to name only a few:  \n\nthe perspective of the sensor optics,  \n\nthe motion of the scanning system,  \n\nthe motion and (in)stability of the platform,  \n\nthe platform altitude, attitude, and velocity,  \n\nthe terrain relief, and  \n\nthe curvature and rotation of the Earth.  \n \nFraming systems, such as cameras used for aerial photography, provide an instantaneous \n\"snapshot\" view of the Earth from directly overhead. The primary geometric distortion in \nvertical aerial photographs is due to \nrelief displacement\n. Objects directly below the centre of \nthe camera lens (i.e. at the \nnadir\n) will have only their tops visible, while all other objects will \nappear to lean away from the centre of the photo such that their tops and sides are visible. If \nthe objects are tall or are far away from the centre of the photo, the distortion and positional \nerror will be larger. \nThe geometry of along-track scanner imagery is similar to that of an aerial photograph for \neach scan line as each detector essentially takes a \"snapshot\" of each ground resolution cell. \nGeometric variations between lines are caused by random variations in platform altitude and \nattitude along the direction of flight. \n  \nPage 52Section 2.10 Geometric Distortion in Imagery\nCanada Centre for Remote Sensing\n\n \nImages from across-track scanning systems exhibit two main types of \ngeometric distortion\n. \nThey too exhibit relief displacement (A), similar to aerial photographs, but in only one direction \nparallel to the direction of scan. There is no displacement directly below the sensor, at nadir. \nAs the sensor scans across the swath, the top and side of objects are imaged and appear to \nlean away from the nadir point in each scan line. Again, the displacement increases, moving \ntowards the edges of the swath. Another distortion (B) occurs due to the rotation of the \nscanning optics. As the sensor scans across each line, the distance from the sensor to the \nground increases further away from the centre of the swath. Although the scanning mirror \nrotates at a constant speed, the IFOV of the sensor moves faster (relative to the ground) and \nscans a larger area as it moves closer to the edges. This effect results in the compression of \nimage features at points away from the nadir and is called \ntangential scale distortion\n.  \nAll images are susceptible to geometric distortions caused by variations in platform stability \nincluding changes in their speed, altitude, and attitude (angular orientation with respect to the \nground) during data acquisition. These effects are most pronounced when using aircraft \nplatforms and are alleviated to a large degree with the use of satellite platforms, as their orbits \nare relatively stable, particularly in relation to their distance from the Earth. However, the \neastward rotation of the Earth,during a satellite orbit causes the sweep of scanning systems to \ncover an area slightly to the west of each previous scan. The resultant imagery is thus skewed \nacross the image. This is known as \nskew distortion\nand is common in imagery obtained from \nsatellite multispectral scanners. \nThe sources of geometric distortion and positional error vary with each specific situation, but \nare inherent in remote sensing imagery. In most instances, we may be able to remove, or at \nleast reduce these errors but they must be taken into account in each instance before \nattempting to make measurements or extract further information. \nNow that we have learned about some of the general characteristics of platforms and sensors, \nin the next sections we will look at some specific sensors (primarily satellite systems) \noperating in the visible and infrared portions of the spectrum.  \nPage 53Section 2.10 Geometric Distortion in Imagery\nCanada Centre for Remote Sensing\n\n2.11 Weather Satellites/Sensors \nWeather monitoring and forecasting was one of the first \ncivilian (as opposed to military) applications of satellite \nremote sensing, dating back to the first true weather \nsatellite, TIROS-1 (Television and Infrared Observation \nSatellite - 1), launched in 1960 by the United States. \nSeveral other weather satellites were launched over the \nnext five years, in near-polar orbits, providing repetitive \ncoverage of global weather patterns. In 1966, NASA (the \nU.S. National Aeronautics and Space Administration) \nlaunched the geostationary Applications Technology \nSatellite (ATS-1) which provided \nhemispheric images\n \nof the Earth's surface and cloud cover every half hour. \nFor the first time, the development and movement of \nweather systems could be routinely monitored. Today, several countries operate weather, or \nmeteorological satellites to monitor weather conditions around the globe. Generally speaking, \nthese satellites use sensors which have fairly coarse spatial resolution (when compared to \nsystems for observing land) and provide large areal coverage.  \nTheir temporal resolutions are generally quite high, providing frequent observations of the \nEarth's surface, atmospheric moisture, and cloud cover, which allows for near-continuous \nmonitoring of global weather conditions, and hence - forecasting. Here we review a few of the \nrepresentative satellites/sensors used for meteorological applications. \nGOES \nThe GOES (Geostationary Operational \nEnvironmental Satellite) System is the follow-up \nto the ATS series. They were designed by \nNASA for the National Oceanic and \nAtmospheric Administration (NOAA) to provide \nthe United States National Weather Service \nwith frequent, small-scale imaging of the \nEarth's surface and cloud cover. The GOES \nseries of satellites have been used extensively \nby meteorologists for weather monitoring and \nforecasting for over 20 years. These satellites \nare part of a global network of meteorological \nsatellites spaced at approximately 70° longitude intervals around the Earth in order to provide \nnear-global coverage. Two GOES satellites, placed in \ngeostationary orbits\n 36000 km above \nthe equator, each view approximately one-third of the Earth. One is situated at 75°W longitude \nand monitors North and South America and most of the Atlantic Ocean. The other is situated \nat 135°W longitude and monitors North America and the Pacific Ocean basin. Together they \nPage 54Section 2.11 Weather Satellites/Sensors\nCanada Centre for Remote Sensing\n\ncover from 20°W to 165°E longitude. This GOES image covers a portion of the southeastern \nUnited States, and the adjacent ocean areas where many severe storms originate and \ndevelop. This image shows Hurricane Fran approaching the southeastern United States and \nthe Bahamas in September of 1996. \n  \nTwo generations of GOES satellites have been launched, each measuring emitted and \nreflected radiation from which atmospheric temperature, winds, moisture, and cloud cover can \nbe derived. The first generation of satellites consisted of GOES-1 (launched 1975) through \nGOES-7 (launched 1992). Due to their design, these satellites were capable of viewing the \nEarth only a small percentage of the time (approximately five per cent). The second \ngeneration of satellites began with GOES-8 (launched 1994) and has numerous technological \nimprovements over the first series. They provide near-continuous observation of the Earth \nallowing more frequent imaging (as often as every 15 minutes). This increase in temporal \nresolution coupled with improvements in the spatial and radiometric resolution of the sensors \nprovides timelier information and improved data quality for forecasting meteorological \nconditions. \nGOES-8 and the other second generation GOES satellites have separate \nimaging\n and \nsounding\n instruments. The \nimager\n has five channels sensing visible and infrared reflected \nand emitted solar radiation. The infrared capability allows for day and night imaging. Sensor \npointing and scan selection capability enable imaging of an entire hemisphere, or small-scale \nimaging of selected areas. The latter allows meteorologists to monitor specific weather trouble \nspots to assist in improved short-term forecasting. The imager data are 10-bit radiometric \nresolution, and can be transmitted directly to local user terminals on the Earth's surface. The \naccompanying table describes the individual bands, their spatial resolution, and their \nmeteorological applications. \n  \n  \n  \n  \n  \n  \n  \n  \nPage 55Section 2.11 Weather Satellites/Sensors\nCanada Centre for Remote Sensing\n\nGOES Bands\n \nThe 19 channel \nsounder\n measures emitted radiation in 18 thermal infrared bands and \nreflected radiation in one visible band. These data have a spatial resolution of 8 km and 13-bit \nradiometric resolution. Sounder data are used for surface and cloud-top temperatures, multi-\nlevel moisture profiling in the atmosphere, and ozone distribution analysis. \nNOAA AVHRR \nNOAA is also responsible for another series of satellites which are useful for meteorological, \nas well as other, applications. These satellites, in \nsun-synchronous, near-polar orbits\n (830-\n870 km above the Earth), are part of the Advanced TIROS series (originally dating back to \n1960) and provide complementary information to the geostationary meteorological satellites \n(such as GOES). Two satellites, each providing global coverage, work together to ensure that \ndata for any region of the Earth is no more than six hours old. One satellite crosses the \nequator in the early morning from north-to-south while the other crosses in the afternoon. \nThe primary sensor on board the NOAA satellites, used for both meteorology and small-scale \nEarth observation and reconnaissance, is the \nAdvanced Very High Resolution Radiometer \n(AVHRR)\n. The AVHRR sensor detects radiation in the visible, near and mid infrared, and \nthermal infrared portions of the electromagnetic spectrum, over a swath width of 3000 km. \nThe accompanying table, outlines the AVHRR bands, their wavelengths and spatial resolution \n(at swath nadir), and general applications of each. \nBand\nWavelength \nRange (\n>μ\nm)\nSpatial \nResolution\nApplication\n1\n0.52 - 0.72 \n(visible)\n1 km\ncloud, pollution, and haze detection; severe \nstorm identification\n2\n3.78 - 4.03 \n(shortwave IR)\n4 km\nidentification of fog at night; discriminating \nwater clouds and snow or ice clouds during \ndaytime; detecting fires and volcanoes; night \ntime determination of sea surface \ntemperatures\n3\n6.47 - 7.02 \n(upper level \nwater vapour)\n4 km\nestimating regions of mid-level moisture \ncontent and advection; tracking mid-level \natmospheric motion\n4\n10.2 - 11.2 \n(longwave IR)\n4 km\nidentifying cloud-drift winds, severe storms, \nand heavy rainfall\n5\n11.5 - 12.5 \n(IR window \nsensitive to \nwater vapour)\n4 km\nidentification of low-level moisture; \ndetermination of sea surface temperature; \ndetection of airborne dust and volcanic ash \nPage 56Section 2.11 Weather Satellites/Sensors\nCanada Centre for Remote Sensing\n\nNOAA AVHRR Bands\n \nAVHRR data can be acquired and formatted in four operational modes, differing in resolution \nand method of transmission. Data can be transmitted directly to the ground and viewed as \ndata are collected, or recorded on board the satellite for later transmission and processing. \nThe accompanying table describes the various data formats and their characteristics. \nAVHRR Data Formats\n \n  \n  \n  \n  \n  \nBand\nWavelength \nRange (\nμ\nm)\nSpatial \nResolution\nApplication\n10.58 - 0.68 (red)1.1 kmcloud, snow, and ice monitoring\n2\n0.725 - 1.1 (near \nIR)\n1.1 km\nwater, vegetation, and agriculture \nsurveys\n33.55 -3.93 (mid IR)1.1 km\nsea surface temperature, volcanoes, \nand forest fire activity\n4\n10.3 - 11.3 (thermal \nIR)\n1.1 kmsea surface temperature, soil moisture\n5\n11.5 - 12.5 (thermal \nIR)\n1.1 kmsea surface temperature, soil moisture\nFormat\nSpatial \nResolution\nTransmission and Processing\nAPT (Automatic Picture \nTransmission)\n4 km\nlow-resolution direct transmission \nand display\nHRPT (High Resolution \nPicture Transmission)\n1.1 km\nfull-resolution direct transmission \nand display\nGAC (Global Area Coverage)4 km\nlow-resolution coverage from \nrecorded data\nLAC (Local Area Coverage)1.1 km\nselected full-resolution local area \ndata from recorded data\nPage 57Section 2.11 Weather Satellites/Sensors\nCanada Centre for Remote Sensing\n\n  \n \nAlthough AVHRR data are widely used for \nweather system\n forecasting and analysis, \nthe sensor is also well-suited to observation \nand monitoring of land features. AVHRR has \nmuch coarser spatial resolution than other \ntypical land observations sensors (discussed \nin the next section), but is used extensively \nfor monitoring regional, small-scale \nphenomena, including mapping of \nsea \nsurface temperature\n, and natural vegetation \nand crop conditions. \nMosaics\n covering large \nareas can be created from several AVHRR \ndata sets allowing small scale analysis and \nmapping of broad vegetation cover.  In \nCanada, AVHRR data received at the Prince \nAlbert Receiving Station Saskatchewan, are used as part of a crop information system, \nmonitoring the health of grain crops in the Prairies throughout the growing season. \n \n  \nOther Weather Satellites \nThe United States operates the \nDMSP\n (Defense Meteorological Satellite Program) series of \nsatellites which are also used for weather monitoring. These are near-polar orbiting satellites \nwhose Operational Linescan System (OLS) sensor provides twice daily coverage with a swath \nwidth of 3000 km at a spatial resolution of 2.7 km. It has two fairly broad wavelength bands: a \nvisible and near infrared band (0.4 to 1.1 \nμ\nm) and a thermal infrared band (10.0 to 13.4 \nμ\nm). \nAn interesting feature of the sensor is its ability to acquire visible band night time imagery \nunder very low illumination conditions. With this sensor, it is possible to collect striking images \nof the Earth showing (typically) the night time lights of large urban centres. \nPage 58Section 2.11 Weather Satellites/Sensors\nCanada Centre for Remote Sensing\n\nThere are several other meteorological satellites in orbit, launched and operated by other \ncountries, or groups of countries. These include Japan, with the \nGMS\n satellite series, and the \nconsortium of European communities, with the \nMeteosat\n satellites. Both are geostationary \nsatellites situated above the equator over Japan and Europe, respectively. Both provide half-\nhourly imaging of the Earth similar to GOES. GMS has two bands: 0.5 to 0.75 \nμ\nm (1.25 km \nresolution), and 10.5 to 12.5 \nμ \nm (5 km resolution). Meteosat has three bands: visible band \n(0.4 to 1.1 \nμ\nm; 2.5 km resolution), mid-IR (5.7 to 7.1 \nμ\nm; 5 km resolution), and thermal IR \n(10.5 to 12.5 \nμ\nm; 5 km resolution). \nPage 59Section 2.11 Weather Satellites/Sensors\nCanada Centre for Remote Sensing\n\n2.12 Land Observation Satellites/Sensors \nLandsat \n \nAlthough many of the weather satellite systems \n(such as those described in the previous section) \nare also used for monitoring the Earth's surface, \nthey are not optimized for detailed mapping of the \nland surface. Driven by the exciting views from, and \ngreat success of the early meteorological satellites \nin the 1960's, as well as from images taken during \nmanned spacecraft missions, the first satellite \ndesigned specifically to monitor the Earth's surface, \nLandsat-1, was launched by NASA in 1972. Initially \nreferred to as ERTS-1, (Earth Resources \nTechnology Satellite), \nLandsat\n was designed as an \nexperiment to test the feasibility of collecting multi-spectral Earth observation data \nfrom an unmanned satellite platform. Since that time, this highly successful program \nhas collected an abundance of data from around the world from several Landsat \nsatellites. Originally managed by NASA, responsibility for the Landsat program was \ntransferred to NOAA in 1983. In 1985, the program became commercialized, \nproviding data to civilian and applications users. \n \nLandsat's success is due to several factors, including: a combination of sensors with spectral \nbands tailored to Earth observation; functional spatial resolution; and good areal coverage \n(swath width and revisit period). The long lifespan of the program has provided a voluminous \narchive of Earth resource data facilitating long term monitoring and historical records and \nresearch. All Landsat satellites are placed in near-polar, sun-synchronous orbits. The first \nthree satellites (Landsats 1-3) are at altitudes around 900 km and have revisit periods of 18 \ndays while the later satellites are at around 700 km and have revisit periods of 16 days. All \nLandsat satellites have equator crossing times in the morning to optimize illumination \nconditions. \nA number of sensors have been on board the Landsat series of satellites, including the \nReturn Beam Vidicon (RBV) \ncamera systems, the \nMultiSpectral Scanner (MSS)\n systems, \nand the \nThematic Mapper (TM)\n. The most popular instrument in the early days of Landsat \nwas the MultiSpectral Scanner (MSS) and later the Thematic Mapper (TM). Each of these \nsensors collected data over a swath width of 185 km, with a full scene being defined as 185 \nkm x 185 km. \nThe MSS senses the electromagnetic radiation from the Earth's surface in four spectral \nbands. Each band has a spatial resolution of approximately 60 x 80 metres and a radiometric \nresolution of 6 bits, or 64 digital numbers. Sensing is accomplished with a line scanning \ndevice using an oscillating mirror. Six scan lines are collected simultaneously with each west-\nto-east sweep of the scanning mirror. The accompanying table outlines the spectral \nwavelength ranges for the MSS. \nPage 60Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nMSS Bands\n \nRoutine collection of MSS data ceased in 1992, as the use of TM data, starting on Landsat 4, \nsuperseded the MSS. The \nTM\n sensor provides several improvements over the MSS sensor \nincluding: higher spatial and radiometric resolution; finer spectral bands; seven as opposed to \nfour spectral bands; and an increase in the number of detectors per band (16 for the non-\nthermal channels versus six for MSS). Sixteen scan lines are captured simultaneously for \neach non-thermal spectral band (four for thermal band), using an oscillating mirror which \nscans during both the forward (west-to-east) and reverse (east-to-west) sweeps of the \nscanning mirror. This difference from the MSS increases the \ndwell time\n (see section 2.8) and \nimproves the geometric and radiometric integrity of the data. Spatial resolution of TM is 30 m \nfor all but the thermal infrared band which is 120 m. All channels are recorded over a range of \n256 digital numbers (8 bits). The accompanying table outlines the spectral resolution of the \nindividual TM bands and some useful applications of each. \nTM Bands\n \nChannel\nWavelength Range (\nμ\nm)\nLandsat 1,2,3Landsat 4,5\nMSS 4MSS 10.5 - 0.6 (green) \nMSS 5MSS 20.6 - 0.7 (red)\nMSS 6MSS 30.7 - 0.8 (near infrared)\nMSS 7MSS 40.8 - 1.1 (near infrared)\nChannel\nWavelength \nRange (\nμ\nm)\nApplication\nTM 10.45 - 0.52 (blue)\nsoil/vegetation discrimination; bathymetry/coastal \nmapping; cultural/urban feature identification\nTM 2\n0.52 - 0.60 \n(green)\ngreen vegetation mapping (measures reflectance \npeak); cultural/urban feature identification\nTM 30.63 - 0.69 (red)\nvegetated vs. non-vegetated and plant species \ndiscrimination (plant chlorophyll absorption); \ncultural/urban feature identification\nTM 4\n0.76 - 0.90 (near \nIR)\nidentification of plant/vegetation types, health, and \nbiomass content; water body delineation; soil moisture\nTM 5\n1.55 - 1.75 (short \nwave IR)\nsensitive to moisture in soil and vegetation; \ndiscriminating snow and cloud-covered areas\nTM 6\n10.4 - 12.5 \n(thermal IR)\nvegetation stress and soil moisture discrimination \nrelated to thermal radiation; thermal mapping (urban, \nwater)\nTM 7\n2.08 - 2.35 (short \nwave IR)\ndiscrimination of mineral and rock types; sensitive to \nvegetation moisture content\nPage 61Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nSPOT \nSPOT \n(Système Pour l'Observation de la Terre) is a \nseries of Earth observation imaging satellites designed \nand launched by CNES (Centre National d'Études \nSpatiales) of France, with support from Sweden and \nBelgium. SPOT-1 was launched in 1986, with \nsuccessors following every three or four years. All \nsatellites are in sun-synchronous, near-polar orbits at \naltitudes around 830 km above the Earth, which results \nin orbit repetition every 26 days. They have equator crossing times around 10:30 AM local \nsolar time. SPOT was designed to be a commercial provider of Earth observation data, and \nwas the first satellite to use along-track, or pushbroom scanning technology. \nThe SPOT satellites each have twin \nhigh resolution visible (HRV)\n imaging systems, which \ncan be operated independently and simultaneously. Each HRV is capable of sensing either in \na high spatial resolution single-channel \npanchromatic (PLA)\n mode, or a coarser spatial \nresolution three-channel \nmultispectral (MLA)\n mode. Each along-track scanning HRV sensor \nconsists of four linear arrays of detectors: one 6000 element array for the panchromatic mode \nrecording at a spatial resolution of 10 m, and one 3000 element array for each of the three \nmultispectral bands, recording at 20 m spatial resolution. The swath width for both modes is \n60 km at nadir. The accompanying table illustrates the spectral characteristics of the two \ndifferent modes. \n  \n  \n  \nData from both the TM and MSS sensors are used \nfor a wide variety of applications, including resource \nmanagement, mapping, environmental monitoring, \nand change detection (e.g. \nmonitoring forest \nclearcutting\n). The archives of Canadian imagery \ninclude over 350,000 scenes of MSS and over \n200,000 scenes of TM, managed by the licensed \ndistributor in Canada: RSI Inc. Many more scenes \nare held by foreign facilities around the world. \nPage 62Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nHRV Mode Spectral Ranges\n \nThe viewing angle of the sensors can be \nadjusted to look to either side of the \nsatellite's vertical (nadir) track, allowing \noff-\nnadir viewing\n which increases the \nsatellite's revisit capability. This ability to \npoint the sensors up to 27° from nadir, \nallows SPOT to view within a 950 km swath \nand to revisit any location several times per \nweek. As the sensors point away from nadir, \nthe swath varies from 60 to 80 km in width. \nThis not only improves the ability to monitor \nspecific locations and increases the \nchances of obtaining cloud free scenes, but \nthe off-nadir viewing also provides the \ncapability of acquiring imagery for stereoscopic coverage. By recording the same area from \ntwo different angles, the imagery can be viewed and analyzed as a three dimensional model, \na technique of tremendous value for terrain interpretation, mapping, and visual terrain \nsimulations. \nThis oblique viewing capability increases the revisit \nfrequency of equatorial regions to three days (seven \ntimes during the 26 day orbital cycle). Areas at a latitude \nof 45º can be imaged more frequently (11 times in 26 \ndays) due to the convergence or orbit paths towards the \npoles. By pointing both HRV sensors to cover \nadjacent \nground swaths\n at nadir, a swath of 117 km (3 km \noverlap between the two swaths) can be imaged. In this \nmode of operation, either panchromatic or multispectral \ndata can be collected, but not both simultaneously. \n  \n  \nMode/Band\nWavelength Range (\nμ\nm)\nPanchromatic (PLA)0.51 - 0.73 (blue-green-red)\nMultispectral (MLA)\nBand 10.50 - 0.59 (green)\nBand 20.61 - 0.68 (red)\nBand 30.79 - 0.89 (near infrared)\nPage 63Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nIRS \nThe Indian Remote Sensing (IRS) satellite series, combines features from both the Landsat \nMSS/TM sensors and the SPOT HRV sensor. The third satellite in the series, IRS-1C, \nlaunched in December, 1995 has three sensors: a single-channel panchromatic (PAN) high \nresolution camera, a medium resolution four-channel Linear Imaging Self-scanning Sensor \n(LISS-III), and a coarse resolution two-channel Wide Field Sensor (WiFS). The accompanying \ntable outlines the specific characteristics of each sensor. \n  \n  \n  \n  \n  \n  \n  \nSPOT has a number of benefits over other \nspaceborne optical sensors. Its fine spatial \nresolution and pointable sensors are the \nprimary reasons for its popularity. The three-\nband multispectral data are well suited to \ndisplaying as false-colour images and the \npanchromatic band can also be used to \n\"sharpen\" the spatial detail in the \nmultispectral data. SPOT allows applications \nrequiring fine spatial detail (such as \nurban \nmapping\n) to be addressed while retaining the \ncost and timeliness advantage of satellite \ndata. The potential applications of SPOT data \nare numerous. Applications requiring frequent \nmonitoring (agriculture, forestry) are well \nserved by the SPOT sensors. The acquisition \nof stereoscopic imagery from SPOT has \nplayed an important role in mapping \napplications and in the derivation of \ntopographic information (Digital Elevation \nModels - DEMs) from satellite data. \nPage 64Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nIRS Sensors\n \nIn addition to its high spatial resolution, the panchromatic sensor can be steered up to 26° \nacross-track, enabling stereoscopic imaging and increased revisit capablilities (as few as five \ndays), similar to SPOT. This high resolution data is useful for urban planning and mapping \napplications. The four LISS-III multispectral bands are similar to Landsat's TM bands 1 to 4 \nand are excellent for vegetation discrimination, land-cover mapping, and natural resource \nplanning. The WiFS sensor is similar to NOAA AVHRR bands and the spatial resolution and \ncoverage is useful for regional scale vegetation monitoring. \nSensor\nWavelength Range \n(\nμ\nm)\nSpatial \nResolution\nSwath \nWidth\nRevisit Period (at \nequator)\nPAN\n0.5 - 0.755.8 m70 km24 days\nLISS-II\nGreen0.52 - 0.5923 m142 km24 days\nRed0.62 - 0.6823 m142 km24 days\nNear IR0.77 - 0.8623 m142 km24 days\nShortwave \nIR\n1.55 - 1.7070 m148 km24 days\nWiFS\nRed0.62 - 0.68188 m774 km5 days\nNear IR0.77 - 0.86188 m774 km5 days\n  \nMEIS-II and CASI \nAlthough this tutorial concentrates on satellite-borne sensors, it is worth mentioning a couple \nof Canadian airborne sensors which have been used for various remote sensing applications, \nas these systems (and others like them) have influenced the design and development of \nsatellite systems. The first is the MEIS-II (\nMultispectral Electro-optical Imaging Scanner)\n \nsensor developed for the Canada Centre for Remote Sensing. Although no longer active, \nMEIS was the first operational use of pushbroom, or along-track scanning technology in an \nairborne platform. The sensor collected 8-bit data (256 digital numbers) in eight spectral \nbands ranging from 0.39 to 1.1 \nμ\nm, using linear arrays of 1728 detectors per band. The \nspecific wavelength ranges were selectable, allowing different band combinations to be used \nfor different applications. Stereo imaging from a single flight line was also possible, with \nchannels aimed ahead of and behind nadir, supplementing the other nadir facing sensors. \nBoth the stereo mapping and the selectable band capabilities were useful in research and \ndevelopment which was applied to development of other satellite (and airborne) sensor \nsystems. \nPage 65Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nCASI, the \nCompact Airborne Spectrographic Imager\n, is a leader in airborne imaging, being \nthe first commercial imaging spectrometer. This hyperspectral sensor detects a vast array of \nnarrow spectral bands in the visible and infrared wavelengths, using along-track scanning. \nThe spectral range covered by the 288 channels is between 0.4 and 0.9 \nμ\nm. Each band \ncovers a wavelength range of 0.018 \nμ\nm. While spatial resolution depends on the altitude of \nthe aircraft, the spectral bands measured and the bandwidths used are all programmable to \nmeet the user's specifications and requirements. Hyperspectral sensors such as this can be \nimportant sources of diagnostic information about specific targets' absorption and reflection \ncharacteristics, in effect providing a spectral 'fingerprint'. Experimentation with CASI and other \nairborne imaging spectrometers has helped guide the development of hyperspectral sensor \nsystems for advanced satellite systems. \nPage 66Section 2.12 Land Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\n2.13 Marine Observation Satellites/Sensors \nThe Earth's oceans cover more than two-thirds of the Earth's surface and play an important \nrole in the global climate system. They also contain an abundance of living organisms and \nnatural resources which are susceptible to pollution and other man-induced hazards. The \nmeteorological and land observations satellites/sensors we discussed in the previous two \nsections can be used for monitoring the oceans of the planet, but there are other \nsatellite/sensor systems which have been designed specifically for this purpose.  \nThe Nimbus-7 satellite, launched in 1978, carried the first sensor, the \nCoastal Zone Colour \nScanner (CZCS)\n, specifically intended for monitoring the Earth's oceans and water bodies. \nThe primary objective of this sensor was to observe ocean colour and temperature, \nparticularly in coastal zones, with sufficient spatial and spectral resolution to detect pollutants \nin the upper levels of the ocean and to determine the nature of materials suspended in the \nwater column. The Nimbus satellite was placed in a sun-synchronous, near-polar orbit at an \naltitude of 955 km. Equator crossing times were local noon for ascending passes and local \nmidnight for descending passes. The repeat cycle of the satellite allowed for global coverage \nevery six days, or every 83 orbits. The CZCS sensor consisted of six spectral bands in the \nvisible, near-IR, and thermal portions of the spectrum each collecting data at a spatial \nresolution of 825 m at nadir over a 1566 km swath width. The accompanying table outlines the \nspectral ranges of each band and the primary parameter measured by each.  \nCZCS Spectral Bands\n \nChannel\nWavelength Range (\nμ\nm)\nPrimary Measured Parameter\n10.43 - 0.45Chlorophyll absorption\n20.51 - 0.53Chlorophyll absorption\n30.54 - 0.56Gelbstoffe (yellow substance)\n40.66 - 0.68Chlorophyll concentration\n50.70 - 0.80Surface vegetation\n610.5 - 12.50Surface temperature\n  \nAs can be seen from the table, the first four bands of the \nCZCS sensor are very narrow. They were optimized to \nallow detailed discrimination of differences in water \nreflectance due to \nphytoplankton concentrations\n and \nother suspended particulates in the water. In addition to \ndetecting surface vegetation on the water, band 5 was \nused to discriminate water from land prior to processing \nthe other bands of information. The CZCS sensor ceased \noperation in 1986. \nPage 67Section 2.13 Marine Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\n  \nMOS \nThe first Marine Observation Satellite (MOS-1) was launched by Japan in February, 1987 and \nwas followed by its successor, MOS-1b, in February of 1990. These satellites carry three \ndifferent sensors: a four-channel Multispectral Electronic Self-Scanning Radiometer (MESSR), \na four-channel Visible and Thermal Infrared Radiometer (VTIR), and a two-channel \nMicrowave Scanning Radiometer (MSR), in the microwave portion of the spectrum. The \ncharacteristics of the two sensors in the visible/infrared are described in the accompanying \ntable. \nMOS Visible/Infrared Instruments\n \nThe MESSR bands are quite similar in spectral range to the Landsat MSS sensor and are \nthus useful for land applications in addition to observations of marine environments. The MOS \nsystems orbit at altitudes around 900 km and have revisit periods of 17 days. \nSeaWiFS \nThe SeaWiFS (Sea-viewing Wide-Field-of View Sensor) on board the SeaStar spacecraft is \nan advanced sensor designed for ocean monitoring. It consists of eight spectral bands of very \nnarrow wavelength ranges (see accompanying table) tailored for very specific detection and \nmonitoring of various ocean phenomena including: ocean primary production and \nphytoplankton processes, ocean influences on climate processes (heat storage and aerosol \nformation), and monitoring of the cycles of carbon, sulfur, and nitrogen. The orbit altitude is \n705 km with a local equatorial crossing time of 12 PM. Two combinations of spatial resolution \nand swath width are available for each band: a higher resolution mode of 1.1 km (at nadir) \nover a swath of 2800 km, and a lower resolution mode of 4.5 km (at nadir) over a swath of \n1500 km. \n  \nSensor\nWavelength Ranges (\nμ\nm)\nSpatial ResolutionSwath Width\nMESSR0.51 - 0.5950 m100 km\n0.61 - 0.6950 m100 km\n0.72 - 0.8050 m100 km\n0.80 - 1.1050 m100 km\nVTIR0.50 - 0.70900 m1500 km\n6.0 - 7.02700 m1500 km\n10.5 - 11.52700 m1500 km\n11.5 - 12.52700 m1500 km\nPage 68Section 2.13 Marine Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\nSeaWiFS Spectral Bands\n \n  \nThese ocean-observing satellite systems are important for global and regional scale \nmonitoring of ocean pollution and health, and assist scientists in understanding the influence \nand impact of the oceans on the global climate system. \nChannel\nWavelength Ranges (\nμ\nm)\n10.402 - 0.422\n20.433 - 0.453\n30.480 - 0.500\n40.500 - 0.520\n50.545 - 0.565\n60.660 - 0.680\n70.745 - 0.785\n80.845 - 0.885\nPage 69Section 2.13 Marine Observation Satellites/Sensors\nCanada Centre for Remote Sensing\n\n2.14 Other Sensors \nThe three previous sections provide a representative \noverview of specific systems available for remote sensing \nin the (predominantly) optical portions of the \nelectromagnetic spectrum. However, there are many \nother \ntypes of less common sensors\n which are used for \nremote sensing purposes. We briefly touch on a few of \nthese other types of sensors. The information is not \nconsidered comprehensive but serves as an introduction \nto alternative imagery sources and imaging concepts. \nVideo \n \nAlthough coarser in spatial resolution than traditional photography or digital imaging, video \ncameras provide a useful means of acquiring timely and inexpensive data and vocally \nannotated imagery. Applications with these requirements include natural disaster \nmanagement, (fires, flooding), crop and disease assessment, environmental hazard control, \nand police surveillance. Cameras used for video recording measure radiation in the visible, \nnear infrared, and sometimes mid-infrared portions of the EM spectrum. The image data are \nrecorded onto cassette, and can be viewed immediately. \nFLIR \nForward Looking InfraRed (FLIR) systems operate in a similar manner to across-track thermal \nimaging sensors, but provide an oblique rather than nadir perspective of the Earth ́s surface. \nTypically positioned on aircraft or helicopters, and imaging the area ahead of the platform, \nFLIR systems provide relatively high spatial resolution imaging that can be used for military \napplications, search and rescue operations, law enforcement, and forest fire monitoring. \nLaser fluorosensor \nSome targets fluoresce, or emit energy, upon receiving incident energy. This is not a simple \nreflection of the incident radiation, but rather an absorption of the initial energy, excitation of \nthe molecular components of the target materials, and emission of longer wavelength \nradiation which is then measured by the sensor. Laser fluorosensors illuminate the target with \na specific wavelength of radiation and are capable of detecting multiple wavelengths of \nfluoresced radiation. This technology has been proven for ocean applications, such as \nchlorophyll mapping, and pollutant detection, particularly for naturally occurring and accidental \noil slicks. \nLidar \nLidar is an acronym for LIght Detection And Ranging, an active imaging technology very \nsimilar to RADAR (see next paragraph). Pulses of laser light are emitted from the sensor and \nPage 70Section 2.14 Other Sensors\nCanada Centre for Remote Sensing\n\nenergy reflected from a target is detected. The time required for the energy to reach the target \nand return to the sensor determines the distance between the two. Lidar is used effectively for \nmeasuring heights of features, such as forest canopy height relative to the ground surface, \nand water depth relative to the water surface (laser profilometer). Lidar is also used in \natmospheric studies to examine the particle content of various layers of the Earth ́s \natmosphere and acquire air density readings and monitor air currents. \nRADAR \nRADAR stands for RAdio Detection And Ranging. RADAR systems are active sensors which \nprovide their own source of electromagnetic energy. Active radar sensors, whether airborne or \nspaceborne, emit microwave radiation in a series of pulses from an antenna, looking obliquely \nat the surface perpendicular to the direction of motion. When the energy reaches the target, \nsome of the energy is reflected back towards the sensor. This backscattered microwave \nradiation is detected, measured, and timed. The time required for the energy to travel to the \ntarget and return back to the sensor determines the distance or range to the target. By \nrecording the range and magnitude of the energy reflected from all targets as the system \npasses by, a two-dimensional image of the surface can be produced. Because RADAR \nprovides its own energy source, images can be acquired day or night. Also, microwave energy \nis able to penetrate through clouds and most rain, making it an all-weather sensor. Because o\nf \nthe unique characteristics and applications of microwave remote sensing, Chapter 3 covers \nthis topic in detail, concentrating on RADAR remote sensing. \nPage 71Section 2.14 Other Sensors\nCanada Centre for Remote Sensing\n\n2.15 Data Reception, Transmission, and Processing \nData obtained during airborne remote sensing missions can be retrieved once the aircraft \nlands. It can then be processed and delivered to the end user. However, data acquired from \nsatellite platforms need to be electronically transmitted to Earth, since the satellite continues \nto stay in orbit during its operational lifetime. The technologies designed to accomplish this \ncan also be used by an aerial platform if the data are urgently needed on the surface.  \n \nThere are three main options for \ntransmitting data\n acquired by satellites to the surface. The \ndata can be directly transmitted to Earth if a Ground Receiving Station (GRS) is in the line of \nsight of the satellite (A). If this is not the case, the data can be recorded on board the satellite \n(B) for transmission to a GRS at a later time. Data can also be relayed to the GRS through the \nTracking and Data Relay Satellite System (TDRSS) (C), which consists of a series of \ncommunications satellites in geosynchronous orbit. The data are transmitted from one satellite \nto another until they reach the appropriate GRS. \nIn Canada, CCRS operates two \nground receiving stations\n - one at Cantley, Québec (GSS), \njust outside of Ottawa, and another one at Prince Albert, Saskatchewan (PASS). The \ncombined coverage circles for these Canadian ground stations enable the potential for \nreception of real-time or recorded data from satellites passing over almost any part of \nCanada's land mass, and much of the continental United States as well. Other ground stations\nhave been set up around the world to capture data from a variety of satellites. \nPage 72Section 2.15 Data Reception, Transmission, and Processing\nCanada Centre for Remote Sensing\n\n \n  \nThe data are received at the GRS in a raw digital format. They may then, if required, be \nprocessed to correct systematic, geometric and atmospheric distortions to the imagery, and \nbe translated into a standardized format. The data are written to some form of storage \nmedium such as tape, disk or CD. The data are typically archived at most receiving and \nprocessing stations, and full libraries of data are managed by government agencies as well as \ncommercial companies responsible for each sensor's archives. \nFor many sensors it is possible to provide customers with \nquick-turnaround\n imagery when \nthey need data as quickly as possible after it is collected. Near real-time processing systems \nare used to produce low resolution imagery in hard copy or soft copy (digital) format within \nhours of data acquisition. Such imagery can then be faxed or transmitted digitally to end \nusers. One application of this type of fast data processing is to provide imagery to ships \nsailing in the Arctic, as it allows them to assess current ice conditions quickly in order to make \nnavigation decisions about the easiest/safest routes through the ice. Real-time processing of \nimagery in airborne systems has been used, for example, to pass thermal infrared imagery to \nforest fire fighters right at the scene. \nLow resolution quick-look imagery is used to preview archived imagery prior to purchase. The \nspatial and radiometric quality of these types of data products is degraded, but they are useful \nfor ensuring that the overall quality, coverage and cloud cover of the data is appropriate.  \nPage 73Section 2.15 Data Reception, Transmission, and Processing\nCanada Centre for Remote Sensing\n\n2.16 Endnotes \nYou have just completed \nChapter 2 - Satellites and Sensors.\n You can continue to Chapter \n3 - Microwave Sensing or first browse the CCRS Web site for other articles related to \nplatforms and sensors. \nFor instance, the Remote Sensing Glossary\n1\n has platform and sensor categories that contain \nmore information about various platforms and sensors and their use around the world. The \nglossary also has optical and radar categories of terms, to allow you to focus on these \naspects of remote sensing technology. \nOur receiving stations at Prince Albert\n2\n, Saskatchewan and Gatineau\n3\n, Quebec receive data \nfrom a number of satellites. See which satellites are received and what data reception \ncoverage\n4\n and services\n5\n they provide.\n \nIf you are curious about detecting targets which are smaller than a pixel, see a detailed \ndiscussion\n6\n in one of our \"Images of Canada\".\n \nUntil 1997, CCRS owned and operated a Convair 580\n7\n aircraft which carried a number of \nresearch instruments including a Synthetic Aperture Radar\n8\n (SAR) sensor. There are a \nnumber of images from this instrument on our Web site, one of which is of the Confederation \nBridge\n9\n between PEI and New Brunswick taken while it was under construction.\n \n \n \n1\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/terms/glossary/glossary_e.html\n \n2\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/stations/pass_e.html\n \n3\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/stations/gss_e.html\n \n4\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/stations/cc_e.html\n \n5\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/stations/grss_e.html\n \n6\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/tour/16/16ns_e.html\n \n7\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbc580_e.html\n \n8\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbmain_e.html\n \n9\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/apps/marine/pei_link/bridge_e.html\n \n \nPage 74Section 2.16 Endnotes\nCanada Centre for Remote Sensing\n\n2. Did You Know?\n \n \n2.1 Did You Know? \n \n\nHigh wing aircraft are preferable to low wing aircraft for hand-held aerial photography.  \n\nThe 'drop hatch' in aircraft such as the DeHavilland \"Beaver\" and \"Otter\" are convenient \nto use for vertical aerial photography without performing aircraft structural modifications. \n\nOblique aerial photography can preferably be done through an open window rather than \nthrough window glass/plastic.  \n\nPhotography through the aircraft door opening (having removed the door prior to flight) \nis also frequently done.  \n\nTethered balloons provide an inexpensive photography platform for long-term \nmonitoring of a specific site.  \nPage 75Section 2 Did you know?\nCanada Centre for Remote Sensing\n\n2.2 Did You Know? \n\"...the forecast calls for scattered clouds with the possibility of rain...\"\n  \n...most of the images you see on television weather forecasts are from geostationary \nsatellites. This is because they provide broad coverage of the weather and cloud patterns on \ncontinental scales. Meteorologists (weather forecasters) use these images to help them \ndetermine in which direction the weather patterns are likely to go. The high repeat coverage \ncapability of satellites with geostationary orbits allows them to collect several images daily to \nallow these patterns to be closely monitored.  \n \n...satellites occasionally require their orbits to be corrected. Because of atmospheric drag and \nother forces that occur when a satellite is in orbit, they may deviate from their initial orbital \npath. In order to maintain the planned orbit, a control center on the ground will issue \ncommands to the satellite to place it back in the proper orbit. Most satellites and their sensors \nhave a finite life-span ranging from a few to several years. Either the sensor will cease to \nfunction adequately or the satellite will suffer severe orbit decay such that the system is no \nlonger useable.  \nPage 76Section 2 Did you know?\nCanada Centre for Remote Sensing\n2.3 Did You Know? \nIf the IFOV for all pixels of a scanner stays constant (which is often the case), then the ground \narea represented by pixels at the nadir will have a larger scale then those pixels which are off-\nnadir. This means that spatial resolution will vary from the image centre to the swath edge. \n\n2.5 Did You Know? \n\"...you just can't have it all!...\" \n \n \n...that there are trade-offs between spatial, spectral, and radiometric resolution which must be \ntaken into consideration when engineers design a sensor. For high spatial resolution, the \nsensor has to have a small IFOV (Instantaneous Field of View). However, this reduces the \namount of energy that can be detected as the area of the ground resolution cell within the \nIFOV becomes smaller. This leads to reduced radiometric resolution - the ability to detect fine \nenergy differences. To increase the amount of energy detected (and thus, the radiometric \nresolution) without reducing spatial resolution, we would have to broaden the wavelength \nrange detected for a particular channel or band. Unfortunately, this would reduce the spectral \nresolution of the sensor. Conversely, coarser spatial resolution would allow improved \nradiometric and/or spectral resolution. Thus, these three types of resolution must be balanced \nagainst the desired capabilities and objectives of the sensor. \nPage 77Section 2 Did You Know?\nCanada Centre for Remote Sensing\n\n2.7 Did You Know? \n\"...let's take a look at the BIG PICTURE...\"\n \n \n...that the U.S. Space Shuttles have been used to take photographs from space. The \nastronauts onboard the shuttle have taken many photographs using hand-held cameras, \nsimilar to the type you would use for taking family photos. They have also used much larger \nand more sophisticated cameras mounted in the shuttle's cargo bay, called Large Format \nCameras (LFCs). LFCs have long focal lengths (305 mm) and take high quality photographs \ncovering several hundreds of kilometres in both dimensions. The exact dimensions depend (o\nf \ncourse) on the height of the shuttle above the Earth. Photos from these passive sensors need \nto be taken when the Earth's surface is being illuminated by the sun and are subject to cloud \ncover and other attenuation from the atmosphere. The shuttle has also been used several \ntimes to image many regions of the Earth using a special active microwave sensor called a \nRADAR. The RADAR sensor can collect detailed imagery during the night or day, as it \nprovides its own energy source, and is able to penetrate and \"see\" through cloud cover due to \nthe long wavelength of the electromagnetic radiation. We will learn more about RADAR in \nChapter 3. \n... although taking photographs in the UV portion of the spectrum is problematic due to \natmospheric scattering and absorption, it can be very useful where other types of photography \nare not. An interesting example in wildlife research and management has used UV \nphotography for detecting and counting harp seals on snow and ice. Adult harp seals have \ndark coats while their young have white coats. In normal panchromatic imagery, the dark \ncoats of the adult seals are readily visible against the snow and ice background but the white \ncoats of the young seals are not. However, the coats of both the adult and infant seals are \nstrong absorbers of UV energy. Thus, both adult and young appear very dark in a UV image \nand can be easily detected. This allows simple and reliable monitoring of seal population \nchanges over very large areas. \nPage 78Section 2 Did You Know?\nCanada Centre for Remote Sensing\n\n2.8 Did You Know? \n\"...backfield in motion...\" \n \n \nThere is a photographic parallel to the push-broom scanner. It is based on the \"slit camera\". \nThis camera does not have a shutter per se, but a slit (A) running in the across-track direction, \nwhich exposes film (B) which is being moved continuously (C) past the slit. The speed of \nmotion of the film has to be proportional to the ground speed (D) of the aircraft. Thus the film \nspeed has to be adjusted for the flying circumstances of the moment. The slit width (E) in the \nalong-track direction is also adjustable so as to control exposure time. There are no individual \nphoto 'frames' produced, but a continuous strip of imagery. Stereo slit photography is also \npossible, using a twin-lens system aimed slightly apart from parallel and each exposing one \nhalf of the film width. \nPage 79Section 2 Did You Know?\nCanada Centre for Remote Sensing\n\n2.10 Did You Know? \n\"...scanning for warm-bodied life forms, captain... \" \n \n...that, just as in aerial photography, some thermal scanner systems view the surface \nobliquely\n. Forward-Looking Infrared (\nFLIR\n) systems point ahead of the aircraft and scan \nacross the scene. FLIR systems produce images very similar in appearance to oblique aerial \nphotographs and are used for applications ranging from forest fire detection to law \nenforcement.  \n \n...many \nsystematic\n, or predictable, geometric distortions can be accounted for in real-time \n(i.e. during image acquisition). As an example, skew distortion in across-track scanner \nimagery due to the Earth's rotation can be accurately modeled and easily corrected. Other \nrandom variations causing distortion cannot be as easily modeled and require \ngeometric \ncorrection\n in a digital environment after the data have been collected. We will discuss this \ntopic in more detail in Chapter 4.  \nPage 80Section 2 Did you know...?\nCanada Centre for Remote Sensing\n\n2.12 Did You Know? \n\"...Land, Ho, matey!...\"\n \n...the ERTS (Earth Resources Technology Satellite) program was renamed to Landsat just \nprior to the launch of the second satellite in the series. The Landsat title was used to \ndistinguish the program from another satellite program in the planning stages, called Seasat, \nintended primarily for oceanographic applications. The first (and only) Seasat satellite was \nsuccessfully launched in 1978, but unfortunately was only operational for 99 days. Even \nthough the satellite was short-lived and the Seasat program was discontinued, it collected \nsome of the first RADAR images from space which helped heighten the interest in satellite \nRADAR remote sensing. Today, several RADAR satellites are operational or planned. We will \nlearn more about RADAR and these satellites in the next chapter.  \n \n...originally the MSS sensor numbering scheme (bands 4, 5, 6, and 7) came from their \nnumerical sequence after the three bands of the RBV (Return Beam Vidicon) sensors. \nHowever, due to technical malfunctions with the RBV sensor and the fact that it was dropped \nfrom the satellite sensor payload with the launch of Landsat-4, the MSS bands were \nrenumbered from 1 to 4. For the TM sensor, if we look at the wavelength ranges for each of \nthe bands, we see that TM6 and TM7 are out of order in terms of increasing wavelength. This \nwas because the TM7 channel was added as an afterthought late in the original system \ndesign process. \nPage 81Section 2.Did You Know?\nCanada Centre for Remote Sensing\n\n2.15 Did You Know? \n\"...I'm receiving you loud and clear...\" \n \n \n... Canada's ground receiving stations have been in operation since 1972 in Prince Albert, \nSaskatchewan and 1985 in Gatineau, Quebec. These two stations receive and process image \ndata from several different satellites (NOAA, Landsat, RADARSAT, J-ERS, MOS, SPOT, and \nERS) from five different countries or group of countries (USA, Canada, Japan, France, and \nEurope).  \nPage 82Section 2.Did You Know?\nCanada Centre for Remote Sensing\n\n2. Whiz Quiz and Answers\n \n \n2.2 Whiz Quiz \nWhat advantages do sensors carried on board satellites have over those carried on aircraft? \nAre there any disadvantages that you can think of?  \n \n \nAs a satellite in a near-polar sun-synchronous orbit revolves around the Earth, the satellite \ncrosses the equator at approximately the same local sun time every day. Because of the \norbital velocity, all other points on the globe are passed either slightly before or after this time. \nFor a sensor in the visible portion of the spectrum, what would be the advantages and \ndisadvantages of crossing times (local sun time) a) in the early morning, b) around noon, and \nc) in the mid afternoon?  \n  \nPage 83Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n\n2.2 Whiz Quiz - Answers \nAnswer 1:\n Sensors on board satellites generally can \"see\" a much larger area of the Earth's \nsurface than would be possible from a sensor onboard an aircraft. Also, because they are \ncontinually orbiting the Earth, it is relatively easy to collect imagery on a systematic and \nrepetitive basis in order to monitor changes over time. The geometry of orbiting satellites with \nrespect to the Earth can be calculated quite accurately and facilitates correction of remote \nsensing images to their proper geographic orientation and position. However, aircraft sensors \ncan collect data at any time and over any portion of the Earth's surface (as long as conditions \nallow it) while satellite sensors are restricted to collecting data over only those areas and \nduring specific times dictated by their particular orbits. It is also much more difficult to fix a \nsensor in space if a problem or malfunction develops! \n \nAnswer 2:\n An early morning crossing time would have the sun at a very low angle in the sky \nand would be good for emphasizing topographic effects but would result in a lot of shadow in \nareas of high relief. A crossing time around noon would have the sun at its highest point in the \nsky and would provide the maximum and most uniform illumination conditions. This would be \nuseful for surfaces of low reflectance but might cause saturation of the sensor over high \nreflectance surfaces, such as ice. Also, under such illumination,'specular reflection' from \nsmooth surfaces may be a problem for interpreters. Inthe mid afternoon, the illumination \nconditions would be more moderate. However, a phenomenon called solar heating (due to the \nPage 84Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\nsun heating the surface), which causes difficulties for recording reflected energy, will be near \nmaximum at this time of day. In order to minimize between these effects, most satellites which \nimage in the visible, reflected, and emitted infrared regions use crossing times around mid-\nmorning as a compromise. \n\n2.3 Whiz Quiz \n1. Look at the detail apparent in each of these two images. Which of the two images is of a \nsmaller scale? What clues did you use to determine this? Would the imaging platform for the \nsmaller scale image most likely have been a satellite or an aircraft?  \n \n \n2. If you wanted to monitor the general health of all vegetation cover over the Canadian \nPrairie provinces for several months, what type of platform and sensor characteristics (spatial, \nspectral, and temporal resolution) would be best for this and why? \n \nPage 85Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n\n2.3 Whiz Quiz - Answers \nAnswer 1:\n The image on the left is from a satellite while the image on the right is a \nphotograph taken from an aircraft. The area covered in the image on the right is also covered \nin the image on the left, but this may be difficult to determine because the scales of the two \nimages are much different. We are able to identify relatively small features (i.e. individual \nbuildings) in the image on the right that are not discernible in the image on the left. Only \ngeneral features such as street patterns, waterways, and bridges can be identified in the left-\nhand image. Because features appear larger in the image on the right and a particular \nmeasurement (eg. 1 cm) on the image represents a smaller true distance on the ground, this \nimage is at a larger scale. It is an aerial photograph of the Parliament Buildings in Ottawa, \nCanada. The left-hand image is a satellite image of the city of Ottawa. \n \nAnswer 2:\n A satellite sensor with large area coverage and fairly coarse spatial resolution \nwould be excellent for monitoring the general state of vegetation health over Alberta, \nSaskatchewan, and Manitoba. The large east-to-west expanse would be best covered by a \nsensor with a wide swath and broad coverage. This would also imply that the spatial \nresolution of the sensor would be fairly coarse. However, fine detail would not really be \nnecessary for monitoring a broad class including all vegetation cover. With broad areal \ncoverage the revisit period would be shorter, increasing the opportunity for repeat coverage \nnecessary for monitoring change. The frequent coverage would also allow for areas covered \nby clouds on one date, to be filled in by data collected from another date, reasonably close in \ntime. The sensor would not necessarily require high spectral resolution, but would at a \nminimum, require channels in the visible and near-infrared regions of the spectrum. \nVegetation generally has a low reflectance in the visible and a high reflectance in the near-\ninfrared. The contrast in reflectance between these two regions assists in identifying \nvegetation cover.The magnitude of the reflected infrared energy is also an indication of \nvegetation health. A sensor on board the U.S. NOAA (National Oceanographic and \nAtmospheric Administration) series of satellites with exactly these types of characteristics is \nactually used for this type of monitoring over the entire surface of the Earth! \n \nPage 86Section 2 Whiz Quiz and Answers\n\n2.4 Whiz Quiz \n1. Hyperspectral scanners (mentioned in Chapter 2.4) are special multispectral sensors which \ndetect and record radiation in several (perhaps hundreds) of very narrow spectral bands. \nWhat would be some of the advantages of these types of sensors? What would be some of \nthe disadvantages? \n \n2. If the spectral range of the 288 channels of the CASI (Compact Airborne Spectrographic \nImager) is exactly 0.40 \nμ\nm to 0.90 \nμ\nm and each band covers a wavelength of 1.8 nm \n(nanometres, 10\n-9\n m), will there be any overlap between the bands?\n \nPage 87Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n2.4 Whiz Quiz - Answers \nAnswer 1:\n Hyperspectral scanners have very high spectral resolution because of their narrow \nbandwidths. By measuring radiation over several small wavelength ranges, we are able to \neffectively build up a continuous spectrum of the radiation detected for each pixel in an image. \nThis allows for fine differentiation between targets based on detailed reflectance and \nabsorption responses which are not detectable using the broad wavelength ranges of \nconventional multispectral scanners. However, with this increased sensitivity comes \nsignificant increases in the volume of data collected. This makes both storage and \nmanipulation of the data, even in a computer environment, much more difficult. Analyzing \nmultiple images at one time or combining them, becomes cumbersome, and trying to identify \nand explain what each unique response represents in the \"real world\" is often difficult.  \nAnswer 2:\n The total wavelength range available will be 0.90-0.40 \nμ\nm = 0.50 mm. If there are \n288 channels of 1.8 nm each, let's calculate the total wavelength range they would span if \nthey did not overlap. \n1.8 nm = 1.8 x 10\n-9\n m\n \n \n1.8 x10\n-9\n m X 288 = 0.0000005184 m\n \n \n0.0000005184 m = 0.5184 \nμ\nm \nSince 0.5184 is greater than 0.50, the answer is YES, there will be have to be some overlap \nbetween some or all of the 288 bands to fit into this 0.50 \nμ\nm range.  \n\n2.5 Whiz Quiz \n \nSuppose you have a digital image which has a radiometric resolution of 6 bits. What is the \nmaximum value of the digital number which could be represented in that image?  \n \nPage 88Section 2 Whiz Quiz and Answers\n \n2.5 Whiz Quiz - Answers \n \nThe number of digital values possible in an image is equal to the  number two (2 - for binary\ncodings in a computer) raised to the exponent of the number of bits in the image  \n(i.e. 2\n# of bits\n). The number of values in a 6-bit image would be equal to \n2\n6\n= 2 x 2 x 2 x 2 x 2 x 2 = 64. Since the range of values displayed in a digital image normally\nstarts at zero (0), in order to have 64 values, the maximum value possible would be 63.\nCanada Centre for Remote Sensing\n\n2.9 Whiz Quiz \n \nHow would thermal imagery be useful in an urban environment?  \n \nPage 89Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n2.9 Whiz Quiz - Answers \n \nDetecting and monitoring heat loss from buildings in urban areas is an excellent application of \nthermal remote sensing. Heating costs, particularly in northern countries such as Canada, can \nbe very expensive. Thermal imaging in both residential and commercial areas allows us to \nidentify specific buildings, or parts of buildings, where heat is escaping. If the amount of heat \nis significant, these areas can be targeted for repair and re-insulation to reduce costs and \nconserve energy. \n\n2.10 Whiz Quiz \n \nIf you wanted to map a mountainous region, limiting geometric distortions as much as \npossible, would you choose a satellite-based or aircraft-based scanning system? Explain why \nin terms of imaging geometry. \n \nPage 90Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n2.10 Whiz Quiz Answers \nAlthough an aircraft scanning system may provide adequate geometric accuracy in most \ninstances, a satellite scanner would probably be preferable in a mountainous region. Because \nof the large variations in relief, geometric distortions as a result of relief displacement would \nbe amplified at aircraft altitudes much more than from satellite altitudes. Also, given the same \nlighting conditions, shadowing would be a greater problem using aircraft imagery because of \nthe shallower viewing angles and would eliminate the possibility for practical mapping in these \nareas. \n \n\n2.12 Whiz Quiz \n \nExplain why data from the Landsat TM sensor might be considered more useful than data \nfrom the original MSS sensor. Hint: Think about their spatial, spectral, and radiometric \nresolutions. \n \nPage 91Section 2 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n2.12 Whiz Quiz - Answers \nThere are several reasons why TM data may be \nconsidered more useful than MSS data. Although the \nareal coverage of a TM scene is virtually the same as a \nMSS scene, TM offers higher spatial, spectral, and \nradiometric resolution. The spatial resolution is 30 m \ncompared to 80 m (except for the TM thermal channels, \nwhich are 120 m to 240 m). Thus, the level of spatial \ndetail detectable in TM data is better. TM has more \nspectral channels which are narrower and better placed \nin the spectrum for certain applications, particularly \nvegetation discrimination. In addition, the increase from \n6 bits to 8 bits for data recording represents a four-fold \nincrease in the radiometric resolution of the data.  \n(Remember, 6 bits = 2\n6\n = 64, and 8 bits = 2\n8\n = 256 - \ntherefore, 256/64 = 4). However, this does not mean that TM data are \"better\" than MSS data. \nIndeed, MSS data are still used to this day and provide an excellent data source for many \napplications. If the desired information cannot be extracted from MSS data, then perhaps the \nhigher spatial, spectral, and radiometric resolution of TM data may be more useful. \n\n3. Microwave Remote Sensing\n \n \n3.1 Introduction \nMicrowave sensing encompasses both active and passive \nforms of remote sensing. As described in Chapter 2, the \nmicrowave portion of the spectrum covers the range from \napproximately 1cm to 1m in wavelength. Because of their long \nwavelengths, compared to the visible and infrared, \nmicrowaves have special properties that are important for \nremote sensing. \nLonger wavelength microwave radiation \ncan penetrate through cloud cover, haze, dust, and all but \nthe heaviest rainfall\n as the longer wavelengths are not \nsusceptible to atmospheric scattering which affects shorter \noptical wavelengths. This property allows detection of \nmicrowave energy under almost all weather and \nenvironmental conditions so that data can be collected at any time. \nPassive microwave sensing is similar in concept to thermal remote sensing. All objects emit \nmicrowave energy of some magnitude, but the amounts are generally very small. A passive \nmicrowave sensor detects the naturally emitted microwave energy within its field of view. This \nemitted energy is related to the temperature and moisture properties of the emitting object or \nsurface. Passive microwave sensors are typically radiometers or scanners and operate in \nmuch the same manner as systems discussed previously except that an antenna is used to \ndetect and record the microwave energy. \nPage 92Section 3.1 Microvaves Introduction\nCanada Centre for Remote Sensing\n\nThe microwave energy recorded by a passive sensor can be emitted by the atmosphere (1), \nreflected from the surface (2), emitted from the surface (3), or transmitted from the subsurface \n(4). Because the wavelengths are so long, the energy available is quite small compared to \noptical wavelengths. Thus, the fields of view must be large to detect enough energy to record \na signal. Most passive microwave sensors are therefore characterized by low spatial \nresolution. \nApplications of passive microwave remote sensing include meteorology, hydrology, and \noceanography. By looking \"at\", or \"through\" the atmosphere, depending on the wavelength, \nmeteorologists can use passive microwaves to measure atmospheric profiles and to \ndetermine water and ozone content in the atmosphere. Hydrologists use passive microwaves \nto measure soil moisture since microwave emission is influenced by moisture content. \nOceanographic applications include mapping sea ice, currents, and surface winds as well as \ndetection of pollutants, such as oil slicks. \nActive microwave sensors provide their own \nsource of microwave radiation to illuminate the \ntarget. Active microwave sensors are generally \ndivided into two distinct categories: \nimaging and \nnon-imaging\n. The most common form of imaging \nactive microwave sensors is RADAR. \nRADAR\n is \nan acronym for \nRA\ndio \nD\netection \nA\nnd \nR\nanging, \nwhich essentially characterizes the function and \noperation of a radar sensor. The sensor transmits \na microwave (radio) signal towards the target and \ndetects the backscattered portion of the signal. \nThe strength of the backscattered signal is measured to discriminate between different targets \nand the time delay between the transmitted and reflected signals determines the distance (or \nrange\n) to the target. \nNon-imaging microwave sensors include \naltimeters\n and \nscatterometers\n. In most cases \nthese are profiling devices which take measurements in one linear dimension, as opposed to \nthe two-dimensional representation of imaging sensors. Radar altimeters transmit short \nmicrowave pulses and measure the round trip time delay to targets to determine their distance \nfrom the sensor. Generally altimeters look straight down at nadir below the platform and thus \nmeasure height or elevation (if the altitude of the platform is accurately known). Radar \naltimetry is used on aircraft for altitude determination and on aircraft and satellites for \ntopographic mapping and sea surface height estimation. Scatterometers are also generally \nnon-imaging sensors and are used to make precise quantitative measurements of the amount \nof energy backscattered from targets. The amount of energy backscattered is dependent on \nthe surface properties (roughness) and the angle at which the microwave energy strikes the \ntarget. Scatterometry measurements over ocean surfaces can be used to estimate wind \nspeeds based on the sea surface roughness. Ground-based scatterometers are used \nextensively to accurately measure the backscatter from various targets in order to \nPage 93Section 3.1 Microvaves Introduction\nCanada Centre for Remote Sensing\n\ncharacterize different materials and surface types. This is analogous to the concept of spectral \nreflectance curves in the optical spectrum. \nFor the remainder of this chapter we focus solely on \nimaging radars\n. As with passive \nmicrowave sensing, a major advantage of radar is the capability of the radiation to penetrate \nthrough cloud cover and most weather conditions. Because radar is an active sensor, it can \nalso be used to image the surface at any time, day or night. These are the two primary \nadvantages of radar: \nall-weather and day or night\nimaging. It is also important to understand \nthat, because of the fundamentally different way in which an active radar operates compared \nto the passive sensors we described in Chapter 2, a radar image is quite different from and \nhas special properties unlike images acquired in the visible and infrared portions of the \nspectrum. Because of these differences, radar and optical data can be complementary to one \nanother as they offer different perspectives of the Earth's surface providing different \ninformation content. We will examine some of these fundamental properties and differences in \nmore detail in the following sections. \nBefore we delve into the peculiarities of radar, let's first look briefly at the origins and history of \nimaging radar, with particular emphasis on the Canadian experience in radar remote sensing. \nThe first demonstration of the transmission of radio microwaves and reflection from various \nobjects was achieved by Hertz in 1886. Shortly after the turn of the century, the first \nrudimentary radar was developed for ship detection. In the 1920s and 1930s, experimental \nground-based pulsed radars were developed for detecting objects at a distance. The first \nimaging radars used during World War II had rotating sweep displays which were used for \ndetection and positioning of aircrafts and ships. After World War II, side-looking airborne radar \n(SLAR) was developed for military terrain reconnaissance and surveillance where a strip of \nthe ground parallel to and offset to the side of the aircraft was imaged during flight. In the \n1950s, advances in SLAR and the development of higher resolution synthetic aperture radar \n(SAR) were developed for military purposes. In the 1960s these radars were declassified and \nbegan to be used for civilian mapping applications. Since this time the development of several \nairborne and spaceborne radar systems for mapping and monitoring applications use has \nflourished. \nCanada initially became involved in radar remote sensing in the mid-1970s. It was recognized \nthat radar may be particularly well-suited for surveillance of our vast northern expanse, which \nis often cloud-covered and shrouded in darkness during the Arctic winter, as well as for \nmonitoring and mapping our natural resources. Canada's SURSAT (Surveillance Satellite) \nproject from 1977 to 1979 led to our participation in the (U.S.) SEASAT radar satellite, the first \noperational civilian radar satellite. The Convair-580 airborne radar program, carried out by the \nCanada Centre for Remote Sensing following the SURSAT program, in conjunction with radar \nresearch programs of other agencies such as NASA and the European Space Agency (ESA), \nled to the conclusion that spaceborne remote sensing was feasible. In 1987, the Radar Data \nDevelopment Program (RDDP), was initiated by the Canadian government with the objective \nof \"operationalizing the use of radar data by Canadians\". Over the 1980s and early 1990s, \nseveral research and commercial airborne radar systems have collected vast amounts of \nPage 94Section 3.1 Microvaves Introduction\nCanada Centre for Remote Sensing\n\nimagery throughout the world demonstrating the utility of radar data for a variety of \napplications. With the launch of ESA's ERS-1 in 1991, spaceborne radar research intensified, \nand was followed by the major launches of Japan's J-ERS satellite in 1992, ERS-2 in 1995, \nand Canada's advanced RADARSAT satellite, also in 1995. \nPage 95Section 3.1 Microvaves Introduction\nCanada Centre for Remote Sensing\n\n3.2 Radar Basics \nAs noted in the previous section, a \nradar\n is essentially a \nranging or distance measuring device. It consists \nfundamentally of a transmitter, a receiver, an antenna, and an \nelectronics system to process and record the data. The \ntransmitter generates successive short bursts (or \npulses\n of \nmicrowave (A) at regular intervals which are focused by the \nantenna into a beam (B). The radar beam illuminates the \nsurface obliquely at a right angle to the motion of the platform. \nThe antenna receives a portion of the transmitted energy \nreflected (or \nbackscattered\n) from various objects within the \nilluminated beam (C). By measuring the time delay between \nthe transmission of a pulse and the reception of the \nbackscattered \"echo\" from different targets, their distance \nfrom the radar and thus their location can be determined. As the sensor platform moves forward, recording and \nprocessing of the backscattered signals builds up a two-dimensional image of the surface. \n \nWhile we have characterized electromagnetic radiation in the visible and infrared portions of the spectrum primarily \nby wavelength, microwave portions of the spectrum are often referenced according to both wavelength and \nfrequency. The \nmicrowave region of the spectrum\n is quite large, relative to the visible and infrared, and there are \nseveral wavelength ranges or bands commonly used which given code letters during World War II, and remain to this \nday. \nKa, K, and Ku bands: very short wavelengths used in early airborne radar systems but uncommon today.  \n\nX-band: used extensively on airborne systems for military reconnaissance and terrain mapping.  \nC-band: common on many airborne research systems (CCRS Convair-580 and NASA AirSAR) and \nspaceborne systems (including  \nERS-1 and 2 and RADARSAT).  \nPage 96Section 3.2 Radar Basics\nCanada Centre for Remote Sensing\n\nS-band: used on board the Russian ALMAZ satellite.  \n\nL-band: used onboard American SEASAT and Japanese JERS-1 satellites and NASA airborne system.  \nP-band: longest radar wavelengths, used on NASA experimental airborne research system.  \n \n \nTwo radar images of the same agricultural fields \nHere are two radar images\n of the same agricultural fields, each image having been collected using a different radar \nband. The one on the top was acquired by a C-band radar and the one below was acquired by an L-band radar. You \ncan clearly see that there are significant differences between the way the various fields and crops appear in each of \nthe two images. This is due to the different ways in which the radar energy interacts with the fields and crops \ndepending on the radar wavelength. We will learn more about this in later sections. \nWhen discussing microwave energy, the \npolarization\n \nof the radiation is also important. Polarization refers to \nthe orientation of the electric field (recall the definition \nof electromagnetic radiation from Chapter 1). Most \nradars are designed to transmit microwave radiation \neither horizontally polarized (H) or vertically polarized \n(V). Similarly, the antenna receives either the \nhorizontally or vertically polarized backscattered \nenergy, and some radars can receive both. These two \npolarization states are designated by the letters H for \nhorizontal, and V, for vertical. Thus, there can be four \ncombinations of both transmit and receive polarizations \nas follows: \nHH - for horizontal transmit and horizontal receive,  \nVV - for vertical transmit and vertical receive,  \nHV - for horizontal transmit and vertical receive, and  \nVH - for vertical transmit and horizontal receive.  \nThe first two polarization combinations are referred to as like-polarized because the transmit and receive \npolarizations are the same. The last two combinations are referred to as cross-polarized because the transmit and \nreceive polarizations are opposite of one another. These \nC-band images\n of agricultural fields demonstrate the \nvariations in radar response due to changes in polarization. The bottom two images are like-polarized (HH and VV, \nrespectively), and the upper right image is cross-polarized (HV). The upper left image is the result of displaying each \nof the three different polarizations together, one through each of the primary colours (red, green, and blue). Similar to \nvariations in wavelength, depending on the transmit and receive polarizations, the radiation will interact with and be \nPage 97Section 3.2 Radar Basics\nCanada Centre for Remote Sensing\n\nbackscattered differently from the surface. Both wavelength and polarization affect how a radar \"sees\" the surface. \nTherefore, radar imagery collected using different polarization and wavelength combinations may provide different \nand complementary information about the targets on the surface.  \n \n \nC-band images \nPage 98Section 3.2 Radar Basics\nCanada Centre for Remote Sensing\n\n3.3 Viewing Geometry and Spatial Resolution \nThe imaging geometry of a radar system is \ndifferent from the framing and scanning \nsystems commonly employed for optical \nremote sensing described in Chapter 2. Similar \nto optical systems, the platform travels forward \nin the \nflight direction (A)\n with the \nnadir (B)\n \ndirectly beneath the platform. The microwave \nbeam is transmitted obliquely at right angles to \nthe direction of flight illuminating a \nswath (C)\n \nwhich is offset from nadir. \nRange (D)\n refers to \nthe across-track dimension perpendicular to the \nflight direction, while \nazimuth (E)\n refers to the \nalong-track dimension parallel to the flight \ndirection. This side-looking viewing geometry is \ntypical of imaging radar systems (airborne or spaceborne). \n \nNear range \nThe portion of the image swath closest to the nadir track of the radar platform is called the \nnear range (A)\n while the portion of the swath farthest from the nadir is called the \nfar range \n(B)\n. \nPage 99Section 3.3 Viewing Geometry and Spatial Resolution\nCanada Centre for Remote Sensing\n\n \nIncidence angle \nThe incidence angle is the angle between the \nradar beam and ground surface (A)\n which \nincreases, moving across the swath from near to far range. The \nlook angle (B)\n is the angle at \nwhich the radar \"looks\" at the surface. In the near range, the viewing geometry may be \nreferred to as being steep, relative to the far range, where the viewing geometry is shallow. At \nall ranges the radar antenna measures the radial line of sight distance between the radar and \neach target on the surface. This is the \nslant range distance (C)\n. The \nground range \ndistance (D)\n is the true horizontal distance along the ground corresponding to each point \nmeasured in slant range. \nUnlike optical systems, a radar's spatial resolution \nis a function of the specific properties of the \nmicrowave radiation and geometrical effects. If a \nReal Aperture Radar (RAR) is used for image \nformation (as in Side-Looking Airborne Radar) a \nsingle transmit pulse and the backscattered signal \nare used to form the image. In this case, the \nresolution is dependent on the effective length of \nthe pulse in the slant range direction and on the \nwidth of the illumination in the azimuth direction. \nThe \nrange or across-track resolution\n is \ndependent on the length of the pulse (P). Two \ndistinct targets on the surface will be resolved in the range dimension if their separation is \ngreater than half the pulse length. For example, targets 1 and 2 will not be separable while \ntargets 3 and 4 will. Slant range resolution remains constant, independent of range. However, \nwhen projected into ground range coordinates, the resolution in ground range will be \ndependent of the incidence angle. Thus, for fixed slant range resolution, the ground range \nresolution will decrease with increasing range. \nPage 100Section 3.3 Viewing Geometry and Spatial Resolution\nCanada Centre for Remote Sensing\n\n \nThe \nazimuth or along-track resolution\n is determined by the angular width of the radiated \nmicrowave beam and the slant range distance. This \nbeamwidth (A)\nis a measure of the width \nof the illumination pattern. As the radar illumination propagates to increasing distance from the \nsensor, the azimuth resolution increases (becomes coarser). In this illustration, targets 1 and \n2 in the near range would be separable, but targets 3 and 4 at further range would not. The \nradar beamwidth is inversely proportional to the antenna length (also referred to as the \naperture) which means that a longer antenna (or aperture) will produce a narrower beam and \nfiner resolution. \nFiner range resolution can be achieved by using a shorter pulse length, which can be done \nwithin certain engineering design restrictions. Finer azimuth resolution can be achieved by \nincreasing the antenna length. However, the actual length of the antenna is limited by what \ncan be carried on an airborne or spaceborne platform. For airborne radars, antennas are \nusually limited to one to two metres; for satellites they can be 10 to 15 metres in length. To \novercome this size limitation, the forward motion of the platform and special recording and \nprocessing of the backscattered echoes are used to simulate a very long antenna and thus \nincrease azimuth resolution\n. \n \nThis figure illustrates how this is achieved. As a \ntarget (A)\n first enters the radar beam (1), the \nbackscattered echoes from each transmitted pulse begin to be recorded. As the platform \ncontinues to move forward, all echoes from the target for each pulse are recorded during the \nentire time that the target is within the beam. The point at which the target leaves the view of \nthe radar beam (2) some time later, determines the length of the simulated or \nsynthesized \nantenna (B)\n. Targets at far range, where the beam is widest will be illuminated for a longer \nperiod of time than objects at near range. The expanding beamwidth, combined with the \nincreased time a target is within the beam as ground range increases, balance each other, \nsuch that the resolution remains constant across the entire swath. This method of achieving \nuniform, fine azimuth resolution across the entire imaging swath is called \nsynthetic aperture \nPage 101Section 3.3 Viewing Geometry and Spatial Resolution\nCanada Centre for Remote Sensing\nradar\n, or \nSAR\n. Most airborne and spaceborne radars employ this type of radar.  \n\n3.4 Radar Image Distortions \nAs with all remote sensing systems, the viewing \ngeometry of a radar results in certain geometric \ndistortions on the resultant imagery. However, there \nare key differences for radar imagery which are due \nto the side-looking viewing geometry, and the fact \nthat the radar is fundamentally a distance \nmeasuring device (i.e. measuring range). \nSlant-\nrange scale distortion\n occurs because the radar is \nmeasuring the distance to features in slant-range \nrather than the true horizontal distance along the \nground. This results in a varying image scale, \nmoving from near to far range. Although targets A1 \nand B1 are the same size on the ground, their apparent dimensions in slant range (A2 and \nB2) are different. This causes targets in the near range to appear compressed relative to the \nfar range. Using trigonometry, ground-range distance can be calculated from the slant-range \ndistance and platform altitude to convert to the proper ground-range format. \n \n \nThis conversion comparison\n shows a radar image in slant-range display (top) where the \nfields and the road in the near range on the left side of the image are compressed, and the \nsame image converted to ground-range display (bottom) with the features in their proper \ngeometric shape. \nSimilar to the distortions encountered when using cameras and scanners, radar images are \nalso subject to geometric distortions due to \nrelief displacement\n. As with scanner imagery, \nthis displacement is one-dimensional and occurs perpendicular to the flight path. However, \nthe displacement is reversed with targets being displaced towards, instead of away from the \nsensor. Radar \nforeshortening\n and \nlayover\n are two consequences which result from relief \ndisplacement. \nPage 102Section 3.4 Radar Image Distortions\nCanada Centre for Remote Sensing\n\n \nWhen the radar beam reaches the base of a tall feature tilted towards the radar (e.g. a \nmountain) before it reaches the top \nforeshortening\n will occur. Again, because the radar \nmeasures distance in slant-range, the slope (A to B) will appear compressed and the length of \nthe slope will be represented incorrectly (A' to B'). Depending on the angle of the hillside or \nmountain slope in relation to the incidence angle of the radar beam, the severity of \nforeshortening will vary. Maximum foreshortening occurs when the radar beam is \nperpendicular to the slope such that the slope, the base, and the top are imaged \nsimultaneously (C to D). The length of the slope will be reduced to an effective length of zero \nin slant range (C'D'). The figure below shows a radar image of \nsteep mountainous terrain\n \nwith severe foreshortening effects. The foreshortened slopes appear as bright features on the \nimage. \n \n  \n  \n  \n  \n  \nPage 103Section 3.4 Radar Image Distortions\nCanada Centre for Remote Sensing\n\n  \n  \n  \nLayover\n occurs when the radar beam reaches the \ntop of a tall feature (B) before it reaches the base \n(A). The return signal from the top of the feature \nwill be received before the signal from the bottom. \nAs a result, the top of the feature is displaced \ntowards the radar from its true position on the \nground, and \"lays over\" the base of the feature (B' \nto A'). \nLayover effects\n on a radar image look very \nsimilar to effects due to foreshortening. As with \nforeshortening, layover is most severe for small \nincidence angles, at the near range of a swath, and \nin mountainous terrain. \n \nBoth foreshortening and layover result in \nradar shadow\n. Radar shadow occurs when the \nradar beam is not able to illuminate the ground surface. Shadows occur in the down range \ndimension (i.e. towards the far range), behind vertical features or slopes with steep sides. \nSince the radar beam does not illuminate the surface, shadowed regions will appear dark on \nan image as no energy is available to be backscattered. As incidence angle increases from \nnear to far range, so will shadow effects as the radar beam looks more and more obliquely at \nthe surface. This image illustrates \nradar shadow effects\n on the right side of the hillsides \nwhich are being illuminated from the left. \nPage 104Section 3.4 Radar Image Distortions\nCanada Centre for Remote Sensing\n\n \nRed surfaces are completely in shadow. Black areas in image are shadowed and contain no \ninformation. \n \nRadar shadow effects \n  \nPage 105Section 3.4 Radar Image Distortions\nCanada Centre for Remote Sensing\n\n3.5 Target Interaction and Image Appearance \nThe brightness of features in a radar image is dependent on the portion of the transmitted \nenergy that is returned back to the radar from targets on the surface. The magnitude or \nintensity of this backscattered energy is dependent on how the radar energy interacts with the \nsurface, which is a function of several variables or parameters. These parameters include the \nparticular characteristics of the radar system (frequency, polarization, viewing geometry, etc.) \nas well as the characteristics of the surface (landcover type, topography, relief, etc.). Because \nmany of these characteristics are interrelated, it is impossible to separate out each of their \nindividual contributions to the appearance of features in a radar image. Changes in the \nvarious parameters may have an impact on and affect the response of other parameters, \nwhich together will affect the amount of backscatter. Thus, the brightness of features in an \nimage is usually a combination of several of these variables. However, for the purposes of our \ndiscussion, we can group these characteristics into three areas which fundamentally control \nradar energy/target interactions. They are: \n\nSurface roughness of the target  \n\nRadar viewing and surface geometry relationship  \n\nMoisture content and electrical properties of the target  \n \nThe surface roughness of a feature controls how the microwave energy interacts with that \nsurface or target and is generally the dominant factor in determining the tones seen on a radar \nimage. \nSurface roughness\n refers to the average height variations in the surface cover from a \nplane surface, and is measured on the order of centimetres. Whether a surface appears rough \nor smooth to a radar depends on the wavelength and incidence angle. \nSimply put, a surface is considered \"smooth\" if the \nheight variations are much smaller than the radar \nwavelength. When the surface height variations begin \nto approach the size of the wavelength, then the \nsurface will appear \"rough\". Thus, a given surface will \nappear rougher as the wavelength becomes shorter \nand smoother as the wavelength becomes longer. A \nsmooth surface (A)\n causes \nspecular\n reflection of the \nincident energy (generally away from the sensor) and \nthus only a small amount of energy is returned to the \nradar. This results in smooth surfaces appearing as \nPage 106Section 3.5 Target Interaction and Image Appearance\nCanada Centre for Remote Sensing\n\ndarker toned areas on an image. A \nrough surface (B)\n will scatter the energy approximately \nequally in all directions (i.e. \ndiffusely\n) and a significant portion of the energy will be \nbackscattered to the radar. Thus, rough surfaces will appear lighter in tone on an image. \nIncidence angle, in combination with wavelength, also plays a role in the apparent roughness \nof a surface. For a given surface and wavelength, the surface will appear smoother as the \nincidence angle increases. Thus, as we move farther across the swath, from near to far range, \nless energy would be returned to the sensor and the image would become increasingly darker \nin tone. \nWe have already discussed incidence or look angle in relation \nto viewing geometry and how changes in this angle affect the \nsignal returned to the radar. However, in relation to surface \ngeometry, and its effect on target interaction and image \nappearance, the local incidence angle is a more appropriate \nand relevant concept. The local incidence angle is the angle \nbetween the radar beam and a line perpendicular to the slope \nat the point of incidence (A). Thus, local incidence angle takes \ninto account the local slope of the terrain in relation to the radar beam. With flat terrain, the \nlocal incidence angle is the same as the look angle (B) of the radar. For terrain with any type \nof relief, this is not the case. Generally, slopes facing towards the radar will have small local \nincidence angles, causing relatively strong backscattering to the sensor, which results in a \nbright-toned appearance in an image. \nAs the concept of \nlocal incidence angle\n demonstrates, the relationship between viewing \ngeometry and the geometry of the surface features plays an important role in how the radar \nenergy interacts with targets and their corresponding brightness on an image. Variations in \nviewing geometry will accentuate and enhance topography and relief in different ways, such \nthat varying degrees of foreshortening, layover, and shadow (section 3.4) may occur \ndepending on surface slope, orientation, and shape. \n \nThe \nlook direction or aspect angle\n of the radar describes the orientation of the transmitted \nradar beam relative to the direction or alignment of linear features on the surface. The look \ndirection can significantly influence the appearance of features on a radar image, particularly \nwhen ground features are organized in a linear structure (such as agricultural crops or \nPage 107Section 3.5 Target Interaction and Image Appearance\nCanada Centre for Remote Sensing\n\nmountain ranges). If the look direction is close to perpendicular to the orientation of the \nfeature (A), then a large portion of the incident energy will be reflected back to the sensor and \nthe feature will appear as a brighter tone. If the look direction is more oblique in relation to the \nfeature orientation (B), then less energy will be returned to the radar and the feature will \nappear darker in tone. Look direction is important for enhancing the contrast between features \nin an image. It is particularly important to have the proper look direction in mountainous \nregions in order to minimize effects such as layover and shadowing. By acquiring imagery \nfrom different look directions, it may be possible to enhance identification of features with \ndifferent orientations relative to the radar. \nFeatures which have two (or more) surfaces (usually \nsmooth) at right angles to one another, may cause \ncorner reflection\n to occur if the 'corner' faces the \ngeneral direction of the radar antenna. The orientation of \nthe surfaces at right angles causes most of the radar \nenergy to be reflected directly back to the antenna due \nto the double bounce (or more) reflection. Corner \nreflectors with complex angular shapes are common in \nurban environments (e.g. buildings and streets, bridges, \nother man-made structures). Naturally occurring corner \nreflectors may include severely folded rock and cliff \nfaces or upright vegetation standing in water. In all cases, corner reflectors show up as very \nbright targets in an image, such as the buildings and other man-made structures in this \nradar \nimage of a city\n. \n \nThe presence (or absence) of moisture affects the electrical properties of an object or \nmedium. Changes in the electrical properties influence the absorption, transmission, and \nreflection of microwave energy. Thus, the moisture content will influence how targets and \nsurfaces reflect energy from a radar and how they will appear on an image. Generally, \nreflectivity (and image brightness) increases with increased moisture content. For example, \nsurfaces such as soil and vegetation cover will appear brighter when they are wet than when \nthey are dry. \nPage 108Section 3.5 Target Interaction and Image Appearance\nCanada Centre for Remote Sensing\n\nWhen a target is moist or wet, scattering from the topmost portion (surface scattering) is the \ndominant process taking place. The type of reflection (ranging from specular to diffuse) and \nthe magnitude will depend on how rough the material appears to the radar. If the target is very \ndry and the surface appears smooth to the radar, the radar energy may be able to penetrate \nbelow the surface, whether that surface is discontinuous (e.g. forest canopy with leaves and \nbranches), or a homogeneous surface (e.g. soil, sand, or ice). For a given surface, longer \nwavelengths are able to penetrate further than shorter wavelengths. \n \nIf the radar energy does manage to penetrate through the topmost surface, then volume \nscattering may occur. \nVolume scattering\n is the scattering of radar energy within a volume or \nmedium, and usually consists of multiple bounces and reflections from different components \nwithin the volume. For example, in a forest, scattering may come from the leaf canopy at the \ntops of the trees, the leaves and branches further below, and the tree trunks and soil at the \nground level. Volume scattering may serve to decrease or increase image brightness, \ndepending on how much of the energy is scattered out of the volume and back to the radar. \nPage 109Section 3.5 Target Interaction and Image Appearance\nCanada Centre for Remote Sensing\n\n3.6 Radar Image Properties \n \nAll radar images appear with some degree of what we call radar speckle. \nSpeckle\n appears as \na grainy \"salt and pepper\" texture in an image. This is caused by random constructive and \ndestructive interference from the multiple scattering returns that will occur within each \nresolution cell. As an example, an homogeneous target, such as a large grass-covered field, \nwithout the effects of speckle would generally result in light-toned pixel values on an image \n(A). However, reflections from the individual blades of grass within each resolution cell results \nin some image pixels being brighter and some being darker than the average tone (B), such \nthat the field appears speckled. \n \nSpeckle is essentially a form of noise which degrades the quality of an image and may make \ninterpretation (visual or digital) more difficult. Thus, it is generally desirable to reduce speckle \nprior to interpretation and analysis. \nSpeckle reduction\n can be achieved in two ways: \n\nmulti-look processing, or  \n\nspatial filtering.  \n  \nPage 110Section 3.6 Radar Image Properties\nCanada Centre for Remote Sensing\n\n  \nMulti-look processing refers to the division of the radar beam (A) \ninto several (in this example, five) narrower sub-beams (1 to 5). \nEach sub-beam provides an independent \"look\" at the \nilluminated scene, as the name suggests. Each of these \"looks\" \nwill also be subject to speckle, but by summing and averaging \nthem together to form the final output image, the amount of \nspeckle will be reduced. \nWhile multi-looking is \nusually done during data \nacquisition, speckle reduction by spatial filtering is \nperformed on the output image in a digital (i.e. computer) \nimage analysis environment. Speckle reduction filtering \nconsists of moving a small window of a few pixels in \ndimension (e.g. 3x3 or 5x5) over each pixel in the image, \napplying a mathematical calculation using the pixel \nvalues under that window (e.g. calculating the average), and replacing the central pixel with \nthe new value. The window is moved along in both the row and column dimensions one pixel \nat a time, until the entire image has been covered. By calculating the average of a small \nwindow around each pixel, a smoothing effect is achieved and the visual appearance of the \nspeckle is reduced. \n \n \nSpeckle reduction using an averaging filter \nThis graphic shows a radar image before (top) and after (bottom) speckle reduction using an \naveraging filter. The median (or middle) value of all the pixels underneath the moving window \nis also often used to reduce speckle. Other more complex filtering calculations can be \nperformed to reduce speckle while minimizing the amount of smoothing taking place. \nPage 111Section 3.6 Radar Image Properties\nCanada Centre for Remote Sensing\n\nBoth multi-look processing and spatial filtering reduce speckle at the expense of resolution, \nsince they both essentially smooth the image. Therefore, the amount of speckle reduction \ndesired must be balanced with the particular application the image is being used for, and the \namount of detail required. If fine detail and high resolution is required then little or no multi-\nlooking/spatial filtering should be done. If broad-scale interpretation and mapping is the \napplication, then speckle reduction techniques may be more appropriate and acceptable. \nAnother property peculiar to radar images is slant-range distortion, which was discussed in \nsome detail in section 3.4. Features in the near-range are compressed relative to features in \nthe far range due to the slant-range scale variability. For most applications, it is desirable to \nhave the radar image presented in a format which corrects for this distortion, to enable true \ndistance measurements between features. This requires the slant-range image to be \nconverted to 'ground range' display. This can be done by the radar processor prior to creating \nan image or after data acquisition by applying a transformation to the slant range image. In \nmost cases, this conversion will only be an estimate of the geometry of the ground features \ndue to the complications introduced by variations in terrain relief and topography. \nA radar antenna transmits more power in the mid-range portion of the illuminated swath than \nat the near and far ranges. This effect is known as \nantenna pattern\n and results in stronger \nreturns from the center portion of the swath than at the edges. Combined with this antenna \npattern effect is the fact that the energy returned to the radar decreases dramatically as the \nrange distance increases. Thus, for a given surface, the strength of the returned signal \nbecomes smaller and smaller moving farther across the swath. These effects combine to \nproduce an image which varies in intensity (tone) in the range direction across the image. A \nprocess known as \nantenna pattern correction\n may be applied to produce a uniform average \nbrightness across the imaged swath, to better facilitate visual interpretation. \n \nThe range of brightness levels a remote sensing system can differentiate is related to \nradiometric resolution (section 2.5) and is referred to as the \ndynamic range\n. While optical \nsensors, such as those carried by satellites such as Landsat and SPOT, typically produce 256 \nintensity levels, radar systems can differentiate intensity levels up to around 100,000 levels! \nSince the human eye can only discriminate about 40 intensity levels at one time, this is too \nmuch information for visual interpretation. Even a typical computer would have difficulty \ndealing with this range of information. Therefore, most radars record and process the original \nPage 112Section 3.6 Radar Image Properties\nCanada Centre for Remote Sensing\n\ndata as 16 bits (65,536 levels of intensity), which are then further scaled down to 8 bits (256 \nlevels) for visual interpretation and/or digital computer analysis. \nCalibration\n is a process which ensures that the radar system and the signals that it measures \nare as consistent and as accurate as possible. Prior to analysis, most radar images will \nrequire \nrelative calibration\n. Relative calibration corrects for known variations in radar \nantenna and systems response and ensures that uniform, repeatable measurements can be \nmade over time. This allows relative comparisons between the response of features within a \nsingle image, and between separate images to be made with confidence. However, if we wish \nto make accurate \nquantitative\n measurements representing the actual energy or power \nreturned from various features or targets for comparative purposes, then \nabsolute \ncalibration\n is necessary. \nAbsolute calibration, a much more involved process than relative calibration, attempts to \nrelate the magnitude of the recorded signal strength to the actual amount of energy \nbackscattered from each resolution cell. To achieve this, detailed measurements of the radar \nsystem properties are required as well as quantitative measurements of the scattering \nproperties of specific targets. The latter are often obtained using ground-based \nscatterometers, as described in section 3.1. Also, devices called \ntransponders\n may be \nplaced on the ground prior to data acquisition to calibrate an image. These devices receive \nthe incoming radar signal, amplify it, and transmit a return signal of known strength back to \nthe radar. By knowing the actual strength of this return signal in the image, the responses \nfrom other features can be referenced to it. \nPage 113Section 3.6 Radar Image Properties\nCanada Centre for Remote Sensing\n\n3.7 Advanced Radar Applications \nIn addition to standard acquisition and use of radar data, there are three specific applications \nworth mentioning. \n \nThe first is \nstereo radar\n which is similar in concept to stereo mapping using aerial \nphotography (described in section 2.7). Stereo radar image pairs are acquired covering the \nsame area, but with different look/incidence angles (A), or opposite look directions (B). Unlike \naerial photos where the displacement is radially outward from the nadir point directly below \nthe camera, radar images show displacement only in the range direction. Stereo pairs taken \nfrom opposite look directions (i.e. one looking north and the other south) may show significant \ncontrast and may be difficult to interpret visually or digitally. In mountainous terrain, this will be \neven more pronounced as shadowing on opposite sides of features will eliminate the stereo \neffect. Same side stereo imaging (A) has been used operationally for years to assist in \ninterpretation for forestry and geology and also to generate topographic maps. The estimation \nof distance measurements and terrain height for topographic mapping from stereo radar data \nis called \nradargrammetry\n, and is analogous to photogrammetry carried out for similar \npurposes with aerial photographs. \n \n  \nRadargrammetry is one method of estimating terrain height using radar. Another, more \nadvanced method is called \ninterferometry\n. Interferometry relies on being able to measure a \nproperty of electromagnetic waves called \nphase\n. Suppose we have \ntwo waves\n with the exact \nPage 114Section 3.7 Advanced Radar Applications\nCanada Centre for Remote Sensing\n\nsame wavelength and frequency traveling along in space, but the starting point of one is offset \nslightly from the other. The offset between matching points on these two waves (A) is called \nthe \nphase difference\n. \nInterferometric systems\n use two \nantennas, separated in the range dimension by a small \ndistance, both recording the returns from each resolution \ncell. The two antennas can be on the same platform (as \nwith some airborne SARs), or the data can be acquired from \ntwo different passes with the same sensor, such has been \ndone with both airborne and satellite radars. By measuring \nthe exact phase \ndifference between the \ntwo returns (A), the \npath length difference can be calculated to an accuracy \nthat is on the order of the wavelength (i.e centimetres). \nKnowing the position of the antennas with respect to the \nEarth's surface, the position of the resolution cell, \nincluding its elevation, can be determined. The phase \ndifference between adjacent resolution cells, is \nillustrated in this \ninterferogram\n, where colours \nrepresents the variations in height. The information contained in an interferogram can be used \nto derive topographic information and produce \nthree-dimensional imagery\n of terrain height. \n \nThe concept of radar \npolarimetry\n was already alluded to in our discussion of radar \nfundamentals in section 3.2. As its name implies, polarimetry involves discriminating between \nthe \npolarizations\n that a radar system is able to transmit and receive. Most radars transmit \nmicrowave radiation in either horizontal (H) or vertical (V) polarization, and similarly, receive \nthe backscattered signal at only one of these polarizations. \nMulti-polarization\n radars are able \nto transmit either H or V polarization and receive both the like- and cross-polarized returns \n(e.g. HH and HV or VV and VH, where the first letter stands for the polarization transmitted \nand the second letter the polarization received). \nPolarimetric radars\n are able to transmit and \nreceive both horizontal and vertical polarizations. Thus, they are able to receive and process \nall four combinations of these polarizations: HH, HV, VH, and VV. Each of these \"polarization \nchannels\" have varying sensitivities to different surface characteristics and properties. Thus, \nPage 115Section 3.7 Advanced Radar Applications\nCanada Centre for Remote Sensing\n\nthe availability of multi-polarization data helps to improve the identification of, and the \ndiscrimination between features. In addition to recording the magnitude (i.e. the strength) of \nthe returned signal for each polarization, most polarimetric radars are also able to record the \nphase\n information of the returned signals. This can be used to further characterize the \npolarimetric \"signature\" of different surface features. \nPage 116Section 3.7 Advanced Radar Applications\nCanada Centre for Remote Sensing\n\n3.8 Radar Polarimetry \nIntroduction to Polarization \nWhen discussing microwave energy propagation and scattering, the polarization of the \nradiation is an important property. For a plane electromagnetic (EM) wave, polarization refers \nto the locus of the electric field vector in the plane perpendicular to the direction of propagation. \nWhile the length of the vector represents the \namplitude\n of the wave, and the rotation rate of \nthe vector represents the \nfrequency\n of the wave, polarization refers to the \norientation\n and \nshape\n of the pattern traced by the tip of the vector.  \nThe waveform of the electric field strength (voltage) of an EM wave can be predictable (the \nwave is polarized) or random (the wave is unpolarized), or a combination of both. In the latter \ncase, the degree of polarization describes the ratio of polarized power to total power of the \nwave. An example of a fully polarized wave would be a \nmonochromatic\n sine wave, with a \nsingle, constant frequency and stable amplitude.  \n \n \nExamples of horizontal (black) and vertical (red) polarizations of a plane electromagnetic wave \n  \nMany radars are designed to transmit microwave radiation that is either horizontally polarized \n(H) or vertically polarized (V). A transmitted wave of either polarization can generate a \nbackscattered wave with a variety of polarizations. It is the analysis of these transmit and \nreceive polarization combinations that constitutes the science of radar polarimetry. \nAny polarization on either transmission or reception can be synthesized by using H and V \ncomponents with a well-defined relationship between them. For this reason, systems that \ntransmit and receive both of these linear polarizations are commonly used. With these radars, \nthere can be four combinations of transmit and receive polarizations: \n\nHH - for horizontal transmit and horizontal receive  \n\nVV - for vertical transmit and vertical receive  \nPage 117Section 3.8 Radar Polarimetry\nCanada Centre for Remote Sensing\n\n\nHV - for horizontal transmit and vertical receive, and  \n\nVH - for vertical transmit and horizontal receive.  \n  \nThe first two polarization combinations are referred to as \"like-polarized\" because the transmit \nand receive polarizations \nare the same\n. The last two combinations are referred to as \"cross-\npolarized\" because the transmit and receive polarizations \nare orthogonal\n to one another. \nRadar systems can have one, two or all four of these transmit/receive polarization \ncombinations. Examples include the following types of radar systems: \n \n \n \nNote that \"quadrature polarization\" and \"fully polarimetric\" can be used as synonyms for \n\"polarimetric\". The \nrelative phase\n between channels is measured in a polarimetric radar, and \nis a very important component of the measurement. In the other radar types, relative phase \nmay or may not be measured. The alternating polarization mode has been introduced on \nENVISAT - relative phase is measured but the important HH-VV phase is not meaningful \nbecause of the time lapse between the measurements.  \nThese C-band images of agricultural fields demonstrate the dependence of the radar response \non polarization. The top two images are like-polarized (HH on left, VV on right), and the lower \nleft image is cross-polarized (HV). The lower right image is the result of displaying these three \nimages as a colour composite (in this case, HH - red, VV - green, and HV - blue). \nBoth wavelength and polarization affect how a radar system \"sees\" the elements in the scene. \nTherefore, radar imagery collected using different polarization and wavelength combinations \nmay provide different and complementary information. Furthermore, when three polarizations \nare combined in a colour composite, the information is presented in a way that an image \ninterpreter can infer more information of the surface characteristics. \n  \nsingle polarized\n- HH or VV (or possibly HV or VH)\ndual polarized\n- HH and HV, VV and VH, or HH and VV\nalternating polarization\n- HH and HV, alternating with VV and VH\npolarimetric\n- HH, VV, HV, and VH\nPage 118Section 3.8 Radar Polarimetry\nCanada Centre for Remote Sensing\n\n    \n \n    \n \nIllustration of how different polarizations (HH, VV, HV & colour composite) bring out different \nfeatures in an agricultural scene  \n  \nPolarimetric Information \nThe primary description of how a radar target or surface feature scatters EM energy is given by \nthe scattering matrix. From the scattering matrix, other forms of polarimetric information can be \nderived, such as synthesized images and polarization signatures. \nPolarization Synthesis \nA polarimetric radar can be used to determine the target response or scattering matrix using \ntwo orthogonal polarizations, typically linear H and linear V on each of transmit and receive. If a \nscattering matrix is known, the response of the target to \nany combination\n of incident and \nreceived polarizations can be computed. This is referred to as \npolarization synthesis\n, and \nillustrates the power and flexibility of a fully polarimetric radar. \nThrough polarization synthesis, an image can be created to improve the detectability of \nPage 119Section 3.8 Radar Polarimetry\nCanada Centre for Remote Sensing\n\nselected features. An example is the detection of ships in ocean images. To find the best \ntransmit-receive polarization combination to use, the polarization signature of a typical ship and \nthat of the ocean is calculated for a number of polarizations. Then the ratio of the ship to ocean \nbackscatter is computed for each polarization. The transmit-receive polarization combination \nthat maximises the ratio of backscatter strength is then used to improve the detectability of \nships. This procedure is called \"polarimetric contrast enhancement\" or the use of a \n\"polarimetric matched filter\".  \nPolarization Signatures \nBecause the incident and scattered waves can take on so many different polarizations, and the \nscattering matrix consists of four complex numbers, it is helpful to simplify the interpretation of \nthe scattering behaviour using three-dimensional plots. The \"polarization signature\" of the \ntarget provides a convenient way of visualising a target's scattering properties. The signatures \nare also called \"polarization response plots\". \nAn incident electromagnetic wave can be selected to have an electric field with ellipticity \nbetween -45º and +45º, and an orientation between 0 and 180º. These variables are used as \nthe x- and y-axes of a 3-D plot portraying the polarization signature. For each of these possible \nincident polarizations, the strength of the backscatter can be computed for the \nsame\n \npolarization on transmit and receive (the co-polarized signature) and for \northogonal\n \npolarizations on transmit and receive (the cross-polarized signature). The strength is displayed \non the z-axis of the signatures. \n  \nPolarization signatures of a large conducting sphere. \nP = Power, O = Orientation (degrees), E = Ellipticity (degrees) \nThis figure shows the polarization signatures of the most simple of all targets - a large \nconducting sphere or a trihedral corner reflector. The wave is backscattered with the same \npolarization, except for a change of sign of the ellipticity (or in the case of linear polarization, a \nCo-polarized signatureCross-polarized signature\n \n \nPage 120Section 3.8 Radar Polarimetry\nCanada Centre for Remote Sensing\n\nchange of the phase angle between Eh and Ev of 180o). The sign changes once for every \nreflection - the sphere represents a single reflection, and the trihedral gives three reflections, so \neach behaves as an \"odd-bounce\" reflector. \nFor more complicated targets, the polarization signature takes on different shapes. Two \ninteresting signatures come from a dihedral corner reflector and Bragg scattering from the sea \nsurface. In the case of the dihedral reflector, the co-pol signature has a double peak, \ncharacteristic of \"even-bounce\" reflectors. In the case of Bragg scattering, the response is \nsimilar to the single-bounce sphere, except that the backscatter of the vertical polarization is \nhigher than that of the horizontal polarization. \nData Calibration \nOne critical requirement of polarimetric radar systems is the need for calibration. This is \nbecause much of the information lies in the ratios of amplitudes and the differences in phase \nangle between the four transmit-receive polarization combinations. If the calibration is not \nsufficiently accurate, the scattering mechanisms will be misinterpreted and the advantages of \nusing polarization will not be realised. \nCalibration is achieved by a combination of radar system design and data analysis. Imagine the \nresponse to a trihedral corner reflector. Its ideal response is only obtained if the four channels \nof the radar system all have the same gain, system-dependent phase differences between \nchannels are absent, and there is no energy leakage from one channel to another. \nIn terms of the radar system design, the channel gains and phases should be as carefully \nmatched as possible. In the case of the phase balance, this means that the signal path lengths \nshould be effectively the same in all channels. Calibration signals are often built into the design \nto help verify these channel balances. \nIn terms of data analysis, channel balances, cross-talk and noise effects can be measured and \ncorrected by analysing the received data. In addition to analysing the response of internal \ncalibration signals, the signals from known targets such as corner reflectors, active \ntransponders, and uniform clutter can be used to calibrate some of the parameters. \n  \nPolarimetric Applications \nSynthetic Aperture Radar polarimetry has been limited to a number of experimental airborne \nSAR systems and the SIR-C (shuttle) mission. With these data, researchers have studied a \nnumber of applications, and have shown that the interpretation of a number of features in a \nscene is facilitated when the radar is operated in polarimetric mode. The launch of \nRADARSAT-2 will make polarimetric data available on an operational basis, and uses of such \ndata will become more routine and more sophisticated. \nSome applications in which polarimetric SAR has already proved useful include: \nPage 121Section 3.8 Radar Polarimetry\nCanada Centre for Remote Sensing\n\n\nAgriculture: for crop type identification, crop condition monitoring, soil moisture \nmeasurement, and soil tillage and crop residue identification;  \n\nForestry: for clearcuts and linear features mapping, biomass estimation, species \nidentification and fire scar mapping;  \n\nGeology: for geological mapping;  \n\nHydrology: for monitoring wetlands and snow cover;  \n\nOceanography: for sea ice identification, coastal windfield measurement, and wave slope \nmeasurement;  \nShipping: for ship detection and classification;  \n\nCoastal Zone: for shoreline detection, substrate mapping, slick detection and general \nvegetation mapping.  \n  \nPage 122Section 3.8 Radar Polarimetry\nCanada Centre for Remote Sensing\n\n3.9 Airborne versus Spaceborne Radars \nLike other remote sensing systems, an imaging radar sensor may be carried on either an \nairborne or spaceborne platform. Depending on the use of the prospective imagery, there are \ntrade-offs between the two types of platforms. Regardless of the platform used, a significant \nadvantage of using a Synthetic Aperture Radar (SAR) is that the spatial resolution is \nindependent of platform altitude. Thus, fine resolution can be achieved from both airborne and \nspaceborne platforms. \n \nAlthough spatial resolution is independent of altitude, viewing geometry and swath coverage \ncan be greatly affected by altitude variations. At aircraft operating altitudes, an airborne radar \nmust image over a wide range of incidence angles, perhaps as much as 60 or 70 degrees, in \norder to achieve relatively wide swaths (let's say 50 to 70 km). As we have learned in the \npreceding sections, incidence angle (or look angle) has a significant effect on the backscatter \nfrom surface features and on their appearance on an image. Image characteristics such as \nforeshortening, layover, and shadowing will be subject to wide variations, across a large \nincidence angle range. Spaceborne radars are able to avoid some of these imaging geometry \nproblems since they operate at altitudes up to one hundred times higher than airborne radars. \nAt altitudes of several hundred kilometres, spaceborne radars can image comparable swath \nwidths, but over a much narrower range of incidence angles, typically ranging from five to 15 \ndegrees. This provides for more uniform illumination and reduces undesirable imaging \nvariations across the swath due to viewing geometry. \nPage 123Section 3.9 Airborne versus Spaceborne Radars\nCanada Centre for Remote Sensing\n\n \nAlthough airborne radar systems may be more susceptible to imaging geometry problems, \nthey are flexible in their capability to collect data from different look angles and look directions. \nBy optimizing the geometry for the particular terrain being imaged, or by acquiring imagery \nfrom more than one look direction, some of these effects may be reduced. Additionally, an \nairborne radar is able to collect data anywhere and at any time (as long as weather and flying \nconditions are acceptable!). A spaceborne radar does not have this degree of flexibility, as its \nviewing geometry and data acquisition schedule is controlled by the pattern of its orbit. \nHowever, satellite radars do have the advantage of being able to collect imagery more quickly \nover a larger area than an airborne radar, and provide consistent viewing geometry. The \nfrequency of coverage may not be as often as that possible with an airborne platform, but \ndepending on the orbit parameters, the viewing geometry flexibility, and the geographic area \nof interest, a spaceborne radar may have a revisit period as short as one day. \nAs with any aircraft, an airborne radar will be susceptible to variations in velocity and other \nmotions of the aircraft as well as to environmental (weather) conditions. In order to avoid \nimage artifacts or geometric positioning errors due to random variations in the motion of the \naircraft, the radar system must use sophisticated navigation/positioning equipment and \nadvanced image processing to compensate for these variations. Generally, this will be able to \ncorrect for all but the most severe variations in motion, such as significant air turbulence. \nSpaceborne radars are not affected by motion of this type. Indeed, the geometry of their orbits \nis usually very stable and their positions can be accurately calculated. However, geometric \ncorrection of imagery from spaceborne platforms must take into account other factors, such as \nthe rotation and curvature of the Earth, to achieve proper geometric positioning of features on \nthe surface. \nPage 124Section 3.9 Airborne versus Spaceborne Radars\nCanada Centre for Remote Sensing\n\n3.10 Airborne and Spaceborne Radar Systems \nIn order to more clearly illustrate the differences between airborne and spaceborne radars, we \nwill briefly outline a few of the representative systems of each type, starting with airborne \nsystems. \n \nThe \nConvair-580 C/X SAR\n system developed and operated by the Canada Centre for \nRemote Sensing was a workhorse for experimental research into advanced SAR applications \nin Canada and around the world, particularly in preparation for satellite-borne SARs. The \nsystem was transferred to Environment Canada in 1996 for use in oil spill research and other \nenvironmental applications. This system operates at two radar bands, C- (5.66 cm) and X- \n(3.24 cm). Cross-polarization data can be recorded simultaneously for both the C- and X-band \nchannels, and the C-band system can be operated as a fully polarimetric radar. Imagery can \nbe acquired at three different imaging geometries (nadir, narrow and wide swath modes) over \na wide range of incidence angles (five degrees to almost 90 degrees). In addition to being a \nfully calibratable system for quantitative measurements, the system has a second antenna \nmounted on the aircraft fuselage to allow the C-band system to be operated as an \ninterferometric radar. \nThe \nSea Ice and Terrain Assessment (STAR)\n \nsystems operated by Intera Technologies Limited of \nCalgary, Alberta, Canada, (later Intermap \nTechnologies ) were among the first SAR systems \nused commercially around the world. Both STAR-1 \nand STAR-2 operate at X-band (3.2 cm) with HH \npolarization in two different resolution modes. The \nswath coverage varies from 19 to 50 km, and the \nresolution from 5 to 18 m. They were primarily \ndesigned for monitoring sea ice (one of the key \napplications for radar, in Canada) and for terrain \nanalysis. Radar's all-weather, day or night imaging capabilities are well-suited to monitoring \nice in Canada's northern and coastal waters. STAR-1 was also the first SAR system to use \non-board data processing and to offer real-time downlinking of data to surface stations. \n  \n  \nPage 125Section 3.10 Airborne and Spaceborne Radar Systems\nCanada Centre for Remote Sensing\n\n  \nThe United States National Aeronautics \nand Space Administration (NASA) has \nbeen at the forefront of multi-frequency, \nmulti-polarization synthetic aperture radar \nresearch for many years. The Jet \nPropulsion Laboratory (JPL) in California \nhas operated various advanced systems \non contract for NASA. The \nAirSAR\n \nsystem is a C-, L-, and P-band advanced polarimetric SAR which can collect data for each of \nthese bands at all possible combinations of horizontal and vertical transmit and receive \npolarizations (i.e. HH, HV, VH, and VV). Data from the AirSAR system can be fully calibrated \nto allow extraction of quantitative measurements of radar backscatter. Spatial resolution of the \nAirSAR system is on the order of 12 metres in both range and azimuth. Incidence angle \nranges from zero degrees at nadir to about 70 degrees at the far range. This capability to \ncollect multi-frequency, multi-polarization data over such a diverse range of incidence angles \nallows a wide variety of specialized research experiments to be carried out. \nWith the advances and success of airborne imaging radar, satellite radars \nwere the next logical step to complement the optical satellite sensors in \noperation. \nSEASAT\n, launched in 1978, was the first civilian remote sensing \nsatellite to carry a spaceborne SAR sensor. The SAR operated at L-band \n(23.5 cm) with HH polarization. The viewing geometry was fixed between \nnine and 15 degrees with a swath width of 100 km and a spatial resolution of \n25 metres. This steep viewing geometry was designed primarily for \nobservations of ocean and sea ice, but a great deal of imagery was also collected over land \nareas. However, the small incidence angles amplified foreshortening and layover effects over \nterrain with high relief, limiting its utility in these areas. Although the satellite was only \noperational for three months, it demonstrated the wealth of information (and the large volumes \nof data!) possible from a spaceborne radar. \nWith the success of the short-lived SEASAT mission, and \nimpetus provided from positive results with several airborne \nSARs, the European Space Agency (ESA) launched ERS-1 \nin July of 1991. \nERS-1\n carried on-board a radar altimeter, an \ninfrared radiometer and microwave sounder, and a C-band \n(5.66 cm), active microwave instrument. This is a flexible \ninstrument which can be operated as a scatterometer to \nmeasure reflectivity of the ocean surface, as well as ocean \nsurface wind speed and direction. It can also operate as a \nsynthetic aperture radar, collecting imagery over a 100 km \nswath over an incidence angle range of 20 to 26 degrees, at \na resolution of approximately 30 metres. Polarization is \nPage 126Section 3.10 Airborne and Spaceborne Radar Systems\nCanada Centre for Remote Sensing\n\nvertical transmit and vertical receive (VV) which, combined \nwith the fairly steep viewing angles, make ERS-1 particularly sensitive to surface roughness. \nThe revisit period (or repeat cycle) of ERS-1 can be varied by adjusting the orbit, and has \nranged from three to 168 days, depending on the mode of operation. Generally, the repeat \ncycle is about 35 days. A second satellite, ERS-2, was launched in April of 1995 and carries \nthe same active microwave sensor as ERS-1. Designed primarily for ocean monitoring \napplications and research, ERS-1 provided the worldwide remote sensing community with the \nfirst wide-spread access to spaceborne SAR data. Imagery from both satellites has been used \nin a wide range of applications, over both ocean and land environments. Like SEASAT, the \nsteep viewing angles limit their utility for some land applications due to geometry effects. \nThe National Space Development Agency of Japan \n(NASDA), launched the \nJERS-1\n satellite in February of \n1992. In addition to carrying two optical sensors, JERS-\n1 has an L-band (23.5 cm) SAR operating at HH \npolarization. The swath width is approximately 75 km \nand spatial resolution is approximately 18 metres in \nboth range and azimuth. The imaging geometry of \nJERS-1 is slightly shallower than either SEASAT or the \nERS satellites, with the incidence angle at the middle of \nthe swath being 35 degrees. Thus, JERS-1 images are \nslightly less susceptible to geometry and terrain effects. \nThe longer L-band wavelength of JERS-1 allows some penetration of the radar energy \nthrough vegetation and other surface types. \nSpaceborne SAR remote sensing took a giant leap forward \nwith the launch of Canada's \nRADARSAT\n satellite on Nov. \n4, 1995. The RADARSAT project, led by the Canadian \nSpace Agency (CSA), was built on the development of \nremote sensing technologies and applications work carried \nout by the Canada Centre for Remote Sensing (CCRS) \nsince the 1970s. RADARSAT carries an advanced C-band (5.6 cm), HH-polarized SAR with a \nsteerable radar beam allowing \nvarious imaging options\n over a 500 km range. Imaging \nswaths can be varied from 35 to 500 km in width, with resolutions from 10 to 100 metres. \nViewing geometry is also flexible, with incidence angles ranging from less than 20 degrees to \nmore than 50 degrees. Although the satellite's orbit repeat cycle is 24 days, the flexibility of \nthe steerable radar beam gives RADARSAT the ability to image regions much more frequently \nand to address specific geographic requests for data acquisition. RADARSAT's orbit is \noptimized for frequent coverage of mid-latitude to polar regions, and is able to provide daily \nimages of the entire Arctic region as well as view any part of Canada within three days. Even \nat equatorial latitudes, complete coverage can be obtained within six days using the widest \nswath of 500 km. \nPage 127Section 3.10 Airborne and Spaceborne Radar Systems\nCanada Centre for Remote Sensing\n\n \nImaging options over a 500 km range \nPage 128Section 3.10 Airborne and Spaceborne Radar Systems\nCanada Centre for Remote Sensing\n\n3. Endnotes\n \n \n3.11 Endnotes \nYou have just completed Chapter 3 - Microwave Sensing. You can continue to Chapter 4 - \nImage Interpretation and Analysis or first browse the CCRS Web site for other articles related \nto microwave remote sensing. \nYou can get more information about remote sensing radars by checking out an the overview\n1\n \nor the more detailed technical specifications\n2\n of Canada's own microwave satellite: \nRADARSAT. You can even see photos\n3\n of the satellite being built, watch a video of the \nlaunch and see the very first image!\n4\nAs well, learn how microwave remote sensing is used for \nvarious applications such as agriculture\n5\n, forestry\n6\n, and geology\n7\n, and see international \napplications\n8\n of RADARSAT imagery.\n \nLearn about a new way of reducing speckle\n9\n in a radar image that was developed by \nscientists at CCRS in co-operation with scientists in France. As well, learn how a digital \nelevation model can be used to correct topographic distortions\n10\n in radar images or how a \nradar image is calibrated using precision transponders\n11\nand see the mysterious movement of \nthe transponder\n12\n when shown in an image!\n \nA training manual\n13\n has been prepared on how radar data can be used to obtain stereo \nimages. Interferometry\n14\n is another fascinating technique studied extensively at CCRS. It has \nbeen tried with both airborne and satellite data and applied to detecting changes in the land\n15\n, \nglacier movement\n16\n and ocean studies\n17\n.\n \nOur Remote Sensing Glossary has extensive terminology and explanations of microwave-\nrelated concepts which can be accessed through individual term searches\n18\n or by selecting \nthe radar\" category.  \n1\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/specs/rsatoview_e.html\n \n2\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/specs/radspec_e.html\n \n3\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/photos/radpix_e.html\n \n4\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/photos/radpix_e.html\n \n5\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbagri_e.html\n \n6\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbfort_e.html\n \nPage 129Section 3.11 Endnotes\nCanada Centre for Remote Sensing\n\n7\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbgeol_e.html\n \n8\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbgbsar_e.html\n \n9\nhttp://www.ccrs.nrcan.gc.ca/ccrs/com/rsnewsltr/2303/2303ap1_e.html\n \n10\nhttp://www.ccrs.nrcan.gc.ca/ccrs/com/rsnewsltr/2401/2401ap3_e.html\n \n11\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/trans/transpo_e.html\n \n12\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/ana/transpond/rpt_e.html\n \n13\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/tutorials/stereosc/chap1/chapter1_1_e.html\n \n14\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/airborne/sarbro/sbinter_e.html\n \n15\nhttp://www.ccrs.nrcan.gc.ca/ccrs/com/rsnewsltr/2301/2301rn2_e.html\n \n16\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/ant/rant01_e.html\n \n17\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/ana/split/insar_e.html\n \n18\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/terms/glossary/glossary_e.html\n \nPage 130Section 3.11 Endnotes\nCanada Centre for Remote Sensing\n\n3. Did You Know?\n \n \n3.1 Did You Know? \n \n'S' band magnetrons are typically used for microwave oven power sources. They operate in \nthe range of 2-4 GHz. The corresponding wavelengths are 15 cm to 7.5 cm. The screening \nmesh used on microwave oven doors is sufficiently fine (much smaller than 7.5 cm) that it \nbehaves as a continuous, thin, metal sheet, preventing the escape of the radar energy, yet \nallowing good visibility of the interior (using visible wavelengths, which are much shorter yet). \nPage 131Section 3 Did you know?\nCanada Centre for Remote Sensing\n\n3.2 Did You Know? \n\"....Just what do those numbers mean?!\"  \n \nTypical output products (e.g. RADARSAT imagery) have used 8-bit or 16-bit data formats \n(digital numbers) for data storage. In order to obtain the original physically meaningful \nbackscatter values ( sigma nought, beta nought) of calibrated radar products, it is \nnecessary to reverse the final steps in the SAR processing chain. For RADARSAT imagery, \nthis must include the squaring of the digital values and the application of a lookup table (which \ncan have range dependent values). Thus, as you can see, the relationships among the digital \nnumbers in the imagery are not that simple! \nPage 132Section 3 Did you know?\nCanada Centre for Remote Sensing\n3.4 Did You Know? \n\"...look to the left, look to the right, stand up, sit down...\"  \n...although a radar's side-looking geometry can \nresult in several image effects such as \nforeshortening, layover, and shadow, this geometry \nis exactly what makes radar so useful for terrain \nanalysis. These effects, if not too severe, actually \nenhance the visual appearance of relief and terrain \nstructure, making radar imagery excellent for \napplications such as topographic mapping and \nidentifying geologic structure.  \n\n3.5 Did You Know? \n\"...rivers in the Sahara desert?...you're crazy!...\" \n \n... that an L-band radar (23.5 cm wavelength) imaging from the orbiting space shuttle was \nable to discover ancient river channels beneath the Sahara Desert in Northern Africa. \nBecause of the long wavelength and the extreme dryness of the sand, the radar was able to \npenetrate several metres below the desert surface to reveal the old river beds during ancient \ntimes when this area was not so dry. \nPage 133Section 3.Did you know?\nCanada Centre for Remote Sensing\n3.7 Did You Know? \n\"...we've picked up an unidentified moving object on the radar, sir...\" \n \n... besides being able to determine terrain height using interferometry, it is also possible to \nmeasure the velocity of targets moving towards or away from the radar sensor, using only one \npass over the target. This is done by recording the returns from two antennas mounted on the \nplatform, separated by a short distance in the along-track or flight direction. The phase \ndifferences between the returns at each antenna are used to derive the speed of motion of \ntargets in the illuminated scene. Potential applications include determination of sea-ice drift, \nocean currents, and ocean wave parameters. \n\n3.8 Did You Know? \nThat many other polarizations can be transmitted (or received) if a radar system can transmit \nor receive the H and V channels simultaneously. For example, if a radar system transmits an \nH and a V signal simultaneously, and the V signal is 90o out of phase with respect to the H \nsignal, the resulting transmitted wave will have circular polarization. \nPage 134Section 3 Did you know?\nCanada Centre for Remote Sensing\n\n3. Whiz Quiz and Answers\n \n \nPage 135Section 3 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n3.2 Answers \n1. Much the same as with optical sensors that have different bands or channels of data, multi-\nwavelength and multi-frequency radar images can provide complementary information. Radar \ndata collected at different wavelengths is analogous to the different bands of data in optical \nremote sensing. Similarly, the various polarizations may also be considered as different bands \nof information. Depending on the wavelength and polarization of the radar energy, it will \ninteract differently with features on the surface. As with multi-band optical data, we can \ncombine these different \"channels\" of data together to produce colour images which may \nhighlight subtle variations in features as a function of wavelength or polarization. \n2. A scatterometer is used to precisely measure the intensity of backscatter reflected from an \nobject or surface. By accurately characterizing (i.e. measuring) the intensity of energy \nreflected from a variety of objects or surface types, these measurements can be used to \ngenerate typical \nbackscatter signatures\n, similar to the concept of spectral signatures with \noptical data. These measurements can be used as references for calibrating imagery from an \nimaging radar sensor so that more accurate comparisons can be made of the response \nbetween different features. \n3.2 Whiz Quiz \nHow could we use radar images of different \nwavelengths and/or polarizations to extract \nmore information about a particular scene? \nThink back to Chapter 1, the general \ncharacteristics of remote sensing images, \nand Chapter 2, interpretation of data from \noptical sensors. \nExplain how data from a non-imaging \nscatterometer could be used to extract more \naccurate information from an imaging radar. \n\n3.3 Whiz Quiz \n \nExplain why the use of a synthetic aperture radar (SAR) is the only practical option for radar \nremote sensing from space.  \nPage 136Section 3 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n3.3 Answer \nThe high altitudes of spaceborne platforms (i.e. hundreds of kilometres) preclude the use of \nreal aperture radar (RAR) because the azimuth resolution, which is a function of the range \ndistance, would be too coarse to be useful. In a spaceborne RAR, the only way to achieve fine \nresolution would be to have a very, very narrow beam which would require an extremely long \nphysical antenna. However, an antenna of several kilometres in length is physically \nimpossible to build, let alone fly on a spacecraft. Therefore, we need to use synthetic aperture \nradar to synthesize a long antenna to achieve fine azimuth resolution.  \n\n3.5 Whiz Quiz \n \nIf an agricultural area, with crops such as wheat and corn, became flooded, what do you think \nthese areas might look like on a radar image? Explain the reasons for your answers based on \nyour knowledge of how radar energy interacts with a target.  \nPage 137Section 3 Whiz Quiz and Answers\n3.5 Answer \nGenerally, image brightness increases with increased moisture content. However, in the case \nof flooding, the surface is completely saturated and results in standing water. Areas where the \nwater has risen above the height of the crops will likely appear dark in tone, as the water acts \nas a specular reflector bouncing the energy away from the radar sensor. Flooded areas would \ngenerally be distinguishable by a darker tone from the surrounding agricultural crops which \nare not flooded and would scatter more diffusely. However, if the wheat and corn stalks are \nnot completely submersed, then these areas may actually appear brighter on the image. In \nthis situation, specular reflections off the water which then bounce and hit the wheat and corn \nstalks may act like corner reflectors and return most of the incoming energy back to the radar. \nThis would result in these areas appearing quite bright on the image. Thus, the degree of \nflooding and how much the crops are submersed will impact the appearance of the image. \n\n3.6 Whiz Quiz \n \nOutline the basic steps you might want to perform on a radar image before carrying out any \nvisual interpretation. \nPage 138Section 3 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n3.6 Answer \nBefore visually interpreting and analyzing a radar image, there are several procedures which \nwould be useful to perform, including: \n\nConverting the slant-range image to the ground-range plane display. This will remove \nthe effects of slant-range scale distortion so that features appear in their proper relative \nsize across the entire swath and distances on the ground are represented correctly.  \n\nCorrecting for antenna pattern. This will provide a uniform average brightness of image \ntone making visual interpretation and comparison of feature responses at different \nranges easier.  \n\nReducing the effects of speckle to some degree. Unless there is a need for detailed \nanalysis of very small features (i.e. less than a few pixels in size), speckle reduction will \nreduce the \"grainy\" appearance of the image and make general image interpretation \nsimpler.  \n\nScaling of the dynamic range in the image to a maximum of 8-bits (256 grey levels). \nBecause of the limitations of most desktop computer systems, as well as of the human \neye in discriminating brightness levels, any more grey levels would not be useful.  \n\n3.8 Whiz Quiz \n \nCan sound waves be polarized? \nPage 139Section 3 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n3.8 Answer \nPolarization is a phenomenon which is characteristic \nof those waves that vibrate in a direction \nperpendicular to their direction of propagation. While \nelectromagnetic waves vibrate up/down, side to side \nand in intermediate directions, sound waves vibrate in \nthe same direction as their direction of travel, so \ncannot be polarized. \n \n\n3.10 Whiz Quiz \n \nA particular object or feature may not have the same appearance (i.e. backscatter response) \non all radar images, particularly airborne versus spaceborne radars. List some of the factors \nwhich might account for this.  \nPage 140Section 3 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n3.10 Answer \nThe backscatter response, and thus the appearance of an object or feature on a radar image, \nis dependent on several things. \n\nDifferent radar wavelengths or frequencies will result in variations due to their differing \nsensitivities to surface roughness, which controls the amount of energy backscattered.  \n\nUsing different polarizations will also affect how the energy interacts with a target and \nthe subsequent energy that is reflected back to the radar.  \n\nVariations in viewing geometry, including look/incidence angle, the look direction and \norientation of features to the radar, and the local incidence angle at which the radar \nenergy strikes the surface, play a major role in the amount of energy reflected. \nGenerally, these differences can be quite significant between airborne and spaceborne \nplatforms.  \n\nChanges in the moisture content of an object or feature will also change the amount of \nbackscatter.  \n\n4. Image Analysis\n \n \n4.1 Introduction \n \nIn order to take advantage of and make good use of remote sensing data, we must be able to \nextract meaningful information from the imagery. This brings us to the topic of discussion in \nthis chapter - \ninterpretation and analysis\n - the sixth element of the remote sensing process \nwhich we defined in Chapter 1. Interpretation and analysis of remote sensing imagery involves \nthe identification and/or measurement of various targets in an image in order to extract useful \ninformation about them. Targets in remote sensing images may be any feature or object which \ncan be observed in an image, and have the following characteristics: \n\nTargets may be a point, line, or area feature. This means that they can have any form, \nfrom a bus in a parking lot or plane on a runway, to a bridge or roadway, to a large \nexpanse of water or a field.  \nThe target must be distinguishable; it must contrast with other features around it in the \nimage.  \n  \nPage 141Section 4.1 Introduction\nCanada Centre for Remote Sensing\n\n \nMuch interpretation and identification of targets in remote sensing imagery is performed \nmanually or visually, i.e. by a human interpreter. In many cases this is done using imagery \ndisplayed in a pictorial or photograph-type format, independent of what type of sensor was \nused to collect the data and how the data were collected. In this case we refer to the data as \nbeing in \nanalog\n format. As we discussed in Chapter 1, remote sensing images can also be \nrepresented in a computer as arrays of pixels, with \neach pixel corresponding to a digital number, \nrepresenting the brightness level of that pixel in the \nimage. In this case, the data are in a \ndigital\n format. \nVisual interpretation may also be performed by \nexamining digital imagery displayed on a computer \nscreen. Both analogue and digital imagery can be \ndisplayed as black and white (also called \nmonochrome) images, or as colour images (refer \nback to Chapter 1, Section 1.7) by combining different \nchannels or bands representing different \nwavelengths. \nWhen remote sensing data are available in digital format, \ndigital processing and analysis\n \nmay be performed using a computer. Digital processing may be used to enhance data as a \nprelude to visual interpretation. Digital processing and analysis may also be carried out to \nautomatically identify targets and extract information completely without manual intervention \nby a human interpreter. However, rarely is digital processing and analysis carried out as a \ncomplete replacement for manual interpretation. Often, it is done to supplement and assist the \nhuman analyst. \n  \nManual interpretation and analysis dates back to the early beginnings of remote sensing for \nPage 142Section 4.1 Introduction\nCanada Centre for Remote Sensing\n\nair photo interpretation. Digital processing and analysis is more recent with the advent of \ndigital recording of remote sensing data and the development of computers. Both manual and \ndigital techniques for interpretation of remote sensing data have their respective advantages \nand disadvantages. Generally, manual interpretation requires little, if any, specialized \nequipment, while digital analysis requires specialized, and often expensive, equipment. \nManual interpretation is often limited to analyzing only a single channel of data or a single \nimage at a time due to the difficulty in performing visual interpretation with multiple images. \nThe computer environment is more amenable to handling complex images of several or many \nchannels or from several dates. In this sense, digital analysis is useful for simultaneous \nanalysis of many spectral bands and can process large data sets much faster than a human \ninterpreter. Manual interpretation is a subjective process, meaning that the results will vary \nwith different interpreters. Digital analysis is based on the manipulation of digital numbers in a \ncomputer and is thus more objective, generally resulting in more consistent results. However, \ndetermining the validity and accuracy of the results from digital processing can be difficult. \nIt is important to reiterate that visual and digital analyses of remote sensing imagery are not \nmutually exclusive. Both methods have their merits. In most cases, a mix of both methods is \nusually employed when analyzing imagery. In fact, the ultimate decision of the utility and \nrelevance of the information extracted at the end of the analysis process, still must be made \nby humans. \nPage 143Section 4.1 Introduction\nCanada Centre for Remote Sensing\n\n4.2 Elements of Visual Interpretation \nAs we noted in the previous section, analysis of remote sensing imagery involves the \nidentification of various targets in an image, and those targets may be environmental or \nartificial features which consist of points, lines, or areas. Targets may be defined in terms of \nthe way they reflect or emit radiation. This radiation is measured and recorded by a sensor, \nand ultimately is depicted as an image product such as an air photo or a satellite image. \nWhat makes interpretation of imagery more difficult than the everyday visual interpretation of \nour surroundings? For one, we lose our sense of depth when viewing a two-dimensional \nimage, unless we can view it \nstereoscopically\n so as to simulate the third dimension of \nheight. Indeed, interpretation benefits greatly in many applications when images are viewed in \nstereo, as visualization (and therefore, recognition) of targets is enhanced dramatically. \nViewing objects from directly above also provides a very different perspective than what we \nare familiar with. Combining an unfamiliar perspective with a very different scale and lack of \nrecognizable detail can make even the most familiar object unrecognizable in an image. \nFinally, we are used to seeing only the visible wavelengths, and the imaging of wavelengths \noutside of this window is more difficult for us to comprehend. \nRecognizing targets is the key to interpretation and information extraction. Observing the \ndifferences between targets and their backgrounds involves comparing different targets based \non any, or all, of the visual elements of \ntone, shape, size, pattern, texture, shadow, and \nassociation\n. Visual interpretation using these elements is often a part of our daily lives, \nwhether we are conscious of it or not. Examining satellite images on the weather report, or \nfollowing high speed chases by views from a helicopter are all familiar examples of visual \nimage interpretation. Identifying targets in remotely sensed images based on these visual \nelements allows us to further interpret and analyze. The nature of each of these interpretation \nelements is described below, along with an image example of each. \n \nTone\n refers to the relative brightness or colour of objects in an image. Generally, tone is the \nfundamental element for distinguishing between different targets or features. Variations in \nPage 144Section 4.2 Elements of Visual Interpretation\nCanada Centre for Remote Sensing\n\ntone also allows the elements of shape, texture, and pattern of objects to be distinguished. \n \nShape\n refers to the general form, structure, or outline of individual objects. Shape can be a \nvery distinctive clue for interpretation. Straight edge shapes typically represent urban or \nagricultural (field) targets, while natural features, such as forest edges, are generally more \nirregular in shape, except where man has created a road or clear cuts. Farm or crop land \nirrigated by rotating sprinkler systems would appear as circular shapes. \n \nSize\n of objects in an image is a function of scale. It is important to assess the size of a target \nrelative to other objects in a scene, as well as the absolute size, to aid in the interpretation of \nthat target. A quick approximation of target size can direct interpretation to an appropriate \nresult more quickly. For example, if an interpreter had to distinguish zones of land use, and \nhad identified an area with a number of buildings in it, large buildings such as factories or \nwarehouses would suggest commercial property, whereas small buildings would indicate \nresidential use. \n  \nPage 145Section 4.2 Elements of Visual Interpretation\nCanada Centre for Remote Sensing\n\n  \n  \nPattern\n refers to the spatial arrangement of visibly discernible objects. \nTypically an orderly repetition of similar tones and textures will produce a \ndistinctive and ultimately recognizable pattern. Orchards with evenly \nspaced trees, and urban streets with regularly spaced houses are good \nexamples of pattern. \nTexture\n refers to the arrangement and frequency of \ntonal variation in particular areas of an image. Rough textures would \nconsist of a mottled tone where the grey levels change abruptly in a small \narea, whereas smooth textures would have very little tonal variation. \nSmooth textures are most often the result of uniform, even surfaces, such \nas fields, asphalt, or grasslands. A target with a rough surface and \nirregular structure, such as a forest canopy, results in a rough textured \nappearance. Texture is one of the most important elements for distinguishing features in radar \nimagery. \nShadow\n is also helpful in interpretation as it may provide an idea of the \nprofile and relative height of a target or targets which may make \nidentification easier. However, shadows can also reduce or eliminate \ninterpretation in their area of influence, since targets within shadows are \nmuch less (or not at all) discernible from their surroundings. Shadow is \nalso useful for enhancing or identifying topography and landforms, \nparticularly in radar imagery. \nAssociation\n takes into account the relationship between other \nrecognizable objects or features in proximity to the target of interest. The \nidentification of features that one would expect to associate with other \nfeatures may provide information to facilitate identification. In the \nexample given above, commercial properties may be associated with \nproximity to major transportation routes, whereas residential areas would \nbe associated with schools, playgrounds, and sports fields. In our \nexample, a lake is associated with boats, a marina, and adjacent recreational land. \nPage 146Section 4.2 Elements of Visual Interpretation\nCanada Centre for Remote Sensing\n\n4.3 Digital Image Processing  \n \nIn today's world of advanced technology where most remote sensing data are recorded in \ndigital format, virtually all image interpretation and analysis involves some element of digital \nprocessing. Digital image processing may involve numerous procedures including formatting \nand correcting of the data, digital enhancement to facilitate better visual interpretation, or even \nautomated classification of targets and features entirely by computer. In order to process \nremote sensing imagery digitally, the data must be recorded and available in a digital form \nsuitable for storage on a computer tape or disk. Obviously, the other requirement for digital \nimage processing is a computer system, sometimes referred to as an \nimage analysis \nsystem\n, with the appropriate hardware and software to process the data. Several \ncommercially available software systems have been developed specifically for remote sensing \nimage processing and analysis. \nFor discussion purposes, most of the common image processing functions available in image \nanalysis systems can be categorized into the following four categories:  \nPreprocessing  \n\nImage Enhancement  \nImage Transformation  \n\nImage Classification and Analysis  \nPreprocessing\n functions involve those operations that are normally required prior to the main \ndata analysis and extraction of information, and are generally grouped \nas radiometric or \ngeometric corrections\n. Radiometric corrections include correcting the data for sensor \nirregularities and unwanted sensor or atmospheric noise, and converting the data so they \naccurately represent the reflected or emitted radiation measured by the sensor. Geometric \ncorrections include correcting for geometric distortions due to sensor-Earth geometry \nvariations, and conversion of the data to real world coordinates (e.g. latitude and longitude) on \nthe Earth's surface. \nPage 147Section 4.3 Digital Image Processing\nCanada Centre for Remote Sensing\n\n  \nThe objective of the second group of image processing functions grouped under the term of \nimage enhancement\n, is solely to \nimprove the appearance of the imagery\n to assist in visual \ninterpretation and analysis. Examples of enhancement functions include contrast stretching to \nincrease the tonal distinction between various features in a scene, and \nspatial filtering\n to \nenhance (or suppress) specific spatial patterns in an image. \nImage transformations\n are operations similar in concept to those for image enhancement. \nHowever, unlike image enhancement operations which are normally applied only to a single \nchannel of data at a time, image transformations usually involve combined processing of data \nfrom multiple spectral bands. Arithmetic operations (i.e. subtraction, addition, multiplication, \ndivision) are performed to combine and transform the original bands into \"new\" images which \nbetter display or highlight certain features in the scene. We will look at some of these \noperations including various methods of \nspectral or band\n ratioing, and a procedure called \nprincipal components analysis\n which is used to more efficiently represent the information in \nmultichannel imagery. \n \nImage classification and analysis\noperations are used to digitally identify and classify pixels \nin the data. \nClassification\n is usually performed on multi-channel data sets (A) and this \nprocess assigns each pixel in an image to a particular class or theme (B) based on statistical \ncharacteristics of the pixel brightness values. There are a variety of approaches taken to \nperform digital classification. We will briefly describe the two generic approaches which are \nused most often, namely \nsupervised\n and \nunsupervised\n classification. \nIn the following sections we will describe each of these four categories of digital image \nprocessing functions in more detail. \nPage 148Section 4.3 Digital Image Processing\nCanada Centre for Remote Sensing\n\n4.4 Pre-processing \nPre-processing operations, sometimes referred to as image restoration and rectification, are \nintended to correct for sensor- and platform-specific radiometric and geometric distortions of \ndata. Radiometric corrections may be necessary due to variations in scene illumination and \nviewing geometry, atmospheric conditions, and sensor noise and response. Each of these will \nvary depending on the specific sensor and platform used to acquire the data and the \nconditions during data acquisition. Also, it may be desirable to convert and/or calibrate the \ndata to known (absolute) radiation or reflectance units to facilitate comparison between data. \n \nVariations in illumination and viewing geometry between images (for optical sensors) can be \ncorrected by modeling the geometric relationship and distance between the area of the \nEarth's surface imaged, the sun, and the sensor. This is often required so as to be able to \nmore readily compare images collected by different sensors at different dates or times, or to \nmosaic multiple images from a single sensor\n while maintaining uniform illumination \nconditions from scene to scene. \n \n  \nAs we learned in Chapter 1, scattering of radiation occurs as it passes through and interacts \nwith the atmosphere. This scattering may reduce, or attenuate, some of the energy \nilluminating the surface. In addition, the atmosphere will further attenuate the signal \npropagating from the target to the sensor. Various methods of atmospheric correction can be \nPage 149Section 4.4 Pre-processing\nCanada Centre for Remote Sensing\n\napplied ranging from detailed modeling of the atmospheric conditions during data acquisition, \nto simple calculations based solely on the image data. An example of the latter method is to \nexamine the observed brightness values\n (digital numbers), in an area of shadow or for a \nvery dark object (such as a large clear lake - A) and determine the minimum value (B). The \ncorrection is applied by subtracting the minimum observed value, determined for each specific \nband, from all pixel values in each respective band. Since scattering is wavelength dependent \n(Chapter 1), the minimum values will vary from band to band. This method is based on the \nassumption that the reflectance from these features, if the atmosphere is clear, should be very \nsmall, if not zero. If we observe values much greater than zero, then they are considered to \nhave resulted from atmospheric scattering. \nNoise in an image may be due to irregularities or \nerrors that occur in the sensor response and/or \ndata recording and transmission. Common forms \nof noise include systematic \nstriping\n or banding \nand \ndropped lines\n. Both of these effects should \nbe corrected before further enhancement or \nclassification is performed. Striping was common \nin early Landsat MSS data due to variations and \ndrift in the response over time of the six MSS \ndetectors. The \"drift\" was different for each of the \nsix \ndetectors, \ncausing the \nsame \nbrightness to be represented differently by each \ndetector. The overall appearance was thus a 'striped' \neffect. The corrective process made a relative correction \namong the six sensors to bring their apparent values in \nline with each other. Dropped lines occur when there are \nsystems errors which result in missing or defective data \nalong a scan line. Dropped lines are normally 'corrected' \nby replacing the line with the pixel values in the line \nabove or below, or with the average of the two. \nFor many quantitative applications of remote sensing data, it is necessary to convert the \ndigital numbers to measurements in units which represent the actual reflectance or emittance \nfrom the surface. This is done based on detailed knowledge of the sensor response and the \nway in which the analog signal (i.e. the reflected or emitted radiation) is converted to a digital \nnumber, called \nanalog-to-digital\n (A-to-D) conversion. By solving this relationship in the \nreverse direction, the absolute radiance can be calculated for each pixel, so that comparisons \ncan be accurately made over time and between different sensors. \nIn section 2.10 in Chapter 2, we learned that all remote sensing imagery are inherently subject \nPage 150Section 4.4 Pre-processing\nCanada Centre for Remote Sensing\n\nto geometric distortions. These distortions may be due to several factors, including: the \nperspective of the sensor optics; the motion of the scanning system; the motion of the \nplatform; the platform altitude, attitude, and velocity; the terrain relief; and, the curvature and \nrotation of the Earth. Geometric corrections are intended to compensate for these distortions \nso that the geometric representation of the imagery will be as close as possible to the real \nworld. Many of these variations are \nsystematic\n, or \npredictable\n in nature and can be \naccounted for by accurate modeling of the sensor and platform motion and the geometric \nrelationship of the platform with the Earth. Other \nunsystematic\n, or \nrandom\n, errors cannot be \nmodeled and corrected in this way. Therefore, \ngeometric registration\n of the imagery to a \nknown ground coordinate system must be performed. \n  \n \nThe \ngeometric registration process\n involves identifying the image coordinates (i.e. row, \ncolumn) of several clearly discernible points, called \nground control points\n (or \nGCPs\n), in the \ndistorted image (A - A1 to A4), and matching them to their true positions in ground \ncoordinates (e.g. latitude, longitude). The true ground coordinates are typically measured from \na map (B - B1 to B4), either in paper or digital format. This is \nimage-to-map registration\n. \nOnce several well-distributed GCP pairs have been identified, the coordinate information is \nprocessed by the computer to determine the proper transformation equations to apply to the \noriginal (row and column) image coordinates to map them into their new ground coordinates. \nGeometric registration may also be performed by registering one (or more) images to another \nimage, instead of to geographic coordinates. This is called image-to-image registration and is \noften done prior to performing various image transformation procedures, which will be \ndiscussed in section 4.6, or for multitemporal image comparison. \nPage 151Section 4.4 Pre-processing\nCanada Centre for Remote Sensing\n\n \nIn order to actually geometrically correct the original distorted image, a procedure called \nresampling\n is used to determine the digital values to place in the new pixel locations of the \ncorrected output image. The resampling process calculates the new pixel values from the \noriginal digital pixel values in the uncorrected image. There are three common methods for \nresampling: \nnearest neighbour, bilinear interpolation\n, and \ncubic convolution\n. \nNearest \nneighbour\n resampling uses the digital value from the pixel in the original image which is \nnearest to the new pixel location in the corrected image. This is the simplest method and does \nnot alter the original values, but may result in some pixel values being duplicated while others \nare lost. This method also tends to result in a disjointed or blocky image appearance. \nBilinear interpolation\n resampling takes a \nweighted average of four pixels in the original \nimage nearest to the new pixel location. The \naveraging process alters the original pixel values \nand creates entirely new digital values in the \noutput image. This may be undesirable if further \nprocessing and analysis, such as classification \nbased on spectral response, is to be done. If this \nis the case, resampling may best be done after \nthe classification process. \nCubic convolution\n \nresampling goes even further to calculate a \ndistance weighted average of a block of sixteen \npixels from the original image which surround the \nnew output pixel location. As with bilinear interpolation, this method results in completely new \npixel values. However, these two methods both produce images which have a much sharper \nappearance and avoid the blocky appearance of the nearest neighbour method. \nPage 152Section 4.4 Pre-processing\nCanada Centre for Remote Sensing\n\n \nPage 153Section 4.4 Pre-processing\nCanada Centre for Remote Sensing\n\n4.5 Image Enhancement \nEnhancements are used to make it easier for visual interpretation and understanding of \nimagery. The advantage of digital imagery is that it allows us to manipulate the digital pixel \nvalues in an image. Although radiometric corrections for illumination, atmospheric influences, \nand sensor characteristics may be done prior to distribution of data to the user, the image may \nstill not be optimized for visual interpretation. Remote sensing devices, particularly those \noperated from satellite platforms, must be designed to cope with levels of target/background \nenergy which are typical of all conditions likely to be encountered in routine use. With large \nvariations in spectral response from a diverse range of targets (e.g. forest, deserts, \nsnowfields, water, etc.) no generic radiometric correction could optimally account for and \ndisplay the optimum brightness range and contrast for all targets. Thus, for each application \nand each image, a custom adjustment of the range and distribution of brightness values is \nusually necessary. \nIn raw imagery, the useful data often populates only a small portion \nof the available range of digital values (commonly 8 bits or 256 \nlevels). Contrast enhancement involves changing the original values \nso that more of the available range is used, thereby increasing the \ncontrast between targets and their backgrounds. The key to \nunderstanding contrast enhancements is to understand the concept \nof an \nimage histogram\n. A histogram is a graphical representation of \nthe brightness values that comprise an image. The brightness values \n(i.e. 0-255) are displayed along the x-axis of the graph. The \nfrequency of occurrence of each of these values in the image is \nshown on the y-axis. \n \nBy manipulating the range of digital values in an image, graphically represented by its \nhistogram, we can apply various enhancements to the data. There are many different \ntechniques and methods of enhancing contrast and detail in an image; we will cover only a \nPage 154Section 4.5 Image Enhancement\nCanada Centre for Remote Sensing\n\nfew common ones here. The simplest type of enhancement is a \nlinear contrast stretch\n. This \ninvolves identifying lower and upper bounds from the histogram (usually the minimum and \nmaximum brightness values in the image) and applying a transformation to stretch this range \nto fill the full range. In our example, the minimum value (occupied by actual data) in the \nhistogram is 84 and the maximum value is 153. These 70 levels occupy less than one-third of \nthe full 256 levels available. A linear stretch uniformly expands this small range to cover the \nfull range of values from 0 to 255. This enhances the contrast in the image with light toned \nareas appearing lighter and dark areas appearing darker, making visual interpretation much \neasier. This graphic illustrates the increase in contrast in an image before (left) and after \n(right) a linear contrast stretch. \n  \n  \nA uniform distribution of the input range of \nvalues across the full range may not always \nbe an appropriate enhancement, particularly \nif the input range is not uniformly distributed. \nIn this case, a \nhistogram-equalized \nstretch\n may be better. This stretch assigns \nmore display values (range) to the \nfrequently occurring portions of the \nhistogram. In this way, the detail in these \nareas will be better enhanced relative to \nthose areas of the original histogram where \nvalues occur less frequently. In other cases, \nit may be desirable to enhance the contrast \nin only a specific portion of the histogram. \nFor example, suppose we have an image of the mouth of a river, and the water portions of the \nimage occupy the digital values from 40 to 76 out of the entire image histogram. If we wished \nto enhance the detail in the water, perhaps to see variations in sediment load, we could \nstretch only that small portion of the histogram represented by the water (40 to 76) to the full \ngrey level range (0 to 255). All pixels below or above these values would be assigned to 0 and \n255, respectively, and the detail in these areas would be lost. However, the detail in the water \nwould be greatly enhanced. \n  \n  \nPage 155Section 4.5 Image Enhancement\nCanada Centre for Remote Sensing\n\nSpatial filtering\n \nencompasses \nanother set of \ndigital processing \nfunctions which \nare used to \nenhance the \nappearance of an \nimage. Spatial filters are designed to highlight or suppress specific features in an image based \non their \nspatial frequency\n. Spatial frequency is related to the concept of image texture, which \nwe discussed in section 4.2. It refers to the frequency of the variations in tone that appear in \nan image. \"Rough\" textured areas of an image, where the changes in tone are abrupt over a \nsmall area, have high spatial frequencies, while \"smooth\" areas with little variation in tone \nover several pixels, have low spatial frequencies. A common \nfiltering procedure\n involves \nmoving a 'window' of a few pixels in dimension (e.g. 3x3, 5x5, etc.) over each pixel in the \nimage, applying a mathematical calculation using the pixel values under that window, and \nreplacing the central pixel with the new value. The window is moved along in both the row and \ncolumn dimensions one pixel at a time and the calculation is repeated until the entire image \nhas been filtered and a \"new\" image has been generated. By varying the calculation \nperformed and the weightings of the individual pixels in the filter window, filters can be \ndesigned to enhance or suppress different types of features. \n  \n  \nA \nlow-pass filter\n is designed to emphasize larger, homogeneous areas of similar tone and \nreduce the smaller detail in an image. Thus, low-pass filters generally serve to smooth the \nappearance of an image. Average and median filters, often used for radar imagery (and \ndescribed in Chapter 3), are examples of low-pass filters. \nHigh-pass filters\n do the opposite \nand serve to sharpen the appearance of fine detail in an image. One implementation of a \nhigh-pass filter first applies a low-pass filter to an image and then subtracts the result from the \noriginal, leaving behind only the high spatial frequency information. \nDirectional, or edge \ndetection filters\n are designed to highlight linear features, such as roads or field boundaries. \nThese filters can also be designed to enhance features which are oriented in specific \ndirections. These filters are useful in applications such as geology, for the detection of linear \ngeologic structures. \nPage 156Section 4.5 Image Enhancement\nCanada Centre for Remote Sensing\n\n  \nPage 157Section 4.5 Image Enhancement\nCanada Centre for Remote Sensing\n\n4.6 Image Transformations \nImage transformations typically involve the manipulation of multiple bands of data, whether \nfrom a single multispectral image or from two or more images of the same area acquired at \ndifferent times (i.e. multitemporal image data). Either way, image transformations generate \n\"new\" images from two or more sources which highlight particular features or properties of \ninterest, better than the original input images. \nBasic image transformations apply simple arithmetic \noperations to the image data. \nImage subtraction\n is often \nused to identify changes that have occurred between \nimages collected on different dates. Typically, two images \nwhich have been geometrically registered (see section 4.4), \nare used with the pixel (brightness) values in one image (1) \nbeing subtracted from the pixel values in the other (2). \nScaling the resultant image (3) by adding a constant (127 in \nthis case) to the output values will result in a suitable \n'difference' image. In such an image, areas where there has \nbeen little or no change (A) between the original images, will \nhave resultant brightness values around 127 (mid-grey tones), while those areas where \nsignificant change has occurred (B) will have values higher or lower than 127 - brighter or \ndarker depending on the 'direction' of change in reflectance between the two images . This \ntype of image transform can be useful for mapping changes in urban development around \ncities and for identifying areas where deforestation is occurring, as in this example. \nImage division or \nspectral ratioing\n is one of the most common transforms applied to image \ndata. Image ratioing serves to highlight subtle variations in the spectral responses of various \nsurface covers. By ratioing the data from two different spectral bands, the resultant image \nenhances variations in the slopes of the spectral reflectance curves between the two different \nspectral ranges that may otherwise be masked by the pixel brightness variations in each of \nthe bands. The following example illustrates the concept of spectral ratioing. Healthy \nvegetation reflects strongly in the near-infrared portion of the spectrum while absorbing \nstrongly in the visible red. Other surface types, such as soil and water, show near equal \nreflectances in both the near-infrared and red portions. Thus, a ratio image of Landsat MSS \nBand 7 (Near-Infrared - 0.8 to 1.1 mm) divided by Band 5 (Red - 0.6 to 0.7 mm) would result \nin ratios much greater than 1.0 for vegetation, and ratios around 1.0 for soil and water. Thus \nthe discrimination of vegetation from other surface cover types is significantly enhanced. Also, \nwe may be better able to identify areas of unhealthy or stressed vegetation, which show low \nnear-infrared reflectance, as the ratios would be lower than for healthy green vegetation. \nPage 158Section 4.6 Image Transformations\nCanada Centre for Remote Sensing\n\n \nAnother benefit of spectral ratioing is that, because we are looking at relative values (i.e. \nratios) instead of absolute brightness values, variations in scene illumination as a result of \ntopographic effects are reduced. Thus, although the absolute reflectances for forest covered \nslopes may vary depending on their orientation relative to the sun's illumination, the ratio of \ntheir reflectances between the two bands should always be very similar. More complex ratios \ninvolving the sums of and differences between spectral bands for various sensors, have been \ndeveloped for monitoring vegetation conditions. One widely used image transform is the \nNormalized Difference Vegetation Index (NDVI)\nwhich has been used to monitor vegetation \nconditions on continental and global scales using the Advanced Very High Resolution \nRadiometer (AVHRR) sensor onboard the NOAA series of satellites (see Chapter 2, section \n2.11). \nDifferent bands of multispectral data are often \nhighly correlated and thus contain similar \ninformation. For example, Landsat MSS \nBands 4 and 5 (green and red, respectively) \ntypically have similar visual appearances since \nreflectances for the same surface cover types \nare almost equal. Image transformation \ntechniques based on complex processing of \nthe statistical characteristics of multi-band \ndata sets can be used to reduce this data \nredundancy and correlation between bands. \nOne such transform is called \nprincipal components analysis\n. The objective of this \ntransformation is to reduce the dimensionality (i.e. the number of bands) in the data, and \ncompress as much of the information in the original bands into fewer bands. The \"new\" bands \nthat result from this statistical procedure are called components. This process attempts to \nmaximize (statistically) the amount of information (or variance) from the original data into the \nleast number of new components. As an example of the use of principal components analysis, \na seven band Thematic Mapper (TM) data set may be transformed such that the first three \nprincipal components contain over 90 percent of the information in the original seven bands. \nInterpretation and analysis of these three bands of data, combining them either visually or \nPage 159Section 4.6 Image Transformations\nCanada Centre for Remote Sensing\n\ndigitally, is simpler and more efficient than trying to use all of the original seven bands. \nPrincipal components analysis, and other complex transforms, can be used either as an \nenhancement technique to improve visual interpretation or to reduce the number of bands to \nbe used as input to digital classification procedures, discussed in the next section.  \nPage 160Section 4.6 Image Transformations\nCanada Centre for Remote Sensing\n\n4.7 Image Classification and Analysis \n \nA human analyst attempting to classify features in an image uses the elements of visual \ninterpretation (discussed in section 4.2) to identify homogeneous groups of pixels which \nrepresent various features or land cover classes of interest. \nDigital image classification\n \nuses the spectral information represented by the digital numbers in one or more spectral \nbands, and attempts to classify each individual pixel based on this spectral information. This \ntype of classification is termed \nspectral pattern recognition\n. In either case, the objective is \nto assign all pixels in the image to particular classes or themes (e.g. water, coniferous forest, \ndeciduous forest, corn, wheat, etc.). The resulting classified image is comprised of a mosaic \nof pixels, each of which belong to a particular theme, and is essentially a thematic \"map\" of \nthe original image. \nWhen talking about classes, we need to distinguish between \ninformation classes and \nspectral classes\n. Information classes are those categories of interest that the analyst is \nactually trying to identify in the imagery, such as different kinds of crops, different forest types \nor tree species, different geologic units or rock types, etc. Spectral classes are groups of \npixels that are uniform (or near-similar) with respect to their brightness values in the different \nspectral channels of the data. The objective is to match the spectral classes in the data to the \ninformation classes of interest. Rarely is there a simple one-to-one match between these two \ntypes of classes. Rather, unique spectral classes may appear which do not necessarily \ncorrespond to any information class of particular use or interest to the analyst. Alternatively, a \nbroad information class (e.g. forest) may contain a number of spectral \nsub-classes\n with \nunique spectral variations. Using the forest example, spectral sub-classes may be due to \nvariations in age, species, and density, or perhaps as a result of shadowing or variations in \nscene illumination. It is the analyst's job to decide on the utility of the different spectral classes \nand their correspondence to useful information classes. \n  \n  \n  \n  \nPage 161Section 4.7 Image Classification and Analysis\nCanada Centre for Remote Sensing\n\n  \nCommon classification procedures can be broken down \ninto two broad subdivisions based on the method used: \nsupervised classification and unsupervised \nclassification\n. In a \nsupervised classification\n, the analyst \nidentifies in the imagery homogeneous representative \nsamples of the different surface cover types (information \nclasses) of interest. These samples are referred to as \ntraining areas\n. The selection of appropriate training areas \nis based on the analyst's familiarity with the geographical \narea and their knowledge of the actual surface cover types \npresent in the image. Thus, the analyst is \"supervising\" the \ncategorization of a set of specific classes. The numerical information in all spectral bands for \nthe pixels comprising these areas are used to \"train\" the computer to recognize spectrally \nsimilar areas for each class. The computer uses a special program or algorithm (of which \nthere are several variations), to determine the numerical \"signatures\" for each training class. \nOnce the computer has determined the signatures for each class, each pixel in the image is \ncompared to these signatures and labeled as the class it most closely \"resembles\" digitally. \nThus, in a supervised classification we are first identifying the information classes which are \nthen used to determine the spectral classes which represent them. \n \nUnsupervised classification\n in essence reverses the supervised classification process. \nSpectral classes are grouped first, based solely on the numerical information in the data, and \nare then matched by the analyst to information classes (if possible). Programs, called \nclustering algorithms\n, are used to determine the natural (statistical) groupings or structures \nin the data. Usually, the analyst specifies how many groups or clusters are to be looked for in \nthe data. In addition to specifying the desired number of classes, the analyst may also specify \nparameters related to the separation distance among the clusters and the variation within \neach cluster. The final result of this iterative clustering process may result in some clusters \nPage 162Section 4.7 Image Classification and Analysis\nCanada Centre for Remote Sensing\n\nthat the analyst will want to subsequently combine, or clusters that should be broken down \nfurther - each of these requiring a further application of the clustering algorithm. Thus, \nunsupervised classification is not completely without human intervention. However, it does not \nstart with a pre-determined set of classes as in a supervised classification. \nPage 163Section 4.7 Image Classification and Analysis\nCanada Centre for Remote Sensing\n\n4.8 Data Integration and Analysis \n \nIn the early days of analog remote sensing when the only remote sensing data source was \naerial photography, the capability for integration of data from different sources was limited. \nToday, with most data available in digital format from a wide array of sensors, data integration \nis a common method used for interpretation and analysis. \nData integration\n fundamentally \ninvolves the combining or merging of data from multiple sources in an effort to extract better \nand/or more information. This may include data that are multitemporal, multiresolution, \nmultisensor, or multi-data type in nature. \n  \nMultitemporal data integration has already been \nalluded to in section 4.6 when we discussed image \nsubtraction. Imagery collected at different times is \nintegrated to identify areas of change. Multitemporal \nchange detection can be achieved through simple \nmethods such as these, or by other more complex \napproaches such as multiple classification \ncomparisons or classifications using integrated \nmultitemporal data sets. Multiresolution data merging \nis useful for a variety of applications. The merging of \ndata of a higher spatial resolution with data of lower \nresolution can significantly sharpen the spatial detail \nin an image and enhance the discrimination of features. \nSPOT data\n are well suited to this \napproach as the 10 metre panchromatic data can be easily merged with the 20 metre \nmultispectral data. Additionally, the multispectral data serve to retain good spectral resolution \nwhile the panchromatic data provide the improved spatial resolution.  \n  \n  \n  \nPage 164Section 4.8 Data Integration and Analysis\nCanada Centre for Remote Sensing\n\n  \nData from different sensors may also be merged, \nbringing in the concept of multisensor data fusion. An \nexcellent example of this technique is the combination \nof \nmultispectral optical data with radar imagery\n. \nThese two diverse spectral representations of the \nsurface can provide complementary information. The \noptical data provide detailed spectral information useful \nfor discriminating between surface cover types, while \nthe radar imagery highlights the structural detail in the \nimage. \nApplications of multisensor data integration \ngenerally require that the data be geometrically \nregistered, either to each other or to a common \ngeographic coordinate system or map base. This \nalso allows other \nancillary\n (supplementary) data \nsources to be integrated with the remote sensing \ndata. For example, elevation data in digital form, \ncalled \nDigital Elevation or Digital Terrain Models \n(DEMs/DTMs)\n, may be combined with remote \nsensing data for a variety of purposes. DEMs/DTMs \nmay be useful in image classification, as effects due to terrain and slope variability can be \ncorrected, potentially increasing the accuracy of the resultant classification. DEMs/DTMs are \nalso useful for generating \nthree-dimensional perspective views\n by draping remote sensing \nimagery over the elevation data, enhancing visualization of the area imaged. \n  \nCombining data of different types and from different sources, \nsuch as we have described above, is the pinnacle of data \nintegration and analysis. In a digital environment where all the \ndata sources are geometrically registered to a common \ngeographic base, the potential for information extraction is \nextremely wide. This is the concept for analysis within a digital \nGeographical Information System (GIS)\n database. Any data \nsource which can be referenced spatially can be used in this \ntype of environment. A DEM/DTM is just one example of this \nkind of data. Other examples could include digital maps of soil \ntype, land cover classes, forest species, road networks, and \nmany others, depending on the application. The results from a classification of a remote \nsensing data set in map format, could also be used in a GIS as another data source to update \nexisting map data. In essence, by analyzing diverse data sets together, it is possible to extract \nbetter and more accurate information in a synergistic manner than by using a single data \nPage 165Section 4.8 Data Integration and Analysis\nCanada Centre for Remote Sensing\nsource alone. There are a myriad of potential applications and analyses possible for many \napplications. In the next and final chapter, we will look at examples of various applications of \nremote sensing data, many involving the integration of data from different sources. \n\n4. Endnotes\n \n \n4.9 Endnotes \nYou have just completed \nChapter 4 - Image Interpretation and Analysis\n. You can continue \nto Chapter 5 - Applications or first browse the CCRS Web site for other articles related to \nImage Interpretation and Analysis. \nBy browsing the \"Images of Canada\"\n1\n, you can learn in detail about the visual elements of \ninterpretation and test yourself with a variety of remote sensing questions and answers.  \nWe have a downloadable tutorial\n2\n and exercise on the topic of digital images and digital \nanalysis techniques that makes a good start into this field. \nSee how the Intensity, Hue and Saturation (IHS) transformation, as applied to 3-D images are \nused to help visualize terrain relief\n3\n. As well, an IHS transformation can also be used to \nexploit the synergy of two different image data sets; in the case shown here, to study the \nhydrogeology\n4\n of an area. Image fusion\n5\n of data from different sensors is well demonstrated \nin an image of Canada's Capital - Ottawa. \nImage compression is important for storage and transmission of large images. One \ncompression technique developed at CCRS uses multiscale methods\n6\n to compress images \nand reduce file size. \nThere are many other image manipulation / interpretation techniques demonstrated on the \nCCRS Web site. You may also want to check our Remote Sensing Glossary for terms in the \n\"techniques\"\n7\n category.\n \n1\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/tour/tour_e.html\n \n2\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/tutorials/digitech/digitech_e.html\n \n3\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/ana/chromo/chromo_e.html\n \n4\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/jor/rjor04_e.html\n \n5\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/tour/06/06ont_e.html\n \n6\nhttp://www.ccrs.nrcan.gc.ca/ccrs/com/rsnewsltr/2302/2302ap1_e.html\n \n7\nhttp://dweb.ccrs.nrcan.gc.ca/ccrs/db/glossary/glossary_e.cfm\n \nPage 166Section 4.9 Endnotes\nCanada Centre for Remote Sensing\n\n4. Did You Know?\n \n \n4.2 Did You Know? \n \n\"...What will they think of next ?!...\"\n \nRemote sensing (image interpretation) has been used for archeological investigations. \nSometimes the 'impression' that a buried artifact, such as an ancient fort foundation, leaves \non the surface, can be detected and identified. That surface impression is typically very \nsubtle, so it helps to know the general area to be searched and the nature of the feature being \nsought. It is also useful if the surface has not been disturbed much by human activities. \nPage 167Section 4 Did you Know\nCanada Centre for Remote Sensing\n\n4.3 Did You Know? \n\"...our standard operating procedure is...\"\n \n \n... the remote sensing industry and those associated with it have attempted to standardize the \nway digital remote sensing data are formatted in order to make the exchange of data easier \nand to standardize the way data can be read into different image analysis systems. The \nCommittee on Earth Observing Satellites (CEOS) have specified this format which is widely \nused around the world for recording and exchanging data. \nPage 168Section 4 Did you Know?\nCanada Centre for Remote Sensing\n4.5 Did You Know? \nAn image 'enhancement' is basically anything that makes it easier or better to visually \ninterpret an image. In some cases, like 'low-pass filtering', the enhanced image can actually \nlook worse than the original, but such an enhancement was likely performed to help the \ninterpreter see low spatial frequency features among the usual high frequency clutter found in \nan image. Also, an enhancement is performed for a specific application. This enhancement \nmay be inappropriate for another purpose, which would demand a different type of \nenhancement.  \n\n4.7 Did You Know? \n\"...this image has such lovely texture, don't you think?...\"\n \n \n...texture was identified as one of the key elements of visual interpretation (section 4.2), \nparticularly for radar image interpretation. Digital texture classifiers are also available and can \nbe an alternative (or assistance) to spectral classifiers. They typically perform a \"moving \nwindow\" type of calculation, similar to those for spatial filtering, to estimate the \"texture\" based \non the variability of the pixel values under the window. Various textural measures can be \ncalculated to attempt to discriminate between and characterize the textural properties of \ndifferent features. \nPage 169Section 4 Did you Know?\nCanada Centre for Remote Sensing\n\n4. Whiz Quiz and Answers\n \n \n4.2 Whiz Quiz \n \nTake a look at the aerial photograph above. Identify the following features in the image and \nexplain how you were able to do so based on the elements of visual interpretation described \nin this section. \n\nrace track  \n\nriver  \n\nroads  \n\nbridges  \n\nresidential area  \n\ndam  \n \nPage 170Section 4.Whiz Quiz and Answers\n4.2 Answers \n\nThe race track in the lower left of the image is quite easy to identify because of its \ncharacteristic shape.  \n\nThe river is also easy to identify due to its contrasting tone with the surrounding land \nand also due to its shape.  \n\nThe roads in the image are visible due to their shape (straight in many cases) and their \ngenerally bright tone contrasting against the other darker features.  \n\nBridges are identifiable based on their shape, tone, and association with the river - they \ncross it!  \n\nResidential areas on the left hand side of the image and the upper right can be \nidentified by the pattern that they make in conjunction with the roads. Individual houses \nand other buildings can also be identified as dark and light tones.  \n\nThe dam in the river at the top center of the image can be identified based on its \ncontrasting tone with the dark river, its shape, and its association with the river - where \nelse would a dam be!  \nCanada Centre for Remote Sensing\n\n4.3 Whiz Quiz \nOne 8-bit pixel takes up one single byte of computer disk space. One \nkilobyte (Kb) is 1024 bytes. One megabyte (Mb) is 1024 kilobytes. How \nmany megabytes of computer disk space would be required to store an 8-bit \nLandsat Thematic Mapper (TM) image (7 bands), which is 6000 pixels by \n6000 lines in dimension?  \nThe answer is ...  \n  \n  \nPage 171Section 4 Whiz Quiz\nCanada Centre for Remote Sensing\n4.3 Answers \n \nIf we have seven bands of TM data, each 6000 pixels by 6000 lines, and each pixel takes up \none byte of disk space, we have: \n7 x 6000 x 6000 = 252,000,000 bytes of data  \nTo convert this to kilobytes we need to divide by 1024, and to convert that answer to \nmegabytes we need to divide by 1024 again! \n252,000,000 (1024 x 1024) = 240.33 megabytes  \nSo, we would need over 240 megabytes of disk space just to hold one full TM image, let alone \nanalyze the imagery and create any new image variations! Needless to say, it takes a lot of \nstorage space and powerful computers to analyze the data from today's remote sensing \nsystems.  \n \n\n4.4 Whiz Quiz \n \nWhat would be the advantage of geometrically correcting an image to geographic coordinates \nprior to further analysis and interpretation? \nPage 172Section 4 Whiz Quiz\nCanada Centre for Remote Sensing\n4.4 Answers \n \nThe advantage of geometrically correcting an image prior to further analysis and interpretation \nis that it would then allow proper measurements of distances and areas to be made from \nfeatures in the image. This may be particularly useful in different applications where true \nmeasurements are necessary, such as in urban mapping applications. Also, the geographic \nlocations of features could be determined. Once an image is geometrically registered to a \nknown geographic base, it can be combined with other mapped data in a digital environment \nfor further analysis. This is the concept of data integration which is discussed in section 4.8. \n\n4.7 Whiz Quiz \n \nYou want to perform a classification on a satellite image, but when examining its histogram, \nyou notice that the range of useful data is very narrow. Prior to attempting classification, would \nyou enhance the image with a linear contrast stretch? \n \nPage 173Section 4 Whiz Quiz\nCanada Centre for Remote Sensing\n4.7 Answer\nAn 'enhancement' of an image is done exclusively for visually appreciating and analyzing its \ncontents. An enhancement would not add anything useful, as far as the classification \nalgorithm is concerned. Another way of looking at this is: if two pixels have brightness values \nust one digital unit different, then it would be very difficult to notice this subtle difference by \neye. But for the computer, the difference is just as 'obvious' as if it was 100 times greater. \n \nAn enhanced version of the image may help in selecting 'training' sites (by eye), but you \nwould still perform the classification on the unenhanced version. \n\n5. Applications\n \n \n5.1 Introduction \nAs we learned in the section on sensors, each one was designed with a specific purpose. \nWith optical sensors, the design focuses on the spectral bands to be collected. With radar \nimaging, the incidence angle and microwave band used plays an important role in defining \nwhich applications the sensor is best suited for. \nEach application itself has specific demands, for spectral resolution, spatial resolution, and \ntemporal resolution. \n \nTo review, spectral resolution refers to the width or range of each spectral band being \nrecorded. As an example, panchromatic imagery (sensing a broad range of all visible \nwavelengths) will not be as sensitive to vegetation stress as a narrow band in the red \nwavelengths, where chlorophyll strongly absorbs electromagnetic energy. \nSpatial resolution refers to the discernible detail in the image. Detailed mapping of wetlands \nrequires far finer spatial resolution than does the regional mapping of physiographic areas. \nTemporal resolution refers to the time interval between images. There are applications \nrequiring data repeatedly and often, such as oil spill, forest fire, and sea ice motion \nmonitoring. Some applications only require seasonal imaging (crop identification, forest insect \ninfestation, and wetland monitoring), and some need imaging only once (geology structural \nmapping). Obviously, the most time-critical applications also demand fast turnaround for \nimage processing and delivery - getting useful imagery quickly into the user's hands. \nPage 174Section 5.1 Introduction\nCanada Centre for Remote Sensing\n\nIn a case where repeated imaging is required, the revisit frequency of a sensor is important \n(how long before it can image the same spot on the Earth again) and the reliability of \nsuccessful data acquisition. Optical sensors have limitations in cloudy environments, where \nthe targets may be obscured from view. In some areas of the world, particularly the tropics, \nthis is virtually a permanent condition. Polar areas also suffer from inadequate solar \nillumination, for months at a time. Radar provides reliable data, because the sensor provides \nits own illumination, and has long wavelengths to penetrate cloud, smoke, and fog, ensuring \nthat the target won't be obscured by weather conditions, or poorly illuminated. \nOften it takes more than a single sensor to adequately address all of the requirements for a \ngiven application. The combined use of multiple sources of information is called integration. \nAdditional data that can aid in the analysis or interpretation of the data is termed \"ancillary\" \ndata. \nThe applications of remote sensing described in this chapter are representative, but not \nexhaustive. We do not touch, for instance, on the wide area of research and practical \napplication in weather and climate analysis, but focus on applications tied to the surface of the \nEarth. The reader should also note that there are a number of other applications that are \npracticed but are very specialized in nature, and not covered here (e.g. terrain trafficability \nanalysis, archeological investigations, route and utility corridor planning, etc.). \nMultiple sources of information\n \nEach band of information collected from a sensor contains important and unique data. We \nknow that different wavelengths of incident energy are affected differently by each target - \nthey are absorbed, reflected or transmitted in different proportions. The appearance of targets \ncan easily change over time, sometimes within seconds. In many applications, using \ninformation from several different sources ensures that target identification or information \nextraction is as accurate as possible. The following describe ways of obtaining far more \ninformation about a target or area, than with one band from a sensor. \nMultispectral\n \nThe use of multiple bands of spectral information attempts to exploit different and independent \n\"views\" of the targets so as to make their identification as confident as possible. Studies have \nbeen conducted to determine the optimum spectral bands for analyzing specific targets, such \nas insect damaged trees. \nMultisensor\n \nDifferent sensors often provide complementary information, and when integrated together, \ncan facilitate interpretation and classification of imagery. Examples include combining high \nresolution panchromatic imagery with coarse resolution multispectral imagery, or merging \nactively and passively sensed data. A specific example is the integration of SAR imagery with \nmultispectral imagery. SAR data adds the expression of surficial topography and relief to an \notherwise flat image. The multispectral image contributes meaningful colour information about \nthe composition or cover of the land surface. This type of image is often used in geology, \nPage 175Section 5.1 Introduction\nCanada Centre for Remote Sensing\n\nwhere lithology or mineral composition is represented by the spectral component, and the \nstructure is represented by the radar component. \nMultitemporal\n \nInformation from multiple images taken over a period of time is referred to as multitemporal \ninformation. Multitemporal may refer to images taken days, weeks, or even years apart. \nMonitoring land cover change or growth in urban areas requires images from different time \nperiods. Calibrated data, with careful controls on the quantitative aspect of the spectral or \nbackscatter response, is required for proper monitoring activities. With uncalibrated data, a \nclassification of the older image is compared to a classification from the recent image, and \nchanges in the class boundaries are delineated. Another valuable multitemporal tool is the \nobservation of vegetation phenology (how the vegetation changes throughout the growing \nseason), which requires data at frequent intervals throughout the growing season. \n\"Multitemporal information\" is acquired from the interpretation of images taken over the same \narea, but at different times. The time difference between the images is chosen so as to be \nable to monitor some dynamic event. Some catastrophic events (landslides, floods, fires, etc.) \nwould need a time difference counted in days, while much slower-paced events (glacier melt, \nforest regrowth, etc.) would require years. This type of application also requires consistency in \nillumination conditions (solar angle or radar imaging geometry) to provide consistent and \ncomparable classification results. \nThe ultimate in critical (and quantitative) multitemporal analysis depends on calibrated data. \nOnly by relating the brightnesses seen in the image to physical units, can the images be \nprecisely compared, and thus the nature and magnitude of the observed changes be \ndetermined. \nPage 176Section 5.1 Introduction\nCanada Centre for Remote Sensing\n\n5.2 Agriculture \n \nAgriculture plays a dominant role in economies of both developed and undeveloped countries. \nWhether agriculture represents a substantial trading industry for an economically strong \ncountry or simply sustenance for a hungry, overpopulated one, it plays a significant role in \nalmost every nation. The production of food is important to everyone and producing food in a \ncost-effective manner is the goal of every farmer, large-scale farm manager and regional \nagricultural agency. A farmer needs to be informed to be efficient, and that includes having \nthe knowledge and information products to forge a viable strategy for farming operations. \nThese tools will help him understand the health of his crop, extent of infestation or stress \ndamage, or potential yield and soil conditions. Commodity brokers are also very interested in \nhow well farms are producing, as yield (both quantity and quality) estimates for all products \ncontrol price and worldwide trading. \nSatellite and airborne images\n are used as mapping tools to \nclassify crops, examine their health and viability, and monitor \nfarming practices. Agricultural applications of remote sensing \ninclude the following: \n  \n  \n  \n  \n\ncrop type classification  \n\ncrop condition assessment  \n\ncrop yield estimation  \nmapping of soil characteristics  \n\nmapping of soil management practices  \ncompliance monitoring (farming practices)  \nPage 177Section 5.2 Agriculture\nCanada Centre for Remote Sensing\n\n5.2.1 Crop Type Mapping \n \nBackground\n \nIdentifying and mapping crops is important for a number of reasons. Maps of crop type are \ncreated by national and multinational agricultural agencies, insurance agencies, and regional \nagricultural boards to prepare an inventory of what was grown in certain areas and when. This \nserves the purpose of forecasting grain supplies (yield prediction), collecting crop production \nstatistics, facilitating crop rotation records, mapping soil productivity, identification of factors \ninfluencing crop stress, assessment of crop damage due to storms and drought, and \nmonitoring farming activity. \nKey activities include identifying the crop types and delineating their extent (often measured in \nacres). Traditional methods of obtaining this information are census and ground surveying. In \norder to standardize measurements however, particularly for multinational agencies and \nconsortiums, remote sensing can provide common data collection and information extraction \nstrategies.  \nWhy remote sensing?\n \nRemote sensing offers an efficient and reliable means of collecting the information required, in \norder to map crop type and acreage. Besides providing a synoptic view, remote sensing can \nprovide structure information about the health of the vegetation. The spectral reflection of a \nfield will vary with respect to changes in the phenology (growth), stage type, and crop health, \nand thus can be measured and monitored by multispectral sensors. Radar is sensitive to the \nstructure, alignment, and moisture content of the crop, and thus can provide complementary \ninformation to the optical data. Combining the information from these two types of sensors \nincreases the information available for distinguishing each target class and its respective \nsignature, and thus there is a better chance of performing a more accurate classification.  \nInterpretations from remotely sensed data can be input to a geographic information system \n(GIS) and crop rotation systems, and combined with ancillary data, to provide information of \nownership, management practices etc. \nData requirements\n \nCrop identification and mapping benefit from the use of multitemporal imagery to facilitate \nclassification by taking into account changes in reflectance as a function of plant phenology \n(stage of growth). This in turn requires calibrated sensors, and frequent repeat imaging \nthroughout the growing season. For example, crops like canola may be easier to identify when \nthey are flowering, because of both the spectral reflectance change, and the timing of the \nPage 178Section 5.2.1 Crop Type Mapping\nCanada Centre for Remote Sensing\n\nflowering. \nMultisensor data are also valuable for increasing classification accuracies by contributing \nmore information than a sole sensor could provide. VIR sensing contributes information \nrelating to the chlorophyll content of the plants and the canopy structure, while radar provides \ninformation relating to plant structure and moisture. In areas of persistent cloud cover or haze, \nradar is an excellent tool for observing and distinguishing crop type due to its active sensing \ncapabilities and long wavelengths, capable of penetrating through atmospheric water vapour. \nCanada vs. International\n \nAlthough the principles of identifying crop type are the same, the scale of observation in \nEurope and Southeast Asia is considerably smaller than in North America, primarily due to \nsmaller field parcel sizes. Cloud cover in Europe and tropical countries also usually limits the \nfeasibility of using high-resolution optical sensors. In these cases high-resolution radar would \nhave a strong contribution. \n \nThe sizable leaves of tropical agricultural crops (cocoa, banana, and oil palm) have distinct \nradar signatures. Banana leaves in particular are characterized by bright backscatter \n(represented by \"B\" in image). Monitoring stages of rice growth is a key application in tropical \nareas, particularly Asian countries. Radar is very sensitive to surface roughness, and the \ndevelopment of rice paddies provides a dramatic change in brightness from the low returns \nfrom smooth water surfaces in flooded paddies , to the high return of the emergent rice crop. \n \nCase study (example)\n \nThe countries involved in the European Communities (EC) are using remote sensing to help \nfulfil the requirements and mandate of the EC Agricultural Policy, which is common to all \nPage 179Section 5.2.1 Crop Type Mapping\nCanada Centre for Remote Sensing\n\nmembers. The requirements are to delineate, identify, and measure the extent of important \ncrops throughout Europe, and to provide an early forecast of production early in the season. \nStandardized procedures for collecting this data are based on remote sensing technology, \ndeveloped and defined through the MARS project (Monitoring Agriculture by Remote \nSensing). \nThe project uses many types of remotely sensed data, from low resolution NOAA-AVHRR, to \nhigh-resolution radar, and numerous sources of ancillary data. These data are used to classify \ncrop type over a regional scale to conduct regional inventories, assess vegetation condition, \nestimate potential yield, and finally to predict similar statistics for other areas and compare \nresults. Multisource data such as VIR and radar were introduced into the project for increasing \nclassification accuracies. Radar provides very different information than the VIR sensors, \nparticularly vegetation structure, which proves valuable when attempting to differentiate \nbetween crop type. \nOne the key applications within this project is the operational use of high resolution optical \nand radar data to confirm conditions claimed by a farmer when he requests aid or \ncompensation. The use of remote sensing identifies potential areas of non-compliance or \nsuspicious circumstances, which can then be investigated by other, more direct methods. \nAs part of the Integrated Administration and Control System (IACS), remote sensing data \nsupports the development and management of databases, which include cadastral \ninformation, declared land use, and parcel measurement. This information is considered when \napplications are received for area subsidies. \nThis is an example of a truly successfully operational crop identification and monitoring \napplication of remote sensing. \nPage 180Section 5.2.1 Crop Type Mapping\nCanada Centre for Remote Sensing\n\n5.2.2 Crop Monitoring & Damage Assessment \nBackground\n \nAssessment of the health of a crop, as well as early detection of crop infestations, is critical in \nensuring good agricultural productivity. Stress associated with, for example, moisture \ndeficiencies, insects, fungal and weed infestations, must be detected early enough to provide \nan opportunity for the farmer to mitigate. This process requires that remote sensing imagery \nbe provided on a frequent basis (at a minimum, weekly) and be delivered to the farmer \nquickly, usually within 2 days. \nAlso, crops do not generally grow evenly across the field and consequently crop yield can \nvary greatly from one spot in the field to another. These growth differences may be a result of \nsoil nutrient deficiencies or other forms of stress. Remote sensing allows the farmer to identify \nareas within a field which are experiencing difficulties, so that he can apply, for instance, the \ncorrect type and amount of fertilizer, pesticide or herbicide. Using this approach, the farmer \nnot only improves the productivity from his land, but also reduces his farm input costs and \nminimizes environmental impacts. \nThere are many people involved in the trading, pricing, and selling of crops that never actually \nset foot in a field. They need information regarding crop health worldwide to set prices and to \nnegotiate trade agreements. Many of these people rely on products such as a crop \nassessment index to compare growth rates and productivity between years and to see how \nwell each country's agricultural industry is producing. This type of information can also help \ntarget locations of future problems, for instance the famine in Ethiopia in the late 1980's, \ncaused by a significant drought which destroyed many crops. Identifying such areas facilitates \nin planning and directing humanitarian aid and relief efforts. \n  \nWhy remote sensing?\n \nRemote sensing has a number of attributes that lend \nthemselves to monitoring the health of crops. One \nadvantage of optical (VIR) sensing is that it can see \nbeyond the visible wavelengths into the infrared, where \nwavelengths are highly sensitive to crop vigour as well \nas crop stress and crop damage. Remote sensing \nimagery also gives the required spatial overview of the \nland. Recent advances in communication and \ntechnology allow a farmer to observe images of his \nfields and make timely decisions about managing the \ncrops. Remote sensing can aid in identifying crops \naffected by conditions that are too dry or wet, affected \nby insect, weed or fungal infestations or \nweather \nrelated damage\n. Images can be obtained throughout \nthe growing season to not only detect problems, but also to monitor the success of the \ntreatment. In the example image given here, a tornado has destroyed/damaged crops \nsouthwest of Winnipeg, Manitoba. \n  \n  \n  \nPage 181Section 5.2.2 Crop Monitoring & Damage Assessment\nCanada Centre for Remote Sensing\n\nHealthy vegetation contains large quantities of \nchlorophyll, the substance that gives most \nvegetation its distinctive green colour. In referring to \nhealthy crops, reflectance in the blue and red parts \nof the spectrum is low since chlorophyll absorbs this \nenergy. In contrast, reflectance in the green and \nnear-infrared spectral regions is high. Stressed or \ndamaged crops experience a decrease in \nchlorophyll content and changes to the internal leaf \nstructure. The reduction in chlorophyll content \nresults in a decrease in reflectance in the green \nregion and internal leaf damage results in a \ndecrease in near-infrared reflectance. These \nreductions in green and infrared reflectance provide \nearly detection of crop stress. Examining the ratio of reflected infrared to red wavelengths is \nan excellent measure of vegetation health. This is the premise behind some vegetation \nindices, such as the normalized differential vegetation \nindex (NDVI) (Chapter 4). Healthy plants have a high NDVI \nvalue because of their high reflectance of infrared light, and \nrelatively low reflectance of red light. Phenology and vigour \nare the main factors in affecting NDVI. An excellent \nexample is the difference between irrigated crops and non-\nirrigated land. The irrigated crops appear bright green in a \nreal-colour simulated image\n. The darker areas are dry \nrangeland with minimal vegetation. In a CIR (\ncolour \ninfrared simulated\n) image, where infrared reflectance is \ndisplayed in red, the healthy vegetation appears bright red, \nwhile the rangeland remains quite low in reflectance. \nExamining variations in crop growth within one field is possible. Areas of consistently healthy \nand vigorous crop would appear uniformly bright. Stressed vegetation would appear dark \namongst the brighter, healthier crop areas. If the data is georeferenced, and if the farmer has \na GPS (global position satellite) unit, he can find the exact area of the problem very quickly, \nby matching the coordinates of his location to that on the image. \n  \nData requirements\n \nDetecting damage and monitoring crop health requires high-resolution imagery and \nmultispectral imaging capabilities. One of the most critical factors in making imagery useful to \nfarmers is a quick turnaround time from data acquisition to distribution of crop information. \nReceiving an image that reflects crop conditions of two weeks earlier does not help real time \nmanagement nor damage mitigation. Images are also required at specific times during the \ngrowing season, and on a frequent basis. \nRemote sensing doesn't replace the field work performed by farmers to monitor their fields, \nbut it does direct them to the areas in need of immediate attention. \nCanada vs. International\n \nEfficient agricultural practices are a global concern, and other countries share many of the \nsame requirements as Canada in terms of monitoring crop health by means of remote \nsensing. In many cases however, the scale of interest is smaller - smaller fields in Europe and \nAsia dictate higher resolution systems and smaller areal coverage. Canada, the USA, and \nPage 182Section 5.2.2 Crop Monitoring & Damage Assessment\nCanada Centre for Remote Sensing\n\nRussia, amongst others, have more expansive areas devoted to agriculture, and have \ndeveloped, or are in the process of developing crop information systems (see below). In this \nsituation, regional coverage and lower resolution data (say: 1km) can be used. The lower \nresolution facilitates computer efficiency by minimizing storage space, processing efforts and \nmemory requirements. \nAs an example of an international crop monitoring application, date palms are the prospective \nsubject of an investigation to determine if remote sensing methods can detect damage from \nthe red palm weevil in the Middle East. In the Arabian Peninsula, dates are extremely popular \nand date crops are one of the region's most important agricultural products. Infestation by the \nweevil could quickly devastate the palm crops and swallow a commodity worth hundreds of \nmillions of dollars. Remote sensing techniques will be used to examine the health of the date \ncrops through spectral analysis of the vegetation. Infested areas appear yellow to the naked \neye, and will show a smaller near infrared reflectance and a higher red reflectance on the \nremotely sensed image data than the healthy crop areas. Authorities are hoping to identify \nareas of infestation and provide measures to eradicate the weevil and save the remaining \nhealthy crops. \nCase study (example)\n \nCanadian Crop Information System: A composite crop index map is created each week, \nderived from composited NOAA-\nAVHRR data. Based on the NDVI, the index shows the health \nof crops in the prairie regions of Manitoba through to Alberta. These indices are produced \nweekly, and can be compared with indices of past years to compare crop growth and health. \n \nIn 1988, severe drought conditions were prevalent across the prairies. Using NDVI values \nfrom NOAA AVHRR data, a \ndrought area analysis\n determined the status of drought effects \non crops across the affected area. Red and yellow areas indicate those crops in a weakened \nand stressed state, while green indicates healthy crop conditions. Note that most of the \nhealthy crops are those in the cooler locations, such as in the northern Alberta (Peace River) \nand the higher elevations (western Alberta). Non-cropland areas (dry rangeland and forested \nland) are indicated in black, within the analysis region. \nPage 183Section 5.2.2 Crop Monitoring & Damage Assessment\nCanada Centre for Remote Sensing\n\n5.3 Forestry \nForests are a valuable resource providing food, shelter, \nwildlife habitat, fuel, and daily supplies such as medicinal \ningredients and paper. Forests play an important role in \nbalancing the Earth's CO\n2\n supply and exchange, acting as a \nkey link between the atmosphere, geosphere, and \nhydrosphere. Tropical rainforests, in particular, house an \nimmense \ndiversity of species\n, more capable of adapting to, \nand therefore surviving, changing environmental conditions \nthan monoculture forests. This diversity also provides habitat \nfor numerous animal species and is an important source of \nmedicinal ingredients. The main issues concerning forest management are depletion due to \nnatural causes (fires and infestations) or human activity (clear-cutting, burning, land \nconversion), and monitoring of health and growth for effective commercial exploitation and \nconservation.  \nHumans generally consider the products of \nforests useful, rather than the forests \nthemselves, and so extracting \nwood\n is a wide-\nspread and historical practice, virtually global in \nscale. Depletion of forest resources has long \nterm effects on climate, soil conservation, \nbiodiversity, and hydrological regimes, and thus \nis a vital concern of environmental monitoring \nactivities. Commercial forestry is an important \nindustry throughout the world. Forests are \ncropped and re-harvested, and the new areas \ncontinually sought for providing a new source of \nlumber. With increasing pressure to conserve \nnative and virgin forest areas, and unsustainable forestry practices limiting the remaining \nareas of potential cutting, the companies involved in extracting wood supplies need to be \nmore efficient, economical, and aware of sustainable forestry practices. Ensuring that there is \na healthy regeneration of trees where forests are extracted will ensure a future for the \ncommercial forestry firms, as well as adequate wood supplies to meet the demands of a \ngrowing population. \nNon-commercial sources of forest depletion \ninclude removal for agriculture (pasture and \ncrops), urban development, droughts, desert \nencroachment, loss of ground water, insect \ndamage, fire and other natural phenomena \n(disease, typhoons). In some areas of the world, \nparticularly in the tropics, (rain) forests, are \ncovering what might be considered the most \nvaluable commodity - viable agricultural land. \nForests are burned or \nclear-cut\n to facilitate \naccess to, and use of, the land. This practice \noften occurs when the perceived need for long \nterm sustainability is overwhelmed by short-term \nsustenance goals. Not only are the depletion of species-rich forests a problem, affecting the \nlocal and regional hydrological regime, the smoke caused by the burning trees pollutes the \nPage 184Section 5.3 Forestry\nCanada Centre for Remote Sensing\n\natmosphere, adding more CO\n2\n, and furthering the greenhouse effect.  \nOf course, monitoring the health of forests is crucial for sustainability and conservation issues. \nDepletion of key species such as mangrove in environmentally sensitive coastline areas, \nremoval of key support or shade trees from a potential crop tree, or disappearance of a large \nbiota acting as a CO\n2\n reservoir all affect humans and society in a negative way, and more \neffort is being made to monitor and enforce regulations and plans to protect these areas. \nInternational and domestic forestry applications where remote sensing can be utilized include \nsustainable development, biodiversity, land title and tenure (cadastre), monitoring \ndeforestation, reforestation monitoring and managing, commercial logging operations, \nshoreline and watershed protection, biophysical monitoring (wildlife habitat assessment), and \nother environmental concerns. \nGeneral forest cover information is valuable to developing countries with limited previous \nknowledge of their forestry resources. General cover type mapping, shoreline and watershed \nmapping and monitoring for protection, monitoring of cutting practices and regeneration, and \nforest fire/burn mapping are global needs which are currently being addressed by Canadian \nand foreign agencies and companies employing remote sensing technology as part of their \ninformation solutions in foreign markets. \nForestry applications of remote sensing include the following: \n1) reconnaissance mapping:\n  \nObjectives to be met by national forest/environment agencies include forest \ncover updating, depletion monitoring, and measuring biophysical properties of \nforest stands. \nz\nforest cover type discrimination  \nz\nagroforestry mapping  \n2) Commercial forestry:\n  \nOf importance to commercial forestry companies and to resource management \nagencies are inventory and mapping applications: collecting harvest \ninformation, updating of inventory information for timber supply, broad forest \ntype, vegetation density, and biomass measurements. \nzclear cut mapping / regeneration assessment  \nz\nburn delineation  \nz\ninfrastructure mapping / operations support  \nz\nforest inventory  \nz\nbiomass estimation  \nz\nspecies inventory  \n3) Environmental monitoring\n  \nConservation authorities are concerned with monitoring the quantity, health, \nand diversity of the Earth's forests. \nz\ndeforestation (rainforest, mangrove colonies)  \nz\nspecies inventory  \nz\nwatershed protection (riparian strips)  \nz\ncoastal protection (mangrove forests)  \nPage 185Section 5.3 Forestry\nCanada Centre for Remote Sensing\n\nz\nforest health and vigour  \nCanadian requirements for forestry application information differ considerably from \ninternational needs, due in part to contrasts in tree size, species diversity (monoculture vs. \nspecies rich forest), and agroforestry practices. The level of accuracy and resolution of data \nrequired to address respective forestry issues differs accordingly. Canadian agencies have \nextensive a priori knowledge of their forestry resources and present inventory and mapping \nneeds are often capably addressed by available data sources. \nFor Canadian applications requirements, high accuracy (for accurate information content), \nmultispectral information, fine resolution, and data continuity are the most important. There \nare requirements for large volumes of data, and reliable observations for seasonal coverage. \nThere is a need to balance spatial resolution with the required accuracy and costs of the data. \nResolution capabilities of 10 m to 30 m are deemed adequate for forest cover mapping, \nidentifying and monitoring clearcuts, burn and fire mapping, collecting forest harvest \ninformation, and identifying general forest damage. Spatial coverage of 100 - 10000 km2 is \nappropriate for district to provincial scale forest cover and clear cut mapping, whereas 1-100 \nkm2 coverage is the most appropriate for site specific vegetation density and volume studies. \nTropical forest managers will be most concerned with having a reliable data source, capable \nof imaging during critical time periods, and therefore unhindered by atmospheric conditions. \nPage 186Section 5.3 Forestry\nCanada Centre for Remote Sensing\n\n5.3.1 Clear Cut Mapping & Deforestation \n  \nBackground\n \nDeforestation is a global problem, with many implications. In industrialized Europe, pollution \n(acid rain, soot and chemicals from factory smoke plumes) has damaged a large percentage \nof forested land. In the former Czechoslovakia, one half of the forests are destroyed or \ndamaged from pollutants. Similar effects are felt in Germany, Poland, and even the \nScandinavian countries. In tropical countries, valuable rainforest is being destroyed in an \neffort to clear potentially valuable agricultural and pasture land. This has resulted in huge \nlosses of tropical rainforest throughout Latin America (Central America, southern Mexico, \nHaiti), South America (Brazil), Africa and Asia. In both Haiti and Madagascar in particular, the \nresults have been devastating. The loss of forests increases soil erosion, river siltation, and \ndeposition, affecting navigation, fisheries, wildlife habitat, and drinking water supplies, as well \nas farming productivity and self-sufficiency. \nSensitive estuarine environments are protected by mangrove forest, which is cut or lost to \nurban growth, aquaculture, or damaged by pollutants or siltation. Monitoring the health of this \nforest is a step towards protecting the coastlines from erosion and degradation, and nearby \ninland areas from flooding. \nThe loss of forests also affects the genetic diversity of species on Earth, which controls our \nintrinsic ability to adapt to changing conditions and environment. Rainforests account for \napproximately one half of the plant and animal species on Earth, and destroying large \nsections will only serve to reduce the gene and species pool. \nThe rate and extent of deforestation, as well as monitoring regeneration, are the key \nparameters measured by remote sensing methods. \nWhy remote sensing?\n \nRemote sensing brings together a multitude of tools to better analyze the scope and scale of \nthe deforestation problem. Multitemporal data provides for change detection analyses. Images \nof earlier years are compared to recent scenes, to tangibly measure the differences in the \nsizes and extents of the clearcuts or loss of forest. Data from a variety of sources are used to \nprovide complementary information. Radar, merged with optical data, can be used to \nefficiently monitor the status of existing clearcuts or emergence of new ones, and even assess \nregeneration condition. In countries where cutting is controlled and regulated, remote sensing \nserves as a monitoring tool to ensure companies are following cut guidelines and \nspecifications. \nPage 187Section 5.3.1 Clear Cut Mapping & Deforestation\nCanada Centre for Remote Sensing\n\nHigh resolution data provide a detailed view of forest depletion, while radar can provide a view \nthat may otherwise be obscured by clouds. All remote sensing devices, however, provide a \nview of often remote and inaccessible areas, where illegal cutting or damage could continue \nunnoticed for long periods of time if aerial surveillance wasn't possible. \nData requirements\n \nGlobal monitoring initiatives, such as rain forest depletion studies, depend on large area \ncoverage and data continuity, so it is important to use a sensor that will have successive \ngenerations launched and operational. Clear cut mapping and monitoring also require regional \nscale images and moderate or high resolution data depending on whether cuts are to be \nsimply detected or delineated. As for many multi-temporal applications, a higher resolution \nimage can be used to define the baseline, and coarser resolution images can be used to \nmonitor changes to that baseline. \nCanada vs. International\n \nOptical sensors are still preferred for clear cut mapping and monitoring in Canada because \nforest vegetation, cuts, and regenerating vegetation have distinguishable spectral signatures, \nand optical sensors can collect sufficient cloud-free data. \n \n \n \nComparison of photo (bottom)andSAR image (top) \nof forest cuts along road. \nRadar is more useful for applications in the humid tropics because its all weather imaging \ncapability is valuable for monitoring all types of depletion, including clear cuts, in areas prone \nto cloudy conditions. Cuts can be defined on \nradar images\n because clear cuts produce less \nbackscatter than the forest canopy, and forest edges are enhanced by shadow and bright \nbackscatter. However, regenerating cuts are typically difficult to detect, as advanced \nregeneration and mature forest canopy are not separable. Mangrove forests generally occur \nin tropical coastal areas, which are prone to cloudy conditions, therefore a reliable monitoring \ntool is required to successively measure the rate of forest depletion. Radar has been proven \nto differentiate mangrove from other land covers, and some bands have long wavelengths \ncapable of penetrating cloud and rain. The only limitation is in differentiating different \nmangrove species. \n  \nPage 188Section 5.3.1 Clear Cut Mapping & Deforestation\nCanada Centre for Remote Sensing\n\n  \nCase study (example)\n \n \nIn Alberta, much of the province's forestland has been sold \nto offshore investors who are interested in selling pulp and \npaper products. Around the area of Whitecourt, clear cutting \nof conifer forest has been occurring for decades. In recent \nyears however, the increasing demand for wood products \nhas accelerated the cutting of the forests, resulting in a \ndissected and checkered landscape. Besides cutting for \nwood supply, forest depletion is also occurring due to cuts \nfor seismic lines for oil and gas exploration and extraction. \nBoth \noptical\n and \nradar\n sensors have been used to monitor \nthe clear cuts and regeneration. \n  \n   \n \nOptical and Radar scenes of forest clear cutting. \nPage 189Section 5.3.1 Clear Cut Mapping & Deforestation\nCanada Centre for Remote Sensing\n\n5.3.2 Species Identification & Typing \nBackground\n \nForest cover typing and species identification are critical to both forest conservation managers and \nforestry companies interested in their supply inventory. Forest cover typing can consist of \nreconnaissance mapping over a large area, while species inventories are highly detailed measurements \nof stand contents and characteristics (tree type, height, density). \nWhy remote sensing?\n \nRemote sensing provides a means of quickly identifying and delineating various forest types, a task that \nwould be difficult and time consuming using traditional ground surveys. Data is available at various \nscales and resolutions to satisfy local or regional demands Large scale species identification can be \nperformed with multispectral, hyperspectral, or airphoto data, while small scale cover type delineation \ncan be performed by radar or multispectral data interpretation. Both imagery and the extracted \ninformation can be incorporated into a GIS to further analyze or present with ancillary data, such as \nslopes, ownership boundaries, or roads. \nHyperspectral imagery can provide a very high spatial resolution while capturing extremely fine \nradiometric resolution data. This type of detailed spectral information can be used to generate signatures \nof vegetation species and certain stresses (e.g. infestations) on trees. Hyperspectral data offers a unique \nview of the forest cover, available only through remote sensing technology. \nData requirements\n \nRequirements depend on the scale of study to be conducted. For regional reconnaissance mapping, \nmoderate area coverage, with a sensor sensitive to differences in forest cover (canopy texture, leaf \ndensity, spectral reflection) is needed. Multitemporal datasets also contribute phenology information that \nmay aid in interpretation by incorporating the seasonal changes of different species. \nFor detailed species identification associated with forest stand analysis, very high resolution, \nmultispectral data is required. Being able to view the images in stereo helps in the delineation and \nassessment of density, tree height, and species. In general, monitoring biophysical properties of forests \nrequires multispectral information and finely calibrated data.  \nCanada vs. International\n \nCurrent sources of data used operationally for forest cover typing and species identification applications \nwithin Canada are aerial photography, orthophotography, Landsat TM, and SPOT data. Landsat data are \nthe most appropriate for executing reconnaissance level forest surveys, while aerial photography and \ndigital orthophoto are the preferred data source for extracting stand and local inventory information. \nAirphotos are the most appropriate operational data source for stand level measurements including \nspecies typing. SAR sensors such as RADARSAT are useful where persistent cloud cover limits the \nusefulness of optical sensors. \nPage 190Section 5.3.2 Species Identification & Typing\nCanada Centre for Remote Sensing\n\nIn humid tropical areas, forest resource assessments and measurements are difficult to obtain because \nof cloudy conditions hindering conventional remote sensing efforts, and difficult terrain impeding ground \nsurveys. In this situation, reliability of data acquisition is more crucial than resolution or frequency of \nimaging. An active sensor may be the only feasible source of data, and its reliability will facilitate regular \nmonitoring. Radar will serve this purpose, and an airborne sensor is sufficient for high resolution \nrequirements such as cover typing. This type of data can be used for a baseline map , while coarser \nresolution data can provide updates to any changes in the baseline. \n \nCase study (example)\n \nInventory Branch, Ministry of Forests, Province of British Columbia, Canada  \nThis is an example of the operational requirements and procedure for a provincial department involved in \na number of forestry applications using remote sensing technology. \nThe Inventory Branch is responsible for maintaining a database of Crown Land information concerning \nhistorical, stand, and sustainable forest management information which is used for determining timber \nvolumes and annual allowable cuts. The inventory itself is performed every ten years with 1:15,000 scale \naerial photography, and updated with satellite imagery every two years. \nThe Inventory branch requires geocoded, terrain corrected data. For most studies, the branch currently \nbuys precision geocoded data, and for large scale mapping projects, they will cut costs by obtaining \nsystematic versus precision geocoded data. Further processing is done in-house on workstations. Some \nlocation data are now being provided by the private sector, conducting field traverses with GPS (global \npositioning system) data. \nPresent planimetric accuracy requirements are 20 m, but will be more demanding in the near future. \nAirphotos and orthophotos meet requirements and are good for interpretation but are limited by expense. \nData continuity is important, as monitoring will be an ongoing operation. TM data for updating maps is \nreasonable in cost and information content for interim monitoring. \nMuch of the updating in the Ministry of Forests is done with TM data, either brought digitally into a \nMicroStation workstation to perform heads-up digitizing, or in transparency form with the image overlain \nonto existing maps using a projection device. The Ministry of Forests is presently investigating the \npotential of a number of data sources with various levels of processing applied, and integration \npossibilities to assess accuracy versus cost relationships. \nThe Ministry of Forests in B.C. employs an expert system SHERI (System of Hierarchical Expert \nSystems for Resource Inventories) to provide a link between remotely sensed data, GIS and growth and \nyield modelling. The end to end information flow is complete with the generation of final products \nincluding forest cover maps incorporating planimetric and administrative boundary information. \nPage 191Section 5.3.2 Species Identification & Typing\nCanada Centre for Remote Sensing\n\nCase study (example)\n \n \n \nHyperspectral image and recent stem count from hyperspectral imagery \nForest companies use hyperspectral imagery to obtain stem counts , stand attributes, and for mapping of \nland cover in the forest region of interest. These images depict a false colour hyperspectral image of a \nDouglas fir forest on Vancouver Island at a resolution of 60 cm. The imagery was acquired in the fall of \n1995 by the CASI (Compact Airborne Imaging Spectrometer). Attributes obtained from the imagery (a \nsubset is shown) include: \n  \n  \n  \nPage 192Section 5.3.2 Species Identification & Typing\nCanada Centre for Remote Sensing\n\n \n\nStand Area (hectares) 9.0  \nTotal number of trees 520  \n\nTree density (stems/ha) 58  \nCrown closure (%) 12.46  \n\nAverage tree crown area (sq m) 21.47 \nThe corresponding land cover map contains the following classes: \n\nDark green:\n conifers  \n\nGreen:\n lower branches  \n\nLight purple:\n gravel  \n\nYellow:\n deciduous  \n\nOrange:\n dry ground cover  \n\nRed:\n wet ground cover  \n\nBlue (light):\n water  \n\nBlue (dark):\n deep or clear water  \nAll imagery courtesy of MacMillan Bloedel and ITRES Research Limited. \n  \nPage 193Section 5.3.2 Species Identification & Typing\nCanada Centre for Remote Sensing\n\n5.3.3 Burn Mapping \nBackground\n \nFire is part of the natural reproductive cycle of many forests revitalizing growth by opening \nseeds and releasing nutrients from the soil. However, fires can also spread quickly and \nthreaten settlements and wildlife, eliminate timber supplies, and temporarily damage \nconservation areas. Information is needed to help control the extent of fire, and to assess how \nwell the forest is recovering following a burn.  \nWhy remote sensing?\n \nRemote sensing can be used to detect and monitor forest fires and the regrowth following a \nfire. As a surveillance tool, routine sensing facilitates observing remote and inaccessible \nareas, alerting monitoring agencies to the presence and extent of a fire. NOAA AVHRR \nthermal data and GOES meteorological data can be used to delineate active fires and \nremaining \"hot-spots\" when optical sensors are hindered by smoke, haze, and /or darkness. \nComparing burned areas to active fire areas provides information as to the rate and direction \nof movement of the fire. Remote sensing data can also facilitate route planning for both \naccess to, and escape from, a fire, and supports logistics planning for fire fighting and \nidentifying areas not successfully recovering following a burn. \nYears following a fire, updates on the health and regenerative status of an area can be \nobtained by a single image, and multitemporal scenes can illustrate the progression of \nvegetation from pioneer species back to a full forest cover. \nData requirements\n \nWhile thermal data is best for detecting and mapping ongoing fires, multispectral (optical and \nnear-infrared) data are preferred for observing stages of growth and phenology in a previous \nburn area. The relative ages and area extent of burned areas can be defined and delineated, \nand health of the successive vegetation assessed and monitored. Moderate spatial coverage, \nhigh to moderate resolution, and a low turnaround time are required for burn mapping. On the \nother hand, fire detection and monitoring requires a large spatial coverage, moderate \nresolution and a very quick turnaround to facilitate response. \nCanadian vs. International\n \nRequirements for burn mapping are the same, except where cloud cover precludes the used \nof optical images. In this case, radar can be used to monitor previous burn areas, and is \neffective from the second year following a burn, onwards. \n  \n  \n  \n  \n  \n  \n  \nPage 194Section 5.3.3 Burn Mapping \nCanada Centre for Remote Sensing\n\n  \n  \n  \nCase study (example) Northwest Territory Burn \n \nBurned and burning forest near Norman Wells, NWT  \nIn the western Northwest Territories along the Mackenzie River, boreal forest covers much of \nthe landscape. Natives rely on the forests for hunting and trapping grounds, and the sensitive \nnorthern soil and permafrost are protected from erosion by the forest cover. In the early \n1990's a huge fire devastated the region immediately east of the Mackenzie and threatened \nthe town of Fort Norman, a native town south of Norman Wells. \nThe extent of the burned area, and the areas still burning, can be identified on this NOAA \nscene, as dark regions (A). The lake in the upper right is Great Bear Lake, and the lake to the \nlower right is Great Slave Lake. The distance represented by the yellow line is approximately \n580 km. The course of the Mackenzie River can be seen to the left of these lakes. Fort \nNorman (B) is located at the junction of the Mackenzie River and Great Bear River, leading \nout of Great Bear Lake. At that location, the fire is on both sides of the river. Norman Wells (C) \nis known as an oil producing area, and storage silos, oil rigs, homes, and the only commercial \nairport in that part of the country were threatened. Fires in this region are difficult to access \nbecause of the lack of roads into the region. Winter roads provide only seasonal access to \nvehicles in this part of Canada. The small population base also makes it difficult to control, let \nalone fight, a fire of this magnitude. \nHaze and smoke reflect a large amount of energy at shorter wavelengths and appear as blue \non this image. \nPage 195Section 5.3.3 Burn Mapping \nCanada Centre for Remote Sensing\n\n5.4 Geology \n \nGeology involves the study of landforms, structures, and the subsurface, to understand \nphysical processes creating and modifying the earth's crust. It is most commonly understood \nas the exploration and exploitation of mineral and hydrocarbon resources, generally to \nimprove the conditions and standard of living in society. Petroleum provides gas and oil for \nvehicle transportation, aggregate and limestone quarrying (sand and gravel) provides \ningredients for concrete for paving and construction, potash mines contribute to fertilizer, coal \nto energy production, precious metals and gems for jewelry, diamonds for drill bits, and \ncopper, zinc and assorted minerals for a variety of uses. Geology also includes the study of \npotential hazards such as volcanoes, landslides, and earth quakes, and is thus a critical factor \nfor geotechnical studies relating to construction and engineering. Geological studies are not \nlimited to Earth - remote sensing has been used to examine the composition and structure of \nother planets and moons. \nRemote sensing is used as a tool to extract information about the land surface structure, \ncomposition or subsurface, but is often combined with other data sources providing \ncomplementary measurements. Multispectral data can provide information on lithology or rock \ncomposition based on spectral reflectance. Radar provides an expression of surface \ntopography and roughness, and thus is extremely valuable, especially when integrated with \nanother data source to provide detailed relief. \nRemote sensing is not limited to direct geology applications - it is also used to support \nlogistics, such as route planning for access into a mining area, reclamation monitoring, and \ngenerating basemaps upon which geological data can be referenced or superimposed. \nGeological applications of remote sensing include the following: \n\nsurficial deposit / bedrock mapping  \n\nlithological mapping  \n\nstructural mapping  \n\nsand and gravel (aggregate) exploration/ exploitation  \n\nmineral exploration  \n\nhydrocarbon exploration  \n\nenvironmental geology  \n\ngeobotany  \n\nbaseline infrastructure  \nPage 196Section 5.4 Geology\nCanada Centre for Remote Sensing\n\n\nsedimentation mapping and monitoring  \n\nevent mapping and monitoring  \n\ngeo-hazard mapping  \nplanetary mapping  \nPage 197Section 5.4 Geology\nCanada Centre for Remote Sensing\n\n5.4.1 Structural Mapping & Terrain Analysis \n \nSyncline structures (in Pennsylvania) on SAR imagery \nBackground\n \nStructural geology plays an important role in mineral and hydrocarbon exploration, and \npotential hazard identification and monitoring. \nStructural mapping is the identification and characterization of structural expression. Structures \ninclude faults, folds, synclines and anticlines and lineaments. Understanding structures is the \nkey to interpreting crustal movements that have shaped the present terrain. Structures can \nindicate potential locations of oil and gas reserves by characterizing both the underlying \nsubsurface geometry of rock units and the amount of crustal deformation and stress \nexperienced in a certain locale. Detailed examination of structure can be obtained by \ngeophysical techniques such as seismic surveying. \nStructures are also examined for clues to crustal movement and potential hazards, such as \nearthquakes, landslides, and volcanic activity. Identification of fault lines can facilitate land use \nplanning by limiting construction over potentially dangerous zones of seismic activity. \nWhy remote sensing?\n \nA synoptic view of regional scale is a much \ndifferent perspective than point ground \nobservations when trying to \nmap structural \nelements\n. Remote sensing offers this perspective \nand allows a geologist to examine other reference \nancillary data simultaneously and synergistically, \nsuch as geo-magnetic information. \nCertain remote sensing devices offer unique \ninformation regarding structures, such as in the \nrelief expression offered by radar sensors. \nComparing surface expression to other geological \ninformation may also allow patterns of association to be recognized. For instance, a rock unit \nmay be characterized by a particular radar texture which may also correlate with a high \nmagnetic intensity or geochemical anomaly. Remote sensing is most useful in combination, or \nin synergy, with complementary datasets. \nA benefit of side looking radar is that the illumination conditions can be controlled, and the most \nPage 198Section 5.4.1 Structural Mapping & Terrain Analysis\nCanada Centre for Remote Sensing\n\nappropriate geometry used for type of terrain being examined. Uniform illumination conditions \nprovided by the sun, especially at equatorial latitudes, are usually not conducive to highlighting \nrelief features. An extra benefit of airborne SAR sensors is that acquisition missions can be \ncustomized to orient the flightline parallel to the target orientation, to maximize the illumination \nand shadow effect. \nData requirements\n \nIn areas where vegetation cover is dense, it is very difficult to detect structural features. A \nheavy canopy will visually blanket the underlying formation, limiting the use of optical sensors \nfor this application. Radar however, is sensitive enough to topographic variation that it is able to \ndiscern the structural expression reflected or mirrored in the tree top canopy, and therefore the \nstructure may be clearly defined on the radar imagery. \nStructural analyses are conducted on regional scales, to provide a comprehensive look at the \nextent of faults, lineaments and other structural features. Geologic features are typically large \n(kilometre scale) and applications therefore require small-scale imagery to cover the extent of \nthe element of interest. Aerial photos can be used in temperate areas where large-scale \nimagery is required, particularly to map potential geohazards (e.g. landslides). \nStructural mapping applications generally are \nnot time sensitive (other than for project \ndeadlines!) and so a fast turnaround is not \nrequired. Unless a time series analysis of \ncrustal deformation is being conducted, \nfrequency of imaging is not a critical issue \neither. The key factor for remotely sensed \ndata are that they provide some information \non the spatial distribution and surficial relief of \nthe structural elements. Radar is well suited to \nthese requirements with its side-looking \nconfiguration. Imaging with shallow incidence angles enhances surficial relief and structure. \nShadows\n can be used to help define the structure height and shape, and thus increasing the \nshadow effect, while shallow incidence angles may benefit structural analysis. \nCanadian vs. International requirements\n \nRequirements for remote sensing parameters of structural features are fairly constant \nthroughout the world. Those areas of persistent cloud cover will benefit from radar imaging, \nwhile areas at very high or low latitudes can benefit from low sun angles to highlight subtle \nrelief for optical imaging. \n  \n  \n  \n  \n  \n  \nPage 199Section 5.4.1 Structural Mapping & Terrain Analysis\nCanada Centre for Remote Sensing\n\n  \n  \nCase study (example): Port Coldwell, Ontario: A case for SAR integration\n \n  \nThe structural information provided by radar complements other spatial datasets. When \nintegrated together, SAR and spatial geological datasets provide a valuable source of \ngeological information. In this example, radioactivity information of the area of Port Coldwell, \nOntario, was provided by an \nairborne gamma-ray spectrometry survey\n, which collected \npotassium, thorium, and uranium readings. This data is informative, but it is difficult to put the \ninformation into perspective without the layout and recognizable characteristics of the \nlandscape. \nAirborne SAR image data\n was also acquired of the same region. The SAR image \nis quite interesting in terms of micro-topography and structure, but does not provide any other \ngeo-technical information about the terrain. These two datasets were integrated, using an IHS \napproach (intensity-hue- saturation to replace the conventional red-green-blue colour display). \nThe airborne gamma-ray spectrometry data are coded as the hue and saturation information, \nwhile the SAR terrain information is coded as the intensity information. The resulting \nintegrated image\n is an excellent display of structural, relief, and natural radioactivity \ninformation, allowing a geologist to have a comprehensive view of the data with only one \nimage. \n \nIntegrated image (natural radioactivity and SAR) of Port Coldwell \nPage 200Section 5.4.1 Structural Mapping & Terrain Analysis\nCanada Centre for Remote Sensing\n\n5.4.2 Geologic Unit Mapping \nBackground\n \nMapping geologic units consists primarily of identifying physiographic units and determining \nthe rock lithology or coarse stratigraphy of exposed units. These units or formations are \ngenerally described by their age, lithology and thickness. Remote sensing can be used to \ndescribe lithology by the colour, weathering and erosion characteristics (whether the rock is \nresistant or recessive), drainage patterns, and thickness of bedding. \nUnit mapping is useful in oil and mineral exploration, since these resources are often \nassociated with specific lithologies. Structures below the ground, which may be conducive to \ntrapping oil or hosting specific minerals, often manifest themselves on the Earth's surface. By \ndelineating the structures and identifying the associated lithologies, geologists can identify \nlocations that would most feasibly contain these resources, and target them for exploration. \nBedrock mapping is critical to engineering, construction, and mining operations, and can play \na role in land use and urban planning. Understanding the distribution and spatial relationships \nof the units also facilitates interpretation of the geologic history of the Earth's surface. \nIn terms of remote sensing, these \"lithostratigraphic\" units can be delineated by their spectral \nreflectance signatures, by the structure of the bedding planes, and by surface morphology. \nWhy remote sensing?\n \nRemote sensing gives the overview required to 1) construct regional unit maps, useful for \nsmall scale analyses, and planning field traverses to sample and verify various units for \ndetailed mapping; and 2) understand the spatial distribution and surface relationships \nbetween the units. VIR remote sensing provides the multispectral information relating to the \ncomposition of the unit, while radar can contribute textural information. Multiple data sources \ncan also be integrated to provide a comprehensive view of the lithostratigraphy. \nStereo imagery can also facilitate delineation and identification of units by providing a three \ndimensional view of the local relief. Some rocks are resistant to erosion, whereas others \nerode easily. Identification elements such as weathering manifestations may be apparent on \nhigh or medium resolution imagery and airphotos. \nImages or airphotos can be taken into the field and used as basemaps for field analysis. \nData requirements\n \nTwo different scales of mapping require slightly different imaging sources and parameters. \n1.   For site specific analysis, airphotos provide a high resolution product that can provide \ninformation on differential weathering, tone, and microdrainage. Photos may be easily \nviewed in stereo to assess relief characteristics.  \n2.   Regional overviews require large coverage area and moderate resolution. An excellent \ndata source for regional applications is a synergistic combination of radar and optical \nimages to highlight terrain and textural information.  \nIn either case, frequency of imaging is not an issue since in many cases the geological \nfeatures of interest remain relatively static. Immediate turnaround is also not critical. \nCanada vs. International\n \nRequirements for this application do not differ significantly around the world. One of the \nPage 201Section 5.4.2 Geologic Unit Mapping\nCanada Centre for Remote Sensing\n\nbiggest problems faced by both temperate and tropical countries is that dense forest covers \nmuch of the landscape. In these areas, geologists can use remote sensing to infer underlying \nlithology by the condition of vegetation growing above it. This concept is called \"geobotany\". \nThe underlying principle is that the mineral and sedimentary constituents of the bedrock may \ncontrol or influence the condition of vegetation growing above. \nIn reality, the topography, structure, surficial \nmaterials, and vegetation combine to facilitate \ngeologic unit interpretation and mapping. Optimal \nuse of \nremote sensing data\n therefore, is one that \nintegrates different sources of image data, such as \noptical and radar, at a scale appropriate to the \nstudy. \n  \nImage example\n \nEven once \ngeological unit maps\n are created, they \ncan still be presented more informatively by \nencompassing the textural information provided by \nSAR data. A basic geological unit map can be made \nmore informative by adding textural and structural \ninformation. In this example of the Sudbury, Ontario \nregion, an integration transform was used to merge \nthe map data (bedrock and structural geology \ninformation, 1992) with the SAR image data. The \nresulting image\n can be used on a local or regional \nscale to detect structural trends within and between \nunits. The areas common to each image are outlined \nin black. \n  \nGeological map and SAR data integrated \nPage 202Section 5.4.2 Geologic Unit Mapping\nCanada Centre for Remote Sensing\n\n5.5 Hydrology \n \nHydrology is the study of water on the Earth's surface, whether flowing above ground, frozen \nin ice or snow, or retained by soil. Hydrology is inherently related to many other applications o\nf \nremote sensing, particularly forestry, agriculture and land cover, since water is a vital \ncomponent in each of these disciplines. Most hydrological processes are dynamic, not only \nbetween years, but also within and between seasons, and therefore require frequent \nobservations. Remote sensing offers a synoptic view of the spatial distribution and dynamics \nof hydrological phenomena, often unattainable by traditional ground surveys. Radar has \nbrought a new dimension to hydrological studies with its active sensing capabilities, allowing \nthe time window of image acquisition to include inclement weather conditions or seasonal or \ndiurnal darkness. \n \nExamples of hydrological applications include: \n\nwetlands mapping and monitoring,  \n\nsoil moisture estimation,  \n\nsnow pack monitoring / delineation of extent,  \n\nmeasuring snow thickness,  \n\ndetermining snow-water equivalent,  \n\nriver and lake ice monitoring,  \n\nflood mapping and monitoring,  \n\nglacier dynamics monitoring (surges, ablation)  \n\nriver /delta change detection  \n\ndrainage basin mapping and watershed modelling  \nirrigation canal leakage detection  \n\nirrigation scheduling  \nPage 203Section 5.5 Hydrology\nCanada Centre for Remote Sensing\n\n5.5.1 Flood Delineation & Mapping \n \nBackground\n \nA natural phenomenon in the hydrological cycle is flooding. Flooding is necessary to replenish \nsoil fertility by periodically adding nutrients and fine grained sediment; however, it can also \ncause loss of life, temporary destruction of animal habitat and permanent damage to urban \nand rural infrastructure. Inland floods can result from disruption to natural or man-made dams, \ncatastrophic melting of ice and snow (jökulhlaups in Iceland), rain, river ice jams and / or \nexcessive runoff in the spring.  \nWhy remote sensing?\n \nRemote sensing techniques are used to measure and monitor the areal extent of the flooded \nareas , to efficiently target rescue efforts and to provide quantifiable estimates of the amount \nof land and infrastructure affected. Incorporating remotely sensed data into a GIS allows for \nquick calculations and assessments of water levels, damage, and areas facing potential flood \ndanger. Users of this type of data include flood forecast agencies, hydropower companies, \nconservation authorities, city planning and emergency response departments, and insurance \ncompanies (for flood compensation). The identification and mapping of floodplains, \nabandoned river channels, and meanders are important for planning and transportation \nrouting. \nData requirements\n \nMany of these users of remotely sensed data need the information during a crisis and \ntherefore require \"near-real time turnaround\". Turnaround time is less demanding for those \ninvolved in hydrologic modelling, calibration/validation studies, damage assessment and the \nplanning of flood mitigation. Flooding conditions are relatively short term and generally occur \nduring inclement weather, so optical sensors, although typically having high information \ncontent for this purpose, can not penetrate through the cloud cover to view the flooded region \nbelow. For these reasons, active SAR sensors are particularly valuable for flood monitoring. \nRADARSAT in particular offers a high turnaround interval, from when the data is acquired by \nthe sensor, to when the image is delivered to the user on the ground. The land / water \nPage 204Section 5.5.1 Flood Delineation & Mapping\nCanada Centre for Remote Sensing\n\ninterface is quite easily discriminated with SAR data, allowing the flood extent to be delineated \nand mapped. The SAR data is most useful when integrated with a pre-flood image, to \nhighlight the flood-affected areas, and then presented in a GIS with cadastral and road \nnetwork information. \nCanada vs. International\n \nRequirements for this application are similar the world over. Flooding can affect many areas o\nf \nthe world, whether coastal or inland, and many of the conditions for imaging are the same. \nRadar provides excellent water/land discrimination and is reliable for imaging despite most \natmospheric limitations. \nCase study (example)\n: \nRADARSAT MAPS THE MANITOBA SEA: \nTHE FLOODS OF 1997 \nIn 1997, the worst Canadian flood of the 20th century inundated prairie fields and towns in the \nstates of Minnesota, North Dakota, and the Canadian province of Manitoba. By May 5th, \n25,000 residents of Manitoba had been evacuated from their homes, with 10,000 more on \nalert. The watershed of the Red River, flowing north from the United States into Canada, \nreceived unusually high winter snowfalls and heavy precipitation in April. These factors, \ncombined with the northward flow into colder ground areas and very flat terrain beyond the \nimmediate floodplain, caused record flooding conditions, with tremendous damage to homes \nand property, in addition to wildlife and livestock casualties. For weeks emergency response \nteams, area residents, and the media monitored the extent of the flood, with some input from \nremote sensing techniques. It is impossible to imagine the scale of flooding from a ground \nperspective, and even video and photographs from aircraft are unable to show the full extent. \nSpectacular satellite images however, have shown the river expand from a 200 m wide \nribbon, to a body of water measuring more than 40 km across. Towns protected by sand-bag \ndikes, were dry islands in the midst of what was described as the \"Red Sea\". Many other \ntowns weren't as fortunate, and home and business owners were financially devastated by \ntheir losses. \nInsurance agents faced their own flood of claims for property, businesses, and crops ruined or \ndamaged by the Red River flood. To quickly assess who is eligible for compensation, the \ninsurance companies can rely on remotely sensed data to delineate the flood extent, and GIS \ndatabases to immediately identify whose land was directly affected. City and town planners \ncould also use the images to study potential locations for future dike reinforcement and \nconstruction, as well as residential planning. \n  \n  \n  \n  \nPage 205Section 5.5.1 Flood Delineation & Mapping\nCanada Centre for Remote Sensing\n\n  \nBoth NOAA-AVHRR and RADARSAT images \ncaptured the scale and extent of the flood. The \nAVHRR sensors onboard the NOAA satellites \nprovided \nsmall-scale views\n of the entire flood area \nfrom Lakes Manitoba and Winnipeg south to the \nNorth Dakota - South Dakota border. Some of the \nbest images are those taken at night in the thermal \ninfrared wavelengths, where the cooler land appears \ndark and the warmer water (A) appears white. \nManmade dikes, such as the Brunkild Dike (B), were \nquickly built to prevent the flow of water into southern \nWinnipeg. Dikes are apparent on the image as very regular straight boundaries between the \nland and floodwater. Although the city of Winnipeg (C) is not clearly defined, the Winnipeg \nfloodway (D) immediately to the east, paralleling the Red River at the northeast end of the \nflood waters, is visible since it is full of water. The floodway was designed to divert excess \nwater flow from the Red River outside of the city limits. In this case, the volume of water was \nsimply too great for the floodway to carry it all, and much of the flow backed up and spread \nacross the prairie. \nRADARSAT\n provided some excellent views of the \nflood, because of its ability to image in darkness or \ncloudy weather conditions, and its sensitivity to the \nland/water differences. In this image, the flood water \n(A) completely surrounds the town of Morris (B), \nvisible as a bright patch within the dark flood water. \nThe flooded areas appear dark on radar imagery \nbecause very little of the incident microwave energy \ndirected toward the smooth water surface returns \nback to the sensor. The town however, has many \nangular (corner) reflectors primarily in the form of \nbuildings, which cause the incident energy to \n\"bounce\" back to the sensor. \nTransportation routes can still be observed. A railroad, on its raised bed, can be seen amidst \nthe water just above (C), trending southwest - northeast. Farmland relatively unaffected by the \nflood (D) is quite variable in its backscatter response. This is due to differences in each field's \nsoil moisture and surface roughness. \nPage 206Section 5.5.1 Flood Delineation & Mapping\nCanada Centre for Remote Sensing\n\n5.5.2 Soil Moisture \nBackground\n \nSoil moisture is an important measure in determining crop yield potential in Canada and in \ndrought-affected parts of the world (Africa) and for watershed modelling. The moisture content \ngenerally refers to the water contained in the upper 1-2m of soil, which can potentially \nevaporate into the atmosphere. Early detection of dry conditions which could lead to crop \ndamage, or are indicative of potential drought, is important for amelioration efforts and \nforecasting potential crop yields, which in turn can serve to warn farmers, prepare \nhumanitarian aid to affected areas, or give international commodities traders a competitive \nadvantage. Soil moisture conditions may also serve as a warning for subsequent flooding if \nthe soil has become too saturated to hold any further runoff or precipitation. Soil moisture \ncontent is an important parameter in watershed modelling that ultimately provides information \non hydroelectric and irrigation capacity. In areas of active deforestation, soil moisture \nestimates help predict amounts of run-off, evaporation rates, and soil erosion. \nWhy remote sensing? Remote sensing offers a means of measuring soil moisture across a \nwide area instead of at discrete point locations that are inherent with ground measurements. \nRADAR is effective for obtaining qualitative imagery and quantitative measurements, because \nradar backscatter response is affected by soil moisture, in addition to topography, surface \nroughness and amount and type of vegetative cover. Keeping the latter elements static, \nmultitemporal radar images can show the change in soil moisture over time. The radar is \nactually sensitive to the soil's dielectric constant, a property that changes in response to the \namount of water in the soil. \nUsers of soil moisture information from remotely sensed data include agricultural marketing \nand administrative boards, commodity brokers, large scale farming managers, conservation \nauthorities, and hydroelectric power producers. \nData requirements\n \nObviously, a sensor must be sensitive to moisture conditions, and radar satisfies this \nrequirement better than optical sensors. Frequent and regular (repeated) imaging is required \nduring the growing season to follow the change in moisture conditions, and a quick turnaround \nis required for a farmer to respond to unsuitable conditions (excessive moisture or dryness) in \na timely manner. Using high resolution images, a farmer can target irrigation efforts more \naccurately. Regional coverage allows an overview of soil and growing conditions of interest to \nagricultural agencies and authorities. \nCanada vs. International\n \nData requirements to address this application are similar around the world, except that higher \nresolution data may be necessary in areas such as Europe and Southeast Asia, where field \nand land parcel sizes are substantially smaller than in North America. \nCase Study (example)\n \nRainfall distribution , Melfort, Saskatchewan, Canada\n  \nAs with most Canadian prairie provinces, the topography of Saskatchewan is quite flat. The \nregion is dominated by black and brown chernozemic soil characterized by a thick dark \norganic horizon, ideal for growing cereal crops such as wheat. More recently, canola has been \nintroduced as an alternative to cereal crops. \nPage 207Section 5.5.2 Soil Moisture\nCanada Centre for Remote Sensing\n\n \nShown here is a radar image acquired July 7, 1992 by the European Space Agency (ESA) \nERS-1 satellite. This synoptic image of an area near Melfort, Saskatchewan details the effects \nof a localized precipitation event on the microwave backscatter recorded by the sensor. Areas \nwhere precipitation has recently occurred can be seen as a bright tone (bottom half) and \nthose areas unaffected by the event generally appear darker (upper half). This is a result of \nthe complex dielectric constant which is a measure of the electrical properties of surface \nmaterials. The dielectric property of a material influences its ability to absorb microwave \nenergy, and therefore critically affects the scattering of microwave energy. \nThe magnitude of the radar backscatter is proportional to the dielectric constant of the \nsurface. For dry, naturally occurring materials, this is in the range of 3 - 8 , and may reach \nvalues as high as 80 for wet surfaces. Therefore the amount of moisture in the surface \nmaterial directly affects the amount of backscattering. For example, the lower the dielectric \nconstant, the more incident energy is absorbed, the darker the object will be on the image. \nPage 208Section 5.5.2 Soil Moisture\nCanada Centre for Remote Sensing\n\n5.6 Sea Ice \n \nFor people living in northern environments, ice is a common phenomenon that affects our \nlocal activities. Most of us however, don't consider its larger regional or global implications. Ice \ncovers a substantial part of the Earth's surface and is a major factor in commercial shipping \nand fishing industries, Coast Guard and construction operations, and global climate change \nstudies. Polar sea ice seasonally covers an even larger area, roughly equal in size to the \nNorth American continent, 25 million km². \nIts extensive distribution means that sea ice plays a large role in the albedo of the earth. \nAlbedo is a term referring to the measure of reflectivity of the Earth's surface. Ice and snow \nare highly reflective and changes in their distribution would affect how much solar energy is \nabsorbed by the earth. Under warming conditions, the ice would melt, and less incoming \nenergy would be reflected, thereby potentially increasing the warming trend. The opposite \nmay also be true - an increase of ice due to cooler conditions would reflect even more of the \nincoming solar energy, potentially propagating even colder conditions. Of course these \npotential changes in sea ice distribution are of concern to scientists studying global climate \nchange, as are sea ice interactions with the ocean and atmosphere. \nDuring winter in the northern hemisphere, ice creates a substantial barrier to both lake and \nocean going vessels trying to reach ports or navigating along coastlines. Ice floes, pack ice \nand icebergs create potential hazards to navigation, while landfast ice hinders access to the \nshore. Ice breakers are often used to create routes for ships to follow from the open water to \ntheir ports. In Canada, two important locations for this type of operation are the Gulf of St. \nLawrence /Great Lakes and the Canadian Arctic. The Gulf is the main route for international \ncargo vessels headed for Montreal and Québec, and is affected by ice through the winter and \nspring. Canada's Arctic is home to mineral and hydrocarbon reserves that require shipping for \nconstruction equipment, supplies, and transport of resources to refineries and populated \nmarkets. In addition, the main method of re-supply for northern communities is by sea. In both \nareas, information regarding ice conditions, type, concentration and movement are required. \nTo address these demands, ice analysis charts, daily ice hazard bulletins, seasonal forecasts, \nand tactical support for observation are provided. In Canada, the Canadian Ice Service is \nresponsible for acquiring and distributing this information and appropriate products. They also \nmaintain an ice information archive which contains useful data for environmental impact \nassessments, risk assessment, short-term and seasonal route planning for ships, efficient \nresource transportation and infrastructure development. \nPage 209Section 5.6 Sea Ice\nCanada Centre for Remote Sensing\n\nRemote sensing data can be used to identify and map different ice types, locate leads (large \nnavigable cracks in the ice), and monitor ice movement. With current technology, this \ninformation can be passed to the client in a very short timeframe from acquisition. Users of \nthis type of information include the Coast Guard, port authorities, commercial shipping and \nfishing industries, ship builders, resource managers (oil and gas / mining), infrastructure \nconstruction companies and environmental consultants, marine insurance agents, scientists, \nand commercial tour operators. \nExamples of sea ice information and applications include: \n\nice concentration  \n\nice type / age /motion  \n\niceberg detection and tracking  \n\nsurface topography  \n\ntactical identification of leads: navigation: safe shipping routes/rescue  \nice condition (state of decay)  \n\nhistorical ice and iceberg conditions and dynamics for planning purposes  \n\nwildlife habitat  \n\npollution monitoring  \n     \nmeteorological / global change research  \nPage 210Section 5.6 Sea Ice\nCanada Centre for Remote Sensing\n\n5.6.1 Ice type and concentration \n \nBackground\n \nShips navigating through high latitude seas (both northern and southern) are often faced with \nobstacles of pack ice and moving ice floes. Ice breakers are designed to facilitate travel in \nthese areas, but they require knowledge about the most efficient and effective route through \nthe ice. It is important to know the extent of the ice, what type of ice it is, and the \nconcentration and distribution of each type. This information is also valuable for offshore \nexploration and construction activities, as well as coastal development planning. \nIce isn't simply ice!\n \nSea ice isn't a uniform, homogeneous unit. What appears to be a single cover of ice can vary \nin roughness, strength, salinity, and thickness. Pack ice and ice floes consist of assemblages \nof different ice types patchworked together, intersected by dynamic leads or cracks. Ice is \nusually defined by its age - either as new, first-year or multi-year ice. New ice is smooth and \nrelatively thin (5-30 cm)and provides the least resistance to ice breakers . First year ice is \nolder and thicker than new ice (30-200cm) and can pose a significant hazard to all vessels, \nincluding icebreakers. When deformed into rubble fields and ridges, first year ice types can \nbecome impassable. Ice that survives into a second and later years, generally becomes \nthicker (>2m) and declines in salinity, increasing the internal strength. This ice is a dangerous \nhazard to ships and off-shore structures. Ice charts are maps of different ice types and \nconcentration of ice, which are distributed to those working in marine environments where ice \naffects their operations. \nWhy remote sensing?\n \nObserving ice conditions is best from a ground perspective, but this doesn't allow for \ndetermining the extent or distribution of the ice. Remote sensing from airborne or spaceborne \nsensors provides this very valuable view. The areas of ice can be easily mapped from an \nimage, and when georeferenced, provide a useful information source. Remote sensing \ntechnology is capable of providing enough information for an analyst to identify ice type (and \nthus infer ice thickness), and from this data, ice charts can be created and distributed to those \nwho require the information. \nActive radar is an excellent sensor to observe ice conditions because the microwave energy \nand imaging geometry combines to provide measures of both surface and internal \ncharacteristics. Backscatter is influenced by dielectric properties of the ice (in turn dependent \nPage 211Section 5.6.1 Ice type and concentration\nCanada Centre for Remote Sensing\n\non salinity and temperature), surface factors (roughness, snow cover) and internal geometry / \nmicrostructure. Surface texture is the main contributor to the radar backscatter and it is this \ncharacteristic which is used to infer ice age and thickness. New ice tends to have a low return \nand therefore dark appearance on the imagery due to the specular reflection of incident \nenergy off the smooth surface. First year ice can have a wide variety of brightness depending \non the degree of roughness caused by ridging and rubbing. Multi-year ice has a bright return \ndue to diffuse scattering from its low salinity, and porous structure. \nCoarse resolution optical sensors such as NOAA's AVHRR provide an excellent overview of \npack ice extent if atmospheric conditions are optimal (resolution = 1km). \nPassive microwave sensing also has a role in sea ice applications. Objects (including people!) \nemit small amounts of microwave radiation, which can be detected by sensors. Sea ice and \nwater emit substantially different amounts of radiation, so it is relatively easy to delineate the \ninterface between the two. The SSM/I onboard the shuttle collected data in this manner. The \nmain drawback of passive microwave sensors is their poor spatial resolution (approx. 25km) \nwhich is too coarse for tactical ice navigation.  \nData requirements\n \nOcean ice occurs in extreme latitudes - the high Arctic and Antarctica. But ice also covers \nprime sea and lake shipping routes in northern countries, particularly Canada, Russia, Japan \nand northern European and Scandinavian countries. High latitude areas experience low solar \nillumination conditions in the winter when the ice is at a maximum. This has traditionally \nhindered remote sensing effectiveness, until the operationalization of radar sensors. The all \nweather / day - night, capabilities of SAR systems, makes radar remote sensing the most \nuseful for ice type and concentration mapping. \nTo provide sufficient information for navigation purposes, the data must be captured \nfrequently and must be processed and ready for use within a very short time frame. High \nresolution data covering 1-50 km is useful for immediate ship navigation, whereas coarse \nresolution (1-50km), large area coverage (100 - 2000km²) images are more useful for regional \nstrategic route planning. For navigation purposes, the value of this information has a limited \ntime window. However, for playing a role in increasing our knowledge about climate dynamics \nand ice as an indicator of global climate change, the data has long term value. \nRADARSAT has orbital parameters and a radar sensor designed to address the demands of \nthe ice applications community. The Arctic area is covered once a day by RADARSAT and \nsystems are in place to efficiently download the data direct from the ground processing station \nright to the vessel requiring the information, in a time frame of four hours. Airborne radar \nsensors are also useful for targeting specific areas and providing high resolution imagery \nunavailable from commercial spaceborne systems. Airborne radar is more expensive but has \nthe benefit of directly targetting the area of interest, which may be important for time critical \ninformation, such as tactical navigation in dynamic ice. Winter is the preferred season for \nacquiring radar scenes for ice typing. Melting and wet conditions reduce the contrast between \nice types which makes information extraction more difficult. \nFuture remote sensing devices are planned to provide comprehensive measurements of sea \nice extent.  \nPage 212Section 5.6.1 Ice type and concentration\nCanada Centre for Remote Sensing\n\n5.6.2 Ice motion \nBackground\n \nIce moves quickly and sometimes unpredictably in response to ocean currents and wind. Ice \nfloes can move like tectonic plates, sometimes breaking apart like a rift valley or colliding in a \nstyle similar to the Indian and Asian plates, creating a smaller version of the Himalayan \nMountains - a series of ridges and blocky ice rubble. Vessels can be trapped or damaged by \nthe pressure resulting from these moving ice floes. Even offshore structures can be damaged \nby the strength and momentum of moving ice. For these reasons it is important to understand \nthe ice dynamics in areas of construction or in the vicinity of a shipping/fishing route.  \nWhy remote sensing?\n \nRemote sensing gives a tangible measure of direction and rate of ice movement through \nmapping and change detection techniques. Ice floes actually have individual morphological \ncharacteristics (shape, structures) that allow them to be distinguished from one another. The \nfloes can be mapped and their movement monitored to facilitate in planning optimum shipping \nroutes, to predict the effect of ice movement on standing structures (bridges, platforms).Users \nof this type of information include the shipping, fishing, and tourism industries, as well as \nengineers involved in offshore platform and bridge design and maintenance. \nData requirements\n \nMonitoring of ice movement requires frequent and reliable imaging. The revisit interval must \nbe frequent enough to follow identifiable features before tracking becomes difficult due to \nexcessive movement or change in appearance. Active microwave sensing (radar) provides a \nreliable source of imaging under all weather and illumination conditions. RADARSAT provides \nthis type of sensor and is a spaceborne platform, which is advantageous for routine imaging \noperations. The orbital path ensures that Arctic areas are covered daily which meets the \nrequirement for frequent imaging. \nThe resolution and imaging frequency requirements for ice motion tracking vary with the size \nof floes and the ice dynamics in a region. In areas of large slow moving floes (e.g. Beaufort \nSea), 1km resolution data over 10 day intervals is adequate. In dynamic marginal ice zones \n(e.g. Gulf of St. Lawrence), 100m resolution data over 12-24 hr intervals is required. \nCase study (example)\n \nThe significance of the force and potential effect of ice movement was brought to light recently \nwith the design and construction of the Confederation Bridge, a 13km link from Prince Edward \nIsland, in Canada's Maritimes, across Northumberland Strait to New Brunswick on Canada's \nmainland. Crossing a strait that endures ice floes moving in response to winds, currents and \ntides through a narrow arm of the Gulf of St. Lawrence, the bridge will have to withstand \ntremendous forces from moving ice impacting its supports. \n\"More effort was spent related to the ice engineering aspect of this bridge \nthan probably on any other [similar] structure that has ever been built\" Dr. \nGus Cammaert \nIce floes in Northumberland Strait are dynamic due to oceanic and atmospheric forces, yet \nconstricted in their movement. The result is compression collisions creating large rubbly ice \nmasses that extend vertically above and below the water level up to 20 m1 (each direction). \nThese ice masses have the potential of critically damaging any structure impeding its \nmovement back and forth in the strait. The design and engineering of the bridge had to take \nPage 213Section 5.6.2 Ice motion\nCanada Centre for Remote Sensing\n\ninto account both the thickness and actual constant movement of the ice. Ice information \narchived at the Canadian Ice Service contributed to the understanding of the ice dynamics in \nthe strait, and its tensile properties, critical for setting engineering parameters.  \n \nDuring construction, a radar image of the bridge site was obtained to observe the impact of \nthe bridge supports on the flow of ice around the site. Due to the design of the supports, which \nare cone-shaped at the waterline to help bend and break the ice, the ice cracked and flowed \naround the supports. This is one image where ice movement can be inferred from a single \nimage and does not require multi-temporal scenes. In the image, the ice can be seen flowing \nfrom bottom to the top\n with the wakes of rubble created by the bridge supports clearly \nvisible. \nRemote sensing will be used to monitor the effect of the bridge on the ice movement and \nensure that ice build up isn't occurring beyond expectations. As exemplified in the image, the \nbridge will have an impact on the ice dynamics, by breaking up large floes into smaller pieces \nwhich may accumulate on the shore in piles. This effect will be monitored, as will any \nsubsequent effects on microclimate, which might affect the agriculture or fishing industries of \nPEI1. \nBridge web site:\n \nReference: Thurston, H., 1997. Strait Across, Canadian Geographic, Vol. 117, No.2, March-\nApril 1997. \nFor more information on ice applications: \nCanadian Ice Service, Environment Canada: \nhttp://ice-glaces.ec.gc.ca/App/WsvPageDsp.cfm?ID=1&Lang=eng  \nPage 214Section 5.6.2 Ice motion\nCanada Centre for Remote Sensing\n\n5.7 Land Cover & Land Use \n \nAlthough the terms land cover and land use are often used interchangeably, their actual \nmeanings are quite distinct. Land cover refers to the surface cover on the ground, whether \nvegetation, urban infrastructure, water, bare soil or other. Identifying, delineating and mapping \nland cover is important for global monitoring studies, resource management, and planning \nactivities. Identification of land cover establishes the baseline from which monitoring activities \n(change detection) can be performed, and provides the ground cover information for baseline \nthematic maps. \nLand use refers to the purpose the land serves, for example, recreation, wildlife habitat, or \nagriculture. Land use applications involve both baseline mapping and subsequent monitoring, \nsince timely information is required to know what current quantity of land is in what type of use \nand to identify the land use changes from year to year. This knowledge will help develop \nstrategies to balance conservation, conflicting uses, and developmental pressures. Issues \ndriving land use studies include the removal or disturbance of productive land, urban \nencroachment, and depletion of forests. \nIt is important to distinguish this difference between land cover and land use, and the \ninformation that can be ascertained from each. The properties measured with remote sensing \ntechniques relate to land cover, from which land use can be inferred, particularly with ancillary \ndata or a priori knowledge. \nLand cover / use studies are multidisciplinary in nature, and thus the participants involved in \nsuch work are numerous and varied, ranging from international wildlife and conservation \nfoundations, to government researchers, and forestry companies. Regional (in Canada, \nprovincial) government agencies have an operational need for land cover inventory and land \nuse monitoring, as it is within their mandate to manage the natural resources of their \nrespective regions. In addition to facilitating sustainable management of the land, land cover \nand use information may be used for planning, monitoring, and evaluation of development, \nindustrial activity, or reclamation. Detection of long term changes in land cover may reveal a \nresponse to a shift in local or regional climatic conditions, the basis of terrestrial global \nmonitoring. \nOngoing negotiations of aboriginal land claims have generated a need for more stringent \nPage 215Section 5.7 Land Cover & Land Use\nCanada Centre for Remote Sensing\n\nknowledge of land information in those areas, ranging from cartographic to thematic \ninformation. \nResource managers involved in parks, oil, timber, and mining companies, are concerned with \nboth land use and land cover, as are local resource inventory or natural resource agencies. \nChanges in land cover will be examined by environmental monitoring researchers, \nconservation authorities, and departments of municipal affairs, with interests varying from tax \nassessment to reconnaissance vegetation mapping. Governments are also concerned with \nthe general protection of national resources, and become involved in publicly sensitive \nactivities involving land use conflicts. \nLand use applications of remote sensing include the following:  \n\nnatural resource management  \n\nwildlife habitat protection  \n\nbaseline mapping for GIS input  \n\nurban expansion / encroachment  \n\nrouting and logistics planning for seismic / exploration / resource extraction activities  \n\ndamage delineation (tornadoes, flooding, volcanic, seismic, fire)  \n\nlegal boundaries for tax and property evaluation  \n\ntarget detection - identification of landing strips, roads, clearings, bridges, land/water \ninterface  \nPage 216Section 5.7 Land Cover & Land Use\nCanada Centre for Remote Sensing\n\n5.7.1 Land Use Change (Rural / Urban) \nBackground\n \nAs the Earth's population increases and national economies continue to move away from \nagriculture based systems, cities will grow and spread. The urban sprawl often infringes upon \nviable agricultural or productive forest land, neither of which can resist or deflect the \noverwhelming momentum of urbanization. City growth is an indicator of industrialization \n(development) and generally has a negative impact on the environmental health of a region. \nThe change in land use from rural to urban is monitored to estimate populations, predict and \nplan direction of urban sprawl for developers, and monitor adjacent environmentally sensitive \nareas or hazards. Temporary refugee settlements and tent cities can be monitored and \npopulation amounts and densities estimated. \nAnalyzing agricultural vs. urban land use is important for ensuring that development does not \nencroach on valuable agricultural land, and to likewise ensure that agriculture is occurring on \nthe most appropriate land and will not degrade due to improper adjacent development or \ninfrastructure. \nWhy remote sensing?\n \nWith multi-temporal analyses, remote sensing gives a unique perspective of how cities evolve. \nThe key element for mapping rural to urban landuse change is the ability to discriminate \nbetween rural uses (farming, pasture forests) and urban use (residential, commercial, \nrecreational). Remote sensing methods can be employed to classify types of land use in a \npractical, economical and repetitive fashion, over large areas. \nData requirements\n \nRequirements for rural / urban change detection and mapping applications are 1) high \nresolution to obtain detailed information, and 2) multispectral optical data to make fine \ndistinction among various land use classes. \nSensors operating in the visible and infrared portion of the spectrum are the most useful data \nsources for land use analysis. While many urban features can be detected on radar and other \nimagery (usually because of high reflectivity), VIR data at high resolution permits fine \ndistinction among more subtle land cover/use classes. This would permit a confident \nidentification of the urban fringe and the transition to rural land usage. Optical imagery \nacquired during winter months is also useful for roughly delineating urban areas vs. non-\nurban. Cities appear in dramatic contrast to smooth textured snow covered fields. \nPage 217Section 5.7.1 Land Use Change (Rural / Urban)\nCanada Centre for Remote Sensing\n\nRadar sensors also have some use for all urban/rural delineation applications, due to the \nability of the imaging geometry to enhance anthropogenic features, such as buildings, in the \nmanner of corner reflectors. The optimum geometric arrangement between the sensor and \nurban area is an orientation of linear features parallel to the sensor movement, perpendicular \nto the incoming incident EM energy. \nGenerally, this type of application does not require a high turnaround rate, or a frequent \nacquisition schedule. \nCanada vs. International\n \n \nThroughout the world, requirements for rural/urban delineation will differ according to the \nprevalent atmospheric conditions. Areas with frequently cloudy skies may require the \npenetrating ability of radar, while areas with clear conditions can use airphoto, optical satellite \nor radar data. While the land use practices for both rural and urban areas will be significantly \ndifferent in various parts of the world, the requirement for remote sensing techniques to be \napplied (other than the cloud-cover issue) will be primarily the need for fine spatial detail. \nCase study (example)\n \nThis image of land cover change provides \nmultitemporal information in the form of urban growth \nmapping. The colours represent urban land cover for \ntwo different years. The green delineates those \nareas of urban cover in 1973, and the pink, urban \nareas for 1985. This image dramatically shows the \nchange in expansion of existing urban areas, and the \nclearing of new land for settlements over a 12 year \nperiod. This type of information would be used for \nupgrading government services, planning for \nincreased transportation routes, etc. \nPage 218Section 5.7.1 Land Use Change (Rural / Urban)\nCanada Centre for Remote Sensing\n\n5.7.2 Land Cover / Biomass Mapping \nBackground\n \nLand cover mapping serves as a basic inventory of land resources for all levels of \ngovernment, environmental agencies, and private industry throughout the world. Whether \nregional or local in scope, remote sensing offers a means of acquiring and presenting land \ncover data in a timely manner. Land cover includes everything from crop type, ice and snow, \nto major biomes including tundra, boreal or rainforest, and barren land. \nRegional land cover mapping is performed by almost anyone who is interested in obtaining an \ninventory of land resources, to be used as a baseline map for future monitoring and land \nmanagement. Programs are conducted around the world to observe regional crop conditions \nas well as investigating climatic change on a regional level through biome monitoring. \nBiomass mapping provides quantifiable estimates of vegetation cover, and biophysical \ninformation such as leaf area index (LAI), net primary productivity (NPP) and total biomass \naccumulations (TBA) measurements - important parameters for measuring the health of our \nforests, for example. \nWhy remote sensing?\n \nThere is nothing as practical and cost efficient for \nobtaining a timely regional overview of land cover \nthan remote sensing techniques. Remote sensing \ndata are capable of capturing changes in plant \nphenology (growth) throughout the growing season, \nwhether relating to changes in chlorophyll content \n(detectable with VIR) or structural changes (via \nradar). For regional mapping, continuous spatial \ncoverage over large areas is required. It would be \ndifficult to detect regional trends with point source \ndata. Remote sensing fulfills this requirement, as \nwell as providing \nmultispectral\n, \nmultisource\n, and \nmultitemporal information for an accurate \nclassification of land cover. The multisource example image shows the benefit of increased \ninformation content when two data sources are integrated. On the left is TM data, and on the \nright it has been merged with airborne SAR. \n \n  \nPage 219Section 5.7.2 Land Cover / Biomass Mapping\nCanada Centre for Remote Sensing\n\nData requirements\n \nFor continental and global scale vegetation studies, moderate resolution data (1km) is \nappropriate, since it requires less storage space and processing effort, a significant \nconsideration when dealing with very large area projects. Of course the requirements depend \nentirely on the scope of the application. Wetland mapping for instance, demands a critical \nacquisition period and a high resolution requirement. \nCoverage demand will be very large for regional types of surveying. One way to adequately \ncover a large area and retain high resolution, is to create mosaics of the area from a number \nof scenes. \nLand cover information may be time sensitive. The identification of crops, for instance canola, \nmay require imaging on specific days of flowering, and therefore, reliable imaging is \nappropriate. Multi-temporal data are preferred for capturing changes in phenology throughout \nthe growing season. This information may be used in the classification process to more \naccurately discriminate vegetation types based on their growing characteristics. \n \nWhile optical data are best for land cover mapping, radar imagery is a good replacement in \nvery cloudy areas.  \nCase study (example)\n  \nNBIOME: Classification of Canada's Land Cover  \nA major initiative of the Canada Centre for Remote \nSensing is the development of an objective, \nreproducible classification of Canada's landcover. \nThis classification methodology is used to produce \na baseline map of the major biomes and land cover \nin Canada, which can then be compared against \nsubsequent classifications to observe changes in \ncover. These changes may relate to regional \nclimatic or anthropogenic changes affecting the \nlandscape. \nThe classification is based on NOAA-AVHRR LAC \n(Local Area Coverage) (1km) data. The coarse \nresolution is required to ensure efficient processing \nand storage of the data, when dealing with such a large coverage area. Before the \nclassification procedure, cloud -cover reduced composites of the Canadian landmass, each \nspanning 10 day periods are created. In the composite, the value for each pixel used is the \nPage 220Section 5.7.2 Land Cover / Biomass Mapping\nCanada Centre for Remote Sensing\n\none most cloud free of the ten days. This is determined by the highest normalized difference \nvegetation index (NDVI) value, since low NDVI is indicative of cloud cover (low infrared \nreflectance, high visible reflectance). The data also underwent a procedure to minimize \natmospheric, bidirectional, and contamination effects. \nThe composites consist of four channels, mean reflectance of AVHRR channels 1 and 2, \nNDVI and area under the (temporal NDVI) curve. 16 composites (in 1993) were included in a \ncustomized land cover classification procedure (named: classification by progressive \ngeneralization), which is neither a supervised nor unsupervised methodology, but incorporates \naspects of both. The classification approach is based on finding dominant spectral clusters \nand conducting progressive merging methodology. Eventually the clusters are labelled with \nthe appropriate land cover classes. The benefit is that the classification is more objective than \na supervised approach, while not controlling the parameters of clustering, which could alter \nthe results. \nThe result of this work is an objective, reproducible classification of Canada's land cover. \nPage 221Section 5.7.2 Land Cover / Biomass Mapping\nCanada Centre for Remote Sensing\n\n5.8 Mapping \n \nMapping constitutes an integral component of the process of managing land resources, and \nmapped information is the common product of analysis of remotely sensed data. Natural \nfeatures and manufactured infrastructures, such as transportation networks, urban areas, and \nadministrative boundaries can be presented spatially with respect to referenced co-ordinate \nsystems, which may then be combined with thematic information. Baseline, thematic, and \ntopographic maps are essential for planning, evaluating, and monitoring, for military or civilian \nreconnaissance, or land use management, particularly if digitally integrated into a geographic \ninformation system as an information base. Integrating elevation information is crucial to many \napplications and is often the key to the potential success of present day mapping programs. \nCanada has been, and continues to be a world leader in mapping technology. Canada's \nimmense land area with a rich resource potential, coupled with a small population base has \nnecessitated the development of thorough and efficient mechanisms of investigating and \nrecording land information. Traditionally, this information was obtained through surveying and \nphotogrammetric techniques, which have been costly and time consuming, particularly for \nperiodic revision of outdated information. Recent advances in computer technology (speed, \ndata handling and storage capability) and a growing demand for digital databases and \ncomputer based mapping production capabilities have encouraged the use of remotely \nsensed information as a data source for cartographic applications. \nThere is a growing demand for the utilization of remote sensing data in map production, since \nthe following benefits may be provided: stereo coverage, frequent revisits, timely delivery, \nwide area coverage, low labour intensity, virtually global coverage, and storage in digital \nformat to facilitate subsequent updating and compatibility with current GIS technology. \nEnd users of base maps and mapping products include resource companies (forestry, mining, \noil), support and service industries (engineering), utility and infrastructure development \nagencies (pipelines, telecommunications, transportation, power), government mapping \nagencies, and the military. This diversification from traditionally military users to commercial \napplications has resulted in a greater demand for a wider range of mapping products, with \nemphasis placed upon the benefits of improved information content and scale, and accuracy \nversus data costs. \nCanadian companies offering mapping services are likely to be looking abroad, as the \ngreatest commercial potential exists within the international community. Developing countries \nPage 222Section 5.8 Mapping\nCanada Centre for Remote Sensing\n\nare currently initiating mapping programs to cover large unsurveyed areas to increase their \ntopographic and planimetric knowledge base. The derived information will be used to support \nterritorial sovereignty issues, assess and monitor resource potential and exploitation, and \nencourage economic opportunity. Radar data will be relied on in tropical areas for remote \nsensing mapping solutions. \nMapping applications of remote sensing include the following: \n1.   planimetry  \n2.   digital elevation models (DEM's)  \n3.   baseline thematic mapping / topographic mapping  \nPage 223Section 5.8 Mapping\nCanada Centre for Remote Sensing\n\n5.8.1 Planimetry \nBackground\n \nPlanimetry consists of the identification and geolocation of basic land cover (e.g. forest, \nmarsh), drainage, and anthropogenic features (e.g. urban infrastructure, transportation \nnetworks) in the x, y plane. Planimetric information is generally required for large-scale \napplications - urban mapping, facilities management, military reconnaissance, and general \nlandscape information. \nWhy remote sensing?\n \nLand surveying techniques accompanied by the use of a GPS can be used to meet high \naccuracy requirements, but limitations include cost effectiveness, and difficulties in attempting \nto map large, or remote areas. Remote sensing provides a means of identifying and \npresenting planimetric data in convenient media and efficient manner. Imagery is available in \nvarying scales to meet the requirements of many different users. Defence applications typify \nthe scope of planimetry applications - extracting transportation route information, building and \nfacilities locations, urban infrastructure, and general land cover. \nData requirements\n \nVery high resolution is usually a requirement for accurate planimetric mapping. Concerns of \nthe mapping community with regard to use of satellite data are spatial accuracy and the level \nof detail of extractable information content. The concern for information content focusses not \nonly on interpretability of features, but on the ability to determine the correct spatial location of \na feature. An example of the latter would be the difficulty associated with defining the centre o\nf \na river or precise location of a powerline or pipeline right-of-way in vector format, when \ninterpreting from a relatively coarse raster base. Spatial resolution is a critical element in this \ncase. \nThe turnaround time of one or two weeks will generally meet the requirements for this type of \nmapping, although defence requirements may be more stringent. \nCanada vs. International\n \nFor general Canadian applications, the ability to provide planimetric information is best \naddressed by current VIR sensors, and for large scale mapping- aerial photography. The \nimportance of adequate resolution and information content outweigh the need for near real \ntime products. Presently, TM and SPOT data provide optimal information for extracting \nplanimetric information for regional applications. Air photos, and particularly orthophotos when \navailable, are preferred for smaller, well defined areas. \n \nTawausar radar image \nPage 224Section 5.8.1 Planimetry\nCanada Centre for Remote Sensing\n\n  \nFor cloud covered areas, \nradar\n is the obvious \nchoice for providing \nplanimetric data\n. The \ndetectability of linear features improves when they \nare oriented perpendicular to the radar look \ndirection. This can be controlled with airborne \nsensors, by planning the flightlines appropriately. \nAnother issue is that a balance between resolution \nand speckle has to be reached. Although single \nlook data provides the finest resolution, speckle \ncan be a hindrance to interpretation, and invites \nmultilook processing. \nPage 225Section 5.8.1 Planimetry\nCanada Centre for Remote Sensing\n\n5.8.2 Digital Elevation Models \nBackground\n \nThe availability of digital elevation models (DEMs) is \ncritical for performing geometric and radiometric \ncorrections for terrain on remotely sensed imagery, and \nallows the generation of contour lines and terrain models, \nthus providing another source of information for analysis. \nPresent mapping programs are rarely implemented with \nonly planimetric considerations. The demand for digital \nelevation models is growing with increasing use of GIS and with increasing evidence of \nimprovement in information extracted using elevation data (for example, in discriminating \nwetlands, flood mapping, and forest management). The incorporation of elevation and terrain \ndata is crucial to many applications, particularly if radar data is being used, to compensate for \nforeshortening and layover effects, and slope induced radiometric effects. Elevation data is \nused in the production of popular topographic maps. \nElevation data, integrated with imagery is also used for generating perspective views, useful \nfor tourism, route planning, to optimize views for developments, to lessen visibility of forest \nclearcuts from major transportation routes, and even golf course planning and development. \nElevation models are integrated into the programming of cruise missiles, to guide them over \nthe terrain. \nResource management, telecommunications planning, and military mapping are some of the \napplications associated with DEMs. \n  \nWhy remote sensing?\n \nThere are a number of ways to generate elevation models. One is to create point data sets by \ncollecting elevation data from altimeter or Global Positioning System (GPS) data, and then \ninterpolating between the points. This is extremely time and effort consuming. Traditional \nsurveying is also very time consuming and limits the timeliness of regional scale mapping. \nGenerating DEMs from remotely sensed data can be cost effective and efficient. A variety of \nsensors and methodologies to generate such models are available and proven for mapping \napplications. Two primary methods if generating elevation data are 1. Stereogrammetry \ntechniques using airphotos (photogrammetry), VIR imagery, or radar data (radargrammetry), \nand 2. Radar interferometry. \nPage 226Section 5.8.2 Digital Elevation Models\nCanada Centre for Remote Sensing\n\n \nStereogrammetry involves the extraction of elevation information from stereo overlapping \nimages, typically airphotos, SPOT imagery, or radar. To give an example, stereo pairs of \nairborne SAR data are used to find point elevations, using the concept of parallax. Contours \n(lines of equal elevation) can be traced along the images by operators constantly viewing the \nimages in stereo. \n \nThe potential of radar interferometric techniques to measure terrain height, and to detect and \nmeasure minute changes in elevation and horizontal base, is becoming quickly recognized. \nInterferometry involves the gathering of precise elevation data using successive passes (or \ndual antenna reception) of spaceborne or airborne SAR. Subsequent images from nearly the \nsame track are acquired and instead of examining the amplitude images, the phase \ninformation of the returned signals is compared. The phase images are coregistered, and the \ndifferences in phase value for each pixel is measured, and displayed as an interferogram. A \ncomputation of phase \"unwrapping\" or phase integration, and geometric rectification are \nperformed to determine altitude values. High accuracies have been achieved in \ndemonstrations using both airborne (in the order of a few centimetres) and spaceborne data \n(in the order of 10m). \nPrimary applications of interferometry include high quality DEM generation, monitoring of \nsurface deformations (measurement of land subsidence due to natural processes, gas \nremoval, or groundwater extraction; volcanic inflation prior to eruption; relative earth \nmovements caused by earthquakes), and hazard assessment and monitoring of natural \nlandscape features and fabricated structures, such as dams. This type of data would be useful \nfor insurance companies who could better measure damage due to natural disasters, and for \nhydrology-specialty companies and researchers interested in routine monitoring of ice jams \nPage 227Section 5.8.2 Digital Elevation Models\nCanada Centre for Remote Sensing\n\nfor bridge safety, and changes in mass balance of glaciers or volcano growth prior to an \neruption. \n \nFrom elevation models, contour lines can be generated for topographic maps, slope and \naspect models can be created for integration into (land cover) thematic classification datasets \nor used as a sole data source, or the model itself can be used to orthorectify remote sensing \nimagery and generate perspective views. \n \nData requirements\n \nThe basic data requirement for both stereogrammetric and interferometric techniques is that \nthe target site has been imaged two times, with the sensor imaging positions separated to \ngive two different viewing angles. \nIn virtually all DEM and topographic map generation applications, cartographic accuracy is the \nimportant limiting factor. Turnaround time is not critical and repeat frequency is dependent on \nwhether the application involves change detection, and what the temporal scope of the study \nis. \n  \n  \n  \n  \nPage 228Section 5.8.2 Digital Elevation Models\nCanada Centre for Remote Sensing\n\nCanada vs. International\n \nAerial photography is the primary data source for \nDEM generation in Canada for national topographic \nmapping. For other applications of DEMs, there are \nadditional satellite sources such as SPOT, with its \npointable sensors and 10m panchromatic spatial \nresolution, producing adequate height information at \nscales smaller than 1:50,000. \nThe height accuracy requirement for 1:50,000 mapping in Canada is between 5 and 20 m. In \ndeveloping countries it is typically 20 m. The original elevation information used in the \nCanadian National Topographic Series Maps was provided from photogrammetric techniques.\nIn foreign markets, airborne radar mapping is most suited for approximately 1:50,000 scale \ntopographic mapping. Spaceborne radar systems will be able to provide data for the \ngeneration of coarser DEMs through radargrammetry, in areas of cloud cover and with less \nstringent accuracy requirements. Stereo data in most modes of operation will be available \nbecause of the flexible incidence angles, allowing most areas to be captured during \nsubsequent passes. Interferometry from airborne and spaceborne systems should meet many \nmapping requirements. \nPage 229Section 5.8.2 Digital Elevation Models\nCanada Centre for Remote Sensing\n\n5.8.3 Topographic & Baseline Thematic Mapping \nBackground\n \nThere is a growing demand for digital databases of topographic and thematic information to \nfacilitate data integration and efficient updating of other spatially oriented data. Topographic \nmaps consist of elevation contours and planimetric detail of varied scale, and serve as \ngeneral base information for civilian and military use. \nBaseline thematic mapping (BTM) is a digital \nintegration of satellite imagery, land use, land \ncover, and topographic data to produce an \"image \nmap\" with contour lines and vector planimetry \ninformation. This new concept of thematic \nmapping was developed to take advantage of \nimprovements in digital processing and integration \nof spatial information, increased compatibility of \nmultisource data sets, the wide use of geographic \ninformation systems to synthesize information and \nexecute analyses customized for the user, and \nincreased ability to present the data in \ncartographic form. \nThe data for baseline thematic maps are compiled from topographic, land cover, and \ninfrastructure databases. Appropriate thematic information is superimposed on a base map, \nproviding specific information for specific end users, such as resource managers. Various \ncombinations of thematic information may be displayed to optimize the map information for \napplication specific purposes, whether for land use allocation, utility site selection and route \nplanning, watershed management, or natural resource management and operations. \nWhy remote sensing?\n \nAs a base map, imagery provides ancillary information to the extracted planimetric or thematic \ndetail. Sensitivity to surface expression makes radar a useful tool for creating base maps and \nproviding reconnaissance abilities for hydrocarbon and mineralogical companies involved in \nexploration activities. This is particularly true in remote northern regions, where vegetation \ncover does not mask the microtopography and generally, information may be sparse. \nMultispectral imagery is excellent for providing ancillary land cover information, such as forest \ncover. Supplementing the optical data with the topographic relief and textural nuance inherent \nin radar imagery can create an extremely useful image composite product for interpretation.  \nData requirements\n \nThe prime data requirement is for high information content and a balance between resolution \nand data handling ability. There is a moderate turnaround requirement for this application; \nprocessed data should be available less than a year after imagery acquisition. \nPage 230Section 5.8.3 Topographic & Baseline Thematic Mapping\nCanada Centre for Remote Sensing\n\nCanada vs. International\n \nVIR imagery is excellent as a base map for planimetry detail on a varied landscape, providing \ninformation on forest, agriculture cover and gross geomorphology of the land. SAR is also \ngood for providing surficial topographic expression.  \nCase study (example) BTM's in BC\n \n(Baseline Thematic Mapping in British Columbia)\n \nBaseline thematic mapping involves the compilation of varied data sources, ranging from \nsatellite imagery to detailed forest stand information to planimetric data from the 1:250,000 \nNational Topographic database. Base map sheets overlain by various combinations of \nthematic data are produced with an aim toward resource management applications. British \nColumbia's Ministry of Environment, Lands, and Parks routinely produces BTMs. The most \nrecent Landsat TM data available is used as a source for classifications of ground cover and \ninterpretation of land use. DEMs are also integrated into the satellite data to provide 3 \ndimensional perspective views. Although B.C. is quite advanced in this application, other \nCanadian provinces have contemplated or are doing similar work, as are private consultants \nin conjunction with forestry companies. \nBaseline thematic mapping incorporates not only interpretations of ground cover data and \nland use, but topographic information such as elevation contours and planimetry to provide an \noptimal tool for resource management. This information may be portrayed in traditional map \nformat, or as an image-map, which is an excellent means of presenting spatial data to \nresource managers and many other users. \nPage 231Section 5.8.3 Topographic & Baseline Thematic Mapping\nCanada Centre for Remote Sensing\n\n5.9 Oceans & Coastal Monitoring \n \nThe oceans not only provide valuable food and biophysical resources, they also serve as \ntransportation routes, are crucially important in weather system formation and CO² storage, \nand are an important link in the earth's hydrological balance. Understanding ocean dynamics \nis important for fish stock assessment, ship routing, predicting global circulation \nconsequences of phenomena such as El Nino, forecasting and monitoring storms so as to \nreduce the impact of disaster on marine navigation, off-shore exploration, and coastal \nsettlements. Studies of ocean dynamics include wind and wave retrieval (direction, speed, \nheight) , mesoscale feature identification, bathymetry, water temperature, and ocean \nproductivity.  \nCoastlines are environmentally sensitive interfaces between the ocean and land and respond \nto changes brought about by economic development and changing land-use patterns. Often \ncoastlines are also biologically diverse inter-tidal zones, and can also be highly urbanized . \nWith over 60% of the world's population living close to the ocean, the coastal zone is a region \nsubject to increasing stress from human activity. Government agencies concerned with the \nimpact of human activities in this region need new data sources with which to monitor such \ndiverse changes as coastal erosion, loss of natural habitat, urbanization, effluents and \noffshore pollution. Many of the dynamics of the open ocean and changes in the coastal region \ncan be mapped and monitored using remote sensing techniques. \nOcean applications of remote sensing include the following: \n\nOcean pattern identification: \ncurrents, regional circulation patterns, shears  \n\nfrontal zones, internal waves, gravity waves, eddies, upwelling zones, shallow water \nbathymetry ,  \n\nStorm forecasting \nwind and wave retrieval  \n\nFish stock and marine mammal assessment \nwater temperature monitoring  \nwater quality  \n\nocean productivity, phytoplankton concentration and drift  \nPage 232Section 5.9 Oceans & Coastal Monitoring\nCanada Centre for Remote Sensing\n\naquaculture inventory and monitoring  \n\nOil spill \nmapping and predicting oilspill extent and drift  \n\nstrategic support for oil spill emergency response decisions  \nidentification of natural oil seepage areas for exploration  \n\nShipping \nnavigation routing  \n\ntraffic density studies  \noperational fisheries surveillance  \n\nnear-shore bathymetry mapping  \n\nIntertidal zone \n\ntidal and storm effects  \ndelineation of the land /water interface  \n\nmapping shoreline features / beach dynamics  \ncoastal vegetation mapping  \n\nhuman activity / impact  \nPage 233Section 5.9 Oceans & Coastal Monitoring\nCanada Centre for Remote Sensing\n\n5.9.1 Ocean Features \nBackground\n \nOcean feature analysis includes determining current strength and direction, amplitude and \ndirection of surface winds, measuring sea surface temperatures, and exploring the dynamic \nrelationship and influences between ocean and atmosphere. Knowledge of currents, wind \nspeed, tides, storm surges and surface wave height can facilitate ship routing. Sea floor \nmodelling supports waste disposal and resource extraction planning activities. \nOcean circulation patterns can be determined by the examination of mesoscale features such \nas eddies, and surface gravity waves. This knowledge is used in global climate modelling, \npollution monitoring, navigation and forecasting for offshore operations. \nWhy remote sensing?\n \nRemote sensing offers a number of different methods for acquiring information on the open \nocean and coastal region. Scatterometers collect wind speed and direction information, \naltimeters measure wave height, and identify wind speed. Synthetic aperture radar (SAR) is \nsensitive to spatially varying surface roughness patterns caused by the interaction of the \nupper ocean with the atmosphere at the marine boundary layer, and scanning radiometers \nand microwave sounders collect sea surface temperature data. Buoy-collected information \ncan be combined with remote sensing data to produce image maps displaying such things as \nhurricane structure with annotated wind direction and strength, and wave height. This \ninformation can be useful for offshore engineering activities, operational fisheries surveillance \nand storm forecast operations. \nData requirements\n \nFor general sea-state information (waves, currents, winds), the data are usually time \nsensitive, meaning that the information is only valuable if it is received while the conditions \nexist. For forecasting and ship routing, real time data handling / turnaround facilities are \nnecessary, requiring two way data links for efficient dissemination between the forecast centre \nand data user. \nCertain wind speed conditions are necessary in order for the SAR to receive signal \ninformation from the ocean surface. At very low wind speeds (2-3m/s) the SAR is not sensitive \nenough to detect the ocean 'clutter' and at very high winds speeds (greater than 14 m/s) the \nocean clutter masks whatever surface features may be present. The principal scattering \nmechanism for ocean surface imaging is Bragg scattering, whereby the short waves on the \nocean surface create spatially varying surface patterns. The backscatter intensity is a function \nof the incidence angle and radar wavelength, as well as the sea state conditions at the time of \nimaging. The surface waves that lead to Bragg scattering are roughly equivalent to the \nwavelength used by RADARSAT. (5.3 cm) These short waves are generally formed in \nresponse to the wind stress at the upper ocean layer. Modulation in the short (surface) waves \nmay be caused by long gravity waves, variable wind speed, and surface currents associated \nwith upper ocean processes such as eddies, fronts and internal waves. These variations \nPage 234Section 5.9.1 Ocean Features\nCanada Centre for Remote Sensing\n\nresult in spatially variable surface roughness patterns which are detectable on SAR imagery. \nCase study (example)\n \nInternal waves form at the interfaces between \nlayers of different water density, which are \nassociated with velocity shears (i.e., where the \nwater above and below the interface is either \nmoving in opposite directions or in the same \ndirection at different speeds). Oscillations can \noccur if the water is displaced vertically resulting \nin internal waves. Internal waves in general occur \non a variety of scales and are widespread \nphenomena in the oceans. The most important \nare those associated with tidal oscillations along \ncontinental margins. The internal waves are large \nenough to be detected by satellite imagery. In this image, the internal waves, are manifested \non the ocean surface as a repeating curvilinear patterns of dark and light banding, a few \nkilometres east of the Strait of Gibraltar, where the Atlantic Ocean and Mediterranean Sea \nmeet. Significant amounts of water move into the Mediterranean from the Atlantic during high \ntide and/or storm surges. \nPage 235Section 5.9.1 Ocean Features\nCanada Centre for Remote Sensing\n\n5.9.2 Ocean Colour & Phytoplankton Concentration \nBackground\n \nOcean colour analysis refers to a method of \nindicating the \"health\" of the ocean, by measuring \noceanic biological activity by optical means . \nPhytoplankton, are significant building blocks in the \nworld's food chain and grow with the assistance of \nsunlight and the pigment chlorophyll. Chlorophyll, \nwhich absorbs red light (resulting in the ocean's \nblue-green colour) is considered a good indicator of \nthe health of the ocean and its level of productivity. \nThe ability to map the spatial and temporal patterns \nof ocean colour over regional and global scales has provided important insights into the \nfundamental properties and processes in the marine biosphere. \nMapping and understanding changes in ocean colour can assist in the management of fish \nstocks and other aquatic life, help define harvest quotas, monitor the water quality and allow \nfor the identification of human and natural water pollution such as oil or algal blooms, which \nare dangerous to fish farms and other shell fish industries. \nIn general, ocean productivity appears highest in coastal areas due to their proximity to \nnutrient upwelling and circulation conditions that favour nutrient accummulation. \nWhy remote sensing?\n \nRemotely sensed data can provide the necessary spatial perspective to collect information \nabout the ocean surface on a regional scale. Optical data can detect such targets as \nsuspended sediments, dissolved organic matter, and discern between algal blooms and \noilslicks. SAR data can provide additional information on current, wave and mesoscale \nfeatures so as to observe trends over time when optical data are not available due to periods \nof cloud cover. Many commercial fishing and aquaculture operators use this information to \npredict catch sizes and locate potential feeding areas. \nRemote sensing provides a near-surface view of the ocean, but is limited in the amount of \ninformation it can derive from the water column. However, many applications of ocean colour \nare in their infancy and with the recent and upcoming missions of advanced sensors, the \ndevelopment and scope of applications will improve substantially. \nData requirements\n \nMultispectral data are required for ocean colour measurements, and wide spatial coverage \nprovides the best synoptic view of distribution and spatial variability of phytoplankton, water \ntemperature and suspended matter concentration. Hyperspectral data, (collected in many and \nnarrow ranges of the visible and infrared wavelengths), allows for greater precision in \ncharacterizing target spectral signatures. Monthly and seasonal imaging provides necessary \nPage 236Section 5.9.2 Ocean Colour & Phytoplankton Concentration\nCanada Centre for Remote Sensing\n\ndata for modelling. For fish harvesting activities and for fish farm operators, information is \nrequired on a daily or weekly basis. \nWe are entering a new era of ocean colour data. The Coastal Zone Colour Scanner (CZCS) \non-board the US Nimbus 7 satellite collected colour data from 1978 until 1986. In 1996 after a \ndecade of limited data availability, the Germans launched the Modular Opto-electronic Sensor \n(MOS) and the Japanese followed with the Ocean Colour Thermal Sensor (OCTS). New \nsensors include SeaWiFs, launched in 1997 (NASA), MERIS (ESA) scheduled for launch in \n1999, MODIS (NASA) in 2000 , GLI (Japan) in 1999, and OCI (Taiwan) in 1998. These \nadvanced sensors will collect data on primary productivity, chlorophyll variablity and sea \nsurface temperature using advanced algorithms. Their spectral channels are designed to \noptimize target reflectance and support quantitative measurements of specific biophysical \nproperties. Most offer regional perspectives with relatively coarse (500-1200m) resolution and \nwide fields of view. \nCase study (example)\n \nEl Nino and the Plankton Disappearance\n \nUnderstanding the dynamics of ocean circulation can play a key role in predicting global \nweather patterns, which can directly impact agriculture and fishing industries around the \nworld. Detecting the arrival of the El Nino Current off the coast of Peru is an example of how \nremote sensing can be used to improve our understanding of, and build prediction models for \nglobal climate patterns. \nEl Nino is a warm water current that appears off the coast of South America approximately \nevery seven years. Nutrients in the ocean are associated with cold water upwelling, so the \narrival of a warm water current such as El Nino, which displaces the cold current further \noffshore, causes changes in the migration of the fish population. In 1988, El Nino caused a \nloss in anchovy stocks near Peru, then moved north, altering the regional climatic patterns \nand creating an unstable weather system. The resulting storms forced the jet stream further \nnorth, which in turn blocked the southward flow of continental precipitation fromCanada over \nthe central United States. Central and eastern American States suffered drought, reducing \ncrop production, increasing crop prices, and raising commodity prices on the international \nmarkets. \nPage 237Section 5.9.2 Ocean Colour & Phytoplankton Concentration\nCanada Centre for Remote Sensing\n\n5.9.3 Oil Spill Detection \nBackground\n \nOil spills can destroy marine life as well as damage habitat for land animals and humans. The \nmajority of marine oilspills result from ships emptying their billage tanks before or after \nentering port. Large area oilspills result from tanker ruptures or collisions with reefs, rocky \nshoals, or other ships. These spills are usually spectacular in the extent of their environmental \ndamage and generate wide spread media coverage. Routine surveillance of shipping routes \nand coastal areas is necessary to enforce maritime pollution laws and identify offenders. \nFollowing a spill, the shipping operator or oil company involved is responsible for setting up \nemergency evaluation and response teams, and employing remediating measures to \nminimize the extent of a spill. If they do not have the resources, the government regulatory \nagencies responsible for disaster mitigation become involved and oversee the activity. In all \nspills, the government agencies play a key role in ensuring the environmental protection laws \nare being met. To limit the areas affected by the spill and facilitate containment and cleanup \nefforts, a number of factors have to be identified. \n1.   Spill location  \n2.   Size and extent of the spill  \n3.   Direction and magnitude of oil movement  \n4.   Wind, current and wave information for predicting future oil movement  \nWhy remote sensing?\n \nRemote sensing offers the advantage of being able to observe events in remote and often \ninaccessible areas. For example, oil spills from ruptured pipelines, may go unchecked for a \nperiod of time because of uncertainty of the exact location of the spill, and limited knowledge \nof the extent of the spill. Remote sensing can be used to both detect and monitor spills. \nFor ocean spills, remote sensing data can provide information on the rate and direction of oil \nmovement through multi-temporal imaging, and input to drift prediction modelling and may \nfacilitate in targeting clean-up and control efforts. Remote sensing devices used include the \nuse of infrared video and photography from airborne platforms, thermal infrared imaging, \nairborne laser fluourosensors, airborne and space-borne optical sensors, as well as airborne \nand spaceborne SAR. SAR sensors have an advantage over optical sensors in that they can \nprovide data under poor weather conditions and during darkness. Users of remotely sensed \ndata for oil spill applications include the Coast Guard, national environmental protection \nagencies and departments, oil companies, shipping industry, insurance industry, fishing \nindustry, national departments of fisheries and oceans, and departments of defence. \nData requirements\n \nThe key operational data requirements are fast turnaround time and frequent imaging of the \nsite to monitor the dynamics of the spill. For spill identification, high resolution sensors are \ngenerally required, although wide area coverage is very important for initial monitoring and \ndetection. Airborne sensors have the advantage of frequent site specific coverage on \nPage 238Section 5.9.3 Oil Spill Detection\nCanada Centre for Remote Sensing\n\ndemand, however, they can be costly. Spills often occur in inclement weather, which can \nhinder airborne surveillance. \nLaser fluorosensors are the best sensors for oil spill detection, and have the capability of \nidentifying oil on shores, ice and snow, and determining what type of oil has been spilled. \nHowever, they require relatively cloud free conditions to detect the oilspill. SAR sensors can \nimage oilspills through the localized suppression of Bragg scale waves. Oilspills are visible on \na radar image as circular or curvilinear features with a darker tone than the surrounding \nocean. The detection of an oilspill is strongly dependent upon the wind speed. At wind speeds \ngreater than 10 m/s, the slick will be broken up and dispersed, making it difficult to detect. \nAnother factor that can play a role in the successful detection of an oilspill is the difficulty in \ndistinguishing between a natural surfactant and an oilspill. Multi-temporal data and ancillary \ninformation can help to discriminate between these two phenomena. \nCase study (example)\n \nA supertanker, the Sea Empress, was grounded near the town of Milford Haven, Wales on \nFebruary 15, 1996. After hitting rocks, the outer hull was breached and approximately 70,000 \ntonnes of light grade crude oil was dispersed southward under storm conditions. \nIn this RADARSAT image taken a week after \nthe spill, the extent of the oil is visible. The \ndark areas off the coast represent the areas \nwhere oil is present and areas of lighter tone \ndirectly south are areas where dispersant \nwas sprayed on the oil to encourage \nemulsification. Oil, which floats on the top of \nwater, suppresses the ocean's capillary \nwaves, creating a surface smoother than the \nsurrounding water. This smoother surface appears dark in the radar image. As the oil starts to \nemulsify and clean-up efforts begin to take effect, the capillary waves are not as effectively \ndamped and the oil appears lighter. Size, location and dispersal of the oil spill can be \ndetermined using this type of imagery. \nPage 239Section 5.9.3 Oil Spill Detection\nCanada Centre for Remote Sensing\n\n5. Endnotes\n \n \n5.10 Endnotes \n \nYou have just completed \nChapter 5 - Applications\n. As a follow-on, you may want to browse \nthe \nCCRS Web site\n where you will find articles dealing with applications of remote sensing in \nthe fields of agriculture, geology, environmental monitoring, hydrology, ice, oceans, forestry. \nAs a starting point, try our 'Images of Canada'\n1\n, the RADARSAT 'Applications In Action'\n2\n, and \nthe articles in our Technology and R&D Section\n3\n.\n \nAdditionally, you may want to browse the terminology in our glossary\n4\n, or review some of the \ntechnical papers\n5\n written by CCRS staff.\n \n1\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/tour/tour_e.html\n \n2\nhttp://www.ccrs.nrcan.gc.ca/ccrs/data/satsens/radarsat/images/imgact_e.html\n \n3\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/rd_e.html\n \n4\nhttp://www.ccrs.nrcan.gc.ca/ccrs/learn/terms/glossary/glossary_e.html\n \n5\nhttp://www.ccrs.nrcan.gc.ca/ccrs/rd/sci_pub/biblio_e.html\n \n \nPage 240Section 5.10 Endnotes\nCanada Centre for Remote Sensing\n\n5. Did You Know?\n \n \n5.2 Did You Know? \n \nFields in Quebec \nDid you know that remote sensing of agricultural areas could give us clues about our \nheritage? In Québec, farmer's field shapes are very different than in Saskatchewan. In \nQuébec, long thin strips of land extend from riverbanks, following French settlers' tradition. \nThese types of fields are also visible in Nova Scotia, where the Acadians farmed, in New \nBrunswick, and in parts of Ontario. In the prairies, the fields are square and strictly follow the \ntownship and range plan.  \n \nFields in Saskatchewan \nPage 241Section 5 Did You Know?\nCanada Centre for Remote Sensing\n\n5.3 Did You Know? \n \nThe forest around Mt. St. Helens after the eruption \nNatural disasters can also wipe out huge areas of forest. Burns can destroy several thousand \nof hectares, landslides can displace trees down a slope, and excessive flooding can damage \ntrees. Volcanoes however, have the greatest potential for destroying forests in the shortest \namount of time. In 1980, Mt. St. Helens in northwestern United States violently erupted. The \nvolcanic blast, reachin\ng 320 km/hour, levelled over 600km\n2\nof forest.\n \nPage 242Section 5 Did You Know?\n5.3.2 Did You Know? \n \nForest interpretation from SAR data \nInterpreting forest cover type with radar data is very similar to interpreting multispectral \nimages. The same interpretation elements are used (tone, texture, shape, pattern, size, \nassociation), but texture plays a dominant role in the discrimination of different forest types. \nViewing the images in stereo helps to differentiate relative tree heights, as well as define \nrivers that have specific vegetation along their banks. \nCanada Centre for Remote Sensing\n\n5.5 Did You Know? \n \nCatastrophic flooding can happen almost anywhere. In Iceland, huge floods that carry \nboulders the size of houses occur relatively frequently. These floods are called jökulhlaups, \nroughly meaning \"glacial flood\". Iceland is situated upon the mid-Atlantic rift, an area of \nfrequent volcanic activity. The island itself is a product of this activity, and continues to grow in \nsize with each volcanic event. Covering much of the island, and some of the volcanic craters, \nis an 8300 km\n2\n ice cap. During sub-glacial eruptions, glacial ice is melted, and temporarily \ndammed by either the crater or the ice itself. Eventually the pressure of the water is released \nin a catastrophic flood. A flood in 1996 discharged a 3km3 volume of water, lasting 2 ½ days. \nThe glaciers and landscape are abruptly and extensively modified by this strong force, which \nerodes channels, moves and deposits huge blocks of ice and rock, and deposits kilometre \nscale alluvial fans. \nScientists can use radar imagery to create topographic models of the glaciers and extensive \noutwash plains to use as baseline maps for multitemporal change detection and mapping \nstudies. Radar is preferred because persistently cloudy conditions limit the use of optical data. \nWith new monitoring methods, including the analysis of glacial dynamics related to volcanic \nactivity, scientists are better able to predict the timing of these extreme jökulhlaups.  \nPage 243Section 5 Did You Know?\nCanada Centre for Remote Sensing\n\n5.5.1 Did You Know? \n \nIt is worth your while to pay attention to the polarization characteristics of the radar imagery \nthat you are collecting. If your target is to map flooded versus dry land, then HH (horizontal \ntransmit, horizontal receive) is a much better choice than (say) VV (vertical transmit, vertical \nreceive) polarization. The HH imagery will produce a noticeably stronger contrast between \nthese two types of surfaces, allowing greater accuracy in the mapped result. \nPage 244Section 5 Did You Know?\nCanada Centre for Remote Sensing\n5.5.2 Did You Know? \n \nAnother part of the electromagnetic spectrum that has been used for soil moisture \nmeasurement is the gamma ray wavelength range. Recording the natural emission of gamma \nrays from the earth, aircraft carrying gamma ray spectrometers are used to detect the \nattenuation or alteration by soil moisture, of the intensity of the emanation. The gamma ray \nwavelength is extremely short - about 10-12 metres in length (!) and the intensity of this \nnatural radiation at the earth's surface is very weak. As a result satellite altitudes are not \npractical for this form of remote sensing. Even the aircraft used for this purpose must fly as \nclose to the ground as possible. \n\n5.6 Did You Know? \n \n\"...GPS = Good Protection Sidekick...\"\n \nAccidents like the sinking of the Titanic are virtually eliminated now, with iceberg \nreconnaissance (provided by the International Ice Patrol) and GPS navigation onboard ships. \nAnd even if a ship did collide with an iceberg, search and rescue operations using remote \nsensing and GPS navigation could save many lives in such an incident. \nPage 245Section 5 Did You Know?\nCanada Centre for Remote Sensing\n\n5.6.1 Did You Know? \n \n\"...I like my eggs on ice...\"\n \nCreating an Ice Chart\n \nThe Canadian Ice Service of Environment Canada \n(CISEC) creates charts for ice type that are \ndistributed to their clients on a near-real time basis. \nThese charts are essentially ice maps with Egg \nCodes superimposed, which explain the \ndevelopment stage (thickness), size, and \nconcentration of ice at both regional and site specific \nscales. The codes used to represent the ice \ninformation are displayed in an oval symbol, \nresembling an egg, hence the term Egg Code . Egg \ncodes are used not only for sea ice, but also lake \nice. Also they conform to the WMO (World \nMeteorological Organization) standards. \nOnce you understand the meaning of the various \ncodes, the interpretation of the ice charts is relatively \neasy. \nFor more detailed information about the coding procedure and terminology, go to the \n Canadian Ice Service homepage.\n1\n \n  \n  \nPage 246Section 5 Did You Know?\nCanada Centre for Remote Sensing\n\n  \nCase study (example)\n \nRADARSAT Expedites Expedition to the Magnetic North Pole! \n \nIn March of 1996, teams of Arctic adventurers set \nout on an expedition to reach the magnetic North \nPole, located on the west coast of Ellef Ringnes \nIsland, in Canada's high Arctic. Travelling across sea \nice by ski, the teams required a route on smooth first \nyear ice in order to haul their gear and conserve \nenergy. Ice blocks, rubble and irregular relief made \ndeformed and multi-year ice virtually impassable. \nOne team relied on remote sensing - image maps \ncreated from RADARSAT data - to plan their route.  \nThe ScanSAR image covered the entire extent of the \nroute, from Resolute Bay on Cornwallis Island to the pole (78°6'N, 104°3'W). The resolution of \n100m provided information about the ice cover and type, and mapped coastlines were added \nfollowing geometric processing, to provide a geographic reference. The team was also \nequipped with GPS and communication technologies.  \nOn the image map, passable ice appears uniformly dark, due to the specular reflection of \nincident radiation from the radar on the smooth surface. Rubbly, rough ice that often \ncontained enough relief to make skiing impossible appears bright, due to the reflection of the \nradar energy back to the sensor.  \nThe team using RADARSAT image maps was the only one to complete their journey to the \nmagnetic North Pole. The other teams were hindered by rough ice and could not efficiently \nplan their route without the synoptic view provided by remote sensing. RADARSAT, with its \nsensitivity to ice type, far northern coverage, and reliable imaging was the most suitable \nsensor for this type of application. Its success bodes well for future exploration endeavors!  \nReference: Lasserre, M., 1996. RADARSAT Image Maps Make Arctic Expedition a Success, \nRemote Sensing in Canada, Vol. 24, No. 1, June, 1996. Natural Resources Canada.  \nExpedition Web Site: http://www.jeaneudes.qc.ca/\n2\n \n1\nhttp://www.msc-smc.ec.gc.ca\n \n2\nhttp://www.jeaneudes.qc.ca/\n \nPage 247Section 5.Did You Know?\nCanada Centre for Remote Sensing\n\n5.7 Did You Know? \n\"...let me make this perfectly clear...\" \n  \nCalgary (Landsat-TM) \nThis is a TM scene of Calgary, Canada, where the 1988 Winter Olympics were held. Calgary \nappears quite blue; the agricultural fields to the east are red, while grazing land to the west is \ngreen. Abutting the southwest corner of the city, is a long rectangular section of land \nstretching towards the west that is darker and more monotone than the other areas around it. \nThis is the area of the Sarcee Reserve (T'suu T'ina) which has been held by native people, \nand protected from urbanization and residential construction. Of all the land on the image, this \nland is the closest to the original state of the Calgary region before agriculture and settlements \nreworked the landscape. It looks like an oasis amidst suburbia and farmland. \nPage 248Section 5 Did You Know?\nCanada Centre for Remote Sensing\n5.8.2 Did You Know? \n \nWhen you look at a stereo pair of images you perceive a virtual 3D model of the terrain or \nobject that was imaged. Through this 3D virtual terrain model (VTM?), it is possible to extract \ncartographic information without using a DEM!  \n\n5.8.3 Did You Know? \n \nA 'close' relative of 3D terrain mapping is 'close range photogrammetry'. Using very similar \ntechniques but at very close range, this method is used for 'mapping' an object like a building, \nsculpture or a human face in three dimensions in order to have a precise record of its shape.  \nPage 249Section 5 Did You Know?\nCanada Centre for Remote Sensing\n5.9.3 Did You Know? \nA typical laser fluorosensor operates by emitting \nradiation at a particular wavelength that will be \neasily absorbed by the intended target, for \ninstance: oil. The energy thus absorbed by the \ntarget is given off by emitting another wavelength \nof radiation, which is then detected by a sensor \n(spectrometer) linked to the laser. With aromatic \nhydrocarbons, this form of fluorescence allows a \n'fingerprinting' of the oil, measuring both the \nspectra of the radiation given off, as well as the \ndecay rate of the fluorescence. Thus oils can be \ndifferentiated from other fluorescing targets and \neven identified into basic oil types (light, heavy, \netc.).  \n\n5. Whiz Quiz and Answers\n \n \n5.2 Whiz Quiz \nCrop Circles Seen from Space!\n \n \nEvery spring seems to bring a resurgence of the mysterious crop circles seen in farmers' \nfields around the world, often attributed to the work of aliens. Finally, these crop circles have \nbeen observed by a remote sensing device! Landsat TM captured this view while over \nsouthern Alberta. Look at the green circles on the image - how could they have been caused, \nother than by alien activity? \n \nPage 250Section 5 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n5.2 Whiz Quiz Answer \nThe \"crop circles\" are in fact, healthy crops irrigated using a pivot irrigation system - not the \nresult of alien tricks. In the dry southern prairies, farmers rely on pivot irrigation systems to \nkeep the crops watered and healthy. You can see that in the corners of the fields where the \nwater fails to reach, the vegetation is missing or has suffered. The brownish grey areas in this \nimage are primarily rangeland, while the crops appear green. Crops can be successfully \ngrown if a regular irrigation routine is followed, but this puts a heavy demand on water \nresources in a typically dry area. \n\n5.3 Whiz Quiz \n \nWhy are lines being cut out of this forested area in northern Alberta? \nPage 251Section 5 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n5.3 Whiz Quiz Answer \nIn northern Alberta, forests are being cut for pulp and paper mills, but they are also being cut \nfor another reason. Exploration and infrastructure for gas wells requires that forests be cut for \nseismic lines, pipeline routing, access to sites, and pumping stations. \n\n5.7 Whiz Quiz \n \nMore alien circles?\n \nThese are even stranger circles than the ones we first encountered. The outer circles are tens \nof kilometers across. What could have created this shape, and other than being a landing \ntarget for UFOs, what possible land use could it serve?  \nPage 252Section 5 Whiz Quiz and Answers\nCanada Centre for Remote Sensing\n5.7 Answer \nYou had a good guess if you thought these circles were created by an ancient civilization, like \nthe Aztecs, or it represents a giant teepee ring. But it's not correct. Try again. \nThe circles are part of a military base in southern Alberta. The land is used for practice \nmaneuvers and is \"protected\" from the ranging and farming on nearby dry grassland. The \ncircles identify radial distances from 'ground zero', where various real and simulated \nexplosions were conducted by the military.  \n\n5.9.1 Whiz Quiz \nWhat on earth is this 'feature' and how is it that RADARSAT can 'see' it? \n \n \nPage 253Section 5 Whiz Quiz amd Answers\nCanada Centre for Remote Sensing\n5.9.1 Answer \nImaged over the Labrador Sea, this RADARSAT image shows a number of 'imprints' made on \nthe ocean surface by unusual atmospheric conditions. Though the radar beams themselves \nare not affected by the atmosphere, they have recorded the ocean topographic effects from \natmospheric phenomena such as a large low pressure cell \n(A)\n, atmospheric gravity waves \n(B)\nand a region of multiple rising/falling air currents \n(C)\n. In each case, where the falling air mass \ndampens ocean waves, the radar backscatter is lessened, while the rising air mass induces \nsurface wind, which in turn increases ocean waves and therefore, radar backscatter. Higher \nbackscatter is shown in the imagery as brighter areas. \n\n \nCredits\n \n \nAcknowledgements \nWe would like to recognize the contributions made by several organizations and \nindividuals to this tutorial:  \nThe bulk of the tutorial was prepared by Intermap Technologies Ltd. of Calgary and Ottawa, \nunder contract to CCRS and funded through the User Education and Training Initiative (UETI). \nRADARSAT International Inc. and the Canadian Space Agency provided permission to use \nmuch of the satellite imagery herein.  \nSeveral CCRS scientists assisted in reviewing the contents of the tutorial.  \nThe CCRS Multimedia Applications Team produced the various versions, contributing the \ncoding, design, editing, graphics and quality control of the tutorial.  \n  \nReferences \nThe following publications were used in the preparation of this tutorial:  \n\nCampbell, J.B. (1987) \nIntroduction to Remote Sensing.\n The Guilford Press, New \nYork.  \n\nLillesand, T.M. and Kiefer, R.W. (1994) \nRemote Sensing and Image Interpretation\n. \nJohn Wiley and Sons Inc., New York.  \n\nJensen, John R. (1986) \nIntroductory Digital Image Processing.\n Prentice-Hall, New \nJersey.  \n\nRuss, John C. (1995) \nThe Image Processing Handbook.\n 2nd edition. CRC Press, \nBaca Raton.  \n\nDougherty, Edward R. and Charles R. Giardina (1987) \nMatrix Structured Image \nPage 254Fundamentals of Remote Sensing - Credits\nCanada Centre for Remote Sensing\n\nProcessing\n. Prentice-Hall, New Jersey.  \n\nComputer Eye: Handbook of Image Processing.\n Spatial Data Systems Inc., \nCalifornia.  \n\nJain, Anil K. (1989) \nFundamentals of Digital Image Processing.\n Prentice-Hall, New \nJersey.  \n\nWahl, Freidrich M. (1987) \nDigital Image Signal Processing.\n Artech House, Boston.  \n\nYu, Francis T.S. and Suganda Jutamulia (1992) \nOptical Signal Processing, \nComputing, and Neural Networks.\n John Wiley & Sons, New York.  \nCanada Centre for Remote Sensing/Natural Resources Canada (1997). \nGlobeSAR2 \nRadar Image Processing and Information Extraction Workbook Version 1.2.\n \nOttawa, Ontario, Canada.  \n\nBarton, D. & S. Leonov (eds.) (1997) \nRadar technology encyclopedia\n, 511 p., Artec \nHouse, Norwood, MA, USA, ISBN 0-89006-893-3  \n\nOliver, C. & S. Quegan (1998)\n Understanding synthetic aperture radar images\n, 479 \np., Artech House, Norwood, MA, USA, ISBN 089006850X.  \n\nWerle D. (1988 and 1992) \nRadar Remote Sensing - A Training Manual\n, 193p, 75 \n35mm slides, Dendron Resource Surveys Ltd, Ottawa, Ontario, Canada, ISBN 0-\n9693733-0-9  \nPage 255Fundamentals of Remote Sensing - Credits\nCanada Centre for Remote Sensing\n\n \nPermission for Use\n \n \nThis tutorial may be copied in any form and used for \nnon-commercial purposes\n provided \nthat: the content of any copy is \nnot altered\n and, it is clearly indicated that the Canada Centre \nfor Remote Sensing is the originator of this material.  \nPage 256Fundamentals of Remote Sensing - Permission for Use\nCanada Centre for Remote Sensing\n\n \nDownload Formats\n \n \nPage 257Fundamentals of Remote Sensing - Download\nCanada Centre for Remote Sensing\nIs this tutorial available in other formats? Can I use multiple copies off-\nline? \nIf you want to use a hard copy version of this tutorial, then download the PDF version and \nprint it in colour. It can be printed on either 8½\" x 11\" or A4 paper \n\n \nNotes for Teachers and Students\n \n \nPage 258Fundamentals of Remote Sensing - Teachers notes\nCanada Centre for Remote Sensing\nWhat is the target audience for this tutorial? \nThis tutorial on remote sensing technology and applications is designed primarily for \nlate high school or early university students\n. Some previous exposure to \nscience, mathematics and environmental studies is a definite advantage. \nWhat are the features of the tutorial? How does it relate to the rest of \nthe CCRS Web site? \nThe tutorial is structured as a course, with each section building on the concepts introduced in \nthe previous sections and chapters. The numerous images and graphics, as well as \ninteresting facts, help explain and illustrate difficult concepts. Each chapter also includes \nseveral questions and quizzes to test the reader's understanding of the subject matter. These \nquizzes may serve as excellent reviews of each chapter. Informative and sometimes \nhumorous facts in the \"Did You Know?\" pages are designed to complement the associated \nsection with anecdotes and examples of how remote sensing is used throughout the world.  \nCovering the material in the tutorial prepares the reader for visiting and appreciating the rest \nof the CCRS Web site, wherein technical and research articles on most remote sensing topics \ncan be found. An extensive glossary of remote sensing terminology and other educational \nmodules are also available and may be of interest to the student or teacher.  \nIs this tutorial available in other formats? Can I use multiple copies off-\nline? \nWe now have a copy of the \"Fundamentals of Remote Sensing Tutorial\" in HTML format that \nmay be downloaded via FTP. It has been compressed and formatted into a zip version and is \nabout 5.2MB in size. It can be downloaded and then copied onto several machines for \nclassroom (non-commercial) usage without an Internet connection. Please read the included \n\"readme.txt\" file to learn about the constraints and limitations of using such a copy. \nIf you want to use a hard copy version of this tutorial, then download the PDF version and \nprint it in colour. It can be printed on either 8½\" x 11\" or A4 paper \n\n## Document Information\n- **Source**: PDF Document (258 pages)\n- **Category**: lab-material\n- **Difficulty**: advanced\n- **Relevant Labs**: general\n- **Topics**: classification, clustering, coordinate system, crs, gee, gis, mapping, projection, raster, remote sensing, satellite, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain http://pcmas1.ccrs.nrcan.gc.ca/fundam/chapter1/chapter1_1_e.htm\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- clustering\n- coordinate system\n- crs\n- gee\n- gis\n- mapping\n- projection\n- raster\n- remote sensing\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "advanced",
      "lab": "general",
      "topics": [
        "classification",
        "clustering",
        "coordinate system",
        "crs",
        "gee",
        "gis",
        "mapping",
        "projection",
        "raster",
        "remote sensing",
        "satellite",
        "vector"
      ],
      "source": "concepts\\fundamentals_rs.md",
      "filename": "fundamentals_rs.md"
    }
  },
  {
    "id": "concepts-gee_comprehensive_intro",
    "title": "gee_comprehensive_intro",
    "content": "# Google Earth Engine: Complete Introduction\n\n# Google Earth Engine: Planetary-Scale Geospatial Analysis\n\n## What is Google Earth Engine?\n\n**Google Earth Engine (GEE)** is a cloud-based platform that combines:\n- **Massive data catalog**: Petabytes of satellite imagery and geospatial datasets\n- **Google's computing power**: Parallel processing across Google's infrastructure\n- **APIs for analysis**: JavaScript and Python interfaces for analysis\n\n### The Revolution: Bring Analysis to Data\n**Traditional approach**: Download terabytes of satellite data locally\n**GEE approach**: Send your code to where the data lives\n**Result**: Global analyses that took months now run in minutes\n\n## Core Earth Engine Concepts\n\n### 1. Everything is Server-Side\n```javascript\n// This doesn't download data to your computer\nvar image = ee.Image('LANDSAT/LC08/C01/T1_SR/LC08_044034_20140318');\nvar mean = image.select('B4').mean();\nprint(mean); // Computation happens on Google's servers\n```\n\n### 2. Container Objects\nAll data in Earth Engine is wrapped in special container objects:\n- **ee.Image**: Single satellite image or raster dataset\n- **ee.ImageCollection**: Time series of images\n- **ee.Feature**: Vector feature with geometry and properties\n- **ee.FeatureCollection**: Collection of vector features\n- **ee.Geometry**: Geographic shapes (points, lines, polygons)\n\n### 3. Lazy Evaluation\nCode describes computations but doesn't execute until needed:\n```javascript\nvar collection = ee.ImageCollection('MODIS/006/MOD11A1'); // Just a description\nvar filtered = collection.filterDate('2020-01-01', '2020-12-31'); // Still just a description\nMap.addLayer(filtered.mean()); // NOW the computation happens\n```\n\n## Earth Engine Data Catalog\n\n### Satellite Imagery:\n- **Landsat**: 1970s-present, 30m resolution, free\n- **Sentinel**: 2015-present, 10m resolution, free\n- **MODIS**: 2000-present, 250m-1km resolution, daily\n- **High-resolution**: Various commercial satellites\n\n### Climate and Weather:\n- **Temperature**: Land surface, air temperature\n- **Precipitation**: Gridded rainfall datasets\n- **Weather**: Wind, humidity, pressure\n\n### Environmental Datasets:\n- **Elevation**: SRTM, ASTER global DEMs\n- **Land cover**: Global and regional classifications\n- **Vegetation indices**: NDVI, EVI, LAI\n- **Population**: Gridded population datasets\n\n### Applications in Health Research:\n- **Vector habitats**: Identify mosquito breeding areas\n- **Air quality**: Monitor pollution from space\n- **Urban heat islands**: Track temperature differences\n- **Water resources**: Monitor drought, floods\n- **Agricultural productivity**: Food security assessment\n\n## Getting Started with Earth Engine\n\n### Prerequisites:\n1. **Google account**: Sign up at earthengine.google.com\n2. **Basic programming**: JavaScript or Python knowledge helpful\n3. **GIS concepts**: Understanding of raster data and projections\n\n### First Steps:\n1. **Explore the Code Editor**: https://code.earthengine.google.com\n2. **Browse data catalog**: https://developers.google.com/earth-engine/datasets\n3. **Complete tutorials**: Start with \"Introduction to Earth Engine\"\n4. **Join the community**: Google Earth Engine Developers group\n\n### Basic Workflow:\n1. **Import data**: Load satellite imagery or datasets\n2. **Filter data**: By date, location, cloud cover\n3. **Process data**: Calculate indices, classify, analyze\n4. **Visualize results**: Display on interactive map\n5. **Export results**: Download or save to Google Drive/Cloud\n\n## Python vs JavaScript APIs\n\n### JavaScript (Code Editor):\n- **Interactive development**: Immediate visual feedback\n- **Prototyping**: Quick testing of ideas\n- **Sharing**: Easy to share scripts\n- **Learning**: Great for beginners\n\n### Python API:\n- **Scientific computing**: Integration with pandas, matplotlib\n- **Jupyter notebooks**: Documentation and analysis together\n- **Machine learning**: scikit-learn, TensorFlow integration\n- **Automation**: Batch processing, operational workflows\n\n## Key Information\n- **Category**: gee\n- **Difficulty**: intermediate\n- **Source**: Google Earth Engine Community Tutorials + Documentation\n\n## Keywords\n- google earth engine\n- cloud computing\n- satellite imagery\n- remote sensing\n- javascript\n- python\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "concepts\\gee_comprehensive_intro.md",
      "filename": "gee_comprehensive_intro.md"
    }
  },
  {
    "id": "concepts-gee_tut1",
    "title": "Introductory course to Google Earth Engine",
    "content": "\n# Introductory course to Google Earth Engine\n\n\n\nIntroductory course to\nGoogle Earth \nEngine\n\n\n\nIntroductory course to\nGoogle Earth \nEngine\nby\nGianluca Franceschini and Mehwish Ali\nFood and Agriculture Organization of the United Nations\nRome, 2022\n\nCover photograph: ©FAO/Shahid Ahmed\n\n1. Remote sensing principles and applications for agriculture\n2. What is Google Earth Engine\n3. The code editor\n4. The script manager\n5. Explore the data catalog\n6. Display an image\n7. Access the metadata of an image\n8. The inspector\\console\\tasks panel\n9. Upload a Shapefile as asset\n10. Clip the image to the area of interest\n11. Apply an algorithm to an image\n12. Save the results to your computer\n13. Display an image from an image collection\n14. Remote sensing data\n15. Image collections\n16. Feature collections\n17. Reducers\n18. Calculate NDVI on an image\n19. Apply a reducer over a feature collection\n20. Apply a mask on an image\n21. Calculate NDVI on a image collection\n22. Cloud removal\n23. Export a video from an image collection\n24. NDVI anomalies\n25. Introduction to Synthetic Aperture Radar images\n26. Characteristics of a SAR system\n27. Surface parameters\n28. Scattering mechanisms\n29. Sentinel-1 main characteristics\n30. Display a color composite SAR Image\n31. Pre-processing Sentinel-1 image collection\n32. Sentinel-1 time series\n33. Land cover classification\nContents\niii\n2\n4\n7\n8\n10\n14\n16\n17\n17\n18\n18\n19\n20\n21\n22\n25\n27\n28\n28\n29\n29\n32\n33\n33\n35\n37\n39\n41\n42\n43\n43\n45\n45\n    Acknowledgements\n    Abbreviations and acronyms \nv\nvi\n\nFigures\n1. Spectral signature of different land cover features\n2. Spectral signature of vegetation\n3. Spectral signature of crops and soil\n4. Interface of Google Earth Engine\n5. Bands of Sentinel-2\n6. Wavelength of the electro-magnetic spectrum\n7. Observation geometry of SAR imager\n8. The radar measurement\n9. Designation of radar bands\n10. Reflectance mechanism of vegetation in different bands\n11. Incident angle\n12. Satellite orbits\n13. Polarization in SAR images\n14. SAR imagery and field validation methods\n15. X-Band and L-Band radar reflections\n16. Scattering mechanisms\n17. Acquisition modes\n18. Product types processing levels\n19. SAR data processing\nTables\n1. NDVI anomalies and their units\n2. Behaviour of main types of surfaces\niv\n2\n2\n3\n7\n21\n35\n35\n36\n37\n37\n38\n38\n39\n39\n40\n41\n42\n42\n44\n34\n41\n\nAcknowledgements\nWe would like to acknowledge the support from FAO Pakistan communications team and \ngeospatial team, as well as the support from the geospatial unit in the Land and Water \nDivision (FAO NSL). The layout, typesetting, and graphic designing was done by Mr. Shahid \nAhmad (FAO Pakistan) while Ms. Areesha Asghar (FAO Pakistan)  improved the editing of the \ndocument.\nv\nAcknowledgements\nWe would like to acknowledge the support from FAO Pakistan communications team and \ngeospatial team, as well as the support from the geospatial unit in the Land and Water \nDivision (FAO NSL). The layout, typesetting, and graphic designing was done by Mr. Shahid \nAhmad (FAO Pakistan) while Ms. Areesha Asghar (FAO Pakistan)  improved the editing of the \ndocument.\n\nAbbreviations and acronyms\nAPI   Application Programming Interface\nDEM   Digital Elevation Model\nESA   European Space Agency\nEW   Extra-Wide swath\nGEE   Google Earth Engine\nGRD   Ground Range Detected\nIDE   Integrated Development Environment\nIW   Interferometric Wide swath\nOCN   Level-2 Ocean\nLTA   Long-term average\nNASA   National Aeronautics and Space Administration\nNIR   Near-Infrared Red\nNDVI   Normalized Difference Vegetation Index\nS1   Sentinel-1\nS2   Sentinel-2\nSTA   Short-term average\nSLC   Single Look Complex\nSM   Stripmap\nSAR   Synthetic Aperture Radar\nVH   Vertical-Horizontal\nVV   Vertical-Vertical\nWV   Wave\nvi\n\nINTRODUCTORY \nCOURSE ON \nGOOGLE EARTH \nENGINE FOR \nLAND COVER \nCLASSIFICATION\nThe Food and Agriculture Organization (FAO) of \nUnited Nations in Pakistan in collaboration with \nthe Geospatial Unit of the Land and Water \nDivision is inviting you to an introductory course \non Google Earth Engine for land cover mapping. \nThe objective is to provide the basic skills to \noperate the platform, select, pre-process and \nanalyse satellite imagery relevant to agriculture \nand food security, in particular for the \nidentification of specific crops in the land and \nmore broadly for land cover mapping, by using \nan automatic classification approach. The book \nis thought for specialists on land use planning, \nagronomists and food security experts. It \nrequires an understanding of the main satellite \nmissions, basic concepts of remote sensing and \nscripting languages.\n1\n\n1. Remote sensing principles and applications for agriculture\n1.1 Principles\nRemote sensing allows to continuously detect information on land that is used in a large \nnumber of agricultural applications. The particular response of a plant to the incoming solar \nradiation allows to identify an agricultural land respect to other land uses and with some \nlimitations a specific crop type. This response defines the spectral signature of the plant, and \ndepends on the amount of surface solar radiation that is absorbed or reflected. \nFigure1. Spectral signature of different land cover features\nAt the wavelength ranges of the light \n(the so-called visible bands), the \nreflectance from vegetation is relatively \nlow as the majority of light is absorbed \nby the leaf pigments. Chlorophyll \nstrongly absorbs energy in the blue \nand red wavelengths and reflects more \ngreen wavelengths. This is why healthy \nvegetation appears green. The Near-\nInfrared Red (NIR) part of the solar \nradiation is not absorbed by the plant \n(it does not have enough energy \ncontent to start photosynthesis but it \nmay harm leaf internal structure). The \nstrong difference between red and NIR \nbands in healthy vegetation is captured \nFigure 2. Spectral signature of vegetation  \nSource: Humboldt State University. 2022. Spectral reflectance curve of vegetation. In: Geospatial science program. \nCalifornia, Humboldt State University.  http://gis.humboldt.edu/gsp/programs.html\n2\nSource: Science Education through Earth Observation for High Schools (SEOS). 2022. Introduction to Remote Sensing. In: SEOS. European Commission.\nhttps://seos-project.eu/remotesensing/remotesensing-c00-p01.html\nIntroductory course to Google Earth Engine \n\nby the Normalized Difference Vegetation Index (NDVI). The other two peaks of absorption are \ndetermined by the water content in the vegetation.\nThe described spectral signature is in general common to healthy vegetation, however \nvariation on the magnitude of the reflectance can be an important discriminator for individual \ncrops.\nFigure 3. Spectral signature of crops and soil \nThe other important aspect that helps us to distinguish different type of crops is related to the \ndifferent phenology of each plant. The number of days from emergence to full maturity and \nharvest vary for each crop and allows to match a temporal sequence of satellite images to the \nspecific crop calendars.\nOther characteristics that are important to discriminate crops are the texture, spatial \narrangements, contrast and in some case, presence of specific management practices (only \nwith very high resolution images).\nFor the sake of completeness, we also have to mention all those elements that may create \nmisclassification when identifying agricultural land and in particular specific crops:\nŸthe complexity of topography that alters the geometry and the reflectance of the image;\nŸmanagement practices, namely inter-cropping or continuous rotation as in the slash and \nburn agriculture;\nŸsmall and interspersed agricultural fields;\nŸheterogeneity of crop varieties and management practices on the same crop;\nŸatmospheric conditions such as clouds, aerosols, dust, smog (mainly for optical images).\nDepending on a specific area, many of these factors can coexist and interact together making \nthe classification process harder and prone to errors.\n3\nSource: Kyllo, K. P. 2003. Department of Space Studies, University of North Dakota.In: Geospatial technology. \nhttps://mapasyst.extension.org/agricultural-remote-sensing-basics/\n\nAnother important aspect that may classification fail is due to an incorrect or not \nrepresentative number and types of samples required to build a classification model (errors in \nlocation, inability to capture the whole ranges of spectral signatures, mistakes in \nclassification). \nNevertheless, advances in remote sensing and computer science, increased availability of \nsatellite images make remote sensing technology apt for many agricultural applications.\n1.2 Remote sensing applications for agriculture\nDetection of  is an important application in agriculture. crop-types and acreage identification\nThis has many direct implications related to food prices, import-export and more generally \nwith national food security policies.\nSimilarly to the quantification of full mature crops in the land, the  early forecast of crop yields\nis an important requirement for food security and investments. Many techniques exists: one \nsimple approach is through the use of empirical relationships with vegetation indices (e.g. \nNDVI) at early stages of crop development.\nQuantification of  relates to emergencies plan, disaster risk crop losses and damages\nmanagement and food security. This is typically done by comparing “normal” averages (often \nlong-term series) to annual indices in order to detect anomalies in affected areas. It may \ninvolves biotic damages (e.g. pests and disease) as well as abiotic disasters (floods, fires, and \ndroughts).\nRemote sensing information contributes to  research by either identifying the irrigated irrigation\nareas or quantifying the amount of water required/supplied. Evapotranspiration can be \nestimated with energy balance models in order to assess the specific crop water \nrequirements and irrigation needs.\n2. What is Google Earth Engine \nGoogle Earth Engine (GEE) is a cloud-based platform for planetary-scale geospatial analysis \nthat brings Google's massive computational capabilities to bear on a variety of high-impact \nsocietal issues including deforestation, drought, disaster, disease, food security, water \nmanagement, climate monitoring and environmental protection.\nData\nComputer\nAPIs\n4\nIntroductory course to Google Earth Engine \n\n2.1 Cloud processing with built-in functions\nGEE is designed for cloud-based, parallelized geospatial data analysis, and it takes care of all \nthe infrastructure and parallelization decisions on the back end for you. Those operations are \ncalled “server-side”.\nUsing GEE, you can call a wide set of functions that have been developed specifically for \ncomputing in Earth Engine and apply them over many images simultaneously using Google \ncomputational infrastructure. No more downloading and analyzing individuals tiles at a time or \nstressing about your local storage.\n2.2 ONLINE PUBLIC DATA ARCHIVE\nIt contains constantly updated time-series of satellite imagery (MODIS, LandSat, Sentinel) and \nclimatic data\n5\n\nUsing the code editor, you write commands that are sent as an object to Google for \nprocessing in parallel in their cloud (server-side). Users can visualize results from Google in \ntheir browser (client-side), including objects like maps, charts or statistical results.\n2.3 Interacting with data\nThe Javascript Application Programming Interface (API) is a set of functions that allows you to \ninteract with the data through a dedicated code editor. \n2.4 How it works\nRequests\nResults\nGeospatial\nDatasets\nAlgorithmic\nPrimitives\nStorage and Compute\n6\nIntroductory course to Google Earth Engine \n\n3. The code editor\nThe code editor at code.earthengine.google.com is a web-based Integrated Development \nEnvironment (IDE) for the Earth Engine JavaScript API. Code editor features are designed to \nmake developing complex geospatial workflows fast and easy. The code editor has the \nfollowing elements:\nFigure 4. Interface of Google Earth Engine\nCode editor panel\nŸThe editor panel is where you write and edit your Javascript code.\nŸNote that the run button executes the code.\nRight panel\nŸConsole tab for printing output.\nŸInspector tab for querying map results.\nŸClick on the map and note that there is a scale in meters associated with the zoom level.\nŸTasks tab for managing long-running tasks.\n \nLeft panel\nŸScripts tab for managing your programming scripts.  These are git repos hosted at \nGoogle.  \nŸDocs tab for accessing documentation of Earth Engine objects and methods, as well as a \nfew specific to the code editor application. This is the definitive API reference and is \npopulated by the server.\nŸAssets tab for managing assets that you upload.  You get 250 GB free.\n \n7\nSource: Google Earth Engine. 2022. In: Earth Engine Code Editor. https://developers.google.com/earth-engine/guides/playground\n\nInteractive map\nŸFor visualizing map layer output.\nŸNote layer controls.\nŸNote the geometry tools.\n \nSearch bar\nŸFor finding datasets and places of interest.\nGet link button\nŸA static snapshot of the code editor at the time the button is clicked.  If you change the \ncode, get a new link.  You can email these around for easy collaboration.\nHelp menu\nŸUser guide - reference documentation.\nŸHelp forum - Google group for discussing Earth Engine.\nŸShortcuts - Keyboard shortcuts for the code editor.\nŸFeature tour - overview of the code editor.\nŸFeedback - for sending feedback on the code editor.\nŸSuggest a dataset - GEE intention is to continue to collect datasets in a public archive and \nmake them more accessible.\nEXERCISE: CLICK ON THE FEATURE TOUR AND TAKE A TOUR OF THE \nCODE EDITOR\n4. The script manager \nThe scripts tab is next to the API docs in the left \npanel of the code editor. The script manager stores \nprivate, shared and example scripts in Git \nrepositories hosted by Google. The repositories are \narranged by access level, with your private scripts \nstored in a repository you own in the owner folder: \nusers/username/default. You (and only you) have \naccess to the repositories in the owner folder unless \nyou share them with someone else. The repositories \nin the writer folder are repositories for which write \naccess has been granted to you by their owner. You \ncan add new scripts to, modify existing scripts in, or \nchange access to (you may not remove their owner) \nthe repositories in the writer folder. The repositories in the reader folder are repositories for \nwhich read access has been granted to you by their owner. The examples folder is a special \nrepository managed by Google which contains code samples. The archive folder contains \nlegacy repositories to which you have access but have not yet been migrated by their owner \nfrom an older version of the script manager. Search through your scripts using the filter bar at \nthe top of the scripts tab. \n8\nIntroductory course to Google Earth Engine \n\nEXERCISE: CREATE A FOLDER\nWe will create a folder to store the scripts of the training:\n1. Click on the NEW button.\n2. Select Folder.\n3. Type: TRAINING-GEE on the dialog that will appear.\n The folder is now created in your default root directory.\nEXERCISE: CREATE THE “Hello World” SCRIPT\nhttps://code.earthengine.google.com/18964ca9f7214c7ebeda2a1ea8ffdabb\nIn the script panel, type the following:\nvar greetings = \"Hello World\"; //String\nvar number = 1; //Number\nprint (greetings);\nvar list = [2.6, 8, -3];\nprint(list[2]);\nvar dictionary = {\na: 'Hello',\nb: 10,\nc: 0.1343,\nd: list\n};\nprint(dictionary.a);\nThen, click on the run button\nThere are few concepts that this script highlights:\nŸeach variable has to be declared with the var operator;\nŸstring characters are within quotes (single or double but keep consistency);\nŸlists are between square brackets and comma-separated;\nŸdictionaries are within braces and with couples of key:values;\nŸeach line ends with a semicolon;\nŸoutputs are written in the console panel;\nŸdouble slash is used to comment.\n9\n\nThen, click on the SAVE button and give a name to the script. You can specify in the name a \nsubfolder of the repository.\nThe Get Link button, allows to generate an URL link of the script that can be shared with \nother users\n5. Explore the data catalog\nTo open and explore the data catalog (i.e. the data uploaded and accessible from GEE), you \nhave to click on the arrow to the right of the \nsearch text box, and select view data catalog.\nThis brings you to the data catalog \nhttps://developers.google.com/earth-\nengine/datasets/ \nwhich contains a description of the available \ndatasets by theme.\n10\nIntroductory course to Google Earth Engine \n\nCollections are both in raster or vector format and may represent a time-series stack of global \nor regional data up to one single layer of information. Main collections (MODIS, Sentinel, and \nLandsat) have their own specific page, alternatively data can be seen by tags (keywords).\n11\n\nEXERCISE: FINDS ALL THE DATASETS RELATED TO “Elevation”\n1. On the data catalog, click on browse by tags.\n2. Select Elevation.\nOnce a dataset has been located, you can click on it to get the dataset page. The dataset \npage contains many interesting information:\nŸ For time-series collections is a crucial information. Data in GEE are Dataset availability:\nuploaded respect to the data of acquisition with a limited lag of time.\nŸThe owner of the dataset.Dataset Provider: \nŸThe code that identify that particular dataset.Earth Engine Snippet: \nŸKeywords to locate the dataset.Tags: \nThen, you have a brief description of the dataset and the number of bands in each image, \nterms of use and citations.\nFinally, you have a simple script which may contains some useful code to display and pre-\nprocess your image.\n12\nIntroductory course to Google Earth Engine \n\nEXERCISE: FIND THE SENTINEL-2 SURFACE REFLECTANCE COLLECTION\nCan you say the difference between an image and an image collection?\nAn alternative, is to Search a dataset directly from the search text box of the code editor.\nOnce a dataset is located, you can click on it to have a description (similar to the data \ncatalog) or import it into a script.\nEXERCISE: IMPORT THE SRTM (ELEVATION) AT 30 METER RESOLUTION \nFROM THE SEARCH TEXT BOX\n1. On the search box, write “SRTM”.\n2. You can explore the description of results to understand the difference between the \ndatasets.\n3. Once located, click on Import (at the right of the name) to Import the data in the script.\nThe results of importing datasets to your script are organized in an imports section at the top \nof your script, hidden until you import something. \nTo copy imports to another script, or convert the imports to Javascript, click the icon next to \nthe imports header and copy the generated code into your script. You can delete the import \nwith the delete icon. \nEXERCISE: CREATE A NEW SCRIPT, CALLED ELEVATION\nCopy the following code:\nvar image = ee.Image(“USGS/SRTMGLI_003”) \n13\n\n6. Display an image\nIn GEE, images are composed of one or more bands and each band has its own name, data \ntype, scale (i.e. resolution), mask and projection. Each image has metadata stored as a set of \nproperties.\nIf you have run the script of elevation, nothing will be displayed in the map window. In reality, \nnothing will happen at all. With the previous code, you created a variable named image where \nyou have placed the Image corresponding to the specified code but you have not explained \nto the editor what you want to do with the image.\nTo display the image in the map panel, you have to add the layer to the map window. Type in \nthe docs panel “addlayer” and click on the addLayer function. You will see a description of \nthe function and the arguments required: the first one is mandatory (the object to map), while \nthe others (in italic) are optional and add specific behavior to the result\n14\nIntroductory course to Google Earth Engine \n\nNow, type in the script the following instruction:\nMap.addLayer(image);\nYou will notice that the image is now displayed in the map panel, but the layer is just called \n“Layer 1” and the display does not look attractive (is a gray scale). You can modify the \nvisualization parameters and add a title to your layer by specifying additional parameters.\nvisualization parameters allow to control how an image is displayed on the map.\nThere are two ways of setting the visualization parameters:\nŸfrom the script;\nŸdynamically from the map window and then imported in the script.\nSeveral parameters can be set. All the settings are defined within a dictionary, that means the \nwhole settings are enclosed by braces {} and each parameter (key) is specified, followed by \ncolon and the value of the parameter. The value can be a single number or a list. When is a \nlist, it needs to be enclosed by brackets [].\nvar vizPar = {bands:[”elevation”],min:0,max:8000};\n15\n\nEXERCISE: CHANGE THE VISUALIZATION PARAMETERS OF A LAYER\n1. Click on the icon next to the layer name. \nThis will open its visualization parameters.\n2. Change the range of the data (e.g. put 0 \nand 5 000).\n3. Change the color to palette and experiment \nwith a range of colors of your choice.\n4. Once done, click on the import button.\n5. Copy the imported code directly into your \nscript.\n6. Modify the script, by adding a second \nparameter (the imported visualization parameters) and a third parameter with the title of the \nlayer. Each parameter must be separated by a comma.\n7. Run the script again\n7. Access the metadata of an image\nImages (and other data formats such as image collections) have metadata that describe the \ntechnical content (for instance bands, resolution, acquisition time) as well as description of \ncontent, source, terms of uses. All this information is defined as property in GEE. Set of \nproperties is different for each image. \nThere are two ways to access the properties of an image:\nŸprinting the image to the console;\nŸfrom the script, using the propertyNames() function.\nEXERCISE: ACCESS THE METADATA OF AN IMAGE\nIn your script type print(image)\nYou will see that in the console panel, information about the image will appear. The property \nsection, will contain all the metadata of that image\nIn your script type:\nvar metadata = image.propertyNames()\nprint(metadata)\nvar property = image.get(property)\n16\nIntroductory course to Google Earth Engine \n\n8. The inspector\\console\\tasks panel\nMetadata of the image can be written with the print statement.\nAdd this line to the code:\nprint(image);\nThe output will be shown in the console panel, where all the textual and graphics (e.g. charts) \nare shown.\nThe inspector panel allows to click on the map panel to have the value of layers (similarly to \nthe identify tool on ArcGIS).\nTasks allow to run specific methods that are or might be time-consuming such as the import \nand export of data.\n9. Upload a Shapefile as asset\nIn many cases, it may be required to upload specific \ninformation to use in the scripts. For instance, we want \nto clip the image only to specific boundaries of interest. \nTo this end, we first need to upload a Shapefile with \nthis boundary. The file will appear on the list of assets.\nEXERCISE: UPLOAD A SHAPEFILE\n1. Click on the asset tab on the top-left panel.\n2. Select Shapefiles (under Table Upload).\n3. On the upload dialog window, click on select to \nchoose the files to be uploaded.\n4. Assign a name to the asset.\n5. Click on upload.\nWhen the uploading is completed, it will appear in the \nlist of assets (you may need to refresh the list). Then, \nclick on Import into the script to use the Shapefile.\nThe uploaded asset is private and only accessible by \nthe user that uploaded the Shapefile. If the script \nneeds to be shared with other colleagues, the asset \nwill not be accessible and the code will not work. To \nmake the asset accessible to other users:\n6. In the asset panel, move next to the asset to share \n(three logos will appear) and click on share.\n17\n\nŸIn the pop-up window, check “Anyone can read”.\n10. Clip the image to the area of interest\nIn GEE, an image is presented uniform around the globe, however is internally stored in single \ntiles. If we want to display a particular region of interest, there are many possible ways. One \nsolution is to clip the image, by using a reference geometry. \nEXERCISE: CLIP AN IMAGE\nAdd the following code:\n  var clippedElevation = image.clip(AOI);\nAnd then:\nŸdisplay the new image on the map panel;\nŸadjust the visualization parameters to a better range.\n11. Apply an algorithm to an image\nYou can use specific algorithms to apply to an image to generate other outputs. These \nfunctions can be mathematical operations (band a + band b), morphological operations (focal \nfunctions), edge detections and many others. In our next example, we will use a slope \nfunction to calculate a slope layer from a Digital Elevation Model (DEM). \nEXERCISE: CALCULATE THE SLOPE\n1. On the top right panel, click on docs.\n2. Type slope (this will produce a number of results).\n3. Apply the slope function to the DEM of the previous exercise.\n18\nIntroductory course to Google Earth Engine \n\nEXERCISE: CALCULATE THE HILLSHADE AND ADD IT TO THE ELEVATION\n \n1. On the top right panel, click on docs.\n2. Type hillshade (this will produce a number of results).\n3. Apply the hillshade function to the DEM of the previous exercise.\n4. Define a visualization parameter with an opacity = 0.2 and overlay it to the elevation image.\n12. Save the results to your computer\nFinal outputs of an analysis such as images, map tiles, tables and video can be exported from \nGEE. The exports can be sent to:\nŸyour Google Drive account;\nŸa Google Cloud Storage;\nŸa new GEE asset.\nEXERCISE: EXPORT AN IMAGE\nAdd the following code:\nExport.image.toDrive({\n  image: clippedElevation, //the image to export\n  description: 'Pakistan_SRTM', //description of the task\n  scale:30, //The resolution\n  folder: 'Pakistan', //The folder in Google Drive\n  fileNamePrefix: 'SRTM30', //The prefix of the raster\n  maxPixels: 1e13 //Max number of pixels to export\n});\nThen, click on run, next to the task created. The export may take several time. At the end the \nimage will be available on your Google Drive.\n19\n\nhttps://code.earthengine.google.com/2649f48fb35e64220e5a5be402839aae\n13. Display an image from an image collection\nAn image collection, contains a set of individual images. We will look at how we can select \nmultiple images within an image collection, but we can also access an individual image within \nan image collection. Type the following code and comment the results. \nEXERCISE: DISPLAY AN IMAGE FROM AN IMAGE COLLECTION\nvar image =\nee.Image(\"COPERNICUS/S2_SR/20200622T055641_20200622T060249_T42RXT\");\nvar vp = {bands:[\"B8\",\"B4\",\"B3\"],min:500, max:3500};\nMap.addLayer(image,vp,\"Sentinel-2\");\nprint(image);\nhttps://code.earthengine.google.com/a5e0fef3956fdc74b9ff9f1d523f9389\nA common task in GEE is to find existing scripts and modify them to be used in your actual \nwork. You will use the image you selected in the previous example to customize an existing \nscript.  \nEXERCISE: CUSTOMIZE AN EXISTING SCRIPT\n1. Find the script Canny Edge detector in the examples.\n2. Find how the Canny Edge detector works. \n3. Update the script to make it work with your image. \nhttps://code.earthengine.google.com/7210f28f984a12930c307a1df2ae7f17\n20\nIntroductory course to Google Earth Engine \n\n14. Remote sensing data\nDuring most of the training, we will focus on data from the Copernicus program of the \nEuropean Space Agency (ESA). Let's first have a look at the program and at some basic \nrelated information related. \nWatch the following video for introduction to Copernicus\nhttps://dlmultimedia.esa.int/download/public/videos/2014/03/018/1403_018_AR_EN.mp4\nSentinel-1 (S1) is an imaging radar mission providing continuous all-weather, day-and-night \nimagery at C-band. The S1 constellation provides high reliability, improved revisit time, \ngeographical coverage and rapid data dissemination to support operational applications in \nthe priority areas of marine monitoring, land monitoring and emergency services. \nS1 key characteristics are:\nŸTwo satellites (S1A, S1B).\nŸMultiple acquisition modes.\nŸBand C.\nŸDual polarization mode.\nŸSpatial resolution up to 10 m.\nŸRevisit around six days (for both satellites).\nSentinel-2 (S2) provides high-resolution optical imaging for land services (e.g. imagery of \nvegetation, soil and water cover, inland waterways and coastal areas).\nS2 key characteristics are:\nŸTwo satellites (S2A, S2B).\nŸMulti-spectral data with 13 bands.\nŸSpatial resolution up to 10 m.\nŸRevisit around five days (for both satellites).\n21\nFigure 5. Bands of Sentinel-2\n \nSource: European Space Agency (ESA). 2022. In: Sentinel Online. https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/resolutions/spatial\n\n15. Image collections\nNow that you are familiar with an image is time to move onto the main data structure you will \ndeal with. As the name suggest, an image collection is just a collection......of images. Each \nimage has a series of attributes that identify and differentiate it within the collection and the \nuser can interact with these attributes to filter or limit the images within the collection.\nWhile is useful to export a single image, in general you will not export an image collection (not \neven a portion of it). Generally the image collections are used within algorithms, some \nfunctions are applied, and the result of the workflow can produce a format (a single image, a \nvideo, a table) that is more suitable to export.\nCan you think to a possible image collections? Remember how satellite works. They collect \ninformation travelling across their orbit. This information, converted in a digital raster format is \nthen processed and transmitted as individual tiles, where each tile has its own date of \nacquisition, location and metadata. The image collection is not a perfect place to store all \nthese images?\nEXERCISE: FIND THE SENTINEL-2 IMAGE COLLECTION AND IMPORT IT IN A \nNEW SCRIPT\n1. Create a new script in the training folder.\n2. Go to the data catalog and click on the Sentinel Tab.\n3. Locate the surface reflectance dataset and click on it.\n4. Copy the following code in the new script.\nvar S2 = ee.ImageCollection(\"COPERNICUS/S2_SR\");\nThe last exercise allowed you to create a variable that contains the whole archive of images \nacquired from the beginning. It is not handy to work on the whole collection, while you may \nbe interest only to a specific period, or location or quality.\nLet's start to filter (limit the number of images according to some criteria) the image collection.\n15.1 Filter by a period\nTypically, you will not need to work on the whole archive, but rather in a selection of only \nimages acquired across a defined interval. Although a generic filter() method exists, the \nmethod filterDate() is more specific for this purpose.\nEXERCISE: SELECT ONLY SENTINEL-2 IMAGES ACQUIRED IN 2020\nType the following code:\nvar S2_2020 = ee.ImageCollection(\"COPERNICUS/S2_SR\")\n.filterDate('2020-01-01', '2020-08-07');\n22\nIntroductory course to Google Earth Engine \n\nOn the previous code, you may have noted that the method filterDate has been assigned to \nthe selected image collection just concatenating the two functions with a dot. This is typical in \nGEE and allows to avoid to create multiple variables. Just be careful that the semicolon must \nbe assigned just at the end of the functions.\n \nUse the concatenation to create variables for each line of code. Below is how would appear \nthe selection of images without concatenation:\nvar S2 = ee.ImageCollection(\"COPERNICUS/S2_SR\");\nvar S2_2020 = S2.filterDate('2020-01-01', '2020-08-07');\n15.2 Filter by a location\nEXERCISE: RE-SELECT ONLY SENTINEL-2 IMAGES COVERING THE AREA \nOF INTEREST\nIn most of the cases, you will also need to refine your selected images only to those that \noverlap specific geometries. This time, we will use a geometry digitized from the screen. Click \non Draw a shape from the top-right tools of the map window:\nDraw a polygon within the area to analyze. Click on the last vertex to close the geometry. \nOnce the geometry is closed, you will see within the Import area that the geometry appeared. \nYou can now copy and paste the new geometry in your script. Then:\n1. Rename the new geometry as “AOI”.\n2. Type the following code to refine the search:\nfilterBounds(AOI) \nNote that filterBounds does not clip the images; it just selects those images that overlap the \ngeometry.\n15.3 Filter by metadata\nEach image contains a number of metadata. We will use some metadata to refine the \nselection of images. To view the metadata of a single image, you have to refer not to the \nImageCollection (which has its own metadata) but rather to a specific image within the \nImageCollection. To do this you can pick the first image within the image collection by using \nthe .first() method. Then, you can print the image to the console.\nThen, we will use the filterMetadata() method with the 'CLOUD_COVERAGE_ASSESSMENT' \nproperty. To understand how the filterMetadata works, type the function in the top-right doc \ntab.\n23\n\nEXERCISE: RE-SELECT ONLY SENTINEL-2 IMAGES WITH CLOUDS < 80%\n1. Check the metadata of one image with the .first() method on the image collection.\n2. Type filterMetadata in the doc tab to understand which operator to use.\n3. Type the corresponding code to refine the selection.\nEXERCISE: COUNT THE NUMBER OF MATCHING IMAGES FROM EACH \nFILTER\nIn order to count how many individual images matches each filter, you can use the size() \nfunction after a filter is selected. You will see that after each filter is applied the resulting \nnumber of matching images will decrease.\n15.4 Select one image from an image collection\nWhile, is theoretical possible to add to the map layer an image collection (but you will easily \nexceed the computation time receiving an error) is simpler to extract an image from the image \ncollection. We have seen already how each image has its unique ID that can be used to \naccess and display the specific image. There are other options that can be used dynamically \nfrom the script: the first() function, returns the first image from the image collection. The sort() \nfunction returns the images in ascending or descending order, based on a property. \nCombining sort and first, you can return the most recent image matching your filters.\nvar mostRecent = S2_2020.sort('system:time_start', false).first();//False is in descending order\nUsing the acquired information and try to display the image with the least cloud coverage in \nyour area of interest. \n \n15.5 Filter the same period over multiple years\nIn some circumstances, it may be useful to select the same period across multiple years. \nWhile is possible to create several image collections and then merge them, the \ncalendarRange() function allows to accomplish this task easily. The function goes over the \nimage collection and filter the images that are within the assigned range. The range can be \nexpressed in various formats: e.g. year, month, day of year, etc.\nTo filter an image collection of images acquired in a specific month of a specific range of \nyears, you can apply the following example:\nvar S2_TS = ee.ImageCollection(\"COPERNICUS/S2\")\n.filterDate('2010-01-01', '2020-01-01')\n.filter(ee.Filter.calendarRange(7,7,'month'))\n24\nIntroductory course to Google Earth Engine \n\n15.6 Select bands\nSo far, we have limited the number of images from the whole image collection, only to those \nthat matches some spatial, temporal or textual attributes. Now, we want to select only some \nof the bands from those images. To this end, we will use the select() method over the filtered \nimage collection. The select method requires a list of band names that will be selected.\nType the following code to select only specific bands.\n.select([\"B2\",\"B3\",\"B4\",\"B8\" ]);\nFinally, as shown before, you may need to adjust the visualization parameters to properly \nshow the image. Use the false color combination (B8, B4, B3) to display the image with \ncorrect stretching. \nhttps://code.earthengine.google.com/4c7fa899a2faa9e6b732d6acfcd3da5a\n16. Feature collections\nIn previous examples, we have seen how we can create a geometry (a point or a polygon) \nand import it into a script. The geometry object requires a type to be specified (line, polygon, \npoint) and couples of coordinates. We have also seen, how we can use these geometries to \nselect images (filterBounds) or to apply specific functions (e.g. clip). \nIn addition to geometries, in GEE you also have features. A feature is an object which has a \ngeometry property and a dictionary of properties to store additional attributes. A feature \ncollection is simply a set of individual features.\nee.Geometry, ee.Feature and ee.FeatureCollection are the constructor for each of the object.\nTable datasets exist in the data catalog and can be added in a script as a feature collection.\n25\n\nEXERCISE: CREATE  GEOMETRY, FEATURE AND FEATURE COLLECTION\n1. Add two points as geometry in your script.\n2. Create two features, using the geometry you created, adding Province and Enumerator.\n3. Create a feature collection with the two features.\nFeature collections can also be added from table datasets and from assets. \nSimilarly to image collections, feature collections can be added to the map, with specific \nvisualization parameters, however most of parameters are a bit more complex to set.\nhttps://code.earthengine.google.com/18f46ad5dfa3f66f5ba6f8517ee04575\n16.1 Specify the color\nThe color of the feature collection can be changed using the color key, similarly to \nassignments of parameters in a image collection (by default the feature collection will be \ndisplayed with solid black lines and semi-opaque black fill). \n16.2 Use the featureCollection.draw\nWith featureCollection.draw three parameters can be defined:\nŸcolor: color of the collection;\nŸpointRadius: the radius in pixels of the point markers;\nŸstrokeWidth: the width in pixels of lines and polygon borders.\nNote that feaureCollection.draw is a function of a feature collection, hence is not part of a \nvisualization parameter.\n16.3 Use image.paint()\nFor additional control on visualization parameters, you need to create an empy image, and on \nthat image you paint the feature collection, specifying color and width. The advantage is that \nyou can also use an attributes of the image collection for color and width:\nvar empty = ee.Image().byte();\nvar GAUL_IMAGE = empty.paint({\n  featureCollection: PakistanAdm1,\n  color: 1,\n  width: 1\n});\nMap.addLayer(GAUL_IMAGE,{palette: 'FF0000'},\"Pakistan adm1\");\nSimilarly to an image collection, you can filter the metadata of a feature collection (its \nproperties), to select only specific features.\n26\nIntroductory course to Google Earth Engine \n\nEXERCISE: DISPLAY LEVEL-1 ADMINISTRATIVE BOUNDARIES OF PAKISTAN\n1. Select GAUL admin 1 from the data catalog.\n2. Identify the property to select Pakistan.\n3. Create a new feature collection, only with the selected features.\n4. Add the image collection to the map. \n17. Reducers\nReducers are a specific group of functions applied to an image collection that aggregate data \nover time, space or in other ways. Often, the result of a reducer is a single image.\nConsider the example of needing to take the median over a time series of images represented \nby an ImageCollection. To reduce an ImageCollection, use imageCollection.reduce(). This \nreduces the collection of images to an individual image. Specifically, the output is computed \npixel-wise, such that each pixel in the output is composed of the median value of all the \nimages in the collection at that location.\nTo apply a reducer that calculate the mean pixel over an image collection, you can type the \nfollowing:\nvar imageCollectionMean = imageCollection.reduce(ee.Reducer.mean());\nNote that for some common reducing functions, a shortcut method is possible.\nvar imageCollectionMean = imageCollection.mean();\n27\n\nEXERCISE: REDUCE THE IMAGE COLLECTION \nOn the already selected image collection, create three new images with min, max and median \nvalues.\nNote also that the bands names of a reduced image change accordingly to the applied \nfunction.\nhttps://code.earthengine.google.com/9b7c3b28a1a3cfb0396c1269038e791f\n18. Calculate NDVI on an image\nA common task on an image is the calculation of a vegetation index such as the NDVI. There \nare many ways to perform this task: we will use the normalizedDifference() function, that only \nrequires the definition of the NIR and red band.\nType the following:\nvar ndvi = S2_2020median.normalizedDifference(['B8_median', \n'B4_median']).rename('NDVI');\nNote that when you reduce an image collection, the name of the bands has changed.\nYou can also add the calculated NDVI within the reduced image, using the addBands() \nfunction.\nType the following:\nvar S2_2020_NDVI = S2_2020median.addBands(ndvi); \nhttps://code.earthengine.google.com/281fbda678b3d98e7e9fcba6b3b17c19\n19. Apply a reducer over a feature collection\nTo calculate the statistics of an image over a geometry or a feature collection, the \nreduceRegion reducers can be applied. This reducers is applied over a specific image (not an \nimage collection) and requires to define a number of parameters:\nvar meanDictionary = ndvi.reduceRegion({\n  reducer: ee.Reducer.mean(),\n  geometry: geometry,\n  scale: 10,\n  maxPixels: 1e9\n});\nŸReducer is the function used to calculate the statistics.\nŸGeometry is the geometry used to define the region(s).\nŸThe scale express the spatial resolution of an image.\nŸmaxPixels is the maximum number of pixels to compute.\nThe result is stored as a dictionary that can then printed or exported. \nhttps://code.earthengine.google.com/3c4d7bde7d145eabf9a2a22eae7fca6d\n28\nIntroductory course to Google Earth Engine \n\n20. Apply a mask on an image\nIn many cases, you will apply a process only to pixels that meet certain criteria. This is \ndifferent from filtering images within an image collection, as the whole image is included or not \nin the analysis according to the filter, while with masks, we will consider specific pixels within \nan image. \nMasking pixels is a two-steps approach. First, you will define the criteria to evaluate each \npixel value. Second, you will apply the filter to the image. The result is a new image where \nmasked pixels will be transparent and treated as no data.\nThere are many operators used for defining specific criteria. Probably the most common are \nthe “great than” and “less than” operators (gte and lte) that evaluate whether a pixel is greater \nor lesser a specific threshold:\nvar filter = ndvi.gte(0.5);\nThen, you will apply the filter to a specific image, with the updateMask():\nvar vegetation = ndvi.updateMask(filter);\nThe two steps can also be embedded in one single line of code:\nvar vegetation = ndvi.updateMask(ndvi.gte(0.5));\nEXERCISE: FIND PIXELS WITH VEGETATION AND ELEVATION HIGHER THAN \n250 METER\nWith the acquired information, try to develop a script that finds pixels with vegetated land \n(according to the mask of the previous chapter) AND with an elevation of 250 meter.\nhttps://code.earthengine.google.com/7d357fea75b02a19dfb636fcbe024396\n21. Calculate NDVI on a image collection\nIn many cases, you will need to apply a process to all the images within an image collection, \nand as a result, to have a new image collection, containing the new updated images. This is \nachieved by using the map function over the image collection. The map function is different \nfrom a reducer, where you apply a function over the whole image collection and as a result \nyou obtain a single image.\nThe process that you will apply is defined within a function, which contains some instructions \nthat will be returned as a result of the function.\n29\n\nTo map a function over a collection, you will \nneed the following:\nA declaration of the function: This is done \nusing: the keyword function, followed by the \nfunction name and by the parameter on which \nyou map the function (e.g. an image). Then, all \nthe instructions are included by curly brackets. \nThe last instruction is a return.\nA map statement on a collection that invokes \nthe declared function and define the new \ncollection.\nThe following image presents a schema of how it works: you start from an image collection (a \nseries of images) and you invoke an existing function, that apply some manipulation and \nreturn each image to the new function.\nThe same schema with proper syntax is as follows:\nLet's begin with a simple function. This function is applied to a collection of a numbers within \na list. These numbers represent years. I want to create a new list with the number of years to \nreach 2080 for each number of the original list. Note that we will use a map over a list (not an \nimage collection).\nLet's define the initial list of years:\nvar startingYears = [2000, 2010, 2020, 2050];\nThen, let's create the function:\nfunction calcYearsTo2080 (year){\nvar difference = 2080 - year\nreturn difference;\n}\n30\nIntroductory course to Google Earth Engine \n\nFinally, let's map the function over the list and print the results.\nvar yearsTo2080 = startingYears.map(calcYearsTo2080);\nprint(yearsTo2080);\nThe concept of mapping over an image collection, can be easily applied to generate an NDVI \nband on the images within an image collection.\nEXERCISE: CALCULATE NDVI OVER A S2 IMAGE COLLECTION \n1. Select an image collection of S2\n2. Write a function to calculate the NDVI. \nŸRemember: you must first type function followed by the function name, the image by \nparenthesis (this is the parameter of the function) all encapsulated by curly brackets { }.\nŸWithin the curly brackets, you can use the image.normalizedDifference([\"B8\",\"B4\"]) \nfunction to generate the NDVI.\nŸReturn the image back to the new image collection.\n3. Map the function over the image collection and assign the result to a new imageCollection\nThe next example uses a more complex logic: it maps over a list of years, to select images \nwithin an image collection, apply a reduction and reselect some pixels. Note how the result of \nmapping over a list is another list. To convert the list to a new image collection, you have to \napply a specific command.\n//Define the image collection\nvar dataset = ee.ImageCollection('MODIS/006/MCD64A1').select('BurnDate');\n//Define a list of years\nvar years = ee.List.sequence(2001, 2019);\n//Map over each year\nvar results = years.map(function(year) {\n  return dataset.filterDate(ee.Date.fromYMD(year, 1, 1), ee.Date.fromYMD(year, 12, \n31)).sum().gte(1);\n});\n//Convert the results to an image collection\nresults = ee.ImageCollection(results);\n//Map the layers\nvar burnedAreaVis = {\n  min: 30.0,\n  max: 341.0,\n  palette: ['4e0400', '951003', 'c61503', 'ff1901']\n};\nMap.addLayer(dataset, burnedAreaVis, 'Burned Area');\nMap.addLayer(results.count(), imageVisParam, \"Frequency of burnt areas\");\n//Map.addLayer(results.mean(), {}, \"results\");\nprint(results);\nhttps://code.earthengine.google.com/03f23f0207a511f580bb7cdc6b2d1155\n31\n\n22. Cloud removal\nWhen working with optical images for land cover assessment, one of the main pre-\nprocessing task, is to remove (or reduce) atmospheric effects caused by clouds, cloud \nshadows and other phenomena that may alter the signal recorded by the satellite. While is \npractical impossible to remove these effects on a single image, an increased availability of \nmultiple images due to shortened revisit time and a redundancy of the information allow to \ndefine a strategy for cloud removals.\nThe first obvious step is to increase the acquisition time range to include in the image \ncollection a larger number of images and hence to increase the probability to have cloud free \nimages. This approach needs to be balanced with the expected temporal behavior of the \nfeatures under investigation. If crop monitoring is the purpose, to have a wide period of \nanalysis (e.g. a year), would result on degrading the information related to the change of \nspectral signature due to the phenology of crops. Typically, a multi-temporal monthly or \nseasonal window is suggested.\nThen, metadata of the images can be used to remove from the image collections those \nimages that are considered of bad quality. On the result image collection, all the pixels that \nare of bad quality can be masked out. Finally on the resulting pixels, a reduction can be \napplied to generate the final single free-cloud image to analyse.\nEXERCISE: REMOVE CLOUDS FROM AN IMAGE COLLECTION \n1. Select images from S2.\n2. Sub-select the images based on metadata.\n3. Remove cloudy pixels.\n4. Apply a median reducer.\nhttps://code.earthengine.google.com/eca8f6f59992509ecfdba933d529e2f3\n32\nIntroductory course to Google Earth Engine \n\n23. Export a video from a reduced cloud removed image collection\nDisplaying an animated time lapse of an image collection can be an interesting assessment of \npressures on land and variability of natural resources, in order to have an exploratory analysis \nof the area of interest.\nTake 5 minutes, to visit some examples on the following link:\nhttps://earthengine.google.com/timelapse/\nYou will then explore how a thumbnail is generated. The example uses the image.visualize \nfunction that produces an RGB or grayscale visualization of an image.\nhttps://code.earthengine.google.com/01bbdd3b5622d279bcf97dd959c4b274\n24. NDVI anomalies\nAn anomaly is defined as a deviation from a normal behavior. In crop monitoring, is a \nquantitative measure that expresses how different a variable at a certain place and time (e.g. \nrainfall, NDVI is from reference (i.e. normal) conditions. While anomalies look both at below \nand above normal conditions, in crop monitoring is important to look at below normal \nconditions (flood detection is one typical example that looks at above normal conditions).\nAnomaly maps of NDVI can identify how and where vegetation conditions are below normal \nconditions, highlighting areas of potential concern, particularly when focusing on agricultural \nand pastoral land. \nWhen considering normal conditions, we typically look at multi-annual averages: Long-Term \nAverages (LTA) usually refers to 30 years of observations (this is the standard for climate \nnormals), while Short-Term Averages (STA) or Recent Average (RA) consider 5 or 10 years.\nAnomalies can be calculated in different ways:\nAbsolute. Simple difference between current value and the normal average. The difference is \nexpressed in the physical unit of the variable. (current value – average).\nRelative. It is expressed as a percentage, where a value below 100% means that the variable \nis lower than normal conditions. It is the ratio between current value and normal average \nmultiplied by 100. ((current value / average) * 100).\nStandardized. It is the difference between current value and average, divided by the standard \ndeviations for all the years. ((current value – average) / standard deviation(average)).\n33\n\nEXERCISE: STATISTICAL CALCULATION OF RAINFALL ANOMALY \nGiven a hypothetical value of 240 mm, in an Excel document calculate the three types of \nanomaly respects to a STA (200,220,200,240,230).\nSTA average = (200+220+200+240+230) / 5 = 218\nStandard deviation = 17.89\nAbsolute anomaly = 240 – 218 = 22\nRelative anomaly = (240/218)*100 = 110\nStandardized anomaly = (240-218)/17.89 = 1.23\nTable 1. NDVI anomalies and their units\nEXERCISE: CALCULATE NDVI ANOMALY IN A SPECIFIC AREA\n1. Choose one area of interest and add a point on the map.\n2. Import the point and use it to filter the image collection of S2.\n3. Select the S2 image collection for the month of July for the years 2015, 2016, 2017, 2018 \nand 2019.\n4. Calculate the median NDVI of S2 image collection STA.\n5. Select the S2 image collection for the month of July 2020 and calculate the median of \nNDVI.\n6. Use map algebra to calculate absolute, relative and standardized anomaly.\n7. Compare the results.\nhttps://code.earthengine.google.com/65cc6d4ba0440027dd12e30c3e795bbf\n34\nIntroductory course to Google Earth Engine \n\n25. Introduction to Synthetic Aperture Radar images\nWhile optical satellites record the Sun's energy reflected from the target surface, Synthetic \nAperture Radar (SAR) satellites emit their own energy that reaches the land, interact with the \ntarget surface and is then scattered back to the satellite. The energy emitted is on the \nmicrowave range of the electromagnetic spectrum. Microwaves penetrate through clouds \nand smoke and because of that are defined as all-wheatear (regardless on weather \nconditions) and all-time sensors (as they collect data during day and night).\n \nFigure 6. NASA's Imagine the Universe\nThe strength of the backscattered signal is measured to discriminate between different \ntargets and the time delay between the transmitted and reflected signals determines the \ndistance (or range) to the target. The beam is oriented to send pulses oblique to the land, \nwhich requires some spatial adjustments when processing SAR images.\nFigure 7. Observation geometry of SAR imager \n35\nSource: National Aeronautics and Space Administration (NASA). 2022. In: Imagine the universe! The electro-magnetic spectrum. https://imagine.gsfc.nasa.gov/\nSource: SAR Handbook: Comprehensive methodologies for forest monitoring and biomass estimation. 2019. In: Servir Global. \nhttps://servirglobal.net/Global/Articles/Article/2674/sar-handbook-comprehensive-methodologies-for-forest-monitoring-and-biomass-estimation\n\nDifferently from a True color optical imagery, the brightness of the pixel is not indicative of the \ncolor of the target object on the land. Instead, its intensity depends on a number of other \nfactors:\nŸthe amount of energy transmitted from the satellite;\nŸthe properties of the target;\nŸthe shape of the target;\nŸthe angle from which the target is viewed.\nThe satellite's receiver records the backscatter coefficient (o), given by the following formula:\no (dB) = 10. Log10 (energy ratio)\nwhereby the energy ration is the ration between the received energy by the sensor and the \nenergy reflected in an isotropic way.\nFigure 8. The radar measurement \n36\nSource: Moreira A. 2013. Conference: Advanced Training Course in Land Remote Sensing. Synthetic Aperture Radar (SAR). Principles and applications. \nIntroductory course to Google Earth Engine \n\n26. Characteristics of a sar system\nThere are three main parameters that characterize SAR systems: wavelength, look angle and \npolarization.\n26.1. Wavelength\nAll the SAR systems emit energy in the microwave spectrum, however specific part of this \nrange are used in different systems. \nThe wavelength is directly linked to the ability of the emitted energy to penetrate through the \ntarget objects, such that longer wavelength signals (L and P band) penetrate deeper into \nvegetation canopy and soils, hence the applications supported depend on the SAR \nwavelength used. \nFigure 9. Designation of radar bands \nFigure 10. Reflectance mechanism of vegetation in different bands (SOURCE ESA Radar \nCourse 2)\n37\nSource: SAR Handbook: Comprehensive methodologies for forest monitoring and biomass estimation. 2019. In: Servir Global. \nhttps://servirglobal.net/Global/Articles/Article/2674/sar-handbook-comprehensive-methodologies-for-forest-monitoring-and-biomass-estimation\nSource: European Space Agency (ESA). 2022. In: Training courses: Radar Course 3. https://earth.esa.int/eogateway/missions/ers/radar-courses/radar-course-3\n\n26.2. Look angle\nSAR sensors are always oriented at a certain angle respect to the satellite's orbit. The \nincident angle is the angle between the radar beam and the ground surface (A).\nFigure 11. Incident angle\nThe incident angle, coupled with the topography of the land may create artifacts (layovers, \nshadowing, foreshortening) that alter the brightness of the images. \nDepending on the satellite's orbit, the image is acquired when satellite is ascending (moving \ncloser to the North) or descending (moving closer to the South).\nFigure 12. Satellite orbits\n26.3. Polarization\nImaging radars can transmit horizontal (H) or vertical (V) microwave radiation. At the same \nway, the receiving antenna can record horizontal and vertical polarizations. Based on this, four \npossible combinations of transmit and receive polarization exists:\nŸHH - for horizontal transmit and horizontal receive\nŸVV - for vertical transmit and vertical receive\nŸHV - for horizontal transmit and vertical receive, and\nŸVH - for vertical transmit and horizontal receive.\n38\nSource: Canada Centre for Remote Sensing. 2022. In: Fundamentals of Remote Sensing. \nhttps://www.nrcan.gc.ca/sites/www.nrcan.gc.ca/files/earthsciences/pdf/resource/tutor/fundam/pdf/fundamentals_e.pdf\nSource: Tre Altamira. 2022. In: InSar at a glance. https://site.tre-altamira.com/insar\nIntroductory course to Google Earth Engine \n\nFigure 13. Polarization in SAR images\n27. Surface parameters\nThe response and intensity of a backscatter signal is dependent of the characteristics of the \ntarget land: surface roughness, material and shape affects this response.\n27.1. Surface roughness\nIn general, smooth surfaces tend to scatter the emitted energy to a specular angle away from \nthe satellite and as a result, the area tends to be dark (low values).\nFigure 14. SAR imagery and field validation methods \n39\nSource: South African National Space Agency (SANSA). 2022. In: Application of GIS to Fast Track Planning and Monitoring of Development Agenda. https://www.nepad.org/\nSource: de Jong T. 2013. Recent changes in glacier facies zonation on Devon Ice Cap, Nunavut, detected from SAR imagery and field validation methods. Thesis for: Msc\n\nHowever, how the surface is perceived as smooth or rough, it depends also from the \nwavelength of the satellite. A surface appearing “rough” in a short wavelength will appear \n“smoother” in a longer wavelength signal. As shorter wavelengths are reflected by smaller \nfeatures, they provide more detailed  information  at  smaller  scales.\nFigure 15. X-Band and L-Band radar reflections \n27.2. Target material \nTarget material properties play a major role in that target's SAR imagery. These properties \ninclude dielectric constant and permeability of the material.  The dielectric constant is \ngenerally affected by moisture, thus increasing moisture is associated with an increased radar \nreflectivity.\n27.3. Shape\nThe shape of certain surface features will cause a specular reflection back toward the sensor, \nby bouncing off multiple surfaces. \n40\nSource: Messina P. 2022. Radar Mapping Techniques and Applications. In: Transmission and Return Characteristics of Radar Signals http://www.geo.hunter.cuny.edu/terrain/radariv.html\nIntroductory course to Google Earth Engine \n\n28. Scattering mechanisms\nSAR characteristics and surface parameters interact together and determine the type and \nstrength of backscattered energy.\nWe discussed already the conditions that affect the surface scattering (roughness and \nwavelength) and the double bounce. Volumetric scattering often occurs in vegetation where \nthe signal is bounced back many times before reaching back the sensor's satellite. \nFigure 16. Scattering mechanisms \nAs a rule of thumb and to support the interpretation of a SAR image, we can generalize the \nbehaviour of the main types of surfaces.\nTarget\n \nBackscatter\n \ncoefficient\n \nPolarization\n \nComposite RGB \n(VV,VH,VV-VH)\nUrban areas, very rough areas, \nterrain slopes towards radars\n \nAbove -5 dB\n \nVV is stronger than VH due to \ndouble bounce\n \nTowards pink (high VV)\nDense vegetation\n \nBetween -10 dB to 0 dB\n \nVH is strong due to volume \nscatter\n \nTowards green (high VH)\nCrops\n \nBetween -20 to -10 dB\n \nVV and VH are similar \n \nTowards purple\n \nWater, bare soil, sand\n \nBelow -20 dB\n \nVH is lower than VV \n \nDark blue, black\n \n(difference \nbetween VV and VH)\n \nTable 2. Behaviour of main types of surfaces\n41\nSource: European Space Agency (ESA). 2022. In: Sentinel Online. https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar\n\n29. Sentinel-1 main characteristics\nS1 operates in four exclusive acquisition modes:\nŸStripmap (SM).\nŸInterferometric Wide swath (IW).\nŸExtra-Wide swath (EW).\nŸWave (WV).\nThe default and main acquisition mode over the land is the Interferometric Wide Swath. The \nother acquisition modes may be activated for specific circumstances and applications.\nFigure17.  Acquisition modes  \nLevel-1 products can be one of two product types - either Single Look Complex (SLC) or \nGround Range Detected (GRD). Level-2 Ocean (OCN) products can have different \ncomponents available depending on the acquisition mode.\nFigure 18. Product types processing levels \n42\nSource: European Space Agency (ESA). 2022. In: Sentinel Online. https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar\nSource: European Space Agency (ESA). 2022. In: Sentinel Online. https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar\nIntroductory course to Google Earth Engine \n\nGRD products consist of focused SAR data that has been detected, multi-looked and \nprojected to ground range using an Earth ellipsoid model. The ellipsoid projection of the GRD \nproducts is corrected using the terrain height specified in the product general annotation. The \nterrain height used varies in azimuth but is constant in range.\nEXERCISE: DISPLAY A SINGLE S1 IMAGE\n1. Add a point to the map.\n2. Select the S1 image collection.\n3. Print the metadata of the first result image.\n4. Filter the image collection to your area of interest, the last year and select the instrument \nmode “IW”, the polarization VV and VH and the descending orbit direction.\n5. Add to the map view two different images, for VV and VH.\nhttps://code.earthengine.google.com/f1a8b0afa0bdf6cfdcdbd2df8827682d\n30. Display a color composite SAR image\nDespite the fact that SAR images can not represent true colors, as the energy recorded is not \nthe visible portion of the spectrum, few color composite combinations may be applied to a \nsingle S1 image. The most common combinations use the VV band, the VH and the ratio (or \ndifference) between the VV and VH. In the next execersize, we will use the same filtered \nimage collection and we will display it as false color composite.\nEXERCISE: DISPLAY A SINGLE SENTINEL-1 IMAGE IN COLOR COMPOSITE\n1. On the previous image collection, select the first image and create a new image as \ndifference between VV and VH.\n2. Add the band to the image (addBands).\n3. Display the resulting image as color composite.\nhttps://code.earthengine.google.com/77845d5ff0b1e1fcdcfe79316dc4e87b\n31. Pre-processing Sentinel-1 image collection\nDifferent pre-process steps are applied to SAR images before using them in applications. \nThese steps depend on the type of application and on how those images are filtered. The \nfollowing image presents the pre-processing steps suggested by SERVIR to be applied to \nSAR data before using. \nYou can apply and practise all the steps on a single image using the SNAP software.\n \n43\n\nFigure 19. SAR data processing \nWe will use functions written in an existing shared workspace, to apply some of those pre-\nprocess steps on a single image. To upload an external script, we will use the 'require' \nfunction, to retrieves the script found at a given path as a module. The module is used to \naccess exposed members of the required script.\nWe will use a function that applies the following steps:\n1. Remove the pixels in the borders.\n2. Apply a calibration.\n3. Add a VV, VH ratio band.\n4. Add a VV, VH difference band.\nFinally, we will use a second preprocessing that will add an extra-step with speckle removal.\nhttps://code.earthengine.google.com/069dd5702e68d56af89d3f9049a08ab3\nhttps://code.earthengine.google.com/720ee9103ae699a4fcbe7f02be500f79\n44\nSource: SAR Handbook: Comprehensive methodologies for forest monitoring and biomass estimation. 2019. In: Servir Global. \nhttps://servirglobal.net/Global/Articles/Article/2674/sar-handbook-comprehensive-methodologies-for-forest-monitoring-and-biomass-estimation\nIntroductory course to Google Earth Engine \n\n \n32. Sentinel-1 time series\nAnother approach to display color composite Sentinel, is to select images over multiple \nperiods and then, assign each period to the red, green and blue channels. The dominance of \na band corresponds to the strength of the backscatter in the assigned period.\nEXERCISE: DISPLAY A THREE-PERIODS TIME SERIES AS COLOR \nCOMPOSITE\n1. Filter three different S1 image collections for April, June, August (leave the other filtering \ncriteria unchanged respect to the previous script) and select the first image.\n2. Pre-process the three selected images.\n3. Create a single image (both with VV and VH).\n4. Display two color composite (VV and VH) and comment results.\nhttps://code.earthengine.google.com/fe4fba5151bbb9e4e0c30b3b2074c60a\n33. Land cover classification\nIn the following scripts, we will explore techniques for a classification of pixels into thematic \nclasses. We will use a simplified legend with only five classes (urban, agriculture, water, sand \nand wetland). The two main techniques for image classifications are unsupervised and \nsupervised classifications. In the first case, the pixels of the images are grouped into a \nnumber of classes (the number classes may not correspond initially to the land cover classes) \nbased on their spectral similarity. Similar pixels belong to the same classes, although no \nthematic information (i.e. the name of the land cover class is provided). This technique does \nnot require the use of training data to build a classification model. Is the use that in a post-\nprocess step, define the thematic classes to each group. The example on a limited area of \ninterest uses progressively an increased number of time-series datasets: S2 only, S1 only, and \nthen a combined image of S1, S2 and topography (elevation and slope).\nThe script is divided into two parts:\nhttps://code.earthengine.google.com/faf72bdc83d6b88961a36944b19e0c8\nhttps://code.earthengine.google.com/69874f4d0cb2e24b1d3d50b60987e609\nThe supervised technique requires that the user provides a set of training samples to build a \nmodel that is than applied to the rest of the image. Multiple steps are required:\n1. Building the image collections (selection, pre-process, stack).\n2. Upload a Shapefile of training samples.\n3. Calculate statistics of each training sample over the image collection.\n4. Define model parameters.\n5. Apply the models over the training sample.\n6. Use the model to classify the image.\nExample of this technique is provided here:\nhttps://code.earthengine.google.com/214a3945780da7c9c853d9c935a59cac\n45\n\n\n\nIntroductory course to\nGoogle Earth \nEngine\n\n## Document Information\n- **Source**: PDF Document (55 pages)\n- **Category**: lab-material\n- **Difficulty**: advanced\n- **Relevant Labs**: lab3\n- **Topics**: arcgis, classification, gee, gis, google earth engine, mapping, overlay, projection, raster, remote sensing, satellite, scripting, shapefile, spatial analysis, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain introductory course to google earth engine\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- arcgis\n- classification\n- gee\n- gis\n- google earth engine\n- mapping\n- overlay\n- projection\n- raster\n- remote sensing\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "advanced",
      "lab": "lab3",
      "topics": [
        "arcgis",
        "classification",
        "gee",
        "gis",
        "google earth engine",
        "mapping",
        "overlay",
        "projection",
        "raster",
        "remote sensing",
        "satellite",
        "scripting",
        "shapefile",
        "spatial analysis",
        "vector"
      ],
      "source": "concepts\\gee_tut1.md",
      "filename": "gee_tut1.md"
    }
  },
  {
    "id": "concepts-gis_comprehensive_intro",
    "title": "gis_comprehensive_intro",
    "content": "# Complete Introduction to GIS - From Basics to Applications\n\n# Geographic Information Systems: A Comprehensive Introduction\n\n## What is GIS?\n\n**GIS (Geographic Information System)** is a multi-component environment for creating, managing, visualizing and analyzing spatial data. Just as we use word processors for text, we use GIS applications for spatial information.\n\n### Core GIS Components:\n1. **Digital Data**: Geographical information stored digitally\n2. **Computer Hardware**: Systems for storing, displaying, processing data\n3. **Computer Software**: GIS applications (QGIS, ArcGIS, Google Earth Engine)\n4. **People**: Users, analysts, decision-makers\n5. **Methods**: Procedures and workflows for analysis\n\n### Why GIS is Revolutionary:\n- **Location-based analysis**: Everything has a geographic component\n- **Pattern recognition**: Identify spatial relationships invisible in tables\n- **Decision support**: Inform policy, planning, emergency response\n- **Data integration**: Combine multiple data sources spatially\n\n## Real-World GIS Example: Health Applications\n\n**Scenario**: Track disease outbreaks and identify patterns\n\n**Traditional Approach**: \n```\nDate       | Location    | Disease | Patients\n13/12/2008 | 26.87, -31.91 | Mumps  | 1\n24/12/2008 | 26.87, -31.91 | Mumps  | 1\n22/01/2009 | 26.87, -31.91 | Mumps  | 1\n```\n\n**GIS Approach**: \n- Map patient locations spatially\n- Identify disease clusters visually\n- Analyze proximity to potential sources\n- Predict spread patterns\n- Target interventions geographically\n\n**Result**: Clear spatial patterns emerge that are invisible in tabular data - mumps cases cluster together, suggesting local transmission.\n\n## GIS vs. Traditional Mapping\n\n**Traditional Maps**: Static representations for navigation\n**GIS Maps**: Dynamic, analytical tools for:\n- **Reference maps**: Navigation, location identification\n- **Presentation maps**: Communicate specific narratives\n- **Statistical maps**: Reveal patterns through data manipulation\n\n## GIS Applications in Health and Development:\n- **Epidemiology**: Disease surveillance, outbreak investigation\n- **Healthcare access**: Facility location, service area analysis\n- **Environmental health**: Pollution exposure, vector habitats\n- **Emergency response**: Resource allocation, evacuation planning\n- **Global development**: Poverty mapping, infrastructure planning\n\n## Key Information\n- **Category**: fundamentals\n- **Difficulty**: beginner\n- **Source**: QGIS Gentle GIS Introduction + Spatial Analysis textbook\n\n## Keywords\n- gis\n- geographic information system\n- spatial analysis\n- health applications\n- mapping\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "concepts\\gis_comprehensive_intro.md",
      "filename": "gis_comprehensive_intro.md"
    }
  },
  {
    "id": "concepts-lab_1_enhanced_qgis_tutorial",
    "title": "Lab 1 Enhanced QGIS Tutorial",
    "content": "\n# Lab 1 Enhanced QGIS Tutorial\n\n\n\n \nEnhanced QGIS Malaria Mapping Tutorial: A \nComprehensive Guide \n1. Introduction to Malaria Mapping and Public Health GIS \n1.1 The Global and Local Impact of Malaria \nMalaria remains one of the most significant public health challenges globally, with 247 million cases \nreported worldwide and particularly severe impact in sub-Saharan Africa \n[1]\n. In Uganda specifically, the \ndisease accounts for an estimated 12.7 million cases and approximately 17,556 deaths annually, placing \nan enormous burden on the country's healthcare system and economy \n[2][3]\n. The disease affects \napproximately 95% of Uganda's population, making it a critical public health priority that requires \nsophisticated monitoring and intervention strategies. \n\n \nPolitical map of Uganda showing its administrative regions, major cities, and geographical features. \n\nUganda's geographic and climatic conditions create ideal environments for malaria transmission, with \ndifferent regions experiencing varying levels of endemicity based on factors such as altitude, rainfall \npatterns, and temperature \n[1]\n. The economic impact of malaria in Uganda is estimated at $500 million \nannually, while the healthcare burden is reflected in malaria cases accounting for 30-50% of all outpatient \nvisits to health facilities \n[2]\n. Understanding the spatial distribution of malaria is essential for effective \nresource allocation, targeted interventions, and evaluation of control programs \n[1][4]\n. \n1.2 The Power of Geographic Information Systems in Disease Mapping \nGeographic Information Systems (GIS) have revolutionized how we understand disease patterns and \nimplement public health interventions by allowing visualization, analysis, and interpretation of spatial \ndata \n[5][6]\n. For malaria control specifically, GIS enables health professionals to identify transmission \nhotspots, direct resources where they're most needed, monitor trends over time, evaluate intervention \nprograms, and predict future outbreaks \n[1][7]\n. These capabilities transform abstract health statistics into \nactionable intelligence that can guide policy decisions and resource allocation \n[8][6]\n. \nThe integration of GIS with epidemiological data provides powerful tools for: \n• Identifying geographic patterns of disease transmission \n[4][6]\n \n• Correlating environmental factors with disease prevalence \n[1][7]\n \n• Monitoring changes in disease distribution over time \n[4][3]\n \n• Targeting interventions to high-risk areas \n[7][2]\n \n• Evaluating the effectiveness of public health programs \n[4][6]\n \n1.3 Uganda's Malaria Context and Surveillance Systems \nUganda is divided into 15 health administrative regions which are further subdivided into districts, \ncreating a geographic framework for health planning and intervention \n[9][10]\n. The country experiences \nseasonal malaria transmission patterns, with peak seasons occurring during March-May (long rainy \nseason) and October-December (short rainy season), though transmission occurs year-round in many \nareas \n[1]\n. The predominant malaria vector is Anopheles gambiae, and the most common parasite species is \nPlasmodium falciparum, which causes the most severe form of the disease \n[2]\n. \nNational malaria surveillance in Uganda operates through multiple systems, including: \n• Health Management Information System (HMIS) with monthly facility reporting \n[1][9]\n \n• Malaria-specific surveillance systems for case-based reporting and outbreak detection \n[1][10]\n \n\n• Community-based surveillance through village health teams \n[9][10]\n \nDespite these systems, data quality issues including completeness, timeliness, accuracy, and consistency \nremain significant challenges \n[9][10]\n. This tutorial will help you leverage GIS technology to make sense of \navailable malaria data, creating visualizations that can drive better decision-making \n[5][7]\n. \n2. Understanding GIS and QGIS Fundamentals \n2.1 Key GIS Concepts for Health Mapping \nBefore diving into practical mapping, it's important to understand fundamental GIS concepts that will \ninform your work \n[1][5]\n. Geographic Information Systems integrate hardware, software, data, and users to \ncapture, analyze, manage, and present geographic or spatial data \n[5][8]\n. In health applications, GIS helps us \nunderstand the \"where\" and \"why\" of disease patterns, enabling more effective public health responses \n[8][6]\n. \nKey GIS terminology relevant to health mapping includes: \n• Vector Data: Represents features as points (health facilities), lines (roads), or polygons (districts) \n[1][11]\n \n• Raster Data: Grid-based data representing continuous surfaces like population density or elevation \n[1][11]\n \n• Attribute Table: Database containing information about spatial features, such as disease counts \n[1][5]\n \n• Choropleth Map: Areas colored according to statistical values, commonly used for disease rates \n[1][12]\n \n• Spatial Join: Combining datasets based on spatial relationships \n[1][13]\n \n2.2 Coordinate Reference Systems for Uganda \nA coordinate reference system (CRS) defines how the curved surface of the Earth is represented on a flat \nmap \n[1][14]\n. Choosing the appropriate CRS is crucial for accurate distance measurements, area calculations, \nand spatial analysis in health applications \n[1][15]\n. For mapping in Uganda, several coordinate systems are \ncommonly used, each with specific applications \n[14][16]\n. \n\n \nCoordinate Reference Systems for Uganda GIS Projects \nWhen working with Uganda data, you'll typically encounter these coordinate systems: \n• WGS 84 (EPSG:4326): The global standard used by GPS systems, ideal for general mapping \n[16][17]\n \n• UTM Zone 35N (EPSG:32635): Provides accurate measurements for western Uganda \n[14][17]\n \n• UTM Zone 36N (EPSG:32636): Best for eastern Uganda projects requiring precise measurements \n[14][17]\n \n• Arc 1960: Legacy system used in historical maps and datasets \n[16][15]\n \nSelecting the appropriate CRS depends on your specific application, area of interest, and the need for \ndistance or area measurements \n[14][17]\n. For most health mapping applications in Uganda, UTM Zone 36N is \nrecommended as it covers the majority of the country and provides good metric accuracy \n[14][17]\n. \n2.3 Understanding the QGIS Interface \nQGIS is a powerful, free, and open-source geographic information system that allows you to create, edit, \nvisualize, analyze, and publish geospatial information \n[18][19]\n. Before beginning your malaria mapping \nproject, familiarize yourself with the main components of the QGIS interface \n[19][20]\n. \n\n \nQGIS interface showing the 'Add ArcGIS REST Server Layer' option within the 'Layer' menu. \nThe main elements of the QGIS interface include: \n• Menu Bar: Contains dropdown menus for all QGIS functions \n[19][20]\n \n• Toolbars: Provides quick access to commonly used tools \n[19][20]\n \n• Browser Panel: Helps you navigate files and databases \n[19][20]\n \n• Layers Panel: Shows all data layers in your project \n[19][21]\n \n• Map Canvas: The main area where your map is displayed \n[19][20]\n \n• Status Bar: Shows coordinates, scale, and projection information \n[19][20]\n \nYou can customize the interface by showing/hiding panels and toolbars according to your needs \n[19][21]\n. \nFor health mapping projects, you may want to ensure that the Processing Toolbox is visible, as it contains \nanalytical tools useful for spatial epidemiology \n[13][21]\n. \n3. Step-by-Step QGIS Malaria Mapping Tutorial \n3.1 Project Setup and Data Preparation \n\nStep 1: Launch QGIS and Create a New Project \n1. Open QGIS from your applications menu or desktop shortcut \n[1][19]\n. \n2. Click on \"Project\" → \"New\" to create a new project \n[1][22]\n. \n3. Immediately save your project by clicking \"Project\" → \"Save As\" and name it \n\"Uganda_Malaria_Mapping.qgz\" \n[1][22]\n. \n4. Choose an appropriate folder where you'll store all project files \n[1][22]\n. \nStep 2: Set Up the Coordinate Reference System \n1. Go to \"Project\" → \"Properties\" → \"CRS\" \n[1][14]\n. \n2. In the filter box, search for \"32636\" to find the WGS 84 / UTM Zone 36N projection \n[1][16]\n. \n3. Select this CRS and click \"Apply\" then \"OK\" \n[1][14]\n. \n4. Verify the CRS is set correctly by checking the bottom-right corner of the QGIS window \n[1][19]\n. \nSelecting the appropriate CRS is crucial as it affects all distance measurements and spatial analyses you'll \nperform \n[14][17]\n. For Uganda, UTM Zone 36N provides accurate measurements for most of the country \n[14][16]\n. \n3.2 Loading Spatial Data \nStep 3: Add Uganda District Boundaries \n1. Click on \"Layer\" → \"Data Source Manager\" or press Ctrl+L \n[1][18]\n. \n2. In the Data Source Manager, select \"Vector\" from the left panel \n[1][18]\n. \n3. For \"Source Type,\" select \"File\" \n[1][18]\n. \n4. Click the \"...\" button to browse for your Uganda_districts shapefile or geopackage \n[1][18]\n. \n5. Click \"Add\" and then \"Close\" \n[1][18]\n. \n\n \nAdding a vector layer from a local GeoJSON file in QGIS using the Data Source Manager. \nThe district boundaries layer is the foundation of your malaria map, providing the geographic framework \nfor visualizing health data \n[1][23]\n. Once loaded, the districts should appear in the map canvas and be listed \nin the Layers panel \n[1][19]\n. \nStep 4: Examine the District Boundaries Attribute Table \n1. Right-click on the Uganda_districts layer in the Layers panel and select \"Open Attribute Table\" \n[1][13]\n. \n2. Examine the table to familiarize yourself with the available attributes \n[1][13]\n. \n3. Take note of the field containing district names (likely \"DIST_NAME\" or similar) as this will be used \nfor joining with health data \n[1][13]\n. \n4. Close the attribute table when finished \n[1][13]\n. \nUnderstanding the structure of your spatial data is essential before attempting to join it with health \nstatistics \n[1][13]\n. Make sure the district names are consistent and free of typographical errors that might \nprevent proper joining \n[1][13]\n. \n\n3.3 Importing and Joining Health Data \nStep 5: Import Malaria Prevalence Data \n1. Click on \"Layer\" → \"Add Layer\" → \"Add Delimited Text Layer\" \n[1][18]\n. \n2. Browse to your malaria_prevalence.csv file \n[1][18]\n. \n3. Ensure \"CSV (comma separated values)\" is selected as the file format \n[1][18]\n. \n4. Under \"Geometry Definition,\" select \"No geometry (attribute table only)\" \n[1][18]\n. \n5. Click \"Add\" and then \"Close\" \n[1][18]\n. \nThe CSV file should contain malaria prevalence data by district, with at least one field matching the \ndistrict names in your spatial data \n[1][18]\n. This tabular data will be joined to the geographic features to \ncreate your malaria map \n[1][13]\n. \nStep 6: Join Malaria Data to District Boundaries \n1. Right-click on the Uganda_districts layer and select \"Properties\" \n[1][13]\n. \n2. Go to the \"Joins\" tab and click the \"+\" button \n[1][13]\n. \n3. In the \"Add Vector Join\" dialog: \no Set \"Join layer\" to your malaria prevalence CSV \n[1][13]\n \no Set \"Join field\" to the district name field in your CSV \n[1][13]\n \no Set \"Target field\" to the district name field in your shapefile \n[1][13]\n \no Optionally check \"Custom field name prefix\" and leave it blank to avoid field name prefixes \n[1][13]\n \n4. Click \"OK\" and then \"Apply\" \n[1][13]\n. \n5. Verify the join by opening the attribute table of the districts layer, which should now include the \nmalaria data fields \n[1][13]\n. \nA successful join combines the geographic information from your districts layer with the health statistics \nfrom your CSV file \n[1][13]\n. If some districts are not joining properly, check for inconsistencies in spelling or \nformatting between the two datasets \n[1][13]\n. \n3.4 Creating a Choropleth Map with Graduated Symbology \nStep 7: Apply Graduated Symbology to Visualize Malaria Prevalence \n\n1. Right-click on the Uganda_districts layer and select \"Properties\" \n[1][12]\n. \n2. Go to the \"Symbology\" tab \n[1][12]\n. \n3. From the dropdown at the top, change from \"Single Symbol\" to \"Graduated\" \n[1][12]\n. \n4. For \"Value,\" select your malaria prevalence field \n[1][12]\n. \n5. Choose an appropriate color ramp (e.g., YlOrRd - yellow to orange to red) \n[1][12]\n. \n6. For \"Mode,\" select \"Natural Breaks (Jenks)\" \n[1][12]\n. \n7. Set the number of classes to 5 \n[1][12]\n. \n8. Click \"Classify\" to generate the class breaks \n[1][12]\n. \n9. Optionally, double-click on each class to adjust the ranges or labels \n[1][12]\n. \n10. Click \"Apply\" and \"OK\" \n[1][12]\n. \n\n \nQGIS interface showing a Uganda malaria mapping project with graduated symbology dialog \nThe graduated symbology visually represents the different levels of malaria prevalence across districts, \nmaking patterns easier to identify \n[1][12]\n. Yellow typically represents lower values while darker reds \nindicate higher prevalence areas \n[1][12]\n. \nStep 8: Customize the Classification Method \n1. Return to the layer properties and Symbology tab \n[1][24]\n. \n2. Experiment with different classification methods: \n\no Natural Breaks: Identifies inherent groupings in the data \n[1][24]\n \no Quantiles: Creates classes with equal numbers of features \n[1][24]\n \no Equal Interval: Creates equal-sized ranges \n[1][24]\n \no Standard Deviation: Based on deviation from the mean \n[1][24]\n \n3. Choose the method that best represents your data patterns \n[1][24]\n. \n \nComparison of GIS Data Classification Methods for Health Mapping \nDifferent classification methods can dramatically change how your data is visualized and interpreted \n[1][24]\n. Natural Breaks is often ideal for disease data as it identifies natural clusters, while Quantiles ensures \neach color is equally represented on the map \n[1][24]\n. \nStep 9: Customize the Color Ramp \n1. In the Symbology tab, click on the color ramp dropdown \n[1][12]\n. \n2. Select \"Create New Color Ramp\" \n[1][12]\n. \n3. Choose \"cpt-city\" for access to a wide range of professionally designed color schemes \n[1][12]\n. \n\n4. Browse categories like \"Health\" or \"Sequential\" to find appropriate gradients for disease mapping \n[1][12]\n. \n5. Select a color scheme and click \"OK\" \n[1][12]\n. \n \nThe QGIS color ramp selection dialog, displaying various color palettes categorized by theme for map \nsymbology. \nColor choice significantly impacts how audiences interpret your map \n[1][12]\n. For disease mapping, \nsequential color schemes (light to dark) effectively show intensity, while diverging schemes can highlight \nareas above or below a significant threshold \n[1][12]\n. \n3.5 Creating a Professional Map Layout \nStep 10: Create a New Print Layout \n\n1. Click on \"Project\" → \"New Print Layout\" \n[1][22]\n. \n2. Enter a name for your layout (e.g., \"Uganda Malaria Map\") and click \"OK\" \n[1][22]\n. \n3. In the print layout window, click on \"Add Item\" → \"Add Map\" from the menu \n[1][22]\n. \n4. Click and drag on the canvas to draw a rectangle where your map will appear \n[1][22]\n. \nThe print layout is where you transform your working map into a professional, presentation-ready \nproduct by adding essential cartographic elements \n[1][22]\n. Think of the layout as the frame that will \nshowcase your analytical work \n[1][22]\n. \nStep 11: Add Essential Map Elements \n1. Add a title: \no Click \"Add Item\" → \"Add Label\" \n[1][22]\n \no Draw a box at the top of your layout \n[1][22]\n \no In the Item Properties panel, enter \"Uganda Malaria Prevalence Map\" \n[1][22]\n \no Format the text to make it prominent (larger font size, bold) \n[1][22]\n \n2. Add a legend: \no Click \"Add Item\" → \"Add Legend\" \n[1][22]\n \no Draw a box on your layout \n[1][22]\n \no In Item Properties, customize the legend title and appearance \n[1][22]\n \no Check only the relevant layers to include \n[1][22]\n \n3. Add a north arrow: \no Click \"Add Item\" → \"Add North Arrow\" \n[1][22]\n \no Draw a small box in a corner of your layout \n[1][22]\n \no In Item Properties, choose an appropriate north arrow style \n[1][22]\n \n4. Add a scale bar: \no Click \"Add Item\" → \"Add Scale Bar\" \n[1][22]\n \no Draw a box on your layout \n[1][22]\n \no In Item Properties, set the units and segments to appropriate values \n[1][22]\n \n5. Add data sources and date: \n\no Click \"Add Item\" → \"Add Label\" \n[1][22]\n \no Draw a box at the bottom of your layout \n[1][22]\n \no Enter source information and map creation date \n[1][22]\n \n \nIllustration of common map elements, including the title, north arrow, scale bar, legend, and map body. \nEach map element serves a specific purpose in helping readers interpret your visualization \n[1][22]\n. The title \nidentifies the subject, the legend explains the symbology, the north arrow provides orientation, the scale \nbar communicates distances, and the data sources establish credibility \n[1][5]\n. \n\n \nQGIS Print Layout window showing a completed Uganda malaria map with legend, title, and map elements \n3.6 Exporting Your Map \nStep 12: Export the Map \n1. To export as an image: \no Click \"Layout\" → \"Export as Image\" \n[1][22]\n \no Choose resolution (300 dpi recommended for printing) \n[1][22]\n \no Select a folder and filename \n[1][22]\n \no Click \"Save\" \n[1][22]\n \n2. To export as a PDF: \no Click \"Layout\" → \"Export as PDF\" \n[1][22]\n \no Adjust settings as needed \n[1][22]\n \no Select a folder and filename \n[1][22]\n \n\no Click \"Save\" \n[1][22]\n \n3. To print directly: \no Click \"Layout\" → \"Print\" \n[1][22]\n \no Configure your printer settings \n[1][22]\n \no Click \"Print\" \n[1][22]\n \nThe export resolution and format should match your intended use \n[1][22]\n. Higher resolution (300 dpi) is \nsuitable for printed materials, while lower resolution (72-150 dpi) is appropriate for digital display or \npresentations \n[1][22]\n. \n4. Advanced Analysis Techniques for Malaria Mapping \n4.1 Effective Use of Classification Methods \nThe choice of classification method significantly impacts how your audience interprets the mapped data \n[1][24]\n. For malaria mapping in Uganda, consider these guidelines for choosing the most appropriate \nmethod \n[1][24]\n: \n• Natural Breaks (Jenks): Ideal for identifying natural clusters in malaria prevalence, highlighting \ntrue patterns in the data \n[24][6]\n. This method is particularly useful when looking for hotspots or when \ndata is unevenly distributed \n[1][24]\n. \n• Quantiles: Best when you need to rank districts from highest to lowest burden, ensuring each class \ncontains an equal number of districts \n[1][24]\n. This approach is useful for prioritization and comparing \nrelative positions \n[1][24]\n. \n• Equal Interval: Appropriate when comparing data across time periods or when working with \nstandardized rates \n[1][24]\n. Creates consistent ranges that are easy to interpret but may create empty \nclasses if data is skewed \n[1][24]\n. \n• Standard Deviation: Useful for research applications where showing statistical significance is \nimportant \n[1][24]\n. Works best with normally distributed data and helps identify outlier districts \n[1][24]\n. \n\n \nSimulated Malaria Prevalence Map of Uganda by District (cases per 1,000 population) \n4.2 Integrating Other Health and Environmental Data \nMalaria transmission is influenced by multiple factors beyond case counts \n[1][7]\n. To create more \ncomprehensive analyses, consider integrating: \n• Environmental data: Temperature, rainfall, elevation, and vegetation index can help explain \ntransmission patterns \n[1][7]\n \n• Population data: Helps calculate incidence rates and identify vulnerable populations \n[1][7]\n \n• Health facility data: Shows access to care and treatment availability \n[1][7]\n \n• Intervention coverage: Bed net distribution, indoor residual spraying, and other control measures \n[1][7]\n \n• Socioeconomic indicators: Poverty rates, housing quality, and education levels that may influence \nrisk \n[1][7]\n \n\nThese additional layers can be imported using the same methods as the district boundaries and joined \nspatially or by attribute \n[1][13]\n. The resulting multi-layer analysis provides a more complete picture of \nmalaria dynamics \n[1][7]\n. \n4.3 Temporal Analysis of Malaria Patterns \nMalaria transmission in Uganda follows seasonal patterns, with peaks during the rainy seasons (March-\nMay and October-December) \n[1]\n. To analyze temporal trends: \n1. Import time-series malaria data with month or season information \n[1][7]\n \n2. Use the \"Temporal Controller\" panel in QGIS to animate changes over time \n[1][19]\n \n3. Create multiple maps for different time periods in your print layout \n[1][22]\n \n4. Calculate and map percent change between time periods to identify trends \n[1][13]\n \nTemporal analysis helps identify seasonality, evaluate interventions, and detect unusual outbreaks that \nrequire investigation \n[1][7]\n. For Uganda, comparing dry and rainy season patterns can inform timing of \ninterventions \n[1]\n. \n5. Applications and Real-World Use Cases \n5.1 Supporting Public Health Decision Making \nGIS-based malaria mapping directly supports public health decisions in multiple ways \n[1][7]\n: \n• Resource allocation: Directing limited resources to highest-burden areas \n[1][7]\n \n• Intervention targeting: Deploying bed nets, indoor residual spraying, and case management where \nmost needed \n[1][7]\n \n• Health facility planning: Identifying gaps in healthcare access in high-burden areas \n[1][7]\n \n• Program evaluation: Measuring changes in spatial patterns following interventions \n[1][7]\n \n• Outbreak response: Rapidly identifying and responding to unusual increases in cases \n[1][7]\n \nMaps communicate complex spatial information more effectively than tables or text, making them \npowerful tools for advocating for resources and explaining strategies to stakeholders \n[1][8]\n. \n5.2 Recommendations for Effective Health Mapping \nWhen creating malaria maps for Uganda's health sector, follow these best practices \n[1][8]\n: \n\n• Know your audience: Create different versions for policymakers, health professionals, and the \npublic \n[1][8]\n \n• Choose appropriate metrics: Consider using rates (cases per 1,000 population) rather than raw \ncounts to account for population differences \n[1][7]\n \n• Include context: Complement disease maps with relevant boundaries, major cities, and key \ngeographic features \n[1][8]\n \n• Mind your colors: Ensure maps are color-blind friendly and consider cultural associations with \ncolors \n[1][8]\n \n• Maintain data integrity: Clearly communicate data limitations and uncertainty \n[1][8]\n \n• Provide interpretation: Include brief analysis points highlighting key patterns \n[1][8]\n \nEffective health maps balance technical accuracy with clarity and ease of interpretation \n[1][8]\n. The most \nsuccessful maps prompt action and inform decisions rather than merely displaying data \n[1][8]\n. \n6. Conclusion and Next Steps \nThis enhanced QGIS tutorial provides a comprehensive foundation for creating professional malaria maps \nusing Uganda as a case study \n[1][18]\n. The skills developed here—from data management to visualization \nand layout design—are transferable to mapping other diseases and public health challenges \n[1][8]\n. \nTo continue developing your health GIS skills: \n• Practice with different datasets and disease indicators \n[1][18]\n \n• Learn advanced spatial analysis techniques like hotspot detection \n[1][13]\n \n• Explore time-series visualization methods \n[1][7]\n \n• Integrate remote sensing data for environmental analysis \n[1][7]\n \n• Develop interactive web maps to share your findings \n[1][8]\n \nBy mastering these techniques, you contribute to the growing field of spatial epidemiology and support \nevidence-based public health decision-making in Uganda and beyond \n[1][6]\n. Geographic information \nsystems have become indispensable tools in the fight against malaria and other infectious diseases, \nproviding clarity and direction to complex health challenges \n[1][6]\n. \n⁂ \n \n\n1. Lab_1_Malaria.pdf                                                                                                                                                                         \n2. https://targetmalaria.org/virtual-press-room/uganda-virtual-press-kit/     \n3. https://pubmed.ncbi.nlm.nih.gov/37208120/   \n4. https://gh.bmj.com/content/8/5/e011137     \n5. https://rr-africa.woah.org/app/uploads/2023/09/04-john_up_qgis.pdf       \n6. https://lib.guides.umd.edu/spatialepi         \n7. https://learn.arcgis.com/en/projects/monitor-malaria-epidemics/                       \n8. https://www.govpilot.com/blog/health-department-gis-map               \n9. https://uniph.go.ug/timeliness-and-completeness-of-monthly-disease-surveillance-data-reporting-in-uganda-\n2020─2021/     \n10. https://uniph.go.ug/wp-content/uploads/2022/03/Weekly-surveillance-data-reporting-on-epidemic-prone-\ndiseases-Uganda-2020–2021.pdf     \n11. https://www.maya-climate.com/post/gis-data-formats   \n12. https://www.youtube.com/watch?v=POi7ei3pLPo                     \n13. https://docs.qgis.org/latest/en/docs/training_manual/vector_analysis/basic_analysis.html                       \n14. https://gis.stackexchange.com/questions/381088/choosing-projected-crs-for-uganda           \n15. https://www.gim-international.com/content/article/establishing-an-accurate-geodetic-reference-network-for-\nuganda   \n16. https://tool-online.com/index/systemes-coordonnees/uganda.html      \n17. https://www.expertgps.com/convert-coordinates/uganda.asp       \n18. https://etch.lstmed.ac.uk/sites/default/files/centre/gives/gives1-3day-malaria-day1.pdf               \n19. https://cartinal.leventhalmap.org/guides/get-started-qgis/interface.html              \n20. https://www.youtube.com/watch?v=6lCTPJHo2eQ       \n21. https://centerforspatialresearch.github.io/methods-in-spatial-research-sp2020/tutorials/01_organizing-viewing-\nspatial-data-in-qgis.html    \n22. https://docs.qgis.org/latest/en/docs/user_manual/print_composer/overview_composer.html                                          \n\n23. https://www.reddit.com/r/QGIS/comments/1hk436l/how_do_i_create_a_qgis_map_on_vector_disease/  \n24. https://community.environicsanalytics.com/hc/en-us/articles/13299751591437-What-are-the-Mapping-\nClassification-Methods                   \n\n## Document Information\n- **Source**: PDF Document (22 pages)\n- **Category**: tutorial\n- **Difficulty**: intermediate\n- **Relevant Labs**: lab1\n- **Topics**: arcgis, classification, coordinate system, crs, gis, malaria, mapping, projection, public health, qgis, raster, remote sensing, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 1 enhanced qgis tutorial\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- arcgis\n- classification\n- coordinate system\n- crs\n- gis\n- malaria\n- mapping\n- projection\n- public health\n- qgis\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [
        "arcgis",
        "classification",
        "coordinate system",
        "crs",
        "gis",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "qgis",
        "raster",
        "remote sensing",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\lab_1_enhanced_qgis_tutorial.md",
      "filename": "lab_1_enhanced_qgis_tutorial.md"
    }
  },
  {
    "id": "concepts-lab_1_malaria",
    "title": "Enhanced QGIS Malaria Mapping Tutorial - Complete Guide",
    "content": "\n# Enhanced QGIS Malaria Mapping Tutorial - Complete Guide\n\n\n\nEnhanced QGIS Malaria Mapping Tutorial\nTable of Contents\n1. Public Health Context\n• Malaria Epidemiology\n• Transmission Cycle\n• Global and Regional Burden\n• Importance of Spatial Analysis\n2. GIS and Disease Mapping Fundamentals\n• Key Concepts and Terminology\n• Vector vs Raster Data\n• Coordinate Reference Systems\n• Choropleth Mapping Principles\n3. Understanding Health Data\n• Malaria Prevalence Measures\n• Data Collection Methods\n• Surveillance Systems\n• Data Quality Considerations\n4. Uganda Malaria Context\n• Endemic Zones\n• District-level Health Planning\n• National Control Program\n5. Step-by-Step QGIS Tutorial\n• Project Setup\n• Data Loading\n• Table Joins\n• Symbology and Classification\n• Layout and Export\n6. Data Classification and Visualization\n• Classification Methods\n• Color Theory for Health Maps\n• Interpretation Guidelines\n7. Map Design for Public Health\n• Layout Principles\n• Effective Communication\n• Professional Presentation\n8. Applications and Extensions\n• Real-world Use Cases\n• Integration with Other Data\n• Future Directions\n1. Public Health Context\n1.1 Introduction to Malaria Epidemiology\nWhat is Malaria?\nMalaria is a life-threatening disease caused by parasites that are transmitted to people through the bites of infected female Anopheles\nmosquitoes. It is preventable and curable, yet it continues to be a major public health challenge globally.\nKey Facts:\n5 parasite species cause malaria in humans\nPlasmodium falciparum is the most deadly\nTransmitted by Anopheles mosquitoes\nSymptoms include fever, headache, and vomiting\nCan be fatal if untreated within 24 hours\nGlobal Impact:\n247 million cases globally in 2021\n619,000 deaths in 2021\nChildren under 5 most vulnerable\n95% of cases occur in Africa\nMajor cause of poverty and reduced productivity\n1.2 Malaria Transmission Cycle\nFigure 1.1: Malaria transmission cycle showing the complex interaction between human host, parasite, and mosquito vector\nHuman Stage\n1. Infected mosquito bites human\n2. Sporozoites enter bloodstream\n3. Parasites travel to liver\n4. Multiplication in liver cells\n5. Release into bloodstream\n6. Infection of red blood cells\n7. Symptoms develop\nMosquito Stage\n1. Mosquito bites infected human\n2. Gametocytes ingested\n3. Sexual reproduction in gut\n4. Oocyst formation\n5. Sporozoite development\n6. Migration to salivary glands\n7. Ready for transmission\n1.3 Burden in Uganda\nUganda Malaria Statistics\nAnnual Cases~15 million\nDeaths per Year~10,000-15,000\nPopulation at Risk95% of population\nEconomic Impact$500 million annually\nHealthcare Burden30-50% of outpatient visits\nMap of Uganda showing malaria endemicity\nFigure 1.2: Map of Uganda showing malaria endemicity levels across different\nregions\n1.4 Importance of Spatial Analysis in Disease Control\nWhy Map Disease?\nIdentify hotspots: Locate areas with high transmission\nResource allocation: Direct interventions where needed most\nMonitor trends: Track changes over time and space\nEvaluate programs: Assess intervention effectiveness\nPredict outbreaks: Anticipate disease spread patterns\nApplications in Malaria Control\nBed net distribution: Target high-risk areas\nIndoor spraying: Prioritize intervention areas\nHealth facility planning: Improve access to care\nSurveillance systems: Monitor disease patterns\nResearch planning: Guide scientific studies\n2. GIS and Disease Mapping Fundamentals\n2.1 Key Concepts and Terminology\nTermDefinitionApplication in Health\nGIS (Geographic Information\nSystem)\nA system for capturing, storing, analyzing, and\nvisualizing spatial data\nDisease surveillance, outbreak investigation,\nhealth service planning\nVector DataData represented as points, lines, or polygons\nHealth facilities (points), roads (lines), districts\n(polygons)\nRaster DataData stored in a grid of cells\nSatellite imagery, elevation models, population\ndensity\nAttribute TableDatabase table linked to spatial featuresDisease counts, population data, health indicators\nChoropleth Map\nThematic map with areas colored by statistical\nvalues\nDisease rates, prevalence, mortality ratios\nSpatial JoinCombining datasets based on locationLinking health data to administrative boundaries\n2.2 Vector vs Raster Data\nFigure 2.1: Vector data types - Points, Lines, and Polygons used in spatial analysis\nVector Data in Health GIS\nPoints\nHealth facilities, disease cases, surveillance sites\nLines\nRoads for accessibility analysis, rivers for disease transmission\nPolygons\nAdministrative boundaries, catchment areas, endemic zones\nRaster Data in Health GIS\nContinuous Surfaces\nTemperature, rainfall, elevation affecting disease transmission\nSatellite Imagery\nLand cover, water bodies, urban development\nModeled Surfaces\nPopulation density, risk surfaces, interpolated values\n2.3 Coordinate Reference Systems (CRS)\nWhy CRS Matters in Health Mapping\nCoordinate Reference Systems define how the curved surface of the Earth is represented on a flat map. Choosing the right CRS is\ncrucial for accurate distance measurements, area calculations, and spatial analysis in health applications.\nCommon CRS for Uganda:\nWGS84 (EPSG:4326): Global standard for GPS\nUTM Zone 36N (EPSG:32636): Best for eastern Uganda\nUTM Zone 35N (EPSG:32635): Best for western Uganda\nHealth Applications:\nAccurate distance calculations\nProper area measurements\nSpatial analysis accuracy\nGPS data integration\n2.4 Choropleth Mapping Principles\nChoropleth Maps in Disease Mapping\nChoropleth maps use color or shading to represent statistical values across geographic areas. They are essential for visualizing\ndisease patterns, health indicators, and epidemiological data.\nData Requirements:\nAggregated to areas\nStandardized rates\nComparable units\nQuality assured\nDesign Principles:\nIntuitive color schemes\nAppropriate classifications\nClear legends\nProper labeling\nHealth Applications:\nDisease prevalence\nMortality rates\nRisk factors\nHealth outcomes\n3. Understanding Health Data\n%3.1 Malaria Prevalence Measures\nKey Malaria Indicators\nPrevalence\nProportion of population infected at a\nspecific time\nIncidenceNumber of new cases per unit time\nMortality Rate\nDeaths per unit population per time\nperiod\nCase Fatality\nRate\nProportion of cases that result in death\nCalculation Examples\nPrevalence Rate\n= (Number of cases / Total population) × 100\nExample: 500 cases / 10,000 people = 5%\nIncidence Rate\n= (New cases / Population at risk) × Time period\nExample: 200 new cases / 10,000 / year = 20 per 1,000 per year\n3.2 Data Collection Methods\nFigure 3.1: Disease surveillance system showing data flow from collection to analysis and action\nPassive Surveillance\nRoutine reporting from health facilities\nAdvantages:\nCost-effective\nContinuous data collection\nWide geographic coverage\nIntegrates with health system\nLimitations:\nUnderreporting common\nQuality varies by facility\nDelayed reporting\nBias toward severe cases\nActive Surveillance\nSystematic collection through surveys and studies\nAdvantages:\nHigher data quality\nStandardized methods\nRepresentative samples\nCaptures asymptomatic cases\nLimitations:\nExpensive to implement\nTime-consuming\nLimited geographic coverage\nPeriodic rather than continuous\n3.3 Surveillance Systems\nUganda's Malaria Surveillance Framework\nHealth Management Information System\n(HMIS)\nMonthly facility reporting\nStandardized indicators\nDistrict-level aggregation\nNational database\nMalaria Surveillance System\nCase-based reporting\nOutbreak detection\nDrug resistance monitoring\nVector surveillance\nCommunity-Based Surveillance\nVillage health teams\nCommunity case management\nRapid diagnostic tests\nMobile data collection\n3.4 Data Quality Considerations\n⚠Common Data Quality Issues\nCompleteness: Missing data from some facilities\nTimeliness: Delayed reporting affects outbreak response\nAccuracy: Diagnostic errors, recording mistakes\nConsistency: Different definitions or methods\nRepresentativeness: Data may not reflect true burden\nData Quality Improvement\nValidation rules: Automated checks for consistency\nTraining programs: Standardized data collection\nFeedback systems: Data quality reports to facilities\nSupervision: Regular quality assurance visits\nTechnology: Electronic systems reduce errors\n4. Uganda Malaria Context\n4.1 Endemic Zones and Transmission Patterns\nTransmission Zones in Uganda\nZoneCharacteristicsRegions\nHyperendemic\nYear-round\ntransmission, high\nprevalence\nCentral, Eastern,\nWestern lowlands\nMesoendemic\nSeasonal\ntransmission,\nmoderate\nprevalence\nNorthern Uganda,\nsome highland\nareas\nHypoendemic\nLow transmission,\nepidemic-prone\nSouthwestern\nhighlands,\nKaramoja\nEnvironmental Factors\nAltitude: Lower transmission above 1,500m\nRainfall: Seasonal patterns affect breeding\nTemperature: Optimal range 20-30°C\nHumidity: High humidity favors mosquitoes\nWater bodies: Breeding sites for vectors\nSeasonal Patterns\nPeak Transmission Seasons:\nMarch-May: Long rainy season\nOctober-December: Short rainy season\nPost-harvest: Increased breeding sites\nLow Transmission Periods:\nJune-September: Dry season\nJanuary-February: Short dry season\nReduced breeding sites\nVector Species\nAn. gambiae s.s.: Major vector, anthropophilic\nAn. arabiensis: Zoophilic, outdoor biting\nAn. funestus: Highly efficient vector\nAn. nili: Riverine breeding\n4.2 District-Level Health Planning\nUganda's Decentralized Health System\nUganda's health system operates through a decentralized structure where districts play a crucial role in health service delivery and\ndisease control. Understanding this structure is essential for effective malaria mapping and intervention planning.\nNational Level\nMinistry of Health\nPolicy formulation\nResource allocation\nTechnical guidance\nMonitoring & evaluation\nDistrict Level\nDistrict Health Offices\nService delivery\nLocal planning\nResource management\nData collection\nCommunity Level\nHealth facilities\nVillage Health Teams\nDirect service provision\nCommunity mobilization\nCase management\n4.3 National Malaria Control Program\nControl Strategies\nVector Control\nLong-lasting insecticidal nets (LLINs)\nIndoor residual spraying (IRS)\nLarval source management\nCommunity education\nCase Management\nRapid diagnostic tests\nArtemisinin-based therapy\nCommunity case management\nSevere malaria treatment\nPrevention Strategies\nIntermittent Preventive Treatment\nPregnant women (IPTp)\nInfants (IPTi)\nSchool-age children (IPTsc)\nSeasonal malaria chemoprevention\nSurveillance & Response\nOutbreak detection\nEpidemic response\nDrug resistance monitoring\nVector resistance surveillance\nWhy District-Level Mapping Matters\nDistrict-level malaria mapping is crucial for effective public health planning and resource allocation in Uganda's decentralized health\nsystem:\nResource allocation: Districts receive funding based on disease burden\nIntervention targeting: Allows for tailored control strategies\nPerformance monitoring: Tracks progress against targets\nEquity assessment: Identifies underserved populations\nOutbreak preparedness: Enables rapid response capacity\n5. Step-by-Step QGIS Tutorial\n▶5.1 Getting Started with QGIS\nStep 1: Launch QGIS and Create New Project\nFigure 5.1: QGIS startup screen with project options and recent files\nWhat to Do:\n1. Open QGIS from your applications menu\n2. Click Project → New from the menu bar\n3. Save your project immediately: Project → Save As\n4. Name it: Malaria_Mapping_Uganda.qgz\n5. Choose an appropriate folder for your project\nWhy This Matters:\nSaves your work and settings\nAllows you to resume later\nPreserves layer styling and layouts\nEnables sharing with colleagues\n5.2 Loading Spatial Data\nStep 2: Load Uganda District Boundaries\nFigure 5.2: Add Vector Layer dialog for loading spatial data\nDetailed Steps:\n1. Go to Layer → Add Layer → Add Vector Layer\n2. Click the Browse (...) button\n3. Navigate to your data folder\n4. Select Uganda_districts.gpkg\n5. Click Open, then Add\n6. The districts should appear on your map\nTroubleshooting:\nLayer not visible? Right-click layer → Zoom to Layer\nWrong colors? We'll fix this in symbolization\nError loading? Check file path and format\nProjection issues? QGIS usually handles automatically\n5.3 Loading Tabular Data\nStep 3: Import Malaria Prevalence Data\nFigure 5.3: Add Delimited Text Layer dialog for importing CSV data\nStep-by-Step Process:\n1. Go to Layer → Add Layer → Add Delimited Text Layer\n2. Click Browse (...) and select malaria_prevalence_uganda.csv\n3. Verify File Format is set to CSV\n4. Under Geometry Definition, select No geometry\n5. Preview the data in the sample section\n6. Click Add to import the table\nData Preview Check:\nDistrict names should match exactly\nPrevalence values should be numeric\nNo unusual characters or formatting\nHeaders should be clear and descriptive\n5.4 Joining Spatial and Tabular Data\nStep 4: Create Table Join\nFigure 5.4: Layer Properties Joins tab for connecting spatial and tabular data\nJoin Configuration:\n1. Right-click on Uganda_districts layer\n2. Select Properties from context menu\n3. Go to the Joins tab\n4. Click the + (Add) button\n5. Set Join layer to your CSV file\n6. Set Join field to district name in CSV\n7. Set Target field to district name in shapefile\n8. Click OK twice to apply\nCritical Success Factors:\nExact name matching: District names must be identical\nNo extra spaces: Trim whitespace from names\nConsistent spelling: Check for typos\nSame case: Consider case sensitivity\n⚠Common Join Problems\nIssues:\nNames don't match exactly\nExtra spaces in text fields\nDifferent spelling conventions\nSpecial characters in names\nSolutions:\nUse attribute table to compare names\nCreate lookup table for mismatches\nUse text processing tools to clean data\nStandardize naming conventions\n5.5 Creating Choropleth Visualization\nStep 5: Apply Graduated Symbology\nFigure 5.5: Graduated symbology dialog for creating choropleth maps\nSymbology Configuration:\n1. Right-click districts layer → Properties\n2. Go to Symbology tab\n3. Change from Single Symbol to Graduated\n4. Set Value to malaria prevalence field\n5. Choose Color ramp (e.g., Reds)\n6. Set Mode (Natural Breaks recommended)\n7. Set number of Classes (5-7 works well)\n8. Click Classify to generate classes\n9. Click OK to apply\nDesign Considerations:\nColor choice: Red intensity for disease burden\nClassification: Natural breaks for meaningful groups\nClass number: 5-7 classes for readability\nLegend labels: Clear, rounded values\n⎙5.6 Creating Professional Map Layout\nStep 6: Design Print Layout\nFigure 5.6: Complete print layout with all essential map elements\nLayout Elements:\n1. Go to Project → New Print Layout\n2. Name it: Malaria_Map_Layout\n3. Add Map using Add Map tool\n4. Add Legend using Add Legend tool\n5. Add Title using Add Label tool\n6. Add Scale Bar using Add Scale Bar tool\n7. Add North Arrow using Add North Arrow tool\n8. Add Data Sources and Date\nProfessional Tips:\nAlignment: Use guides and grids\nSpacing: Consistent margins and gaps\nFonts: Readable, professional typefaces\nColors: High contrast for readability\n6. Data Classification and Visualization\n6.1 Classification Methods Comparison\nFigure 6.1: Comparison of different classification methods showing how they affect data interpretation\nNatural Breaks (Jenks)\nCreates classes based on natural groupings in the data\ndistribution\nWhen to Use:\nData has natural clusters\nWant to show meaningful patterns\nDefault choice for most health data\nAdvantages:\nStatistically optimal groupings\nReveals natural patterns\nGood for varied distributions\nQuantile (Equal Count)\nEach class contains the same number of features\nWhen to Use:\nWant equal representation\nData has extreme outliers\nComparing relative positions\nAdvantages:\nGood color distribution\nHandles outliers well\nShows relative ranking\nEqual Interval\nClasses have equal ranges between minimum and maximum\nvalues\nWhen to Use:\nComparing across time/space\nData is evenly distributed\nNeed consistent intervals\nConsiderations:\nMay create empty classes\nSensitive to outliers\nEasy to interpret\nStandard Deviation\nClasses based on standard deviations from the mean\nWhen to Use:\nNormally distributed data\nWant to show deviation from average\nStatistical analysis focus\nAdvantages:\nShows statistical significance\nHighlights outliers\nGood for research\n6.2 Color Theory for Health Maps\nChoosing Appropriate Colors for Disease Maps\nColor selection in health mapping is crucial for effective communication and can significantly impact how audiences interpret your\ndata.\nSequential Colors\nFor ordered data (low to high prevalence)\nReds: Disease burden, mortality\nOranges: Infection rates, cases\nBlues: Water-related diseases\nGreens: Vaccination coverage\nDiverging Colors\nFor data with meaningful midpoint\nRed-White-Blue: Above/below target\nBrown-White-Green: Decrease/increase\nUse when comparing to benchmark\nCenter on meaningful value\nAccessibility\nEnsure colors work for all audiences\nColorblind-friendly palettes\nHigh contrast ratios\nAvoid red-green combinations\nTest with grayscale conversion\n6.3 Interpretation Guidelines\nReading Choropleth Maps\nPattern recognition: Look for spatial clusters\nOutlier identification: Unusual high/low values\nBoundary effects: Consider administrative boundaries\nData availability: Check for missing areas\nPopulation density: Consider underlying population\nCommon Interpretation Pitfalls\nEcological fallacy: Don't assume area-level patterns apply to\nindividuals\nModifiable areal unit: Patterns may change with different boundaries\nVisual bias: Larger areas appear more important\nColor bias: Brighter colors draw more attention\nClassification effects: Different methods show different patterns\n7. Map Design for Public Health\n7.1 Layout Principles\nEssential Map Elements\nTitle\nClear, descriptive, includes location and\ntime\nLegend\nExplains symbols, colors, and\nclassifications\nScale BarShows distance relationships\nNorth\nArrow\nIndicates orientation\nData SourceCredits and data attribution\nDateWhen map was created\nDesign Hierarchy\nPrimary Focus\nThe map itself - should dominate the layout\nSecondary Elements\nTitle, legend - important but supporting\nTertiary Elements\nScale bar, north arrow, credits - necessary but subtle\n7.2 Effective Communication\nAudience-Specific Design\nPolicymakers\nSimple, clear patterns\nFocus on key messages\nMinimal technical detail\nAction-oriented titles\nInclude cost implications\nHealth Professionals\nDetailed classifications\nStatistical measures\nConfidence intervals\nMethodological notes\nClinical relevance\nGeneral Public\nIntuitive color schemes\nFamiliar geographic areas\nClear, simple language\nAvoid technical jargon\nInclude prevention messages\n7.3 Professional Presentation\nTypography Guidelines\nFont choice: Sans-serif for digital, serif for print\nSize hierarchy: Title (18-24pt), subtitle (14-16pt), body (10-12pt)\nConsistency: Limit to 2-3 font families maximum\nReadability: High contrast, appropriate spacing\nAlignment: Consistent left, center, or right alignment\nQuality Assurance\nAccuracy: Verify all data and calculations\nCompleteness: Include all necessary elements\nConsistency: Standardize formatting throughout\nClarity: Test with intended audience\nAttribution: Proper credits and data sources\n8. Applications and Extensions\n8.1 Real-World Use Cases\nOutbreak Investigation\nMapping disease cases to identify patterns and sources\nCase mapping: Plot individual cases by location and time\nCluster detection: Identify unusual concentrations\nSource identification: Map potential exposure sources\nContact tracing: Visualize transmission chains\nControl measures: Target interventions geographically\nResource Allocation\nUsing disease burden maps to guide resource distribution\nBed net distribution: Prioritize high-transmission areas\nStaff deployment: Allocate personnel based on need\nFacility planning: Site new clinics optimally\nSupply chain: Stock medications where needed\nBudget allocation: Distribute funds equitably\nProgram Evaluation\nAssessing the effectiveness of health interventions\nBefore/after comparisons: Map changes over time\nIntervention coverage: Visualize program reach\nImpact assessment: Measure reduction in disease burden\nEquity analysis: Identify underserved populations\nCost-effectiveness: Map outcomes relative to investment\nSurveillance Systems\nRoutine monitoring of disease patterns\nTrend monitoring: Track changes over time\nSeasonal patterns: Identify predictable cycles\nEarly warning: Detect emerging threats\nPerformance indicators: Monitor system effectiveness\nQuality assurance: Identify data gaps\n8.2 Integration with Other Health Data\nMulti-Disease Mapping\nCombining malaria data with other health indicators for comprehensive analysis\nCo-morbidities\nHIV/AIDS prevalence\nTuberculosis rates\nMalnutrition levels\nMaternal mortality\nChild health indicators\nRisk Factors\nSocioeconomic status\nEducation levels\nAccess to healthcare\nEnvironmental factors\nBehavioral indicators\nHealth Systems\nFacility distribution\nService availability\nStaff deployment\nSupply chain status\nQuality measures\n→8.3 Future Directions\nTechnology Integration\nReal-time data: Mobile data collection and transmission\nSatellite imagery: Environmental monitoring and prediction\nMachine learning: Automated pattern detection\nWeb platforms: Interactive dashboards and maps\nMobile apps: Field data collection and validation\nAdvanced Analytics\nSpatial statistics: Hotspot analysis and clustering\nPredictive modeling: Forecasting disease outbreaks\nRisk assessment: Vulnerability mapping\nNetwork analysis: Transmission pathway modeling\nTime series: Temporal pattern analysis\nContinuing Your GIS Journey\nThis tutorial provides a foundation for disease mapping. To advance your skills:\nPractice regularly: Work with different datasets and diseases\nLearn statistics: Understand spatial analysis methods\nJoin communities: Connect with other GIS professionals\nTake courses: Formal training in spatial epidemiology\nStay updated: Follow developments in health GIS\nReferences and Further Reading\nKey References\n1. World Health Organization. (2022). World Malaria Report 2022. Geneva: World Health Organization.\n2. Uganda Ministry of Health. (2020). Uganda Malaria Reduction Strategic Plan 2021-2025. Kampala: MoH.\n3. Brewer, C.A., & Pickle, L. (2002). Evaluation of methods for classifying epidemiological data on choropleth maps in series. Annals of the Association of\nAmerican Geographers, 92(4), 662-681.\n4. Moore, D.A., & Carpenter, T.E. (1999). Spatial analytical methods and geographic information systems: use in health research and epidemiology.\nEpidemiologic Reviews, 21(2), 143-161.\n5. Rytkönen, M.J.P. (2004). Not all maps are equal: GIS and spatial analysis in epidemiology. International Journal of Circumpolar Health, 63(1), 9-24.\nAdditional Resources\nQGIS Learning Resources\nQGIS Documentation: docs.qgis.org\nQGIS Tutorials: qgistutorials.com\nQGIS Community: qgis.org/community\nTraining Materials: QGIS official training manual\nHealth GIS Resources\nCDC GIS Resources: cdc.gov/gis\nWHO Health Atlas: who.int/data/gho\nSpatial Epidemiology Network: Spatial-epi.org\nHealth Mapping Resources: healthmap.org\nEnhanced QGIS Malaria Mapping Tutorial\nComplete Guide to Disease Mapping in Public Health\nComprehensive Resource for Spatial Epidemiology and GIS Applications\nComplete Guide to Disease Mapping in Public Health\n© 2024 - Educational Resource for Public Health GIS\n\n## Document Information\n- **Source**: PDF Document (1 pages)\n- **Category**: lab-material\n- **Difficulty**: intermediate\n- **Relevant Labs**: lab1\n- **Topics**: accessibility, classification, clustering, crs, gis, machine learning, malaria, mapping, projection, public health, qgis, raster, satellite, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain enhanced qgis malaria mapping tutorial - complete guide\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- classification\n- clustering\n- crs\n- gis\n- machine learning\n- malaria\n- mapping\n- projection\n- public health\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [
        "accessibility",
        "classification",
        "clustering",
        "crs",
        "gis",
        "machine learning",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "qgis",
        "raster",
        "satellite",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\lab_1_malaria.md",
      "filename": "lab_1_malaria.md"
    }
  },
  {
    "id": "concepts-lab_2_enhanced_qgis_healthfacility_access",
    "title": "Lab 2 Enhanced QGIS HealthFacility Access",
    "content": "\n# Lab 2 Enhanced QGIS HealthFacility Access\n\n\n\n \nEnhanced QGIS Health Facility Access Analysis \nTutorial: A Comprehensive Guide to Spatial \nAccessibility and Public Health Equity \n1. Introduction to Healthcare Accessibility and Spatial Analysis \n1.1 The Critical Importance of Healthcare Accessibility \nHealthcare accessibility represents one of the most fundamental determinants of health outcomes and a \ncornerstone of health equity \n[1]\n. In Uganda, where approximately 86.6% of the population lives in rural \nareas, geographic barriers to healthcare access create substantial disparities in health outcomes and \ncontribute to preventable morbidity and mortality \n[2]\n. Spatial accessibility, defined as the ease with which \nindividuals can reach healthcare services from their location, encompasses both physical distance and the \navailability of transportation infrastructure \n[3]\n. \n\n \nA newly opened clinic building with a green roof and yellow walls, surrounded by people in rural Eastern \nUganda. \nThe relationship between geographic access and health outcomes is particularly pronounced for time-\nsensitive conditions like malaria, where delayed treatment significantly increases the risk of severe \ncomplications and death \n[4]\n. Research demonstrates that mortality in children under 5 years doubles when \nhealthcare facilities are more than a 4-hour walk away, emphasizing the life-or-death importance of \nspatial accessibility analysis \n[5]\n. In Uganda's context, where malaria accounts for 30-50% of all outpatient \nvisits, understanding and improving spatial access patterns becomes essential for reducing disease \nburden and achieving health equity \n[6]\n. \n1.2 Understanding Uganda's Health System Hierarchy \nUganda's decentralized health system operates through a well-defined hierarchy designed to provide \ncomprehensive coverage across diverse geographic and demographic contexts \n[7]\n. The system consists of \nseven levels, each serving specific population catchments and providing defined service packages \n[8]\n. At \nthe community level, Village Health Teams (Level I) serve approximately 1,000-2,000 people and provide \n\nbasic health education and referrals \n[9]\n. Health Centre II facilities, intended to serve 5,000 people, offer \noutpatient services and are typically staffed by enrolled nurses \n[9]\n. \nThe intermediate levels include Health Centre III facilities serving 20,000-40,000 people with basic \ninpatient services and laboratory capabilities, and Health Centre IV facilities serving 100,000-200,000 \npeople with surgical capacity and specialized care \n[10]\n. District hospitals provide comprehensive services \nfor populations of 500,000-1,000,000, while regional referral hospitals and national referral hospitals \noffer increasingly specialized care \n[9]\n. This hierarchical structure creates the spatial framework within \nwhich accessibility analysis becomes crucial for health planning and resource allocation. \n1.3 The Science of Spatial Accessibility Measurement \nSpatial accessibility measurement in healthcare has evolved from simple distance-based metrics to \nsophisticated models that account for multiple factors influencing access \n[11]\n. Traditional approaches using \nEuclidean (straight-line) distance provide useful approximations but fail to capture the realities of road \nnetworks, topographic barriers, and transportation availability \n[12]\n. More advanced methods incorporate \ntravel time, facility capacity, population demand, and competing destinations to create realistic \naccessibility measures \n[13]\n. \n\n \nGeospatial analysis showing healthcare accessibility under walking-only and motorized plus walking \nscenarios, illustrating population coverage and facility catchments. \nThe choice of distance threshold for accessibility analysis significantly impacts policy recommendations \nand resource allocation decisions \n[12]\n. International guidelines suggest that 1-2 hours of travel time \nrepresents acceptable access to health services, though this varies by service level and urgency \n[12]\n. For \nUganda's context, where walking remains the primary mode of transportation for many rural residents, \n\nthe 10-kilometer buffer used in this tutorial represents approximately 2-3 hours of walking time, aligning \nwith WHO recommendations for basic health service access \n[14]\n. \n2. Theoretical Foundations of Buffer Analysis and Spatial Queries \n2.1 Buffer Analysis in Health Geography \nBuffer analysis represents one of the most fundamental techniques in health geography, creating zones of \nspecified distance around geographic features to analyze spatial relationships and accessibility patterns \n[15]\n. In healthcare applications, buffers around health facilities represent service catchment areas, helping \nidentify populations within reasonable access distances and highlighting underserved areas requiring \nintervention \n[16]\n. The technique assumes that people are more likely to access services within the buffer \nzone, though actual utilization patterns may vary based on factors including service quality, \ntransportation availability, and cultural preferences \n[11]\n. \n \nHealthcare utilization decreases exponentially with distance, supporting 10km buffer analysis \n\nThe distance decay effect, fundamental to understanding healthcare utilization patterns, demonstrates \nthat healthcare use decreases exponentially with distance from facilities \n[11]\n. This relationship justifies the \nuse of buffer analysis and provides empirical support for distance-based accessibility thresholds. \nResearch from sub-Saharan Africa consistently shows dramatic decreases in facility utilization beyond 5-\n10 kilometers, supporting the choice of 10-kilometer buffers for identifying adequately served \npopulations \n[12]\n. \n2.2 Spatial Query Theory and Applications \nSpatial queries enable analysts to identify complex geographic relationships between different layers of \nspatial data, moving beyond simple visual analysis to quantitative assessment of accessibility patterns \n[17]\n. \nThe fundamental spatial relationships used in accessibility analysis include intersects (overlapping areas), \ncontains (complete containment), and disjoint (no overlap), each providing different insights into access \npatterns \n[17]\n. For healthcare accessibility, the \"do not intersect\" relationship identifies populations \ncompletely outside service catchment areas, representing the most underserved areas requiring \nimmediate attention \n[18]\n. \n \nQGIS spatial query interface demonstrating selection of regions that contain airports. \n\nThe power of spatial queries lies in their ability to combine multiple criteria, enabling analysts to identify \nareas with compound disadvantages such as high disease burden and poor access \n[17]\n. This analytical \ncapability transforms simple mapping into sophisticated equity analysis, revealing hidden patterns of \nhealth inequality and guiding evidence-based intervention strategies \n[3]\n. \n2.3 Coordinate Reference Systems for Uganda \nAccurate spatial analysis requires appropriate coordinate reference systems (CRS) that minimize \ndistortion and enable precise distance measurements \n[19]\n. For Uganda, several coordinate systems are \ncommonly used, each with specific applications and advantages \n[20]\n. The WGS 84 geographic coordinate \nsystem (EPSG:4326) provides global compatibility and GPS integration but lacks the metric properties \nnecessary for accurate distance calculations \n[21]\n. \nFor analytical work requiring precise distance measurements, projected coordinate systems offer \nsuperior accuracy \n[20]\n. UTM Zone 36N (EPSG:32636) provides excellent coverage for most of Uganda, \noffering meter-based measurements essential for buffer analysis and distance calculations \n[21]\n. This \ncoordinate system covers the area between 30°E and 36°E in the northern hemisphere, encompassing \nUganda's entire territory with minimal distortion \n[22]\n. \n3. Comprehensive Step-by-Step QGIS Tutorial \n3.1 Project Setup and Initial Configuration \nStep 1: Create and Configure Your QGIS Project \nBegin by launching QGIS and creating a new project specifically for healthcare accessibility analysis \n[23]\n. \nNavigate to Project → New to start fresh, then immediately save your project using Project → Save As with \nthe filename \"Uganda_Health_Facility_Access_Analysis.qgz\" \n[23]\n. Choose a dedicated folder structure that \nwill accommodate all project files, data inputs, and analytical outputs. \nConfigure the project's coordinate reference system by accessing Project → Properties → CRS \n[23]\n. Search \nfor \"32636\" to locate WGS 84 / UTM Zone 36N and select this projection for accurate metric \nmeasurements throughout Uganda \n[21]\n. Verify the CRS selection by checking the coordinate display in the \nbottom-right corner of the QGIS interface, which should now show coordinates in meters rather than \ndecimal degrees. \nStep 2: Organize Your Data and Workspace \n\nEffective spatial analysis requires well-organized data management and an optimized workspace \n[23]\n. \nCreate a folder structure within your project directory including subfolders for \"Raw_Data,\" \n\"Processed_Data,\" \"Maps,\" and \"Analysis_Results.\" This organization facilitates data management and \nensures reproducible analysis workflows. \nCustomize the QGIS interface for healthcare analysis by ensuring the Processing Toolbox is visible (View \n→ Panels → Processing Toolbox) as this contains essential tools for spatial analysis \n[17]\n. Also enable the \nBrowser Panel to facilitate data navigation and the Layers Panel to manage multiple data layers effectively \n[23]\n. \n3.2 Loading and Converting Spatial Data \nStep 3: Import Uganda District Boundaries \nLoad the foundational geographic framework by importing Uganda district boundaries, which will serve \nas the spatial units for accessibility analysis \n[10]\n. Use Layer → Add Layer → Add Vector Layer to import the \nUganda_districts.gpkg file, ensuring the layer loads correctly in the map canvas. These administrative \nboundaries provide the geographic framework for calculating population-level accessibility metrics and \nidentifying districts requiring intervention. \nExamine the attribute table by right-clicking the districts layer and selecting \"Open Attribute Table\" to \nfamiliarize yourself with available fields \n[24]\n. Key attributes should include district names, population data, \nand any existing health indicators that will be joined with accessibility metrics. Note the field containing \ndistrict names as this will be crucial for data joining operations. \nStep 4: Convert Health Facility Coordinates to Spatial Data \nTransform the health facility coordinate data from tabular format to spatial points using QGIS's delimited \ntext import functionality \n[24]\n. Navigate to Layer → Add Layer → Add Delimited Text Layer and select the \nhealth_facilities_uganda.csv file. Configure the import settings carefully: set File format to \"CSV,\" identify \nthe X field as \"Longitude\" and Y field as \"Latitude,\" and set the Geometry CRS to EPSG:4326 (WGS 84) \nsince the coordinates are in decimal degrees \n[24]\n. \nClick \"Add\" to create the temporary point layer, then immediately convert it to a permanent shapefile to \nensure data persistence \n[24]\n. Right-click the temporary layer, select Export → Save Features As, choose \nESRI Shapefile format, and save as \"health_facilities_uganda.shp\" with CRS set to EPSG:32636 for \nconsistency with your project \n[24]\n. Remove the temporary CSV layer and work exclusively with the \npermanent shapefile for all subsequent analysis. \n\nStep 5: Import and Join Health Indicator Data \nImport additional health data that will be used for compound analysis of access and health outcomes \n[24]\n. \nUse Layer → Add Layer → Add Delimited Text Layer to import malaria_prevalence_uganda.csv, selecting \n\"No geometry (attribute table only)\" since this contains only statistical data without coordinates \n[24]\n. \nCreate a table join to combine district boundaries with health indicator data, enabling analysis that \nconsiders both accessibility and health outcomes \n[24]\n. Right-click the districts layer, select Properties → \nJoins, and click the \"+\" button to add a new join. Configure the join by setting Join layer to the malaria \nprevalence data, selecting appropriate field names for both Join field and Target field (typically district \nnames), and enabling the join \n[24]\n. \n3.3 Visualizing Health Facility Distribution \nStep 6: Create Effective Point Symbology \nDevelop clear visualization of health facility locations using appropriate symbology that communicates \nfacility types and service levels \n[25]\n. Right-click the health facilities layer and select Properties → \nSymbology to access styling options. Choose \"Categorized\" symbology and set the Value to \"Facility_Type\" \nto create distinct symbols for different facility levels \n[25]\n. \nConfigure symbols that effectively communicate the healthcare hierarchy: use large red crosses for \nDistrict Hospitals, medium blue plus signs for Health Centre IV, smaller green circles for Health Centre III, \nand small orange dots for Health Centre II \n[25]\n. Ensure symbol sizes are large enough for clear visibility (3-\n5 mm) while maintaining map clarity and avoiding overlap in dense areas. \nStep 7: Assess Initial Spatial Patterns \nBefore conducting formal analysis, visually assess the spatial distribution of health facilities to identify \nobvious patterns and potential accessibility gaps \n[25]\n. Look for clustering around urban centers, sparse \ncoverage in rural areas, and geographic barriers that might influence access patterns. This preliminary \nassessment provides context for subsequent quantitative analysis and helps identify areas of particular \nconcern. \nUse the map canvas navigation tools to systematically examine different regions of Uganda, noting the \nrelationship between facility distribution and population centers \n[23]\n. Areas with obvious gaps in facility \ncoverage or regions where facilities appear clustered while large areas remain unserved should be noted \nfor particular attention in the accessibility analysis. \n\n3.4 Performing Buffer Analysis \nStep 8: Create Service Catchment Buffers \nGenerate 10-kilometer buffer zones around each health facility to represent reasonable access distances \nfor the Ugandan context \n[15]\n. Access the buffer tool through Vector → Geoprocessing Tools → Buffer, and \nconfigure the analysis parameters carefully. Set the Input layer to your health facilities shapefile, specify \nDistance as 10,000 meters (10 km), and maintain 20 segments for smooth circular buffers \n[15]\n. \n\n \nGIS map displaying injury locations and various playground buffer zones in a city. \nSave the output as \"facility_buffers_10km.shp\" in your processed data folder for future reference \n[15]\n. The \nresulting buffer zones represent areas within reasonable walking distance of health facilities, accounting \nfor the reality that most rural Ugandans rely on walking for transportation \n[26]\n. The 10-kilometer distance \nrepresents approximately 2-3 hours of walking time, aligning with international recommendations for \nbasic health service access \n[14]\n. \n\nStep 9: Analyze Buffer Coverage Patterns \nExamine the resulting buffer pattern to understand spatial coverage and identify areas with overlapping \nservice areas versus gaps in coverage \n[15]\n. Areas with multiple overlapping buffers indicate well-served \npopulations with choice of facilities, while gaps between buffers reveal underserved areas requiring \nattention. Use different colors for the buffer symbology (transparent fill with distinct outline) to clearly \nvisualize overlapping areas. \n \nGIS map illustrating distance-based service areas and origin-destination connections for COVID-19 \nreferral hospitals. \nCalculate basic coverage statistics by examining the total area covered by buffers relative to Uganda's total \narea, providing a preliminary metric of national accessibility \n[15]\n. Areas of particular concern include \nborder regions, mountainous areas, and sparsely populated regions where geographic barriers compound \ndistance challenges. \n3.5 Conducting Spatial Query Analysis \nStep 10: Identify Underserved Districts \n\nUse spatial queries to systematically identify districts with inadequate facility coverage \n[17]\n. Navigate to \nVector → Research Tools → Select by Location to access the spatial query interface. Configure the query to \n\"Select features from\" the Uganda districts layer \"where the features\" \"do not intersect\" \"by comparing to \nthe features from\" the facility buffers layer \n[17]\n. \n \nQGIS interface with the \"Extract by location\" tool highlighted in the Processing Toolbox for spatial queries. \nThis query identifies districts that have no overlap with any facility buffer zones, indicating areas \ncompletely outside the 10-kilometer service areas of all health facilities \n[18]\n. These districts represent the \nmost underserved areas from a spatial accessibility perspective and should receive priority for health \nsystem strengthening interventions. \nStep 11: Combine Spatial and Attribute Queries \nEnhance the analysis by combining spatial accessibility criteria with health outcome indicators to identify \nareas with compound disadvantages \n[17]\n. With districts still selected from the previous spatial query, \naccess the attribute table and use the \"Select by Expression\" tool to further refine the selection \n[18]\n. \n\nCreate an expression to identify districts with both poor access and high disease burden: \n\"Malaria_Prevalence_Percent\" > 20 AND current selection \n[18]\n. Set the selection mode to \"Intersect current \nselection\" to find districts meeting both criteria. This identifies areas with the greatest need for \nintervention, combining high disease burden with poor facility access. \nStep 12: Export and Save Analysis Results \nSave the results of your compound analysis for further use and reporting \n[17]\n. Right-click the districts layer \nand select Export → Save Selected Features As to create a new layer containing only the high-priority \ndistricts. Save as \"high_priority_districts.gpkg\" to preserve all attribute information for subsequent \nanalysis and reporting \n[17]\n. \nThis layer represents districts requiring immediate attention for health system strengthening, combining \nevidence of both accessibility gaps and health needs \n[27]\n. These results form the foundation for evidence-\nbased policy recommendations and resource allocation decisions. \n3.6 Creating Professional Map Layouts \nStep 13: Design Comprehensive Map Layout \nTransform your analytical results into professional presentation materials using QGIS's print layout \nfunctionality \n[23]\n. Create a new print layout (Project → New Print Layout) named \"Health Facility Access \nAnalysis\" and configure the page orientation and size appropriate for your intended use \n[23]\n. \nAdd the main map frame by clicking Add Item → Add Map and drawing a rectangle covering most of the \nlayout area \n[23]\n. Configure the map extent to show all of Uganda with appropriate margins, ensuring all \nanalytical results are clearly visible. Lock the map extent to prevent accidental changes during layout \nrefinement. \nStep 14: Add Essential Cartographic Elements \nCreate a professional map by including all essential cartographic elements that enable proper \ninterpretation \n[23]\n. Add a clear, descriptive title such as \"Health Facility Access Analysis: Identifying \nUnderserved Districts in Uganda\" using Add Item → Add Label \n[23]\n. Position the title prominently at the top \nof the layout with appropriate font size and styling. \nInclude a comprehensive legend explaining all map symbols: facility types, buffer zones, and district \nclassification \n[23]\n. Use Add Item → Add Legend and customize to show only relevant layers with clear, \n\ndescriptive labels. Add a north arrow (Add Item → Add North Arrow) and scale bar (Add Item → Add Scale \nBar) to provide geographic orientation and scale reference \n[23]\n. \nAdd data source information and map creation details at the bottom of the layout, including coordinate \nsystem used, data sources, analysis date, and creator information \n[23]\n. This metadata ensures transparency \nand enables others to reproduce or verify your analysis. \n3.7 Exporting and Sharing Results \nStep 15: Export High-Quality Maps \nGenerate final map products suitable for various uses by configuring appropriate export settings \n[23]\n. For \nprinted materials, export as PDF using Layout → Export as PDF with high resolution (300 dpi) to ensure \ncrisp text and clear symbol definition \n[23]\n. For digital presentations, export as PNG using Layout → Export \nas Image with moderate resolution (150-200 dpi) for optimal file size and display quality. \nConsider creating multiple versions of your map for different audiences: a detailed technical version for \nhealth planners and a simplified version for community stakeholders and policymakers \n[23]\n. Each version \nshould maintain analytical integrity while adapting visual complexity to audience needs and technical \nliteracy. \n4. Advanced Analysis and Interpretation \n4.1 Understanding Accessibility Patterns and Health Equity \nThe spatial analysis reveals critical patterns of healthcare accessibility that directly impact health equity \nand population health outcomes \n[3]\n. Districts identified through the compound spatial and attribute query \nrepresent areas experiencing a \"double burden\" of high disease prevalence and poor spatial access to care \n[1]\n. These patterns reflect broader inequities in health system development, infrastructure investment, and \nresource allocation that perpetuate health disparities. \n\n \nHealthcare accessibility strongly correlates with health outcomes in Uganda districts \nThe strong negative correlation between healthcare accessibility and malaria prevalence demonstrates \nthe public health significance of spatial access patterns \n[4]\n. Areas with better facility coverage consistently \nshow lower malaria prevalence, supporting the hypothesis that improved access enables earlier \ntreatment, reduces transmission, and improves overall health outcomes \n[4]\n. This relationship provides \ncompelling evidence for targeted health system strengthening in underserved areas. \n4.2 District-Level Access Patterns and Urban-Rural Disparities \nAnalysis of facility access by district type reveals stark disparities that mirror broader patterns of urban-\nrural inequality in Uganda \n[2]\n. Urban districts demonstrate significantly higher facility density and better \npopulation coverage, reflecting historical patterns of health infrastructure development and ongoing \nurban bias in health investment \n[10]\n. \n\n \nUrban districts have significantly better healthcare facility access than rural areas in Uganda \nSemi-urban districts show intermediate access levels, often benefiting from proximity to urban centers \nwhile still facing infrastructure challenges \n[10]\n. Rural districts demonstrate the greatest accessibility \nchallenges, with limited facility coverage and large populations living beyond reasonable access distances \n[26]\n. These patterns contribute to rural-urban health disparities and highlight the need for targeted rural \nhealth strategies. \n4.3 Population-Level Accessibility Metrics \nDetailed analysis of population distribution relative to health facilities reveals the scale of accessibility \nchallenges facing Uganda's health system \n[12]\n. The majority of rural populations live more than optimal \ndistances from health facilities, creating barriers to timely care and contributing to preventable morbidity \nand mortality \n[14]\n. \n\n \nRural populations face significantly longer distances to health facilities compared to urban areas \nThe distance decay effect in healthcare utilization provides strong empirical justification for accessibility \nimprovement interventions \n[11]\n. Areas where significant populations live beyond 10-15 kilometers from \nfacilities experience dramatically reduced healthcare utilization, supporting the need for additional \nfacilities or alternative service delivery approaches \n[12]\n. \n5. Policy Implications and Public Health Applications \n5.1 Evidence-Based Health System Planning \nThe accessibility analysis provides robust evidence for health system planning decisions, including facility \nlocation planning, resource allocation, and service delivery optimization \n[27]\n. Districts identified as having \npoor access and high disease burden represent clear priorities for health infrastructure investment and \nshould receive preferential consideration for new facility construction or mobile health programs \n[6]\n. \nThe analysis also reveals opportunities for service delivery optimization in areas with overlapping \ncatchment areas, where resources might be redistributed to extend coverage to underserved populations \n\n[27]\n. Mobile health services, community health worker programs, and telemedicine initiatives offer \npotential solutions for addressing accessibility gaps without requiring major infrastructure investment. \n5.2 Health Equity and Social Justice Applications \nSpatial accessibility analysis serves as a powerful tool for advancing health equity by quantifying \ndisparities and providing evidence for targeted interventions \n[3]\n. The compound analysis of access and \nhealth outcomes reveals areas where geographic inequities intersect with health burden, creating priority \nareas for equity-focused interventions \n[28]\n. \nResults from this analysis can inform advocacy efforts for health equity, provide evidence for resource \nallocation decisions, and support community mobilization around health access issues \n[28]\n. The visual \nnature of spatial analysis makes complex equity patterns accessible to diverse stakeholders, from \npolicymakers to community leaders. \n5.3 Integration with Health System Strengthening \nThe analytical framework developed in this tutorial can be adapted and extended to support \ncomprehensive health system strengthening efforts \n[29]\n. By incorporating additional health indicators, \nservice quality measures, and population vulnerability data, the analysis can provide increasingly \nsophisticated guidance for health system improvement \n[13]\n. \nRegular repetition of this analysis enables monitoring of progress in addressing accessibility gaps and \nevaluation of health system interventions \n[13]\n. As new facilities are constructed or existing services are \nexpanded, updated accessibility analysis can quantify improvements and identify remaining gaps \nrequiring attention. \n6. Methodological Considerations and Limitations \n6.1 Analytical Assumptions and Limitations \nThe buffer analysis approach employed in this tutorial makes several simplifying assumptions that users \nshould understand when interpreting results \n[11]\n. The use of Euclidean distance assumes straight-line \ntravel, which may not reflect actual travel routes constrained by road networks, topography, or seasonal \nbarriers \n[12]\n. In Uganda's context, where road infrastructure varies significantly and seasonal factors affect \naccessibility, these assumptions may underestimate actual travel times and distances. \nThe 10-kilometer buffer threshold, while based on international recommendations and local context, \nrepresents an approximation of reasonable access distance \n[14]\n. Actual willingness to travel for healthcare \n\nvaries by individual factors, health condition severity, and service quality perceptions \n[30]\n. Some \npopulations may travel much further for specialized care, while others may consider smaller distances \nprohibitive for routine services. \n6.2 Data Quality and Availability Considerations \nThe accuracy of accessibility analysis depends heavily on the quality and completeness of input data \n[11]\n. \nHealth facility location data may not capture all service delivery points, particularly private facilities, faith-\nbased organizations, or informal care providers that serve significant portions of the population \n[7]\n. \nSimilarly, facility service level classifications may not reflect actual service availability, which can vary due \nto staffing, supply, or infrastructure constraints. \nPopulation data used for accessibility calculations may not reflect current demographic patterns, \nparticularly in areas experiencing rapid urbanization, displacement, or migration \n[10]\n. Regular updates to \nboth facility and population data are essential for maintaining analytical accuracy and policy relevance. \n6.3 Extensions and Future Enhancements \nThe analytical framework presented here provides a foundation for more sophisticated accessibility \nanalysis \n[13]\n. Network analysis using actual road data would provide more realistic travel time estimates \nand enable consideration of transportation mode differences \n[11]\n. Integration of elevation data could \naccount for topographic barriers that significantly affect travel times in mountainous regions. \nTemporal analysis incorporating seasonal factors, facility operating hours, and service availability would \nprovide more nuanced understanding of accessibility patterns \n[12]\n. Population-weighted analysis \nconsidering demographic characteristics and health needs would enable more targeted intervention \nplanning and resource allocation \n[13]\n. \n7. Conclusion and Professional Development \nThis comprehensive tutorial demonstrates the power of GIS-based spatial analysis for understanding and \naddressing healthcare accessibility challenges in Uganda and similar contexts \n[3]\n. The skills developed \nthrough this tutorial—from basic data management to sophisticated spatial analysis and professional \nmapping—are directly applicable to public health practice, health system planning, and health equity \nresearch \n[23]\n. \nThe analytical approach combines technical GIS skills with public health knowledge to generate actionable \nintelligence for health system improvement \n[27]\n. By quantifying accessibility patterns and identifying \n\npriority areas for intervention, this analysis contributes to evidence-based health policy and supports \nefforts to achieve universal health coverage and health equity \n[1]\n. \nFuture applications of these skills might include analysis of other health services (maternal care, \nimmunization, chronic disease management), integration with health outcome data for impact evaluation, \nor development of predictive models for health facility planning \n[13]\n. The foundational spatial analysis \nconcepts learned here provide a platform for increasingly sophisticated health geography applications \nthroughout your professional career. \nThe integration of spatial analysis with public health practice represents a growing field with significant \npotential for impact \n[3]\n. As health systems worldwide grapple with challenges of equity, efficiency, and \neffectiveness, spatial analysis provides essential tools for understanding complex geographic patterns and \ndeveloping targeted solutions that can improve health outcomes for all populations. \n⁂ \n \n1. lab2_health_facility_access_tutorial.pdf    \n2. https://pmc.ncbi.nlm.nih.gov/articles/PMC11535691/   \n3. https://thinkmd.org/project/addressing-healthcare-challenges-in-uganda/       \n4. https://pmc.ncbi.nlm.nih.gov/articles/PMC8238135/    \n5. https://www.volusia.org/services/financial-and-administrative-services/finance-department/information-\ntechnology/geographic-information-services/geographic-spatial-analysis/buffer-analysis.stml  \n6. https://www.medrxiv.org/content/10.1101/2025.02.13.25322240v1.full-text   \n7. https://realhealthuganda.org/our-work/access/   \n8. https://academic.oup.com/eurjcn/article/22/8/832/7244655  \n9. https://en.wikipedia.org/wiki/Healthcare_in_Uganda    \n10. https://pmc.ncbi.nlm.nih.gov/articles/PMC8505862/      \n11. https://sonams.ac.ug/Notes/UGANDA HEALTH CARE SYSTEM.pdf        \n12. https://pmc.ncbi.nlm.nih.gov/articles/PMC8886189/         \n13. https://bmchealthservres.biomedcentral.com/articles/10.1186/s12913-017-2059-9       \n\n14. https://www.pewresearch.org/short-reads/2018/12/12/how-far-americans-live-from-the-closest-hospital-differs-\nby-community-type/     \n15. https://library.health.go.ug/sites/default/files/resources/National Health Facility MasterLlist 2017.pdf       \n16. https://www.qgistutorials.com/en/docs/3/performing_spatial_queries.html  \n17. https://www.youtube.com/watch?v=WfMvc-4jERM          \n18. https://astuntechnology.github.io/qgis-tutorials/html/en/docs/performing_spatial_queries.html     \n19. https://www.youtube.com/watch?v=zoElYnD2G5o  \n20. https://mapscaping.com/converting-csv-files-into-shapefiles-with-qgis/   \n21. https://www.igismap.com/mapping-healthcare-efficiency-gis-buffer-analysis-of-hospital-locations/    \n22. https://www.youtube.com/watch?v=EPmmFIzO3P8  \n23. https://www.youtube.com/watch?v=CU1A86JJMIk                   \n24. https://pmc.ncbi.nlm.nih.gov/articles/PMC8597972/          \n25. https://www.ruralhealth.us/blogs/2019/05/nrha-supports-bipartisan-legislation-to-eliminate-mileage-limitation-\nfor-critical-access-hospital-de     \n26. https://pmc.ncbi.nlm.nih.gov/articles/PMC3515413/   \n27. https://pmc.ncbi.nlm.nih.gov/articles/PMC7571702/     \n28. https://pmc.ncbi.nlm.nih.gov/articles/PMC5178808/   \n29. https://pubmed.ncbi.nlm.nih.gov/21262911/  \n30. https://epsg.io/?q=Uganda  \n\n## Document Information\n- **Source**: PDF Document (22 pages)\n- **Category**: lab-material\n- **Difficulty**: intermediate\n- **Relevant Labs**: lab2\n- **Topics**: accessibility, buffer, classification, clustering, coordinate system, crs, gis, health geography, malaria, mapping, projection, public health, qgis, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 2 enhanced qgis healthfacility access\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- buffer\n- classification\n- clustering\n- coordinate system\n- crs\n- gis\n- health geography\n- malaria\n- mapping\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "intermediate",
      "lab": "lab2",
      "topics": [
        "accessibility",
        "buffer",
        "classification",
        "clustering",
        "coordinate system",
        "crs",
        "gis",
        "health geography",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "qgis",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\lab_2_enhanced_qgis_healthfacility_access.md",
      "filename": "lab_2_enhanced_qgis_healthfacility_access.md"
    }
  },
  {
    "id": "concepts-lab_2_health_facility_access_tutorial",
    "title": "Lab 2: Health Facility Access Analysis - Complete QGIS Tutorial",
    "content": "\n# Lab 2: Health Facility Access Analysis - Complete QGIS Tutorial\n\n\n\n Lab 2: Health Facility Access Analysis\nSpatial Query and Buffer Analysis in QGIS\nComplete Tutorial with Public Health Context\n This comprehensive tutorial covers spatial analysis techniques for evaluating healthcare accessibility, combining GIS technical skills with\npublic health applications.\nLearning Objectives\nBy the end of this lab, you will be able to:\nUnderstand the concept of spatial accessibility in healthcare\nConvert CSV coordinate data to spatial point layers in QGIS\nCreate buffer zones around health facilities for proximity analysis\nPerform spatial queries to identify underserved areas\nCombine spatial and attribute queries for comprehensive analysis\nInterpret results in the context of health equity and policy\nCreate professional maps for public health decision-making\nMaterials Needed\nSoftware: QGIS 3.0 or higher\nData Files:\nUganda_districts.gpkg - District boundaries\nmalaria_prevalence_uganda.csv - Health indicator data\nhealth_facilities_uganda.csv - Facility coordinates\nPrerequisites: Completion of Lab 1 (recommended)\n 1. Public Health Context: Healthcare Accessibility\n1.1 Understanding Healthcare Accessibility\nKey Concept: Spatial Accessibility\nSpatial accessibility refers to the ease with which individuals can reach healthcare services from their location. It's a critical\ncomponent of healthcare equity and involves:\nPhysical distance to healthcare facilities\nTransportation barriers and travel time\nGeographic barriers like mountains, rivers, or roads\nService availability and capacity at facilities\nHealthcare accessibility is particularly important in low- and middle-income countries like Uganda, where:\nRural populations may live far from health facilities\nTransportation infrastructure is often limited\nGeographic barriers can prevent timely access to care\nEmergency conditions like malaria require prompt treatment\nFigure 1: Rural-urban health disparities showing higher death rates in rural areas for many conditions, highlighting the importance of spatial\naccessibility analysis.\n1.2 Geographic Barriers to Healthcare\nUnderstanding geographic barriers helps explain why spatial analysis is essential for health planning:\nBarrier TypeDescriptionImpact on Access\nDistancePhysical distance between home and facilityLonger travel times, higher costs\nTopographyMountains, valleys, water bodiesIncreases travel time and difficulty\nTransportationLimited roads, public transportReduces ability to reach facilities\nSeasonal factorsWeather, road conditionsTemporary barriers during certain periods\n⚠ Critical Consideration\nFor conditions like malaria, geographic barriers can be life-threatening. Delayed treatment significantly increases the risk of\nsevere complications and death, making spatial accessibility a matter of life and death.\n 2. Uganda's Health System Structure\n2.1 District-Level Healthcare Delivery\nUganda's health system is organized at multiple levels, with districts serving as key administrative units:\nLevelFacility TypeServices ProvidedCatchment Population\nDistrictDistrict HospitalSpecialized care, referrals500,000 - 1,000,000\nSub-districtHealth Centre IVGeneral medicine, surgery100,000 - 200,000\nSub-countyHealth Centre IIIOutpatient care, basic inpatient20,000 - 40,000\nParishHealth Centre IIBasic outpatient services5,000 - 10,000\nVillageHealth Centre ICommunity health services1,000 - 2,000\n Why Districts Matter for Spatial Analysis\nDistricts are ideal units for spatial health analysis because they:\nRepresent administrative boundaries for health planning\nHave defined populations and health service responsibilities\nAllow for resource allocation and policy implementation\nEnable comparison of health outcomes and service coverage\n2.2 Malaria and Healthcare Access\nMalaria remains a leading cause of morbidity and mortality in Uganda, making healthcare accessibility particularly critical for:\nEarly diagnosis: Rapid diagnostic tests and microscopy\nPrompt treatment: Artemisinin-based combination therapy (ACT)\nSevere case management: Inpatient care and monitoring\nPrevention services: Insecticide-treated nets, indoor spraying\nFigure 2: Example of spatial accessibility analysis showing healthcare facility coverage areas and population access patterns.\n 3. Spatial Analysis Fundamentals\n3.1 Buffer Analysis Concepts\n What is Buffer Analysis?\nA buffer is a zone of specified distance around a geographic feature. In healthcare accessibility analysis, buffers represent:\nService catchment areas around health facilities\nReasonable travel distances for accessing care\nCoverage zones for planning service delivery\nBuffer analysis helps answer critical questions:\nWhich areas are within reasonable distance of health facilities?\nHow many people live outside service catchment areas?\nWhere should new facilities be located to improve coverage?\nWhich districts have the poorest spatial access to care?\n3.2 Proximity Measures and Distance\nDistance TypeDefinitionUse CaseLimitations\nEuclidean DistanceStraight-line distanceQuick approximation, air transportIgnores roads, terrain\nManhattan\nDistance\nDistance along grid/roadsUrban areas with grid systemsLimited to regular patterns\nNetwork Distance\nDistance along actual\nroads\nMost realistic travel analysisRequires road network data\nTravel TimeTime to reach destination\nPatient experience, emergency\ncare\nDepends on transport mode,\ntraffic\n Best Practice\nFor this lab, we use Euclidean distance (straight-line buffers) as a starting point. While this doesn't account for roads or\nterrain, it provides a useful first approximation and is computationally simple. More advanced analyses would incorporate\nroad networks and travel time.\n3.3 Spatial Relationships and Queries\nSpatial queries help identify relationships between different geographic features:\nSpatial RelationshipDescriptionHealthcare Application\nIntersectsFeatures that overlap or touchDistricts served by facility buffers\nContainsFeatures completely inside othersFacilities within district boundaries\nWithinFeatures completely contained by othersPopulation centers within service areas\nDisjointFeatures that don't touch or overlapAreas with no nearby facilities\n 4. Essential GIS Techniques\n4.1 Working with Coordinate Data\n Understanding Coordinate Systems\nGeographic coordinates (latitude/longitude) represent locations on Earth's surface:\nLatitude: North-South position (-90° to +90°)\nLongitude: East-West position (-180° to +180°)\nWGS 84 (EPSG:4326): Global standard coordinate system\nUganda coordinates: Latitude ~4°N to -1°S, Longitude ~29°E to 35°E\nHealth facility data often comes as CSV files with latitude/longitude coordinates. Converting this to spatial data allows for\ngeographic analysis and visualization.\n 5. Step-by-Step QGIS Tutorial\n1 Load and Convert Health Facility Data\nFirst, we'll load the health facility coordinates and convert them to a spatial point layer.\nStep 1a: Add Delimited Text Layer\n1. Go to Layer → Add Layer → Add Delimited Text Layer\n2. Browse and select health_facilities_uganda.csv\n3. Configure the import settings as shown below\nFigure 3: Add Delimited Text Layer dialog showing coordinate field configuration.\n⚙ Dialog Configuration\nFile format: CSV (comma separated values)\nX field: Longitude\nY field: Latitude\nGeometry CRS: EPSG:4326 - WGS 84\nSample data: Preview should show facility locations\nStep 1b: Convert to Permanent Shapefile\n1. Right-click the newly loaded layer in the Layers panel\n2. Select Export → Save Features As...\n3. Choose ESRI Shapefile format\n4. Save as health_facilities_uganda.shp\n5. Remove the temporary CSV layer\n⚠ Troubleshooting: Points Not Appearing\nIf your points don't appear on the map:\nCheck that X field = Longitude, Y field = Latitude\nVerify coordinates are in decimal degrees (not degrees/minutes/seconds)\nEnsure CRS is set to EPSG:4326\nRight-click layer → Zoom to Layer\n2 Visualize Facility Distribution\nStep 2: Customize Point Symbology\n1. Right-click the health facilities layer → Properties\n2. Go to the Symbology tab\n3. Choose a distinctive symbol (cross, plus, or circle)\n4. Set color to red or blue for visibility\n5. Adjust size to 3-4 mm for clear visibility\n6. Click OK to apply\n Visualization Tips\nFor effective visualization:\nUse contrasting colors between facilities and district boundaries\nMake points large enough to see but not overwhelming\nConsider using medical symbols (+ or cross) for health facilities\nEnsure good contrast against background maps\n3 Create Buffer Zones Around Facilities\nNow we'll create 10-kilometer buffer zones around each health facility to represent reasonable access distances.\nStep 3: Buffer Analysis\n1. Go to Vector → Geoprocessing Tools → Buffer\n2. Configure buffer parameters (see dialog below)\n3. Run the analysis\nFigure 4: Buffer analysis tool dialog in QGIS.\n⚙ Buffer Parameters\nInput layer: Health facilities shapefile\nDistance: 10,000 meters (10 km)\nSegments: 20 (default - creates smooth circles)\nEnd cap style: Round\nOutput: Save to file (e.g., facility_buffers_10km.shp)\nFigure 5: Example of buffer zones around healthcare facilities showing coverage areas.\n Why 10 Kilometers?\nThe 10-kilometer buffer distance represents:\nReasonable walking distance: 2-3 hours on foot\nBicycle travel: 30-45 minutes\nMotorcycle taxi: 15-20 minutes\nWHO recommendations: Within 5-10 km for basic health services\n4 Perform Spatial Query: Identify Underserved Districts\nNext, we'll identify districts that do NOT intersect with any facility buffer zones, indicating areas with poor spatial access to\nhealthcare.\nStep 4: Select by Location\n1. Go to Vector → Research Tools → Select by Location\n2. Configure spatial query parameters\n3. Run the selection\nFigure 6: Select by Location dialog for spatial queries in QGIS.\n⚙ Spatial Query Configuration\nSelect features from: Uganda_districts (polygon layer)\nWhere the features: do not intersect\nBy comparing to the features from: facility_buffers_10km\nModify current selection: Creating new selection\n Understanding \"Do Not Intersect\"\nThe \"do not intersect\" relationship identifies districts that have NO overlap with any buffer zone, meaning they are completely\noutside the 10km service areas of all health facilities. These represent the most underserved areas.\n5 Filter for High Malaria Prevalence Areas\nNow we'll combine our spatial selection with attribute data to identify districts with both high malaria burden AND poor facility\naccess.\nStep 5a: Open Attribute Table\n1. Right-click the districts layer → Open Attribute Table\n2. Note that some districts are already selected (highlighted)\n3. Click the Select by Expression button\nStep 5b: Create Attribute Expression\n1. In the expression builder, enter:\n\"Malaria_Prevalence_Percent\" > 15\n2. Set selection mode to Intersect current selection\n3. Click Select Features\n Combining Selections\nBy using \"Intersect current selection,\" we're finding districts that meet BOTH criteria:\nDo NOT intersect with facility buffers (poor access)\nAND have malaria prevalence > 15% (high disease burden)\nThese represent the highest-priority areas for health system strengthening.\n6 Save and Export Results\nStep 6: Export Selected Features\n1. Right-click the districts layer → Export → Save Selected Features As...\n2. Choose format: GeoPackage\n3. File name: high_risk_underserved_districts.gpkg\n4. Click OK to save\n5. Add the new layer to your map for visualization\n7 Create Professional Map Layout\nStep 7: Design Map Layout\n1. Go to Project → New Print Layout\n2. Name: \"Health Facility Access Analysis\"\n3. Add map frame and essential elements:\nTitle: \"High Malaria Risk Districts Without Nearby Health Facilities\"\nLegend showing all layers\nScale bar and North arrow\nData source and date information\n4. Export as PDF for sharing and presentation\n 6. Data Interpretation and Analysis\n6.1 Understanding Accessibility Gaps\nThe results of your spatial analysis reveal important patterns about healthcare accessibility:\nAnalysis ResultInterpretationPolicy Implications\nDistricts with no facility buffersAreas with poor spatial accessNeed new facilities or mobile services\nHigh malaria + poor accessHighest priority areasUrgent intervention needed\nOverlapping buffer zonesWell-served areasPotential for service optimization\nBorder districts without accessCross-border health challengesRegional cooperation needed\n Critical Insight: High-Risk Underserved Areas\nDistricts that appear in your final selection represent a \"double burden\":\nHigh disease burden: Malaria prevalence > 15%\nPoor access: No health facilities within 10km\nHealth inequity: Greatest need, least access\nThese areas should receive priority for health system investments.\n6.2 Limitations and Considerations\n⚠ Analysis Limitations\nRemember that this analysis has several limitations:\nStraight-line distance: Doesn't account for roads, terrain\nFacility capacity: Doesn't consider size or service availability\nPopulation distribution: Rural areas may have lower density\nSeasonal factors: Access may vary by weather, road conditions\nTransportation: Assumes universal access to transport\n 7. Professional Applications\n7.1 Health Program Planning\nSpatial accessibility analysis supports evidence-based decision making:\nApplication AreaHow Analysis HelpsExample Decision\nFacility PlanningIdentify underserved areasWhere to build new health centers\nResource AllocationPrioritize high-need areasBudget distribution across districts\nService DeliveryDesign mobile health programsRoutes for outreach services\nEmergency ResponsePlan rapid response capacityPre-position supplies and staff\n7.2 Health Equity Assessment\nThis type of analysis is fundamental to assessing and addressing health inequities:\nIdentify disparities: Which populations have the least access?\nMeasure equity: Quantify gaps in service coverage\nMonitor progress: Track improvements over time\nTarget interventions: Focus resources where most needed\n Career Applications\nThese spatial analysis skills are valuable for careers in:\nPublic health program management\nHealth policy analysis and development\nInternational development and NGO work\nHealth systems research\nEpidemiology and disease surveillance\nEmergency response and humanitarian aid\n 8. Extensions and Advanced Techniques\n8.1 Network Analysis vs Buffer Analysis\nMethodAdvantagesDisadvantagesWhen to Use\nBuffer Analysis\nSimple, fast, works without road\ndata\nUnrealistic distance\nassumptions\nInitial assessment, data-poor\nsettings\nNetwork\nAnalysis\nRealistic travel routes and timesRequires road network dataDetailed planning, urban areas\n8.2 Additional Analysis Ideas\n Try These Extensions\n1. Different buffer distances: Compare 5km, 10km, and 15km buffers\n2. Population-weighted analysis: Include population density data\n3. Facility type analysis: Separate hospitals from health centers\n4. Multi-disease analysis: Include HIV, TB, or maternal health data\n5. Temporal analysis: Compare access over multiple years\n6. Cost-distance analysis: Account for terrain and travel costs\n8.3 Integration with Other Tools\nQGIS analysis can be enhanced by integrating with other tools:\nR Statistical Software: Advanced statistical analysis of spatial patterns\nPython: Automated processing of large datasets\nGoogle Earth Engine: Satellite imagery and environmental data\nOpenStreetMap: Detailed road network data\nWeb mapping: Interactive online maps for stakeholder engagement\n Conclusion and Key Takeaways\nWhat You've Accomplished\nThrough this lab, you have successfully:\nConverted coordinate data into spatial point features\nCreated buffer zones to represent service catchment areas\nPerformed spatial queries to identify underserved areas\nCombined spatial and attribute queries for complex analysis\nInterpreted results in public health context\nCreated professional maps for decision-making\nKey Concepts Mastered\nSpatial accessibility: Geographic barriers to healthcare access\nBuffer analysis: Proximity-based service area modeling\nSpatial queries: Identifying relationships between geographic features\nHealth equity analysis: Combining health outcomes with access measures\nEvidence-based planning: Using spatial data for health policy decisions\nNext Steps in Your GIS Journey\nContinue building your spatial analysis skills by exploring:\nNetwork analysis for realistic travel time calculations\nPopulation-weighted accessibility measures\nTime-series analysis of changing access patterns\nIntegration with remote sensing and environmental data\nAdvanced statistical methods for spatial health data\nWeb-based mapping and interactive visualization\nLab 2: Health Facility Access Analysis - Complete QGIS Tutorial\nThis tutorial provides foundational skills in spatial health analysis using QGIS. Continue practicing with different datasets and explore advanced\ntechniques to become proficient in GIS for public health applications.\n Spatial Analysis Public Health Evidence-Based Planning\n\n## Document Information\n- **Source**: PDF Document (1 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: lab2\n- **Topics**: accessibility, buffer, coordinate system, crs, gis, google earth engine, malaria, mapping, public health, python, qgis, remote sensing, satellite, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 2: health facility access analysis - complete qgis tutorial\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- buffer\n- coordinate system\n- crs\n- gis\n- google earth engine\n- malaria\n- mapping\n- public health\n- python\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "lab2",
      "topics": [
        "accessibility",
        "buffer",
        "coordinate system",
        "crs",
        "gis",
        "google earth engine",
        "malaria",
        "mapping",
        "public health",
        "python",
        "qgis",
        "remote sensing",
        "satellite",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\lab_2_health_facility_access_tutorial.md",
      "filename": "lab_2_health_facility_access_tutorial.md"
    }
  },
  {
    "id": "concepts-lab_3_environmental_risk_mapping_tutorial",
    "title": "Lab 3: Environmental Risk Mapping for Malaria - Complete Google Earth Engine Tutorial",
    "content": "\n# Lab 3: Environmental Risk Mapping for Malaria - Complete Google Earth Engine Tutorial\n\n\n\n Lab 3: Environmental Risk Mapping\nfor Malaria\nComplete Google Earth Engine Tutorial\nTable of Contents\n1. Learning Objectives & Introduction\n2. Environmental Epidemiology Background\n3. Remote Sensing Fundamentals\n4. Google Earth Engine Platform\n5. MODIS and CHIRPS Data\n6. Step-by-Step Tutorial\n7. Environmental Risk Assessment\n8. Professional Applications\nLearning Objectives & Introduction\nBy the end of this lab, you will be able to:\n✓Understand how environmental factors influence malaria transmission\n✓Access and process satellite data using Google Earth Engine\n✓Analyze NDVI and rainfall patterns for disease risk assessment\n✓Export environmental data for integration with health datasets\n✓Create environmental risk maps for public health applications\nWhy Environmental Mapping Matters\nMalaria transmission is heavily influenced by environmental conditions that affect mosquito vector\necology. By mapping these environmental factors using satellite data, we can:\nPredict Risk Areas\nIdentify regions with optimal conditions for mosquito\nbreeding and survival\nMonitor Changes\nTrack seasonal and long-term environmental\nchanges affecting transmission\nTarget Interventions\nGuide resource allocation and control measures to\nhigh-risk areas\nEarly Warning\nDevelop systems to predict malaria outbreaks based\non environmental conditions\nEnvironmental Epidemiology Background\nEnvironmental Determinants of Malaria Transmission\nKey factors influencing malaria transmission\nKey environmental factors influencing malaria transmission (Source: ResearchGate)\nVegetation Factors\nHumidity: Dense vegetation maintains high\nhumidity favorable for mosquito survival\nTemperature: Vegetation provides optimal\ntemperature zones for parasite development\nResting Sites: Vegetation offers protected areas\nfor mosquito resting\nBreeding Habitat: Plant debris creates\nmicrohabitats for larval development\n⛆Rainfall Factors\nBreeding Sites: Rainfall creates temporary\nwater bodies for mosquito breeding\nSeasonal Patterns: Transmission peaks typically\nfollow rainy seasons\nWater Quality: Fresh rainwater provides optimal\nbreeding conditions\nDuration: Extended wet periods increase vector\npopulation size\nMosquito Vector Ecology\n\nTemperature\n20-30°C optimal for development\n\nHumidity\n>60% for adult survival\n\nWater Bodies\nStanding water for breeding\n⚠Climate Change Implications\nChanging rainfall patterns and rising temperatures are altering malaria transmission zones globally. Remote\nsensing allows us to monitor these changes and adapt control strategies accordingly.\nRemote Sensing Fundamentals\nIntroduction to Satellite Data\nRemote sensing uses electromagnetic radiation reflected or emitted from Earth's surface to gather\ninformation about environmental conditions. For malaria risk assessment, we focus on:\nVegetation Indices (NDVI)\nNDVI values comparison\nNDVI measures vegetation health and density\nusing near-infrared and red light reflectance.\nNDVI = (NIR - Red) / (NIR + Red)\n⛆Precipitation Data\nCHIRPS combines satellite infrared observations\nwith ground station data to estimate rainfall at\nhigh resolution.\nNDVI Interpretation Guide\n-1 to 0\nWater, Snow,\nClouds\n0 to 0.2\nBare Soil, Rock\n0.2 to 0.4\nSparse\nVegetation\n0.4 to 0.7\nModerate\nVegetation\n0.7 to 1\nDense Vegetation\nApplications in Disease Mapping\nRemote sensing applications in disease mapping (Source: IntechOpen)\n☁Google Earth Engine Platform\nWhat is Google Earth Engine?\nGoogle Earth Engine (GEE) is a cloud-based platform for planetary-scale geospatial analysis. It\nprovides:\nMassive Data Archive\nPetabytes of satellite imagery and geospatial\ndatasets\nCloud Computing\nNo need to download data or have powerful local\ncomputers\nJavaScript API\nUser-friendly programming interface for analysis\nInteractive Interface\nWeb-based code editor with instant visualization\nCode Editor Interface\nGoogle Earth Engine Code Editor interface components\nLeft Panel - Scripts & Assets\n• Script repository and management\n• Asset imports and uploads\n• Documentation and examples\nRight Panel - Inspector & Console\n• Interactive map inspection\n• Console output and debugging\n• Task management for exports\nJavaScript Basics for GEE\nKey Programming Concepts\nVariables: Store data and objects\nvar myVariable = value;\nFunctions: Perform operations on data\n.filterDate(), .mean(), .sum()\nImage Collections: Time series of satellite images\nee.ImageCollection('dataset')\nFeature Collections: Vector datasets like boundaries\nee.FeatureCollection('shapefile')\nMODIS and CHIRPS Data\nMODIS NDVI Data\nMOD13Q1 Product Specifications:\nSpatial Resolution:250 meters\nTemporal Resolution:16 days\nCoverage:Global\nData Range:2000 - Present\nApplications for Malaria:\n• Identify vegetation density patterns\n• Monitor seasonal vegetation changes\n• Assess habitat suitability for vectors\n• Track land use changes over time\n⛆CHIRPS Precipitation Data\nCHIRPS Dataset Specifications:\nSpatial Resolution:5 kilometers\nTemporal Resolution:Daily\nCoverage:50°S-50°N, global\nData Range:1981 - Near real-time\nApplications for Malaria:\n• Map breeding site potential\n• Track seasonal rainfall patterns\n• Identify outbreak risk periods\n• Monitor drought/flood impacts\nData Quality Considerations\nMODIS NDVI Limitations:\n• Cloud contamination in tropical regions\n• Mixed pixel effects in heterogeneous areas\n• Atmospheric interference\n• Temporal compositing artifacts\nCHIRPS Limitations:\n• Lower accuracy for light precipitation\n• Limited ground station validation in remote areas\n• Satellite sensor calibration changes\n• Spatial interpolation uncertainties\nStep-by-Step Tutorial\nPrerequisites\n• Google Earth Engine account (sign up at earthengine.google.com)\n• Modern web browser (Chrome, Firefox, or Safari recommended)\n• Stable internet connection\n• Basic familiarity with programming concepts (helpful but not required)\nStep 1: Access Google Earth Engine\n1.1 Navigate to https://code.earthengine.google.com\n1.2 Sign in with your Google account that has Earth\nEngine access\n1.3 You'll see the Code Editor interface with four main\npanels\n1.4 Take a moment to familiarize yourself with the layout\nGoogle Earth Engine Code Editor interface\nStep 2: Create a New Script\n2.1 In the Scripts panel (left side), click the \"New\" button\n2.2 Name your script: \"Malaria_Environment_Uganda\"\n2.3 Click \"OK\" to create a blank script\n2.4 The script will open in the center code editor panel\nTip: Save your script frequently using Ctrl+S (Windows) or Cmd+S (Mac)\nStep 3: Load and Process NDVI Data\nCopy and paste the following code block into your script:\n// Load MODIS NDVI Image Collection for 2022 var ndvi =\nee.ImageCollection('MODIS/006/MOD13Q1') .filterDate('2022-01-01', '2022-12-31')\n.select('NDVI') .mean(); print('NDVI Image:', ndvi);\nCode Explanation:\nee.ImageCollection(): Loads the MODIS vegetation index dataset\n.filterDate(): Filters images to the year 2022\n.select('NDVI'): Selects only the NDVI band from the dataset\n.mean(): Computes the average NDVI value across all 2022 images\nprint(): Displays information about the image in the Console\nStep 4: Load and Process Rainfall Data\nAdd this code block below your NDVI code:\n// Load CHIRPS Daily Rainfall and compute total for 2022 var rainfall =\nee.ImageCollection('UCSB-CHG/CHIRPS/DAILY') .filterDate('2022-01-01', '2022-12-31')\n.sum(); print('Rainfall Image:', rainfall);\nCode Explanation:\nUCSB-CHG/CHIRPS/DAILY: Daily precipitation dataset from Climate Hazards Group\n.sum(): Adds up all daily rainfall values to get total annual rainfall\nThis creates a single image showing total 2022 rainfall for each pixel\nStep 5: Define the Uganda Boundary\nAdd this code to clip your data to Uganda:\n// Load Uganda Boundary var uganda = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n.filter(ee.Filter.eq('country_na', 'Uganda')); print('Uganda Boundary:', uganda);\n// Center the map on Uganda Map.centerObject(uganda, 6);\nCode Explanation:\nUSDOS/LSIB_SIMPLE/2017: US State Department world boundaries dataset\n.filter(): Selects only Uganda from the global boundaries\nMap.centerObject(): Centers and zooms the map to Uganda at zoom level 6\nStep 6: Visualize NDVI and Rainfall\nAdd visualization parameters to display your data:\n// NDVI Visualization Map.addLayer(ndvi.clip(uganda), {min: 0, max: 9000, palette:\n['white', 'lightgreen', 'darkgreen']}, 'Mean NDVI 2022'); // Rainfall Visualization\nMap.addLayer(rainfall.clip(uganda), {min: 0, max: 2000, palette: ['white',\n'lightblue', 'darkblue']}, 'Total Rainfall 2022'); // Add Uganda boundary outline\nMap.addLayer(uganda, {color: 'red'}, 'Uganda Boundary');\nVisualization Parameters:\n.clip(): Clips the global data to Uganda boundaries\nmin/max: Sets the data range for color mapping\npalette: Defines colors from low to high values\nLayer name: Appears in the Layers panel for easy toggling\nClick \"Run\" button to execute your code and see the results on the map!\nStep 7: Export Data to Google Drive\nAdd export functions to download your processed data:\n// Export NDVI to Google Drive Export.image.toDrive({ image: ndvi.clip(uganda),\ndescription: 'Uganda_NDVI_2022', scale: 250, region: uganda.geometry(), maxPixels:\n1e9 }); // Export Rainfall to Google Drive Export.image.toDrive({ image:\nrainfall.clip(uganda), description: 'Uganda_Rainfall_2022', scale: 5000, region:\nuganda.geometry(), maxPixels: 1e9 });\nExport Process:\n1. Run the script to queue the export tasks\n2. Go to the \"Tasks\" tab in the right panel\n3. Click \"Run\" for each export task\n4. Files will be saved to your Google Drive in GeoTIFF format\n5. Download may take 5-15 minutes depending on data size\nComplete Script\nHere's the complete code for copy-paste convenience:\n// Lab 3: Environmental Risk Mapping for Malaria in Uganda // Load MODIS NDVI Image Collection for 2022 var\nndvi = ee.ImageCollection('MODIS/006/MOD13Q1') .filterDate('2022-01-01', '2022-12-31') .select('NDVI') .mean();\n// Load CHIRPS Daily Rainfall and compute total for 2022 var rainfall = ee.ImageCollection('UCSB-\nCHG/CHIRPS/DAILY') .filterDate('2022-01-01', '2022-12-31') .sum(); // Load Uganda Boundary var uganda =\nee.FeatureCollection('USDOS/LSIB_SIMPLE/2017') .filter(ee.Filter.eq('country_na', 'Uganda')); // Center the map\non Uganda Map.centerObject(uganda, 6); // Visualize NDVI and Rainfall Map.addLayer(ndvi.clip(uganda), {min: 0,\nmax: 9000, palette: ['white', 'lightgreen', 'darkgreen']}, 'Mean NDVI 2022');\nMap.addLayer(rainfall.clip(uganda), {min: 0, max: 2000, palette: ['white', 'lightblue', 'darkblue']}, 'Total\nRainfall 2022'); Map.addLayer(uganda, {color: 'red'}, 'Uganda Boundary'); // Export data to Google Drive\nExport.image.toDrive({ image: ndvi.clip(uganda), description: 'Uganda_NDVI_2022', scale: 250, region:\nuganda.geometry(), maxPixels: 1e9 }); Export.image.toDrive({ image: rainfall.clip(uganda), description:\n'Uganda_Rainfall_2022', scale: 5000, region: uganda.geometry(), maxPixels: 1e9 }); print('Script completed\nsuccessfully!');\nEnvironmental Risk Assessment\nInterpreting NDVI and Rainfall Patterns\nNDVI Risk Interpretation\nHigh Risk (NDVI > 0.6): Dense vegetation,\nhigh humidity, optimal mosquito habitat\nModerate Risk (NDVI 0.3-0.6): Moderate\nvegetation, suitable for some vector species\nLow Risk (NDVI < 0.3): Sparse vegetation,\nless suitable for mosquito survival\n⛆Rainfall Risk Interpretation\nHigh Risk (>1200mm/year): Abundant\nbreeding sites, extended transmission\nseasons\nModerate Risk (600-1200mm/year):\nSeasonal breeding sites, intermittent\ntransmission\nLow Risk (<600mm/year): Limited water\nsources, unsuitable for most vectors\nMalaria Transmission Risk Zones\nCombined Environmental Risk Matrix\nNDVI / Rainfall\nLow Rainfall\n(<600mm)\nModerate Rainfall\n(600-1200mm)\nHigh Rainfall\n(>1200mm)\nHigh NDVI (>0.6)Moderate RiskHigh RiskVery High Risk\nModerate NDVI (0.3-0.6)Low RiskModerate RiskHigh Risk\nLow NDVI (<0.3)Very Low RiskLow RiskModerate Risk\nSeasonal Risk Variation\n⛆\nWet Season\nMarch-May, Oct-Nov\nPeak transmission risk due to\nabundant breeding sites\n☀\nDry Season\nDec-Feb, Jun-Aug\nReduced transmission but persistent\nrisk in suitable areas\n\nTransition\nSep, May\nVariable risk depending on rainfall\nonset/cessation\n⚠Important Considerations\n• Environmental suitability doesn't guarantee malaria presence - human factors matter too\n• Vector species vary in their environmental preferences\n• Climate change is shifting traditional risk zones\n• Control interventions can reduce transmission despite suitable environment\nProfessional Applications\nDisease Surveillance Applications\nSurveillance Enhancement\n• Risk Stratification: Prioritize surveillance\nefforts in high-risk environmental zones\n• Seasonal Alerts: Intensify monitoring during\npeak transmission periods\n• Resource Allocation: Deploy limited\nsurveillance resources efficiently\n• Early Detection: Identify potential outbreak\nareas before cases spike\nPredictive Modeling\n• Risk Forecasting: Predict malaria risk based\non environmental conditions\n• Outbreak Prediction: Use environmental\ntriggers to forecast epidemics\n• Intervention Timing: Optimize timing of\ncontrol measures\n• Climate Adaptation: Plan for changing\ntransmission patterns\nEarly Warning Systems\nSatellite observations for malaria early warning\nSatellite-based early warning system framework for malaria (Source: Cell Press)\n⚠Early Warning System Components\nEnvironmental Monitoring\n• Real-time rainfall tracking\n• Vegetation condition monitoring\n• Temperature and humidity data\n• Seasonal pattern analysis\nRisk Assessment\n• Environmental risk scoring\n• Threshold-based alerts\n• Multi-factor risk indices\n• Spatial risk mapping\nResponse Activation\n• Automated alert generation\n• Stakeholder notifications\n• Response protocol activation\n• Resource mobilization\nClimate Change Impact Assessment\nClimate Impacts on Transmission\n• Temperature Changes: Altered vector\ndevelopment rates and survival\n• Precipitation Shifts: Changed breeding site\navailability\n• Extreme Events: Droughts and floods affecting\ntransmission\n• Seasonal Shifts: Extended or altered\ntransmission seasons\nAdaptation Strategies\n• Risk Zone Mapping: Identify new areas at risk\n• Intervention Planning: Adapt control\nstrategies to new patterns\n• Health System Prep: Strengthen capacity in\nemerging risk areas\n• Community Education: Raise awareness in\nnewly affected regions\nPublic Health Planning Applications\nProgram Implementation\nVector Control Programs\n• Target high-risk environmental zones\n• Time interventions with environmental conditions\n• Optimize resource allocation geographically\n• Monitor intervention effectiveness\nHealth Service Planning\n• Plan facility capacity based on risk zones\n• Stock medical supplies seasonally\n• Train healthcare workers in high-risk areas\n• Develop referral systems for remote areas\nCareer Applications\nSkills from this lab are valuable for careers in:\n• Epidemiology and Disease Surveillance\n• Public Health Emergency Response\n• Environmental Health Assessment\n• Climate Change and Health Adaptation\n• Geospatial Health Analysis\n• Remote Sensing Applications\n• Global Health Program Management\n• Health Research and Academia\nExtensions and Next Steps\nOptional Exercises\nTemporal Analysis\n• Compare NDVI patterns across different years\n• Analyze seasonal rainfall variations\n• Create time-series animations\n• Identify long-term environmental trends\nTry this:\nfilterDate('2021-01-01', '2021-12-31')\nAdvanced Integration\n• Combine with population density data\n• Add land use classification\n• Include elevation and slope data\n• Create composite risk indices\nExplore:\nee.Image(\"WORLDPOP/GP/100m/pop\")\nAdvanced Google Earth Engine Techniques\nStatistical Analysis Tools\nChart Generation\n• Time-series plots\n• Histogram analysis\n• Scatter plot correlation\n• Regional comparisons\nZonal Statistics\n• District-level summaries\n• Mean values by region\n• Area calculations\n• Percentile analysis\nClassification\n• Risk category mapping\n• Threshold-based classes\n• Multi-criteria decision\n• Machine learning approaches\nIntegration with QGIS\nWorking with Exported Data\n1. Download GeoTIFF files from Google Drive\n2. Load into QGIS as raster layers\n3. Apply appropriate symbology and classification\n4. Combine with district boundaries and health data from previous labs\n5. Create comprehensive risk assessment maps\n6. Export publication-ready maps and analysis results\nUsing AI to Enhance Your Work\nChatGPT and other AI tools can help with:\n• Writing and debugging Google Earth Engine code\n• Explaining error messages and troubleshooting\n• Suggesting visualization parameters\n• Creating documentation and reports\n• Interpreting analysis results\nExample prompt: \"Help me modify this GEE code to calculate NDVI for the rainy season months (March-May) only\"\nTroubleshooting Guide\nCommon Code Errors\nError: \"Collection.filter: No band named...\"\nSolution: Check band names using .bandNames()\nor verify dataset documentation\nError: \"Exported 0 pixels\"\nSolution: Ensure region geometry is valid and\noverlaps with data\nError: \"User memory limit exceeded\"\nSolution: Reduce spatial resolution or region size\nPerformance Issues\n• Increase scale parameter for faster processing\n• Use smaller date ranges for initial testing\n• Apply .limit() to image collections during\ndevelopment\n• Cache intermediate results with .getInfo()\nVisualization Problems\nIssue: Map appears blank or wrong colors\nFix: Adjust min/max values in visualization\nparameters\nIssue: Export files are too large\nFix: Increase scale parameter or reduce region size\nIssue: Layers not loading\nFix: Check Console for error messages and data\navailability\nGetting Help\n• Google Earth Engine Developers Guide\n• GEE Help Forum and Stack Overflow\n• Dataset documentation pages\n• YouTube tutorials and courses\n• AI assistants like ChatGPT for code help\nConclusion and Key Takeaways\nWhat You've Accomplished\n• Accessed and processed satellite data using\nGoogle Earth Engine\n• Analyzed environmental factors relevant to\nmalaria transmission\n• Created meaningful visualizations of NDVI and\nrainfall patterns\n• Exported geospatial data for further analysis\n• Understood the connection between\nenvironment and disease risk\nKey Concepts Learned\n• Remote sensing applications in public health\n• Environmental determinants of vector-borne\ndiseases\n• Cloud-based geospatial analysis platforms\n• Integration of multiple environmental datasets\n• Spatial risk assessment methodologies\nCongratulations!\nYou have successfully completed Lab 3: Environmental Risk Mapping for Malaria using Google\nEarth Engine.\nYou now have the skills to analyze environmental factors influencing disease transmission using cutting-edge\nsatellite data and cloud computing platforms.\nThis tutorial was created for educational purposes to demonstrate the application of remote sensing and GIS\ntechnologies in public health research and practice.\nFor more advanced applications and continued learning, explore the Google Earth Engine documentation and\nconsider formal training in remote sensing and spatial epidemiology.\nUsing Remote Sensing to Analyze Environmental Factors Influencing Malaria Transmission in\nUganda\n\n## Document Information\n- **Source**: PDF Document (1 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: lab3\n- **Topics**: classification, gee, gis, google earth engine, machine learning, malaria, mapping, public health, qgis, raster, remote sensing, satellite, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 3: environmental risk mapping for malaria - complete google earth engine tutorial\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- gee\n- gis\n- google earth engine\n- machine learning\n- malaria\n- mapping\n- public health\n- qgis\n- raster\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "lab3",
      "topics": [
        "classification",
        "gee",
        "gis",
        "google earth engine",
        "machine learning",
        "malaria",
        "mapping",
        "public health",
        "qgis",
        "raster",
        "remote sensing",
        "satellite",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\lab_3_environmental_risk_mapping_tutorial.md",
      "filename": "lab_3_environmental_risk_mapping_tutorial.md"
    }
  },
  {
    "id": "concepts-lab_3_gee_environmental_risk_ma",
    "title": "Lab 3 GEE Environmental Risk Ma",
    "content": "\n# Lab 3 GEE Environmental Risk Ma\n\n\n\n \nEnhanced Google Earth Engine Environmental Risk \nMapping Tutorial: A Comprehensive Guide to \nSatellite-Based Malaria Surveillance \nThis comprehensive tutorial builds upon cutting-edge remote sensing technologies and cloud-based \ngeospatial analysis to address one of the most pressing public health challenges in Uganda and sub-\nSaharan Africa. By leveraging Google Earth Engine's planetary-scale computing capabilities with MODIS \nvegetation indices and CHIRPS precipitation data, this tutorial transforms complex environmental \nmonitoring into actionable intelligence for malaria control programs. The integration of satellite-derived \nenvironmental indicators with epidemiological understanding provides unprecedented opportunities for \npredictive modeling, early warning systems, and evidence-based intervention targeting that can \nsignificantly improve public health outcomes in resource-constrained settings. \n1. Introduction to Environmental Epidemiology and Remote Sensing Applications \n1.1 The Environmental Determinants of Malaria Transmission \nMalaria transmission represents a complex interaction between environmental conditions, vector ecology, \nand human populations that creates distinct spatial and temporal patterns of disease risk \n[1]\n. The \nrelationship between climate-based factors, particularly temperature and precipitation, and malaria \ntransmission has been extensively documented, with these environmental determinants serving as \nprimary constraints on the geographical suitability for malaria transmission \n[2]\n. Temperature impacts \nboth vector and parasite development, with recent models indicating that malaria transmission is \nconstrained to temperatures between 16°C and 34°C, with optimal transmission occurring at \napproximately 25°C \n[2]\n. \n\n \nDiagram illustrating the malaria parasite's life cycle in mosquito and human hosts, alongside potential \nvaccine strategies targeting various stages. \nPrecipitation patterns contribute fundamentally to malaria transmission dynamics through their influence \non mosquito breeding habitat availability and quality \n[3]\n. The frequency, duration, and intensity of \nprecipitation events create suitable aquatic habitats for mosquito development, though the relationship \nbetween rainfall and malaria transmission often produces complex and sometimes contradictory results \ndepending on local ecological conditions \n[2]\n. Moderate to heavy rainfall events can synchronize mosquito \npopulation activity by increasing near-surface humidity levels and stimulating resting gravid mosquitoes \nto seek new hosts for blood feeding \n[3]\n. \nEnvironmental factors beyond climate also play crucial roles in determining malaria transmission \npatterns. Local hydrography, hydrology, and topography affect water flow and collection patterns, \ninfluencing the formation of water pools suitable for mosquito breeding \n[2]\n. The presence of natural \npredators, humidity levels affecting mosquito survival, and natural disasters that create population \ndisplacement and habitat changes all contribute to the complex environmental epidemiology of malaria \ntransmission \n[2]\n. \n1.2 The Revolution of Remote Sensing in Public Health \n\nRemote sensing technology has fundamentally transformed our ability to monitor and understand \nenvironmental determinants of disease transmission at scales ranging from local to global \n[4]\n. The \nutilization of remote sensing-driven climatic and environmental variables has become essential for \ndetermining malaria transmission patterns in sub-Saharan Africa, providing researchers and public health \npractitioners with unprecedented access to spatially and temporally consistent environmental data \n[4]\n. \nThis technological revolution enables the assessment of environmental conditions across vast geographic \nareas without the need for extensive ground-based monitoring networks, which are often impractical or \nimpossible to maintain in resource-limited settings \n[5]\n. \n\n \nMap of Africa showing rainfall distribution in millimeters, with higher precipitation observed in Central \nand West African countries. \nThe emergence of satellite-based remote sensing has provided a wide array of environmental variables at \ndifferent spatial and temporal scales, creating new opportunities to enhance our understanding of the \nassociations between malaria disease patterns and various environmental and climatic variables \n[4]\n. \nRemote sensing applications in vector-borne disease monitoring have expanded dramatically, enabling \n\nthe identification of environmental conditions that influence disease vectors and transmission patterns \nwhile supporting the development of surveillance, prevention, and control strategies \n[6]\n. \nSatellite observations offer unique advantages for malaria surveillance including the ability to monitor \nenvironmental changes in real-time, track seasonal patterns that influence transmission dynamics, and \nidentify areas with optimal conditions for mosquito breeding and survival \n[7]\n. The integration of multiple \nsatellite data sources enables comprehensive environmental monitoring that can support predictive \nmodeling efforts and early warning systems for malaria outbreaks \n[6]\n. \n1.3 Google Earth Engine: Democratizing Planetary-Scale Analysis \nGoogle Earth Engine represents a paradigm shift in geospatial analysis by combining a multi-petabyte \ncatalog of satellite imagery and geospatial datasets with planetary-scale computational capabilities \n[8]\n. \nThis cloud-based platform democratizes access to advanced remote sensing analysis by eliminating the \ntraditional barriers of data acquisition, storage, and computational resources that have historically limited \nthe application of satellite data in public health research \n[9]\n. \nThe platform's key features include massive data repositories containing over thirty years of historical \nimagery and scientific datasets, cloud-based processing power that leverages Google's computational \ninfrastructure, and scalability that enables analysis from local to global scales \n[10]\n. The integrated \ndevelopment environment supports both JavaScript and Python programming languages, making \nadvanced geospatial analysis accessible to researchers with varying technical backgrounds \n[9]\n. \n\n \nComparison of MODIS NDVI and CHIRPS datasets for malaria environmental risk mapping \nFor malaria environmental risk assessment, Google Earth Engine provides seamless access to critical \ndatasets including MODIS vegetation indices for monitoring habitat conditions and CHIRPS precipitation \ndata for tracking rainfall patterns that influence mosquito breeding \n[11][12]\n. The platform's ability to \nprocess these datasets at scale enables researchers to conduct comprehensive environmental risk \nassessments across entire countries or regions without requiring local computational infrastructure \n[8]\n. \n2. Theoretical Foundations of Environmental Risk Assessment \n2.1 Understanding Vegetation Indices and Mosquito Ecology \nThe Normalized Difference Vegetation Index (NDVI) serves as a critical indicator of environmental \nconditions that influence malaria transmission through its relationship with mosquito vector ecology \n[13]\n. \nNDVI measures vegetation health and density using the relationship between near-infrared and red light \nreflectance, providing insights into habitat conditions that affect mosquito survival, reproduction, and \nhost-seeking behavior \n[11]\n. Research has demonstrated that remote sensing NDVI maintains close \ncorrelations with Anopheles density and can serve as a sensitive evaluation index for both mosquito \npopulations and malaria incidence rates \n[13]\n. \n\n \nNDVI map displaying varying vegetation density across a landscape, with dark green indicating high \ndensity and red squares marking potential hot spots. \nVegetation factors influence malaria transmission through multiple pathways including humidity \nmaintenance, temperature regulation, provision of resting sites, and creation of breeding habitats \n[14]\n. \nDense vegetation maintains high humidity levels that are favorable for adult mosquito survival, while also \nproviding optimal temperature zones for parasite development within the mosquito vector \n[14]\n. The \nrelationship between NDVI and malaria risk follows a generally positive correlation, with areas of higher \nvegetation density typically supporting larger and more stable mosquito populations \n[13]\n. \nThe interpretation of NDVI values for malaria risk assessment requires understanding of the ecological \nthresholds that define suitable habitat conditions. Areas with NDVI values greater than 0.6 typically \nindicate dense vegetation that creates high humidity environments optimal for mosquito habitat, while \nmoderate NDVI values between 0.3 and 0.6 suggest suitable conditions for some vector species \n[14]\n. Areas \nwith NDVI values below 0.3 generally represent sparse vegetation that is less suitable for mosquito \nsurvival and reproduction \n[14]\n. \n\n2.2 Precipitation Patterns and Breeding Site Dynamics \nPrecipitation serves as the primary environmental driver of mosquito breeding site availability and \nquality, with rainfall patterns directly influencing the temporal and spatial dynamics of malaria \ntransmission \n[3]\n. The Climate Hazards Group Infrared Precipitation with Stations (CHIRPS) dataset \nprovides high-resolution precipitation estimates that enable detailed analysis of rainfall patterns relevant \nto mosquito ecology and malaria transmission \n[12]\n. \n\n \nMap showing seasonal rainfall accumulation anomaly across Africa from October 2024 to May 2025, \nbased on CHIRPS data. \nThe relationship between precipitation and malaria transmission operates through multiple mechanisms \nincluding the creation of temporary water bodies for mosquito breeding, seasonal patterns that drive \n\ntransmission cycles, and the provision of fresh water conditions optimal for larval development \n[14]\n. \nHowever, the relationship between rainfall and malaria transmission is complex, with both insufficient \nand excessive precipitation potentially limiting transmission through different mechanisms \n[2]\n. \nRainfall risk interpretation for malaria assessment considers both total precipitation amounts and \ntemporal patterns. Areas receiving more than 1200mm of annual rainfall typically provide abundant \nbreeding sites that support extended transmission seasons, while moderate rainfall between 600-\n1200mm creates seasonal breeding sites with intermittent transmission patterns \n[14]\n. Areas with less than \n600mm of annual rainfall generally experience limited water sources that are unsuitable for most vector \nspecies \n[14]\n. \n2.3 Environmental Risk Integration and Assessment Methods \nThe integration of multiple environmental variables into comprehensive risk assessments requires \nsophisticated analytical approaches that account for the complex interactions between different \nenvironmental factors \n[1]\n. The combination of vegetation indices and precipitation data provides a \nfoundation for environmental risk assessment, but the relationship between these variables and malaria \ntransmission varies significantly based on local ecological conditions and vector species characteristics \n[1]\n. \n \n\nEnvironmental Risk Matrix for Malaria Transmission Based on NDVI and Rainfall Patterns \nEnvironmental risk assessment methodologies must account for seasonal variations in transmission risk, \nwith different combinations of NDVI and rainfall values creating varying levels of malaria transmission \npotential \n[14]\n. The development of risk matrices that combine environmental variables enables the \nclassification of areas into different risk categories, supporting targeted intervention strategies and \nresource allocation decisions \n[14]\n. \nThe application of environmental risk assessment requires consideration of local factors that may modify \nthe relationship between environmental conditions and malaria transmission, including vector control \ninterventions, housing quality, population immunity levels, and healthcare access \n[1]\n. These factors can \nsignificantly alter the expected relationship between environmental suitability and actual malaria \nincidence, emphasizing the importance of integrating environmental risk assessment with comprehensive \nepidemiological surveillance systems \n[15]\n. \n3. Comprehensive Google Earth Engine Tutorial \n3.1 Platform Orientation and Account Setup \nGoogle Earth Engine requires user registration and project setup before accessing the platform's \nanalytical capabilities \n[16]\n. The registration process involves selecting project purposes (commercial or \nnoncommercial), creating or selecting Google Cloud projects, and confirming project information \n[17]\n. For \nacademic and research applications, Google Earth Engine remains freely available, while commercial \napplications require licensing through Google Cloud \n[5]\n. \nAccess to the Google Earth Engine Code Editor begins by navigating to code.earthengine.google.com, \nwhere users encounter a web-based interactive development environment designed for geospatial \nanalysis \n[17]\n. The Code Editor interface consists of several key components including the script repository \nfor code management, the map display for visualization, the console for output inspection, and the tasks \npanel for managing export operations \n[16]\n. \nThe Code Editor environment supports JavaScript programming with extensive documentation and \ntutorial resources available through the platform \n[18]\n. Users new to JavaScript programming can leverage \nthe platform's autocompletion features and extensive example repository to develop proficiency in Earth \nEngine API usage \n[19]\n. The platform's design philosophy emphasizes accessibility, enabling researchers \nwith limited programming experience to conduct sophisticated geospatial analyses \n[20]\n. \n3.2 Data Access and Collection Overview \n\nGoogle Earth Engine's data catalog contains over 900 geospatial datasets spanning more than 40 years of \nsatellite observations and environmental measurements \n[5]\n. For malaria environmental risk assessment, \nthe platform provides access to critical datasets including the MODIS Vegetation Indices (MOD13Q1) \ncollection and the CHIRPS precipitation dataset \n[11][12]\n. These datasets offer complementary environmental \ninformation necessary for comprehensive risk assessment activities. \nThe MODIS MOD13Q1 product provides vegetation indices at 250-meter spatial resolution with 16-day \ntemporal compositing, enabling detailed monitoring of vegetation conditions that influence mosquito \nhabitat quality \n[11]\n. The dataset includes both Normalized Difference Vegetation Index (NDVI) and \nEnhanced Vegetation Index (EVI) products, along with quality assessment layers that enable users to \nidentify and filter low-quality observations \n[11]\n. \nCHIRPS precipitation data offers daily rainfall estimates at 5-kilometer spatial resolution covering the \nperiod from 1981 to near real-time \n[12]\n. The dataset builds on infrared Cold Cloud Duration observations \ncombined with station data to provide accurate precipitation estimates particularly valuable for regions \nwith sparse ground-based monitoring networks \n[12]\n. The combination of spatial resolution, temporal \ncoverage, and data quality makes CHIRPS particularly suitable for malaria environmental risk assessment \napplications \n[12]\n. \n3.3 Detailed Step-by-Step Implementation \nStep 1: Project Initialization and Environment Setup \nBegin your Google Earth Engine analysis by accessing the Code Editor at code.earthengine.google.com and \ncreating a new script named \"Malaria_Environmental_Risk_Uganda\" \n[16]\n. The initial setup involves \nestablishing the analytical framework and loading the necessary datasets for environmental risk \nassessment. Proper project organization facilitates reproducible analysis and enables efficient \ncollaboration with other researchers \n[20]\n. \nInitialize your analysis by defining the temporal scope for your environmental assessment, typically \nfocusing on a complete annual cycle to capture seasonal variations in environmental conditions \n[19]\n. For \nthis tutorial, we focus on 2022 data to demonstrate the analytical approach, though the methodology can \nbe applied to any time period of interest depending on research objectives and data availability \nrequirements. \nStep 2: MODIS NDVI Data Loading and Processing \n\nLoad the MODIS vegetation index collection using the Earth Engine ImageCollection constructor, applying \ntemporal filters to select data for your analysis period \n[21]\n. The MOD13Q1 product provides 16-day \ncomposite vegetation indices that reduce cloud contamination and atmospheric interference while \nmaintaining high spatial resolution necessary for detailed habitat assessment \n[11]\n. \n// Load MODIS NDVI Image Collection for 2022 \nvar ndvi = ee.ImageCollection('MODIS/006/MOD13Q1') \n  .filterDate('2022-01-01', '2022-12-31') \n  .select('NDVI') \n  .mean(); \n \nprint('NDVI Image:', ndvi); \n \nThe code above demonstrates the loading and processing of MODIS NDVI data through a series of method \ncalls that filter the collection by date, select the NDVI band, and compute the mean value across all images \nin the collection \n[19]\n. This approach creates a single composite image representing average vegetation \nconditions throughout 2022, providing a baseline assessment of habitat suitability for mosquito \npopulations \n[11]\n. \n\n \nMODIS NDVI satellite data showing vegetation density in East Africa, including Tsavo National Park and \nMount Kilimanjaro, between February 18 and March 5, 2009. \nStep 3: CHIRPS Precipitation Data Integration \nAccess the CHIRPS daily precipitation dataset and process it to generate annual rainfall totals that \nrepresent the cumulative water availability for mosquito breeding throughout the analysis period \n[22]\n. The \nCHIRPS dataset provides daily precipitation estimates that can be aggregated to various temporal scales \ndepending on analytical requirements \n[12]\n. \n// Load CHIRPS Daily Rainfall and compute total for 2022 \nvar rainfall = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY') \n  .filterDate('2022-01-01', '2022-12-31') \n  .sum(); \n \n\nprint('Rainfall Image:', rainfall); \n \nThis processing step aggregates daily precipitation values to create an annual total rainfall map that \nrepresents the cumulative water availability for mosquito breeding throughout 2022 \n[12]\n. The sum() \nfunction efficiently computes total precipitation across all days in the specified time period, creating a \nsingle raster layer suitable for environmental risk assessment \n[22]\n. \nStep 4: Spatial Boundary Definition and Geographic Filtering \nDefine the geographic extent of your analysis by loading administrative boundary data for Uganda from \nthe Earth Engine feature collection catalog \n[17]\n. Administrative boundaries provide the spatial framework \nfor clipping global datasets to your study area and enable country-specific analysis of environmental risk \npatterns \n[19]\n. \n// Load Uganda Boundary \nvar uganda = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017') \n  .filter(ee.Filter.eq('country_na', 'Uganda')); \n \nprint('Uganda Boundary:', uganda); \n \n// Center the map on Uganda \nMap.centerObject(uganda, 6); \n \nThe boundary definition process involves filtering the global administrative boundaries collection to \nselect only Uganda features, creating a geographic mask for subsequent data processing operations \n[17]\n. \nThe Map.centerObject() function configures the display extent to focus on Uganda at an appropriate zoom \nlevel for national-scale analysis \n[20]\n. \n3.4 Data Visualization and Quality Assessment \nStep 5: Environmental Data Visualization \nCreate informative visualizations of your environmental datasets using Earth Engine's mapping \ncapabilities, applying appropriate color schemes and scaling parameters to effectively communicate \nspatial patterns \n[19]\n. Visualization serves both analytical and communication purposes, enabling pattern \nrecognition during analysis and supporting effective presentation of results to stakeholders \n[20]\n. \n\n// NDVI Visualization \nMap.addLayer(ndvi.clip(uganda),  \n  {min: 0, max: 9000, palette: ['white', 'lightgreen', 'darkgreen']},  \n  'Mean NDVI 2022'); \n \n// Rainfall Visualization   \nMap.addLayer(rainfall.clip(uganda),  \n  {min: 0, max: 2000, palette: ['white', 'lightblue', 'darkblue']},  \n  'Total Rainfall 2022'); \n \n// Add Uganda boundary outline \nMap.addLayer(uganda, {color: 'red'}, 'Uganda Boundary'); \n \nThe visualization parameters include minimum and maximum values that define the data range for color \nmapping, and color palettes that provide intuitive interpretation of environmental conditions \n[20]\n. The \nchoice of green colors for vegetation and blue colors for rainfall follows standard conventions in \nenvironmental visualization that facilitate audience understanding \n[19]\n. \n \nGoogle Earth Engine Workflow for Environmental Malaria Risk Mapping \n\nStep 6: Data Quality Verification and Assessment \nImplement quality assessment procedures to verify data completeness and identify potential issues that \nmight affect analysis results \n[11]\n. Quality assessment involves examining data distributions, identifying \noutliers, and assessing spatial coverage to ensure that analytical results are based on reliable \nenvironmental information \n[21]\n. \nData quality considerations for MODIS NDVI include cloud contamination, atmospheric interference, and \nsensor calibration issues that can affect vegetation index values \n[11]\n. CHIRPS precipitation data quality \ndepends on satellite sensor performance, ground station data availability, and interpolation accuracy, \nparticularly in regions with sparse observational networks \n[12]\n. Regular quality assessment enables \nidentification of data limitations that should be communicated when presenting analytical results \n[22]\n. \n3.5 Environmental Risk Assessment and Classification \nStep 7: Risk Matrix Application and Classification \nApply environmental risk classification methods that combine NDVI and rainfall data to create \ncomprehensive risk assessments for malaria transmission \n[14]\n. Risk classification requires establishing \nthresholds for environmental variables and defining risk categories that correspond to different levels of \ntransmission potential \n[1]\n. \nThe risk classification approach combines vegetation density categories (based on NDVI values) with \nprecipitation categories (based on annual rainfall totals) to create a matrix of environmental risk levels \n[14]\n. This classification system enables identification of areas with optimal environmental conditions for \nmalaria transmission while highlighting regions where environmental factors may limit transmission \npotential \n[15]\n. \nEnvironmental risk assessment must account for the complex relationships between different \nenvironmental factors and their combined effects on mosquito ecology and malaria transmission \n[1]\n. The \nintegration of multiple environmental variables requires careful consideration of how different \ncombinations of conditions influence vector populations and disease transmission dynamics \n[2]\n. \n3.6 Data Export and Integration Capabilities \nStep 8: Data Export for External Analysis \nConfigure data export operations to save processed environmental data for integration with external \nanalytical platforms and geographic information systems \n[22]\n. Google Earth Engine's export capabilities \n\nenable users to download processed datasets in standard geospatial formats compatible with desktop GIS \nsoftware and statistical analysis packages \n[22]\n. \n// Export NDVI to Google Drive \nExport.image.toDrive({ \n  image: ndvi.clip(uganda), \n  description: 'Uganda_NDVI_2022', \n  scale: 250, \n  region: uganda.geometry(), \n  maxPixels: 1e9 \n}); \n \n// Export Rainfall to Google Drive   \nExport.image.toDrive({ \n  image: rainfall.clip(uganda), \n  description: 'Uganda_Rainfall_2022',  \n  scale: 5000, \n  region: uganda.geometry(), \n  maxPixels: 1e9 \n}); \n \nExport operations require specification of spatial resolution (scale parameter), geographic extent (region \nparameter), and output format preferences \n[22]\n. The exported GeoTIFF files maintain spatial reference \ninformation and can be directly imported into desktop GIS platforms for further analysis, visualization, or \nintegration with other datasets \n[22]\n. \nThe export process operates asynchronously, with tasks appearing in the Earth Engine Tasks panel where \nusers can monitor progress and manage multiple export operations \n[22]\n. Completed exports are saved to \nGoogle Drive in the specified format and can be downloaded for local use or shared with collaborators \n[22]\n. \n4. Advanced Environmental Analysis and Interpretation \n4.1 Temporal Dynamics and Seasonal Patterns \nEnvironmental risk assessment for malaria requires understanding of temporal dynamics that influence \ntransmission patterns throughout annual cycles \n[23]\n. Uganda experiences distinct seasonal patterns with \npeak transmission typically occurring during March-May and October-December rainy seasons, though \ntransmission occurs year-round in many areas due to favorable environmental conditions \n[1]\n. The \n\nintegration of seasonal environmental analysis enables prediction of transmission peaks and supports \ntiming of intervention activities. \nTemporal analysis capabilities in Google Earth Engine enable examination of environmental changes over \nmultiple time scales, from daily observations to multi-year trends \n[19]\n. Time-series analysis of NDVI and \nprecipitation data reveals patterns of environmental variability that influence mosquito population \ndynamics and malaria transmission potential \n[3]\n. These analytical capabilities support development of \nearly warning systems that use environmental indicators to predict transmission risk before case \nincreases become apparent \n[6]\n. \nClimate change impacts on malaria transmission patterns require long-term environmental monitoring to \ndetect shifts in transmission zones and seasonal patterns \n[23]\n. Changing rainfall patterns and rising \ntemperatures are altering malaria transmission zones globally, with remote sensing providing essential \ntools for monitoring these changes and adapting control strategies accordingly \n[2]\n. The historical depth of \nsatellite data archives enables assessment of environmental trends that may influence future \ntransmission patterns \n[5]\n. \n4.2 Spatial Heterogeneity and Local Environmental Factors \nEnvironmental risk assessment must account for spatial heterogeneity in environmental conditions that \ncreates localized patterns of transmission risk within broader geographic regions \n[15]\n. Uganda's diverse \ntopography and climate create substantial spatial variation in environmental conditions, with altitude, \nproximity to water bodies, and land use patterns all influencing local transmission potential \n[1]\n. High-\nresolution satellite data enables identification of environmental gradients and localized risk patterns that \nmay not be apparent in coarser-scale analyses \n[11]\n. \n\n \nMethodological diagram illustrating the process of deriving urban area and population nodes on a road \nnetwork from remote sensing, population, and road data for infectious disease modeling. \nVector control interventions can modify the relationship between environmental conditions and malaria \ntransmission, requiring consideration of intervention coverage when interpreting environmental risk \nassessments \n[1]\n. Research has demonstrated that the influence of environmental factors on malaria \nincidence varies significantly depending on the presence and effectiveness of vector control measures \nsuch as indoor residual spraying and long-lasting insecticidal nets \n[15]\n. Environmental risk assessment \nshould therefore be integrated with intervention monitoring to provide accurate risk estimates \n[1]\n. \nLocal ecological factors including vector species composition, breeding site preferences, and natural \npredator populations can significantly influence the relationship between environmental conditions and \nactual transmission risk \n[2]\n. Different Anopheles species have varying environmental preferences and \nbreeding site requirements, meaning that environmental suitability assessments must consider local \nvector ecology when interpreting risk patterns \n[3]\n. The integration of entomological surveillance data with \nenvironmental risk assessment enhances the accuracy and local relevance of transmission predictions \n[6]\n. \n4.3 Integration with Health System Data and Surveillance \n\nEnvironmental risk assessment provides greatest value when integrated with health system surveillance \ndata to create comprehensive understanding of malaria transmission dynamics \n[6]\n. The combination of \nenvironmental risk indicators with epidemiological surveillance enables validation of environmental \npredictions and identification of areas where environmental conditions suggest high transmission risk but \nsurveillance data indicates low incidence \n[15]\n. These discrepancies may indicate successful intervention \nprograms or surveillance gaps requiring attention \n[1]\n. \nEarly warning systems that combine environmental monitoring with epidemiological surveillance provide \nopportunities for proactive public health responses to predicted transmission increases \n[3]\n. Satellite-based \nenvironmental monitoring enables identification of conditions favorable for malaria transmission before \nincreases in case numbers become apparent through surveillance systems \n[6]\n. These early warning \ncapabilities support timely deployment of prevention and control measures that can prevent outbreaks or \nreduce their magnitude \n[7]\n. \nThe integration of environmental risk assessment with health facility data enables identification of areas \nwhere environmental conditions suggest high transmission risk but healthcare access is limited \n[8]\n. This \ninformation supports health system strengthening efforts by identifying priority areas for facility \nconstruction, mobile health services, or community health worker deployment \n[6]\n. Geographic targeting of \nhealth system investments based on environmental risk assessment can improve efficiency and impact of \nlimited health resources \n[10]\n. \n5. Professional Applications and Career Development \n5.1 Public Health Program Applications \nEnvironmental risk mapping using Google Earth Engine provides direct support for malaria control \nprogram implementation through evidence-based targeting of interventions and resources \n[6]\n. National \nmalaria control programs can use environmental risk assessments to identify priority areas for \nintervention deployment, optimize timing of seasonal interventions, and monitor environmental changes \nthat may affect transmission patterns \n[7]\n. The integration of environmental risk mapping with program \nmonitoring enables adaptive management approaches that respond to changing environmental conditions \n[1]\n. \nVector control program planning benefits significantly from environmental risk assessment through \nidentification of areas with optimal conditions for vector breeding and survival \n[15]\n. Indoor residual \nspraying programs can use environmental risk maps to target high-risk areas during periods of peak \nenvironmental suitability \n[1]\n. Bed net distribution campaigns can be timed and targeted based on \n\nenvironmental indicators of transmission risk \n[15]\n. The spatial precision of satellite-based environmental \nassessment enables district and sub-district level targeting that maximizes intervention impact \n[6]\n. \nEpidemic preparedness and response systems increasingly rely on environmental monitoring to provide \nearly warning of conditions favorable for malaria outbreaks \n[3]\n. Environmental indicators can signal \nincreased transmission risk weeks or months before increases in case numbers become apparent through \nsurveillance systems \n[6]\n. This early warning capability enables proactive deployment of prevention \nmeasures, enhanced surveillance activities, and resource mobilization before epidemics peak \n[7]\n. \n5.2 Research and Academic Applications \nEnvironmental risk mapping using Google Earth Engine provides powerful research tools for investigating \nthe relationships between environmental factors and malaria transmission \n[4]\n. Academic researchers can \nuse the platform's extensive data archives and computational capabilities to conduct large-scale analyses \nof environmental drivers of malaria transmission \n[5]\n. The platform's accessibility enables researchers in \nresource-limited settings to conduct sophisticated analyses without requiring expensive computational \ninfrastructure \n[10]\n. \nSpatial epidemiology research benefits from Google Earth Engine's ability to integrate multiple \nenvironmental datasets at various spatial and temporal scales \n[9]\n. Researchers can investigate how \ncombinations of environmental factors influence transmission patterns, examine the effects of climate \nchange on malaria distribution, and evaluate the environmental impacts of land use changes on \ntransmission risk \n[24]\n. The platform's machine learning capabilities enable development of predictive \nmodels that combine environmental data with epidemiological observations \n[9]\n. \nClimate change research applications include monitoring long-term trends in environmental conditions \nthat influence malaria transmission and predicting future transmission patterns under different climate \nscenarios \n[24]\n. The historical depth of satellite data archives enables assessment of environmental changes \nover multiple decades \n[5]\n. Researchers can investigate how changing precipitation patterns and rising \ntemperatures are affecting malaria transmission zones and use this information to predict future changes \nin transmission patterns \n[2]\n. \n5.3 Operational Integration and Decision Support \nHealth ministry applications of environmental risk mapping include strategic planning for malaria control \nprograms, resource allocation decisions, and monitoring of program effectiveness \n[6]\n. Environmental risk \nmaps provide evidence-based foundation for national malaria strategic plans by identifying geographic \n\nand temporal patterns of transmission risk \n[7]\n. Resource allocation decisions can be informed by \nenvironmental risk assessments that identify areas with highest transmission potential \n[1]\n. \nDistrict health office applications include targeting of vector control interventions, planning of seasonal \ncampaigns, and integration of environmental monitoring with routine surveillance systems \n[15]\n. District-\nlevel environmental risk assessment enables identification of sub-district areas requiring enhanced \nintervention coverage \n[6]\n. Seasonal environmental monitoring supports timing decisions for intervention \ndeployment and surveillance intensification \n[1]\n. \nCommunity health program applications include targeting of community health worker deployment, \nhealth education campaigns, and community-based surveillance activities \n[7]\n. Environmental risk \nassessment can identify communities at highest risk for malaria transmission, enabling targeted \ndeployment of community health resources \n[6]\n. Community education programs can be developed that \nhelp communities understand how environmental conditions influence malaria risk and what actions can \nbe taken to reduce transmission \n[10]\n. \n5.4 Career Pathways and Professional Development \nSkills developed through Google Earth Engine environmental risk mapping provide foundations for \ncareers in spatial epidemiology, environmental health assessment, and global health program \nmanagement \n[20]\n. The combination of remote sensing technical skills with public health knowledge creates \nunique professional capabilities that are increasingly valued in global health organizations \n[9]\n. Career \nopportunities include positions with international organizations, government health agencies, academic \ninstitutions, and non-governmental organizations focused on disease control \n[6]\n. \nGeospatial health analysis represents a rapidly growing field with significant opportunities for \nprofessional advancement \n[10]\n. The increasing availability of satellite data and cloud-based analytical \nplatforms is creating new opportunities for geospatial specialists in health organizations \n[5]\n. Professional \ndevelopment in this field requires combining technical remote sensing skills with epidemiological \nknowledge and public health understanding \n[20]\n. \nGlobal health program management increasingly requires understanding of spatial analysis and \nenvironmental factors influencing disease transmission \n[6]\n. Program managers who understand how to \ninterpret and use environmental risk assessments are better positioned to develop effective intervention \nstrategies and optimize resource allocation \n[7]\n. The skills developed through Google Earth Engine training \nprovide valuable qualifications for leadership positions in malaria control programs and broader global \nhealth initiatives \n[24]\n. \n\n6. Methodological Considerations and Future Directions \n6.1 Data Quality and Validation Considerations \nEnvironmental risk assessment using satellite data requires careful attention to data quality issues that \ncan affect analytical accuracy and interpretation \n[11]\n. MODIS NDVI data quality can be affected by cloud \ncontamination, atmospheric interference, and sensor calibration changes over time \n[11]\n. CHIRPS \nprecipitation data accuracy varies spatially depending on ground station density and satellite sensor \nperformance \n[12]\n. Users must implement quality assessment procedures and communicate data limitations \nwhen presenting analytical results \n[22]\n. \nValidation of environmental risk assessments requires comparison with ground-based observations and \nepidemiological surveillance data \n[4]\n. Independent validation datasets including meteorological station \ndata, vegetation surveys, and entomological monitoring provide opportunities to assess the accuracy of \nsatellite-derived environmental indicators \n[13]\n. Cross-validation approaches that compare environmental \nrisk predictions with observed malaria incidence patterns help identify limitations and improve analytical \nmethods \n[15]\n. \nTemporal stability of environmental-malaria relationships requires ongoing monitoring and validation as \nenvironmental conditions and intervention coverage change over time \n[23]\n. Climate change and land use \nmodifications can alter the relationships between environmental indicators and malaria transmission, \nrequiring periodic recalibration of risk assessment models \n[2]\n. Long-term monitoring programs that \ncombine environmental assessment with epidemiological surveillance provide opportunities to detect \nand adapt to changing environmental-disease relationships \n[1]\n. \n6.2 Technological Advances and Platform Evolution \nGoogle Earth Engine continues to evolve with new datasets, analytical capabilities, and integration options \nthat expand applications for health research \n[24]\n. Machine learning tools within the platform enable \ndevelopment of sophisticated predictive models that combine multiple environmental variables with \nepidemiological data \n[9]\n. Integration with other cloud computing platforms and data sources creates \nopportunities for more comprehensive analytical workflows \n[22]\n. \nEmerging satellite missions and sensor technologies provide new opportunities for environmental \nmonitoring relevant to malaria transmission \n[5]\n. Higher spatial and temporal resolution sensors enable \nmore detailed monitoring of environmental conditions at scales relevant to vector ecology and disease \ntransmission \n[11]\n. Hyperspectral sensors provide new capabilities for monitoring vegetation conditions \nand water quality parameters relevant to mosquito breeding \n[6]\n. \n\nArtificial intelligence and machine learning applications in remote sensing create opportunities for \nautomated environmental risk assessment and real-time monitoring systems \n[24]\n. These technological \nadvances enable development of operational systems that provide continuous environmental risk \nmonitoring without requiring extensive manual analysis \n[9]\n. Integration of AI capabilities with traditional \nepidemiological approaches creates opportunities for more responsive and accurate disease surveillance \nsystems \n[6]\n. \n6.3 Integration with Global Health Initiatives \nEnvironmental risk mapping contributes to global malaria elimination efforts through improved \nunderstanding of transmission patterns and more effective targeting of interventions \n[7]\n. The World \nHealth Organization's global technical strategy for malaria emphasizes the importance of surveillance and \ntargeted interventions, both of which benefit from environmental risk assessment capabilities \n[6]\n. Country-\nlevel elimination programs can use environmental risk mapping to identify remaining transmission foci \nand guide final elimination efforts \n[1]\n. \nSustainable Development Goal monitoring includes targets related to malaria burden reduction that \nrequire sophisticated monitoring and evaluation approaches \n[24]\n. Environmental risk assessment provides \ntools for monitoring progress toward malaria reduction targets and identifying areas where additional \nefforts are needed \n[7]\n. The integration of environmental monitoring with health outcome indicators \nsupports comprehensive assessment of progress toward elimination goals \n[10]\n. \nClimate change adaptation planning for health systems requires understanding of how changing \nenvironmental conditions will affect disease transmission patterns \n[2]\n. Environmental risk assessment \nprovides foundation for adaptation planning by identifying areas likely to experience changing \ntransmission patterns due to climate change \n[23]\n. Health system strengthening efforts can be informed by \nenvironmental risk projections that identify areas requiring enhanced capacity to address changing \ndisease patterns \n[24]\n. \n7. Conclusion and Professional Impact \nThis comprehensive tutorial demonstrates the transformative potential of Google Earth Engine for \nenvironmental risk assessment in malaria control through the integration of cutting-edge remote sensing \ntechnology with epidemiological understanding. The skills and knowledge developed through this tutorial \nprovide a foundation for evidence-based public health decision-making that can significantly improve the \neffectiveness of malaria control programs in Uganda and similar settings. The combination of technical \nremote sensing capabilities with public health applications creates unique professional competencies that \nare increasingly valued in global health organizations and national disease control programs. \n\nThe accessibility of Google Earth Engine technology democratizes advanced geospatial analysis, enabling \nresearchers and public health practitioners in resource-limited settings to conduct sophisticated \nenvironmental assessments without requiring expensive computational infrastructure. This technological \naccessibility creates opportunities for local capacity building and indigenous research leadership that can \nenhance the sustainability and local relevance of malaria control efforts. The platform's extensive \ndocumentation and educational resources support continued learning and professional development in \nthis rapidly evolving field. \nFuture applications of these analytical approaches will likely expand to include real-time environmental \nmonitoring systems, integration with mobile health technologies, and development of predictive models \nthat combine environmental data with social and economic indicators of disease risk. The foundational \nskills developed through this tutorial provide preparation for these emerging applications while \ncontributing immediately to current malaria control efforts. As environmental conditions continue to \nchange due to climate change and human activities, the importance of sophisticated environmental risk \nassessment will only increase, making these skills essential for future public health professionals working \nin malaria-endemic regions. \nThe integration of environmental risk assessment with broader health system strengthening efforts \nprovides opportunities to address multiple health challenges simultaneously while building local \nanalytical capacity that supports sustainable disease control programs. The evidence-based approach \ndemonstrated in this tutorial contributes to the broader goal of achieving universal health coverage and \nhealth equity through more effective targeting of limited resources and more responsive public health \nsystems that adapt to changing environmental and epidemiological conditions. \n⁂ \n \n1. lab3_environmental_risk_mapping_tutorial.pdf                  \n2. programming.ai_tools             \n3. https://earthengine.google.com        \n4. https://developers.google.com/earth-engine/guides      \n5. https://swastikedustart.com/the-importance-of-google-earth-engine-in-gis/         \n6. https://pmc.ncbi.nlm.nih.gov/articles/PMC4924041/                   \n7. https://lpdaac.usgs.gov/products/mod13q1v006/          \n\n8. https://www.nature.com/articles/sdata201566    \n9. https://pmc.ncbi.nlm.nih.gov/articles/PMC5629986/        \n10. https://www.earthblox.io/resources/advantages-and-disadvantages-of-google-earth-engine       \n11. https://pmc.ncbi.nlm.nih.gov/articles/PMC10671539/              \n12. https://www.sciencedirect.com/science/article/pii/S2405673118300047           \n13. https://www.nature.com/articles/s41598-022-15654-0     \n14. https://www.besjournal.com/fileSWYXYHJKX/journal/article/swyxyhjkx/2006/2/PDF/bes200602008.pdf            \n15. https://pmc.ncbi.nlm.nih.gov/articles/PMC1824708/          \n16. https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0119.pdf    \n17. https://skywatch.com/5-ways-satellite-data-can-be-used-to-improve-global-health/     \n18. https://developers.google.com/earth-engine/tutorials/tutorial_api_01  \n19. https://developers.google.com/earth-engine/tutorials/tutorial_js_01        \n20. https://www.youtube.com/watch?v=RV3Sv5iogHs        \n21. https://courses.spatialthoughts.com/end-to-end-gee.html   \n22. https://courses.spatialthoughts.com/gee-introduction.html            \n23. https://developers.google.com/earth-engine/guides/quickstart_javascript     \n24. https://tutorials.geemap.org/ImageCollection/image_collection_overview/        \n\n## Document Information\n- **Source**: PDF Document (27 pages)\n- **Category**: lab-material\n- **Difficulty**: advanced\n- **Relevant Labs**: lab3\n- **Topics**: accessibility, classification, gee, gis, google earth engine, machine learning, malaria, mapping, projection, public health, python, raster, remote sensing, satellite, spatial analysis, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 3 gee environmental risk ma\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- classification\n- gee\n- gis\n- google earth engine\n- machine learning\n- malaria\n- mapping\n- projection\n- public health\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "advanced",
      "lab": "lab3",
      "topics": [
        "accessibility",
        "classification",
        "gee",
        "gis",
        "google earth engine",
        "machine learning",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "python",
        "raster",
        "remote sensing",
        "satellite",
        "spatial analysis",
        "vector"
      ],
      "source": "concepts\\lab_3_gee_environmental_risk_ma.md",
      "filename": "lab_3_gee_environmental_risk_ma.md"
    }
  },
  {
    "id": "concepts-lab_4_ai-assisted_gee_programmi",
    "title": "Lab 4 AI Assisted GEE Programmi",
    "content": "\n# Lab 4 AI Assisted GEE Programmi\n\n\n\n \nEnhanced AI-Assisted Google Earth Engine \nProgramming Tutorial: Transforming \nEnvironmental Analysis Through Intelligent Code \nGeneration \nThis revolutionary tutorial introduces a paradigm shift in environmental programming education by \nintegrating artificial intelligence tools with Google Earth Engine's powerful cloud-based geospatial \nanalysis capabilities. Through the strategic use of ChatGPT and other AI coding assistants, students and \nresearchers can accelerate their learning curve, improve code quality, and focus on scientific insights \nrather than syntax challenges \n[1]\n. The integration of AI assistance in programming education has \ndemonstrated significant benefits including 92% productivity increases and 89% improvement in \ndebugging capabilities, while maintaining academic integrity through proper verification practices \n[2]\n. This \ncomprehensive guide provides the foundation for leveraging AI tools to enhance environmental research \ncapabilities while developing genuine programming expertise in the rapidly evolving field of Earth \nobservation science. \n\n \nCover of the book \"AI Assisted Programming for Web and Machine Learning\" detailing the use of ChatGPT \nand GitHub Copilot. \n1. Introduction to AI-Assisted Programming in Environmental Science \n\n1.1 The Revolution of Intelligent Programming Assistance \nArtificial intelligence has fundamentally transformed the landscape of programming education and \npractice, particularly in specialized domains like environmental science and remote sensing \n[1]\n. AI-assisted \nprogramming represents a collaborative approach where human programmers work alongside intelligent \nsystems to write, debug, and optimize code more effectively than either could accomplish independently \n[3]\n. The emergence of large language models like ChatGPT has democratized access to sophisticated \nprogramming assistance, enabling researchers and students to overcome technical barriers and focus on \nscientific problem-solving \n[2]\n. \nThe application of AI programming assistance in environmental science addresses several critical \nchallenges including the complexity of satellite data processing, the steep learning curve associated with \nplatforms like Google Earth Engine, and the need for rapid prototyping of analytical workflows \n[4]\n. Modern \nenvironmental challenges require interdisciplinary approaches that combine domain expertise with \ntechnical programming skills, making AI assistance particularly valuable for bridging knowledge gaps \n[5]\n. \nResearch has demonstrated that AI-assisted programming can reduce development time by up to 50% \nwhile improving code quality and reducing errors \n[6]\n. \n \n\nA satellite with extended solar panels orbits in space, representing remote sensing capabilities for \nenvironmental monitoring. \n1.2 Educational Benefits and Transformative Learning \nAI-assisted programming education offers transformative benefits that extend beyond simple code \ngeneration to encompass accelerated learning, enhanced confidence building, and improved \nunderstanding of complex programming concepts \n[1]\n. Students using AI programming assistants \ndemonstrate 85% faster learning curves for new programming concepts and 78% improvement in \nconfidence when tackling complex analytical challenges \n[7]\n. The interactive nature of AI assistance \nprovides immediate feedback and explanation, creating a personalized tutoring experience that adapts to \nindividual learning styles and pace \n[3]\n. \nThe educational value of AI assistance lies not in replacing traditional learning but in amplifying human \ncapabilities and removing barriers to entry in technical fields \n[8]\n. By handling routine syntax concerns and \nproviding instant debugging support, AI tools enable students to focus on higher-level conceptual \nunderstanding and problem-solving strategies \n[2]\n. This approach is particularly valuable in environmental \nscience education where students must master both domain-specific knowledge and technical \nprogramming skills to conduct meaningful research \n[9]\n. \n\n \nBenefits and Considerations of AI-Assisted Programming in Education \n1.3 Ethical Considerations and Academic Integrity \nThe integration of AI assistance in programming education requires careful consideration of ethical \nimplications and academic integrity principles \n[10]\n. While AI tools provide substantial benefits, their use \nmust be balanced with the development of independent programming skills and critical thinking abilities \n[8]\n. Educational institutions and instructors must establish clear guidelines for AI tool usage that promote \nlearning while maintaining academic honesty \n[11]\n. \nResponsible AI use in education involves transparency about AI assistance, verification of generated code, \nand ensuring that students develop genuine understanding rather than mere dependence on automated \ntools \n[12]\n. The goal is to use AI as a learning amplifier that accelerates skill development while preserving \nthe essential human elements of creativity, problem-solving, and domain expertise \n[13]\n. Best practices \ninclude disclosing AI assistance, understanding generated code thoroughly, and building incremental \nexpertise through guided practice \n[10]\n. \n2. Understanding ChatGPT for Google Earth Engine Programming \n\n2.1 Natural Language to Code Translation \nChatGPT's ability to translate natural language descriptions into functional Google Earth Engine JavaScript \ncode represents a breakthrough in accessibility for environmental programming \n[2]\n. The model's training \non extensive code repositories and documentation enables it to understand both the intent behind \nprogramming requests and the specific syntax requirements of the Earth Engine API \n[14]\n. This capability \nallows researchers to describe their analytical goals in plain language and receive immediate, functional \ncode implementations \n[3]\n. \nThe natural language interface significantly reduces the cognitive load associated with learning new \nprogramming languages and APIs, enabling domain experts to focus on scientific questions rather than \ntechnical implementation details \n[15]\n. For Google Earth Engine specifically, ChatGPT can generate code for \ncommon tasks including data loading, filtering, processing, visualization, and export operations \n[16]\n. This \ncapability is particularly valuable for researchers who need to rapidly prototype analytical workflows or \nexplore new methodological approaches \n[17]\n. \n2.2 Code Explanation and Learning Support \nBeyond code generation, ChatGPT provides sophisticated code explanation capabilities that support deep \nlearning and understanding of Earth Engine programming concepts \n[2]\n. When presented with existing \ncode, the model can break down complex operations line by line, explaining the purpose and function of \neach component \n[18]\n. This explanatory capability transforms opaque code into learning opportunities, \nhelping users understand not just what the code does but why specific approaches are used \n[3]\n. \nThe interactive nature of ChatGPT's explanations allows for follow-up questions and clarification \nrequests, creating a personalized tutoring experience that adapts to individual knowledge levels \n[7]\n. For \nEarth Engine programming, this includes explanations of data structures, function parameters, processing \nworkflows, and optimization strategies \n[15]\n. Users can request explanations at different levels of detail, \nfrom high-level conceptual overviews to detailed technical implementation discussions \n[12]\n. \n2.3 Debugging and Error Resolution \nChatGPT's debugging capabilities provide immediate assistance for resolving programming errors and \noptimizing code performance \n[2]\n. When presented with error messages and problematic code, the model \ncan identify likely causes and suggest specific fixes \n[3]\n. This debugging support is particularly valuable for \nEarth Engine programming, where complex data processing workflows can generate obscure error \nmessages that are difficult for beginners to interpret \n[14]\n. \n\nThe AI's debugging approach typically involves systematic analysis of error patterns, identification of \ncommon mistake categories, and provision of corrected code examples \n[6]\n. For Earth Engine applications, \nthis includes assistance with coordinate reference system errors, data filtering problems, memory \nlimitations, and export configuration issues \n[15]\n. The immediate availability of debugging support reduces \nfrustration and maintains learning momentum, particularly important for complex environmental \nanalysis projects \n[17]\n. \n3. Google Earth Engine-Specific AI Applications \n3.1 Satellite Data Access and Processing \nAI assistance proves particularly valuable for navigating Google Earth Engine's extensive satellite data \ncatalog and implementing appropriate processing workflows \n[16]\n. ChatGPT can help users identify relevant \ndatasets for specific research questions, understand data characteristics and limitations, and implement \nproper filtering and preprocessing steps \n[19]\n. The complexity of satellite data products, with their various \nbands, quality flags, and temporal characteristics, makes AI assistance especially beneficial for \nresearchers new to remote sensing \n[20]\n. \n \nEarth observation satellites shown in orbit collecting data. \n\nThe AI can generate code for common satellite data processing tasks including cloud masking, \natmospheric correction, temporal compositing, and multi-sensor data fusion \n[21]\n. For environmental \nmonitoring applications, this includes implementing vegetation index calculations, water body detection, \nland cover classification, and change detection analyses \n[22]\n. The ability to quickly prototype different \nanalytical approaches enables researchers to explore methodological alternatives and optimize their \nworkflows \n[23]\n. \n3.2 Spatial Analysis and Visualization \nGoogle Earth Engine's spatial analysis capabilities can be efficiently leveraged through AI-assisted code \ngeneration for complex geospatial operations \n[16]\n. ChatGPT can help implement spatial filtering, geometric \noperations, zonal statistics, and advanced analytical techniques that would otherwise require extensive \nmanual coding \n[15]\n. This capability is particularly valuable for environmental applications requiring \nsophisticated spatial analysis workflows \n[24]\n. \n \nA land cover map of Albufeira dos Pequenos, Mozambique, illustrating various land classifications derived \nfrom satellite remote sensing data. \n\nVisualization of results represents another area where AI assistance provides significant value, helping \nusers create effective maps, charts, and interactive displays of their analytical results \n[17]\n. The AI can \ngenerate code for customizing color palettes, classification schemes, layout parameters, and export \nsettings to create publication-ready visualizations \n[16]\n. This capability enables researchers to focus on \ninterpretation and communication of results rather than technical visualization details \n[25]\n. \n3.3 Environmental Monitoring Applications \nAI-assisted programming excels in implementing environmental monitoring workflows that require \nintegration of multiple data sources and complex analytical procedures \n[9]\n. ChatGPT can help generate \ncode for monitoring applications including air quality assessment, water resource monitoring, \ndeforestation tracking, and agricultural productivity analysis \n[26]\n. These applications often require \nsophisticated temporal analysis, statistical modeling, and multi-scale assessment approaches that benefit \nsignificantly from AI assistance \n[21]\n. \n \nA diagram illustrating the use of optical and SAR remote sensing satellites for monitoring various \nenvironmental phenomena and hazards. \n\nThe integration of environmental domain knowledge with programming assistance enables rapid \ndevelopment of monitoring systems that can track environmental changes, assess intervention \neffectiveness, and support policy decision-making \n[23]\n. AI assistance is particularly valuable for \nimplementing early warning systems, anomaly detection algorithms, and predictive modeling approaches \nthat require complex programming logic \n[24]\n. \n4. Prompt Engineering Best Practices for Earth Engine \n4.1 Constructing Effective Programming Prompts \nEffective prompt engineering for Google Earth Engine programming requires clear specification of \nobjectives, constraints, and desired outputs \n[12]\n. The most successful prompts combine specific technical \nrequirements with sufficient context about the analytical goals and data characteristics \n[27]\n. For Earth \nEngine applications, this includes specifying geographic areas of interest, temporal periods, satellite \ndatasets, processing requirements, and output formats \n[28]\n. \nOptimal prompts follow a structured format that includes role assignment, context provision, step-by-step \ntask breakdown, format specification, and quality requirements \n[11]\n. For example, effective prompts might \nbegin by establishing the AI as a remote sensing expert, provide background on the research question, \nspecify the exact analytical steps required, and request code with comprehensive documentation \n[12]\n. This \nstructured approach ensures that generated code meets both technical and scientific requirements \n[27]\n. \n4.2 Iterative Prompt Refinement \nPrompt engineering for complex Earth Engine applications typically requires iterative refinement to \nachieve optimal results \n[27]\n. Initial prompts often generate functional code that requires modification to \naddress specific requirements, handle edge cases, or optimize performance \n[28]\n. The iterative process \ninvolves testing generated code, identifying limitations or errors, and refining prompts to address specific \nissues \n[11]\n. \nSuccessful refinement strategies include providing example inputs and outputs, specifying error handling \nrequirements, requesting alternative approaches, and asking for code optimization suggestions \n[12]\n. For \nEarth Engine programming, refinement often focuses on memory management, processing efficiency, data \nquality control, and visualization enhancement \n[15]\n. The goal is to develop increasingly sophisticated \nprompts that generate production-ready code for complex environmental analysis tasks \n[27]\n. \n4.3 Domain-Specific Prompt Templates \n\nDeveloping standardized prompt templates for common Earth Engine tasks improves efficiency and \nensures consistent code quality \n[28]\n. These templates can be customized for specific applications including \nvegetation monitoring, water resource assessment, urban analysis, and climate studies \n[11]\n. Effective \ntemplates incorporate best practices for data access, processing workflows, quality control, and result \nvisualization \n[12]\n. \nTemplate development should consider common analysis patterns, typical data requirements, standard \nprocessing steps, and frequent troubleshooting needs \n[27]\n. For environmental applications, templates \nmight address seasonal analysis, trend detection, anomaly identification, and multi-temporal comparison \n[15]\n. Well-designed templates enable researchers to quickly generate customized code for their specific \nresearch questions while maintaining consistency and quality standards \n[28]\n. \n5. Step-by-Step Implementation Tutorial \n5.1 Platform Setup and Initial Configuration \nBegin your AI-assisted Earth Engine programming by establishing accounts and configuring your \ndevelopment environment \n[14]\n. Access Google Earth Engine at code.earthengine.google.com and ChatGPT \nat chat.openai.com in separate browser tabs to enable efficient workflow between platforms \n[29]\n. Create a \nnew Earth Engine script named \"Lab4_AI_Assisted_Analysis\" and save it in your workshop folder for \norganized project management \n[16]\n. \nConfigure your workspace by enabling the Earth Engine documentation panel, setting up the code editor \npreferences, and familiarizing yourself with the debugging console \n[15]\n. Open ChatGPT in a separate \nwindow and begin your session by establishing context with an introductory prompt such as \"I'm working \non Google Earth Engine JavaScript programming for environmental analysis and need assistance with \ncode generation and debugging\" \n[12]\n. This context-setting improves the relevance and accuracy of \nsubsequent AI responses \n[27]\n. \n5.2 Your First AI-Generated Earth Engine Code \nStart with a fundamental Earth Engine task to demonstrate the AI assistance workflow \n[16]\n. Copy this \ncomprehensive prompt to ChatGPT to generate your first analytical code: \n\"As a Google Earth Engine expert, write JavaScript code that: 1. Loads Landsat 8 Surface Reflectance data \n('LANDSAT/LC08/C02/T1_L2') for Kenya, 2. Filters for images from January 2023 to December 2023, 3. \nApplies cloud masking using the QA_PIXEL band, 4. Calculates NDVI using the formula (NIR - Red) / (NIR + \nRed), 5. Creates a median composite for the year, 6. Clips the result to Kenya's boundary using \n\n'USDOS/LSIB_SIMPLE/2017', 7. Displays the result with a green color palette, 8. Centers the map on \nKenya with zoom level 6, 9. Includes comprehensive comments explaining each step\" \n[15]\n. \n \nAI-assisted Google Earth Engine programming step-by-step workflow \nThe AI will generate comprehensive code that demonstrates proper Earth Engine syntax, data handling \nprocedures, and visualization techniques \n[14]\n. Copy the generated code into your Earth Engine script and \nexecute it to verify functionality \n[16]\n. Examine each section of the code to understand the logical flow, data \nprocessing steps, and parameter specifications \n[18]\n. \n5.3 Code Testing and Validation \nExecute the AI-generated code and systematically verify its functionality \n[15]\n. Check the map display for \nproper visualization, examine the console output for any error messages, and verify that the analysis \nextent matches your expectations \n[14]\n. Common issues might include incorrect dataset IDs, improper date \nformatting, visualization parameter errors, or memory limitations with large datasets \n[16]\n. \nIf errors occur, copy the exact error message and problematic code section back to ChatGPT with a \ndebugging request such as \"I received this error message: [ERROR TEXT]. Here's the code that generated \n\nit: [CODE SECTION]. Please help me identify and fix the problem\" \n[2]\n. The AI will typically provide both \ncorrected code and an explanation of the error cause, supporting your learning process \n[3]\n. \n5.4 Code Enhancement and Optimization \nRequest code improvements and additional functionality to extend your analysis capabilities \n[16]\n. Ask \nChatGPT to enhance your code with features such as \"Add a function to calculate and export zonal \nstatistics for administrative boundaries,\" \"Include time series analysis to show seasonal NDVI trends,\" or \n\"Add interactive charting capabilities to display temporal patterns\" \n[15]\n. \nThe enhancement process demonstrates the iterative nature of AI-assisted programming, where initial \nfunctional code serves as a foundation for increasingly sophisticated analysis \n[27]\n. Request explanations for \nnew functionality to ensure you understand the enhanced capabilities and can modify them for future \napplications \n[12]\n. \n5.5 Documentation and Code Organization \nGenerate comprehensive documentation for your analytical workflow using AI assistance \n[2]\n. Request that \nChatGPT create detailed comments, function documentation, and user guides for your code \n[3]\n. Ask for \nexplanations of parameter choices, discussion of limitations and assumptions, and suggestions for \nalternative approaches \n[18]\n. \nProper documentation ensures that your code is reproducible, maintainable, and understandable to \ncollaborators \n[15]\n. AI assistance can help generate professional-quality documentation that follows best \npractices and includes all necessary information for code reuse and modification \n[14]\n. \n6. Advanced Analysis Techniques with AI Assistance \n6.1 Multi-Temporal Change Detection \nAI assistance enables rapid implementation of sophisticated change detection analyses that track \nenvironmental changes over time \n[19]\n. Request code for comparing satellite imagery across different time \nperiods, implementing change detection algorithms, and quantifying the magnitude and direction of \nobserved changes \n[21]\n. ChatGPT can generate code for both simple difference calculations and complex \nstatistical change detection methods \n[22]\n. \nAdvanced change detection implementations might include trend analysis using linear regression, \nbreakpoint detection algorithms, or machine learning-based change classification approaches \n[23]\n. The AI \ncan help implement quality control procedures, statistical significance testing, and uncertainty \n\nassessment for change detection results \n[24]\n. These capabilities enable researchers to develop robust \nmonitoring systems for environmental applications \n[26]\n. \n6.2 Machine Learning Integration \nLeverage AI assistance to implement machine learning workflows within Google Earth Engine for \nclassification, regression, and pattern recognition tasks \n[30]\n. ChatGPT can generate code for supervised \nclassification using Random Forest, Support Vector Machine, or Gradient Tree Boosting algorithms \n[16]\n. \nThe AI assistance includes help with training data preparation, feature selection, model validation, and \naccuracy assessment procedures \n[15]\n. \nAdvanced machine learning implementations might include unsupervised clustering, dimensionality \nreduction, ensemble methods, or deep learning integration \n[17]\n. AI assistance proves particularly valuable \nfor optimizing hyperparameters, implementing cross-validation procedures, and interpreting model \nresults \n[14]\n. These capabilities enable sophisticated analytical approaches that would otherwise require \nextensive manual programming \n[29]\n. \n6.3 Scalable Processing Workflows \nImplement large-scale processing workflows using AI assistance to handle continental or global analyses \n[16]\n. Request code for batch processing multiple images, implementing parallel processing strategies, and \nmanaging memory limitations for large datasets \n[15]\n. ChatGPT can help design efficient workflows that \nmaximize Earth Engine's computational capabilities while minimizing processing time and resource \nconsumption \n[14]\n. \nScalable workflow implementations include strategies for data chunking, progressive processing, error \nhandling, and result aggregation \n[17]\n. AI assistance can help implement monitoring and logging systems \nthat track processing progress and identify potential issues \n[29]\n. These capabilities enable researchers to \nconduct large-scale environmental assessments that would be impractical with traditional desktop \nprocessing \n[30]\n. \n7. Professional Development and Career Applications \n7.1 Building Technical Expertise \nAI-assisted programming provides a pathway for rapidly developing technical expertise in environmental \nremote sensing and geospatial analysis \n[13]\n. The combination of immediate code assistance, \ncomprehensive explanations, and iterative refinement enables accelerated learning that builds both \n\npractical skills and conceptual understanding \n[8]\n. Students can progress from basic programming tasks to \nsophisticated analytical workflows more quickly than traditional learning approaches \n[1]\n. \nThe key to professional development through AI assistance lies in maintaining balance between tool \nutilization and independent skill building \n[10]\n. Successful learners use AI tools to overcome initial barriers \nwhile gradually building the expertise needed for independent programming and problem-solving \n[31]\n. \nThis approach enables career advancement in fields requiring both domain expertise and technical \nprogramming capabilities \n[13]\n. \n7.2 Research and Academic Applications \nAI-assisted Earth Engine programming opens new possibilities for research productivity and \nmethodological innovation \n[9]\n. Researchers can rapidly prototype analytical approaches, test alternative \nmethodologies, and implement complex workflows that would otherwise require extensive development \ntime \n[20]\n. This capability enables more ambitious research projects and faster iteration cycles for \nmethodological development \n[21]\n. \nAcademic applications include developing new analytical methods, implementing reproducible research \nworkflows, and creating educational materials and tutorials \n[19]\n. AI assistance can help generate code for \nnovel research approaches, implement cutting-edge algorithms, and develop tools for sharing research \nmethods with the broader scientific community \n[23]\n. These capabilities enhance research impact and \nfacilitate collaboration across institutions and disciplines \n[24]\n. \n7.3 Operational and Commercial Applications \nThe skills developed through AI-assisted Earth Engine programming have direct applications in \noperational environmental monitoring and commercial geospatial services \n[25]\n. Professional applications \ninclude developing automated monitoring systems, implementing real-time analysis workflows, and \ncreating custom analytical tools for specific client needs \n[26]\n. AI assistance enables rapid development of \nproduction-ready systems that meet operational requirements \n[22]\n. \nCommercial applications span industries including agriculture, forestry, urban planning, insurance, and \nenvironmental consulting \n[9]\n. The ability to quickly develop and deploy analytical solutions using AI \nassistance provides competitive advantages in markets requiring rapid response to client needs \n[21]\n. These \napplications demonstrate the practical value of combining domain expertise with AI-enhanced \nprogramming capabilities \n[23]\n. \n8. Ethical Considerations and Best Practices \n\n8.1 Responsible AI Use in Environmental Science \nResponsible use of AI programming assistance requires understanding both the capabilities and \nlimitations of these tools in environmental science applications \n[10]\n. Users must verify AI-generated code \nfor scientific accuracy, validate results against known benchmarks, and understand the assumptions and \nlimitations of implemented methods \n[12]\n. The goal is to use AI assistance to enhance human capabilities \nwhile maintaining scientific rigor and methodological transparency \n[8]\n. \nEthical considerations include proper attribution of AI assistance, transparent reporting of \nmethodological approaches, and careful validation of results \n[11]\n. Environmental science applications have \nparticular responsibilities for accuracy given their potential impact on policy decisions and resource \nmanagement \n[9]\n. Best practices include independent verification of results, peer review of AI-assisted \nanalyses, and clear documentation of AI tool usage \n[10]\n. \n8.2 Academic Integrity and Learning Goals \nMaintaining academic integrity while using AI programming assistance requires clear guidelines and \ntransparent practices \n[8]\n. Educational institutions must develop policies that encourage beneficial AI use \nwhile preserving learning objectives and assessment validity \n[10]\n. Students should disclose AI assistance, \ndemonstrate understanding of generated code, and develop independent programming capabilities \nalongside AI tool usage \n[31]\n. \nLearning goals should emphasize understanding over code production, with AI assistance serving as a \nlearning amplifier rather than a replacement for skill development \n[13]\n. Successful educational approaches \nuse AI tools to remove barriers and accelerate learning while ensuring that students develop the critical \nthinking and problem-solving skills essential for independent research \n[12]\n. This balance enables students \nto benefit from AI assistance while building the expertise needed for long-term career success \n[8]\n. \n8.3 Future Perspectives and Continuous Learning \nThe rapid evolution of AI tools requires continuous learning and adaptation of best practices \n[11]\n. \nEnvironmental scientists and programmers must stay current with new capabilities, emerging limitations, \nand evolving ethical considerations \n[10]\n. The goal is to maintain effectiveness and responsibility as AI tools \nbecome increasingly sophisticated and integrated into scientific workflows \n[13]\n. \nFuture developments may include more specialized AI assistants for environmental applications, \nimproved integration with scientific computing platforms, and enhanced capabilities for complex \nanalytical tasks \n[31]\n. Successful professionals will adapt their practices to leverage new capabilities while \n\nmaintaining scientific standards and ethical principles \n[8]\n. This adaptive approach ensures continued \nbenefit from AI assistance throughout evolving technological landscapes \n[12]\n. \n9. Conclusion and Next Steps \nThis comprehensive tutorial demonstrates the transformative potential of AI-assisted programming for \nGoogle Earth Engine applications in environmental science and remote sensing. The integration of \nChatGPT and similar AI tools with Earth Engine's powerful analytical capabilities creates unprecedented \nopportunities for accelerated learning, enhanced productivity, and methodological innovation \n[2]\n. Through \nproper implementation of AI assistance, researchers and students can overcome technical barriers, focus \non scientific insights, and develop sophisticated analytical capabilities more rapidly than traditional \napproaches allow \n[3]\n. \nThe success of AI-assisted programming depends on maintaining balance between tool utilization and \nskill development, ensuring that AI assistance enhances rather than replaces human expertise \n[10]\n. The \nmost effective practitioners use AI tools to amplify their capabilities while building the independent skills \nand critical thinking abilities essential for scientific research \n[8]\n. This approach enables both immediate \nproductivity gains and long-term professional development in the rapidly evolving field of environmental \nremote sensing \n[13]\n. \nFuture applications of AI-assisted Earth Engine programming will likely expand to include real-time \nmonitoring systems, automated analysis pipelines, and integration with machine learning platforms \n[31]\n. \nThe foundational skills and best practices developed through this tutorial provide preparation for these \nemerging applications while contributing immediately to current research and operational needs \n[11]\n. As \nenvironmental challenges become increasingly complex and urgent, the combination of human expertise \nwith AI assistance offers powerful tools for developing effective monitoring, analysis, and decision-\nsupport systems that can contribute to environmental sustainability and informed policy-making \n[9]\n. \n⁂ \n \n1. https://blog.jetbrains.com/education/2025/04/15/learn-ai-assisted-programming-with-jetbrains-academy-and-\nnebius/     \n2. https://www.techrepublic.com/article/chatgpt-benefits-developers/          \n3. https://kodekloud.com/courses/ai-assisted-development         \n4. https://plego.com/blog/leverage-chatgpt-assisted-coding/  \n\n5. https://algocademy.com/uses/ai-assisted-programming-learning/  \n6. https://theusaleaders.com/articles/ai-tools-for-students/   \n7. https://www.deeplearning.ai/short-courses/ai-python-for-beginners/   \n8. https://www.code.org/artificial-intelligence         \n9. https://appliedsciences.nasa.gov/sites/default/files/2020-11/healthmonitoringpart2.pdf       \n10. https://www.techforgood.net/guestposts/the-ethical-debate-around-students-using-chatgpt-in-education         \n11. https://campusrecmag.com/seven-best-practices-for-ai-prompt-engineering/        \n12. https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api            \n13. https://www.coursera.org/professional-certificates/applied-artifical-intelligence-ibm-watson-ai       \n14. https://developers.google.com/earth-engine/guides/getstarted         \n15. https://developers.google.com/earth-engine/guides/best_practices              \n16. https://courses.spatialthoughts.com/end-to-end-gee.html            \n17. https://geemap.org/notebooks/125_example_code/      \n18. https://developers.google.com/earth-engine/tutorials/tutorial_js_01    \n19. https://pmc.ncbi.nlm.nih.gov/articles/PMC2640871/    \n20. https://ntrs.nasa.gov/api/citations/20120016675/downloads/20120016675.pdf   \n21. https://ntrs.nasa.gov/api/citations/20230000905/downloads/Holloway_review_satellite monitoring for air quality \nand health.pdf      \n22. https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2023.1270033/full    \n23. https://www.heraldopenaccess.us/openaccess/the-role-of-remote-sensing-in-epidemiological-studies-and-the-\nglobal-pandemic-surveillance      \n24. https://ntrs.nasa.gov/api/citations/20130010179/downloads/20130010179.pdf     \n25. https://pubmed.ncbi.nlm.nih.gov/34465183/   \n26. https://wwwnc.cdc.gov/eid/article/6/3/pdfs/00-0301-combined.pdf    \n27. https://www.prompthub.us/blog/10-best-practices-for-prompt-engineering-with-any-model        \n\n28. https://cloud.google.com/discover/what-is-prompt-engineering     \n29. https://www.youtube.com/watch?v=8rTZS3L8XpI    \n30. https://www.uclaextension.edu/computer-science/gis-geographic-information-systems/course/advanced-remote-\nsensing-geog-xl-182c   \n31. https://geniusee.com/single-blog/ai-in-edtech     \n\n## Document Information\n- **Source**: PDF Document (19 pages)\n- **Category**: lab-material\n- **Difficulty**: advanced\n- **Relevant Labs**: lab4\n- **Topics**: accessibility, classification, clustering, gee, gis, google earth engine, machine learning, python, remote sensing, satellite, spatial analysis, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 4 ai assisted gee programmi\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- classification\n- clustering\n- gee\n- gis\n- google earth engine\n- machine learning\n- python\n- remote sensing\n- satellite\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "advanced",
      "lab": "lab4",
      "topics": [
        "accessibility",
        "classification",
        "clustering",
        "gee",
        "gis",
        "google earth engine",
        "machine learning",
        "python",
        "remote sensing",
        "satellite",
        "spatial analysis",
        "vector"
      ],
      "source": "concepts\\lab_4_ai-assisted_gee_programmi.md",
      "filename": "lab_4_ai-assisted_gee_programmi.md"
    }
  },
  {
    "id": "concepts-lab_4_ai_assisted_gee_programming_tutorial",
    "title": "Lab 4: AI-Assisted Programming for Google Earth Engine - Complete Tutorial",
    "content": "\n# Lab 4: AI-Assisted Programming for Google Earth Engine - Complete Tutorial\n\n\n\nLab 4: AI-Assisted Programming for Google Earth Engine\n\nAI-Powered Coding\n\nEarth Engine Integration\n\nEducational Best Practices\n\nTable of Contents\n1. Learning Objectives\n2. AI in Education & Programming\n3. Introduction to ChatGPT for Coding\n4. GEE-Specific AI Applications\n5. Prompt Engineering Best Practices\n6. Step-by-Step Tutorial\n7. Debugging with AI\n8. Professional Development\nLearning Objectives\nTechnical Skills\nGenerate GEE code using natural language prompts\nDebug JavaScript errors with AI assistance\nUnderstand complex Earth Engine functions\nOptimize code for better performance\nLearning Outcomes\nBuild confidence in programming\nDevelop efficient coding workflows\nMaster prompt engineering techniques\nApply ethical AI practices\n Lab Overview\nThis lab transforms your approach to Google Earth Engine programming by integrating ChatGPT as your coding assistant. You'll\nlearn to leverage AI for writing, understanding, and debugging GEE scripts while maintaining scientific rigor and developing\ngenuine programming expertise. By the end, you'll have a powerful workflow that accelerates your environmental analysis\ncapabilities.\nAI in Education & Programming\nBenefits of AI Coding Assistants\n Accelerated Learning\nAI assistants provide instant explanations, helping you\nunderstand complex concepts and syntax without getting\nstuck on implementation details.\n Confidence Building\nReduces programming anxiety by providing a supportive\nlearning environment where you can experiment and make\nmistakes safely.\n Focused Problem-Solving\nAllows you to focus on scientific questions rather than getting\nbogged down in syntax and implementation details.\nEducational Technology Integration\nModern Learning Paradigm\nAI tools are transforming education by providing personalized,\ninteractive learning experiences that adapt to individual learning styles\nand pace.\nResponsible AI Use in Academic Settings\n\nEthical Guidelines\n• Always cite AI assistance\n• Understand generated code\n• Verify all outputs\n• Use as learning tool\n\nAcademic Integrity\n• Supplement, don't replace learning\n• Develop genuine understanding\n• Practice independent coding\n• Build core competencies\n⚖\nBest Practices\n• Start with simple tasks\n• Gradually increase complexity\n• Always test and validate\n• Document your process\nIntroduction to ChatGPT for Coding\nUnderstanding Large Language Models\nHow ChatGPT Works for Programming\nChatGPT is trained on vast amounts of code and\ndocumentation, allowing it to understand programming\npatterns, syntax, and best practices across multiple\nlanguages including JavaScript for Google Earth Engine.\nKey Capabilities:\n• Code generation from natural language\n• Function and algorithm explanation\n• Error diagnosis and debugging\n• Code optimization suggestions\n• Documentation and commenting\nCapabilities and Limitations\n✅ Strengths\n• Rapid prototyping\n• Syntax assistance\n• Pattern recognition\n• Documentation help\n⚠ Limitations\n• May produce errors\n• Context limitations\n• Requires validation\n• No real-time data\nConversational Programming Approach\n Your Prompt\n\"I need to load MODIS NDVI data for Uganda in\n2023, calculate the mean, and display it with a\ngreen color palette. Can you write the GEE\nJavaScript code?\"\n烙 ChatGPT Response\n// Load Uganda boundary\nvar uganda =\nee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n.filter(ee.Filter.eq('country_na', 'Uganda'));\n// Load and process MODIS NDVI\nvar ndvi =\nee.ImageCollection('MODIS/061/MOD13Q1')\n.filterDate('2023-01-01', '2023-12-31')\n.select('NDVI')\n.mean()\n.clip(uganda);\n// Display on map\nMap.centerObject(uganda, 6);\nMap.addLayer(ndvi, {min: 0, max: 8000, palette:\n['white', 'green']}, 'NDVI');\nGEE-Specific AI Applications\nJavaScript Syntax Assistance\nFunction Syntax Help\nAsk ChatGPT for specific function syntax:\n\"How do I use ee.ImageCollection.filterDate() in\nGoogle Earth Engine?\"\nParameter Explanation\nGet detailed parameter explanations:\n\"Explain the parameters for Map.addLayer() in GEE\"\nDataset Identification & Usage\nDataset Discovery\nChatGPT can help you find the right datasets for your analysis and\nprovide the correct dataset IDs and usage patterns.\nCommon GEE Tasks with AI Assistance\n\nData Loading\nGet help with ImageCollection\nand FeatureCollection syntax\n\nFiltering\nLearn temporal and spatial\nfiltering techniques\n\nProcessing\nMaster calculations,\naggregations, and\ntransformations\n\nExport\nConfigure exports to Drive,\nAssets, or Cloud Storage\nPrompt Engineering Best Practices\nClear and Specific Prompt Construction\n Specificity Principle\nThe more specific your prompt, the better the response.\nInclude context, constraints, and desired outcomes.\n❌ Vague Prompt\n\"Help me with NDVI in\nGEE\"\n✅ Specific Prompt\n\"Write GEE JavaScript\ncode to calculate mean\nNDVI for Kenya in 2023\nusing MODIS MOD13Q1,\nfilter for quality\npixels, and export as\nGeoTIFF to Google\nDrive\"\nProviding Context and Requirements\n Essential Elements\nGeographic Area: Specify country, region, or\ncoordinates\nTime Period: Define start and end dates\nDataset: Mention specific satellite products\n⚙Processing: Describe desired calculations\nOutput: Specify visualization or export needs\nIterative Prompt Refinement\n1\nInitial Prompt\n2\nClarify & Refine\n3\nOptimize & Validate\nExample Prompt Templates\n Vegetation Analysis Template\n\"Write Google Earth Engine JavaScript code to: 1.\nLoad [DATASET] for [LOCATION] 2. Filter for\n[TIME_PERIOD] 3. Calculate [METRIC] (e.g., mean\nNDVI) 4. Clip to [BOUNDARY] 5. Visualize with\n[COLOR_SCHEME] 6. Export as [FORMAT] to\n[DESTINATION]\"\n Climate Analysis Template\n\"Create GEE code to analyze [CLIMATE_VARIABLE]: -\nDataset: [SPECIFIC_PRODUCT] - Region:\n[GEOGRAPHIC_BOUNDS] - Period: [TEMPORAL_RANGE] -\nProcessing: [AGGREGATION_METHOD] - Quality\nfiltering: [QA_REQUIREMENTS] - Output:\n[VISUALIZATION_AND_EXPORT]\"\nStep-by-Step Tutorial\n1\nInitial Setup\nOpen Required Platforms\n Google Earth Engine\nNavigate to code.earthengine.google.com\n烙 ChatGPT\nOpen chat.openai.com in a new tab\nCreate New Script\n// In GEE Code Editor: // 1. Click \"NEW\" button // 2.\nName: \"Lab4_AI_Assistant\" // 3. Save in your workshop\nfolder\n2\nGenerate Your First Code\n Copy This Prompt to ChatGPT:\nWrite Google Earth Engine JavaScript code that: 1. Loads the CHIRPS Daily rainfall dataset ('UCSB-\nCHG/CHIRPS/DAILY') 2. Filters data for July 2023 (2023-07-01 to 2023-07-31) 3. Calculates the total rainfall\nfor that month using .sum() 4. Clips the result to Uganda's boundary using 'USDOS/LSIB_SIMPLE/2017' 5.\nDisplays the result on the map with a blue color palette (white to dark blue) 6. Centers the map on Uganda\nwith zoom level 6 7. Adds the layer with the name \"July 2023 Rainfall\" Please include comments explaining each\nstep.\nExpected Response Structure:\n// Load Uganda boundary var uganda = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n.filter(ee.Filter.eq('country_na', 'Uganda')); // Load CHIRPS rainfall data for July 2023 var rainfall =\nee.ImageCollection('UCSB-CHG/CHIRPS/DAILY') .filterDate('2023-07-01', '2023-07-31') .sum() .clip(uganda); //\nSet up visualization parameters var visParams = { min: 0, max: 200, palette: ['white', 'lightblue', 'blue',\n'darkblue'] }; // Display on map Map.centerObject(uganda, 6); Map.addLayer(rainfall, visParams, 'July 2023\nRainfall');\n3\nTest and Validate Code\n✅ Testing Process\n1. Copy code from ChatGPT to GEE\n2. Click \"Run\" button\n3. Check console for errors\n4. Verify map display\n5. Inspect data values\n⚠ Common Issues\n• Incorrect dataset IDs\n• Wrong date formats\n• Visualization parameter errors\n• Timeout issues with large datasets\n4\nGet Code Explanations\n Ask ChatGPT to Explain Code\nCan you explain this Google Earth Engine code line by line? var rainfall = ee.ImageCollection('UCSB-\nCHG/CHIRPS/DAILY') .filterDate('2023-07-01', '2023-07-31') .sum() .clip(uganda); What does each method do and\nwhy is this sequence important?\nExpected Explanation Format:\nLine 1: Creates an ImageCollection object from the CHIRPS dataset...\nLine 2: Filters the collection to include only images from July 2023...\nLine 3: Sums all daily rainfall values to get total monthly rainfall...\nLine 4: Clips the result to Uganda's boundaries...\n5\nModify and Extend Code\n Request Modifications\n\"Can you modify the previous code to: 1. Change the\ntime period to August 2023 2. Add an export function\nto save as GeoTIFF 3. Include a print statement\nshowing the date range\"\n Add Visualization\n\"Add a histogram chart showing the distribution of\nrainfall values across Uganda for this time period\"\nDebugging with AI\nDebugging Process\nError Interpretation & Troubleshooting\n Common GEE Errors\nTypeError: map.addlayer is not a function\nProblem: Case sensitivity in JavaScript\n// Wrong: map.addlayer // Correct:\nMap.addLayer\nCollection.first: Collection is empty\nProblem: No data found for specified filters\n// Check date ranges and geographic bounds\nprint(collection.size()); // Debug collection\nsize\nSystematic Debugging Approach\n AI-Assisted Debugging Workflow\n1\nCopy Error Message\nInclude the exact error text and relevant code snippet\n2\nProvide Context\nExplain what you're trying to accomplish\n3\nRequest Explanation\nAsk for both the fix and an explanation of why it works\nDebugging Example Scenarios\n Debugging Prompt Template\nI'm getting this error in Google Earth Engine:\n[ERROR MESSAGE] Here's my code: [CODE SNIPPET] I'm\ntrying to [GOAL]. Can you help me fix this error\nand explain what went wrong?\n Real Example\nI'm getting this error: \"Invalid argument:\n'filter'\" Code: var filtered =\ncollection.filter('2023-01-01'); I'm trying to\nfilter by date. What's wrong?\nLearning from Error Messages\n Building Debugging Skills\nWhat to Ask ChatGPT:\n• \"Why did this error occur?\"\n• \"How can I prevent this in the future?\"\n• \"What are common causes of this error?\"\n• \"Show me the corrected code with comments\"\nBuilding Understanding:\n• Always ask for explanations\n• Request alternative approaches\n• Learn the underlying concepts\n• Practice with similar examples\nProfessional Development\nEfficient Workflow Development\n Productivity Strategies\nTemplate Library\nSave successful prompts and code snippets for reuse\nIterative Refinement\nStart simple, then add complexity incrementally\nDocumentation Habit\nDocument your process for future reference\nContinuous Learning with AI\nAI Workflow for Scientific Research\n Learning Strategy\nUse AI as a mentor, not a replacement. Always seek to understand the\n'why' behind the code.\nEthical Considerations in AI-Assisted Programming\n⚖\nAcademic Integrity\n• Always disclose AI assistance\n• Understand generated code\n• Don't submit unverified results\n• Build genuine competency\n\nData Responsibility\n• Validate all results\n• Check for bias in AI responses\n• Verify dataset citations\n• Maintain data quality standards\n\nProfessional Growth\n• Use AI to accelerate learning\n• Develop critical thinking\n• Practice independent coding\n• Share knowledge responsibly\nCareer Applications & Next Steps\n Environmental Applications\n• Climate change monitoring\n• Deforestation analysis\n• Agricultural assessment\n• Disaster response mapping\n• Biodiversity conservation\n Public Health Applications\n• Disease surveillance systems\n• Environmental health assessment\n• Health equity analysis\n• Emergency response planning\n• Intervention targeting\nBuilding Advanced Skills\n Progressive Learning Path\n1\nBasic Prompting\nSimple code generation\n2\nComplex Analysis\nMulti-step workflows\n3\nCustom Functions\nSpecialized algorithms\n4\nIndependent Expert\nAI-enhanced productivity\n Lab 4 Completion Summary\n Skills Acquired\nAI-assisted code generation for GEE\nEffective prompt engineering techniques\nSystematic debugging with AI assistance\nCode understanding and learning strategies\n Next Steps\n→Apply AI assistance to your own projects\n→Explore advanced GEE applications\n→Build a personal prompt library\n→Share knowledge with colleagues\nAdditional Resources\n\nDocumentation\nGoogle Earth Engine Guides\n\nCommunity\nGEE Developers Forum\n\nLearning\nContinued Education Opportunities\n© 2024 GIS Workshop Series - Lab 4: AI-Assisted Programming for Google Earth Engine\nComplete ChatGPT Integration Tutorial for Environmental Analysis\nStart with basic requirementsAdd missing details and constraintsTest code and request improvements\nYou're now equipped to leverage AI for accelerated Earth Engine programming while maintaining scientific\nrigor and building genuine expertise!\n\n## Document Information\n- **Source**: PDF Document (1 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: lab4\n- **Topics**: gee, gis, google earth engine, mapping, public health, satellite\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 4: ai-assisted programming for google earth engine - complete tutorial\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- gee\n- gis\n- google earth engine\n- mapping\n- public health\n- satellite\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "lab4",
      "topics": [
        "gee",
        "gis",
        "google earth engine",
        "mapping",
        "public health",
        "satellite"
      ],
      "source": "concepts\\lab_4_ai_assisted_gee_programming_tutorial.md",
      "filename": "lab_4_ai_assisted_gee_programming_tutorial.md"
    }
  },
  {
    "id": "concepts-lab_5_ai-based_clustering_malaria_risk",
    "title": "Lab 5 AI Based Clustering Malaria Risk",
    "content": "\n# Lab 5 AI Based Clustering Malaria Risk\n\n\n\n \nEnhanced AI-Based Clustering for Malaria Risk \nMapping Tutorial: A Comprehensive Guide to \nMachine Learning and Intelligent Environmental \nAnalysis \nThis groundbreaking tutorial represents the convergence of artificial intelligence, machine learning, and \npublic health surveillance, introducing advanced unsupervised learning techniques for environmental \ndisease risk assessment \n[1]\n. The integration of AI-assisted programming with Google Earth Engine's \nmachine learning capabilities creates unprecedented opportunities for rapid development of \nsophisticated analytical tools that can transform how we approach malaria surveillance and control \n[2]\n. \nThrough the strategic application of K-means clustering algorithms to satellite-derived environmental \ndata, this tutorial demonstrates how modern computational approaches can identify complex patterns in \nenvironmental conditions that influence disease transmission dynamics \n[3]\n. \n\n \nMachine Learning Workflow for Environmental Risk Assessment Using K-means Clustering \n1. Introduction to Machine Learning Revolution in Public Health Surveillance \n\n1.1 The Paradigm Shift to Intelligent Disease Monitoring \nMachine learning has fundamentally transformed epidemiological research by enabling the discovery of \nhidden patterns in complex, high-dimensional health data without requiring predetermined hypotheses \nor labeled training examples \n[1]\n. Unsupervised learning techniques, particularly clustering algorithms, \nhave emerged as powerful tools for identifying latent structures within environmental and health datasets \nthat traditional statistical approaches might overlook \n[3]\n. The application of these techniques to malaria \nsurveillance represents a significant advancement in our ability to understand and predict disease \ntransmission patterns at multiple spatial and temporal scales \n[4]\n. \nThe integration of artificial intelligence with environmental health surveillance addresses several critical \nchallenges in malaria control including the complexity of environmental determinants, the need for real-\ntime risk assessment, and the requirement for scalable analytical approaches that can be applied across \ndiverse geographic settings \n[5]\n. Research demonstrates that AI-assisted analytical workflows can reduce \ndevelopment time by up to 50% while improving analytical accuracy and enabling non-technical users to \nconduct sophisticated spatial analyses \n[6]\n. This democratization of advanced analytical capabilities has \nprofound implications for global health equity and local capacity building in malaria-endemic regions \n[7]\n. \n1.2 Unsupervised Learning Applications in Spatial Epidemiology \nUnsupervised machine learning techniques excel in exploratory data analysis where the goal is to identify \nnatural groupings or patterns within complex datasets without prior knowledge of expected outcomes \n[1]\n. \nIn the context of malaria environmental risk assessment, clustering algorithms can identify areas with \nsimilar combinations of environmental conditions that may support disease transmission, revealing \npatterns that might not be apparent through traditional mapping approaches \n[8]\n. K-means clustering, in \nparticular, has proven effective for partitioning environmental data into distinct risk zones based on \nvegetation indices and precipitation patterns \n[9]\n. \nThe power of unsupervised learning lies in its ability to process multiple environmental variables \nsimultaneously, identifying complex interactions and threshold effects that influence mosquito ecology \nand malaria transmission \n[3]\n. Unlike supervised classification approaches that require extensive training \ndata with known outcomes, unsupervised methods can be applied in data-scarce environments and can \nreveal unexpected patterns that challenge existing assumptions about disease ecology \n[10]\n. This capability \nis particularly valuable for emerging infectious diseases or areas where limited epidemiological \nsurveillance data is available \n[8]\n. \n\n \nK-means Clustering Process for Malaria Environmental Risk Assessment \n1.3 The ChatGPT Revolution in Scientific Programming \nThe emergence of large language models like ChatGPT has created unprecedented opportunities for \naccelerating scientific programming and reducing barriers to advanced analytical techniques \n[6]\n. AI-\nassisted programming enables researchers to rapidly prototype complex analytical workflows, debug \ncode efficiently, and learn new programming concepts through interactive dialogue \n[11]\n. Studies \ndemonstrate that programmers using AI assistance show 92% productivity increases and 89% \nimprovement in debugging capabilities while maintaining code quality and scientific rigor \n[7]\n. \nThe integration of AI programming assistance with Google Earth Engine represents a particularly \npowerful combination, enabling researchers to leverage cloud-based planetary-scale computing \ncapabilities without requiring extensive programming expertise \n[12]\n. This democratization of advanced \ngeospatial analysis tools has profound implications for global health research, particularly in resource-\nlimited settings where technical capacity may be constrained \n[13]\n. The key to successful AI-assisted \nlearning lies in maintaining balance between tool utilization and genuine skill development, ensuring that \nAI augments rather than replaces human expertise and critical thinking \n[14]\n. \n\n2. Theoretical Foundations of Clustering and Environmental Risk Assessment \n2.1 K-means Clustering Algorithm and Spatial Applications \nK-means clustering represents one of the most widely used unsupervised learning algorithms for \npartitioning data into distinct groups based on similarity in feature space \n[3]\n. The algorithm operates by \niteratively assigning data points to the nearest cluster centroid and updating centroid positions to \nminimize within-cluster sum of squared distances \n[15]\n. For environmental health applications, this \napproach enables identification of areas with similar combinations of environmental conditions that may \nsupport disease transmission or vector survival \n[9]\n. \nThe mathematical foundation of K-means clustering relies on minimizing the objective function J = Σᵢ₌₁ⁿ \nΣⱼ₌₁ᵏ wᵢⱼ ||xᵢ - μⱼ||², where wᵢⱼ indicates cluster membership and μⱼ represents cluster centroids \n[16]\n. For \nmalaria risk assessment, this translates to identifying geographic areas where combinations of vegetation \ndensity (NDVI) and precipitation patterns create similar ecological conditions for mosquito breeding and \nsurvival \n[9]\n. The algorithm's computational efficiency and interpretability make it particularly suitable for \nlarge-scale environmental analysis using satellite data \n[2]\n. \nSpatial applications of K-means clustering must consider geographic context and spatial autocorrelation \neffects that can influence cluster formation and interpretation \n[8]\n. The choice of optimal cluster number (k) \nbecomes critical for meaningful environmental risk assessment, requiring validation through domain \nknowledge, statistical metrics like silhouette analysis, and comparison with epidemiological data where \navailable \n[17]\n. Advanced implementations may incorporate spatial constraints or distance-weighted \nclustering to account for geographic proximity and spatial dependence in environmental variables \n[15]\n. \n2.2 Environmental Variables and Disease Ecology \nThe selection and preprocessing of environmental variables for clustering analysis requires deep \nunderstanding of vector ecology and disease transmission dynamics \n[9]\n. NDVI serves as a proxy for \nvegetation density and habitat suitability, with research demonstrating significant correlations between \nvegetation indices and mosquito density, particularly in savannah environments \n[9]\n. Values above 0.36-0.4 \ntypically indicate conditions favorable for increased malaria transmission, though these thresholds vary \nby geographic region and vector species \n[9]\n. \n\n \nNormalized Difference Vegetation Index (NDVI) map showing varying vegetation density across a \ngeographical region, marked with red data points. \nPrecipitation patterns influence malaria transmission through multiple pathways including creation of \nbreeding sites, provision of humidity for adult mosquito survival, and seasonal synchronization of vector \npopulation dynamics \n[18]\n. CHIRPS precipitation data provides high-resolution rainfall estimates that \nenable detailed analysis of temporal and spatial patterns relevant to mosquito breeding cycles \n[19]\n. The \nrelationship between rainfall and malaria transmission follows complex non-linear patterns, with both \ninsufficient and excessive precipitation potentially limiting transmission through different mechanisms \n[18]\n. \n\n \nRainfall estimates across the African continent, with darker shades indicating higher precipitation. \nThe integration of multiple environmental variables requires careful consideration of scale, temporal \nalignment, and ecological relevance to disease transmission processes \n[19]\n. Preprocessing steps including \ntemporal aggregation, spatial resampling, and normalization ensure that variables contribute \nappropriately to clustering outcomes \n[2]\n. Advanced approaches may incorporate additional variables such \nas temperature, elevation, land use patterns, and human population density to create more \ncomprehensive risk assessments \n[20]\n. \n\n2.3 Spatial Scale and Temporal Dynamics in Risk Assessment \nEnvironmental risk assessment for vector-borne diseases requires careful consideration of spatial and \ntemporal scales that align with ecological processes and operational decision-making needs \n[19]\n. Mosquito \nbreeding sites typically operate at scales of meters to kilometers, while population-level transmission \npatterns may be relevant at district or regional scales \n[8]\n. The choice of spatial resolution for clustering \nanalysis must balance ecological relevance with computational efficiency and data availability \n[2]\n. \nTemporal dynamics in environmental risk assessment reflect seasonal patterns of transmission that vary \nwith climate cycles, vector phenology, and human activities \n[18]\n. Annual aggregation of environmental \nvariables provides baseline risk assessment capabilities, while seasonal or monthly analysis enables \nidentification of temporal patterns relevant for intervention timing and early warning systems \n[19]\n. Multi-\nyear analysis can reveal longer-term trends associated with climate change or land use modifications that \nmay influence transmission patterns \n[20]\n. \nThe integration of spatial and temporal analysis enables development of dynamic risk assessment systems \nthat can adapt to changing environmental conditions and support real-time decision-making \n[21]\n. Cloud-\nbased platforms like Google Earth Engine provide the computational infrastructure necessary for \nprocessing large-scale spatiotemporal datasets and implementing sophisticated analytical workflows \n[2]\n. \nThese capabilities are essential for operational applications that require regular updates and responsive \nadaptation to changing conditions \n[22]\n. \n3. Google Earth Engine Machine Learning Implementation \n3.1 Platform Capabilities and Data Access \nGoogle Earth Engine provides unprecedented access to planetary-scale environmental datasets and \ncomputational resources necessary for large-scale machine learning applications \n[2]\n. The platform's data \ncatalog includes over 900 datasets spanning more than 40 years of satellite observations, enabling \ncomprehensive environmental analysis across multiple spatial and temporal scales \n[2]\n. For malaria risk \nassessment, key datasets include MODIS vegetation indices at 250-meter resolution and CHIRPS \nprecipitation data at 5.5-kilometer resolution, both providing the environmental variables necessary for \nclustering analysis \n[23]\n. \nThe platform's cloud-based architecture eliminates traditional barriers associated with satellite data \nacquisition, storage, and processing, enabling researchers in resource-limited settings to conduct \nsophisticated analyses without requiring local computational infrastructure \n[24]\n. Built-in machine learning \nalgorithms including K-means clustering, Random Forest, and Support Vector Machine classifiers provide \n\nready-to-use tools for environmental classification and risk assessment \n[23]\n. The JavaScript and Python \nAPIs enable flexible development of custom analytical workflows while maintaining access to Google's \ncomputational infrastructure \n[10]\n. \n \nIntegration of Satellite Data Sources for AI-Based Malaria Risk Assessment \nIntegration capabilities with external platforms including QGIS, R, and Python enable seamless workflows \nthat combine Earth Engine's processing power with specialized analytical tools and visualization \ncapabilities \n[24]\n. Export functions support multiple formats including GeoTIFF, Shapefile, and CSV, \nensuring compatibility with downstream analysis and decision support systems \n[23]\n. The platform's \nsharing and collaboration features facilitate reproducible research and enable capacity building through \ncode sharing and educational applications \n[10]\n. \n\n3.2 Clustering Algorithm Implementation and Optimization \nGoogle Earth Engine's implementation of K-means clustering provides efficient processing of large \nsatellite datasets through distributed computing and optimized algorithms \n[2]\n. The basic workflow \ninvolves loading and preprocessing environmental data, generating training samples, training the \nclustering algorithm, and applying the classifier to create risk zone maps \n[23]\n. Parameter optimization \nincluding cluster number selection, sample size determination, and spatial resolution choices significantly \ninfluence clustering outcomes and computational efficiency \n[16]\n. \nTraining sample generation strategies must balance representativeness with computational efficiency, \ntypically using random sampling with 1000-5000 points for country-scale analysis \n[2]\n. Stratified sampling \napproaches can ensure representation across environmental gradients, while systematic sampling \nprovides more spatially distributed coverage \n[24]\n. Sample size affects both clustering accuracy and \ncomputational time, requiring optimization based on dataset characteristics and analytical objectives \n[10]\n. \nPerformance optimization techniques include spatial and temporal filtering to reduce data volume, \nappropriate coordinate reference system selection for accurate distance calculations, and memory \nmanagement strategies for large datasets \n[23]\n. Advanced implementations may incorporate preprocessing \nsteps such as cloud masking, outlier detection, and data quality assessment to improve clustering \naccuracy \n[2]\n. Parallel processing capabilities within Earth Engine enable efficient handling of continental or \nglobal-scale analyses \n[24]\n. \n3.3 Validation and Quality Assessment \nValidation of unsupervised clustering results requires multiple approaches including statistical metrics, \ndomain knowledge assessment, and comparison with independent datasets where available \n[3]\n. Internal \nvalidation metrics such as within-cluster sum of squares, silhouette scores, and cluster separation indices \nprovide quantitative assessment of clustering quality \n[17]\n. These metrics help determine optimal cluster \nnumbers and identify potential issues with clustering results \n[16]\n. \nExternal validation through comparison with epidemiological data, expert knowledge, or field \nobservations provides assessment of ecological and public health relevance \n[8]\n. Areas identified as high-\nrisk based on environmental clustering should correspond to known transmission patterns or areas with \nfavorable ecological conditions for vector populations \n[9]\n. Discrepancies between environmental risk and \nobserved transmission patterns may indicate the influence of interventions, surveillance gaps, or \nadditional factors not captured in the environmental analysis \n[4]\n. \n\nSensitivity analysis through parameter variation, temporal stability assessment, and cross-validation with \ndifferent time periods provides insight into clustering robustness and reliability \n[3]\n. Geographic validation \nacross different regions or ecological zones helps assess the generalizability of clustering approaches and \nidentifies potential limitations \n[8]\n. Documentation of validation results and limitations ensures appropriate \ninterpretation and application of clustering outcomes \n[14]\n. \n4. Comprehensive AI-Assisted Tutorial Implementation \n4.1 Environment Setup and ChatGPT Integration \nThe integration of ChatGPT with Google Earth Engine programming requires strategic planning and \nstructured interaction to maximize learning outcomes and code quality \n[6]\n. Begin by establishing clear \nlearning objectives and identifying specific analytical goals for your malaria risk assessment project \n[13]\n. \nOpen both Google Earth Engine (code.earthengine.google.com) and ChatGPT (chat.openai.com) in \nseparate browser tabs to enable efficient iterative development between AI assistance and code testing \n[11]\n. \nEffective AI-assisted learning begins with context-setting prompts that establish the analytical framework \nand technical requirements \n[7]\n. Inform ChatGPT about your project objectives, geographic area of interest, \ntechnical skill level, and specific learning goals to enable more targeted and appropriate assistance \n[6]\n. The \ninitial prompt should clearly specify the integration of MODIS NDVI data, CHIRPS precipitation data, and \nK-means clustering for malaria risk assessment, providing the necessary context for generating relevant \ncode examples \n[14]\n. \nCreate a structured workspace within Google Earth Engine by organizing scripts, importing necessary \nlibraries, and establishing consistent coding practices that facilitate collaboration and reproducibility \n[12]\n. \nSave your project with descriptive names and maintain version control through Earth Engine's script \nmanagement system \n[10]\n. This organized approach enables more effective AI assistance by providing clear \ncontext for debugging and enhancement requests \n[11]\n. \n4.2 Initial Code Generation and Testing \nThe first step in AI-assisted clustering implementation involves generating foundational code that loads \nand processes environmental datasets for your study area \n[6]\n. Use structured prompts that specify data \nsources, temporal periods, geographic boundaries, and processing requirements to ensure ChatGPT \ngenerates appropriate and functional code \n[11]\n. Request comprehensive commenting and explanation to \nsupport learning and understanding of Earth Engine API functions and clustering concepts \n[13]\n. \n\nBegin with a basic implementation that loads MODIS NDVI data for a single year, processes CHIRPS \nprecipitation data, and combines these datasets for clustering analysis \n[7]\n. Test the generated code \nincrementally, starting with data loading functions before proceeding to more complex processing steps \n[14]\n. This approach enables early identification of errors and facilitates iterative improvement through \ntargeted AI assistance \n[6]\n. \nCommon initial challenges include dataset ID specifications, temporal filtering syntax, geographic \nboundary definition, and coordinate reference system consistency \n[11]\n. Use specific error messages and \nproblematic code sections in follow-up prompts to ChatGPT for targeted debugging assistance \n[14]\n. \nRequest explanations for corrections to support learning and prevent similar issues in future \ndevelopment \n[13]\n. \nMonitor memory usage and processing time during initial testing to identify potential optimization needs \n[12]\n. Earth Engine's computational limitations may require modifications to spatial resolution, temporal \nextent, or sampling strategies, which can be addressed through AI-assisted optimization prompts \n[10]\n. \nDocument successful parameter combinations and optimization strategies for future reference and \nsharing \n[7]\n. \n4.3 Clustering Implementation and Parameter Optimization \nImplement K-means clustering through Earth Engine's built-in machine learning functions, beginning with \nbasic parameter settings and systematically optimizing for your specific application \n[2]\n. Use ChatGPT to \ngenerate code that creates training samples, configures clustering parameters, and applies the trained \nalgorithm to your environmental dataset \n[23]\n. Request multiple approaches to parameter selection \nincluding statistical methods and domain knowledge guidance \n[7]\n. \nCluster number selection represents a critical decision that significantly influences risk assessment \noutcomes and interpretation \n[3]\n. Generate code that tests multiple cluster numbers (typically 3-7 for \nmalaria risk assessment) and implements validation metrics to support decision-making \n[16]\n. Use AI \nassistance to implement silhouette analysis, within-cluster sum of squares calculations, and domain-\nspecific validation approaches \n[17]\n. \nSample size optimization balances computational efficiency with clustering accuracy, typically ranging \nfrom 1000-5000 points for national-scale analysis \n[2]\n. Request ChatGPT assistance for implementing \nadaptive sampling strategies that ensure representation across environmental gradients while \nmaintaining computational efficiency \n[24]\n. Test different sampling approaches including random, stratified, \nand systematic methods to identify optimal strategies for your specific application \n[10]\n. \n\nSpatial resolution choices affect both clustering detail and computational requirements, requiring careful \nbalance between analytical precision and operational feasibility \n[23]\n. Use AI assistance to implement multi-\nresolution analysis that compares clustering outcomes at different spatial scales \n[21]\n. This approach \nenables identification of scale-dependent patterns and supports selection of appropriate resolution for \noperational applications \n[2]\n. \n4.4 Visualization and Export Configuration \nDevelop comprehensive visualization capabilities that support both analytical interpretation and \ncommunication to diverse stakeholders \n[24]\n. Use ChatGPT to generate code for customized color schemes \nthat represent risk levels intuitively, with appropriate legends, labels, and cartographic elements \n[10]\n. \nRequest multiple visualization approaches including continuous and categorical representations to \nsupport different analytical needs \n[23]\n. \nInteractive visualization capabilities enable exploration of clustering results and support quality \nassessment through visual inspection \n[2]\n. Generate code for overlay capabilities that combine clustering \nresults with administrative boundaries, population data, and existing epidemiological information \n[24]\n. \nThese integrated visualizations provide context for interpreting environmental risk patterns and \nidentifying priority areas for intervention \n[21]\n. \nExport configuration must support diverse downstream applications including QGIS integration, \nstatistical analysis, and operational decision support systems \n[23]\n. Use AI assistance to implement flexible \nexport functions that provide multiple formats, appropriate metadata, and consistent spatial reference \nsystems \n[10]\n. Automated export workflows enable regular updates and operational implementation of \nclustering results \n[2]\n. \nQuality control visualization includes maps of input data, intermediate processing results, and final \nclustering outcomes to support validation and interpretation \n[24]\n. Generate code for statistical summaries, \ncluster statistics, and validation metrics that provide quantitative assessment of clustering quality \n[16]\n. \nThese materials support both technical validation and communication to non-technical stakeholders \n[7]\n. \n4.5 Advanced Enhancement and Integration \nEnhance basic clustering implementation with advanced features including temporal analysis, multi-\nvariable integration, and predictive capabilities \n[21]\n. Use ChatGPT to generate code for time-series \nclustering that identifies seasonal patterns and long-term trends in environmental risk \n[22]\n. These \ncapabilities support development of early warning systems and climate change adaptation planning \n[20]\n. \n\nIntegration with external datasets including population data, health facility locations, and intervention \ncoverage enables comprehensive risk assessment that considers multiple determinants of transmission \n[8]\n. \nRequest AI assistance for spatial join operations, proximity analysis, and multi-criteria assessment \napproaches that combine environmental clustering with operational considerations \n[10]\n. These integrated \nanalyses provide more actionable intelligence for malaria control programs \n[4]\n. \nAutomated quality control and validation routines ensure consistent and reliable clustering results across \ndifferent time periods and geographic areas \n[3]\n. Generate code for outlier detection, temporal consistency \nchecking, and comparison with historical patterns \n[16]\n. These quality assurance measures support \noperational implementation and build confidence in analytical results \n[14]\n. \nDocumentation and metadata generation enable reproducible research and facilitate sharing with \ncollaborators and stakeholders \n[12]\n. Use AI assistance to create comprehensive documentation including \nmethodology descriptions, parameter specifications, validation results, and usage guidelines \n[11]\n. This \ndocumentation supports sustainable implementation and knowledge transfer to local partners \n[13]\n. \n5. Advanced Analysis Techniques and Interpretation \n5.1 Multi-dimensional Environmental Risk Assessment \nAdvanced clustering applications extend beyond simple NDVI-rainfall combinations to incorporate \nmultiple environmental variables that influence malaria transmission patterns \n[20]\n. Integration of \ntemperature data, elevation models, land use classifications, and hydrological variables creates more \ncomprehensive environmental profiles that better capture the complexity of mosquito ecology \n[19]\n. Use AI \nassistance to develop multi-variable clustering approaches that maintain interpretability while \nincorporating additional environmental dimensions \n[21]\n. \nTemporal clustering analysis reveals seasonal and inter-annual patterns in environmental risk that \nsupport intervention timing and early warning system development \n[18]\n. Generate code for time-series \nclustering that identifies distinct seasonal patterns and anomalous conditions that may indicate elevated \ntransmission risk \n[22]\n. These capabilities enable proactive response to environmental conditions favorable \nfor malaria transmission \n[20]\n. \n\n \nMaps of Kenya illustrating geographical features and malaria epidemiological risk zones. \nHierarchical clustering approaches provide insight into the nested structure of environmental risk, \nrevealing how broad regional patterns subdivide into local risk variations \n[15]\n. Request ChatGPT assistance \nfor implementing hierarchical clustering algorithms that complement K-means analysis and provide \nalternative perspectives on environmental risk patterns \n[3]\n. These multi-scale approaches support \ndecision-making at different administrative levels and enable targeted intervention strategies \n[8]\n. \n5.2 Validation and Uncertainty Assessment \nComprehensive validation of clustering results requires integration of multiple assessment approaches \nincluding statistical metrics, epidemiological validation, and expert knowledge evaluation \n[3]\n. Generate \ncode for computing cluster validity indices including silhouette scores, Calinski-Harabasz indices, and \nDavies-Bouldin indices that provide quantitative assessment of clustering quality \n[17]\n. These metrics \nsupport parameter optimization and enable comparison of different clustering approaches \n[16]\n. \nCross-validation approaches using different time periods, geographic regions, or environmental datasets \nprovide assessment of clustering stability and generalizability \n[8]\n. Use AI assistance to implement temporal \ncross-validation that tests clustering consistency across multiple years and seasonal patterns \n[22]\n. \n\nGeographic cross-validation assesses whether clustering approaches developed in one region transfer \neffectively to other areas with similar ecological conditions \n[20]\n. \nUncertainty assessment acknowledges the inherent limitations of environmental data and clustering \nalgorithms while providing bounds on risk estimates \n[14]\n. Request code for implementing bootstrap \nsampling, sensitivity analysis, and confidence interval estimation that quantify uncertainty in clustering \noutcomes \n[3]\n. These uncertainty measures support appropriate interpretation and application of clustering \nresults in operational settings \n[4]\n. \nEpidemiological validation through comparison with disease surveillance data provides the ultimate test \nof clustering relevance for malaria control applications \n[9]\n. Generate code for spatial overlay analysis that \ncompares environmental risk clusters with reported malaria incidence, intervention coverage, and health \nfacility utilization \n[8]\n. Discrepancies between environmental risk and epidemiological patterns may \nindicate intervention effects, surveillance gaps, or additional risk factors not captured in environmental \nanalysis \n[4]\n. \n5.3 Seasonal Dynamics and Temporal Analysis \nSeasonal analysis of environmental clustering reveals temporal patterns that align with malaria \ntransmission cycles and support intervention timing optimization \n[18]\n. Use ChatGPT to generate code for \nseasonal aggregation of environmental variables, seasonal clustering analysis, and comparison of risk \npatterns across different time periods \n[19]\n. These temporal approaches enable identification of peak \ntransmission periods and support seasonal intervention strategies \n[20]\n. \n\n \nMap showing seasonal rainfall accumulation anomaly across Africa from October 2024 to May 2025, \nbased on CHIRPS satellite data. \nInter-annual variability analysis identifies long-term trends and climate anomalies that may influence \nmalaria transmission patterns \n[18]\n. Generate code for trend analysis, anomaly detection, and climate index \n\nintegration that provides context for environmental risk assessment \n[20]\n. These capabilities support \nclimate change adaptation planning and enable early warning of unusual environmental conditions \n[22]\n. \nReal-time analysis capabilities enable operational implementation of environmental risk assessment for \ncurrent conditions and short-term forecasting \n[21]\n. Request AI assistance for developing automated \nworkflows that process recent satellite data and generate updated risk assessments on regular schedules \n[2]\n. These operational systems support responsive malaria control and enable evidence-based resource \nallocation \n[4]\n. \n6. Professional Applications and Career Development \n6.1 Public Health Program Implementation \nEnvironmental clustering analysis provides direct support for national malaria control programs through \nevidence-based targeting of interventions and resources \n[4]\n. Integration of clustering results with program \nplanning enables optimization of bed net distribution campaigns, indoor residual spraying programs, and \ncase management strategies based on environmental risk patterns \n[8]\n. The spatial precision of clustering \nanalysis supports sub-district level targeting that maximizes intervention impact while optimizing \nresource allocation \n[25]\n. \nEarly warning system development represents a critical application of environmental clustering for \nepidemic preparedness and response \n[20]\n. Automated processing of satellite data combined with clustering \nanalysis enables identification of environmental conditions favorable for malaria transmission before \nincreases in case numbers become apparent through surveillance systems \n[19]\n. These early warning \ncapabilities support proactive deployment of prevention measures and enhanced surveillance activities \n[22]\n. \n\n \n\nSeasonal rainfall accumulation as a percentage of normal for March-May 2025 across Eastern Africa, \nbased on CHIRPS data. \nMonitoring and evaluation of intervention programs benefits from environmental clustering through \nassessment of coverage patterns and identification of areas requiring enhanced intervention intensity \n[4]\n. \nIntegration of clustering results with intervention monitoring data enables assessment of whether high-\nrisk areas are receiving appropriate intervention coverage \n[8]\n. This analytical capability supports adaptive \nmanagement approaches that respond to changing environmental and epidemiological conditions \n[21]\n. \n6.2 Research and Academic Applications \nAcademic research applications of environmental clustering span multiple disciplines including spatial \nepidemiology, environmental health, and climate science \n[25]\n. Researchers can use clustering approaches \nto investigate relationships between environmental change and disease patterns, evaluate intervention \neffectiveness, and develop predictive models for future transmission scenarios \n[26]\n. The accessibility of AI-\nassisted programming enables researchers in resource-limited settings to conduct sophisticated analyses \nwithout requiring extensive programming expertise \n[13]\n. \nClimate change research applications include assessment of changing environmental suitability for \nmalaria transmission under different climate scenarios \n[20]\n. Long-term clustering analysis can identify \nshifting transmission zones, changing seasonal patterns, and emerging risk areas that require enhanced \nsurveillance and control efforts \n[18]\n. These research applications provide critical information for \nadaptation planning and resource allocation under changing environmental conditions \n[22]\n. \nMethodological research focuses on improving clustering algorithms, validation approaches, and \nintegration with other analytical methods \n[3]\n. AI-assisted programming enables rapid prototyping of new \napproaches and comparison of different methodological alternatives \n[11]\n. These research activities \ncontribute to the broader development of spatial analytical tools for environmental health applications \n[21]\n. \n6.3 Technology Transfer and Capacity Building \nKnowledge transfer to national health systems requires development of user-friendly tools and training \nprograms that enable local implementation of clustering approaches \n[13]\n. AI-assisted programming \nfacilitates development of simplified interfaces and automated workflows that reduce technical barriers \nto implementation \n[7]\n. These capacity building efforts support sustainable implementation and local \nownership of analytical capabilities \n[25]\n. \n\nEducational applications include development of training materials, workshops, and online courses that \nteach environmental clustering concepts and implementation techniques \n[27]\n. The combination of AI \nassistance with hands-on practice provides effective learning approaches that build both conceptual \nunderstanding and practical skills \n[6]\n. These educational resources support development of local expertise \nand sustainable capacity for environmental health analysis \n[28]\n. \nCollaboration networks enable sharing of code, data, and analytical approaches across institutions and \ncountries \n[29]\n. AI-assisted programming facilitates standardization of analytical workflows and enables \ncollaborative development of improved methods \n[12]\n. These collaborative approaches accelerate \nmethodological development and support global capacity building for environmental health surveillance \n[30]\n. \n6.4 Career Pathways and Professional Development \nSkills developed through AI-assisted environmental clustering provide foundations for careers in spatial \nepidemiology, environmental health assessment, and global health program management \n[25]\n. The \ncombination of machine learning expertise with public health knowledge creates unique professional \ncapabilities that are increasingly valued in global health organizations \n[31]\n. Career opportunities include \npositions with international organizations, government health agencies, academic institutions, and \ntechnology companies focused on health applications \n[32]\n. \nProfessional development pathways include advanced training in machine learning, spatial analysis, and \npublic health applications \n[27]\n. The rapid evolution of AI tools requires continuous learning and adaptation \nto new capabilities and best practices \n[7]\n. Professional networks and continuing education opportunities \nsupport career advancement and knowledge sharing across the environmental health community \n[29]\n. \nEntrepreneurial opportunities include development of consulting services, software tools, and analytical \nplatforms that serve the growing market for environmental health assessment \n[33]\n. The combination of \ntechnical skills with domain expertise enables development of innovative solutions that address real-\nworld public health challenges \n[31]\n. These entrepreneurial pathways contribute to the broader ecosystem \nof tools and services that support global health improvement \n[26]\n. \n7. Methodological Considerations and Future Directions \n7.1 Limitations and Validation Requirements \nEnvironmental clustering approaches must acknowledge inherent limitations including data quality \nconstraints, algorithm assumptions, and ecological complexity that may not be fully captured in satellite-\n\nderived variables \n[14]\n. MODIS NDVI data quality can be affected by cloud contamination, atmospheric \ninterference, and seasonal vegetation changes that may not directly relate to mosquito habitat suitability \n[9]\n. CHIRPS precipitation estimates vary in accuracy depending on ground station density and may not \ncapture localized rainfall patterns that influence breeding site availability \n[18]\n. \nK-means clustering assumes spherical clusters and similar cluster sizes, which may not reflect the \ncomplex, irregular patterns of environmental suitability for malaria transmission \n[3]\n. The algorithm's \nsensitivity to initialization and outliers requires careful parameter selection and validation to ensure \nrobust results \n[16]\n. Alternative clustering approaches including hierarchical clustering, density-based \nclustering, or mixture model approaches may provide different perspectives on environmental risk \npatterns \n[15]\n. \nValidation requirements include both internal cluster validation using statistical metrics and external \nvalidation through comparison with epidemiological data and expert knowledge \n[8]\n. The lack of \ncomprehensive epidemiological surveillance data in many malaria-endemic areas limits opportunities for \nexternal validation and requires careful interpretation of clustering results \n[4]\n. Temporal validation across \nmultiple years and seasonal patterns provides assessment of clustering stability and reliability \n[22]\n. \n7.2 Integration with Emerging Technologies \nMachine learning advances including deep learning, ensemble methods, and automated feature selection \noffer opportunities for improving environmental risk assessment accuracy and reducing parameter \ndependence \n[21]\n. Integration of convolutional neural networks with satellite imagery analysis may enable \nmore sophisticated pattern recognition and feature extraction \n[34]\n. Ensemble clustering approaches that \ncombine multiple algorithms and parameter settings can provide more robust risk assessments \n[3]\n. \nReal-time data streams from weather stations, mobile phone data, and social media platforms offer \nopportunities for enhancing environmental clustering with additional information sources \n[22]\n. Internet of \nThings (IoT) sensors deployed in field settings can provide ground-truth data for validating satellite-\nderived environmental indicators \n[33]\n. These emerging data sources require development of new \nintegration and analysis approaches \n[21]\n. \nCloud computing advances enable increasingly sophisticated analysis of planetary-scale datasets and \nsupport development of operational monitoring systems \n[2]\n. Edge computing capabilities may enable local \nprocessing and real-time analysis in resource-limited settings \n[33]\n. These technological advances create \nopportunities for more responsive and locally relevant environmental health surveillance \n[31]\n. \n7.3 Policy and Implementation Considerations \n\nPolicy applications of environmental clustering require consideration of decision-making contexts, \nresource constraints, and implementation feasibility \n[25]\n. Results must be presented in formats and at \nscales that align with administrative structures and planning processes \n[26]\n. Integration with existing \nhealth information systems requires compatibility with current data formats and analytical workflows \n[29]\n. \nImplementation challenges include technical capacity building, infrastructure requirements, and \nsustainable financing for operational systems \n[30]\n. Success requires collaboration between technical \nspecialists, public health professionals, and policy makers to ensure that analytical capabilities align with \noperational needs \n[25]\n. Training programs and technical assistance must address both analytical skills and \ninstitutional capacity for sustained implementation \n[27]\n. \nEthical considerations include data privacy, community consent, and equitable access to benefits from \nenvironmental health surveillance \n[14]\n. International collaboration and data sharing require careful \nattention to sovereignty and local ownership of analytical capabilities \n[26]\n. These ethical considerations \nbecome increasingly important as analytical capabilities expand and become more operationally relevant \n[29]\n. \n8. Conclusion and Future Impact \nThis comprehensive tutorial demonstrates the transformative potential of AI-assisted machine learning \nfor environmental health surveillance through the integration of advanced clustering algorithms with \nsatellite-based environmental monitoring \n[1]\n. The combination of Google Earth Engine's planetary-scale \ncomputing capabilities with ChatGPT's intelligent programming assistance creates unprecedented \nopportunities for rapid development of sophisticated analytical tools that can significantly improve \nmalaria surveillance and control effectiveness \n[2][6]\n. The skills and methodological approaches developed \nthrough this tutorial provide a foundation for addressing complex environmental health challenges that \nrequire integration of multiple data sources and analytical approaches \n[21]\n. \nThe democratization of advanced machine learning capabilities through AI-assisted programming has \nprofound implications for global health equity and local capacity building \n[7]\n. Researchers and public \nhealth professionals in resource-limited settings can now access and implement analytical approaches \nthat were previously available only to well-resourced institutions with extensive technical expertise \n[13]\n. \nThis technological democratization supports development of locally relevant solutions and enables \nindigenous research leadership that can enhance the sustainability and cultural appropriateness of \nenvironmental health interventions \n[27]\n. \nFuture applications of these AI-assisted clustering approaches will likely expand to include real-time \nenvironmental monitoring systems, integration with mobile health technologies, and development of \n\npredictive models that combine environmental data with social, economic, and behavioral indicators of \ndisease risk \n[21][22]\n. The rapid advancement of machine learning algorithms, satellite sensor technologies, \nand AI programming assistance tools ensures that the capabilities demonstrated in this tutorial represent \nthe foundation for increasingly sophisticated analytical approaches \n[31]\n. As environmental conditions \ncontinue to change due to climate change and human activities, the importance of intelligent \nenvironmental health surveillance will only increase, making these skills essential for future public health \nprofessionals working in malaria-endemic regions \n[20]\n. \nThe integration of environmental clustering with broader health system strengthening efforts provides \nopportunities to address multiple health challenges simultaneously while building local analytical \ncapacity that supports sustainable disease control programs \n[25]\n. The evidence-based approach \ndemonstrated in this tutorial contributes to the broader goal of achieving universal health coverage and \nhealth equity through more effective targeting of limited resources and more responsive public health \nsystems that adapt to changing environmental and epidemiological conditions \n[26]\n. Through the strategic \napplication of artificial intelligence and machine learning to environmental health challenges, this tutorial \nprovides the foundation for a new generation of public health professionals equipped with the analytical \ntools necessary to address the complex health challenges of the 21st century \n[29]\n. \n⁂ \n \n1. https://pubmed.ncbi.nlm.nih.gov/36378293/     \n2. https://developers.google.com/earth-engine/guides/machine-learning                   \n3. https://pmc.ncbi.nlm.nih.gov/articles/PMC10034574/               \n4. https://pubmed.ncbi.nlm.nih.gov/38509529/          \n5. https://pharmafeatures.com/power-of-unsupervised-learning-in-healthcare/  \n6. https://www.evergrowingdev.com/p/how-to-use-chatgpt-for-learning-to         \n7. https://www.qodo.ai/blog/best-ai-coding-assistant-tools/           \n8. https://pmc.ncbi.nlm.nih.gov/articles/PMC7120538/              \n9. https://pmc.ncbi.nlm.nih.gov/articles/PMC2686729/          \n10. https://dges.carleton.ca/CUOSGwiki/index.php/Unsupervised_Classification_using_Google_Earth_Engine           \n11. https://www.ninjatech.ai/product/ai-code-generator        \n\n12. https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code-and-my-top-trick-for-debugging-what-it-\ngenerates/      \n13. https://algocademy.com/uses/best-ai-coding-tutor/         \n14. https://rollbar.com/blog/how-to-debug-code-using-chatgpt/          \n15. https://journals.lww.com/environepidem/fulltext/2018/09000/pollutant_composition_modification_of_the_effect.8\n.aspx     \n16. https://ml-gis-service.com/index.php/2020/10/14/data-science-unsupervised-classification-of-satellite-images-\nwith-k-means-algorithm/         \n17. https://iwaponline.com/jwh/article/22/8/1527/103290/Reducing-sample-size-by-clustering-A-way-to-make     \n18. https://pmc.ncbi.nlm.nih.gov/articles/PMC10300711/         \n19. https://ui.adsabs.harvard.edu/abs/2018AGUFMGH24A..04A/abstract        \n20. https://wellcome.org/news/how-climate-change-affects-vector-borne-diseases            \n21. https://www.numberanalytics.com/blog/adapting-environmental-changes-remote-sensing             \n22. https://www.youtube.com/watch?v=HMR_2VkDE9s           \n23. https://developers.google.com/earth-engine/guides/classification          \n24. https://blog.gishub.org/earth-engine-tutorial-32-machine-learning-with-earth-engine-supervised-classification         \n25. https://www.indeed.com/q-spatial-epidemiology-jobs.html        \n26. https://www.ziprecruiter.com/Jobs/Spatial-Epidemiology      \n27. https://www.ohio.edu/cas/geography/graduate/gis-geospatial-analysis-certificate     \n28. https://www.publichealth.columbia.edu/academics/degrees/master-science/environmental-health-data-science  \n29. https://epiresearch.org/membership/ser-member-homepage/job-board/job-board-current-postings/      \n30. http://scholarshipdb.net/spatial-epidemiology-scholarships   \n31. https://www.indeed.com/q-geospatial-machine-learning-jobs.html     \n32. https://www.linkedin.com/jobs/spatial-epidemiology-jobs  \n33. https://careerservices.wvu.edu/jobs/oak-ridge-institute-for-science-and-education-dcph-a-deployment-\nenvironmental-health-and-remote-sensing-internship/    \n\n34. https://www.lerner.ccf.org/news/article/?title=Cleveland+Clinic+successfully+applies+unsupervised+machine+lea\nrning+for+patient+subtyping+&id=ec1852222847cff8c1ea099acba583bb743da40a  \n\n## Document Information\n- **Source**: PDF Document (26 pages)\n- **Category**: lab-material\n- **Difficulty**: advanced\n- **Relevant Labs**: lab5\n- **Topics**: accessibility, classification, clustering, gis, google earth engine, machine learning, malaria, mapping, overlay, public health, python, qgis, satellite, shapefile, spatial analysis, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 5 ai based clustering malaria risk\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- classification\n- clustering\n- gis\n- google earth engine\n- machine learning\n- malaria\n- mapping\n- overlay\n- public health\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "advanced",
      "lab": "lab5",
      "topics": [
        "accessibility",
        "classification",
        "clustering",
        "gis",
        "google earth engine",
        "machine learning",
        "malaria",
        "mapping",
        "overlay",
        "public health",
        "python",
        "qgis",
        "satellite",
        "shapefile",
        "spatial analysis",
        "vector"
      ],
      "source": "concepts\\lab_5_ai-based_clustering_malaria_risk.md",
      "filename": "lab_5_ai-based_clustering_malaria_risk.md"
    }
  },
  {
    "id": "concepts-lab_5_ml_clustering_malaria_risk_tutorial",
    "title": "Lab 5: AI-Based Clustering for Malaria Risk Mapping - Complete Machine Learning Tutorial",
    "content": "\n# Lab 5: AI-Based Clustering for Malaria Risk Mapping - Complete Machine Learning Tutorial\n\n\n\nLab 5: AI-Based Clustering for Malaria\nRisk Mapping\n2-3 HoursAdvanced LevelIndividual/Group\nTable of Contents\n\n1. Machine Learning in Public Health\n\n2. K-means Clustering Theory\n\n3. Environmental Risk Modeling\n\n4. Google Earth Engine ML\n\n5. AI-Assisted Development\n\n6. Step-by-Step Tutorial\n\n7. Results & Validation\n\n8. Professional Applications\nLearning Objectives\n\nUnderstand unsupervised machine learning concepts and\napplications in epidemiology\n\nImplement K-means clustering algorithms for\nenvironmental risk assessment\n\nCombine NDVI and rainfall data for malaria transmission\nrisk modeling\n\nUse ChatGPT for AI-assisted machine learning code\ndevelopment\n\nProcess large-scale satellite data using Google Earth\nEngine clustering tools\n\nInterpret and validate unsupervised classification results\n\nExport and visualize machine learning results in QGIS\n\nApply clustering techniques to real-world public health\nproblems\n1. Machine Learning in Public Health\nUnsupervised Learning Concepts\nUnsupervised Learning discovers hidden patterns in data\nwithout labeled examples. Unlike supervised learning, we\ndon't have \"correct answers\" to train from.\nKey Characteristics:\nNo predefined target variable or outcome\nExplores data structure and relationships\nIdentifies natural groupings or clusters\nUseful for exploratory data analysis\nIn public health, unsupervised learning helps identify:\nDisease outbreak patterns\nRisk factor combinations\nPopulation health subgroups\nEnvironmental exposure zones\nApplications in Epidemiology\n\nSpatial Clustering\nIdentify disease hotspots and\ntransmission zones\n\nTemporal Patterns\nDiscover outbreak timing and\nseasonality\nEnvironmental Risk Assessment with ML\nMachine learning enables us to combine multiple environmental variables to identify areas with similar conditions that\nmay support disease transmission. This approach moves beyond simple thematic mapping to reveal complex\nenvironmental patterns.\nTraditional Mapping\nSingle variable visualization\nMulti-variable Analysis\nCombines multiple risk factors\nPattern Discovery\nReveals hidden relationships\n2. K-means Clustering Theory\nAlgorithm Fundamentals\nK-means clustering partitions data into k clusters by\nminimizing within-cluster sum of squared distances to cluster\ncentroids.\nObjective Function:\nJ = Σᵢ₌₁ⁿ Σⱼ₌₁ᵏ wᵢⱼ ||xᵢ - μⱼ||²\nWhere wᵢⱼ = 1 if xᵢ belongs to cluster j, 0 otherwise\nAlgorithm Steps:\n1. Initialize k cluster centroids randomly\n2. Assign each point to nearest centroid\n3. Update centroids to cluster means\n4. Repeat steps 2-3 until convergence\nClustering Visualization\nK-means Clustering Process\nAdvantages for Spatial Analysis\nSimple and computationally efficient\nWorks well with spherical clusters\nScales to large datasets (like satellite imagery)\nProduces interpretable results\nCompatible with GIS software\n⚠Limitations & Considerations\nRequires pre-defining number of clusters (k)\nSensitive to initialization and outliers\nAssumes clusters are spherical and similar size\nMay struggle with non-linear patterns\nResults can vary between runs\nChoosing Optimal Number of Clusters\nElbow Method\nPlot within-cluster sum of squares vs. k\nand look for \"elbow\" point\nSilhouette Analysis\nMeasure how similar points are to their\nown cluster vs. other clusters\nDomain Knowledge\nUse epidemiological understanding to\nguide cluster number selection\n3. Environmental Risk Modeling\nNDVI as Predictive Variable\nNDVI Values and Sensor Comparison\nNDVI Formula:\nNDVI = (NIR - RED) / (NIR + RED)\nWhere NIR = Near Infrared reflectance, RED = Red reflectance\nMalaria Relevance:\nHigh NDVI indicates dense vegetation\nProvides mosquito resting sites\nCreates humid microenvironments\nCorrelates with suitable breeding conditions\n⛆CHIRPS Rainfall Data\nCHIRPS Characteristics:\nDaily precipitation estimates since 1981\n0.05° spatial resolution (~5.5 km)\nCombines satellite and station data\nOptimized for drought monitoring\nMosquito Breeding Relevance:\nCreates standing water bodies\nOptimal breeding occurs at moderate rainfall\nToo little: insufficient breeding sites\nToo much: washes away larvae\nEcological Niche Modeling Concepts\nEnvironmental Space\nMulti-dimensional space defined by\nenvironmental variables (NDVI, rainfall,\ntemperature, etc.)\nRealized Niche\nActual environmental conditions where\nspecies (mosquitoes) occur in nature\nFundamental Niche\nFull range of environmental conditions\nwhere species can potentially survive\nEnvironmental Suitability Mapping Process\n1\nData Collection\nGather environmental\nvariables (NDVI, rainfall)\n2\nData Processing\nNormalize and combine\nvariables\n3\nClustering\nApply K-means to identify\nsimilar areas\n4\nRisk Assessment\nInterpret clusters as risk\nzones\n4. Google Earth Engine Machine Learning\nGEE Clustering Implementation\nGEE Clustering Workflow:\n1. Load and process image collections\n2. Create composite multi-band image\n3. Generate training samples\n4. Train clustering algorithm\n5. Apply classifier to full image\n6. Visualize and export results\n// Basic GEE K-means structure\nvar clusterer = ee.Clusterer.wekaKMeans(numClusters\nvar trainedClusterer = clusterer.train(trainingSamp\nvar clusteredImage = inputImage.cluster(trainedClus\nData Preprocessing & Feature\nEngineering\nKey Preprocessing Steps:\nTemporal Aggregation: Mean, median, or sum over\ntime periods\nSpatial Resampling: Ensure consistent resolution\nCloud Masking: Remove cloudy pixels from optical\ndata\nNormalization: Scale variables to similar ranges\nBand Stacking: Combine variables into single image\n// Preprocessing example\nvar ndvi = ndviCollection.filterDate(start, end)\n    .select('NDVI').mean().multiply(0.0001);\nvar rainfall = rainfallCollection.filterDate(start,\n    .sum();\n// Stack bands and normalize\nvar input = ndvi.addBands(rainfall.rename('rainfall\n    .unitScale(-1, 1); // Normalize to -1 to 1\nSampling Strategies:\nRandom sampling: Uniform distribution across study\narea\nStratified sampling: Ensure representation of all\nenvironments\nSample size: Balance between performance and\ncomputation time\nParameter Tuning & Optimization\nNumber of Clusters (k)\nStart with 3-5 clusters for malaria risk zones\nSample Size\nTypically 1000-5000 points for country-scale analysis\nSpatial Resolution\nBalance detail with computational efficiency\nLarge-Scale Analysis Considerations\nMemory Management\nUse .clip() to reduce processing area\nParallel Processing\nGEE automatically parallelizes operations\nExport Limitations\nMaximum 1e13 pixels per export task\nPerformance Monitoring\n5. AI-Assisted Development Workflow\nUsing ChatGPT for ML Code\nGeneration\nEffective Prompting Strategies:\nBe specific about the task and context\nInclude data types and expected outputs\nMention relevant libraries (Google Earth Engine)\nRequest explanations with code\nAsk for error handling and best practices\nExample Prompt:\n\"Write a Google Earth Engine script to perform K-means\nclustering on NDVI and rainfall data for Uganda. Use 3 clusters,\nsample 2000 points, and visualize results with distinct colors.\nInclude comments explaining each step.\"\nIterative Development Process\nDevelopment Cycle:\n1Initial prompt and code generation\n2Test code in GEE environment\n3Identify issues or improvements\n4Refine prompt and regenerate\n// Example refinement prompt:\n\"The previous code works but takes too long to proc\nCan you optimize it by reducing the sample size to \npoints and using a coarser spatial resolution of 1k\nCommon Refinement Requests:\nPerformance optimization\nError handling improvements\nAdditional visualization options\nExport format modifications\nParameter adjustments\nDebugging Machine Learning Algorithms\nCommon ML Debugging Issues:\nMemory errors with large datasets\nIncorrect data types or scaling\nEmpty or invalid training samples\nProjection mismatches between datasets\nConvergence failures in clustering\nDebugging with ChatGPT:\nExample: \"I'm getting this error in GEE: 'Image.sample: Too\nmany pixels in the region.' How can I fix this while maintaining\ngood clustering results?\"\nBest Practices for AI-Assisted ML Development\nStart Simple\nBegin with basic clustering, then add\ncomplexity incrementally\nValidate Results\nAlways test AI-generated code with\nsmall datasets first\nLearn Actively\nAsk ChatGPT to explain the reasoning\nbehind code suggestions\n6. Step-by-Step Tutorial\n1\nEnvironment Setup and ChatGPT Preparation\nGoogle Earth Engine Setup\n1. Navigate to\nhttps://code.earthengine.google.com\n2. Sign in with your registered Google account\n3. Create new script: Lab5_Malaria_Clustering.js\n4. Verify access to the Code Editor interface\nChatGPT Preparation\n1. Open https://chat.openai.com in new tab\n2. Start fresh conversation session\n3. Prepare context prompt about your project\n4. Have both tabs ready for iterative development\n2\nGenerate Initial Clustering Code with ChatGPT\nInitial ChatGPT Prompt:\nWrite a Google Earth Engine JavaScript script that performs K-means clustering for malaria risk mapping in\nUganda. The script should:\n1. Load MODIS NDVI data (MODIS/061/MOD13Q1) for 2022\n2. Load CHIRPS rainfall data (UCSB-CHG/CHIRPS/DAILY) for 2022\n3. Compute mean NDVI and total rainfall for the year\n4. Clip data to Uganda boundaries (USDOS/LSIB_SIMPLE/2017)\n5. Stack the bands and perform K-means clustering with 3 clusters\n6. Sample 2000 training points\n7. Visualize results with distinct colors\n8. Add detailed comments explaining each step\nExpected ChatGPT Response Structure:\n// Load and process NDVI data\nvar ndvi = ee.ImageCollection('MODIS/061/MOD13Q1')\n  .filterDate('2022-01-01', '2022-12-31')\n  .select('NDVI')\n  .mean()\n  .multiply(0.0001); // Scale factor\n// Load and process rainfall data  \nvar rainfall = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n  .filterDate('2022-01-01', '2022-12-31')\n  .sum();\n// Load Uganda boundary\nvar uganda = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n  .filter(ee.Filter.eq('country_na', 'Uganda'));\n// Stack bands and clip to Uganda\nvar input = ndvi.addBands(rainfall.rename('rainfall'))\n  .clip(uganda);\n// Generate training samples\nvar training = input.sample({\n  region: uganda,\n  scale: 5000,\n  numPixels: 2000,\n  seed: 42\n});\n// Train K-means clusterer\nvar clusterer = ee.Clusterer.wekaKMeans(3)\n  .train(training);\n// Apply clustering\nvar result = input.cluster(clusterer);\n// Visualize results\nMap.centerObject(uganda, 6);\nMap.addLayer(result.randomVisualizer(), {}, 'Malaria Risk Clusters');\nMap.addLayer(uganda, {color: 'red'}, 'Uganda Boundary', false);\n3\nTest and Debug the Initial Code\nTesting Process:\n1. Copy code into GEE Code Editor\n2. Click Run button\n3. Monitor Console for errors\n4. Check Map for visualization\n5. Verify Tasks tab for exports\nCommon Issues & ChatGPT Fixes:\nMemory Error: \"Too many pixels\"\nAsk ChatGPT to reduce sample size or increase scale\nTimeout Error: \"User memory limit exceeded\"\nRequest optimization for computational efficiency\n4\nEnhance Visualization and Add Export Functionality\nEnhancement Prompt for ChatGPT:\n\"Enhance the clustering script with: 1) Custom color palette for 3 risk levels (low=green, medium=yellow, high=red), 2) Export\nfunctionality to Google Drive as GeoTIFF, 3) Add legends and better visualization parameters, 4) Include cluster statistics in console\noutput\"\n// Enhanced visualization with custom colors\nvar palette = ['#00FF00', '#FFFF00', '#FF0000']; // Green, Yellow, Red\nMap.addLayer(result, {\n  min: 0, \n  max: 2, \n  palette: palette\n}, 'Malaria Risk Zones');\n// Add input data layers for comparison\nMap.addLayer(ndvi, {min: 0, max: 0.8, palette: ['white', 'green']}, 'NDVI', false);\nMap.addLayer(rainfall, {min: 0, max: 2000, palette: ['white', 'blue']}, 'Rainfall', false);\n// Export to Google Drive\nExport.image.toDrive({\n  image: result,\n  description: 'Uganda_Malaria_Risk_Clusters_2022',\n  folder: 'GEE_Exports',\n  fileNamePrefix: 'malaria_risk_clusters',\n  region: uganda.geometry(),\n  scale: 5000,\n  crs: 'EPSG:4326',\n  maxPixels: 1e13\n});\n// Print cluster statistics\nprint('Cluster Statistics:', training.aggregate_histogram('cluster'));\nprint('Number of training samples:', training.size());\n5\nOptimize Parameters and Validate Results\nParameter Optimization with ChatGPT:\nCluster Number: Test 3, 4, and 5 clusters\nAsk ChatGPT to create comparison script\nSample Size: Balance accuracy vs. performance\nRequest optimization recommendations\nSpatial Resolution: Test different scale values\nGet advice on resolution trade-offs\nValidation Approaches:\nVisual Inspection: Check if clusters make ecological\nsense\nCluster Statistics: Examine within-cluster variance\nDomain Knowledge: Compare with known malaria\npatterns\nSensitivity Analysis: Test parameter stability\n6\nExport and Post-Process in QGIS\nGEE Export Process:\n1. Run the enhanced script with export code\n2. Check Tasks tab in GEE\n3. Click Run on the export task\n4. Monitor progress and download from Google Drive\n5. Verify file integrity and projection\nQGIS Visualization:\n1. Open QGIS and create new project\n2. Add raster layer (exported GeoTIFF)\n3. Set symbology to Paletted/Unique values\n4. Assign meaningful labels and colors\n5. Create professional map layout\nTutorial Completion Checklist\nTechnical Achievements:\n☐ Successfully ran K-means clustering in GEE\n☐ Combined NDVI and rainfall data effectively\n☐ Generated meaningful cluster visualizations\n☐ Exported results for further analysis\nLearning Outcomes:\n☐ Understood unsupervised ML concepts\n☐ Applied ChatGPT for code development\n☐ Interpreted environmental clustering results\n☐ Connected analysis to public health applications\n7. Results Interpretation and Validation\nUnderstanding Cluster\nCharacteristics\nCluster Interpretation Framework:\nCluster 0 (Green): Low NDVI, Low Rainfall - Minimal\nRisk\nCluster 1 (Yellow): Moderate NDVI, Moderate Rainfall\n- Medium Risk\nCluster 2 (Red): High NDVI, High Rainfall - High Risk\nStatistical Interpretation:\nExamine cluster centroids in feature space\nCalculate within-cluster sum of squares\nAssess cluster separation and compactness\nAnalyze cluster size distribution\nEnvironmental Interpretation\nEcological Significance:\nHigh Risk Areas:\nDense vegetation + abundant rainfall = optimal mosquito\nhabitat\nMedium Risk Areas:\nSeasonal suitability depending on rainfall patterns\nLow Risk Areas:\nArid or sparse vegetation limiting mosquito survival\nGeographic Context:\nCompare with known malaria endemic regions\nConsider altitude and climate variations\nAccount for land use and human settlements\nEvaluate seasonal transmission patterns\nValidation Approaches\nInternal Validation\nSilhouette analysis for cluster quality\nWithin-cluster sum of squares (WCSS)\nCalinski-Harabasz index\nExternal Validation\nCompare with epidemiological data\nExpert knowledge assessment\nHistorical outbreak location analysis\nCross-Validation\nTemporal validation with different years\nSpatial validation with different regions\nBootstrap sampling validation\nUncertainty Assessment &\nLimitations\nData Limitations\nSatellite data quality and cloud cover\nTemporal resolution limitations\nSpatial resolution constraints\nModel Limitations\nK-means assumes spherical clusters\nSensitive to initialization\nMay not capture complex patterns\nInterpretation Caveats\nCorrelation does not imply causation\nOther factors influence transmission\nHuman behavior and interventions matter\n⚖Validation Checklist for Clustering Results\nStatistical Validation:\n☐ Optimal number of clusters determined\n☐ Cluster quality metrics calculated\n☐ Sensitivity analysis performed\n☐ Statistical significance assessed\nEcological Validation:\n☐ Results align with ecological theory\n☐ Spatial patterns make geographic sense\n☐ Seasonal variations considered\n☐ Expert knowledge incorporated\nPractical Validation:\n☐ Compared with field data (if available)\n☐ Results useful for decision-making\n☐ Limitations clearly documented\n☐ Future validation strategy defined\n8. Professional Applications\nDisease Surveillance & Early\nWarning\nMalaria Risk Mapping Application\nEarly Warning System Components:\nReal-time Monitoring: Automated processing of\nlatest satellite data\nRisk Alerts: Threshold-based warnings for high-risk\nconditions\nSeasonal Forecasting: Predict favorable\ntransmission periods\nResource Allocation: Target interventions to high-\nrisk clusters\nImplementation Strategy:\n1. Establish baseline risk maps using historical data\n2. Develop automated GEE workflows for regular updates\n3. Integrate with national surveillance systems\n4. Train local health officials in interpretation\n5. Validate with field observations and case data\nPublic Health Program Planning\nProgram Applications:\n\nBed Net Distribution: Prioritize high-risk clusters for\nITN campaigns\n\nIndoor Spraying: Target IRS programs to medium-\nhigh risk areas\n\nPreventive Treatment: Plan IPT distribution in high-\ntransmission zones\n\nActive Surveillance: Intensify case detection in high-\nrisk clusters\nBudget Optimization:\nUse cluster analysis to optimize intervention coverage vs. cost.\nHigh-risk clusters receive intensive interventions, medium-risk\nareas get targeted approaches, and low-risk zones focus on\nsurveillance and prevention.\nEnvironmental\nMonitoring\nClimate Change Adaptation\nMonitor shifting risk patterns due to\nchanging climate\nLand Use Planning\nInform development projects about\ndisease risk implications\nVector Control\nTarget environmental management\nstrategies\nResearch\nApplications\nAcademic Research\nEnvironmental epidemiology and disease\necology studies\nMethod Development\nImprove clustering algorithms for health\napplications\nMulti-Disease Studies\nApply similar methods to other vector-\nborne diseases\nPolicy Support\nNational Strategies\nInform national malaria control strategic\nplans\nInternational Aid\nGuide donor funding and resource\nallocation\nCross-Border Coordination\nRegional approaches to transboundary\ntransmission\nImplementation Roadmap\n1\nPilot Phase\nTest methodology in limited\ngeographic area with\nvalidation data\n2\nScale-Up\nExpand to national level\nwith automated processing\nworkflows\n3\nIntegration\nConnect with existing\nsurveillance and health\ninformation systems\n4\nSustainability\nEstablish local capacity and\ncontinuous improvement\nprocesses\nCareer Development Pathways\nTechnical Skills Development:\nAdvanced machine learning techniques (Random Forest, SVM)\nDeep learning applications in remote sensing\nTime series analysis and forecasting\nBayesian spatial modeling approaches\nCloud computing and big data processing\nProfessional Opportunities:\nSpatial epidemiologist at WHO, CDC, or national health agencies\nGIS analyst for international development organizations\nResearch scientist in academic institutions\nData scientist for health technology companies\nConsultant for environmental health assessments\n⭐Congratulations!\n\nMachine Learning Mastery\nApplied unsupervised learning to real-\nworld health problems\n\nRemote Sensing Integration\nCombined satellite data for environmental\nrisk assessment\n\nAI-Assisted Development\nLeveraged ChatGPT for efficient code\ndevelopment and learning\nAdvanced tutorial combining machine learning clustering techniques, Google Earth\nEngine programming, and AI-assisted development for environmental health risk\nassessment\nUnderstanding the role of AI in disease surveillance and risk assessment\nMathematical foundations and algorithmic understanding\nCombining vegetation and climate data for disease transmission risk\nCloud-based implementation of clustering algorithms\nLeveraging ChatGPT for machine learning code development\nComplete implementation guide with ChatGPT assistance\nUnderstanding and validating unsupervised clustering outcomes\nReal-world implementation in public health and research settings\nYou have successfully completed the AI-based clustering tutorial for malaria risk mapping\n\n“ The future of public health lies at the intersection of artificial intelligence, remote sensing, and epidemiological\nexpertise. ”\n\n## Document Information\n- **Source**: PDF Document (2 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: lab5\n- **Topics**: classification, clustering, crs, gee, gis, google earth engine, machine learning, malaria, mapping, projection, public health, qgis, raster, remote sensing, satellite, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain lab 5: ai-based clustering for malaria risk mapping - complete machine learning tutorial\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- clustering\n- crs\n- gee\n- gis\n- google earth engine\n- machine learning\n- malaria\n- mapping\n- projection\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "lab5",
      "topics": [
        "classification",
        "clustering",
        "crs",
        "gee",
        "gis",
        "google earth engine",
        "machine learning",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "qgis",
        "raster",
        "remote sensing",
        "satellite",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\lab_5_ml_clustering_malaria_risk_tutorial.md",
      "filename": "lab_5_ml_clustering_malaria_risk_tutorial.md"
    }
  },
  {
    "id": "concepts-machine_learning_tutorial",
    "title": "Machine Learning",
    "content": "\n# Machine Learning\n\n\n\n  i \n \n \n\n  i \n \nAbout the Tutorial \nToday’s Artificial Intelligence (AI) has far surpassed the hype of blockchain and quantum \ncomputing. The developers now take advantage of this in creating new Machine Learning \nmodels and to re-train the existing models for better performance and results.  \nThis  tutorial  will  give  an  introduction  to machine  learning  and  its  implementation  in \nArtificial Intelligence. \nAudience \nThis tutorial has been prepared for professionals aspiring to learn the complete picture of \nmachine learning and artificial intelligence. \nThis  tutorial caters  the  learning  needs  of both  the  novice  learners  and  experts, to  help \nthem understand the concepts and implementation of artificial intelligence. \n \nPrerequisites \nThe  learners  of  this  tutorial  are  expected  to  know  the  basics  of  Python  programming. \nBesides,  they  need  to  have a  solid  understanding  of computer  programing  and \nfundamentals. \nIf you are new to this arena, we suggest you pick up tutorials based on these concepts \nfirst, before you embark on with Machine Learning. \n \nCopyright & Disclaimer \n@Copyright 2019 by Tutorials Point (I) Pvt. Ltd.     \nAll the content and graphics published in this e-book are the property of Tutorials Point (I) \nPvt. Ltd.  The user of this e-book is prohibited to reuse, retain, copy, distribute or republish \nany contents or a part of contents of this e-book in any manner without written consent \nof the publisher.   \nWe strive to update the contents of our website and tutorials as timely and as precisely as \npossible, however, the contents may contain inaccuracies or errors. Tutorials Point (I) Pvt. \nLtd.  provides  no  guarantee  regarding  the  accuracy,  timeliness  or  completeness  of  our \nwebsite or its contents including this tutorial. If you discover any errors on our website or \nin this tutorial, please notify us at contact@tutorialspoint.com \n  \n\nMachine Learning   \n \n \n  ii \n \nTable of Contents \nAbout the Tutorial ................................................................................................................................ i \nAudience ............................................................................................................................................... i \nPrerequisites ......................................................................................................................................... i \nCopyright & Disclaimer ......................................................................................................................... i \nTable of Contents ................................................................................................................................. ii \n1. MACHINE LEARNING – INTRODUCTION ............................................................................ 1 \n2. MACHINE LEARNING – WHAT TODAY’S AI CAN DO? ......................................................... 2 \nExample ............................................................................................................................................... 2 \n3. MACHINE LEARNING – TRADITIONAL AI ........................................................................... 3 \nStatistical Techniques .......................................................................................................................... 3 \n4. MACHINE LEARNING – WHAT IS MACHINE LEARNING? .................................................... 4 \n5. MACHINE LEARNING – CATEGORIES OF MACHINE LEARNING .......................................... 6 \nSupervised Learning ............................................................................................................................. 7 \nUnsupervised Learning ........................................................................................................................ 8 \nReinforcement Learning....................................................................................................................... 9 \nDeep Learning .................................................................................................................................... 10 \nDeep Reinforcement Learning ........................................................................................................... 10 \n6. MACHINE LEARNING – SUPERVISED LEARNING .............................................................. 11 \nAlgorithms for Supervised Learning ................................................................................................... 11 \nk-Nearest Neighbours ........................................................................................................................ 11 \nDecision Trees .................................................................................................................................... 13 \nNaive Bayes ....................................................................................................................................... 14 \n \n \n\nMachine Learning   \n \n \n  iii \n \nLogistic Regression ............................................................................................................................. 14 \nSupport Vector Machines .................................................................................................................. 15 \n7. MACHINE LEARNING – SCIKIT-LEARN ALGORITHM ......................................................... 16 \n8. MACHINE LEARNING – UNSUPERVISED LEARNING ......................................................... 17 \nAlgorithms for Unsupervised Learning ............................................................................................... 17 \n9. MACHINE LEARNING – ARTIFICIAL NEURAL NETWORKS ................................................. 19 \nANN Architectures ............................................................................................................................. 20 \n10. MACHINE LEARNING – DEEP LEARNING ......................................................................... 22 \nApplications ....................................................................................................................................... 22 \nUntapped Opportunities of Deep Learning ........................................................................................ 22 \nWhat is Required for Achieving More Using Deep Learning? ............................................................. 23 \nDeep Learning - Disadvantages .......................................................................................................... 23 \n11. MACHINE LEARNING – SKILLS FOR MACHINE LEARNING ................................................ 26 \nNecessity of Various Skills of Machine Learning ................................................................................. 26 \n12. MACHINE LEARNING – IMPLEMENTING MACHINE LEARNING ........................................ 29 \nLanguage Choice ................................................................................................................................ 29 \nIDEs.................................................................................................................................................... 29 \nPlatforms ........................................................................................................................................... 30 \n13. MACHINE LEARNING – CONCLUSION ............................................................................. 31 \n \n \n\n  1 \n \nToday’s Artificial Intelligence (AI) has far surpassed the hype of blockchain and quantum \ncomputing. This is due to the fact that huge computing resources are easily available to \nthe common man. The  developers now  take advantage of this in creating new  Machine \nLearning models and to re-train the existing models for better performance and results. \nThe  easy  availability  of  High  Performance  Computing  (HPC)  has  resulted  in  a  sudden \nincreased demand for IT professionals having Machine Learning skills.  \nIn this tutorial, you will learn in detail about: \nWhat is the crux of machine learning? \n \n What are the different types in machine learning?  \n \n What  are  the  different  algorithms  available  for  developing  machine  learning \nmodels?  \n \n What tools are available for developing these models?  \n \n What are the programming language choices?  \n \n What  platforms  support  development  and  deployment  of  Machine  Learning \napplications?  \n \n What IDEs (Integrated Development Environment) are available?  \n \n How to quickly upgrade your skills in this important area?  \n  \n1. Machine Learning – Introduction \n\nMachine Learning   \n \n \n  2 \n \nWhen you tag a face in a Facebook photo, it is AI that is running behind the scenes and \nidentifying faces in a picture. Face tagging is now omnipresent in several applications that \ndisplay pictures with human faces. Why just human faces? There are several applications \nthat  detect  objects  such  as  cats,  dogs,  bottles,  cars,  etc.  We  have  autonomous  cars \nrunning on our roads that detect objects in real time to steer the car. When you travel, \nyou use Google Directions to learn the real-time traffic situations and follow the best path \nsuggested by Google at that point of time. This is yet another implementation of object \ndetection technique in real time.  \nLet us consider the example of Google Translate application that we typically use while \nvisiting  foreign  countries. Google’s  online  translator  app  on  your  mobile  helps  you \ncommunicate with the local people speaking a language that is foreign to you.  \nThere are several applications of AI that we use practically today. In fact, each one of us \nuse AI in many parts of our lives, even without our knowledge. Today’s AI can perform \nextremely complex jobs with a great accuracy and speed. Let us discuss an example of \ncomplex task to understand what capabilities are expected in an AI application that you \nwould be developing today for your clients.  \nExample  \nWe all use Google Directions during our trip anywhere in the city for a daily commute or \neven for inter-city travels. Google Directions application suggests the fastest path to our \ndestination at that time instance. When we follow this path, we have observed that Google \nis almost 100% right in its suggestions and we save our valuable time on the trip.  \nYou can imagine the complexity involved in developing this kind of application considering \nthat there are multiple paths to your destination and the application has to judge the traffic \nsituation  in  every  possible  path  to give  you  a  travel  time  estimate  for  each  such  path. \nBesides,  consider  the  fact  that  Google  Directions  covers the entire  globe. Undoubtedly, \nlots of AI and Machine Learning techniques are in-use under the hoods of such applications.   \nConsidering the continuous demand for the development of such applications, you will now \nappreciate why there is a sudden demand for IT professionals with AI skills. \nIn our next chapter, we will learn what it takes to develop AI programs.  \n  \n2. Machine Learning – What Today’s AI Can Do? \n\nMachine Learning   \n \n \n  3 \n \nThe journey of AI began in the 1950's when the computing power was a fraction of what \nit  is today.  AI  started  out  with  the  predictions  made  by  the  machine  in  a  fashion  a \nstatistician does predictions using his calculator. Thus, the initial entire AI development \nwas based mainly on statistical techniques.  \nIn this chapter, let us discuss in detail what these statistical techniques are. \nStatistical Techniques \nThe development of today’s AI applications started with using the  age-old  traditional \nstatistical techniques. You must have used straight-line interpolation in schools to predict \na future value. There are several other such statistical techniques which are successfully \napplied in developing so-called AI programs. We say “so-called” because the AI programs \nthat we have today are much more complex and use techniques far beyond the statistical \ntechniques used by the early AI programs.  \nSome of the examples of statistical techniques that are used for developing AI applications \nin those days and are still in practice are listed here: \n \n Regression \n Classification \n Clustering \n Probability Theories \n Decision Trees \n \nHere we have listed only some primary techniques that are enough to get you started on \nAI  without  scaring  you  of  the  vastness  that  AI demands. If  you  are  developing  AI \napplications based on limited data, you would be using these statistical techniques. \nHowever, today the data is abundant. To analyze the kind of huge data that we possess \nstatistical techniques are  of not much help as  they have  some limitations  of their own. \nMore  advanced  methods  such  as  deep  learning are  hence developed  to  solve  many \ncomplex problems.  \nAs we move ahead in this tutorial, we will understand what Machine Learning is and how \nit is used for developing such complex AI applications.  \n  \n3. Machine Learning – Traditional AI \n\nMachine Learning   \n \n \n  4 \n \nConsider the following figure that shows a plot of house prices versus its size in sq. ft.  \n \n \n \nAfter  plotting  various  data  points  on  the  XY  plot,  we  draw  a  best-fit  line  to  do  our \npredictions for any other house given its size. You will feed the known data to the machine \nand ask it to find the best fit line. Once the best fit line is found by the machine, you will \ntest its suitability by feeding in a known house size, i.e. the Y-value in the above curve. \nThe machine will now return the estimated X-value, i.e. the expected price of the house. \nThe diagram can be extrapolated to find out the price of a house which is 3000 sq. ft. or \neven larger. This is called regression in statistics. Particularly, this kind of regression is \ncalled linear regression as the relationship between X & Y data points is linear.  \n \n4. Machine Learning – What is Machine \nLearning? \n\nMachine Learning   \n \n \n  5 \n \nIn many cases, the relationship between the X & Y data points may not be a straight line, \nand it may be a curve with a complex equation. Your task would be now to find out the \nbest  fitting  curve  which  can  be  extrapolated  to  predict  the  future  values.  One  such \napplication plot is shown in the figure below.  \n \n \n \nSource: \nhttps://upload.wikimedia.org/wikipedia/commons/c/c9/Segmented_linear_regression_graph_showing_yield_of\n_mustard_plants_vs_soil_salinity_in_Haryana%2C_India%2C_1987%E2%80%931988.jpg \n \nYou will use the statistical optimization techniques to find out the equation for the best fit \ncurve  here.  And this  is  what exactly  Machine  Learning  is  about.  You  use  known \noptimization techniques to find the best solution to your problem.  \n \nNext, let us look at the different categories of Machine Learning.  \n  \n\nMachine Learning   \n \n \n  6 \n \nMachine Learning is broadly categorized under the following headings: \n \n \nMachine learning evolved from left to right as shown in the above diagram.  \n Initially, researchers started  out  with  Supervised  Learning.  This  is  the  case  of \nhousing price prediction discussed earlier.  \n \n This was followed by unsupervised learning, where the machine is made to learn \non its own without any supervision.  \n \n Scientists  discovered  further  that it  may  be  a  good  idea  to  reward  the  machine \nwhen it does the job the expected way and there came the Reinforcement Learning. \n \n Very soon, the data that is available these days has become so humongous that \nthe  conventional  techniques  developed  so  far  failed  to  analyze  the  big  data  and \nprovide us the predictions.  \n \n Thus, came the deep learning where the human brain is simulated in the Artificial \nNeural Networks (ANN) created in our binary computers. \n \n The  machine  now  learns  on  its  own  using  the  high  computing  power  and  huge \nmemory resources that are available today.  \n \n It is now observed that Deep Learning has solved many of the previously unsolvable \nproblems.  \n \n The  technique  is  now  further  advanced  by  giving  incentives  to  Deep  Learning \nnetworks as awards and there finally comes Deep Reinforcement Learning.  \n \n5. Machine Learning – Categories of Machine \nLearning \n\nMachine Learning   \n \n \n  7 \n \nLet us now study each of these categories in more detail.  \nSupervised Learning \nSupervised learning is analogous to training a child to walk. You will hold the child’s hand, \nshow him how to take his foot forward, walk yourself for a demonstration and so on, until \nthe child learns to walk on his own.  \nRegression \nSimilarly, in the case of supervised learning, you give concrete  known examples to the \ncomputer. You say that for given feature value x1 the output is y1, for x2 it is y2, for x3 \nit  is  y3,  and  so  on.  Based  on  this  data, you let  the  computer  figure  out  an  empirical \nrelationship between x and y.  \nOnce the machine is trained in this way with a sufficient number of data points, now you \nwould ask the machine to predict Y for a given X. Assuming that you know the real value \nof Y for this given X, you will be able to deduce whether the machine’s prediction is correct. \nThus, you will test whether the machine has learned by using the known test data. Once \nyou  are  satisfied  that  the  machine  is  able  to  do  the  predictions  with  a  desired  level  of \naccuracy (say 80 to 90%) you can stop further training the machine.  \nNow, you can safely use the machine to do the predictions on unknown data points, or ask \nthe machine to predict Y for a given X for which you do not know the real value of Y. This \ntraining comes under the regression that we talked about earlier.  \nClassification \nYou may also use machine learning techniques for classification problems. In classification \nproblems, you classify objects of similar nature into a single group. For example, in a set \nof 100 students say, you may like to group them into three groups based on their heights \n- short, medium and long. Measuring the height of each student, you will place them in a \nproper group.  \nNow, when a new student comes in, you will put him in an appropriate group by measuring \nhis height. By following the principles in regression training, you will train the machine to \nclassify a student based on his feature – the height. When the machine learns how the \ngroups are  formed, it will be able to classify any unknown new  student correctly. Once \nagain, you would use the test data to verify that the machine has learned your technique \nof classification before putting the developed model in production.  \nSupervised Learning is where the AI really began its journey. This technique was applied \nsuccessfully  in several  cases.  You  have  used  this  model  while  doing  the  hand-written \nrecognition  on  your  machine.  Several  algorithms  have  been  developed  for  supervised \nlearning. You will learn about them in the following chapters. \n\nMachine Learning   \n \n \n  8 \n \nUnsupervised Learning \nIn unsupervised learning, we do not specify a target variable to the machine, rather we \nask machine “What can you tell me about X?”. More specifically, we may ask questions \nsuch as given a huge data set X, “What are the five best groups we can make out of X?” \nor “What features occur together most frequently in X?”. To arrive at the answers to such \nquestions,  you  can  understand  that  the  number  of  data  points  that  the  machine  would \nrequire  to  deduce  a  strategy  would  be  very  large.  In  case  of  supervised  learning,  the \nmachine can be trained with even about few thousands of data points. However, in case \nof  unsupervised  learning,  the  number  of  data  points  that  is  reasonably  accepted  for \nlearning starts in a few millions. These days, the data is generally abundantly available. \nThe  data  ideally  requires  curating.  However,  the  amount  of  data  that  is  continuously \nflowing in a social area network, in most cases data curation is an impossible task.  \n \nThe following figure shows the boundary between the yellow and red dots as determined \nby unsupervised machine learning. You can see it clearly that the machine would be able \nto determine the class of each of the black dots with a fairly good accuracy.  \n \n \nSource: \nhttps://chrisjmccormick.files.wordpress.com/2013/08/approx_decision_boun\ndary.png \n \nThe unsupervised learning has shown a great  success in many modern AI applications, \nsuch as face detection, object detection, and so on.  \n\nMachine Learning   \n \n \n  9 \n \nReinforcement Learning \nConsider training a pet dog, we train our pet to bring a ball to us. We throw the ball at a \ncertain distance and ask the dog to fetch it back to us. Every time the dog does this right, \nwe reward the dog. Slowly, the dog learns that doing the job rightly gives him a reward \nand then the dog starts doing the job right way every time in future. Exactly, this concept \nis applied in “Reinforcement” type of learning. The technique was initially developed for \nmachines to play games. The machine is given an algorithm to analyze all possible moves \nat each stage of the game. The machine may select one of the moves at random. If the \nmove  is  right,  the  machine  is  rewarded,  otherwise  it  may  be  penalized.  Slowly,  the \nmachine  will  start  differentiating  between  right  and  wrong  moves  and  after  several \niterations would learn to solve the game puzzle with a better accuracy. The accuracy of \nwinning the game would improve as the machine plays more and more games.  \n \nThe entire process may be depicted in the following diagram: \n \n \n \nThis technique of machine learning differs from the supervised learning in that you need \nnot supply the labelled input/output pairs. The focus is  on finding the balance between \nexploring the new solutions versus exploiting the learned solutions.  \n\nMachine Learning   \n \n \n  10 \n \nDeep Learning \nThe deep learning is a model based on Artificial Neural Networks (ANN), more specifically \nConvolutional  Neural  Networks  (CNN)s. There  are  several  architectures  used  in  deep \nlearning such as deep neural networks, deep belief networks, recurrent neural networks, \nand convolutional neural networks.  \nThese networks have been successfully applied in solving the problems of computer vision, \nspeech  recognition,  natural  language  processing,  bioinformatics,  drug  design,  medical \nimage  analysis,  and  games.  There  are  several  other  fields  in  which  deep  learning  is \nproactively applied. The deep learning requires huge processing power and humongous \ndata, which is generally easily available these days.  \nWe will talk about deep learning more in detail in the coming chapters. \nDeep Reinforcement Learning  \nThe  Deep  Reinforcement  Learning  (DRL)  combines  the  techniques  of  both  deep  and \nreinforcement  learning.  The  reinforcement  learning  algorithms  like  Q-learning  are  now \ncombined with deep learning to create a powerful DRL model. The technique has been with \na  great  success  in  the  fields  of  robotics,  video  games,  finance  and  healthcare.  Many \npreviously unsolvable problems are now solved by creating DRL models. There is lots of \nresearch going on in this area and this is very actively pursued by the industries.  \nSo far, you have got a brief introduction to various machine learning models, now let us \nexplore slightly deeper into various algorithms that are available under these models.  \n  \n\nMachine Learning   \n \n \n  11 \n \nSupervised  learning  is  one  of  the  important  models  of  learning  involved  in  training \nmachines. This chapter talks in detail about the same. \nAlgorithms for Supervised Learning \nThere are several algorithms available for supervised learning. Some of the widely used \nalgorithms of supervised learning are as shown below: \n \n k-Nearest Neighbours \n Decision Trees \n Naive Bayes \n Logistic Regression \n Support Vector Machines \nAs we move ahead in this chapter, let us discuss in detail about each of the algorithms. \nk-Nearest Neighbours \nThe k-Nearest Neighbours, which is simply called kNN is a statistical technique that can \nbe used for solving for classification and regression problems. Let us discuss the case of \nclassifying an unknown object using kNN. Consider the distribution of objects as shown in \nthe image given below: \n \n \n \nSource: \nhttps://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm \n \n6. Machine Learning – Supervised Learning \n\nMachine Learning   \n \n \n  12 \n \nThe diagram shows three types of objects, marked in red, blue and green colors. When \nyou run the kNN classifier on the above dataset, the boundaries for each type of object \nwill be marked as shown below: \n \n \n \nSource: \nhttps://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm \n \nNow, consider a new unknown object that you want to classify as red, green or blue. This \nis depicted in the figure below.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\nMachine Learning   \n \n \n  13 \n \nAs  you  see  it  visually,  the  unknown  data  point  belongs  to  a  class  of  blue  objects. \nMathematically, this can be concluded by measuring the distance of this unknown point \nwith every  other point in the data  set.  When you do so,  you will know  that most of its \nneighbours  are  of  blue  color.  The  average  distance  to  red  and  green  objects  would  be \ndefinitely more than the average distance to blue objects. Thus, this unknown object can \nbe classified as belonging to blue class.   \n \nThe  kNN  algorithm  can  also  be  used  for  regression  problems.  The  kNN  algorithm  is \navailable as ready-to-use in most of the ML libraries.  \nDecision Trees \nA simple decision tree in a flowchart format is shown below: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nYou would write a code to classify your input data based on this flowchart. The flowchart \nis self-explanatory and trivial. In this scenario, you are trying to classify an incoming email \nto decide when to read it.  \nIn  reality,  the  decision  trees  can  be  large  and  complex.  There  are  several  algorithms \navailable to create and traverse these trees. As a Machine Learning enthusiast, you need \nto understand and master these techniques of creating and traversing decision trees.  \n\nMachine Learning   \n \n \n  14 \n \nNaive Bayes \nNaive Bayes is used for creating classifiers. Suppose you want to sort out (classify) fruits \nof different kinds from a fruit basket. You may use features such as color, size and shape \nof a fruit, For example, any fruit that is red in color, is round in shape and is about 10 cm \nin diameter  may  be  considered  as  Apple.  So  to  train  the  model,  you  would  use  these \nfeatures and test the probability that a given feature matches the desired constraints. The \nprobabilities of different features are then combined to arrive at a probability that a given \nfruit  is  an  Apple.  Naive  Bayes  generally  requires  a  small  number  of  training  data  for \nclassification.  \nLogistic Regression \nLook at the following diagram. It shows the distribution of data points in XY plane.  \n \n \n \nFrom the diagram, we can visually inspect the separation of red dots from green dots. You \nmay draw a boundary line to separate out these dots. Now, to classify a new data point, \nyou will just need to determine on which side of the line the point lies.  \n\nMachine Learning   \n \n \n  15 \n \nSupport Vector Machines \nLook at the following distribution of data. Here the three classes of data cannot be linearly \nseparated. The boundary curves are non-linear. In such a case, finding the equation of the \ncurve becomes a complex job.  \n \n \n \nSource: http://uc-r.github.io/svm \n \nThe  Support  Vector  Machines  (SVM)  comes  handy  in  determining  the  separation \nboundaries in such situations.  \n  \n\nMachine Learning   \n \n \n  16 \n \nFortunately, most of the time you do not have to code the algorithms mentioned in the \nprevious  lesson.  There  are  many  standard  libraries  which  provide  the  ready-to-use \nimplementation of these algorithms. One such toolkit that is popularly used is scikit-learn. \nThe figure below illustrates the kind of algorithms which are available for your use in this \nlibrary.  \n \n \n \n \nSource: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html \n \nThe use of these algorithms is trivial and since these are well and field tested, you can \nsafely use them in your AI applications. Most of these libraries are free to use even for \ncommercial purposes.  \n \n \n \n \n  \n7. Machine Learning – Scikit-learn Algorithm \n\nMachine Learning   \n \n \n  17 \n \nSo far what you have seen is making the machine learn to find out the solution to our \ntarget. In regression, we train the machine to predict a future value. In classification, we \ntrain the machine to classify an unknown object in one of the categories defined by us. In \nshort, we have been training machines so that it can predict Y for our data X. Given a huge \ndata set and not estimating the categories, it would be difficult for us to train the machine \nusing  supervised  learning.  What  if  the  machine  can  look  up  and analyze  the  big  data \nrunning into several Gigabytes and Terabytes and tell us that this data contains so many \ndistinct categories?  \nAs an example, consider the voter’s data. By considering some inputs from each voter \n(these are called features in AI terminology), let the machine predict  that there are so \nmany voters who would vote for X political party and so many would vote for Y, and so \non. Thus, in general, we are asking the machine given a huge set of data points X, “What \ncan you tell me about X?”. Or it may be a question like “What are the five best groups we \ncan make out of X?”. Or it could be even like “What three features occur together most \nfrequently in X?”. \n \nThis is exactly the Unsupervised Learning is all about.   \nAlgorithms for Unsupervised Learning \nLet  us  now  discuss  one  of  the  widely  used  algorithms  for  classification  in  unsupervised \nmachine learning. \nk-means clustering \nThe 2000 and 2004 Presidential elections in the United States were close — very close. \nThe largest percentage of the popular vote that any candidate received was 50.7% and \nthe  lowest  was  47.9%.  If  a  percentage  of  the  voters  were  to  have  switched  sides, the \noutcome of the election would have been different. There are small groups of voters who, \nwhen properly appealed to, will switch sides. These groups may not be huge, but with such \nclose races, they may be big enough to change the outcome of the election. How do you \nfind these groups of people? How do you appeal to them with a limited budget? The answer \nis clustering. \nLet us understand how it is done.  \n First, you collect information on people either with or without their consent: any \nsort of information that might give some clue about what is important to them and \nwhat will influence how they vote.  \n \n \n Then you put this information into some sort of clustering algorithm.  \n \n8. Machine Learning – Unsupervised Learning \n\nMachine Learning   \n \n \n  18 \n \n Next, for each cluster (it would be smart to choose the largest one first) you craft \na message that will appeal to these voters.  \n \n Finally, you deliver the campaign and measure to see if it’s working. \n \nClustering is a type of unsupervised learning that automatically forms clusters of similar \nthings. It is like automatic classification. You can cluster almost anything, and the more \nsimilar the items are in the cluster, the better the clusters are.  In this chapter, we are \ngoing  to  study  one  type  of  clustering  algorithm  called  k-means.  It  is  called  k-means \nbecause it finds ‘k’ unique clusters, and the center of each cluster is the mean of the values \nin that cluster.  \nCluster Identification \nCluster identification tells an algorithm, “Here’s some data. Now group similar things \ntogether and tell me about those groups.” The key difference from classification is that in \nclassification you know what you are looking for. While that is not the case in clustering.  \nClustering is sometimes called unsupervised classification because it produces the same \nresult as classification does but without having predefined classes. \nNow, we are comfortable with both supervised and unsupervised learning. To understand \nthe  rest  of  the  machine  learning  categories, we must  first  understand  Artificial  Neural \nNetworks (ANN), which we will learn in the next chapter. \n \n  \n\nMachine Learning   \n \n \n  19 \n \nThe idea of artificial neural networks was derived from the neural networks in the human \nbrain. The human brain is really complex. Carefully studying the brain, the scientists and \nengineers  came  up  with  an  architecture  that  could  fit  in  our  digital  world  of  binary \ncomputers. One such typical architecture is shown in the diagram below: \n \n \n \nThere is an input layer which has many sensors to collect data from the outside world. On \nthe  right  hand  side,  we  have  an  output  layer  that  gives  us  the  result  predicted  by  the \nnetwork.  In  between these  two, several  layers  are  hidden.  Each  additional  layer  adds \nfurther complexity in training the network, but would provide better results in most of the \nsituations. There are several types of architectures designed which we will discuss now. \n  \n9. Machine Learning – Artificial Neural Networks \n\nMachine Learning   \n \n \n  20 \n \nANN Architectures \nThe diagram below shows several ANN architectures developed over a period of time and \nare in practice today.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSource: \nhttps://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-\n3fb6f2367464 \n \n\nMachine Learning   \n \n \n  21 \n \nEach  architecture  is  developed  for  a  specific  type  of  application.  Thus,  when  you  use  a \nneural network for your machine learning application, you will have to use either one of \nthe existing architecture or design your own. The type of application that you finally decide \nupon depends on your application needs. There is no single guideline that tells you to use \na specific network architecture.  \n  \n\nMachine Learning   \n \n \n  22 \n \nDeep Learning uses ANN. First we will look at a few deep learning applications that will \ngive you an idea of its power.  \nApplications \nDeep Learning has shown a lot of success in several areas of machine learning applications.  \nSelf-driving Cars: The autonomous self-driving cars use deep learning techniques. They \ngenerally adapt to the ever changing traffic situations and get better and better at driving \nover a period of time.  \nSpeech  Recognition: Another  interesting  application  of  Deep  Learning  is  speech \nrecognition. All of us use several mobile apps today that are capable of recognizing our \nspeech. Apple’s Siri, Amazon’s Alexa, Microsoft’s Cortena and Google’s Assistant – all these \nuse deep learning techniques.   \nMobile Apps: We use several web-based and mobile apps for organizing our photos. Face \ndetection,  face  ID,  face  tagging,  identifying  objects  in  an  image – all  these  use  deep \nlearning.  \nUntapped Opportunities of Deep Learning \nAfter  looking  at  the  great  success  deep  learning  applications  have  achieved  in  many \ndomains, people started exploring other domains where machine learning was not so far \napplied. There  are  several  domains  in  which  deep  learning  techniques  are  successfully \napplied  and  there  are many  other domains  which can be  exploited.  Some  of  these  are \ndiscussed here: \n Agriculture is one such industry where people can apply deep learning techniques \nto improve the crop yield.  \n \n Consumer  finance  is  another  area  where  machine  learning  can  greatly  help  in \nproviding early detection on frauds and analyzing customer’s ability to pay.  \n \n Deep learning techniques are also applied to the field of medicine to create new \ndrugs and provide a personalized prescription to a patient.  \nThe  possibilities  are  endless  and  one  has  to  keep  watching  as  the  new  ideas  and \ndevelopments pop up frequently.  \n \n \n10. Machine Learning – Deep Learning \n\nMachine Learning   \n \n \n  23 \n \nWhat is Required for Achieving More Using Deep Learning? \nTo use deep learning, supercomputing power is a mandatory requirement. You need both \nmemory as well as the CPU to develop deep learning models. Fortunately, today we have \nan easy availability of HPC – High Performance Computing. Due to this, the development \nof the deep learning applications that we mentioned above became a reality today and in \nthe  future too we can see  the  applications  in  those  untapped  areas that  we  discussed \nearlier. \nNow, we will look at some of the limitations of deep learning that we must consider before \nusing it in our machine learning application.  \nDeep Learning - Disadvantages \nSome of the important points that you need to consider before using deep learning are \nlisted below: \n Black Box approach \n Duration of Development \n Amount of Data \n Computationally Expensive \nWe will now study each one of these limitations in detail. \nBlack Box approach \nAn  ANN  is  like  a  blackbox.  You  give  it  a  certain  input  and it  will  provide  you  a  specific \noutput. The following diagram shows you one such application where you feed an animal \nimage to a neural network and it tells you that the image is of a dog.  \n \nWhy this is called a black-box approach is that you do not know why the network came up \nwith a certain result. You do not know how the network concluded that it is a dog? Now \nconsider a banking application where the bank wants to decide the creditworthiness of a \nclient. The network will definitely provide you an answer to this question. However, will \nyou be able to justify it to a client? Banks need to explain it to their customers why the \nloan is not sanctioned? \n\nMachine Learning   \n \n \n  24 \n \nDuration of Development \nThe process of training a neural network is depicted in the diagram below: \n \nYou first define the problem that you want to solve, create a specification for it, decide on \nthe input features, design a network, deploy it and test the output. If the output is not as \nexpected, take this as a feedback to restructure your network. This is an iterative process \nand may require several iterations until the time network is fully trained to produce desired \noutputs.  \nAmount of Data \nThe deep learning networks usually require a huge amount of data for training, while the \ntraditional machine learning algorithms can be used with a great success even with just a \nfew thousands of data points. Fortunately, the data abundance is growing at 40% per year \nand CPU processing power is growing at 20% per year as seen in the diagram given below: \n \n \n\nMachine Learning   \n \n \n  25 \n \nComputationally Expensive \nTraining a neural network requires several times more computational power than the one \nrequired  in  running  traditional  algorithms.  Successful  training  of  deep  Neural  Networks \nmay require several weeks of training time.  \nIn contrast to this, traditional machine learning algorithms take only a few minutes/hours \nto train. Also, the amount of computational power needed for training deep neural network \nheavily depends on the size of your data and how deep and complex the network is? \nAfter  having  an  overview  of  what  Machine  Learning is,  its  capabilities,  limitations,  and \napplications, let us now dive into learning “Machine Learning”. \n  \n\nMachine Learning   \n \n \n  26 \n \nMachine Learning has a very large width and requires skills across several domains. The \nskills that you need to acquire for becoming an expert in Machine Learning are listed below: \n \n Statistics \n Probability Theories \n Calculus \n Optimization techniques \n Visualization \nNecessity of Various Skills of Machine Learning \nTo give you a brief idea of what skills you need to acquire, let us discuss some examples: \nMathematical Notation \nMost of the machine learning algorithms are heavily based on mathematics. The level of \nmathematics that you need to know is probably just a beginner level. What is important \nis that you should be able to read the notation that mathematicians use in their equations. \nFor example - if you are able to read the notation and comprehend what it means, you \nare ready for  learning  machine  learning.  If  not,  you  may  need  to  brush  up  your \nmathematics knowledge.  \n \n \n \n \n \n \n \n11. Machine Learning – Skills for Machine \nLearning \n\nMachine Learning   \n \n \n  27 \n \nProbability Theory \nHere is an example to test your current knowledge of probability theory: Classifying with \nconditional probabilities. \n \n \n \n \n \n \nWith these definitions, we can define the Bayesian classification rule: \n If P(c\n1\n|x, y) > P(c\n2\n|x, y) , the class is c\n1\n . \n If P(c\n1\n|x, y) < P(c\n2\n|x, y) , the class is c\n2\n . \nOptimization Problem \nHere is an optimization function \n \n \n \n \n \nSubject to the following constraints: \n \n \n \n \n \nIf you can read and understand the above, you are all set.  \n\nMachine Learning   \n \n \n  28 \n \nVisualization \nIn  many  cases,  you  will  need  to  understand  the  various  types  of  visualization  plots  to \nunderstand your data distribution and interpret the results of the algorithm’s output.  \n \n \n \nBesides the above theoretical aspects of machine learning, you need good programming \nskills to code those algorithms.  \n \nSo what does it take to implement ML? Let us look into this in the next chapter. \n  \n\nMachine Learning   \n \n \n  29 \n \nTo  develop  ML  applications,  you  will  have  to  decide  on  the  platform,  the  IDE  and  the \nlanguage for development. There are several choices available. Most of these would meet \nyour  requirements  easily  as  all  of  them  provide  the  implementation  of  AI  algorithms \ndiscussed so far.  \nIf  you  are  developing  the  ML  algorithm  on  your  own, the  following  aspects  need  to  be  \nunderstood carefully: \nThe language of your choice – this essentially is your proficiency in one of the languages \nsupported in ML development.   \nThe IDE that you use – This would depend on your familiarity with the existing IDEs and \nyour comfort level.  \nDevelopment  platform – There are  several  platforms  available  for  development  and \ndeployment. Most of these are free-to-use. In some cases, you may have to incur a license \nfee beyond a certain amount of usage. Here is a brief list of choice of languages, IDEs and \nplatforms for your ready reference.  \nLanguage Choice \nHere is a list of languages that support ML development: \n Python \n R \n Matlab \n Octave \n Julia \n C++ \n C \nThis  list  is  not  essentially  comprehensive;  however,  it  covers  many  popular  languages \nused  in  machine  learning  development.  Depending  upon  your  comfort  level,  select  a \nlanguage for the development, develop your models and test.  \nIDEs \nHere is a list of IDEs which support ML development: \n R Studio \n Pycharm \n iPython/Jupyter Notebook \n \n12. Machine Learning – Implementing Machine \nLearning \n\nMachine Learning   \n \n \n  30 \n \n Julia \n Spyder \n Anaconda \n Rodeo \n Google –Colab  \nThe above list is not essentially comprehensive. Each one has its own merits and demerits. \nThe reader is encouraged to try out these different IDEs before narrowing down to a single \none.  \nPlatforms \nHere is a list of platforms on which ML applications can be deployed: \n \n IBM  \n Microsoft Azure  \n Google Cloud  \n Amazon  \n Mlflow \n \nOnce again this list is not exhaustive. The reader is encouraged to sign-up for the above-\nmentioned services and try them out themselves.  \n  \n\nMachine Learning   \n \n \n  31 \n \nThis  tutorial  has  introduced  you  to  Machine  Learning.  Now,  you  know  that  Machine \nLearning is a technique of training machines to perform the activities a human brain can \ndo, albeit bit faster and better than an average human-being. Today we have seen that \nthe machines can beat human champions in games such as Chess, AlphaGO, which are \nconsidered very complex. You have seen that machines can be trained to perform human \nactivities in several areas and can aid humans in living better lives.  \nMachine Learning can be a Supervised or Unsupervised. If you have lesser amount of data \nand clearly labelled data for training, opt for Supervised Learning. Unsupervised Learning \nwould  generally  give  better  performance  and  results  for  large  data  sets.  If  you  have  a \nhuge  data  set  easily  available,  go  for  deep  learning  techniques.  You also have  learned \nReinforcement  Learning  and  Deep  Reinforcement  Learning.  You  now  know  what  Neural \nNetworks are, their applications and limitations.  \nFinally, when it comes to the development of machine learning models of your own, you \nlooked at the choices of various development languages, IDEs and Platforms. Next thing \nthat you need to do is start learning and practicing each machine learning technique. The \nsubject is vast, it means that there is width, but if you consider the depth, each topic can \nbe learned in a few hours. Each topic is independent of each other. You need to take into \nconsideration one topic at a time, learn it, practice it and implement the algorithm/s in it \nusing a language choice of yours. This is the best way to start studying Machine Learning. \nPracticing one topic at a time, very soon you would acquire the width that is eventually \nrequired of a Machine Learning expert.  \nGood Luck!  \n13. Machine Learning – Conclusion  \n\n## Document Information\n- **Source**: PDF Document (35 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: lab5\n- **Topics**: classification, clustering, gis, machine learning, python, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain machine learning\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- clustering\n- gis\n- machine learning\n- python\n- vector\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "lab5",
      "topics": [
        "classification",
        "clustering",
        "gis",
        "machine learning",
        "python",
        "vector"
      ],
      "source": "concepts\\machine_learning_tutorial.md",
      "filename": "machine_learning_tutorial.md"
    }
  },
  {
    "id": "concepts-mlclustering2022-10-26",
    "title": "Machine Learning Part 2:  Clustering",
    "content": "\n# Machine Learning Part 2:  Clustering\n\n\n\nMachine Learning Part 2: \nClustering\nLouise Capener, Research Associate at the UK Data Service (Cathie \nMarsh Institute, UoM)\nCopyright © year Institution. Created by Organisation, UK Data Service. \n1\n\n• Recap\n• What is clustering?\n• Why bother with it?\n• Types of clustering algorithms\n• K-  M\neans\n• Hierarchical clustering\nOutline\n\n6\nSupervised learningUnsupervised learning\nInput data is labelled Input data is unlabelled\nData is classified based on the \ntraining dataset\nAssigns properties of given data to \nclassify it\nDivided into Regression and \nClassification\nDivided into Clustering and \nAssociation\nUsed for prediction Used for analysis\nAlgorithms include: decision trees, \nlogistic regressions, support vector \nmachine\nAlgorithms include: k-means \nclustering, hierarchical clustering, \napriori algorithm\nA known number of classesAn unknown number of classes\nRecap  \n\n7\nDpsSepal \nlength \n(cm)\nPetal length \n(cm)\nPetal \nwidth (cm)\nA3.51.40.2\nB3.25.72.3\nC3.25.92.3\nD2.94.71.4\nE3.71.50.4\nUnsupervised learning: used for analysis\nDpsSepal \nlength \n(cm)\nPetal length \n(cm)\nPetal width \n(cm)\nSpecies\nA3.51.40.2Iris-Versicolour\nB3.25.72.3Iris-Setosa\nC3.25.92.3Iris-Setosa\nD2.94.71.4Iris-Virginica\nE3.71.50.4Iris-Versicolour\nF3.15.52.2?\nSupervised learning: used for prediction\nRecap (contd.)\n\n8\nDpsSepal \nlength (cm)\nPetal length \n(cm)\nPetal width \n(cm)\ncluster\nA3.51.40.21\nB3.25.72.32\nC3.25.92.32\n“Clustering is the task of partitioning the dataset \ninto groups, called clusters. The goal is to split up \nthe data in such a way that points within a single \ncluster are very similar and points in different \nclusters are different.”\n(Müller and Guido 2017)\nWhat is clustering?\n\n9\n• It provides more information on the \nstructure of the data patterns\n• It can help identify problems in the \ndata, such as outliers\n• It can be used to compress data\nWhy bother with it?\n\n10\n•   Customer recommendation systems: \n“People who bought Harry Potter and the \nPhilosopher’s Stonealso bought The \nHunger Games...”\n•   Grouping DNA sequences of different \nstrains of HIV into families of genetically \nsimilar viruses\n•   Identifying fake news by clustering the \nwords used in articles. Certain words may \nappear more in sensationalized click-bait \narticles.\n•   And the more frivolous and fun side \nprojects...\nOther use cases\n\n11\n“There is no universal definition of what \na cluster is: it really depends on the \ncontext, and different algorithms will \ncapture different kinds of clusters.”\n(Géron, 2019)\nWhat is a cluster?\n\n12\nEXPLORE YOUR DATA\n?\n?\n?\nHow do I know which type of algorithm is right for me?\nHierarchical clustering\nDistribution-based\nDensity-basedCentroid-based\nTypes of clustering algorithms\n\n13\n•We want to separate our data points \ninto k clusters \n•First, we initialize the algorithm with k \nrandom points (our centroids)\n•Then, we assign each data point to its \nnearest initialisation point – using the \nEuclidean distance\n•Once each data point is assigned, we \nrelocate the initialisation point to the \nmean of the data points that were \nassigned to it\n•Repeat the highlighted steps until the \nassignment of data points to centroids \nremains unchanged\nK-Means clustering\n\n14\nIntroducing pseudocode...\n\n15\nPseudo English\n\n16\nPseudocode \n\n17\nCode\n\n18\nForgy’smethod: choose k random data points from the dataset\nRandom Partition method: Randomly assign data points to a \ncluster. Then calculate the mean of each cluster to get the \ninitial centroids.\nK-  means++: first centroid is a random datapoint, but remaining \ncentroids are chosen based on the maximum squared distance \ncentroids are spread out evenly\nInitialisation – how do we select our \ncentroids?\n\n19\n•    Each time we increase the \nnumber of clusters the SSE \ndecreases\n•Goal: select a small value of k \nthat still has a low SSE\n•Elbow represents where we \nstart to have diminishing returns \nby increasing k\nk value\nSSE\nElbow plot\nK = ?\nSepal \nlength \n(cm)\nPetal \nlength \n(cm)\nPetal \nwidth \n(cm)\n3.51.40.2\n3.25.72.3\n3.25.92.3\n2.94.71.4\n3.71.50.4\nOkay... but how do we determine the \nnumber of clusters we want? \n\n20\n• Easy to understand and \nimplement\n• Fast\n• Scalable\nWhat are the strengths?\n\n21\nshapedirectiondensity\nSuboptimal solution\nBad centroid  initialization \nElbow method\n•  Choosing 푘푘manually – it’s a hassle!\n•  It is dependent on initial values: \nnecessary to run the algorithm \nseveral times to avoid suboptimal \nsolutions – converges to a local \nminimum\n•  Not good at clustering data of \nvarying sizes, densities, or \nnonspherical shapes\nWhat are the limitations?\n\n22\n“Hierarchical clustering algorithms [...] \napproach the problem of clustering by \ndeveloping a binary tree-based data \nstructure called the dendrogram. Once \nthe dendrogram is constructed, one \ncan automatically choose the right \nnumber of clusters by splitting the tree \nat different levels to obtain different \nclustering solutions for the same \ndataset without rerunning the \nclustering algorithm again.”\n(Reddy and Vinzamuri, 2015)\nHierarchical clustering\n\n23\nSplit\nA\nB\nC\nD\nE\n0\n1\n2\n3\n4\n5\n6\n01234\nA\nB\nC\nD\nE\n0\n1\n2\n3\n4\n5\n6\n01234\nBranches\nIncreasing similarity\nHow do I read a dendrogram?\n\n24\nDE\nABC\nABCDE\nABC\nDE\nAB\nABCDE\nD\nECB\nA\nD\nE\nBAC\nAB\nA\nB\nC\nD\nE\n0\n1\n2\n3\n4\n5\n6\n01234\n2) Divisive  \n1)   Agglomerative\nWhat are the 2 main approaches to hierarchical \nclustering?\n\n25\npqED\n341.414214\n21\nIncreasing similarity\n•  Hierarchical clustering is proximity-based\n•  Affects the shape of the clusters\n•  Used to build distance matrix\n•  Default is Euclidean distance, but other \nmeasures exist:correlation-based, \nLevenshteindistance etc. \n1) Measure of distance – some measure of similarity\n...but how do we know which clusters should be \ncombined, or split?\n\n26\n•  A means of determining whether certain clusters should be merged\n•  Default is complete-linkage\n•  Other commonly used linkage criteria: single-linkage, average-\nlinkage\n•  Used to update the distance matrix and merge clusters \n2) Linkage criterion – different ways to link clusters based on distance\n\n27\nAgglomerative hierarchical clustering: \nUsing complete-linkage\n\n28\nA\nB\nC\nD\nE\n0\n1\n2\n3\n4\n5\n6\n00.511.522.533.5\nDpssepal \nlength (cm)\nPetal \nlength \n(cm)\nA11\nB10\nC02\nD24\nE35\nyx\n1) Load in dataset\nStep by step...\n\n29\nABCDE\nA011.43.24.5\nB102.24.15.4\nC1.42.202.84.2\nD3.24.12.801.4\nE4.55.44.21.40\n2) Build distance matrix and identify smallest \ndistance\n\n30\nd[(A,B),C] = max {d(A,C), \nd(B,C)}\n= max {1.4, 2.2}\nd[(A,B),D] = max {d(A,D), \nd(B,D)}\n= max {3.2, 4.1}\nd[(A,B),E] = max {d(A,E), \nd(B,E)}\n= max {4.5, 5.4}\nABCDE\nAB0\nC2.20\nD4.12.80\nE5.44.21.40\nUpdated distance matrix:\n3) Perform merge and update distance matrix\n\n31\nd[(A,B,C),(D,E) = max \n{d((D,E)(A,B), ((D,E,(C))\n= max {5.4, 4.2}\nABCDE\nABC0\nDE5.40\nd[(A,B),(D,E)] = max \n{d((A,B)D), d(A,B)E))}\n= max {4.1, 5.4}\nd[(C,(D,E))] = max\n{d(C,D), d (C,E)}\n= max {2.8, 4.2}\nABDEC\nAB0\nDE5.40\nC2.24.20\nContinue merging and updating the distance \nmatrix...\n\n32\ntwo clusters\nthree clusters\n•  Dendrogram: y-axis \ndenotes when in the \nagglomerative algorithm \ntwo clusters get merged\n•  Y-axis also shows how far \napart the merged clusters \nare pay attention to the \nlength of the branches\n\n33\nK = ?\n•Easy to understand and implement\n•Most appealing output\n•Can handle non-convex clusters\n•No need to specify the number of \nclusters!\nWhat are the strengths?\n\n34\n•Mathematically simple...but \ncomputationally expensive!\n•Hard to visualize results with a large \ndataset\n•Heavily driven by heuristics and arbitrary \ndecisions\n•Algorithm can’t undo previous step\nWhat are the limitations?\n\n35\nK-MeansHierarchical clustering\nTime complexityO(n)O(n²)\nHyperparameters \nTuning\nMust specify the number \nof clusters (k) and \nretrain model for each k\nNo need to specify k \nvalue, can perform split \nwherever\nData structureBetter performance \nwhen dealing with \nconvex clusters\nGenerates better results \nwhen dealing with non-\nconvex clusters\nTypes/variationsMany variations (e.g., K-\nmedian, K-medoid) \nTwo approaches: \nAgglomerative and \nDivisive\nResult RobustnessResult may be different \non different runs\nSame parameters \ngenerate the same \nresult every time\nK-Means vs Hierarchical clustering\n\n37\nGeron, A (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: \nConcepts, Tools, and Techniques to Build Intelligent Systems.\nMüller, A.C, and Guido, S (2017). Introduction to Machine Learning with Python: A Guide for Data \nScientists, O’Reilly Media, Inc. \nReddy, C.K., and Vinzamuri, B (2015). A Survey of Partitional and Hierarchical Clustering \nAlgorithms.\n-Outlier detection using clustering (Outlier detection image) \nhttps://blogs.sap.com/2020/12/16/outlier-detection-by-clustering/\n-Image compression using K-Means clustering (parrot image) \nhttps://medium.com/@agarwalvibhor84/image-compression-using-k-means-clustering-\n8c0ec055103f\n-Clustering Algorithms: Types of Clustering (images) https://developers.google.com/machine-\nlearning/clustering/clustering-algorithms\n-K-Means clustering (image with centroids as triangles) \n-K-Means pseudocode (image) \nhttps://www.cms.waikato.ac.nz/~abifet/book/chapter_9.html#rfig9-1\n-K-Means Elbow Method and Silhouette Analysis (image) https://\nstackabuse.com/k-means-\nelbow-method-and-silhouette-analysis-with-yellowbrick-and-scikit-learn/\nReferences\n\n38\nGitHub: \nhttps://github.com/UKDataServiceOpen/ML_Workshop\nMaterial for Tuesday the 2\nnd\nof \nNovember\n\n-When you leave the webinar, please complete our short \nsurvey \n-Just click on ‘continue’ to access the survey. \nSurvey\n\n40\nEmail:  \nlouise.capener@Manchester.ac.uk\nnadia.kennar@manchester.ac.uk, \nTwitter:  \n@CapenerLouise\n@NadiaKennar\nThank You.\n\n## Document Information\n- **Source**: PDF Document (36 pages)\n- **Category**: concepts\n- **Difficulty**: advanced\n- **Relevant Labs**: lab5\n- **Topics**: classification, clustering, gis, machine learning, python, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain machine learning part 2:  clustering\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- clustering\n- gis\n- machine learning\n- python\n- vector\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "advanced",
      "lab": "lab5",
      "topics": [
        "classification",
        "clustering",
        "gis",
        "machine learning",
        "python",
        "vector"
      ],
      "source": "concepts\\mlclustering2022-10-26.md",
      "filename": "mlclustering2022-10-26.md"
    }
  },
  {
    "id": "concepts-ml_book",
    "title": "AnIntroductiontoMachineLearning",
    "content": "\n# AnIntroductiontoMachineLearning\n\n\n\nINTRODUCTION TO MACHINE LEARNING\n\n\n\nIntroduction to Machine Learning\nAlex Smola and S.V.N. Vishwanathan\nYahoo! Labs\nSanta Clara\n–and–\nDepartments of Statistics and Computer Science\nPurdue University\n–and–\nCollege of Engineering and Computer Science\nAustralian National University\n\npublished by the press syndicate of the university of cambridge\nThe Pitt Building, Trumpington Street, Cambridge, United Kingdom\ncambridge university press\nThe Edinburgh Building, Cambridge CB2 2RU, UK\n40 West 20th Street, New York, NY 10011–4211, USA\n477 Williamstown Road, Port Melbourne, VIC 3207, Australia\nRuiz de Alarc ́on 13, 28014 Madrid, Spain\nDock House, The Waterfront, Cape Town 8001, South Africa\nhttp://www.cambridge.org\nc\n©Cambridge University Press 2008\nThis book is in copyright. Subject to statutory exception\nand to the provisions of relevant collective licensing agreements,\nno reproduction of any part may take place without\nthe written permission of Cambridge University Press.\nFirst published 2008\nPrinted in the United Kingdom at the University Press, Cambridge\nTypefaceMonotype Times 10/13ptSystemL\nA\nT\nE\nX 2\nε\n[Alexander J. Smola and S.V.N.\nVishwanathan]\nA catalogue record for this book is available from the British Library\nLibrary of Congress Cataloguing in Publication data available\nISBN 0 521 82583 0 hardback\nAuthor: vishy\nRevision: 252\nTimestamp: October 1, 2010\nURL: svn://smola@repos.stat.purdue.edu/thebook/trunk/Book/thebook.tex\n\nContents\nPrefacepage1\n1Introduction3\n1.1A Taste of Machine Learning3\n1.1.1    Applications3\n1.1.2    Data7\n1.1.3    Problems9\n1.2Probability Theory12\n1.2.1    Random Variables12\n1.2.2    Distributions13\n1.2.3    Mean and Variance15\n1.2.4    Marginalization, Independence, Conditioning, and\nBayes Rule16\n1.3Basic Algorithms20\n1.3.1    Naive Bayes22\n1.3.2    Nearest Neighbor Estimators24\n1.3.3    A Simple Classifier27\n1.3.4    Perceptron29\n1.3.5    K-Means32\n2Density Estimation37\n2.1Limit Theorems37\n2.1.1    Fundamental Laws38\n2.1.2    The Characteristic Function42\n2.1.3    Tail Bounds45\n2.1.4    An Example48\n2.2Parzen Windows51\n2.2.1    Discrete Density Estimation51\n2.2.2    Smoothing Kernel52\n2.2.3    Parameter Estimation54\n2.2.4    Silverman’s Rule57\n2.2.5    Watson-Nadaraya Estimator59\n2.3Exponential Families60\n2.3.1    Basics60\nv\n\nvi0  Contents\n2.3.2    Examples62\n2.4Estimation66\n2.4.1    Maximum Likelihood Estimation66\n2.4.2    Bias, Variance and Consistency68\n2.4.3    A Bayesian Approach71\n2.4.4    An Example75\n2.5Sampling77\n2.5.1    Inverse Transformation78\n2.5.2    Rejection Sampler82\n3Optimization91\n3.1Preliminaries91\n3.1.1    Convex Sets92\n3.1.2    Convex Functions92\n3.1.3    Subgradients96\n3.1.4    Strongly Convex Functions97\n3.1.5    Convex Functions with Lipschitz Continous Gradient  98\n3.1.6    Fenchel Duality98\n3.1.7    Bregman Divergence100\n3.2Unconstrained Smooth Convex Minimization102\n3.2.1    Minimizing a One-Dimensional Convex Function102\n3.2.2    Coordinate Descent104\n3.2.3    Gradient Descent104\n3.2.4    Mirror Descent108\n3.2.5    Conjugate Gradient111\n3.2.6    Higher Order Methods115\n3.2.7    Bundle Methods121\n3.3Constrained Optimization125\n3.3.1    Projection Based Methods125\n3.3.2    Lagrange Duality127\n3.3.3    Linear and Quadratic Programs131\n3.4Stochastic Optimization135\n3.4.1    Stochastic Gradient Descent136\n3.5Nonconvex Optimization137\n3.5.1    Concave-Convex Procedure137\n3.6Some Practical Advice139\n4Online Learning and Boosting143\n4.1Halving Algorithm143\n4.2Weighted Majority144\n\nContentsvii\n5Conditional Densities149\n5.1Logistic Regression150\n5.2Regression151\n5.2.1    Conditionally Normal Models151\n5.2.2    Posterior Distribution151\n5.2.3    Heteroscedastic Estimation151\n5.3Multiclass Classification151\n5.3.1    Conditionally Multinomial Models151\n5.4What is a CRF?152\n5.4.1    Linear Chain CRFs152\n5.4.2    Higher Order CRFs152\n5.4.3    Kernelized CRFs152\n5.5Optimization Strategies152\n5.5.1    Getting Started152\n5.5.2    Optimization Algorithms152\n5.5.3    Handling Higher order CRFs152\n5.6Hidden Markov Models153\n5.7Further Reading153\n5.7.1    Optimization153\n6Kernels and Function Spaces155\n6.1The Basics155\n6.1.1    Examples156\n6.2Kernels161\n6.2.1    Feature Maps161\n6.2.2    The Kernel Trick161\n6.2.3    Examples of Kernels161\n6.3Algorithms161\n6.3.1    Kernel Perceptron161\n6.3.2    Trivial Classifier161\n6.3.3    Kernel Principal Component Analysis161\n6.4Reproducing Kernel Hilbert Spaces161\n6.4.1    Hilbert Spaces163\n6.4.2    Theoretical Properties163\n6.4.3    Regularization163\n6.5Banach Spaces164\n6.5.1    Properties164\n6.5.2    Norms and Convex Sets164\n7Linear Models165\n7.1Support Vector Classification165\n\nviii0  Contents\n7.1.1    A Regularized Risk Minimization Viewpoint170\n7.1.2    An Exponential Family Interpretation170\n7.1.3    Specialized Algorithms for Training SVMs172\n7.2Extensions177\n7.2.1    Theνtrick177\n7.2.2    Squared Hinge Loss179\n7.2.3    Ramp Loss180\n7.3Support Vector Regression181\n7.3.1    Incorporating General Loss Functions184\n7.3.2    Incorporating theνTrick186\n7.4Novelty Detection186\n7.5Margins and Probability189\n7.6Beyond Binary Classification189\n7.6.1    Multiclass Classification190\n7.6.2    Multilabel Classification191\n7.6.3    Ordinal Regression and Ranking192\n7.7Large Margin Classifiers with Structure193\n7.7.1    Margin193\n7.7.2    Penalized Margin193\n7.7.3    Nonconvex Losses193\n7.8Applications193\n7.8.1    Sequence Annotation193\n7.8.2    Matching193\n7.8.3    Ranking193\n7.8.4    Shortest Path Planning193\n7.8.5    Image Annotation193\n7.8.6    Contingency Table Loss193\n7.9Optimization193\n7.9.1    Column Generation193\n7.9.2    Bundle Methods193\n7.9.3    Overrelaxation in the Dual193\n7.10   CRFs vs Structured Large Margin Models194\n7.10.1  Loss Function194\n7.10.2  Dual Connections194\n7.10.3  Optimization194\nAppendix 1Linear Algebra and Functional Analysis197\nAppendix 2Conjugate Distributions201\nAppendix 3Loss Functions203\nBibliography221\n\nPreface\nSince this is a textbook we biased our selection of references towards easily\naccessible work rather than the original references. While this may not be\nin the interest of the inventors of these concepts, it greatly simplifies access\nto those topics. Hence we encourage the reader to follow the references in\nthe  cited  works  should  they  be  interested  in  finding  out  who  may  claim\nintellectual ownership of certain key ideas.\n1\n\n20  Preface\nStructure of the Book\nIntroduction\nDensity \nEstimation\nGraphical \nModels\nKernelsOptimization\nConditional \nDensities\nConditional \nRandom Fields\nLinear Models\nStructured \nEstimation\nDuality and \nEstimation\nMoment\nMethods\nReinforcement \nLearning\nIntroduction\nDensity \nEstimation\nGraphical \nModels\nKernelsOptimization\nConditional \nDensities\nConditional \nRandom Fields\nLinear Models\nStructured \nEstimation\nDuality and \nEstimation\nMoment\nMethods\nReinforcement \nLearning\nIntroduction\nDensity \nEstimation\nGraphical \nModels\nKernelsOptimization\nConditional \nDensities\nConditional \nRandom Fields\nLinear Models\nStructured \nEstimation\nDuality and \nEstimation\nMoment\nMethods\nReinforcement \nLearning\nCanberra, August 2008\n\n1\nIntroduction\nOver the past two decades Machine Learning has become one of the main-\nstays of information technology and with that, a rather central, albeit usually\nhidden, part of our life. With the ever increasing amounts of data becoming\navailable there is good reason to believe that smart data analysis will become\neven more pervasive as a necessary ingredient for technological progress.\nThe purpose of this chapter is to provide the reader with an overview over\nthe vast range of applications which have at their heart a machine learning\nproblem  and  to  bring  some  degree  of  order  to  the  zoo  of  problems.  After\nthat, we will discuss some basic tools from statistics and probability theory,\nsince they form the language in which many machine learning problems must\nbe phrased to become amenable to solving. Finally, we will outline a set of\nfairly basic yet effective algorithms to solve an important problem, namely\nthat of classification. More sophisticated tools, a discussion of more general\nproblems and a detailed analysis will follow in later parts of the book.\n1.1  A Taste of Machine Learning\nMachine learning can appear in many guises. We now discuss a number of\napplications, the types of data they deal with, and finally, we formalize the\nproblems in a somewhat more stylized fashion. The latter is key if we want to\navoid reinventing the wheel for every new application. Instead, much of the\nartof machine learning is to reduce a range of fairly disparate problems to\na set of fairly narrow prototypes. Much of thescienceof machine learning is\nthen to solve those problems and provide good guarantees for the solutions.\n1.1.1  Applications\nMost readers will be familiar with the concept of web pageranking. That\nis, the process of submitting a query to a search engine, which then finds\nwebpages  relevant  to  the  query  and  which  returns  them  in  their  order  of\nrelevance. See e.g. Figure 1.1 for an example of the query results for “ma-\nchine learning”. That is, the search engine returns a sorted list of webpages\ngiven a query. To achieve this goal, a search engine needs to ‘know’ which\n3\n\n41  Introduction\nWeb Images Maps News Shopping Gmail more !\n \n    \nSponsored Links\nMachine Learning\nGoogle Sydney needs machine\nlearning experts. Apply today!\nwww.google.com.au/jobs\nSign in\n Search\n  Advanced Search\n  Preferences\n Web    Scholar   Results 1 - 10 of about 10,500,000 for machine learning. (0.06 seconds) \nMachine learning - Wikipedia, the free encyclopedia\nAs a broad subfield of artificial intelligence, machine learning is concerned with the design\nand development of algorithms and techniques that allow ...\nen.wikipedia.org/wiki/Machine_learning - 43k - Cached - Similar pages\nMachine Learning textbook\nMachine Learning is the study of computer algorithms that improve automatically through\nexperience. Applications range from datamining programs that ...\nwww.cs.cmu.edu/~tom/mlbook.html - 4k - Cached - Similar pages\nmachine learning\nwww.aaai.org/AITopics/html/machine.html - Similar pages\nMachine Learning\nA list of links to papers and other resources on machine learning.\nwww.machinelearning.net/ - 14k - Cached - Similar pages\nIntroduction to Machine Learning\nThis page has pointers to my draft book on Machine Learning and to its individual\nchapters. They can be downloaded in Adobe Acrobat format. ...\nai.stanford.edu/~nilsson/mlbook.html - 15k - Cached - Similar pages\nMachine Learning - Artificial Intelligence (incl. Robotics ...\nMachine Learning - Artificial Intelligence. Machine Learning is an international forum for\nresearch on computational approaches to learning.\nwww.springer.com/computer/artificial/journal/10994 - 39k - Cached - Similar pages\nMachine Learning (Theory)\nGraduating students in Statistics appear to be at a substantial handicap compared to\ngraduating students in Machine Learning, despite being in substantially ...\nhunch.net/ - 94k - Cached - Similar pages\nAmazon.com: Machine Learning: Tom M. Mitchell: Books\nAmazon.com: Machine Learning: Tom M. Mitchell: Books.\nwww.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077 - 210k -\nCached - Similar pages\nMachine Learning Journal\nMachine Learning publishes articles on the mechanisms through which intelligent systems\nimprove their performance over time. We invite authors to submit ...\npages.stern.nyu.edu/~fprovost/MLJ/ - 3k - Cached - Similar pages\nCS 229: Machine Learning\nSTANFORD. CS229 Machine Learning Autumn 2007. Announcements. Final reports from\nthis year's class projects have been posted here. ...\ncs229.stanford.edu/ - 10k - Cached - Similar pages\n12345678910\nNext\n \n Search\nSearch within results | Language Tools | Search Tips | Dissatisfied? Help us improve | Try Google Experimental\n©2008 Google - Google Home - Advertising Programs - Business Solutions - About Google\nmachine learning\nmachine learning\nGoogle\nFig. 1.1.  The 5 top scoring webpages for the query “machine learning”\npages are relevant and which pages match the query. Such knowledge can be\ngained from several sources: the link structure of webpages, their content,\nthe frequency with which users will follow the suggested links in a query, or\nfrom examples of queries in combination with manually ranked webpages.\nIncreasingly machine learning rather than guesswork and clever engineering\nis used toautomatethe process of designing a good search engine [RPB06].\nA rather related application iscollaborative filtering. Internet book-\nstores such as Amazon, or video rental sites such as Netflix use this informa-\ntion extensively to entice users to purchase additional goods (or rent more\nmovies). The problem is quite similar to the one of web page ranking. As\nbefore, we want to obtain a sorted list (in this case of articles). The key dif-\nference is that an explicit query is missing and instead we can only use past\npurchase  and  viewing  decisions  of  the  user  to  predict  future  viewing  and\npurchase habits. The key side information here are the decisions made by\nsimilarusers, hence the collaborative nature of the process. See Figure 1.2\nfor an example. It is clearly desirable to have an automatic system to solve\nthis problem, thereby avoiding guesswork and time [BK07].\nAn equally ill-defined problem is that ofautomatic translationof doc-\numents. At one extreme, we could aim at fullyunderstandinga text before\ntranslating it using a curated set of rules crafted by a computational linguist\nwell versed in the two languages we would like to translate. This is a rather\narduous task, in particular given that text is not always grammatically cor-\nrect, nor is the document understanding part itself a trivial one. Instead, we\ncould simply useexamplesof translated documents, such as the proceedings\nof the Canadian parliament or other multilingual entities (United Nations,\nEuropean Union,  Switzerland)  tolearnhow  to  translate  between  the  two\n\n1.1  A Taste of Machine Learning5\nlanguages. In other words, we could use examples of translations to learn\nhow  to  translate.  This  machine  learning  approach  proved  quite  successful\n[?].\nMany security applications, e.g. for access control, use face recognition as\none  of  its  components.  That  is,  given  the  photo  (or  video  recording)  of  a\nperson, recognize who this person is. In other words, the system needs to\nclassifythe faces into one of many categories (Alice, Bob, Charlie, . . . ) or\ndecide that it is an unknown face. A similar, yet conceptually quite different\nproblem is that of verification. Here the goal is to verify whether the person\nin  question  is  who  he  claims  to  be.  Note  that  differently  to  before,  this\nis now a yes/no question. To deal with different lighting conditions, facial\nexpressions, whether a person is wearing glasses, hairstyle, etc., it is desirable\nto have a system whichlearnswhich features are relevant for identifying a\nperson.\nAnother application where learning helps is the problem ofnamed entity\nrecognition(see Figure 1.4). That is, the problem of identifying entities,\nsuch as places, titles, names, actions, etc. from documents. Such steps are\ncrucial in the automatic digestion and understanding of documents. Some\nmodern  e-mail  clients,  such  as  Apple’s  Mail.app  nowadays  ship  with  the\nability  to  identify  addresses  in  mails  and  filing  them  automatically  in  an\naddress book. While systems using hand-crafted rules can lead to satisfac-\ntory results, it is far more efficient to use examples of marked-up documents\nto  learn  such  dependencies  automatically,  in  particular  if  we  want  to  de-\nploy  our  system  in  many  languages.  For  instance,  while  ’bush’  and  ’rice’\nYour Amazon.com Today's DealsGifts & Wish Lists Gift Cards \nYour Account  |  Help\nAdvertise on Amazon\n5 star: (23)\n4 star: (2)\n3 star: (3)\n2 star: (2)\n1 star:  (0)\n   \nQuantity: 1\n \nor\nSign in to turn on 1-Click ordering.\n \n  \nMore Buying Choices\n16 used & new from\n$52.00\nHave one to sell? \n \n  \n \n \nShare your own customer images\nSearch inside another edition of this book\nAre You an Author or\nPublisher? \nFind out how to publish\nyour own Kindle Books\n \n  \nHello. Sign in to get personalized recommendations. New customer? Start here.\n  \n \nBooks   \nBooks\nAdvanced SearchBrowse SubjectsHot New  ReleasesBestsellersThe New  York Times®  Best  SellersLibros En EspañolBargain BooksTextbooks\nJoin Amazon Prime and ship Two-Day for free and Overnight for $3.99. Already a member? Sign in.\nMachine Learning (Mcgraw-Hill International Edit)\n(Paperback)\nby Thomas Mitchell (Author) \"Ever since computers were invented, we have wondered whether\nthey might be made to learn...\" (more)\n    (30 customer reviews)  \nList Price:$87.47\nPrice:$87.47 & this item ships for FREE with Super Saver Shipping.\nDetails\nAvailability: Usually ships within 4 to 7 weeks. Ships from and sold by Amazon.com. Gift-\nwrap available.\n16 used & new available from $52.00\nAlso Available in:List Price:Our Price:Other Offers:\nHardcover (1)$153.44$153.4434 used & new from $67.00\n \n  \nBetter Together\nBuy this book with Introduction to Machine Learning (Adaptive Computation and Machine Learning) by Ethem Alpaydin today!\nBuy Together Today: $130.87\nCustomers Who Bought This Item Also Bought\nPattern Recognition and\nMachine Learning\n(Information Science and\nStatistics) by Christopher\nM. Bishop\n (30)  $60.50\nArtificial Intelligence: A\nModern Approach (2nd\nEdition) (Prentice Hall\nSeries in Artificial\nIntelligence) by Stuart\nRussell\n (76)  $115.00\nThe Elements of Statistical\nLearning by T. Hastie\n (25)  $72.20\nPattern Classification (2nd\nEdition) by Richard O.\nDuda\n (25)  $115.00\nData Mining: Practical\nMachine Learning Tools\nand Techniques, Second\nEdition (Morgan Kaufmann\nSeries in Data\nManagement Systems) by\nIan H. Witten\n (21)  $39.66\n› Explore similar items : Books (50)\nEditorial Reviews\nBook Description\nThis exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly\nchanging field of machine learning--including probability and statistics, artificial intelligence, and neural networks--unifying them all in a logical\nand coherent manner. Machine Learning serves as a useful reference tool for software developers and researchers, as well as an outstanding text\nfor college students. --This text refers to the Hardcover edition. \nBook Info\nPresents the key algorithms and theory that form the core of machine learning. Discusses such theoretical issues as How does learning\nperformance vary with the number of training examples presented? and Which learning algorithms are most appropriate for various types of\nlearning tasks? DLC: Computer algorithms. --This text refers to the Hardcover edition.\nProduct Details\nPaperback: 352 pages\nPublisher: McGraw-Hill Education (ISE Editions); 1st edition (October 1, 1997)\nLanguage: English\nISBN-10: 0071154671\nISBN-13: 978-0071154673\nProduct Dimensions: 9 x 5.9 x 1.1 inches\nShipping Weight: 1.2 pounds (View shipping rates and policies)\nAverage Customer Review:   (30 customer reviews)\nAmazon.com Sales Rank: #104,460 in Books (See Bestsellers in Books)\nPopular in this category: (What's this?)\n#11 in Books > Computers & Internet > Computer Science > Artificial Intelligence > Machine Learning\n(Publishers and authors: Improve Your Sales)\nIn-Print Editions: Hardcover (1) |  All Editions\n Would you like to update product info or give feedback on images? (We'll ask you to sign in so we can get back to you)\nInside This Book (learn more) \nBrowse and search another edition of this book.\nFirst Sentence:\nEver since computers were invented, we have wondered whether they might be made to learn. Read the first page\nBrowse Sample Pages:\nFront Cover | Copyright | Table of Contents | Excerpt | Index | Back Cover | Surprise Me!\nSearch Inside This Book:\n \nCustomers viewing this page may be interested in these Sponsored Links (What's this?)\nOnline Law Degree\nhttp://www.edu-onlinedegree.org Juris Doctor JD & LLM Masters Low tuition, Free Textbooks \nLearning CDs\nwww.mindperk.com Save on powerful mind-boosting CDs & DVDs. Huge Selection \nVideo Edit Magic\nwww.deskshare.com/download Video Editing Software trim, modify color, and merge video \nTags Customers Associate with This Product (What's this?)\nClick on a tag to find related items, discussions, and people.\nmachine learning (6)\nartificial intelligence (2)\ncomputer science (1)\npattern recognition (1)\nYour tags: Add your first tag\nHelp others find this product - tag it for Amazon search\nNo one has tagged this product for Amazon search yet. Why not be the first to\nsuggest a search for which it should appear?\nSearch Products Tagged with\n \nAre you the publisher or author? Learn how Amazon can help you make this book an eBook. \nIf you are a publisher or author and hold the digital rights to a book, you can make it available as an eBook on Amazon.com. Learn more\nRate This Item to Improve Your Recommendations\nI own itNot rated\nYour rating\nDon't like it < > I love it!\nSave your\nrating\n  \n?12345\n \nCustomer Reviews\n30 Reviews\n \n \nAverage Customer Review\n(30 customer reviews)\n \n \n  \nShare your thoughts with other customers:\nMost Helpful Customer Reviews\n 44 of 44 people found the following review helpful:\n An excellent overview for the adv. undergrad or beg. grad,\nSeptember 30, 2002\nBy Todd Ebert (Long Beach California) - See all my reviews\nThis review is from: Machine Learning (Hardcover)\nI agree with some of the previous reviews which criticize the book for its lack of\ndepth, but I believe this to be an asset rather than a liability given its target\naudience (seniors and beginning grad. students). The average college senior typically\nknows very little about subjects like neural networks, genetic algorithms, or Baysian\nnetworks, and this book goes a long way in demystifying these subjects in a very\nclear, concise, and understandable way. Moreover, the first-year grad. student who is\ninterested in possibly doing research in this field needs more of an overview than to\ndive deeply into \none of the many branches which themselves have had entire books written about\nthem. This is one of the few if only books where one will find diverse areas of\nlearning (e.g. analytical, reinforcment, Bayesian, neural-network, genetic-algorithmic)\nall within the same cover.\nBut more than just an encyclopedic introduction, the author makes a number of\nconnections between the different paradigms. For example, he explains that\nassociated with each paradigm is the notion of an inductive-learning bias, i.e. the\nunderlying assumptions that lend validity to a given learning approach. These end-of-\nchapter discussions on bias seem very interesting and unique to this book.\nFinally, I used this book for part of the reading material for an intro. AI class, and\nreceived much positive feedback from the students, although some did find the\npresentation a bit too abstract for their undergraduate tastes\n Comment | Permalink | Was this review helpful to you?   (Report this) \n 22 of 27 people found the following review helpful:\n Great compilation, May 18, 2001\nBy Steven Burns (-) - See all my reviews\nThis review is from: Machine Learning (Hardcover)\nThis book is completely worth the price, and worth the hardcover to take care of it.\nThe main chapters of the book are independent, so you can read them in any order.\nThe way it explains the different learning approaches is beautiful because: 1)it\nexplains them nicely 2)it gives examples and 3)it presents pseudocode summaries of\nthe algorithms. As a software developer, what else could I possibly ask for?\n Comment | Permalink | Was this review helpful to you?   (Report this) \n 23 of 23 people found the following review helpful:\n Venerable, in both senses, April 4, 2004\nBy eldil (Albuquerque NM) - See all my reviews\nThis review is from: Machine Learning (Hardcover)\nIt's pretty well done, it covers theory and core areas but - maybe it was more the\nstate of the field when it was written - I found it unsatisfyingly un-synthesized,\nunconnected, and short of detail (but this is subjective). I found the 2nd edition of\nRussell and Norvig to be a better introduction where it covers the same topic, which\nit does for everything I can think of, except VC dimension.\nThe book sorely needs an update, it was written in 1997 and the field has moved\nfast. A comparison with Mitchell's current course (materials generously available\nonline) shows that about 1/4 of the topics taught have arisen since the book was\npublished; Boosting, Support Vector Machines and Hidden Markov Models to name\nthe best-known. The book also does not cover statistical or data mining methods.\nDespite the subjective complaint about lack of depth it does give the theoretical\nroots and many fundamental techniques decently and readably. For many purposes\nthough it may have been superceded by R&N 2nd ed.\n Comment | Permalink | Was this review helpful to you?   (Report this) \nShare your thoughts with other customers: \n› See all 30 customer reviews...\n \n \nMost Recent Customer Reviews\n Outstanding\nI read this book about 7 years ago while in\nthe PhD program at Stanford University. I\nconsider this book not only the best\nMachine Learning book, but one of the best\nbooks in all... Read more\nPublished 6 months ago by Husam Abu-Haimed\n Great Start to Machine Learning\nI have used this book during my masters\nand found it to be an extremely helpful and\na gentle introduction to the thick and things\nof machine learning applications.\nRead more\nPublished 6 months ago by Subrat Nanda\n Best book I've seen on topic\nI have this book listed as one of the best\nand most interesting I've ever read. I loved\nthe book just as much as I loved the course\nwe used it in. Read more\nPublished 13 months ago by Lars Kristensson\n too expensive I would say\ngreat book if you wanna start sth anywhere\nin machine learning, but it is toooooo\nexpensive.\nPublished 17 months ago by X. Wu\n Excellent book, concise and\nreadable\nThis is a great book if you're starting out\nwith machine learning. It's rare to come\nacross a book like this that is very well\nwritten and has technical depth. Read more\nPublished 20 months ago by Part Time Reader\n great book\nThis is a great book because it focuses on\nmachine learning techniques. It has been\nused as textbook in my class.\nPublished on November 11, 2005 by Jay\n Great introduction book for\nstudents in data mining and machine\nlearning class\nAlthough this text book is not required in\nmy data mining class, but I found it is very\nhelpful for my study. Read more\nPublished on October 24, 2005 by Thanh Doan\n Excellently written\nI am using this textbook for a Machine\nLearning class. While my professor is\nexcellent, I must say that this book is a\nwelcome addition to class. Read more\nPublished on October 12, 2005 by Gregor Kronenberger\n Just a brief introduction to ML\n...\nFirst of all, the statistical part of machine\nlearning is JUST a real subset of\nmathematical statisitcs, whatever Bayesian\nor frequentist. Read more\nPublished on September 12, 2005 by supercutepig\n Excellent reference book\nI liked the book. But I think author must\nprovide more figures in the book like Duda\nand Hart's Pattern Classification book.\nRead more\nPublished on December 25, 2004 by Fatih Nar\nSearch Customer Reviews\n Only search this product's reviews\n› See all 30 customer reviews...\n \nCustomer Discussions Beta (What's this?)\nNew! See recommended Discussions for You\nThis product's forum (0 discussions)\nDiscussionRepliesLatest Post\nNo discussions yet\nAsk questions, Share opinions, Gain insight\nStart a new discussion\nTopic:\n   \nRelated forums\nmachine learning (start the discussion)\nartificial intelligence  (1 discussion)\nProduct Information from the Amapedia Community Beta (What's this?)\nBe the first person to add an article about this item at Amapedia.com. \n› See featured Amapedia.com articles \nListmania!\n \nMachine Learning and Graphs: A list by J. Chan \"PhD Student (Computer\nScience)\"\n Bayesian Network Books: A list by Tincture Of Iodine \"TOI\"\n Books on Algorithms on a variety of topics: A list by calvinnme \"Texan refugee\"\nCreate a Listmania! list\nSearch Listmania!\nSo You'd Like to...\n \nLearn Advanced Mathematics on Your Own: A guide by Gal Gross \"Wir müssen\nwissen, wir werden wissen. - David Hilbert\"\n Learn more about Artificial Intelligence (AI) and Games: A guide by John Funge\n \nstudy curriculum of B.S. computer science (honors mode): A guide by\n\"josie_roberts\"\nCreate a guide\nSearch Guides\nLook for Similar Items by Category\nComputers & Internet > Computer Science > Artificial Intelligence > Machine Learning\nLook for Similar Items by Subject\n Machine learning\n Computer Books: General\nFind books matching ALL checked subjects \ni.e., each book must be in subject 1 AND subject 2 AND ... \nHarry Potter Store\nOur Harry\nPotter\nStore\nfeatures\nall things\nHarry,\nincluding\nbooks, audio CDs and\ncassettes, DVDs,\nsoundtracks, and more.\n \nGot Your Neti Pot?\nGive your\nsinuses a\nbath with\none of the many neti\npots in our Health &\nPersonal Care Store.\n›See more\n \nDrop It Like It's\nWaterproof\nAnd\nshockproof,\ncrushproof,\nand\nfreezeproof. All that, in\naddition to 7-megapixel\nresolution and Bright\nCapture technology,\nmakes the Olympus\nStylus 770SW the\nperfect vacation\ncompanion. Plus, it's now\navailable for only\n$289.94 from\nAmazon.com.\n \nEditors' Faves in\nBooks\nSave\n40%\non The\nSignificant 7, our favorite\npicks for the month.\n \n \n  \nFeedback \n If you need help or have a question for Customer Service, contact us.\n Would you like to update product info or give feedback on images? (We'll ask you to sign in so we can get back to you)\n Is there any other feedback you would like to provide? Click here\nWhere's My Stuff?\nTrack your recent orders.\nView or change your orders in Your Account.\nShipping & Returns\nSee our shipping rates & policies.\nReturn an item (here's our Returns Policy).\nNeed Help?\nForgot your password? Click here.\nRedeem or buy a gift certificate/card.\nVisit our Help department.\nSearch Amazon.com    \nYour Recent History (What's this?)\n \nRecently Viewed Products\nAfter viewing product detail pages or search results, look here to find an easy way to navigate back to pages you are interested in.\nLook to the right column to find helpful suggestions for your shopping session.\n› View & edit Your Browsing History\n   \n Amazon.com Home  |   Directory of All Stores\nInternational Sites:  Canada  |  United Kingdom  |  Germany  |  Japan  |  France  |  China\nHelp  |  View Cart  |  Your Account  |  Sell Items  |  1-Click Settings\n  \n \n  \n \n  \n \nFig. 1.2.  Books recommended by Amazon.com when viewing Tom Mitchell’s Ma-\nchine Learning Book [Mit97]. It is desirable for the vendor to recommend relevant\nbooks which a user might purchase.\nFig.  1.3.  11  Pictures  of  the  same  person  taken  from  the  Yale  face  recognition\ndatabase.  The  challenge  is  to  recognize  that  we  are  dealing  with  the  same  per-\nson in all 11 cases.\n\n61  Introduction\nHAVANA (Reuters) - The European Union’s top development aid official\nleft Cuba on Sunday convinced that EU diplomatic sanctions against\nthe communist island should be dropped after Fidel Castro’s\nretirement, his main aide said.\n<TYPE=\"ORGANIZATION\">HAVANA</>(<TYPE=\"ORGANIZATION\">Reuters</>) - The\n<TYPE=\"ORGANIZATION\">European Union</>’s top development aid official left\n<TYPE=\"ORGANIZATION\">Cuba</>on Sunday convinced that EU diplomatic sanctions\nagainst the communist<TYPE=\"LOCATION\">island</>should be dropped after\n<TYPE=\"PERSON\">Fidel Castro</>’s retirement, his main aide said.\nFig.  1.4.  Named  entity  tagging  of  a  news  article  (using  LingPipe).  The  relevant\nlocations, organizations and persons are tagged for further information extraction.\nare clearly terms from agriculture, it is equally clear that in the context of\ncontemporary politics they refer to members of the Republican Party.\nOther applications which take advantage of learning arespeech recog-\nnition(annotate an audio sequence with text, such as the system shipping\nwith Microsoft Vista), the recognition of handwriting (annotate a sequence\nof strokes with text, a feature common to many PDAs), trackpads of com-\nputers (e.g. Synaptics, a major manufacturer of such pads derives its name\nfrom the synapses of a neural network), the detection of failure in jet en-\ngines,  avatar  behavior  in  computer  games  (e.g.  Black  and  White),  direct\nmarketing (companies use past purchase behavior to guesstimate whether\nyou might be willing to purchase even more) and floor cleaning robots (such\nas iRobot’s Roomba). The overarching theme of learning problems is that\nthere exists a nontrivial dependence between some observations, which we\nwill commonly refer to asxand a desired response, which we refer to asy,\nfor which a simple set of deterministic rules is not known. By using learning\nwe can infer such a dependency betweenxandyin a systematic fashion.\nWe  conclude  this  section  by  discussing  the  problem  ofclassification,\nsince  it  will  serve  as  a  prototypical  problem  for  a  significant  part  of  this\nbook. It occurs frequently in practice: for instance, when performing spam\nfiltering, we are interested in a yes/no answer as to whether an e-mail con-\ntains relevant information or not. Note that this issue is quite user depen-\ndent: for a frequent traveller e-mails from an airline informing him about\nrecent discounts might prove valuable information, whereas for many other\nrecipients this might prove more of an nuisance (e.g. when the e-mail relates\nto  products  available  only  overseas).  Moreover,  the  nature  of  annoying  e-\nmails might change over time, e.g. through the availability of new products\n(Viagra, Cialis, Levitra, . . . ), different opportunities for fraud (the Nigerian\n419 scam which took a new twist after the Iraq war), or different data types\n(e.g. spam which consists mainly of images). To combat these problems we\n\n1.1  A Taste of Machine Learning7\nFig. 1.5.  Binary classification; separate stars from diamonds. In this example we\nare able to do so by drawing a straight line which separates both sets. We will see\nlater that this is an important example of what is called alinear classifier.\nwant to build a system which is able tolearnhow to classify new e-mails.\nA seemingly unrelated problem, that of cancer diagnosis shares a common\nstructure: given histological data (e.g. from a microarray analysis of a pa-\ntient’s tissue) infer whether a patient is healthy or not. Again, we are asked\nto generate a yes/no answer given a set of observations. See Figure 1.5 for\nan example.\n1.1.2  Data\nIt is useful to characterize learning problems according to the type of data\nthey use. This is a great help when encountering new challenges, since quite\noften problems on similar data types can be solved with very similar tech-\nniques. For instance natural language processing and bioinformatics use very\nsimilar  tools  for  strings  of  natural  language  text  and  for  DNA  sequences.\nVectorsconstitute the most basic entity we might encounter in our work.\nFor instance, a life insurance company might be interesting in obtaining the\nvector  of  variables  (blood  pressure,  heart  rate,  height,  weight,  cholesterol\nlevel, smoker, gender) to infer the life expectancy of a potential customer.\nA farmer might be interested in determining the ripeness of fruit based on\n(size, weight, spectral data). An engineer might want to find dependencies\nin (voltage, current) pairs. Likewise one might want to represent documents\nby a vector of counts which describe the occurrence of words. The latter is\ncommonly referred to as bag of words features.\nOne of the challenges in dealing with vectors is that thescalesand units\nof different coordinates may vary widely. For instance, we could measure the\nheight in kilograms, pounds, grams, tons, stones, all of which would amount\nto  multiplicative  changes.  Likewise,  when  representing  temperatures,  we\nhave  a  full  class  of  affine  transformations,  depending  on  whether  we  rep-\nresent  them  in  terms  of  Celsius,  Kelvin  or  Farenheit.  One  way  of  dealing\n\n81  Introduction\nwith those issues in an automatic fashion is to normalize the data. We will\ndiscuss means of doing so in an automatic fashion.\nLists:In some cases the vectors we obtain may contain a variable number\nof features. For instance, a physician might not necessarily decide to perform\na full battery of diagnostic tests if the patient appears to be healthy.\nSetsmay appear in learning problems whenever there is a large number of\npotential causes of an effect, which are not well determined. For instance, it is\nrelatively easy to obtain data concerning the toxicity of mushrooms. It would\nbe desirable to use such data to infer the toxicity of a new mushroom given\ninformation about its chemical compounds. However, mushrooms contain a\ncocktail of compounds out of which one or more may be toxic. Consequently\nwe need to infer the properties of an object given asetof features, whose\ncomposition and number may vary considerably.\nMatricesare a convenient means of representing pairwise relationships.\nFor instance, in collaborative filtering applications the rows of the matrix\nmay represent users whereas the columns correspond to products. Only in\nsome cases we will have knowledge about a given (user, product) combina-\ntion, such as the rating of the product by a user.\nA related situation occurs whenever we only have similarity information\nbetween  observations,  as  implemented  by  a  semi-empirical  distance  mea-\nsure.  Some  homology  searches  in  bioinformatics,  e.g.  variants  of  BLAST\n[AGML90], only return a similarity score which does not necessarily satisfy\nthe requirements of a metric.\nImagescould be thought of as two dimensional arrays of numbers, that is,\nmatrices. This representation is very crude, though, since they exhibit spa-\ntial coherence (lines, shapes) and (natural images exhibit) a multiresolution\nstructure. That is, downsampling an image leads to an object which has very\nsimilar statistics to the original image. Computer vision and psychooptics\nhave created a raft of tools for describing these phenomena.\nVideoadds a temporal dimension to images. Again, we could represent\nthem as a three dimensional array. Good algorithms, however, take the tem-\nporal coherence of the image sequence into account.\nTrees and Graphsare often used to describe relations between collec-\ntions of objects. For instance the ontology of webpages of the DMOZ project\n(www.dmoz.org) has  the  form of a  tree with topics becoming  increasingly\nrefined as we traverse from the root to one of the leaves (Arts→Animation\n→Anime→General Fan Pages→Official Sites). In the case of gene ontol-\nogy the relationships form a directed acyclic graph, also referred to as the\nGO-DAG [ABB\n+\n00].\nBoth examples above describe estimation problems where our observations\n\n1.1  A Taste of Machine Learning9\nare  vertices  of  a  tree  or  graph.  However,  graphs  themselves  may  be  the\nobservations.  For  instance,  the  DOM-tree  of  a  webpage,  the  call-graph  of\na computer program, or the protein-protein interaction networks may form\nthe basis upon which we may want to perform inference.\nStringsoccur frequently, mainly in the area of bioinformatics and natural\nlanguage processing. They may be the input to our estimation problems, e.g.\nwhen classifying an e-mail as spam, when attempting to locate all names of\npersons and organizations in a text, or when modeling the topic structure\nof a document. Equally well they may constitute the output of a system.\nFor instance, we may want to perform document summarization, automatic\ntranslation, or attempt to answer natural language queries.\nCompound structuresare the most commonly occurring object. That\nis, in most situations we will have a structured mix of different data types.\nFor instance, a webpage might contain images, text, tables, which in turn\ncontain numbers, and lists, all of which might constitute nodes on a graph of\nwebpages linked among each other. Good statistical modelling takes such de-\npendencies and structures into account in order to tailor sufficiently flexible\nmodels.\n1.1.3  Problems\nThe range of learning problems is clearly large, as we saw when discussing\napplications. That said, researchers have identified an ever growing number\nof templates which can be used to address a large set of situations. It is those\ntemplates which make deployment of machine learning in practice easy and\nour discussion will largely focus on a choice set of such problems. We now\ngive a by no means complete list of templates.\nBinary Classificationis probably the most frequently studied problem\nin machine learning and it has led to a large number of important algorithmic\nand  theoretic  developments  over  the  past  century.  In  its  simplest  form  it\nreduces to the question: given a patternxdrawn from a domainX, estimate\nwhich  value  an  associated  binary  random  variabley∈ {±1}will  assume.\nFor instance, given pictures of apples and oranges, we might want to state\nwhether the object in question is an apple or an orange. Equally well, we\nmight  want  to  predict  whether  a  home  owner  might  default  on  his  loan,\ngiven income data, his credit history, or whether a given e-mail is spam or\nham. The ability to solve this basic problem already allows us to address a\nlarge variety of practical settings.\nThere are many variants exist with regard to the protocol in which we are\nrequired to make our estimation:\n\n101  Introduction\nFig. 1.6.  Left: binary classification. Right: 3-class classification. Note that in the\nlatter case we have much more degree for ambiguity. For instance, being able to\ndistinguish stars from diamonds may not suffice to identify either of them correctly,\nsince we also need to distinguish both of them from triangles.\n•We might see a sequence of (x\ni\n,y\ni\n) pairs for whichy\ni\nneeds to be estimated\nin an instantaneous online fashion. This is commonly referred to as online\nlearning.\n•We might observe a collectionX:={x\n1\n,...x\nm\n}andY:={y\n1\n,...y\nm\n}of\npairs (x\ni\n,y\ni\n) which are then used to estimateyfor a (set of) so-far unseen\nX\n′\n=\n{\nx\n′\n1\n,...,x\n′\nm\n′\n}\n. This is commonly referred to as batch learning.\n•We might be allowed to knowX\n′\nalready at the time of constructing the\nmodel. This is commonly referred to as transduction.\n•We might be allowed to chooseXfor the purpose of model building. This\nis known as active learning.\n•We might not have full information aboutX, e.g. some of the coordinates\nof  thex\ni\nmight  be  missing,  leading  to  the  problem  of  estimation  with\nmissing variables.\n•The setsXandX\n′\nmight come from different data sources, leading to the\nproblem of covariate shift correction.\n•We might be given observations stemming from two problems at the same\ntime with the side information that both problems are somehow related.\nThis is known as co-training.\n•Mistakes of estimation might be penalized differently depending on the\ntype of error, e.g. when trying to distinguish diamonds from rocks a very\nasymmetric loss applies.\nMulticlass  Classificationis  the  logical  extension  of  binary  classifica-\ntion. The main difference is that nowy∈ {1,...,n}may assume a range\nof different values. For instance, we might want to classify a document ac-\ncording to the language it was written in (English, French, German, Spanish,\nHindi, Japanese, Chinese, . . . ). See Figure 1.6 for an example. The main dif-\nference to before is that the cost of error may heavily depend on the type of\n\n1.1  A Taste of Machine Learning11\nFig. 1.7.  Regression estimation. We are given a number of instances (indicated by\nblack dots) and would like to find some functionfmapping the observationsXto\nRsuch thatf(x) is close to the observed values.\nerror we make. For instance, in the problem of assessing the risk of cancer, it\nmakes a significant difference whether we mis-classify an early stage of can-\ncer as healthy (in which case the patient is likely to die) or as an advanced\nstage of cancer (in which case the patient is likely to be inconvenienced from\noverly aggressive treatment).\nStructured  Estimationgoes  beyond  simple  multiclass  estimation  by\nassuming that the labelsyhave some additional structure which can be used\nin the estimation process. For instance,ymight be a path in an ontology,\nwhen  attempting  to  classify  webpages,ymight  be  a  permutation,  when\nattempting to match objects, to perform collaborative filtering, or to rank\ndocuments in a retrieval setting. Equally well,ymight be an annotation of\na text, when performing named entity recognition. Each of those problems\nhas  its  own  properties  in  terms  of  the  set  ofywhich  we  might  consider\nadmissible, or how to search this space. We will discuss a number of those\nproblems in Chapter??.\nRegressionis another prototypical application. Here the goal is to esti-\nmate a real-valued variabley∈Rgiven a patternx(see e.g. Figure 1.7). For\ninstance, we might want to estimate the value of a stock the next day, the\nyield of a semiconductor fab given the current process, the iron content of\nore given mass spectroscopy measurements, or the heart rate of an athlete,\ngiven accelerometer data. One of the key issues in which regression problems\ndiffer from each other is the choice of a loss. For instance, when estimating\nstock values our loss for a put option will be decidedly one-sided. On the\nother hand, a hobby athlete might only care that our estimate of the heart\nrate matches the actual on average.\nNovelty Detectionis a rather ill-defined problem. It describes the issue\nof  determining  “unusual”  observations  given  a  set  of  past  measurements.\nClearly, the choice of what is to be considered unusual is very subjective.\nA commonly accepted notion is that unusual events occur rarely. Hence a\npossible goal is to design a system which assigns to each observation a rating\n\n121  Introduction\nFig.  1.8.  Left:  typical  digits  contained  in  the  database  of  the  US  Postal  Service.\nRight:  unusual  digits  found  by  a  novelty  detection  algorithm  [SPST\n+\n01]  (for  a\ndescription of the algorithm see Section 7.4). The score below the digits indicates\nthe degree of novelty. The numbers on the lower right indicate the class associated\nwith the digit.\nas to how novel it is. Readers familiar with density estimation might contend\nthat the latter would be a reasonable solution. However, we neither need a\nscore which sums up to 1 on the entire domain, nor do we care particularly\nmuch about novelty scores fortypicalobservations. We will later see how this\nsomewhat easier goal can be achieved directly. Figure 1.8 has an example of\nnovelty detection when applied to an optical character recognition database.\n1.2  Probability Theory\nIn order to deal with the instances of where machine learning can be used, we\nneed to develop an adequate language which is able to describe the problems\nconcisely. Below we begin with a fairly informal overview over probability\ntheory. For more details and a very gentle and detailed discussion see the\nexcellent book of [BT03].\n1.2.1  Random Variables\nAssume that we cast a dice and we would like to know our chances whether\nwe would see 1 rather than another digit. If the dice is fair all six outcomes\nX={1,...,6}are equally likely to occur, hence we would see a 1 in roughly\n1 out of 6 cases. Probability theory allows us to model uncertainty in the out-\ncome of such experiments. Formally we state that 1 occurs with probability\n1\n6\n.\nIn  many  experiments,  such  as  the  roll  of  a  dice,  the  outcomes  are  of  a\nnumerical nature and we can handle them easily. In other cases, the outcomes\nmay not be numerical,e.g.,if we toss a coin and observe heads or tails. In\nthese cases, it is useful to associate numerical values to the outcomes. This\nis done via a random variable. For instance, we can let a random variable\n\n1.2  Probability Theory13\nXtake  on  a  value  +1  whenever  the  coin  lands  heads  and  a  value  of−1\notherwise. Our notational convention will be to use uppercase letters,e.g.,\nX,Yetc to denote random variables and lower case letters,e.g.,x,yetc to\ndenote the values they take.\nX\nweight\nheight\nξ(x)\nx\nFig. 1.9.  The random variableξmaps from the set of outcomes of an experiment\n(denoted  here  byX)  to  real  numbers.  As  an  illustration  hereXconsists  of  the\npatients a physician might encounter, and they are mapped viaξto their weight\nand height.\n1.2.2  Distributions\nPerhaps  the  most  important  way  to  characterize  a  random  variable  is  to\nassociate probabilities with the values it can take. If the random variable is\ndiscrete,i.e.,it takes on a finite number of values, then this assignment of\nprobabilities is called aprobability mass functionor PMF for short. A PMF\nmust  be,  by  definition,  non-negative  and  must  sum  to  one.  For  instance,\nif the coin is fair,i.e.,heads and tails are equally likely, then the random\nvariableXdescribed above takes on values of +1 and−1 with probability\n0.5. This can be written as\nPr(X= +1) = 0.5 andPr(X=−1) = 0.5.(1.1)\nWhen there is no danger of confusion we will use the slightly informal no-\ntationp(x) :=Pr(X=x).\nIn case of a continuous random variable the assignment of probabilities\nresults in aprobability density functionor PDF for short. With some abuse\nof terminology, but keeping in line with convention, we will often use density\nor distribution instead of probability density function. As in the case of the\nPMF, a PDF must also be non-negative and integrate to one. Figure 1.10\nshows two distributions: the uniform distribution\np(x) =\n{\n1\nb−a\nifx∈[a,b]\n0otherwise,\n(1.2)\n\n141  Introduction\n-4-2024\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n-4-2024\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nFig.  1.10.  Two  common  densities.  Left:  uniform  distribution  over  the  interval\n[−1,1]. Right: Normal distribution with zero mean and unit variance.\nand the Gaussian distribution (also called normal distribution)\np(x) =\n1\n√\n2πσ\n2\nexp\n(\n−\n(x−μ)\n2\n2σ\n2\n)\n.(1.3)\nClosely associated with a PDF is the indefinite integral overp. It is com-\nmonly referred to as the cumulative distribution function (CDF).\nDefinition 1.1 (Cumulative Distribution Function)For a real valued\nrandom variableXwith PDFpthe associated Cumulative Distribution Func-\ntionFis given by\nF(x\n′\n) := Pr\n{\nX≤x\n′\n}\n=\n∫\nx\n′\n−∞\ndp(x).(1.4)\nThe  CDFF(x\n′\n)  allows  us  to  perform  range  queries  onpefficiently.  For\ninstance, by integral calculus we obtain\nPr(a≤X≤b) =\n∫\nb\na\ndp(x) =F(b)−F(a).(1.5)\nThe values ofx\n′\nfor whichF(x\n′\n) assumes a specific value, such as 0.1 or 0.5\nhave a special name. They are called thequantilesof the distributionp.\nDefinition 1.2 (Quantiles)Letq∈(0,1). Then the value ofx\n′\nfor which\nPr(X < x\n′\n)≤qandPr(X > x\n′\n)≤1−qis theq-quantile of the distribution\np. Moreover, the valuex\n′\nassociated withq= 0.5is called the median.\n\n1.2  Probability Theory15\np(x)\nFig. 1.11.  Quantiles of a distribution correspond to the area under the integral of\nthe densityp(x) for which the integral takes on a pre-specified value. Illustrated\nare the 0.1, 0.5 and 0.9 quantiles respectively.\n1.2.3  Mean and Variance\nA common question to ask about a random variable is what its expected\nvalue might be. For instance, when measuring the voltage of a device, we\nmight ask what its typical values might be. When deciding whether to ad-\nminister a growth hormone to a child a doctor might ask what a sensible\nrange of height should be. For those purposes we need to define expectations\nand related quantities of distributions.\nDefinition 1.3 (Mean)We define the mean of a random variableXas\nE[X] :=\n∫\nxdp(x)(1.6)\nMore  generally,  iff:R→Ris  a  function,  thenf(X)is  also  a  random\nvariable. Its mean is mean given by\nE[f(X)] :=\n∫\nf(x)dp(x).(1.7)\nWheneverXis a discrete random variable the integral in (1.6) can be re-\nplaced by a summation:\nE[X] =\n∑\nx\nxp(x).(1.8)\nFor instance, in the case of a dice we have equal probabilities of 1/6 for all\n6  possible  outcomes.  It  is  easy  to  see  that  this  translates  into  a  mean  of\n(1 + 2 + 3 + 4 + 5 + 6)/6 = 3.5.\nThe mean of a random variable is useful in assessing expected losses and\nbenefits. For instance, as a stock broker we might be interested in the ex-\npected value of our investment in a year’s time. In addition to that, however,\nwe also might want to investigate theriskof our investment. That is, how\nlikely it is that the value of the investment might deviate from its expecta-\ntion since this might be more relevant for our decisions. This means that we\n\n161  Introduction\nneed a variable to quantify the risk inherent in a random variable. One such\nmeasure is thevarianceof a random variable.\nDefinition 1.4 (Variance)We  define  the  variance  of  a  random  variable\nXas\nVar[X] :=E\n[\n(X−E[X])\n2\n]\n.(1.9)\nAs before, iff:R→Ris a function, then the variance off(X)is given by\nVar[f(X)] :=E\n[\n(f(X)−E[f(X)])\n2\n]\n.(1.10)\nThe variance measures by how much on averagef(X) deviates from its ex-\npected value. As we shall see in Section 2.1, an upper bound on the variance\ncan be used to give guarantees on the probability thatf(X) will be within\n\u000fof its expected value. This is one of the reasons why the variance is often\nassociated with the risk of a random variable. Note that often one discusses\nproperties of a random variable in terms of itsstandard deviation, which is\ndefined as the square root of the variance.\n1.2.4  Marginalization, Independence, Conditioning, and Bayes\nRule\nGiven  two  random  variablesXandY,  one  can  write  their  joint  density\np(x,y). Given the joint density, one can recoverp(x) by integrating outy.\nThis operation is called marginalization:\np(x) =\n∫\ny\ndp(x,y).(1.11)\nIfYis a discrete random variable, then we can replace the integration with\na summation:\np(x) =\n∑\ny\np(x,y).(1.12)\nWe say thatXandYare independent,i.e.,the values thatXtakes does\nnot depend on the values thatYtakes whenever\np(x,y) =p(x)p(y).(1.13)\nIndependence is useful when it comes to dealing with large numbers of ran-\ndom  variables  whose  behavior  we  want  to  estimate  jointly.  For  instance,\nwhenever we perform repeated measurements of a quantity, such as when\n\n1.2  Probability Theory17\n-0.50.00.51.01.52.0\n-0.5\n0.0\n0.5\n1.0\n1.5\n2.0\n-0.50.00.51.01.52.0\n-0.5\n0.0\n0.5\n1.0\n1.5\n2.0\nFig.  1.12.  Left:  a  sample  from  two  dependent  random  variables.  Knowing  about\nfirst coordinate allows us to improve our guess about the second coordinate. Right:\na  sample  drawn  from  two  independent  random  variables,  obtained  by  randomly\npermuting the dependent sample.\nmeasuring the voltage of a device, we will typically assume that the individ-\nual measurements are drawn from the same distribution and that they are\nindependent of each other. That is, having measured the voltage a number\nof times will not affect the value of the next measurement. We will call such\nrandom variables to beindependently and identically distributed, or in short,\niidrandom variables. See Figure 1.12 for an example of a pair of random\nvariables drawn from dependent and independent distributions respectively.\nConversely, dependence can be vital in classification and regression prob-\nlems. For instance, the traffic lights at an intersection are dependent of each\nother. This allows a driver to perform the inference that when the lights are\ngreen in his direction there will be no traffic crossing his path, i.e. the other\nlights will indeed be red. Likewise, whenever we are given a picturexof a\ndigit, we hope that there will be dependence betweenxand its labely.\nEspecially in the case of dependent random variables, we are interested\nin  conditional  probabilities,i.e.,probability  thatXtakes  on  a  particular\nvalue given the value ofY. ClearlyPr(X=rain|Y=cloudy) is higher than\nPr(X=rain|Y=sunny). In other words, knowledge about the value ofY\nsignificantly influences the distribution ofX. This is captured via conditional\nprobabilities:\np(x|y) :=\np(x,y)\np(y)\n.(1.14)\nEquation 1.14 leads to one of the key tools in statistical inference.\nTheorem 1.5 (Bayes Rule)Denote  byXandYrandom  variables  then\n\n181  Introduction\nthe following holds\np(y|x) =\np(x|y)p(y)\np(x)\n.(1.15)\nThis follows from the fact thatp(x,y) =p(x|y)p(y) =p(y|x)p(x). The key\nconsequence  of  (1.15)  is  that  we  mayreversethe  conditioning  between  a\npair of random variables.\n1.2.4.1  An Example\nWe illustrate our reasoning by means of a simple example — inference using\nan AIDS test. Assume that a patient would like to have such a test carried\nout on him. The physician recommends a test which is guaranteed to detect\nHIV-positive whenever a patient is infected. On the other hand, for healthy\npatients it has a 1% error rate. That is, with probability 0.01 it diagnoses\na patient as HIV-positive even when he is, in fact, HIV-negative. Moreover,\nassume that 0.15% of the population is infected.\nNow  assume  that  the  patient  has  the  test  carried  out  and  the  test  re-\nturns ’HIV-negative’. In this case, logic implies that he is healthy, since the\ntest has 100% detection rate. In the converse case things are not quite as\nstraightforward. Denote byXandTthe random variables associated with\nthe health status of the patient and the outcome of the test respectively. We\nare interested inp(X= HIV+|T= HIV+). By Bayes rule we may write\np(X= HIV+|T= HIV+) =\np(T= HIV+|X= HIV+)p(X= HIV+)\np(T= HIV+)\nWhile we know all terms in the numerator,p(T= HIV+) itself is unknown.\nThat said, it can be computed via\np(T= HIV+) =\n∑\nx∈{HIV+,HIV-}\np(T= HIV+,x)\n=\n∑\nx∈{HIV+,HIV-}\np(T= HIV+|x)p(x)\n= 1.0·0.0015 + 0.01·0.9985.\nSubstituting back into the conditional expression yields\np(X= HIV+|T= HIV+) =\n1.0·0.0015\n1.0·0.0015 + 0.01·0.9985\n= 0.1306.\nIn other words, even though our test is quite reliable, there is such a low\nprior probability of having been infected with AIDS that there is not much\nevidence to accept the hypothesis even after this test.\n\n1.2  Probability Theory19\nagex\ntest 1\ntest 2\nFig. 1.13.  A graphical description of our HIV testing scenario. Knowing the age of\nthe patient influences our prior on whether the patient is HIV positive (the random\nvariableX). The outcomes of the tests 1 and 2 are independent of each other given\nthe  statusX.  We  observe  the  shaded  random  variables  (age,  test  1,  test  2)  and\nwould like to infer the un-shaded random variableX. This is a special case of a\ngraphical model which we will discuss in Chapter??.\nLet us now think how we could improve the diagnosis. One way is to ob-\ntain further information about the patient and to use this in the diagnosis.\nFor instance, information about his age is quite useful. Suppose the patient\nis 35 years old. In this case we would want to computep(X= HIV+|T=\nHIV+,A= 35) where the random variableAdenotes the age. The corre-\nsponding expression yields:\np(T= HIV+|X= HIV+,A)p(X= HIV+|A)\np(T= HIV+|A)\nHere we simplyconditionedall random variables onAin order to take addi-\ntional information into account. We may assume that the test isindependent\nof the age of the patient, i.e.\np(t|x,a) =p(t|x).\nWhat remains therefore isp(X= HIV+|A). Recent US census data pegs this\nnumber at approximately 0.9%. Plugging all data back into the conditional\nexpression yields\n1·0.009\n1·0.009+0.01·0.991\n= 0.48. What has happened here is that\nby including additional observed random variables our estimate has become\nmore  reliable.  Combination  of  evidence  is  a  powerful  tool.  In  our  case  it\nhelped  us  make  the  classification  problem  of  whether  the  patient  is  HIV-\npositive or not more reliable.\nA second tool in our arsenal is the use of multiple measurements. After\nthe first test the physician is likely to carry out a second test to confirm the\ndiagnosis. We denote byT\n1\nandT\n2\n(andt\n1\n,t\n2\nrespectively) the two tests.\nObviously, what we want is thatT\n2\nwill give us an “independent” second\nopinion  of  the  situation.  In  other  words,  we  want  to  ensure  thatT\n2\ndoes\nnot make the same mistakes asT\n1\n. For instance, it is probably a bad idea\nto repeatT\n1\nwithout changes, since it might perform the same diagnostic\n\n201  Introduction\nmistake as before. What we want is that the diagnosis ofT\n2\nis independent\nof that ofT\n2\ngiventhe health statusXof the patient. This is expressed as\np(t\n1\n,t\n2\n|x) =p(t\n1\n|x)p(t\n2\n|x).(1.16)\nSee Figure 1.13 for a graphical illustration of the setting. Random variables\nsatisfying  the  condition  (1.16)  are  commonly  referred  to  asconditionally\nindependent. In shorthand we writeT\n1\n,T\n2\n⊥⊥X. For the sake of the argument\nwe assume that the statistics forT\n2\nare given by\np(t\n2\n|x)x= HIV-x= HIV+\nt\n2\n= HIV-0.950.01\nt\n2\n= HIV+    0.050.99\nClearly  this  test  is  less  reliable  than  the  first  one.  However,  we  may  now\ncombine  both  estimates  to  obtain  a  very  reliable  estimate  based  on  the\ncombination of both events. For instance, fort\n1\n=t\n2\n= HIV+ we have\np(X= HIV+|T\n1\n= HIV+,T\n2\n= HIV+) =\n1.0·0.99·0.009\n1.0·0.99·0.009 + 0.01·0.05·0.991\n= 0.95.\nIn other words, by combining two tests we can now confirm with very high\nconfidence that the patient is indeed diseased. What we have carried out is a\ncombination of evidence. Strong experimental evidence of two positive tests\neffectively overcame an initially very strong prior which suggested that the\npatient might be healthy.\nTests  such  as  in  the  example  we  just  discussed  are  fairly  common.  For\ninstance, we might need to decide which manufacturing procedure is prefer-\nable, which choice of parameters will give better results in a regression es-\ntimator, or whether to administer a certain drug. Note that often our tests\nmay not be conditionally independent and we would need to take this into\naccount.\n1.3  Basic Algorithms\nWe conclude our introduction to machine learning by discussing four simple\nalgorithms,  namely  Naive  Bayes,  Nearest  Neighbors,  the  Mean  Classifier,\nand the Perceptron, which can be used to solve a binary classification prob-\nlem such as that described in Figure 1.5. We will also introduce the K-means\nalgorithm  which  can  be  employed  when  labeled  data  is  not  available.  All\nthese algorithms are readily usable and easily implemented from scratch in\ntheir most basic form.\nFor the sake of concreteness assume that we are interested in spam filter-\ning. That is, we are given a set ofme-mailsx\ni\n, denoted byX:={x\n1\n,...,x\nm\n}\n\n1.3  Basic Algorithms21\nFrom: \"LucindaParkison497072\" <LucindaParkison497072@hotmail.com>\nTo: <kargr@earthlink.net>\nSubject: we think ACGU is our next winner\nDate: Mon, 25 Feb 2008 00:01:01 -0500\nMIME-Version: 1.0\nX-OriginalArrivalTime: 25 Feb 2008 05:01:01.0329 (UTC) FILETIME=[6A931810:01C8776B]\nReturn-Path: lucindaparkison497072@hotmail.com\n(ACGU) .045 UP 104.5%\nI do think that (ACGU) at it’s current levels looks extremely attractive.\nAsset Capital Group, Inc., (ACGU) announced that it is expanding the marketing of bio-remediation fluids and cleaning equipment. After\nits recent acquisition of interest in American Bio-Clean Corporation and an 80\nNews is expected to be released next week on this growing company and could drive the price even higher. Buy (ACGU) Monday at open. I\nbelieve those involved at this stage could enjoy a nice ride up.\nFig. 1.14.  Example of a spam e-mail\nx\n1\n:The quick brown fox jumped over the lazy dog.\nx\n2\n:The dog hunts a fox.\nthe  quick  brown  fox  jumped  over  lazy  dog  hunts  a\nx\n1\n2111111100\nx\n2\n1001000111\nFig. 1.15.  Vector space representation of strings.\nand associated labelsy\ni\n, denoted byY:={y\n1\n,...,y\nm\n}. Here the labels sat-\nisfyy\ni\n∈ {spam,ham}. The key assumption we make here is that the pairs\n(x\ni\n,y\ni\n)  are  drawn  jointly  from  some  distributionp(x,y)  which  represents\nthe  e-mail  generating  process  for  a  user.  Moreover,  we  assume  that  there\nis sufficiently strong dependence betweenxandythat we will be able to\nestimateygivenxand a set of labeled instancesX,Y.\nBefore we do so we need to address the fact that e-mails such as Figure 1.14\naretext,  whereas  the  three  algorithms  we  present  will  require  data  to  be\nrepresented in avectorialfashion. One way of converting text into a vector\nis by using the so-calledbag of wordsrepresentation [Mar61, Lew98]. In its\nsimplest version it works as follows: Assume we have a list of all possible\nwords occurring inX, that is a dictionary, then we are able to assign a unique\nnumber with each of those words (e.g. the position in the dictionary). Now\nwe  may  simply  count  for  each  documentx\ni\nthe  number  of  times  a  given\nwordjis occurring. This is then used as the value of thej-th coordinate\nofx\ni\n. Figure 1.15 gives an example of such a representation. Once we have\nthe latter it is easy to compute distances, similarities, and other statistics\ndirectly from the vectorial representation.\n\n221  Introduction\n1.3.1  Naive Bayes\nIn the example of the AIDS test we used the outcomes of the test to infer\nwhether the patient is diseased. In the context of spam filtering the actual\ntext of the e-mailxcorresponds to the test and the labelyis equivalent to\nthe diagnosis. Recall Bayes Rule (1.15). We could use the latter to infer\np(y|x) =\np(x|y)p(y)\np(x)\n.\nWe may have a good estimate ofp(y), that is, the probability of receiving\na spam or ham mail. Denote bym\nham\nandm\nspam\nthe number of ham and\nspam e-mails inX. In this case we can estimate\np(ham)≈\nm\nham\nm\nandp(spam)≈\nm\nspam\nm\n.\nThe key problem, however, is that we do not knowp(x|y) orp(x). We may\ndispose of the requirement of knowingp(x) by settling for a likelihood ratio\nL(x) :=\np(spam|x)\np(ham|x)\n=\np(x|spam)p(spam)\np(x|ham)p(ham)\n.(1.17)\nWheneverL(x) exceeds a given thresholdcwe decide thatxis spam and\nconsequently reject the e-mail. Ifcis large then our algorithm is conservative\nand classifies an email as spam only ifp(spam|x)\u001dp(ham|x). On the other\nhand, ifcis small then the algorithm aggressively classifies emails as spam.\nThe key obstacle is that we have no access top(x|y). This is where we make\nour key approximation. Recall Figure 1.13. In order to model the distribution\nof  the  test  outcomesT\n1\nandT\n2\nwe  made  the  assumption  that  they  are\nconditionally  independent  of  each  other  given  the  diagnosis.  Analogously,\nwe may now treat the occurrence of each word in a document as a separate\ntest and combine the outcomes in anaivefashion by assuming that\np(x|y) =\n# of words inx\n∏\nj=1\np(w\nj\n|y),(1.18)\nwherew\nj\ndenotes  thej-th  word  in  documentx.  This  amounts  to  the  as-\nsumption  that  the  probability  of  occurrence  of  a  word  in  a  document  is\nindependent of all other words given the category of the document. Even\nthough  this  assumption  does  not  hold  in  general – for  instance,  the  word\n“York”  is  much  more  likely  to  after  the  word  “New” – it  suffices  for  our\npurposes (see Figure 1.16).\nThis assumption reduces the difficulty of knowingp(x|y) to that of esti-\nmating the probabilities of occurrence of individual wordsw. Estimates for\n\n1.3  Basic Algorithms23\ny\nword 1word 2\n...\nword n\nword 3\nFig. 1.16.  Naive Bayes model. The occurrence of individual words is independent\nof each other, given the category of the text. For instance, the wordViagrais fairly\nfrequent ify= spam but it is considerably less frequent ify= ham, except when\nconsidering the mailbox of a Pfizer sales representative.\np(w|y) can be obtained, for instance, by simply counting the frequency oc-\ncurrence of the word within documents of a given class. That is, we estimate\np(w|spam)≈\n∑\nm\ni=1\n∑\n# of words inx\ni\nj=1\n{\ny\ni\n= spam andw\nj\ni\n=w\n}\n∑\nm\ni=1\n∑\n# of words inx\ni\nj=1\n{y\ni\n= spam}\nHere\n{\ny\ni\n= spam andw\nj\ni\n=w\n}\nequals 1 if and only ifx\ni\nis labeled as spam\nandwoccurs as thej-th word inx\ni\n. The denominator is simply the total\nnumber of words in spam documents. Similarly one can computep(w|ham).\nIn principle we could perform the above summation whenever we see a new\ndocumentx. This would be terribly inefficient, since each such computation\nrequires a full pass throughXandY. Instead, we can perform a single pass\nthroughXandYand store the resulting statistics as a good estimate of the\nconditional  probabilities.  Algorithm  1.1  has  details  of  an  implementation.\nNote that we performed a number of optimizations: Firstly, the normaliza-\ntion bym\n−1\nspam\nandm\n−1\nham\nrespectively is independent ofx, hence we incor-\nporate it as a fixed offset. Secondly, since we are computing a product over\na large number of factors the numbers might lead to numerical overflow or\nunderflow. This can be addressed by summing over the logarithm of terms\nrather than computing products. Thirdly, we need to address the issue of\nestimatingp(w|y) for wordswwhich we might not have seen before. One\nway  of  dealing  with  this  is  to  increment  all  counts  by  1.  This  method  is\ncommonly referred to as Laplace smoothing. We will encounter a theoretical\njustification for this heuristic in Section 2.3.\nThis simple algorithm is known to perform surprisingly well, and variants\nof  it  can  be  found  in  most  modern  spam  filters.  It  amounts  to  what  is\ncommonly known as “Bayesian spam filtering”. Obviously, we may apply it\nto problems other than document categorization, too.\n\n241  Introduction\nAlgorithm 1.1Naive Bayes\nTrain(X,Y){reads documentsXand labelsY}\nCompute dictionaryDofXwithnwords.\nComputem,m\nham\nandm\nspam\n.\nInitializeb:= logc+ logm\nham\n−logm\nspam\nto offset the rejection threshold\nInitializep∈R\n2×n\nwithp\nij\n= 1,w\nspam\n=n,w\nham\n=n.\n{Count occurrence of each word}\n{Herex\nj\ni\ndenotes the number of times wordjoccurs in documentx\ni\n}\nfori= 1 tomdo\nify\ni\n= spamthen\nforj= 1 tondo\np\n0,j\n←p\n0,j\n+x\nj\ni\nw\nspam\n←w\nspam\n+x\nj\ni\nend for\nelse\nforj= 1 tondo\np\n1,j\n←p\n1,j\n+x\nj\ni\nw\nham\n←w\nham\n+x\nj\ni\nend for\nend if\nend for\n{Normalize counts to yield word probabilities}\nforj= 1 tondo\np\n0,j\n←p\n0,j\n/w\nspam\np\n1,j\n←p\n1,j\n/w\nham\nend for\nClassify(x){classifies documentx}\nInitialize score thresholdt=−b\nforj= 1 tondo\nt←t+x\nj\n(logp\n0,j\n−logp\n1,j\n)\nend for\nift >0returnspamelse returnham\n1.3.2  Nearest Neighbor Estimators\nAn even simpler estimator than Naive Bayes is nearest neighbors. In its most\nbasic form it assigns the label of its nearest neighbor to an observationx\n(see Figure 1.17). Hence, all we need to implement it is a distance measure\nd(x,x\n′\n) between pairs of observations. Note that this distance need not even\nbe symmetric. This means that nearest neighbor classifiers can be extremely\n\n1.3  Basic Algorithms25\nFig. 1.17.  1 nearest neighbor classifier. Depending on whether the query pointxis\nclosest to the star, diamond or triangles, it uses one of the three labels for it.\nFig.  1.18.k-Nearest  neighbor  classifiers  using  Euclidean  distances.  Left:  decision\nboundaries obtained from a 1-nearest neighbor classifier. Middle: color-coded sets\nof where the number of red / blue points ranges between 7 and 0. Right: decision\nboundary determining where the blue or red dots are in the majority.\nflexible.  For  instance,  we  could  use  string  edit  distances  to  compare  two\ndocuments or information theory based measures.\nHowever, the problem with nearest neighbor classification is that the esti-\nmates can be very noisy whenever the data itself is very noisy. For instance,\nif  a  spam  email  is  erroneously  labeled  as  nonspam  then  all  emails  which\nare  similar  to  this  email  will  share  the  same  fate.  See  Figure  1.18  for  an\nexample. In this case it is beneficial to pool together a number of neighbors,\nsay thek-nearest neighbors ofxand use a majority vote to decide the class\nmembership  ofx.  Algorithm  1.2  has  a  description  of  the  algorithm.  Note\nthat nearest neighbor algorithms can yield excellent performance when used\nwith a good distance measure. For instance, the technology underlying the\nNetflix progress prize [BK07] was essentially nearest neighbours based.\nNote that it is trivial to extend the algorithm to regression. All we need\nto change in Algorithm 1.2 is to return the average of the valuesy\ni\ninstead\nof their majority vote. Figure 1.19 has an example.\nNote that the distance computationd(x\ni\n,x) for all observations can be-\n\n261  Introduction\nAlgorithm 1.2k-Nearest Neighbor Classification\nClassify(X,Y,x){reads documentsX, labelsYand queryx}\nfori= 1tomdo\nCompute distanced(x\ni\n,x)\nend for\nCompute setIcontaining indices for theksmallest distancesd(x\ni\n,x).\nreturnmajority label of{y\ni\nwherei∈I}.\nFig. 1.19.k-Nearest neighbor regression estimator using Euclidean distances. Left:\nsome  points  (x,y)  drawn  from  a  joint  distribution.  Middle:  1-nearest  neighbour\nclassifier. Right: 7-nearest neighbour classifier. Note that the regression estimate is\nmuch more smooth.\ncome extremely costly, in particular whenever the number of observations is\nlarge or whenever the observationsx\ni\nlive in a very high dimensional space.\nRandom projections are a technique that can alleviate the high computa-\ntional cost of Nearest Neighbor classifiers. A celebrated lemma by Johnson\nand Lindenstrauss [DG03] asserts that a set ofmpoints in high dimensional\nEuclidean space can be projected into aO(logm/\u000f\n2\n) dimensional Euclidean\nspace such that the distance between any two points changes only by a fac-\ntor of (1±\u000f). Since Euclidean distances are preserved, running the Nearest\nNeighbor  classifier  on  this  mapped  data  yields  the  same  results  but  at  a\nlower computational cost [GIM99].\nThe surprising fact is that the projection relies on a simple randomized\nalgorithm: to obtain ad-dimensional representation ofn-dimensional ran-\ndom observations we pick a matrixR∈R\nd×n\nwhere each element is drawn\nindependently from a normal distribution withn\n−\n1\n2\nvariance and zero mean.\nMultiplyingxwith this projection matrix can be shown to achieve this prop-\nerty with high probability. For details see [DG03].\n\n1.3  Basic Algorithms27\nw\nμ\n-\nμ\n+\nx\nFig. 1.20.  A trivial classifier. Classification is carried out in accordance to which of\nthe two meansμ\n−\norμ\n+\nis closer to the test pointx. Note that the sets of positive\nand negative labels respectively form a half space.\n1.3.3  A Simple Classifier\nWe can use geometry to design another simple classification algorithm [SS02]\nfor our problem. For simplicity we assume that the observationsx∈R\nd\n, such\nas the bag-of-words representation of e-mails. We define the meansμ\n+\nand\nμ\n−\nto correspond to the classesy∈{±1}via\nμ\n−\n:=\n1\nm\n−\n∑\ny\ni\n=−1\nx\ni\nandμ\n+\n:=\n1\nm\n+\n∑\ny\ni\n=1\nx\ni\n.\nHere we usedm\n−\nandm\n+\nto denote the number of observations with label\ny\ni\n=−1 andy\ni\n= +1 respectively. An even simpler approach than using the\nnearest neighbor classifier would be to use the class label which corresponds\nto the mean closest to a new queryx, as described in Figure 1.20.\nFor Euclidean distances we have\n‖μ\n−\n−x‖\n2\n=‖μ\n−\n‖\n2\n+‖x‖\n2\n−2〈μ\n−\n,x〉and(1.19)\n‖μ\n+\n−x‖\n2\n=‖μ\n+\n‖\n2\n+‖x‖\n2\n−2〈μ\n+\n,x〉.(1.20)\nHere〈·,·〉denotes the standard dot product between vectors. Taking differ-\nences between the two distances yields\nf(x) :=‖μ\n+\n−x‖\n2\n−‖μ\n−\n−x‖\n2\n= 2〈μ\n−\n−μ\n+\n,x〉+‖μ\n−\n‖\n2\n−‖μ\n+\n‖\n2\n.\n(1.21)\nThis is alinearfunction inxand its sign corresponds to the labels we esti-\nmate forx. Our algorithm sports an important property: The classification\nrule can be expressed via dot products. This follows from\n‖μ\n+\n‖\n2\n=〈μ\n+\n,μ\n+\n〉=m\n−2\n+\n∑\ny\ni\n=y\nj\n=1\n〈x\ni\n,x\nj\n〉and〈μ\n+\n,x〉=m\n−1\n+\n∑\ny\ni\n=1\n〈x\ni\n,x〉.\n\n281  Introduction\nX\nφ(x)\nx\nH\nFig. 1.21.  The feature mapφmaps observationsxfromXinto a feature spaceH.\nThe mapφis a convenient way of encoding pre-processing steps systematically.\nAnalogous expressions can be computed forμ\n−\n. Consequently we may ex-\npress the classification rule (1.21) as\nf(x) =\nm\n∑\ni=1\nα\ni\n〈x\ni\n,x〉+b(1.22)\nwhereb=m\n−2\n−\n∑\ny\ni\n=y\nj\n=−1\n〈x\ni\n,x\nj\n〉−m\n−2\n+\n∑\ny\ni\n=y\nj\n=1\n〈x\ni\n,x\nj\n〉andα\ni\n=y\ni\n/m\ny\ni\n.\nThis offers a number of interesting extensions. Recall that when dealing\nwith documents we needed to perform pre-processing to map e-mails into a\nvector space. In general, we may pick arbitrary mapsφ:X→Hmapping\nthe  space  of  observations  into  afeature  spaceH,  as  long  as  the  latter  is\nendowed with a dot product (see Figure 1.21). This means that instead of\ndealing with〈x,x\n′\n〉we will be dealing with〈φ(x),φ(x\n′\n)〉.\nAs we will see in Chapter 6, wheneverHis a so-called Reproducing Kernel\nHilbert Space, the inner product can be abbreviated in the form of a kernel\nfunctionk(x,x\n′\n) which satisfies\nk(x,x\n′\n) :=\n〈\nφ(x),φ(x\n′\n)\n〉\n.(1.23)\nThis small modification leads to a number of very powerful algorithm and\nit  is  at  the  foundation  of  an  area  of  research  called  kernel  methods.  We\nwill  encounter  a  number  of  such  algorithms  for  regression,  classification,\nsegmentation, and density estimation over the course of the book. Examples\nof suitablekare the polynomial kernelk(x,x\n′\n) =〈x,x\n′\n〉\nd\nford∈Nand the\nGaussian RBF kernelk(x,x\n′\n) =e\n−γ‖x−x\n′\n‖\n2\nforγ >0.\nThe upshot of (1.23) is that our basic algorithm can bekernelized. That\nis, we may rewrite (1.21) as\nf(x) =\nm\n∑\ni=1\nα\ni\nk(x\ni\n,x) +b(1.24)\nwhere as beforeα\ni\n=y\ni\n/m\ny\ni\nand the offsetbis computed analogously. As\n\n1.3  Basic Algorithms29\nAlgorithm 1.3The Perceptron\nPerceptron(X,Y){reads stream of observations (x\ni\n,y\ni\n)}\nInitializew= 0 andb= 0\nwhileThere exists some (x\ni\n,y\ni\n) withy\ni\n(〈w,x\ni\n〉+b)≤0do\nw←w+y\ni\nx\ni\nandb←b+y\ni\nend while\nAlgorithm 1.4The Kernel Perceptron\nKernelPerceptron(X,Y){reads stream of observations (x\ni\n,y\ni\n)}\nInitializef= 0\nwhileThere exists some (x\ni\n,y\ni\n) withy\ni\nf(x\ni\n)≤0do\nf←f+y\ni\nk(x\ni\n,·) +y\ni\nend while\na consequence we have now moved from a fairly simple and pedestrian lin-\near  classifier  to  one  which  yields  a  nonlinear  functionf(x)  with  a  rather\nnontrivial decision boundary.\n1.3.4  Perceptron\nIn the previous sections we assumed that our classifier had access to a train-\ning set of spam and non-spam emails. In real life, such a set might be difficult\nto obtain all at once. Instead, a user might want to haveinstantresults when-\never a new e-mail arrives and he would like the system to learn immediately\nfrom any corrections to mistakes the system makes.\nTo overcome both these difficulties one could envisage working with the\nfollowing protocol: As emails arrive our algorithm classifies them as spam or\nnon-spam, and the user provides feedback as to whether the classification is\ncorrect or incorrect. This feedback is then used to improve the performance\nof the classifier over a period of time.\nThis  intuition  can  be  formalized  as  follows:  Our  classifier  maintains  a\nparameter vector. At thet-th time instance it receives a data pointx\nt\n, to\nwhich it assigns a label ˆy\nt\nusing its current parameter vector. The true label\ny\nt\nis then revealed, and used to update the parameter vector of the classifier.\nSuch  algorithms  are  said  to  beonline.  We  will  now  describe  perhaps  the\nsimplest classifier of this kind namely the Perceptron [Heb49, Ros58].\nLet us assume that the data pointsx\nt\n∈R\nd\n, and labelsy\nt\n∈ {±1}. As\nbefore we represent an email as a bag-of-words vector and we assign +1 to\nspam emails and−1 to non-spam emails. The Perceptron maintains a weight\n\n301  Introduction\nw*\nw\nt\nw*\nw\nt+1\nx\nt\nx\nt\nFig. 1.22.  The Perceptron without bias. Left: at timetwe have a weight vectorw\nt\ndenoted by the dashed arrow with corresponding separating plane (also dashed).\nFor  reference  we  include  the  linear  separatorw\n∗\nand  its  separating  plane  (both\ndenoted  by  a  solid  line).  As  a  new  observationx\nt\narrives  which  happens  to  be\nmis-classified by the current weight vectorw\nt\nwe perform an update. Also note the\nmargin between the pointx\nt\nand the separating hyperplane defined byw\n∗\n. Right:\nThis leads to the weight vectorw\nt+1\nwhich is more aligned withw\n∗\n.\nvectorw∈R\nd\nand classifiesx\nt\naccording to the rule\nˆy\nt\n:= sign{〈w,x\nt\n〉+b},(1.25)\nwhere〈w,x\nt\n〉denotes the usual Euclidean dot product andbis an offset. Note\nthe similarity of (1.25) to (1.21) of the simple classifier. Just as the latter,\nthe Perceptron is alinearclassifier which separates its domainR\nd\ninto two\nhalfspaces, namely{x|〈w,x〉+b >0}and its complement. If  ˆy\nt\n=y\nt\nthen\nno  updates  are  made.  On  the  other  hand,  if  ˆy\nt\n6=y\nt\nthe  weight  vector  is\nupdated as\nw←w+y\nt\nx\nt\nandb←b+y\nt\n.(1.26)\nFigure 1.22 shows an update step of the Perceptron algorithm. For simplicity\nwe illustrate the case without bias, that is, whereb= 0 and where it remains\nunchanged. A detailed description of the algorithm is given in Algorithm 1.3.\nAn important property of the algorithm is that it performs updates onw\nby multiples of the observationsx\ni\non which it makes a mistake. Hence we\nmay expresswasw=\n∑\ni∈Error\ny\ni\nx\ni\n. Just as before, we can replacex\ni\nandx\nbyφ(x\ni\n) andφ(x) to obtain a kernelized version of the Perceptron algorithm\n[FS99] (Algorithm 1.4).\nIf the dataset (X,Y) is linearly separable, then the Perceptron algorithm\n\n1.3  Basic Algorithms31\neventually converges and correctly classifies all the points inX. The rate of\nconvergence however depends on the margin. Roughly speaking, the margin\nquantifies how linearly separable a dataset is, and hence how easy it is to\nsolve a given classification problem.\nDefinition 1.6 (Margin)Letw∈R\nd\nbe a weight vector and letb∈Rbe\nan offset. The margin of an observationx∈R\nd\nwith associated labelyis\nγ(x,y) :=y(〈w,x〉+b).(1.27)\nMoreover, the margin of an entire set of observationsXwith labelsYis\nγ(X,Y) := min\ni\nγ(x\ni\n,y\ni\n).(1.28)\nGeometrically speaking (see Figure 1.22) the margin measures the distance\nofxfrom the hyperplane defined by{x|〈w,x〉+b= 0}. Larger the margin,\nthe more well separated the data and hence easier it is to find a hyperplane\nwith correctly classifies the dataset. The following theorem asserts that if\nthere exists a linear classifier which can classify a dataset with a large mar-\ngin, then the Perceptron will also correctly classify the same dataset after\nmaking a small number of mistakes.\nTheorem 1.7 (Novikoff ’s theorem)Let(X,Y)be a dataset with at least\none example labeled+1and one example labeled−1. LetR:= max\nt\n‖x\nt\n‖, and\nassume that there exists(w\n∗\n,b\n∗\n)such that‖w\n∗\n‖= 1andγ\nt\n:=y\nt\n(〈w\n∗\n,x\nt\n〉+\nb\n∗\n)≥γfor  allt.  Then,  the  Perceptron  will  make  at  most\n(1+R\n2\n)(1+(b\n∗\n)\n2\n)\nγ\n2\nmistakes.\nThis  result  is  remarkable  since  it  doesnotdepend  on  the  dimensionality\nof  the  problem.  Instead,  it  only  depends  on  thegeometryof  the  setting,\nas  quantified  via  the  marginγand  the  radiusRof  a  ball  enclosing  the\nobservations. Interestingly, a similar bound can be shown for Support Vector\nMachines [Vap95] which we will be discussing in Chapter 7.\nProofWe can safely ignore the iterations where no mistakes were made\nand hence no updates were carried out. Therefore, without loss of generality\nassume that thet-th update was made after seeing thet-th observation and\nletw\nt\ndenote the weight vector after the update. Furthermore, for simplicity\nassume that the algorithm started withw\n0\n= 0 andb\n0\n= 0. By the update\nequation (1.26) we have\n〈w\nt\n,w\n∗\n〉+b\nt\nb\n∗\n=〈w\nt−1\n,w\n∗\n〉+b\nt−1\nb\n∗\n+y\nt\n(〈x\nt\n,w\n∗\n〉+b\n∗\n)\n≥〈w\nt−1\n,w\n∗\n〉+b\nt−1\nb\n∗\n+γ.\n\n321  Introduction\nBy induction it follows that〈w\nt\n,w\n∗\n〉+b\nt\nb\n∗\n≥tγ. On the other hand we made\nan update becausey\nt\n(〈x\nt\n,w\nt−1\n〉+b\nt−1\n)<0. By usingy\nt\ny\nt\n= 1,\n‖w\nt\n‖\n2\n+b\n2\nt\n=‖w\nt−1\n‖\n2\n+b\n2\nt−1\n+y\n2\nt\n‖x\nt\n‖\n2\n+ 1 + 2y\nt\n(〈w\nt−1\n,x\nt\n〉+b\nt−1\n)\n≤‖w\nt−1\n‖\n2\n+b\n2\nt−1\n+‖x\nt\n‖\n2\n+ 1\nSince‖x\nt\n‖\n2\n=R\n2\nwe can again apply induction to conclude that‖w\nt\n‖\n2\n+b\n2\nt\n≤\nt\n[\nR\n2\n+ 1\n]\n. Combining the upper and the lower bounds, using the Cauchy-\nSchwartz inequality, and‖w\n∗\n‖= 1 yields\ntγ≤〈w\nt\n,w\n∗\n〉+b\nt\nb\n∗\n=\n〈[\nw\nt\nb\nt\n]\n,\n[\nw\n∗\nb\n∗\n]〉\n≤\n∥\n∥\n∥\n∥\n[\nw\nt\nb\nt\n]\n∥\n∥\n∥\n∥\n∥\n∥\n∥\n∥\n[\nw\n∗\nb\n∗\n]\n∥\n∥\n∥\n∥\n=\n√\n‖w\nt\n‖\n2\n+b\n2\nt\n√\n1 + (b\n∗\n)\n2\n≤\n√\nt(R\n2\n+ 1)\n√\n1 + (b\n∗\n)\n2\n.\nSquaring both sides of the inequality and rearranging the terms yields an\nupper bound on the number of updates and hence the number of mistakes.\nThe Perceptron  was the  building  block of research  on Neural Networks\n[Hay98, Bis95]. The key insight was to combine large numbers of such net-\nworks, often in a cascading fashion, to larger objects and to fashion opti-\nmization algorithms which would lead to classifiers with desirable properties.\nIn this book we will take a complementary route. Instead of increasing the\nnumber of nodes we will investigate what happens when increasing the com-\nplexity of the feature mapφand its associated kernelk. The advantage of\ndoing so is that we will reap the benefits from convex analysis and linear\nmodels, possibly at the expense of a slightly more costly function evaluation.\n1.3.5  K-Means\nAll the algorithms we discussed so far are supervised, that is, they assume\nthat labeled training data is available. In many applications this is too much\nto hope for; labeling may be expensive, error prone, or sometimes impossi-\nble. For instance, it is very easy to crawl and collect every page within the\nwww.purdue.edudomain,  but  rather  time  consuming  to  assign  a  topic  to\neach page based on its contents. In such cases, one has to resort to unsuper-\nvised learning. A prototypical unsupervised learning algorithm is K-means,\nwhich is clustering algorithm. GivenX={x\n1\n,...,x\nm\n}the goal of K-means\nis to partition it intokclusters such that each point in a cluster is similar\nto points from its own cluster than with points from some other cluster.\n\n1.3  Basic Algorithms33\nTowards  this  end,  define  prototype  vectorsμ\n1\n,...,μ\nk\nand  an  indicator\nvectorr\nij\nwhich is 1 if, and only if,x\ni\nis assigned to clusterj. To cluster our\ndataset we will minimize the following distortion measure, which minimizes\nthe distance of each point from the prototype vector:\nJ(r,μ) :=\n1\n2\nm\n∑\ni=1\nk\n∑\nj=1\nr\nij\n‖x\ni\n−μ\nj\n‖\n2\n,(1.29)\nwherer={r\nij\n},μ={μ\nj\n}, and‖·‖\n2\ndenotes the usual Euclidean square\nnorm.\nOur goal is to findrandμ, but since it is not easy to jointly minimizeJ\nwith respect to bothrandμ, we will adapt a two stage strategy:\nStage 1Keep theμfixed and determiner. In this case, it is easy to see\nthat  the  minimization  decomposes  intomindependent  problems.\nThe solution for thei-th data pointx\ni\ncan be found by setting:\nr\nij\n= 1 ifj= argmin\nj\n′\n‖x\ni\n−μ\nj\n′\n‖\n2\n,(1.30)\nand 0 otherwise.\nStage 2Keep therfixed and determineμ. Since ther’s are fixed,Jis an\nquadratic function ofμ. It can be minimized by setting the derivative\nwith respect toμ\nj\nto be 0:\nm\n∑\ni=1\nr\nij\n(x\ni\n−μ\nj\n) = 0 for allj.(1.31)\nRearranging obtains\nμ\nj\n=\n∑\ni\nr\nij\nx\ni\n∑\ni\nr\nij\n.(1.32)\nSince\n∑\ni\nr\nij\ncounts the number of points assigned to clusterj, we are\nessentially settingμ\nj\nto be the sample mean of the points assigned\nto clusterj.\nThe  algorithm  stops  when  the  cluster  assignments  do  not  change  signifi-\ncantly. Detailed pseudo-code can be found in Algorithm 1.5.\nTwo  issues  with  K-Means  are  worth  noting.  First,  it  is  sensitive  to  the\nchoice of the initial cluster centersμ. A number of practical heuristics have\nbeen developed. For instance, one could randomly choosekpoints from the\ngiven dataset as cluster centers. Other methods try to pickkpoints fromX\nwhich are farthest away from each other. Second, it makes ahardassignment\nof every point to a cluster center. Variants which we will encounter later in\n\n341  Introduction\nAlgorithm 1.5K-Means\nCluster(X){Cluster datasetX}\nInitialize cluster centersμ\nj\nforj= 1,...,krandomly\nrepeat\nfori= 1tomdo\nComputej\n′\n= argmin\nj=1,...,k\nd(x\ni\n,μ\nj\n)\nSetr\nij\n′\n= 1 andr\nij\n= 0 for allj\n′\n6=j\nend for\nforj= 1tokdo\nComputeμ\nj\n=\n∑\ni\nr\nij\nx\ni\n∑\ni\nr\nij\nend for\nuntilCluster assignmentsr\nij\nare unchanged\nreturn{μ\n1\n,...,μ\nk\n}andr\nij\nthe book will relax this. Instead of lettingr\nij\n∈ {0,1}thesesoftvariants\nwill replace it with the probability that a givenx\ni\nbelongs to clusterj.\nThe K-Means algorithm concludes our discussion of a set of basic machine\nlearning  methods  for  classification  and  regression.  They  provide  a  useful\nstarting point for an aspiring machine learning researcher. In this book we\nwill  see  many  more  such  algorithms  as  well  as  connections  between  these\nbasic algorithms and their more advanced counterparts.\nProblems\nProblem 1.1 (Eyewitness)Assume  that  an  eyewitness  is  90%  certain\nthat  a  given  person  committed  a  crime  in  a  bar.  Moreover,  assume  that\nthere were 50 people in the restaurant at the time of the crime. What is the\nposterior probability of the person actually having committed the crime.\nProblem 1.2 (DNA Test)Assume  the  police  have  a  DNA  library  of  10\nmillion  records.  Moreover,  assume  that  the  false  recognition  probability  is\nbelow0.00001% per record. Suppose a match is found after a database search\nfor an individual. What are the chances that the identification is correct? You\ncan  assume  that  the  total  population  is  100  million  people.  Hint:  compute\nthe probability of no match occurring first.\nProblem 1.3 (Bomb Threat)Suppose  that  the  probability  that  one  of  a\nthousand passengers on a plane has a bomb is1 : 1,000,000. Assuming that\nthe  probability  to  have  a  bomb  is  evenly  distributed  among  the  passengers,\n\n1.3  Basic Algorithms35\nthe  probability  that  two  passengers  have  a  bomb  is  roughly  equal  to10\n−12\n.\nTherefore, one might decide to take a bomb on a plane to decrease chances\nthat somebody else has a bomb. What is wrong with this argument?\nProblem 1.4 (Monty-Hall Problem)Assume  that  in  a  TV  show  the\ncandidate  is  given  the  choice  between  three  doors.  Behind  two  of  the  doors\nthere is a pencil and behind one there is the grand prize, a car. The candi-\ndate chooses one door.After that, the showmaster opens another door behind\nwhich there is a pencil. Should the candidate switch doors after that? What\nis the probability of winning the car?\nProblem 1.5 (Mean and Variance for Random Variables)Denote by\nX\ni\nrandom variables. Prove that in this case\nE\nX\n1\n,...X\nN\n[\n∑\ni\nx\ni\n]\n=\n∑\ni\nE\nX\ni\n[x\ni\n]andVar\nX\n1\n,...X\nN\n[\n∑\ni\nx\ni\n]\n=\n∑\ni\nVar\nX\ni\n[x\ni\n]\nTo show the second equality assume independence of theX\ni\n.\nProblem 1.6 (Two Dices)Assume you have a game which uses the max-\nimum  of  two  dices.  Compute  the  probability  of  seeing  any  of  the  events\n{1,...,6}. Hint: prove first that the cumulative distribution function of the\nmaximum of a pair of random variables is the square of the original cumu-\nlative distribution function.\nProblem 1.7 (Matching Coins)Consider the following game: two play-\ners  bring  a  coin  each.  the  first  player  bets  that  when  tossing  the  coins  both\nwill match and the second one bets that they will not match. Show that even\nif  one  of  the  players  were  to  bring  a  tainted  coin,  the  game  still  would  be\nfair. Show that it is in the interest of each player to bring a fair coin to the\ngame.  Hint:  assume  that  the  second  player  knows  that  the  first  coin  favors\nheads over tails.\nProblem 1.8 (Randomized Maximization)How many observations do\nyou need to draw from a distribution to ensure that the maximum over them\nis  larger  than  95%  of  all  observations  with  at  least  95%  probability?  Hint:\ngeneralize the result from Problem 1.6 to the maximum overnrandom vari-\nables.\nApplication: Assume we have 1000 computers performing MapReduce [DG08]\nand the Reducers have to wait until all 1000 Mappers are finished with their\njob. Compute the quantile of the typical time to completion.\n\n361  Introduction\nProblem 1.9Prove  that  the  Normal  distribution  (1.3)  has  meanμand\nvarianceσ\n2\n. Hint: exploit the fact thatpis symmetric aroundμ.\nProblem 1.10 (Cauchy Distribution)Prove that for the density\np(x) =\n1\nπ(1 +x\n2\n)\n(1.33)\nmean and variance are undefined. Hint: show that the integral diverges.\nProblem 1.11 (Quantiles)Find  a  distribution  for  which  the  mean  ex-\nceeds the median. Hint: the mean depends on the value of the high-quantile\nterms, whereas the median does not.\nProblem 1.12 (Multicategory Naive Bayes)Prove that for multicate-\ngory Naive Bayes the optimal decision is given by\ny\n∗\n(x) := argmax\ny\np(y)\nn\n∏\ni=1\np([x]\ni\n|y)(1.34)\nwherey∈Yis the class label of the observationx.\nProblem 1.13 (Bayes Optimal Decisions)Denote byy\n∗\n(x) = argmax\ny\np(y|x)\nthe label associated with the largest conditional class probability. Prove that\nfory\n∗\n(x)the probability of choosing the wrong labelyis given by\nl(x) := 1−p(y\n∗\n(x)|x).\nMoreover, show thaty\n∗\n(x)is the label incurring the smallest misclassification\nerror.\nProblem 1.14 (Nearest Neighbor Loss)Show that the expected loss in-\ncurred by the nearest neighbor classifier does not exceed twice the loss of the\nBayes optimal decision.\n\n2\nDensity Estimation\n2.1  Limit Theorems\nAssume you are a gambler and go to a casino to play a game of dice. As\nit happens, it is your unlucky day and among the 100 times you toss the\ndice, you only see ’6’ eleven times. For a fair dice we know that each face\nshould occur with equal probability\n1\n6\n. Hence the expected value over 100\ndraws is\n100\n6\n≈17, which is considerably more than the eleven times that we\nobserved. Before crying foul you decide that some mathematical analysis is\nin order.\nThe probability of seeing aparticularsequence ofmtrials out of whichn\nare a ’6’ is given by\n1\n6\nn\n5\n6\nm−n\n. Moreover, there are\n(\nm\nn\n)\n=\nm!\nn!(m−n)!\ndifferent\nsequences of ’6’ and ’not 6’ with proportionsnandm−nrespectively. Hence\nwe may compute the probability of seeing a ’6’ only 11 or less via\nPr(X≤11) =\n11\n∑\ni=0\np(i) =\n11\n∑\ni=0\n(\n100\ni\n)[\n1\n6\n]\ni\n[\n5\n6\n]\n100−i\n≈7.0%(2.1)\nAfter looking at this figure you decide that things are probably reasonable.\nAnd, in fact, they are consistent with the convergence behavior of a sim-\nulated  dice  in  Figure  2.1.  In  computing  (2.1)  we  have  learned  something\nuseful: the expansion is a special case of abinomialseries. The first term\n123456\n0.0\n0.1\n0.2\n0.3\nm=10\n123456\n0.0\n0.1\n0.2\n0.3\nm=20\n123456\n0.0\n0.1\n0.2\n0.3\nm=50\n123456\n0.0\n0.1\n0.2\n0.3\nm=100\n123456\n0.0\n0.1\n0.2\n0.3\nm=200\n123456\n0.0\n0.1\n0.2\n0.3\nm=500\nFig. 2.1.  Convergence of empirical means to expectations. From left to right: em-\npirical frequencies of occurrence obtained by casting a dice 10, 20, 50, 100, 200, and\n500 times respectively. Note that after 20 throws we still have not observed a single\n’6’, an event which occurs with only\n[\n5\n6\n]\n20\n≈2.6% probability.\n37\n\n382  Density Estimation\ncounts the number of configurations in which we could observeitimes ’6’ in a\nsequence of 100 dice throws. The second and third term are the probabilities\nof seeing one particular instance of such a sequence.\nNote  that  in  general  we  may  not  be  as  lucky,  since  we  may  have  con-\nsiderably less information about the setting we are studying. For instance,\nwe might notknowthe actual probabilities for each face of the dice, which\nwould  be  a  likely  assumption  when  gambling  at  a  casino  of  questionable\nreputation. Often the outcomes of the system we are dealing with may be\ncontinuous valued random variables rather than binary ones, possibly even\nwith  unknown  range.  For  instance,  when  trying  to  determine  the  average\nwage through a questionnaire we need to determine how many people we\nneed to ask in order to obtain a certain level of confidence.\nTo  answer  such  questions  we  need  to  discuss  limit  theorems.  They  tell\nus by how much averages over a set of observations may deviate from the\ncorresponding expectations and how many observations we need to draw to\nestimate a number of probabilities reliably. For completeness we will present\nproofs for some of the more fundamental theorems in Section 2.1.2. They\nare useful albeit non-essential for the understanding of the remainder of the\nbook and may be omitted.\n2.1.1  Fundamental Laws\nThe  Law  of  Large  Numbers  developed  by  Bernoulli  in  1713  is  one  of  the\nfundamental building blocks of statistical analysis. It states that averages\nover a number of observations converge to their expectations given a suffi-\nciently large number of observations and given certain assumptions on the\nindependence of these observations. It comes in two flavors: the weak and\nthe strong law.\nTheorem 2.1 (Weak Law of Large Numbers)Denote  byX\n1\n,...,X\nm\nrandom variables drawn fromp(x)with meanμ=E\nX\ni\n[x\ni\n]for alli. Moreover\nlet\n ̄\nX\nm\n:=\n1\nm\nm\n∑\ni=1\nX\ni\n(2.2)\nbe the empirical average over the random variablesX\ni\n. Then for any\u000f >0\nthe following holds\nlim\nm→∞\nPr\n(\n∣\n∣\n ̄\nX\nm\n−μ\n∣\n∣\n≤\u000f\n)\n= 1.(2.3)\n\n2.1  Limit Theorems39\n10\n1\n10\n2\n10\n3\n1\n2\n3\n4\n5\n6\nFig.  2.2.  The  mean  of  a  number  of  casts  of  a  dice.  The  horizontal  straight  line\ndenotes  the  mean  3.5.  The  uneven  solid  line  denotes  the  actual  mean\n ̄\nX\nn\nas  a\nfunction of the number of draws, given as a semilogarithmic plot. The crosses denote\nthe outcomes of the dice. Note how\n ̄\nX\nn\never more closely approaches the mean 3.5\nare we obtain an increasing number of observations.\nThis establishes that, indeed, for large enough sample sizes, the average will\nconverge to the expectation. The strong law strengthens this as follows:\nTheorem 2.2 (Strong Law of Large Numbers)Under  the  conditions\nof Theorem 2.1 we havePr\n(\nlim\nm→∞\n ̄\nX\nm\n=μ\n)\n= 1.\nThe strong law implies that almost surely (in a measure theoretic sense)\n ̄\nX\nm\nconverges toμ, whereas the weak law only states that for every\u000fthe random\nvariable\n ̄\nX\nm\nwill be within the interval [μ−\u000f,μ+\u000f]. Clearly the strong implies\nthe weak law since the measure of the events\n ̄\nX\nm\n=μconverges to 1, hence\nany\u000f-ball aroundμwould capture this.\nBoth laws justify that we may take sample averages, e.g. over a number\nof events such as the outcomes of a dice and use the latter to estimate their\nmeans, their probabilities (here we treat the indicator variable of the event\nas a{0; 1}-valued random variable), their variances or related quantities. We\npostpone a proof until Section 2.1.2, since an effective way of proving Theo-\nrem 2.1 relies on the theory of characteristic functions which we will discuss\nin the next section. For the moment, we only give a pictorial illustration in\nFigure 2.2.\nOnce we established that the random variable\n ̄\nX\nm\n=m\n−1\n∑\nm\ni=1\nX\ni\ncon-\nverges to its meanμ, a natural second question is to establish howquicklyit\nconverges and what the properties of the limiting distribution of\n ̄\nX\nm\n−μare.\nNote in Figure 2.2 that the initial deviation from the mean is large whereas\nas we observe more data the empirical mean approaches the true one.\n\n402  Density Estimation\n10\n1\n10\n2\n10\n3\n1\n2\n3\n4\n5\n6\nFig. 2.3.  Five instantiations of a running average over outcomes of a toss of a dice.\nNote that all of them converge to the mean 3.5. Moreover note that they all are\nwell contained within the upper and lower envelopes given byμ±\n√\nVar\nX\n[x]/m.\nThe central limit theorem answers this question exactly by addressing a\nslightly more general question, namely whether the sum over a number of\nindependent  random  variables  where  each  of  them  arises  from  adifferent\ndistribution  might  also  have  a  well  behaved  limiting  distribution.  This  is\nthe case as long as thevarianceof each of the random variables is bounded.\nThe limiting distribution of such a sum is Gaussian. This affirms the pivotal\nrole of the Gaussian distribution.\nTheorem 2.3 (Central Limit Theorem)Denote byX\ni\nindependent ran-\ndom variables with meansμ\ni\nand standard deviationσ\ni\n. Then\nZ\nm\n:=\n[\nm\n∑\ni=1\nσ\n2\ni\n]\n−\n1\n2\n[\nm\n∑\ni=1\nX\ni\n−μ\ni\n]\n(2.4)\nconverges to a Normal Distribution with zero mean and unit variance.\nNote that just like the law of large numbers the central limit theorem (CLT)\nis anasymptoticresult. That is, only in the limit of an infinite number of\nobservations will it become exact. That said, it often provides an excellent\napproximation even for finite numbers of observations, as illustrated in Fig-\nure 2.4. In fact, the central limit theorem and related limit theorems build\nthe foundation of what is known as asymptotic statistics.\nExample 2.1 (Dice)If  we  are  interested  in  computing  the  mean  of  the\nvalues returned by a dice we may apply the CLT to the sum overmvariables\n\n2.1  Limit Theorems41\nwhich have all meanμ= 3.5and variance (see Problem 2.1)\nVar\nX\n[x] =E\nX\n[x\n2\n]−E\nX\n[x]\n2\n= (1 + 4 + 9 + 16 + 25 + 36)/6−3.5\n2\n≈2.92.\nWe now study the random variableW\nm\n:=m\n−1\n∑\nm\ni=1\n[X\ni\n−3.5]. Since each\nof the terms in the sum has zero mean, alsoW\nm\n’s mean vanishes. Moreover,\nW\nm\nis  a  multiple  ofZ\nm\nof  (2.4).  Hence  we  have  thatW\nm\nconverges  to  a\nnormal distribution with zero mean and standard deviation2.92m\n−\n1\n2\n.\nConsequently  the  average  ofmtosses  of  the  dice  yields  a  random  vari-\nable with mean3.5and it will approach a normal distribution with variance\nm\n−\n1\n2\n2.92.  In  other  words,  the  empirical  mean  converges  to  its  average  at\nrateO(m\n−\n1\n2\n).  Figure  2.3  gives  an  illustration  of  the  quality  of  the  bounds\nimplied by the CLT.\nOne remarkable property of functions of random variables is that in many\nconditions convergence properties of the random variables are bestowed upon\nthe functions, too. This is manifest in the following two results: a variant\nof Slutsky’s theorem and the so-called delta method. The former deals with\nlimit behavior whereas the latter deals with an extension of the central limit\ntheorem.\nTheorem 2.4 (Slutsky’s Theorem)Denote  byX\ni\n,Y\ni\nsequences  of  ran-\ndom variables withX\ni\n→XandY\ni\n→cforc∈Rin probability. Moreover,\ndenote  byg(x,y)a  function  which  is  continuous  for  all(x,c).  In  this  case\nthe random variableg(X\ni\n,Y\ni\n)converges in probability tog(X,c).\nFor a proof see e.g. [Bil68]. Theorem 2.4 is often referred to as the continuous\nmapping  theorem  (Slutsky  only  proved  the  result  for  affine  functions).  It\nmeans that for functions of random variables it is possible to pull the limiting\nprocedureintothe function. Such a device is useful when trying to prove\nasymptotic normality and in order to obtain characterizations of the limiting\ndistribution.\nTheorem 2.5 (Delta Method)Assume  thatX\nn\n∈R\nd\nis  asymptotically\nnormal  witha\n−2\nn\n(X\nn\n−b)→N(0,Σ)fora\n2\nn\n→0.  Moreover,  assume  that\ng:R\nd\n→R\nl\nis  a  mapping  which  is  continuously  differentiable  atb.  In  this\ncase the random variableg(X\nn\n)converges\na\n−2\nn\n(g(X\nn\n)−g(b))→N(0,[∇\nx\ng(b)]Σ[∇\nx\ng(b)]\n>\n).(2.5)\nProofVia a Taylor expansion we see that\na\n−2\nn\n[g(X\nn\n)−g(b)] = [∇\nx\ng(ξ\nn\n)]\n>\na\n−2\nn\n(X\nn\n−b)(2.6)\n\n422  Density Estimation\nHereξ\nn\nlies on the line segment [b,X\nn\n]. SinceX\nn\n→bwe have thatξ\nn\n→b,\ntoo. Sincegis continuously differentiable atbwe may apply Slutsky’s the-\norem  to  see  thata\n−2\nn\n[g(X\nn\n)−g(b)]→[∇\nx\ng(b)]\n>\na\n−2\nn\n(X\nn\n−b).  As  a  con-\nsequence, the transformed random variable is asymptotically normal with\ncovariance [∇\nx\ng(b)]Σ[∇\nx\ng(b)]\n>\n.\nWe will use the delta method when it comes to investigating properties of\nmaximum likelihood estimators in exponential families. Theregwill play the\nrole of a mapping between expectations and the natural parametrization of\na distribution.\n2.1.2  The Characteristic Function\nThe Fourier transform plays a crucial role in many areas of mathematical\nanalysis and engineering. This is equally true in statistics. For historic rea-\nsons  its  applications  to  distributions  is  called  the  characteristic  function,\nwhich we will discuss in this section. At its foundations lie standard tools\nfrom functional analysis and signal processing [Rud73, Pap62]. We begin by\nrecalling the basic properties:\nDefinition 2.6 (Fourier Transform)Denote  byf:R\nn\n→Ca  function\ndefined on ad-dimensional Euclidean space. Moreover, letx,ω∈R\nn\n. Then\nthe Fourier transformFand its inverseF\n−1\nare given by\nF[f](ω) := (2π)\n−\nd\n2\n∫\nR\nn\nf(x) exp(−i〈ω,x〉)dx(2.7)\nF\n−1\n[g](x) := (2π)\n−\nd\n2\n∫\nR\nn\ng(ω) exp(i〈ω,x〉)dω.(2.8)\nThe key insight is thatF\n−1\n◦F=F◦F\n−1\n= Id. In other words,Fand\nF\n−1\nare inverses to each other for all functions which areL\n2\nintegrable on\nR\nd\n, which includes probability distributions. One of the key advantages of\nFourier transforms is that derivatives and convolutions onftranslate into\nmultiplications. That isF[f◦g] = (2π)\nd\n2\nF[f]·F[g]. The same rule applies\nto the inverse transform, i.e.F\n−1\n[f◦g] = (2π)\nd\n2\nF\n−1\n[f]F\n−1\n[g].\nThe benefit for statistical analysis is that often problems are more easily\nexpressed in the Fourier domain and it is easier to prove convergence results\nthere.  These  results  then  carry  over  to  the  original  domain.  We  will  be\nexploiting this fact in the proof of the law of large numbers and the central\nlimit theorem. Note that the definition of Fourier transforms can be extended\nto more general domains such as groups. See e.g. [BCR84] for further details.\n\n2.1  Limit Theorems43\nWe next introduce the notion of acharacteristic functionof a distribution.\n1\nDefinition 2.7 (Characteristic Function)Denote byp(x)a distribution\nof a random variableX∈R\nd\n. Then the characteristic functionφ\nX\n(ω)with\nω∈R\nd\nis given by\nφ\nX\n(ω) := (2π)\nd\n2\nF\n−1\n[p(x)] =\n∫\nexp(i〈ω,x〉)dp(x).(2.9)\nIn other words,φ\nX\n(ω) is theinverse Fourier transformapplied to the prob-\nability measurep(x). Consequentlyφ\nX\n(ω)uniquelycharacterizesp(x) and\nmoreover,p(x) can be recovered fromφ\nX\n(ω) via the forward Fourier trans-\nform. One of the key utilities of characteristic functions is that they allow\nus to deal in easy ways withsumsof random variables.\nTheorem 2.8 (Sums of random variables and convolutions)Denote\nbyX,Y∈Rtwo  independent  random variables.  Moreover,  denote byZ:=\nX+Ythe sum of both random variables. Then the distribution overZsat-\nisfiesp(z) =p(x)◦p(y). Moreover, the characteristic function yields:\nφ\nZ\n(ω) =φ\nX\n(ω)φ\nY\n(ω).(2.10)\nProofZis  given  byZ=X+Y.  Hence,  for  a  givenZ=zwe  have\nthe freedom to chooseX=xfreely provided thatY=z−x. In terms of\ndistributions this means that the joint distributionp(z,x) is given by\np(z,x) =p(Y=z−x)p(x)\nand hencep(z) =\n∫\np(Y=z−x)dp(x) = [p(x)◦p(y)](z).\nThe  result  for  characteristic  functions  follows  form  the  property  of  the\nFourier transform.\nFor sums of several random variables the characteristic function is the prod-\nuct of the individual characteristic functions. This allows us to prove both\nthe weak law of large numbers and the central limit theorem (see Figure 2.4\nfor an illustration) by proving convergence in the Fourier domain.\nProof [Weak Law of Large Numbers]At the heart of our analysis lies\na Taylor expansion of the exponential into\nexp(iwx) = 1 +i〈w,x〉+o(|w|)\nand henceφ\nX\n(ω) = 1 +iwE\nX\n[x] +o(|w|).\n1\nIn Chapter??we will discuss more general descriptions of distributions of whichφ\nX\nis a special\ncase. In particular, we will replace the exponential exp(i〈ω,x〉) by a kernel functionk(x,x\n′\n).\n\n442  Density Estimation\n-505\n0.0\n0.5\n1.0\n-505\n0.0\n0.5\n1.0\n-505\n0.0\n0.5\n1.0\n-505\n0.0\n0.5\n1.0\n-505\n0.0\n0.5\n1.0\n-101\n0.0\n0.5\n1.0\n1.5\n-101\n0.0\n0.5\n1.0\n1.5\n-101\n0.0\n0.5\n1.0\n1.5\n-101\n0.0\n0.5\n1.0\n1.5\n-101\n0.0\n0.5\n1.0\n1.5\nFig.  2.4.  A  working  example  of  the  central  limit  theorem.  The  top  row  contains\ndistributions  of  sums  of  uniformly  distributed  random  variables  on  the  interval\n[0.5,0.5]. From left to right we have sums of 1,2,4,8 and 16 random variables. The\nbottom row contains the same distribution with the means rescaled by\n√\nm, where\nmis the number of observations. Note how the distribution converges increasingly\nto the normal distribution.\nGivenmrandom variablesX\ni\nwith meanE\nX\n[x] =μthis means that their\naverage\n ̄\nX\nm\n:=\n1\nm\n∑\nm\ni=1\nX\ni\nhas the characteristic function\nφ\n ̄\nX\nm\n(ω) =\n(\n1 +\ni\nm\nwμ+o(m\n−1\n|w|)\n)\nm\n(2.11)\nIn the limit ofm→ ∞this converges to exp(iwμ), the characteristic func-\ntion of the constant distribution with meanμ. This proves the claim that in\nthe large sample limit\n ̄\nX\nm\nis essentially constant with meanμ.\nProof [Central Limit Theorem]We use the same idea as above to prove\nthe CLT. The main difference, though, is that we need to assume that the\nsecond moments of the random variablesX\ni\nexist. To avoid clutter we only\nprove the case of constant meanE\nX\ni\n[x\ni\n] =μand variance Var\nX\ni\n[x\ni\n] =σ\n2\n.\n\n2.1  Limit Theorems45\nLetZ\nm\n:=\n1\n√\nmσ\n2\n∑\nm\ni=1\n(X\ni\n−μ). Our proof relies on showing convergence\nof  the  characteristic  function  ofZ\nm\n,  i.e.φ\nZ\nm\nto  that  of  a  normally  dis-\ntributed random variableWwith zero mean and unit variance. Expanding\nthe exponential to second order yields:\nexp(iwx) = 1 +iwx−\n1\n2\nw\n2\nx\n2\n+o(|w|\n2\n)\nand henceφ\nX\n(ω) = 1 +iwE\nX\n[x]−\n1\n2\nw\n2\nVar\nX\n[x] +o(|w|\n2\n)\nSince the mean ofZ\nm\nvanishes by centering (X\ni\n−μ) and the variance per\nvariable ism\n−1\nwe may write the characteristic function ofZ\nm\nvia\nφ\nZ\nm\n(ω) =\n(\n1−\n1\n2m\nw\n2\n+o(m\n−1\n|w|\n2\n)\n)\nm\nAs before, taking limitsm→ ∞yields the exponential function. We have\nthat lim\nm→∞\nφ\nZ\nm\n(ω) = exp(−\n1\n2\nω\n2\n) which is the characteristic function of\nthe normal distribution with zero mean and variance 1. Since the character-\nistic function transform is injective this proves our claim.\nNote that the characteristic function has a number of useful properties. For\ninstance, it can also be used as moment generating function via the identity:\n∇\nn\nω\nφ\nX\n(0) =i\n−n\nE\nX\n[x\nn\n].(2.12)\nIts proof is left as an exercise. See Problem 2.2 for details. This connection\nalso implies (subject to regularity conditions) that if we know the moments\nof  a  distribution  we  are  able  to  reconstruct  it  directly  since  it  allows  us\nto  reconstruct  its  characteristic  function.  This  idea  has  been  exploited  in\ndensity  estimation  [Cra46]  in  the  form  of  Edgeworth  and  Gram-Charlier\nexpansions [Hal92].\n2.1.3  Tail Bounds\nIn practice we never have access to aninfinitenumber of observations. Hence\nthe central limit theorem does not apply but is just an approximation to the\nreal situation. For instance, in the case of the dice, we might want to state\nworst case boundsforfinitesums of random variables to determine by how\nmuch the empirical mean may deviate from its expectation. Those bounds\nwill not only be useful for simple averages but to quantify the behavior of\nmore sophisticated estimators based on a set of observations.\nThe  bounds  we  discuss  below  differ  in  the  amount  of  knowledge  they\nassume about the random variables in question. For instance, we might only\n\n462  Density Estimation\nknow  their  mean.  This  leads  to  the  Gauss-Markov  inequality.  If  we  know\ntheir  mean  and  their  variance  we  are  able  to  state  a  stronger  bound,  the\nChebyshev  inequality.  For  an  even  stronger  setting,  when  we  know  that\neach variable has bounded range, we will be able to state a Chernoff bound.\nThose bounds are progressively more tight and also more difficult to prove.\nWe state them in order of technical sophistication.\nTheorem 2.9 (Gauss-Markov)Denote byX≥0a random variable and\nletμbe its mean. Then for any\u000f >0we have\nPr(X≥\u000f)≤\nμ\n\u000f\n.(2.13)\nProofWe use the fact that for nonnegative random variables\nPr(X≥\u000f) =\n∫\n∞\n\u000f\ndp(x)≤\n∫\n∞\n\u000f\nx\n\u000f\ndp(x)≤\u000f\n−1\n∫\n∞\n0\nxdp(x) =\nμ\n\u000f\n.\nThis means that for random variables with a small mean, the proportion of\nsamples with large value has to be small.\nConsequently deviations from the mean areO(\u000f\n−1\n). However, note that this\nbound doesnotdepend on the number of observations. A useful application\nof the Gauss-Markov inequality is Chebyshev’s inequality. It is a statement\non the range of random variables using its variance.\nTheorem 2.10 (Chebyshev)Denote byXa random variable with mean\nμand varianceσ\n2\n. Then the following holds for\u000f >0:\nPr(|x−μ|≥\u000f)≤\nσ\n2\n\u000f\n2\n.(2.14)\nProofDenote  byY:=|X−μ|\n2\nthe  random  variable  quantifying  the\ndeviation ofXfrom its meanμ. By construction we know thatE\nY\n[y] =σ\n2\n.\nNext letγ:=\u000f\n2\n. Applying Theorem 2.9 toYandγyields Pr(Y > γ)≤σ\n2\n/γ\nwhich proves the claim.\nNote the improvement to the Gauss-Markov inequality. Where before we had\nbounds whose confidence improved withO(\u000f\n−1\n) we can now stateO(\u000f\n−2\n)\nbounds for deviations from the mean.\nExample 2.2 (Chebyshev bound)Assume that\n ̄\nX\nm\n:=m\n−1\n∑\nm\ni=1\nX\ni\nis\nthe  average overmrandom  variables with  meanμand  varianceσ\n2\n.  Hence\n ̄\nX\nm\nalso has meanμ. Its variance is given by\nVar\n ̄\nX\nm\n[ ̄x\nm\n] =\nm\n∑\ni=1\nm\n−2\nVar\nX\ni\n[x\ni\n] =m\n−1\nσ\n2\n.\n\n2.1  Limit Theorems47\nApplying  Chebyshev’s  inequality  yields  that  the  probability  of  a  deviation\nof\u000ffrom  the  meanμis  bounded  by\nσ\n2\nm\u000f\n2\n.  For  fixed  failure  probabilityδ=\nPr(|\n ̄\nX\nm\n−μ|> \u000f)we have\nδ≤σ\n2\nm\n−1\n\u000f\n−2\nand equivalently\u000f≤σ/\n√\nmδ.\nThis  bound  is  quite  reasonable  for  largeδbut  it  means  that  for  high  levels\nof confidence we need a huge number of observations.\nMuch  stronger  results  can  be  obtained  if  we  are  able  to  bound  therange\nof the random variables. Using the latter, we reap an exponential improve-\nment in the quality of the bounds in the form of the McDiarmid [McD89]\ninequality. We state the latter without proof:\nTheorem 2.11 (McDiarmid)Denote  byf:X\nm\n→Ra  function  onX\nand letX\ni\nbe independent random variables. In this case the following holds:\nPr (|f(x\n1\n,...,x\nm\n)−E\nX\n1\n,...,X\nm\n[f(x\n1\n,...,x\nm\n)]|> \u000f)≤2 exp\n(\n−2\u000f\n2\nC\n−2\n)\n.\nHere the constantC\n2\nis given byC\n2\n=\n∑\nm\ni=1\nc\n2\ni\nwhere\n∣\n∣\nf(x\n1\n,...,x\ni\n,...,x\nm\n)−f(x\n1\n,...,x\n′\ni\n,...,x\nm\n)\n∣\n∣\n≤c\ni\nfor allx\n1\n,...,x\nm\n,x\n′\ni\nand for alli.\nThis  bound  can  be  used  for  averages  of  a  number  of  observations  when\nthey are computed according to some algorithm as long as the latter can be\nencoded inf. In particular, we have the following bound [Hoe63]:\nTheorem 2.12 (Hoeffding)Denote byX\ni\niid random variables with bounded\nrangeX\ni\n∈[a,b]and  meanμ.  Let\n ̄\nX\nm\n:=m\n−1\n∑\nm\ni=1\nX\ni\nbe  their  average.\nThen the following bound holds:\nPr\n(\n∣\n∣\n ̄\nX\nm\n−μ\n∣\n∣\n> \u000f\n)\n≤2 exp\n(\n−\n2m\u000f\n2\n(b−a)\n2\n)\n.(2.15)\nProofThis is a corollary of Theorem 2.11. In\n ̄\nX\nm\neach individual random\nvariable has range [a/m,b/m] and we setf(X\n1\n,...,X\nm\n) :=\n ̄\nX\nm\n. Straight-\nforward  algebra  shows  thatC\n2\n=m\n−2\n(b−a)\n2\n.  Plugging  this  back  into\nMcDiarmid’s theorem proves the claim.\nNote  that  (2.15)  isexponentiallybetter  than  the  previous  bounds.  With\nincreasing sample size the confidence level also increases exponentially.\nExample 2.3 (Hoeffding bound)As in example 2.2 assume thatX\ni\nare\niid  random  variables  and  let\n ̄\nX\nm\nbe  their  average.  Moreover,  assume  that\n\n482  Density Estimation\nX\ni\n∈[a,b]for alli. As before we want to obtain guarantees on the probability\nthat|\n ̄\nX\nm\n−μ|> \u000f. For a given level of confidence1−δwe need to solve\nδ≤2 exp\n(\n−\n2m\u000f\n2\n(b−a)\n2\n)\n(2.16)\nfor\u000f. Straightforward algebra shows that in this case\u000fneeds to satisfy\n\u000f≥|b−a|\n√\n[log 2−logδ]/2m(2.17)\nIn other words, while the confidence level only enters logarithmically into the\ninequality, the sample sizemimproves our confidence only with\u000f=O(m\n−\n1\n2\n).\nThat is, in order to improve our confidence interval from\u000f= 0.1to\u000f= 0.01\nwe need 100 times as many observations.\nWhile this bound is tight (see Problem 2.5 for details), it is possible to ob-\ntain better bounds if we knowadditionalinformation. In particular knowing\na bound on thevarianceof a random variable in addition to knowing that it\nhas bounded range would allow us to strengthen the statement considerably.\nThe Bernstein inequality captures this connection. For details see [BBL05]\nor works on empirical process theory [vdVW96, SW86, Vap82].\n2.1.4  An Example\nIt is probably easiest to illustrate the various bounds using a concrete exam-\nple. In a semiconductor fab processors are produced on a wafer. A typical\n300mm  wafer  holds  about  400  chips.  A  large  number  of  processing  steps\nare required to produce a finished microprocessor and often it is impossible\nto assess the effect of a design decision until the finished product has been\nproduced.\nAssume  that  the  production  manager  wants  to  change  some  step  from\nprocess ’A’ to some other process ’B’. The goal is to increase the yield of\nthe process, that is, the number of chips of the 400 potential chips on the\nwafer which can be sold. Unfortunately this number is a random variable,\ni.e. the number of working chips per wafer can vary widely between different\nwafers.  Since  process  ’A’  has  been  running  in  the  factory  for  a  very  long\ntime we may assume that the yield is well known, say it isμ\nA\n= 350 out\nof  400  processors  on  average.  It  is  our  goal  to  determine  whether  process\n’B’ is better and what its yield may be. Obviously, since production runs\nare expensive we want to be able to determine this number as quickly as\npossible, i.e. using as few wafers as possible. The production manager is risk\naverse and wants to ensure that the new process is really better. Hence he\nrequires a confidence level of 95% before he will change the production.\n\n2.1  Limit Theorems49\nA first step is to formalize the problem. Since we know process ’A’ exactly\nwe only need to concern ourselves with ’B’. We associate the random variable\nX\ni\nwith waferi. A reasonable (and somewhat simplifying) assumption is to\nposit that allX\ni\nare independent and identically distributed where allX\ni\nhave the meanμ\nB\n. Obviously we do not knowμ\nB\n— otherwise there would\nbe no reason for testing! We denote by\n ̄\nX\nm\nthe average of the yields ofm\nwafers  using  process  ’B’.  What  we  are  interested  in  is  the  accuracy\u000ffor\nwhich the probability\nδ= Pr(|\n ̄\nX\nm\n−μ\nB\n|> \u000f) satisfiesδ≤0.05.\nLet  us  now  discuss  how  the  various  bounds  behave.  For  the  sake  of  the\nargument  assume  thatμ\nB\n−μ\nA\n=  20,  i.e.  the  new  process  produces  on\naverage 20 additional usable chips.\nChebyshevIn order to apply the Chebyshev inequality we need to bound\nthe variance of the random variablesX\ni\n. The worst possible variance would\noccur ifX\ni\n∈ {0; 400}where both events occur with equal probability. In\nother words, with equal probability the wafer if fully usable or it is entirely\nbroken. This amounts toσ\n2\n= 0.5(200−0)\n2\n+ 0.5(200−400)\n2\n= 40,000.\nSince for Chebyshev bounds we have\nδ≤σ\n2\nm\n−1\n\u000f\n−2\n(2.18)\nwe can solve form=σ\n2\n/δ\u000f\n2\n= 40,000/(0.05·400) = 20,000. In other words,\nwe would typically need 20,000 wafers to assess with reasonable confidence\nwhether process ’B’ is better than process ’A’. This is completely unrealistic.\nSlightly  better  bounds  can  be  obtained  if  we  are  able  to  make  better\nassumptions on the variance. For instance, if we can be sure that the yield\nof process ’B’ is at least 300, then the largest possible variance is 0.25(300−\n0)\n2\n+ 0.75(300−400)\n2\n=  30,000,  leading  to  a  minimum  of  15,000  wafers\nwhich is not much better.\nHoeffdingSince the yields are in the interval{0,...,400}we have an ex-\nplicit bound on the range of observations. Recall the inequality (2.16) which\nbounds the failure probablyδ= 0.05 by an exponential term. Solving this\nformyields\nm≥0.5|b−a|\n2\n\u000f\n−2\nlog(2/δ)≈737.8(2.19)\nIn other words, we need at lest 738 wafers to determine whether process ’B’\nis  better.  While  this  is  a  significant  improvement  of  almost  two  orders  of\nmagnitude, it still seems wasteful and we would like to do better.\n\n502  Density Estimation\nCentral Limit TheoremThe central limit theorem is anapproximation.\nThis  means  that  our  reasoning  is  not  accurate  any  more.  That  said,  for\nlarge enough sample sizes, the approximation is good enough to use it for\npractical predictions. Assume for the moment that we knew the varianceσ\n2\nexactly. In this case we know that\n ̄\nX\nm\nis approximately normal with mean\nμ\nB\nand variancem\n−1\nσ\n2\n. We are interested in the interval [μ−\u000f,μ+\u000f] which\ncontains 95% of the probability mass of a normal distribution. That is, we\nneed to solve the integral\n1\n2πσ\n2\n∫\nμ+\u000f\nμ−\u000f\nexp\n(\n−\n(x−μ)\n2\n2σ\n2\n)\ndx= 0.95(2.20)\nThis can be solved efficiently using the cumulative distribution function of\na  normal  distribution  (see  Problem  2.3  for  more  details).  One  can  check\nthat (2.20) is solved for\u000f= 2.96σ. In other words, an interval of±2.96σ\ncontains 95% of the probability mass of a normal distribution. The number\nof observations is therefore determined by\n\u000f= 2.96σ/\n√\nmand hencem= 8.76\nσ\n2\n\u000f\n2\n(2.21)\nAgain, our problem is that we donotknow the variance of the distribution.\nUsing the worst-case bound on the variance, i.e.σ\n2\n= 40,000 would lead to\na requirement of at leastm= 876 wafers for testing. However, while we do\nnotknowthe variance, we may estimate it along with the mean and use the\nempirical estimate, possibly plus some small constant to ensure we do not\nunderestimate the variance, instead of the upper bound.\nAssuming that fluctuations turn out to be in the order of 50 processors,\ni.e.σ\n2\n= 2500, we are able to reduce our requirement to approximately 55\nwafers. This is probably an acceptable number for a practical test.\nRates and ConstantsThe astute reader will have noticed that all three\nconfidence bounds had scaling behaviorm=O(\u000f\n−2\n). That is, in all cases\nthe number of observations was a fairly ill behaved function of the amount\nof confidence required. If we were just interested in convergence per se, a\nstatement  like  that  of  the  Chebyshev  inequality would have  been entirely\nsufficient.  The  various  laws  and  bounds  can  often  be  used  to  obtain  con-\nsiderably  betterconstantsfor  statistical  confidence  guarantees.  For  more\ncomplex  estimators,  such  as  methods  to  classify,  rank,  or  annotate  data,\na  reasoning  such  as  the  one  above  can  become  highly  nontrivial.  See  e.g.\n[MYA94, Vap98] for further details.\n\n2.2  Parzen Windows51\n2.2  Parzen Windows\n2.2.1  Discrete Density Estimation\nThe  convergence  theorems  discussed  so  far  mean  that  we  can  use  empir-\nical observations for the purpose of density estimation. Recall the case of\nthe Naive Bayes classifier of Section 1.3.1. One of the key ingredients was\nthe  ability  to  use  information  about  word  counts  for  different  document\nclasses to estimate the probabilityp(w\nj\n|y), wherew\nj\ndenoted the number\nof occurrences of wordjin documentx, given that it was labeledy. In the\nfollowing we discuss an extremely simple and crude method for estimating\nprobabilities. It relies on the fact that for random variablesX\ni\ndrawn from\ndistributionp(x) with discrete valuesX\ni\n∈Xwe have\nlim\nm→∞\nˆp\nX\n(x) =p(x)(2.22)\nwhere  ˆp\nX\n(x) :=m\n−1\nm\n∑\ni=1\n{x\ni\n=x}for allx∈X.(2.23)\nLet us discuss a concrete case. We assume that we have 12 documents and\nwould like to estimate the probability of occurrence of the word ’dog’ from\nit. As raw data we have:\nDocument ID1    2    3    4    5    6    7    8    9    10    11    12\nOccurrences of ‘dog’    1    0    2    0    4    6    3    0    6    201\nThis means that the word ‘dog’ occurs the following number of times:\nOccurrences of ‘dog’0    1    2    3    4    5    6\nNumber of documents    4    2    2    1    1    0    2\nSomething  unusual  is happening  here:  for some reason we never observed\n5  instances  of  the  word  dog  in  our  documents,  only  4  and  less,  or  alter-\nnatively 6 times. So what about 5 times? It is reasonable to assume that\nthe corresponding value should not be 0 either. Maybe we did not sample\nenough. One possible strategy is to add pseudo-counts to the observations.\nThis amounts to the following estimate:\nˆp\nX\n(x) := (m+|X|)\n−1\n[\n1 +\nm\n∑\ni=1\n{x\ni\n=x}=p(x)\n]\n(2.24)\nClearly the limit form→ ∞is stillp(x). Hence, asymptotically we do not\nlose  anything.  This  prescription  is  what  we  used  in  Algorithm  1.1  used  a\nmethod called Laplace smoothing. Below we contrast the two methods:\n\n522  Density Estimation\nOccurrences of ‘dog’0123456\nNumber of documents4221102\nFrequency of occurrence    0.33    0.17    0.17    0.083    0.083    00.17\nLaplace smoothing0.26    0.16    0.16    0.110.110.05    0.16\nThe problem with this method is that as|X|increases we need increasingly\nmore observations to obtain even a modicum of precision. On average, we\nwill need at least one observation for everyx∈X. This can be infeasible for\nlarge domains as the following example shows.\nExample 2.4 (Curse of Dimensionality)Assume thatX={0,1}\nd\n, i.e.\nxconsists of binary bit vectors of dimensionalityd. Asdincreases the size of\nXincreases  exponentially,  requiring  an  exponential  number  of  observations\nto perform density estimation. For instance, if we work with images, a 100×\n100 black and white picture would require in the order of10\n3010\nobservations\nto model such fairly low-resolution images accurately. This is clearly utterly\ninfeasible  —  the  number  of  particles  in  the  known  universe  is  in  the  order\nof10\n80\n.  Bellman  [Bel61]  was  one  of  the  first  to  formalize  this  dilemma  by\ncoining the term ’curse of dimensionality’.\nThis  example  clearly  shows  that  we  need  better  tools  to  deal  with  high-\ndimensional data. We will present one of such tools in the next section.\n2.2.2  Smoothing Kernel\nWe  now  proceed  to  proper  density  estimation.  Assume  that  we  want  to\nestimate  the  distribution  of  weights  of  a  population.  Sample  data  from  a\npopulation might look as follows:X={57, 88, 54, 84, 83, 59, 56, 43, 70, 63,\n90, 98, 102, 97, 106, 99, 103, 112}. We could use this to perform a density\nestimate by placing discrete components at the locationsx\ni\n∈Xwith weight\n1/|X|as what is done in Figure 2.5. There is no reason to believe that weights\nare quantized in kilograms, or grams, or miligrams (or pounds and stones).\nAnd even if it were, we would expect that similar weights would have similar\ndensities associated with it. Indeed, as the right diagram of Figure 2.5 shows,\nthe corresponding density is continuous.\nThe  key  question  arising  is  how  we  may  transformXinto  a  realistic\nestimate  of  the  densityp(x).  Starting  with  a  ’density  estimate’  with  only\ndiscrete terms\nˆp(x) =\n1\nm\nm\n∑\ni=1\nδ(x−x\ni\n)(2.25)\n\n2.2  Parzen Windows53\nwe may choose to smooth it out by a smoothing kernelh(x) such that the\nprobability mass becomes somewhat more spread out. For a density estimate\nonX⊆R\nd\nthis is achieved by\nˆp(x) =\n1\nm\nm\n∑\ni=1\nr\n−d\nh\n(\nx−x\ni\nr\n)\n.(2.26)\nThis expansion is commonly known as theParzen windowsestimate. Note\nthat  obviouslyhmust  be  chosen  such  thath(x)≥0  for  allx∈Xand\nmoreover that\n∫\nh(x)dx= 1 in order to ensure that (2.26) is a proper prob-\nability  distribution.  We  now  formally  justify  this  smoothing.  LetRbe  a\nsmall region such that\nq=\n∫\nR\np(x)dx.\nOut of themsamples drawn fromp(x), the probability thatkof them fall\nin regionRis given by the binomial distribution\n(\nm\nk\n)\nq\nk\n(1−q)\nm−k\n.\nThe expected fraction of points falling inside the region can easily be com-\nputed  from  the  expected  value  of  the  Binomial  distribution:E[k/m]  =q.\nSimilarly,  the  variance  can  be  computed  as  Var[k/m]  =q(1−q)/m.  As\nm→ ∞the variance goes to 0 and hence the estimate peaks around the\nexpectation. We can therefore set\nk≈mq.\nIf we assume thatRis so small thatp(x) is constant overR, then\nq≈p(x)·V,\nwhereVis the volume ofR. Rearranging we obtain\np(x)≈\nk\nmV\n.(2.27)\nLet us now setRto be a cube with side lengthr, and define a function\nh(u) =\n{\n1 if|u\ni\n|≤\n1\n2\n0 otherwise.\nObserve thath\n(\nx−x\ni\nr\n)\nis 1 if and only ifx\ni\nlies inside a cube of sizercentered\n\n542  Density Estimation\naroundx. If we let\nk=\nm\n∑\ni=1\nh\n(\nx−x\ni\nr\n)\n,\nthen one can use (2.27) to estimatepvia\nˆp(x) =\n1\nm\nm\n∑\ni=1\nr\n−d\nh\n(\nx−x\ni\nr\n)\n,\nwherer\nd\nis the volume of the hypercube of sizerinddimensions. By symme-\ntry, we can interpret this equation as the sum overmcubes centered around\nmdata pointsx\nn\n. If we replace the cube by any smooth kernel functionh(·)\nthis recovers (2.26).\nThere exists a large variety of different kernels which can be used for the\nkernel density estimate. [Sil86] has a detailed description of the properties\nof a number of kernels. Popular choices are\nh(x) = (2π)\n−\n1\n2\ne\n−\n1\n2\nx\n2\nGaussian kernel(2.28)\nh(x) =\n1\n2\ne\n−|x|\nLaplace kernel(2.29)\nh(x) =\n3\n4\nmax(0,1−x\n2\n)Epanechnikov kernel(2.30)\nh(x) =\n1\n2\nχ\n[−1,1]\n(x)Uniform kernel(2.31)\nh(x) = max(0,1−|x|)Triangle kernel.(2.32)\nFurther kernels are the triweight and the quartic kernel which are basically\npowers of the Epanechnikov kernel. For practical purposes the Gaussian ker-\nnel (2.28) or the Epanechnikov kernel (2.30) are most suitable. In particular,\nthe latter has the attractive property of compact support. This means that\nfor any given density estimate at locationxwe will only need to evaluate\ntermsh(x\ni\n−x) for which the distance‖x\ni\n−x‖is less thanr. Such expan-\nsions are computationally much cheaper, in particular when we make use of\nfast nearest neighbor search algorithms [GIM99, IM98]. Figure 2.7 has some\nexamples of kernels.\n2.2.3  Parameter Estimation\nSo far we have not discussed the issue of parameter selection. It should be\nevident from Figure 2.6, though, that it is quite crucial to choose a good\nkernel width. Clearly, a kernel that is overly wide will oversmooth any fine\ndetail that there might be in the density. On the other hand, a very narrow\nkernel will not be very useful, since it will be able to make statements only\nabout the locations where we actually observed data.\n\n2.2  Parzen Windows55\n405060708090100110\n0.00\n0.05\n0.10\n405060708090100110\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\nFig. 2.5.  Left: a naive density estimate given a sample of the weight of 18 persons.\nRight: the underlying weight distribution.\n406080100\n0.000\n0.025\n0.050\n406080100\n0.000\n0.025\n0.050\n406080100\n0.000\n0.025\n0.050\n406080100\n0.000\n0.025\n0.050\nFig. 2.6.  Parzen windows density estimate associated with the 18 observations of\nthe Figure above. From left to right: Gaussian kernel density estimate with kernel\nof width 0.3,1,3, and 10 respectively.\n-2-1012\n0.0\n0.5\n1.0\n-2-1012\n0.0\n0.5\n1.0\n-2-1012\n0.0\n0.5\n1.0\n-2-1012\n0.0\n0.5\n1.0\nFig. 2.7.  Some kernels for Parzen windows density estimation. From left to right:\nGaussian kernel, Laplace kernel, Epanechikov kernel, and uniform density.\nMoreover, there is the issue of choosing a suitable kernel function. The\nfact that a large variety of them exists might suggest that this is a crucial\nissue. In practice, this turns out not to be the case and instead, the choice\nof a suitable kernel width is much more vital for good estimates. In other\nwords, size matters, shape is secondary.\nThe problem is that we do not know which kernel width is best for the\ndata. If the problem is one-dimensional, we might hope to be able to eyeball\nthe size ofr. Obviously, in higher dimensions this approach fails. A second\n\n562  Density Estimation\noption  would  be  to  choosersuch  that  the  log-likelihood  of  the  data  is\nmaximized. It is given by\nlog\nm\n∏\ni=1\np(x\ni\n) =−mlogm+\nm\n∑\ni=1\nlog\nm\n∑\nj=1\nr\n−d\nh\n(\nx\ni\n−x\nj\nr\n)\n(2.33)\nRemark 2.13 (Log-likelihood)We  consider  the  logarithm  of  the  likeli-\nhood for reasons of computational stability to prevent numerical underflow.\nWhile each termp(x\ni\n)might be within a suitable range, say10\n−2\n, the prod-\nuct  of1000of  such  terms  will  easily  exceed  the  exponent  of  floating  point\nrepresentations  on  a  computer.  Summing  over  the  logarithm,  on  the  other\nhand, is perfectly feasible even for large numbers of observations.\nUnfortunately computing the log-likelihood is equally infeasible: for decreas-\ningrthe only surviving terms in (2.33) are the functionsh((x\ni\n−x\ni\n)/r) =\nh(0),  since  the  arguments  of  all  other  kernel  functions  diverge.  In  other\nwords, the log-likelihood is maximized whenp(x) is peaked exactly at the\nlocations where we observed the data. The graph on the left of Figure 2.6\nshows what happens in such a situation.\nWhat we just experienced is a case ofoverfittingwhere our model is too\nflexible.  This  led  to  a  situation  where  our  model  was  able  to  explain  the\nobserved data “unreasonably well”, simply because we were able to adjust\nour parameters given the data. We will encounter this situation throughout\nthe book. There exist a number of ways to address this problem.\nValidation Set:We  could  use  a  subset  of  our  set  of  observations  as  an\nestimateof the log-likelihood. That is, we could partition the obser-\nvations  intoX:={x\n1\n,...,x\nn\n}andX\n′\n:={x\nn+1\n,...,x\nm\n}and use\nthe second part for a likelihood score according to (2.33). The second\nset is typically called avalidation set.\nn-fold Cross-validation:Taking  this  idea  further,  note  that  there  is  no\nparticular reason why any givenx\ni\nshould belong toXorX\n′\nrespec-\ntively.  In  fact,  we  could  use  all  splits  of  the  observations  into  sets\nXandX\n′\nto infer the quality of our estimate. While this is compu-\ntationally infeasible, we could decide to split the observations into\nnequally sized subsets, sayX\n1\n,...,X\nn\nand use each of them as a\nvalidation set at a time while the remainder is used to generate a\ndensity estimate.\nTypicallynis  chosen  to  be  10,  in  which  case  this  procedure  is\n\n2.2  Parzen Windows57\nreferred  to  as10-fold  cross-validation.  It  is  a  computationally  at-\ntractive  procedure  insofar  as  it  does  not  require  us  to  change  the\nbasic estimation algorithm. Nonetheless, computation can be costly.\nLeave-one-out Estimator:At the extreme end of cross-validation we could\nchoosen=m. That is, we only remove a single observation at a time\nand use the remainder of the data for the estimate. Using the average\nover the likelihood scores provides us with an even more fine-grained\nestimate.  Denote  byp\ni\n(x)  the  density  estimate  obtained  by  using\nX:={x\n1\n,...,x\nm\n}withoutx\ni\n. For a Parzen windows estimate this\nis given by\np\ni\n(x\ni\n) = (m−1)\n−1\n∑\nj6=i\nr\n−d\nh\n(\nx\ni\n−x\nj\nr\n)\n=\nm\nm−1\n[\np(x\ni\n)−r\n−d\nh(0)\n]\n.\n(2.34)\nNote  that  this  is  precisely  the  termr\n−d\nh(0)  that  is  removed  from\nthe  estimate.  It  is  this  term  which  led  to  divergent  estimates  for\nr→0.  This  means  that  the  leave-one-out  log-likelihood  estimate\ncan be computed easily via\nL(X) =mlog\nm\nm−1\n+\nm\n∑\ni=1\nlog\n[\np(x\ni\n)−r\n−d\nh(0)\n]\n.(2.35)\nWe then choosersuch thatL(X) is maximized. This strategy is very\nrobust  and  whenever  it  can  be  implemented  in  a  computationally\nefficient manner, it is very reliable in performing model selection.\nAn alternative, probably more of theoretical interest, is to choose the scaler\na prioribased on the amount of data we have at our disposition. Intuitively,\nwe need a scheme which ensures thatr→0 as the number of observations\nincreasesm→ ∞.  However,  we  need  to  ensure  that  this  happens  slowly\nenough that the number of observations within rangerkeeps on increasing in\norder to ensure good statistical performance. For details we refer the reader\nto [Sil86]. Chapter??discusses issues of model selection for estimators in\ngeneral in considerably more detail.\n2.2.4  Silverman’s Rule\nAssume you are an aspiring demographer who wishes to estimate the popu-\nlation density of a country, say Australia. You might have access to a limited\ncensus which, for a random portion of the population determines where they\nlive. As a consequence you will obtain a relatively high number of samples\n\n582  Density Estimation\nFig. 2.8.  Nonuniform density. Left: original density with samples drawn from the\ndistribution. Middle: density estimate with a uniform kernel. Right: density estimate\nusing Silverman’s adjustment.\nof city dwellers, whereas the number of people living in the countryside is\nlikely to be very small.\nIf  we attempt  to perform  density estimation using  Parzen windows,  we\nwill  encounter  an  interesting  dilemma:  in  regions  of  high  density  (i.e.  the\ncities) we will want to choose a narrow kernel width to allow us to model\nthe variations in population density accurately. Conversely, in the outback,\na  very  wide  kernel  is  preferable,  since  the  population  there  is  very  low.\nUnfortunately,  this  information  is  exactly  what  a  density  estimator  itself\ncould  tell  us.  In  other  words  we  have  a  chicken  and  egg  situation  where\nhaving a good density estimate seems to be necessary to come up with a\ngood density estimate.\nFortunately this situation can be addressed by realizing that we do not\nactually need to know thedensitybut rather a rough estimate of the latter.\nThis can be obtained by using information about the average distance of the\nknearest neighbors of a point. One of Silverman’s rules of thumb [Sil86] is\nto chooser\ni\nas\nr\ni\n=\nc\nk\n∑\nx∈kNN(x\ni\n)\n‖x−x\ni\n‖.(2.36)\nTypicallycis chosen to be 0.5 andkis small, e.g.k= 9 to ensure that the\nestimate is computationally efficient. The density estimate is then given by\np(x) =\n1\nm\nm\n∑\ni=1\nr\n−d\ni\nh\n(\nx−x\ni\nr\ni\n)\n.(2.37)\nFigure 2.8 shows an example of such a density estimate. It is clear that a\nlocality dependent kernel width is better than choosing a uniformly constant\nkernel density estimate. However, note that this increases the computational\ncomplexity of performing a density estimate, since first theknearest neigh-\nbors need to be found before the density estimate can be carried out.\n\n2.2  Parzen Windows59\n2.2.5  Watson-Nadaraya Estimator\nNow that we are able to perform density estimation we may use it to perform\nclassification and regression. This leads us to an effective method for non-\nparametric data analysis, the Watson-Nadaraya estimator [Wat64, Nad65].\nThe basic idea is very simple: assume that we have a binary classification\nproblem, i.e. we need to distinguish between two classes. Provided that we\nare able to compute density estimatesp(x) given a set of observationsXwe\ncould appeal to Bayes rule to obtain\np(y|x) =\np(x|y)p(y)\np(x)\n=\nm\ny\nm\n·\n1\nm\ny\n∑\ni:y\ni\n=y\nr\n−d\nh\n(\nx\ni\n−x\nr\n)\n1\nm\n∑\nm\ni=1\nr\n−d\nh\n(\nx\ni\n−x\nr\n)\n.(2.38)\nHere we only take the sum over allx\ni\nwith labely\ni\n=yin the numerator.\nThe advantage of this approach is that it is very cheap to design such an\nestimator. After all, we only need to compute sums. The downside, similar\nto that of the k-nearest neighbor classifier is that it may require sums (or\nsearch) over a large number of observations. That is, evaluation of (2.38) is\npotentially anO(m) operation. Fast tree based representations can be used\nto accelerate this [BKL06, KM00], however their behavior depends signifi-\ncantly on the dimensionality of the data. We will encounter computationally\nmore attractive methods at a later stage.\nFor  binary  classification  (2.38)  can  be  simplified  considerably.  Assume\nthaty∈{±1}. Forp(y= 1|x)>0.5 we will choose that we should estimate\ny=  1  and  in  the  converse  case  we  would  estimatey=−1.  Taking  the\ndifference  between  twice  the  numerator  and  the  denominator  we  can  see\nthat the function\nf(x) =\n∑\ni\ny\ni\nh\n(\nx\ni\n−x\nr\n)\n∑\ni\nh\n(\nx\ni\n−x\nr\n)\n=\n∑\ni\ny\ni\nh\n(\nx\ni\n−x\nr\n)\n∑\ni\nh\n(\nx\ni\n−x\nr\n)\n=:\n∑\ni\ny\ni\nw\ni\n(x)(2.39)\ncan be used to achieve the same goal sincef(x)>0⇐⇒p(y= 1|x)>0.5.\nNote thatf(x) is a weighted combination of the labelsy\ni\nassociated with\nweightsw\ni\n(x)  which  depend  on  the  proximity  ofxto  an  observationx\ni\n.\nIn other words, (2.39) is a smoothed-out version of thek-nearest neighbor\nclassifier of Section 1.3.2. Instead of drawing a hard boundary at thekclosest\nobservation we use a soft weighting scheme with weightsw\ni\n(x) depending\non which observations are closest.\nNote furthermore that the numerator of (2.39) is very similar to the simple\nclassifier of Section 1.3.3. In fact, for kernelsk(x,x\n′\n) such as the Gaussian\nRBF kernel, which are also kernels in the sense of a Parzen windows den-\nsity estimate, i.e.k(x,x\n′\n) =r\n−d\nh\n(\nx−x\n′\nr\n)\nthe two terms are identical. This\n\n602  Density Estimation\nFig. 2.9.  Watson Nadaraya estimate. Left: a binary classifier. The optimal solution\nwould be a straight line since both classes were drawn from a normal distribution\nwith the same variance. Right: a regression estimator. The data was generated from\na sinusoid with additive noise. The regression tracks the sinusoid reasonably well.\nmeans that the Watson Nadaraya estimator provides us with an alternative\nexplanation as to why (1.24) leads to a usable classifier.\nIn  the  same  fashion  as  the  Watson  Nadaraya  classifier  extends  the  k-\nnearest  neighbor  classifier  we  also  may  construct  a  Watson  Nadaraya  re-\ngression  estimator  by  replacing  the  binary  labelsy\ni\nby  real-valued  values\ny\ni\n∈Rto obtain the regression estimator\n∑\ni\ny\ni\nw\ni\n(x). Figure 2.9 has an ex-\nample of the workings of both a regression estimator and a classifier. They\nare easy to use and they work well for moderately dimensional data.\n2.3  Exponential Families\nDistributions  from  the  exponential  family  are  some  of  the  most  versatile\ntools for statistical inference. Gaussians, Poisson, Gamma and Wishart dis-\ntributions all form part of the exponential family. They play a key role in\ndealing with graphical models, classification, regression and conditional ran-\ndom fields which we will encounter in later parts of this book. Some of the\nreasons for their popularity are that they lead to convex optimization prob-\nlems and that they allow us to describe probability distributions by linear\nmodels.\n2.3.1  Basics\nDensities from the exponential family are defined by\np(x;θ) :=p\n0\n(x) exp (〈φ(x),θ〉−g(θ)).(2.40)\n\n2.3  Exponential Families61\nHerep\n0\n(x) is a density onXand is often called the base measure,φ(x) is\na map fromxto the sufficient statisticsφ(x).θis commonly referred to as\nthenaturalparameter. It lives in the space dual toφ(x). Moreover,g(θ) is a\nnormalization constant which ensures thatp(x) is properly normalized.gis\noften referred to as the log-partition function. The name stems from physics\nwhereZ=e\ng(θ)\ndenotes the number of states of a physical ensemble.gcan\nbe computed as follows:\ng(θ) = log\n∫\nX\nexp (〈φ(x),θ〉)dx.(2.41)\nExample 2.5 (Binary Model)Assume  thatX={0; 1}and  thatφ(x) =\nx.  In  this  case  we  haveg(θ) = log\n[\ne\n0\n+e\nθ\n]\n= log\n[\n1 +e\nθ\n]\n.  It  follows  that\np(x=  0;θ)  =\n1\n1+e\nθ\nandp(x=  1;θ)  =\ne\nθ\n1+e\nθ\n.  In  other  words,  by  choosing\ndifferent values ofθone can recover different Bernoulli distributions.\nOne  of  the  convenient  properties  of  exponential  families  is  that  the  log-\npartition  functiongcan  be  used  to  generate  moments  of  the  distribution\nitself simply by taking derivatives.\nTheorem 2.14 (Log partition function)The  functiong(θ)is  convex.\nMoreover, the distributionp(x;θ)satisfies\n∇\nθ\ng(θ) =E\nx\n[φ(x)]and∇\n2\nθ\ng(θ) = Var\nx\n[φ(x)].(2.42)\nProofNote that∇\n2\nθ\ng(θ) = Var\nx\n[φ(x)] implies thatgis convex, since the\ncovariance matrix is positive semidefinite. To show (2.42) we expand\n∇\nθ\ng(θ) =\n∫\nX\nφ(x) exp〈φ(x),θ〉dx\n∫\nX\nexp〈φ(x),θ〉\n=\n∫\nφ(x)p(x;θ)dx=E\nx\n[φ(x)].(2.43)\nNext we take the second derivative to obtain\n∇\n2\nθ\ng(θ) =\n∫\nX\nφ(x) [φ(x)−∇\nθ\ng(θ)]\n>\np(x;θ)dx(2.44)\n=E\nx\n[\nφ(x)φ(x)\n>\n]\n−E\nx\n[φ(x)]E\nx\n[φ(x)]\n>\n(2.45)\nwhich proves the claim. For the first equality we used (2.43). For the second\nline we used the definition of the variance.\nOne  may  show  that  higher  derivatives∇\nn\nθ\ng(θ)  generate  higher  order  cu-\nmulants  ofφ(x)  underp(x;θ).  This  is  whygis  often  also  referred  as  the\ncumulant-generating  function.  Note  that  in  general,  computation  ofg(θ)\n\n622  Density Estimation\nis nontrivial since it involves solving a highdimensional integral. For many\ncases, in fact, the computation is NP hard, for instance whenXis the do-\nmain of permutations [FJ95]. Throughout the book we will discuss a number\nof approximation techniques which can be applied in such a case.\nLet  us  briefly  illustrate  (2.43)  using  the  binary  model  of  Example  2.5.\nWe have that∇\nθ\n=\ne\nθ\n1+e\nθ\nand∇\n2\nθ\n=\ne\nθ\n(1+e\nθ\n)\n2\n.This is exactly what we would\nhave obtained from direct computation of the meanp(x= 1;θ) and variance\np(x= 1;θ)−p(x= 1;θ)\n2\nsubject to the distributionp(x;θ).\n2.3.2  Examples\nA large number of densities are members of the exponential family. Note,\nhowever,  that  in  statistics  it  is  not  common  to  express  them  in  the  dot\nproduct formulation for historic reasons and for reasons of notational com-\npactness. We discuss a number of common densities below and show why\nthey can be written in terms of an exponential family. A detailed description\nof the most commonly occurring types are given in a table.\nGaussianLetx,μ∈R\nd\nand  let  Σ∈R\nd×d\nwhere  Σ\u001f0,  that  is,  Σ  is  a\npositive definite matrix. In this case the normal distribution can be\nexpressed via\np(x) = (2π)\n−\nd\n2\n|Σ|\n−\n1\n2\nexp\n(\n−\n1\n2\n(x−μ)\n>\nΣ\n−1\n(x−μ)\n)\n(2.46)\n= exp\n(\nx\n>\n[\nΣ\n−1\nμ\n]\n+ tr\n([\n−\n1\n2\nxx\n>\n]\n[\nΣ\n−1\n]\n)\n−c(μ,Σ)\n)\nwherec(μ,Σ) =\n1\n2\nμ\n>\nΣ\n−1\nμ+\nd\n2\nlog 2π+\n1\n2\nlog|Σ|. By combining the\nterms inxintoφ(x) := (x,−\n1\n2\nxx\n>\n) we obtain the sufficient statistics\nofx. The corresponding linear coefficients (Σ\n−1\nμ,Σ\n−1\n) constitute the\nnatural parameterθ. All that remains to be done to expressp(x) in\nterms of (2.40) is to rewriteg(θ) in terms ofc(μ,Σ). The summary\ntable on the following page contains details.\nMultinomialAnother popular distribution is one overkdiscrete events.\nIn this caseX={1,...,k}and we have in completely generic terms\np(x) =π\nx\nwhereπ\nx\n≥0 and\n∑\nx\nπ\nx\n= 1. Now denote bye\nx\n∈R\nk\nthe\nx-th unit vector of the canonical basis, that is〈e\nx\n,e\nx\n′\n〉= 1 ifx=x\n′\nand 0 otherwise. In this case we may rewritep(x) via\np(x) =π\nx\n= exp (〈e\nx\n,logπ〉)(2.47)\nwhere logπ= (logπ\n1\n,...,logπ\nk\n). In other words, we have succeeded\n\n2.3  Exponential Families63\nin rewriting the distribution as a member of the exponential family\nwhereφ(x) =e\nx\nand whereθ= logπ. Note that in this definitionθ\nis restricted to ak−1 dimensional manifold (thekdimensional prob-\nability simplex). If we relax those constraints we need to ensure that\np(x) remains normalized. Details are given in the summary table.\nPoissonThis distribution is often used to model distributions over discrete\nevents. For instance, the number of raindrops which fall on a given\nsurface  area  in  a  given  amount  of  time,  the  number  of  stars  in  a\ngiven volume of space, or the number of Prussian soldiers killed by\nhorse-kicks in the Prussian cavalry all follow this distribution. It is\ngiven by\np(x) =\ne\n−λ\nλ\nx\nx!\n=\n1\nx!\nexp (xlogλ−λ)  wherex∈N\n0\n.(2.48)\nBy definingφ(x) =xwe obtain an exponential families model. Note\nthat  things  are  a  bit  less  trivial  here  since\n1\nx!\nis  the  nonuniform\ncountingmeasureonN\n0\n.  The  case  of  the  uniform  measure  which\nleads to the exponential distribution is discussed in Problem 2.16.\nThe reason why many discrete processes follow the Poisson distri-\nbution is that it can be seen as the limit over the average of a large\nnumber of Bernoulli draws: denote byz∈ {0,1}a random variable\nwithp(z= 1) =α. Moreover, denote byz\nn\nthe sum overndraws\nfrom this random variable. In this casez\nn\nfollows the multinomial\ndistribution withp(z\nn\n=k) =\n(\nn\nk\n)\nα\nk\n(1−α)\nn−k\n. Now assume that\nwe letn→∞such that the expected value ofz\nn\nremains constant.\nThat is, we rescaleα=\nλ\nn\n. In this case we have\np(z\nn\n=k) =\nn!\n(n−k)!k!\nλ\nk\nn\nk\n(\n1−\nλ\nn\n)\nn−k\n(2.49)\n=\nλ\nk\nk!\n(\n1−\nλ\nn\n)\nn\n[\nn!\nn\nk\n(n−k)!\n(\n1−\nλ\nn\n)\nk\n]\nForn→ ∞the second term converges toe\n−λ\n. The third term con-\nverges to 1, since we have a product of only 2kterms, each of which\nconverge to 1. Using the exponential families notation we may check\nthatE[x] =λand that moreover also Var[x] =λ.\nBetaThis  is  a  distribution  on  the  unit  intervalX=  [0,1]  which  is  very\nversatile when it comes to modelling unimodal and bimodal distri-\n\n642  Density Estimation\n051015202530\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.00.20.40.60.81.0\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\nFig. 2.10.  Left: Poisson distributions withλ={1,3,10}. Right: Beta distributions\nwitha=  2  andb∈ {1,2,3,5,7}.  Note  how  with  increasingbthe  distribution\nbecomes more peaked close to the origin.\nbutions. It is given by\np(x) =x\na−1\n(1−x)\nb−1\nΓ(a+b)\nΓ(a)Γ(b)\n.(2.50)\nTaking logarithms we see that this, too, is an exponential families\ndistribution,  sincep(x)  =  exp((a−1) logx+ (b−1) log(1−x) +\nlog Γ(a+b)−log Γ(a)−log Γ(b)).\nFigure 2.10 has a graphical description of the Poisson distribution and the\nBeta distribution. For a more comprehensive list of exponential family dis-\ntributions  see  the  table  below  and  [Fel71,  FT94,  MN83].  In  principle  any\nmapφ(x), domainXwith underlying measureμare suitable, as long as the\nlog-partition functiong(θ) can be computed efficiently.\nTheorem 2.15 (Convex feasible domain)The  domain  of  definitionΘ\nofg(θ)is convex.\nProofBy constructiongis convex and differentiable everywhere. Hence the\nbelow-sets for all valuescwith{x|g(x)≤c}exist. Consequently the domain\nof definition is convex.\nHaving a convex function is very valuable when it comes to parameter infer-\nence since convex minimization problems have unique minimum values and\nglobal minima. We will discuss this notion in more detail when designing\nmaximum likelihood estimators.\n\n2.3  Exponential Families65\nName\nDomain\nX\nMeasure\nφ\n(\nx\n)\ng\n(\nθ\n)\nDomain Θ\nBernoulli\n{\n0\n,\n1\n}\nCounting\nx\nlog\n(\n1 +\ne\nθ\n)\nR\nMultinomial\n{\n1\n..N\n}\nCounting\ne\nx\nlog\n∑\nNi\n=1\ne\nθ\ni\nR\nN\nExponential\nN\n+0\nCounting\nx\n−\nlog\n(\n1\n−\ne\nθ\n)\n(\n−∞\n,\n0)\nPoisson\nN\n+0\n1\nx\n!\nx\ne\nθ\nR\nLaplace\n[0\n,\n∞\n)\nLebesgue\nx\nlog\nθ\n(\n−∞\n,\n0)\nGaussian\nR\nLebesgue\n(\nx,\n−\n12\nx\n2\n)\n12\nlog 2\nπ\n−\n12\nlog\nθ\n2\n+\n1\n2\nθ\n2\n1\nθ\n2\nR\n×\n(0\n,\n∞\n)\nR\nn\nLebesgue\n(\nx,\n−\n1\n2\nxx\n>\n)\nn\n2\nlog 2\nπ\n−\n12\nlog\n|\nθ\n2\n|\n+\n1\n2\nθ\n>\n1\nθ\n−\n1\n2\nθ\n1\nR\nn\n×\nC\nn\nInverse Normal    [0\n,\n∞\n)\nx\n−\n3\n2\n(\n−\nx,\n−\n1\nx\n)\n12\nlog\nπ\n−\n2\n√\nθ\n1\nθ\n2\n−\n12\nlog\nθ\n2\n(0\n,\n∞\n)\n2\nBeta\n[0\n,\n1]\n1\nx\n(1\n−\nx\n)\n(log\nx,\nlog (1\n−\nx\n))\nlog\nΓ(\nθ\n1\n)Γ(\nθ\n2\n)\nΓ(\nθ\n1\n+\nθ\n2\n)\nR\n2\nGamma\n[0\n,\n∞\n)\n1\nx\n(log\nx,\n−\nx\n)\nlog Γ(\nθ\n1\n)\n−\nθ\n1\nlog\nθ\n2\n(0\n,\n∞\n)\n2\nWishart\nC\nn\n|\nX\n|\n−\nn\n+1\n2\n(\nlog\n|\nx\n|\n,\n−\n12\nx\n)\n−\nθ\n1\nlog\n|\nθ\n2\n|\n+\nθ\n1\nn\nlog 2\nR\n×\nC\nn\n+\n∑\nni\n=1\nlog Γ\n(\nθ\n1\n+\n1\n−\ni\n2\n)\nDirichlet\nS\nn\n(\n∏\nni\n=1\nx\ni\n)\n−\n1\n(log\nx\n1\n,...,\nlog\nx\nn\n)\n∑\nni\n=1\nlog Γ(\nθ\ni\n)\n−\nlog Γ (\n∑\nni\n=1\nθ\ni\n)\n(\nR\n+\n)\nn\nInverse\nχ\n2\nR\n+\ne\n−\n1\n2\nx\n−\nlog\nx\n(\nθ\n−\n1) log 2 + log(\nθ\n−\n1)\n(0\n,\n∞\n)\nLogarithmic\nN\n1\nx\nx\nlog(\n−\nlog(1\n−\ne\nθ\n))\n(\n−∞\n,\n0)\nConjugate\nΘ\nLebesgue\n(\nθ,\n−\ng\n(\nθ\n))\ngeneric\nS\nn\ndenotes the probability simplex in\nn\ndimensions.\nC\nn\nis the cone of positive semidefinite matrices in\nR\nn\n×\nn\n.\n\n662  Density Estimation\n2.4  Estimation\nIn many statistical problems the challenge is to estimate parameters of in-\nterest.  For  instance,  in  the  context  of  exponential  families,  we  may  want\nto estimate a parameter\nˆ\nθsuch that it is close to the “true” parameterθ\n∗\nin the distribution. While the problem is fully general, we will describe the\nrelevant steps in obtaining estimates for the special case of the exponential\nfamily. This is done for two reasons — firstly, exponential families are an\nimportant special case and we will encounter slightly more complex variants\non the reasoning in later chapters of the book. Secondly, they are of a suffi-\nciently simple form that we are able to show arangeof different techniques.\nIn more advanced applications only a small subset of those methods may be\npractically  feasible.  Hence  exponential  families  provide  us  with  a  working\nexample based on which we can compare the consequences of a number of\ndifferent techniques.\n2.4.1  Maximum Likelihood Estimation\nWhenever we have a distributionp(x;θ) parametrized by some parameter\nθwe may use data to find a value ofθwhich maximizes thelikelihoodthat\nthe  data  would  have  been  generated  by  a  distribution  with  this  choice  of\nparameter.\nFor instance, assume that we observe a set of temperature measurements\nX={x\n1\n,...,x\nm\n}. In this case, we could try finding a normal distribution\nsuch that the likelihoodp(X;θ) of the data under the assumption of a normal\ndistribution is maximized. Note that this doesnotimply in any way that the\ntemperature measurements are actually drawn from a normal distribution.\nInstead, it means that we are attempting to find the Gaussian which fits the\ndata in the best fashion.\nWhile this distinction may appear subtle, it is critical: we donotassume\nthat our model accurately reflects reality. Instead, we simply try doing the\nbest possible job at modeling the data given a specified model class. Later\nwe  will  encounter  alternative  approaches  at  estimation,  namely  Bayesian\nmethods, whichmakethe assumption that our model ought to be able to\ndescribe the data accurately.\nDefinition 2.16 (Maximum Likelihood Estimator)For a modelp(·;θ)\nparametrized  byθand  observationsXthe  maximum  likelihood  estimator\n(MLE) is\nˆ\nθ\nML\n[X] := argmax\nθ\np(X;θ).(2.51)\n\n2.4  Estimation67\nIn the context of exponential families this leads to the following procedure:\ngivenmobservations drawn iid from some distribution, we can express the\njoint likelihood as\np(X;θ) =\nm\n∏\ni=1\np(x\ni\n;θ) =\nm\n∏\ni=1\nexp (〈φ(x\ni\n),θ〉−g(θ))(2.52)\n= exp (m(〈μ[X],θ〉−g(θ)))(2.53)\nwhereμ[X] :=\n1\nm\nm\n∑\ni=1\nφ(x\ni\n).(2.54)\nHereμ[X] is the empirical average of the mapφ(x). Maximization ofp(X;θ)\nis  equivalent  to  minimizing  the  negative  log-likelihood−logp(X;θ).  The\nlatter  is  a  common  practical  choice  since  for  independently  drawn  data,\nthe product of probabilities decomposes into the sum of the logarithms of\nindividual likelihoods. This leads to the following objective function to be\nminimized\n−logp(X;θ) =m[g(θ)−〈θ,μ[X]〉](2.55)\nSinceg(θ) is convex and〈θ,μ[X]〉is linear inθ, it follows that minimization\nof (2.55) is a convex optimization problem. Using Theorem 2.14 and the first\norder optimality condition∇\nθ\ng(θ) =μ[X] for (2.55) implies that\nθ= [∇\nθ\ng]\n−1\n(μ[X]) or equivalentlyE\nx∼p(x;θ)\n[φ(x)] =∇\nθ\ng(θ) =μ[X].\n(2.56)\nPut another way, the above conditions state that we aim to find the distribu-\ntionp(x;θ) which has the same expected value ofφ(x) as what we observed\nempirically  viaμ[X].  Under  very  mild  technical  conditions  a  solution  to\n(2.56) exists.\nIn general, (2.56) cannot be solved analytically. In certain special cases,\nthough, this is easily possible. We discuss two such choices in the following:\nMultinomial and Poisson distributions.\nExample 2.6 (Poisson Distribution)For the Poisson distribution\n1\nwhere\np(x;θ) =\n1\nx!\nexp(θx−e\nθ\n)it follows thatg(θ) =e\nθ\nandφ(x) =x. This allows\n1\nOften the Poisson distribution is specified usingλ:= logθas its rate parameter. In this case we\nhavep(x;λ) =λ\nx\ne\n−λ\n/x! as its parametrization. The advantage of thenaturalparametrization\nusingθis that we can directly take advantage of the properties of the log-partition function as\ngenerating the cumulants ofx.\n\n682  Density Estimation\nus to solve (2.56) in closed form using\n∇\nθ\ng(θ) =e\nθ\n=\n1\nm\nm\n∑\ni=1\nx\ni\nand henceθ= log\nm\n∑\ni=1\nx\ni\n−logm.(2.57)\nExample 2.7 (Multinomial Distribution)For  the  multinomial  distri-\nbution  the  log-partition  function  is  given  byg(θ) = log\n∑\nN\ni=1\ne\nθ\ni\n,  hence  we\nhave that\n∇\ni\ng(θ) =\ne\nθ\ni\n∑\nN\nj=1\ne\nθ\nj\n=\n1\nm\nm\n∑\nj=1\n{x\nj\n=i}.(2.58)\nIt is easy to check that (2.58) is satisfied fore\nθ\ni\n=\n∑\nm\nj=1\n{x\nj\n=i}. In other\nwords,  the  MLE  for  a  discrete  distribution  simply  given  by  the  empirical\nfrequencies of occurrence.\nThe multinomial setting also exhibits two rather important aspects of ex-\nponential families: firstly, choosingθ\ni\n=c+ log\n∑\nm\ni=1\n{x\nj\n=i}for anyc∈R\nwill lead to an equivalent distribution. This is the case since the sufficient\nstatisticφ(x) is not minimal. In our context this means that the coordinates\nofφ(x)  are  linearly  dependent  —  for  anyxwe  have  that\n∑\nj\n[φ(x)]\nj\n=  1,\nhence  we  could  eliminate  one  dimension.  This  is  precisely  the  additional\ndegree of freedom which is reflected in the scaling freedom inθ.\nSecondly, for data where some events do not occur at all, the expression\nlog\n[\n∑\nm\nj=1\n{x\nj\n=i}\n]\n= log 0 is ill defined. This is due to the fact that this\nparticular  set  of  counts  occurs  on  the  boundary  of  the  convex  set  within\nwhich the natural parametersθare well defined. We will see how different\ntypes of priors can alleviate the issue.\nUsing the MLE is not without problems. As we saw in Figure 2.1, conver-\ngence can be slow, since we are not using any side information. The latter\ncan provide us with problems which are both numerically better conditioned\nand which show better convergence,provided  that  our  assumptions  are  ac-\ncurate. Before discussing a Bayesian approach to estimation, let us discuss\nbasic statistical properties of the estimator.\n2.4.2  Bias, Variance and Consistency\nWhen designing any estimator\nˆ\nθ(X) we would like to obtain a number of\ndesirable properties: in general it should not be biased towards a particular\nsolution  unless  we  have  good  reason  to  believe  that  this  solution  should\nbe  preferred.  Instead,  we  would  like  the  estimator  to  recover,  at  least  on\n\n2.4  Estimation69\naverage, the “correct” parameter, should it exist. This can be formalized in\nthe notion of anunbiasedestimator.\nSecondly, we would like that, even if no correct parameter can be found,\ne.g. when we are trying to fit a Gaussian distribution to data which is not\nnormally distributed, that we will converge to the best possible parameter\nchoice as we obtain more data. This is what is understood byconsistency.\nFinally, we would like the estimator to achieve low bias and near-optimal\nestimates  as  quickly  as  possible.  The  latter  is  measured  by  theefficiency\nof an estimator. In this context we will encounter the Cram ́er-Rao bound\nwhich controls the best possible rate at which an estimator can achieve this\ngoal. Figure 2.11 gives a pictorial description.\nFig. 2.11.  Left: unbiased estimator; the estimates, denoted by circles have as mean\nthe true parameter, as denoted by a star. Middle: consistent estimator. While the\ntrue model is not within the class we consider (as denoted by the ellipsoid), the\nestimates converge to the white star which is the best model within the class that\napproximates the true model, denoted by the solid star. Right: different estimators\nhave  different regions of uncertainty,  as made explicit by  the ellipses around the\ntrue parameter (solid star).\nDefinition 2.17 (Unbiased Estimator)An  estimator\nˆ\nθ[X]is  unbiased\nif for allθwhereX∼p(X;θ)we haveE\nX\n[\nˆ\nθ[X]] =θ.\nIn other words, in expectation the parameter estimate matches the true pa-\nrameter. Note that this only makes sense if a true parameter actuallyexists.\nFor instance, if the data is Poisson distributed and we attempt modeling it\nby a Gaussian we will obviously not obtain unbiased estimates.\nFor finite sample sizes MLE is oftenbiased. For instance, for the normal\ndistribution  the  variance  estimates  carry  biasO(m\n−1\n).  See  problem  2.19\nfor details. In general, under fairly mild conditions, MLE is asymptotically\nunbiased [DGL96]. We prove this for exponential families. For more general\nsettings  the  proof  depends  on  the  dimensionality  and  smoothness  of  the\nfamily of densities that we have at our disposition.\n\n702  Density Estimation\nTheorem 2.18 (MLE for Exponential Families)Assume thatXis an\nm-sample drawn iid fromp(x;θ). The estimate\nˆ\nθ[X] =g\n−1\n(μ[X])is asymp-\ntotically normal with\nm\n−\n1\n2\n[\nˆ\nθ[X]−θ]→N(0,\n[\n∇\n2\nθ\ng(θ)\n]\n−1\n).(2.59)\nIn other words, the estimate\nˆ\nθ[X] is asymptotically normal, it converges to\nthe true parameterθ, and moreover, the variance at the correct parameter\nis given by the inverse of the covariance matrix of the data, as given by the\nsecond derivative of the log-partition function∇\n2\nθ\ng(θ).\nProofDenote byμ=∇\nθ\ng(θ) the true mean. Moreover, note that∇\n2\nθ\ng(θ) is\nthe covariance of the data drawn fromp(x;θ). By the central limit theorem\n(Theorem 2.3) we have thatn\n−\n1\n2\n[μ[X]−μ]→N(0,∇\n2\nθ\ng(θ)).\nNow  note  that\nˆ\nθ[X]  =  [∇\nθ\ng]\n−1\n(μ[X]).  Therefore,  by  the  delta  method\n(Theorem 2.5) we know that\nˆ\nθ[X] is also asymptotically normal. Moreover,\nby the inverse function theorem the Jacobian ofg\n−1\nsatisfies∇\nμ\n[∇\nθ\ng]\n−1\n(μ) =\n[\n∇\n2\nθ\ng(θ)\n]\n−1\n. Applying Slutsky’s theorem (Theorem 2.4) proves the claim.\nNow that we established the asymptotic properties of the MLE for exponen-\ntial families it is only natural to ask how much variation one may expect in\nˆ\nθ[X] when performing estimation. The Cramer-Rao bound governs this.\nTheorem 2.19 (Cram ́er and Rao [Rao73])Assume thatXis drawn from\np(X;θ)and  let\nˆ\nθ[X]be  an  asymptotically  unbiased  estimator.  Denote  byI\nthe Fisher information matrix and byBthe variance of\nˆ\nθ[X]where\nI:= Cov [∇\nθ\nlogp(X;θ)]andB:= Var\n[\nˆ\nθ[X]\n]\n.(2.60)\nIn this casedetIB≥1for all estimators\nˆ\nθ[X].\nProofWe prove the claim for the scalar case. The extension to matrices is\nstraightforward. Using the Cauchy-Schwarz inequality we have\nCov\n2\n[\n∇\nθ\nlogp(X;θ),\nˆ\nθ[X]\n]\n≤Var [∇\nθ\nlogp(X;θ)] Var\n[\nˆ\nθ[X]\n]\n=IB.(2.61)\nNote that at the true parameter the expected log-likelihood score vanishes\nE\nX\n[∇\nθ\nlogp(X;θ)] =∇\nθ\n∫\np(X;θ)dX=∇\nθ\n1 = 0.(2.62)\n\n2.4  Estimation71\nHence we may simplify the covariance formula by dropping the means via\nCov\n[\n∇\nθ\nlogp(X;θ),\nˆ\nθ[X]\n]\n=E\nX\n[\n∇\nθ\nlogp(X;θ)\nˆ\nθ[X]\n]\n=\n∫\np(X;θ)\nˆ\nθ(X)∇\nθ\nlogp(X;θ)dθ\n=∇\nθ\n∫\np(X;θ)\nˆ\nθ(X)dX=∇\nθ\nθ= 1.\nHere  the  last  equality  follows  since  we  may  interchange  integration  byX\nand the derivative with respect toθ.\nThe Cram ́er-Rao theorem implies that there is a limit to how well we may\nestimate a parameter given finite amounts of data. It is also a yardstick by\nwhich we may measure how efficiently an estimator uses data. Formally, we\ndefine  the  efficiency  as  the  quotient  between  actual  performance  and  the\nCram ́er-Rao bound via\ne:= 1/detIB.(2.63)\nThe closereis to 1, the lower the variance of the corresponding estimator\nˆ\nθ(X). Theorem 2.18 implies that for exponential families MLE is asymptot-\nically efficient. It turns out to be generally true.\nTheorem 2.20 (Efficiency of MLE [Cra46, GW92, Ber85])The max-\nimum likelihood estimator is asymptotically efficient (e= 1).\nSo far we only discussed the behavior of\nˆ\nθ[X] whenever thereexistsa trueθ\ngeneratingp(θ;X). If this is not true, we need to settle for less: how well\nˆ\nθ[X]\napproaches the best possible choice of within the given model class. Such\nbehavior is referred to as consistency. Note that it is not possible to define\nconsistencyper  se.  For  instance,  we  may  ask  whether\nˆ\nθconverges  to  the\noptimal parameterθ\n∗\n, or whetherp(x;\nˆ\nθ) converges to the optimal density\np(x;θ\n∗\n),  and  with  respect  to  which  norm.  Under  fairly  general  conditions\nthis  turns  out  to  be  true  for  finite-dimensional  parameters  and  smoothly\nparametrized densities. See [DGL96, vdG00] for proofs and further details.\n2.4.3  A Bayesian Approach\nThe  analysis  of  the  Maximum  Likelihood  method  might  suggest  that  in-\nference is a solved problem. After all, in the limit, MLE is unbiased and it\nexhibits as small variance as possible. Empirical results using afiniteamount\nof data, as present in Figure 2.1 indicate otherwise.\nWhile  not  making  any  assumptions  can  lead  to  interesting  and  general\n\n722  Density Estimation\ntheorems, it ignores the fact that in practice we almost always have some\nidea about what to expect of our solution. It would be foolish to ignore such\nadditional information. For instance, when trying to determine the voltage\nof a battery, it is reasonable to expect a measurement in the order of 1.5V\nor less. Consequently suchpriorknowledge should be incorporated into the\nestimation process. In fact, the use of side information to guide estimation\nturns  out  to  bethetool  to  building  estimators  which  work  well  in  high\ndimensions.\nRecall Bayes’ rule (1.15) which states thatp(θ|x) =\np(x|θ)p(θ)\np(x)\n. In our con-\ntext  this  means  that  if  we  are  interested  in  the  posterior  probability  ofθ\nassuming a particular value, we may obtain this using the likelihood (often\nreferred to as evidence) ofxhaving been generated byθviap(x|θ) and our\nprior  beliefp(θ)  thatθmight  be  chosen  in  the  distribution  generatingx.\nObserve the subtle but important difference to MLE: instead of treatingθ\nas  a  parameter  of  a  density  model,  we  treatθas  an  unobserved  random\nvariable which we may attempt to infer given the observationsX.\nThis can be done for a number of different purposes: we might want to\ninfer the most likely value of the parameter given the posterior distribution\np(θ|X). This is achieved by\nˆ\nθ\nMAP\n(X) := argmax\nθ\np(θ|X) = argmin\nθ\n−logp(X|θ)−logp(θ).(2.64)\nThe second equality follows sincep(X) does not depend onθ. This estimator\nis also referred to as theMaximum a Posteriori, or MAP estimator. It differs\nfrom  the  maximum  likelihood  estimator  by  adding  the  negative  log-prior\nto the optimization problem. For this reason it is sometimes also referred\nto  as  Penalized  MLE.  Effectively  we  are  penalizing  unlikely  choicesθvia\n−logp(θ).\nNote that using\nˆ\nθ\nMAP\n(X) as the parameter of choice is not quite accurate.\nAfter all, we can only infer a distribution overθand in general there is no\nguarantee that the posterior is indeed concentrated around its mode. A more\naccurate treatment is to use thedistributionp(θ|X) directly via\np(x|X) =\n∫\np(x|θ)p(θ|X)dθ.(2.65)\nIn other words, we integrate out the unknown parameterθand obtain the\ndensity estimate directly. As we will see, it is generally impossible to solve\n(2.65) exactly, an important exception being conjugate priors. In the other\ncases one may resort to sampling from the posterior distribution to approx-\nimate the integral.\nWhile it is possible to design a wide variety of prior distributions, this book\n\n2.4  Estimation73\nfocuses  on  two  important  families:  norm-constrained  prior  and  conjugate\npriors.  We  will  encounter  them  throughout,  the  former  sometimes  in  the\nguise of regularization and Gaussian Processes, the latter in the context of\nexchangeable models such as the Dirichlet Process.\nNorm-constrained priors take on the form\np(θ)∝exp(−λ‖θ−θ\n0\n‖\nd\np\n) forp,d≥1 andλ >0.(2.66)\nThat is, they restrict the deviation of the parameter valueθfrom some guess\nθ\n0\n. The intuition is that extreme values ofθare much less likely than more\nmoderate choices ofθwhich will lead to more smooth and even distributions\np(x|θ).\nA  popular  choice  is  the  Gaussian  prior  which  we  obtain  forp=d=  1\nandλ= 1/2σ\n2\n. Typically one setsθ\n0\n= 0 in this case. Note that in (2.66)\nwe  did  not  spell  out  the  normalization  ofp(θ)  —  in  the  context  of  MAP\nestimation this is not needed since it simply becomes a constant offset in\nthe optimization problem (2.64). We have\nˆ\nθ\nMAP\n[X] = argmin\nθ\nm[g(θ)−〈θ,μ[X]〉] +λ‖θ−θ\n0\n‖\nd\np\n(2.67)\nFord,p≥1 andλ≥0 the resulting optimization problem isconvexand it\nhas a unique solution. Moreover, very efficient algorithms exist to solve this\nproblem. We will discuss this in detail in Chapter 3. Figure 2.12 shows the\nregions of equal prior probability for a range of different norm-constrained\npriors.\nAs can be seen from the diagram, the choice of the norm can have profound\nconsequences on the solution. That said, as we will show in Chapter??, the\nestimate\nˆ\nθ\nMAP\nis well concentrated and converges to the optimal solution\nunder fairly general conditions.\nAn alternative to norm-constrained priors areconjugatepriors. They are\ndesigned such that the posteriorp(θ|X) has the same functional form as the\npriorp(θ). In exponential families such priors are defined via\np(θ|n,ν) = exp (〈nν,θ〉−ng(θ)−h(ν,n))  where(2.68)\nh(ν,n) = log\n∫\nexp (〈nν,θ〉−ng(θ))dθ.(2.69)\nNote  thatp(θ|n,ν)  itself  is  a  member  of  the  exponential  family  with  the\nfeature mapφ(θ) = (θ,−g(θ)). Henceh(ν,n) isconvexin (nν,n). Moreover,\nthe posterior distribution has the form\np(θ|X)∝p(X|θ)p(θ|n,ν)∝exp (〈mμ[X] +nν,θ〉−(m+n)g(θ)).(2.70)\n\n742  Density Estimation\nFig. 2.12.  From left to right: regions of equal prior probability inR\n2\nfor priors using\nthe`\n1\n,`\n2\nand`\n∞\nnorm. Note that only the`\n2\nnorm is invariant with regard to the\ncoordinate system. As we shall see later, the`\n1\nnorm prior leads to solutions where\nonly a small number of coordinates is nonzero.\nThat is, the posterior distribution has the same form as a conjugate prior\nwith parameters\nmμ[X]+nν\nm+n\nandm+n. In other words,nacts like a phantom\nsample size andνis the corresponding mean parameter. Such an interpreta-\ntion is reasonable given our desire to design a prior which, when combined\nwith the likelihood remains in the same model class: we treat prior knowl-\nedge as having observed virtual data beforehand which is then added to the\nactual set of observations. In this sense data and prior become completely\nequivalent — we obtain our knowledge either from actual observations or\nfrom virtual observations which describe our belief into how the data gen-\neration process is supposed to behave.\nEq. (2.70) has the added benefit of allowing us to provide an exact nor-\nmalized version of the posterior. Using (2.68) we obtain that\np(θ|X) = exp\n(\n〈mμ[X] +nν,θ〉−(m+n)g(θ)−h\n(\nmμ[X]+nν\nm+n\n,m+n\n))\n.\nThe main remaining challenge is to compute the normalizationhfor a range\nof important conjugate distributions. The table on the following page pro-\nvides details. Besides attractive algebraic properties, conjugate priors also\nhave a second advantage — the integral (2.65) can be solved exactly:\np(x|X) =\n∫\nexp (〈φ(x),θ〉−g(θ))×\nexp\n(\n〈mμ[X] +nν,θ〉−(m+n)g(θ)−h\n(\nmμ[X]+nν\nm+n\n,m+n\n))\ndθ\nCombining terms one may check that the integrand amounts to the normal-\n\n2.4  Estimation75\nization in the conjugate distribution, albeitφ(x) added. This yields\np(x|X) = exp\n(\nh\n(\nmμ[X]+nν+φ(x)\nm+n+1\n,m+n+ 1\n)\n−h\n(\nmμ[X]+nν\nm+n\n,m+n\n))\nSuch  an  expansion  is  very  useful  whenever  we  would  like  to  drawxfrom\np(x|X) without the need to obtain an instantiation of the latent variableθ.\nWe  provide  explicit  expansions  in  appendix  2.  [GS04]  use  the  fact  thatθ\ncan be integrated out to obtain what is called a collapsed Gibbs sampler for\ntopic models [BNJ03].\n2.4.4  An Example\nAssume  we  would  like  to  build  a  language  model  based  on  available  doc-\numents. For instance, a linguist might be interested in estimating the fre-\nquency  of  words  in  Shakespeare’s  collected  works,  or  one  might  want  to\ncompare the change with respect to a collection of webpages. While mod-\nels describing documents by treating them as bags of words which all have\nbeen obtained independently of each other are exceedingly simple, they are\nvaluable for quick-and-dirty content filtering and categorization, e.g. a spam\nfilter on a mail server or a content filter for webpages.\nHence we model a documentdas a multinomial distribution: denote by\nw\ni\nfori∈ {1,...,m\nd\n}the  words  ind.  Moreover,  denote  byp(w|θ)  the\nprobability  of  occurrence  of  wordw,  then  under  the  assumption  that  the\nwords are independently drawn, we have\np(d|θ) =\nm\nd\n∏\ni=1\np(w\ni\n|θ).(2.71)\nIt is our goal to find parametersθsuch thatp(d|θ) is accurate. For a given\ncollectionDof documents denote bym\nw\nthe number of counts for wordw\nin the entire collection. Moreover, denote bymthe total number of words\nin the entire collection. In this case we have\np(D|θ) =\n∏\ni\np(d\ni\n|θ) =\n∏\nw\np(w|θ)\nm\nw\n.(2.72)\nFinding suitable parametersθgivenDproceeds as follows: In a maximum\nlikelihood model we set\np(w|θ) =\nm\nw\nm\n.(2.73)\nIn  other  words,  we  use  the  empirical  frequency  of  occurrence  as  our  best\nguess and the sufficient statistic ofDisφ(w) =e\nw\n, wheree\nw\ndenotes the unit\nvector which is nonzero only for the “coordinate”w. Henceμ[D]\nw\n=\nm\nw\nm\n.\n\n762  Density Estimation\nWe know that the conjugate prior of the multinomial model is a Dirichlet\nmodel. It follows from (2.70) that the posterior mode is obtained by replacing\nμ[D] by\nmμ[D]+nν\nm+n\n. Denote byn\nw\n:=ν\nw\n·nthe pseudo-counts arising from\nthe conjugate prior with parameters (ν,n). In this case we will estimate the\nprobability of the wordwas\np(w|θ) =\nm\nw\n+n\nw\nm+n\n=\nm\nw\n+nν\nw\nm+n\n.(2.74)\nIn other words, we add the pseudo countsn\nw\nto the actual word countsm\nw\n.\nThis is particularly useful when the document we are dealing with is brief,\nthat is, whenever we have little data: it is quite unreasonable to infer from\na  webpage  of  approximately  1000  words  that  words  not  occurring  in  this\npage have zero probability. This is exactly what is mitigated by means of\nthe conjugate prior (ν,n).\nFinally, let us consider norm-constrained priors of the form (2.66). In this\ncase, the integral required for\np(D) =\n∫\np(D|θ)p(θ)dθ\n∝\n∫\nexp\n(\n−λ‖θ−θ\n0\n‖\nd\np\n+m〈μ[D],θ〉−mg(θ)\n)\ndθ\nisintractableand we need to resort to an approximation. A popular choice\nis to replace the integral byp(D|θ\n∗\n) whereθ\n∗\nmaximizes the integrand. This\nis precisely the MAP approximation of (2.64). Hence, in order to perform\nestimation we need to solve\nminimize\nθ\ng(θ)−〈μ[D],θ〉+\nλ\nm\n‖θ−θ\n0\n‖\nd\np\n.(2.75)\nA very simple strategy for minimizing (2.75) is gradient descent. That is for\na given value ofθwe compute the gradient of the objective function and take\na fixed step towards its minimum. For simplicity assume thatd=p= 2 and\nλ= 1/2σ\n2\n, that is, we assume thatθis normally distributed with variance\nσ\n2\nand meanθ\n0\n. The gradient is given by\n∇\nθ\n[−logp(D,θ)] =E\nx∼p(x|θ)\n[φ(x)]−μ[D] +\n1\nmσ\n2\n[θ−θ\n0\n](2.76)\nIn  other  words,  it  depends  on  the  discrepancy  between  the  mean  ofφ(x)\nwith respect to our current model and the empirical averageμ[X], and the\ndifference betweenθand the prior meanθ\n0\n.\nUnfortunately, convergence of the procedureθ←θ−η∇\nθ\n[...] is usually\nvery slow, even if we adjust the steplengthηefficiently. The reason is that\nthe gradient need not point towards the minimum as the space is most likely\n\n2.5  Sampling77\ndistorted. A better strategy is to use Newton’s method (see Chapter 3 for\na detailed discussion and a convergence proof). It relies on a second order\nTaylor approximation\n−logp(D,θ+δ)≈−logp(D,θ) +〈δ,G〉+\n1\n2\nδ\n>\nHδ(2.77)\nwhereGandHare  the  first  and  second  derivatives  of−logp(D,θ)  with\nrespect toθ. The quadratic expression can be minimized with respect toδ\nby choosingδ=−H\n−1\nGand we can fashion an update algorithm from this\nby lettingθ←θ−H\n−1\nG. One may show (see Chapter 3) that Algorithm 2.1\nis quadratically convergent. Note that the prior onθensures thatHis well\nconditioned even in the case where the variance ofφ(x) is not. In practice this\nmeans that the prior ensures fast convergence of the optimization algorithm.\nAlgorithm 2.1Newton method for MAP estimation\nNewtonMAP(D)\nInitializeθ=θ\n0\nwhilenot convergeddo\nComputeG=E\nx∼p(x|θ)\n[φ(x)]−μ[D] +\n1\nmσ\n2\n[θ−θ\n0\n]\nComputeH= Var\nx∼p(x|θ)\n[φ(x)] +\n1\nmσ\n2\n1\nUpdateθ←θ−H\n−1\nG\nend while\nreturnθ\n2.5  Sampling\nSo far we considered the problem of estimating the underlying probability\ndensity, given a set of samples drawn from that density. Now let us turn to\nthe converse problem, that is, how to generate random variables given the\nunderlying probability density. In other words, we want to design a random\nvariable generator. This is useful for a number of reasons:\nWe may encounter probability distributions where optimization over suit-\nable model parameters is essentially impossible and where it is equally im-\npossible to obtain a closed form expression of the distribution. In these cases\nit may still be possible to perform sampling to draw examples of the kind\nof data we expect to see from the model. Chapter??discusses a number of\ngraphical models where this problem arises.\nSecondly, assume that we are interested in testing the performance of a\nnetwork router under different load conditions. Instead of introducing the\nunder-development router in a live network and wreaking havoc, one could\n\n782  Density Estimation\nestimate  the  probability  density  of  the  network  traffic  under  various  load\nconditions  and  build  a  model.  The  behavior  of  the  network  can  then  be\nsimulated  by  using  a  probabilistic  model.  This  involves  drawing  random\nvariables from an estimated probability distribution.\nCarrying on, suppose that we generate data packets by sampling and see\nan  anomalous  behavior  in  your  router.  In  order  to  reproduce  and  debug\nthis  problem  one  needs  access  to  the  same  set  of  random  packets  which\ncaused the problem in the first place. In other words, it is often convenient\nif our random variable generator is reproducible; At first blush this seems\nlike  a  contradiction.  After  all,  our  random  number  generator  is  supposed\nto generate random variables. This is less of a contradiction if we consider\nhow  random  numbers  are  generated  in  a  computer  —  given  a  particular\ninitialization (which typically depends on the state of the system, e.g. time,\ndisk  size,  bios  checksum,  etc.)  the  random  number  algorithm  produces  a\nsequence of numbers which, for all practical purposes, can be treated as iid.\nA simple method is the linear congruential generator [PTVF94]\nx\ni+1\n= (ax\ni\n+b) modc.\nThe performance of these iterations depends significantly on the choice of the\nconstantsa,b,c. For instance, the GNU C compiler usesa= 1103515245,b=\n12345 andc= 2\n32\n. In generalbandcneed to be relatively prime anda−1\nneeds  to  be  divisible  by  all  prime  factors  ofcand  by  4.  It  is  very  much\nadvisablenotto attempt implementing such generators on one’s own unless\nit is absolutely necessary.\nUseful desiderata for a pseudo random number generator (PRNG) are that\nfor practical purposes it is statistically indistinguishable from a sequence of\niid data. That is, when applying a number of statistical tests, we will accept\nthe null-hypothesis that the random variables are iid. See Chapter??for\na detailed discussion of statistical testing procedures for random variables.\nIn the following we assume that we have access to auniformRNGU[0,1]\nwhich draws random numbers uniformly from the range [0,1].\n2.5.1  Inverse Transformation\nWe now consider the scenario where we would like to draw from some dis-\ntinctively non-uniform distribution. Whenever the latter is relatively simple\nthis can be achieved by applying an inverse transform:\nTheorem 2.21Forz∼p(z)withz∈Zand  an  injective  transformation\nφ:Z→Xwith  inverse  transformφ\n−1\nonφ(Z)it  follows  that  the  random\n\n2.5  Sampling79\n12345\n0\n0.1\n0.2\n0.3\nDiscrete Probability Distribution\n123456\n0\n0.2\n0.4\n0.6\n0.8\n1\nCumulative Density Function\nFig. 2.13.  Left: discrete probability distribution over 5 possible outcomes. Right:\nassociated cumulative distribution function. When sampling, we drawxuniformly\nat random fromU[0,1] and compute the inverse ofF.\nvariablex:=φ(z)is  drawn  from\n∣\n∣\n∇\nx\nφ\n−1\n(x)\n∣\n∣\n·p(φ\n−1\n(x)).  Here\n∣\n∣\n∇\nx\nφ\n−1\n(x)\n∣\n∣\ndenotes the determinant of the Jacobian ofφ\n−1\n.\nThis follows immediately by applying a variable transformation for a mea-\nsure, i.e. we changedp(z) todp(φ\n−1\n(x))\n∣\n∣\n∇\nx\nφ\n−1\n(x)\n∣\n∣\n. Such a conversion strat-\negy is particularly useful for univariate distributions.\nCorollary 2.22Denote byp(x)a distribution onRwith cumulative distri-\nbution  functionF(x\n′\n) =\n∫\nx\n′\n−∞\ndp(x).  Then  the  transformationx=φ(z) =\nF\n−1\n(z)converts samplesz∼U[0,1]to samples drawn fromp(x).\nWe now apply this strategy to a number of univariate distributions. One of\nthe most common cases is sampling from a discrete distribution.\nExample 2.8 (Discrete Distribution)In the case of a discrete distribu-\ntion  over{1,...,k}the  cumulative  distribution  function  is  a  step-function\nwith steps at{1,...,k}where the height of each step is given by the corre-\nsponding probability of the event.\nThe  implementation  works  as  follows:  denote  byp∈[0,1]\nk\nthe  vector  of\nprobabilities  and  denote  byf∈[0,1]\nk\nwithf\ni\n=f\ni−1\n+p\ni\nandf\n1\n=p\n1\nthe\nsteps of the cumulative distribution function. Then for a random variablez\ndrawn fromU[0,1]we obtainx=φ(z) := argmin\ni\n{f\ni\n≥z}. See Figure 2.13\nfor an example of a distribution over5events.\n\n802  Density Estimation\n0246810\n0\n0.2\n0.4\n0.6\n0.8\n1\nExponential Distribution\n0246810\n0\n0.2\n0.4\n0.6\n0.8\n1\nCumulative Distribution Function\nFig. 2.14.  Left: Exponential distribution withλ= 1. Right: associated cumulative\ndistribution function. When sampling, we drawxuniformly at random fromU[0,1]\nand compute the inverse.\nExample 2.9 (Exponential Distribution)The density of a Exponential-\ndistributed random variable is given by\np(x|λ) =λexp(−λx)ifλ >0andx≥0.(2.78)\nThis allows us to compute its cdf as\nF(x|λ) = 1−exp(−λx)ifλ >0forx≥0.(2.79)\nTherefore  to  generate  a  Exponential  random  variable  we  drawz∼U[0,1]\nand  solvex=φ(z) =F\n−1\n(z|λ) =−λ\n−1\nlog(1−z).  Sincezand1−zare\ndrawn fromU[0,1]we can simplify this tox=−λ\n−1\nlogz.\nWe could apply the same reasoning to the normal distribution in order to\ndraw Gaussian random variables. Unfortunately, the cumulative distribution\nfunction of the Gaussian is not available in closed form and we would need\nresort to rather nontrivial numerical techniques. It turns out that there exists\na much more elegant algorithm which has its roots in Gauss’ proof of the\nnormalization constant of the Normal distribution. This technique is known\nas the Box-M ̈uller transform.\nExample 2.10 (Box-M ̈uller Transform)Denote byX,Yindependent Gaus-\nsian random variables with zero mean and unit variance. We have\np(x,y) =\n1\n√\n2π\ne\n−\n1\n2\nx\n2\n1\n√\n2π\ne\n−\n1\n2\ny\n2\n=\n1\n2π\ne\n−\n1\n2\n(x\n2\n+y\n2\n)\n(2.80)\n\n2.5  Sampling81\n4\n3\n2\n1\n0\n1\n23\n45\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\nFig. 2.15.  Red: true density of the standard normal distribution (red line) is con-\ntrasted with the histogram of 20,000 random variables generated by the Box-M ̈uller\ntransform.\nThe key observation is that thejointdistributionp(x,y)is radially symmet-\nric, i.e. it only depends on the radiusr\n2\n=x\n2\n+y\n2\n. Hence we may perform\na variable substitution in polar coordinates via the mapφwhere\nx=rcosθandy=rsinθhence(x,y) =φ\n−1\n(r,θ).(2.81)\nThis allows us to express the density in terms of(r,θ)via\np(r,θ) =p(φ\n−1\n(r,θ))\n∣\n∣\n∇\nr,θ\nφ\n−1\n(r,θ)\n∣\n∣\n=\n1\n2π\ne\n−\n1\n2\nr\n2\n∣\n∣\n∣\n∣\n[\ncosθsinθ\n−rsinθ rcosθ\n]\n∣\n∣\n∣\n∣\n=\nr\n2π\ne\n−\n1\n2\nr\n2\n.\nThe  fact  thatp(r,θ)isconstantinθmeans  that  we  can  easily  sampleθ∈\n[0,2π]by drawing a random variable, sayz\nθ\nfromU[0,1]and rescaling it with\n2π. To obtain a sampler forrwe need to compute the cumulative distribution\nfunction forp(r) =re\n−\n1\n2\nr\n2\n:\nF(r\n′\n) =\n∫\nr\n′\n0\nre\n−\n1\n2\nr\n2\ndr= 1−e\n−\n1\n2\nr\n′\n2\nand hencer=F\n−1\n(z) =\n√\n−2 log(1−z).\n(2.82)\nObserving  thatz∼U[0,1]implies  that1−z∼U[0,1]yields  the  following\nsampler: drawz\nθ\n,z\nr\n∼U[0,1]and computexandyby\nx=\n√\n−2 logz\nr\ncos 2πz\nθ\nandy=\n√\n−2 logz\nr\nsin 2πz\nθ\n.\nNote  that  the  Box-M ̈uller  transform  yieldstwo independentGaussian  ran-\ndom variables. See Figure 2.15 for an example of the sampler.\n\n822  Density Estimation\nExample 2.11 (Uniform distribution on the disc)A  similar  strategy\ncan be employed when sampling from the unit disc. In  this case the closed-\nform expression of the distribution is simply given by\np(x,y) =\n{\n1\nπ\nifx\n2\n+y\n2\n≤1\n0otherwise\n(2.83)\nUsing the variable transform (2.81) yields\np(r,θ) =p(φ\n−1\n(r,θ))\n∣\n∣\n∇\nr,θ\nφ\n−1\n(r,θ)\n∣\n∣\n=\n{\nr\nπ\nifr≤1\n0otherwise\n(2.84)\nIntegrating  outθyieldsp(r)  =  2rforr∈[0,1]with  corresponding  CDF\nF(r) =r\n2\nforr∈[0,1]. Hence our sampler drawsz\nr\n,z\nθ\n∼U[0,1]and then\ncomputesx=\n√\nz\nr\ncos 2πz\nθ\nandy=\n√\nz\nr\nsin 2πz\nθ\n.\n2.5.2  Rejection Sampler\nAll the methods for random variable generation that we looked at so far re-\nquire intimate knowledge about the pdf of the distribution. We now describe\na general purpose method, which can be used to generate samples from an\narbitrary distribution. Let us begin with sampling from a set:\nExample 2.12 (Rejection Sampler)Denote byX⊆Xa set and letpbe\na density onX. Then a sampler for drawing fromp\nX\n(x)∝p(x)forx∈X\nandp\nX\n(x) = 0forx6∈X,  that  is,p\nX\n(x) =p(x|x∈X)is  obtained  by  the\nprocedure:\nrepeat\ndrawx∼p(x)\nuntilx∈X\nreturnx\nThat is, the algorithm keeps on drawing frompuntil the random variable is\ncontained  inX.  The  probability  that  this  occurs  is  clearlyp(X).  Hence  the\nlargerp(X)the higher the efficiency of the sampler. See Figure 2.16.\nExample 2.13 (Uniform distribution on a disc)The  procedure  works\ntrivially as follows: drawx,y∼U[0,1]. Accept if(2x−1)\n2\n+ (2y−1)\n2\n≤1\nand return sample(2x−1,2y−1). This sampler has efficiency\n4\nπ\nsince this\nis the surface ratio between the unit square and the unit ball.\nNote that this time we did not need to carry out any sophisticated measure\n\n2.5  Sampling83\nFig. 2.16.  Rejection sampler. Left: samples drawn from the uniform distribution on\n[0,1]\n2\n. Middle: the samples drawn from the uniform distribution on the unit disc\nare all the points in the grey shaded area. Right: the same procedure allows us to\nsample uniformly from arbitrary sets.\n0.00.20.40.60.81.0\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n0.00.20.40.60.81.0\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nFig. 2.17.  Accept reject sampling for the Beta(2,5) distribution. Left: Samples are\ngenerated  uniformly  from  the  blue  rectangle  (shaded  area).  Only  those  samples\nwhich fall under the red curve of the Beta(2,5) distribution (darkly shaded area)\nare  accepted.  Right:  The  true  density  of  the  Beta(2,5)  distribution  (red  line)  is\ncontrasted with the histogram of 10,000 samples drawn by the rejection sampler.\ntransform. This mathematical convenience came at the expense of a slightly\nless efficient sampler — about 21% of all samples are rejected.\nThe same reasoning that we used to obtain a hard accept/reject procedure\ncan  be  used  for  a  considerably  more  sophisticated  rejection  sampler.  The\nbasic idea is that if, for a given distributionpwe can find another distribution\nqwhich, after rescaling, becomes an upper envelope onp, we can useqto\nsample from and reject depending on the ratio betweenqandp.\nTheorem 2.23 (Rejection Sampler)Denote bypandqdistributions on\nXand  letcbe  a  constant  such  that  such  thatcq(x)≥p(x)for  allx∈X.\n\n842  Density Estimation\nThen  the  algorithm  below  draws  frompwith  acceptance  probabilityc\n−1\n.\nrepeat\ndrawx∼q(x)andt∼U[0,1]\nuntilct≤\np(x)\nq(x)\nreturnx\nProofDenote byZthe event that the sample drawn fromqis accepted.\nThen by Bayes rule the probability Pr(x|Z) can be written as follows\nPr(x|Z) =\nPr(Z|x) Pr(x)\nPr(Z)\n=\np(x)\ncq(x)\n·q(x)\nc\n−1\n=p(x)(2.85)\nHere we used that Pr(Z) =\n∫\nPr(Z|x)q(x)dx=\n∫\nc\n−1\np(x)dx=c\n−1\n.\nNote that the algorithm of Example 2.12 is a special case of such a rejection\nsampler — we majorizep\nX\nby the uniform distribution rescaled by\n1\np(X)\n.\nExample 2.14 (Beta distribution)Recall that theBeta(a,b)distribution,\nas a member of the Exponential Family with sufficient statistics(logx,log(1−\nx)), is given by\np(x|a,b) =\nΓ(a+b)\nΓ(a)Γ(b)\nx\na−1\n(1−x)\nb−1\n,(2.86)\nFor given(a,b)one can verify (problem 2.25) that\nM:= argmax\nx\np(x|a,b) =\na−1\na+b−2\n.(2.87)\nprovideda >1. Hence, if we use as proposal distribution the uniform distri-\nbutionU[0,1]with scaling factorc=p(M|a,b)we may apply Theorem 2.23.\nAs  illustrated  in  Figure  2.17,  to  generate  a  sample  fromBeta(a,b)we  first\ngenerate  a  pair(x,t),  uniformly  at  random  from  the  shaded  rectangle.  A\nsample  is  retained  ifct≤p(x|a,b),  and  rejected  otherwise.  The  acceptance\nrate of this sampler is\n1\nc\n.\nExample 2.15 (Normal distribution)We  may  use  the  Laplace  distri-\nbution to generate samples from the Normal distribution. That is, we use\nq(x|λ) =\nλ\n2\ne\n−λ|x|\n(2.88)\nas the proposal distribution. For a normal distributionp=N(0,1)with zero\n\n2.5  Sampling85\nmean  and  unit  variance  it  turns  out  that  choosingλ=  1yields  the  most\nefficient sampling scheme (see Problem 2.27) with\np(x)≤\n√\n2e\nπ\nq(x|λ= 1)\nAs  illustrated  in  Figure  2.18,  we  first  generatex∼q(x|λ=  1)using  the\ninverse  transform  method  (see  Example  2.9  and  Problem  2.21)  andt∼\nU[0,1]. Ift≤\n√\n2e/πp(x)we acceptx, otherwise we reject it. The efficiency\nof this scheme is\n√\nπ\n2e\n.\n−4−2024\n0\n0.2\n0.4\n0.6\n√\n2e\nπ\ng(x|0,1)\np(x)\nFig. 2.18.  Rejection sampling for the Normal distribution (red curve). Samples are\ngenerated uniformly from the Laplace distribution rescaled by\n√\n2e/π. Only those\nsamples which fall under the red curve of the standard normal distribution (darkly\nshaded area) are accepted.\nWhile rejection sampling is fairly efficient in low dimensions its efficiency is\nunsatisfactory in high dimensions. This leads us to an instance of the curse of\ndimensionality [Bel61]: the pdf of ad-dimensional Gaussian random variable\ncentered at 0 with varianceσ\n2\n1is given by\np(x|σ\n2\n) = (2π)\n−\nd\n2\nσ\n−d\ne\n−\n1\n2σ\n2\n‖x‖\n2\nNow suppose that we want to draw fromp(x|σ\n2\n) by sampling from another\nGaussianqwith  slightly  larger  varianceρ\n2\n> σ\n2\n.  In  this  case  the  ratio\nbetween both distributions is maximized at 0 and it yields\nc=\nq(0|σ\n2\n)\np(0|ρ\n2\n)\n=\n[\nρ\nσ\n]\nd\n\n862  Density Estimation\nIf suppose\nρ\nσ\n= 1.01, andd= 1000, we find thatc≈20960. In other words,\nwe need to generate approximately 21,000 samples on the average fromqto\ndraw a single sample fromp. We will discuss a more sophisticated sampling\nalgorithms, namely Gibbs Sampling, in Section??. It allows us to draw from\nrather nontrivial distributions as long as the distributions in small subsets\nof random variables are simple enough to be tackled directly.\nProblems\nProblem 2.1 (Bias Variance Decomposition{1})Prove that the vari-\nanceVar\nX\n[x]of a random variable can be written asE\nX\n[x\n2\n]−E\nX\n[x]\n2\n.\nProblem 2.2 (Moment Generating Function{2})Prove that the char-\nacteristic function can be used to generate moments as given in (2.12). Hint:\nuse the Taylor expansion of the exponential and apply the differential oper-\nator before the expectation.\nProblem 2.3 (Cumulative Error Function{2})\nerf(x) =\n√\n2/π\n∫\nx\n0\ne\n−x\n2\ndx.(2.89)\nProblem 2.4 (Weak Law of Large Numbers{2})In analogy to the proof\nof the central limit theorem prove the weak law of large numbers. Hint: use\na first order Taylor expansion ofe\niωt\n= 1 +iωt+o(t)to compute an approx-\nimation  of  the  characteristic  function.  Next  compute  the  limitm→ ∞for\nφ\n ̄\nX\nm\n. Finally, apply the inverse Fourier transform to associate the constant\ndistribution at the meanμwith it.\nProblem 2.5 (Rates and confidence bounds{3})Show  that  the  rate\nof hoeffding is tight — get bound from central limit theorem and compare to\nthe hoeffding rate.\nProblem 2.6Why  can’t  we  just  use  each  chip  on  the  wafer  as  a  random\nvariable? Give a counterexample. Give bounds if we actually were allowed to\ndo this.\nProblem 2.7 (Union Bound)Work  on  many  bounds  at  the  same  time.\nWe only have logarithmic penalty.\nProblem 2.8 (Randomized Rounding{4})Solve  the  linear  system  of\nequationsAx=bfor integralx.\n\n2.5  Sampling87\nProblem 2.9 (Randomized Projections{3})Prove  that  the  random-\nized projections converge.\nProblem 2.10 (The Count-Min Sketch{5})Prove the projection trick\nProblem 2.11 (Parzen windows with triangle kernels{1})Suppose\nyou are given the following data:X={2,3,3,5,5}. Plot the estimated den-\nsity using a kernel density estimator with the following kernel:\nk(u) =\n{\n0.5−0.25∗|u|if|u|≤2\n0otherwise.\nProblem 2.12Gaussian  process  link  with  Gaussian  prior  on  natural  pa-\nrameters\nProblem 2.13Optimization for Gaussian regularization\nProblem 2.14Conjugate prior (student-t and wishart).\nProblem 2.15 (Multivariate Gaussian{1})Prove thatΣ\u001f0is a nec-\nessary and sufficient condition for the normal distribution to be well defined.\nProblem 2.16 (Discrete Exponential Distribution{2})φ(x) =xand\nuniform measure.\nProblem 2.17Exponential random graphs.\nProblem 2.18 (Maximum Entropy Distribution)Show that exponen-\ntial families arise as the solution of the maximum entropy estimation prob-\nlem.\nProblem 2.19 (Maximum Likelihood Estimates for Normal Distributions)\nDerive the maximum likelihood estimates for a normal distribution, that is,\nshow that they result in\nˆμ=\n1\nm\nm\n∑\ni=1\nx\ni\nandˆσ\n2\n=\n1\nm\nm\n∑\ni=1\n(x\ni\n−ˆμ)\n2\n(2.90)\nusing  the  exponential  families  parametrization.  Next  show  that  while  the\nmean estimateˆμis unbiased, the variance estimate has a slight bias ofO(\n1\nm\n).\nTo see this, take the expectation with respect toˆσ\n2\n.\n\n882  Density Estimation\nProblem 2.20 (cdf of Logistic random variable{1})Show that the cdf\nof the Logistic random variable(??)is given by(??).\nProblem 2.21 (Double-exponential (Laplace) distribution{1})Use\nthe inverse-transform method to generate a sample from the double-exponential\n(Laplace) distribution(2.88).\nProblem 2.22 (Normal random variables in polar coordinates{1})\nIfX\n1\nandX\n2\nare  standard  normal  random  variables  and  let(R,θ)de-\nnote  the  polar  coordinates  of  the  pair(X\n1\n,X\n2\n).  Show  thatR\n2\n∼χ\n2\n2\nand\nθ∼Unif[0,2π].\nProblem 2.23 (Monotonically increasing mappings{1})A mapping\nT:R→Ris one-to-one if, and only if,Tis monotonically increasing, that\nis,x > yimplies thatT(x)> T(y).\nProblem 2.24 (Monotonically increasing multi-maps{2})LetT:R\nn\n→\nR\nn\nbe  one-to-one.  IfX∼p\nX\n(x),  then  show  that  the  distributionp\nY\n(y)of\nY=T(X)can be obtained via(??).\nProblem 2.25 (Argmax of theBeta(a,b)distribution{1})Show that\nthe mode of theBeta(a,b)distribution is given by(2.87).\nProblem 2.26 (Accept reject sampling for the unit disk{2})Give at\nleastTWO\ndifferent accept-reject based sampling schemes to generate sam-\nples uniformly at random from the unit disk. Compute their efficiency.\nProblem 2.27 (Optimizing Laplace for Standard Normal{1})Optimize\nthe ratiop(x)/g(x|μ,σ), with respect toμandσ, wherep(x)is the standard\nnormal distribution(??), andg(x|μ,σ)is the Laplace distribution(2.88).\nProblem 2.28 (Normal Random Variable Generation{2})The aim\nof  this  problem  is  to  write  code  to  generate  standard  normal  random  vari-\nables(??)by  using  different  methods.  To  do  this  generateU∼Unif[0,1]\nand apply\n(i)the Box-Muller transformation outlined in Section??.\n(ii)use the following approximation to the inverse CDF\nΦ\n−1\n(α)≈t−\na\n0\n+a\n1\nt\n1 +b\n1\nt+b\n2\nt\n2\n,(2.91)\n\n2.5  Sampling89\nwheret\n2\n= log(α\n−2\n)and\na\n0\n= 2.30753,a\n1\n= 0.27061,b\n1\n= 0.99229,b\n2\n= 0.04481\n(iii)use the method outlined in example 2.15.\nPlot a histogram of the samples you generated to confirm that they are nor-\nmally  distributed.  Compare  these  different  methods  in  terms  of  the  time\nneeded to generate 1000 random variables.\nProblem 2.29 (Non-standard Normal random variables{2})Describe\na scheme based on the Box-Muller transform to generateddimensional nor-\nmal  random  variablesp(x|0,I).  How  can  this  be  used  to  generate  arbitrary\nnormal random variablesp(x|μ,Σ).\nProblem 2.30 (Uniform samples from a disk{2})Show how the ideas\ndescribed in Section??can be generalized to draw samples uniformly at ran-\ndom from an axis parallel ellipse:{(x,y) :\nx\n2\n1\na\n2\n+\nx\n2\n2\nb\n2\n≤1}.\n\n\n\n3\nOptimization\nOptimization plays an increasingly important role in machine learning. For\ninstance,  many  machine  learning  algorithms  minimize  a  regularized  risk\nfunctional:\nmin\nf\nJ(f) :=λΩ(f) +R\nemp\n(f),(3.1)\nwith the empirical risk\nR\nemp\n(f) :=\n1\nm\nm\n∑\ni=1\nl(f(x\ni\n),y\ni\n).(3.2)\nHerex\ni\nare the training instances andy\ni\nare the corresponding labels.lthe\nloss function measures the discrepancy betweenyand the predictionsf(x\ni\n).\nFinding the optimalfinvolves solving an optimization problem.\nThis chapter provides a self-contained overview of some basic concepts and\ntools from optimization, especially geared towards solving machine learning\nproblems.  In  terms  of  concepts,  we  will  cover  topics  related  to  convexity,\nduality, and Lagrange multipliers. In terms of tools, we will cover a variety\nof  optimization  algorithms  including  gradient  descent,  stochastic  gradient\ndescent, Newton’s method, and Quasi-Newton methods. We will also look\nat some specialized algorithms tailored towards solving Linear Programming\nand Quadratic Programming problems which often arise in machine learning\nproblems.\n3.1  Preliminaries\nMinimizing an arbitrary function is, in general, very difficult, but if the ob-\njective function to be minimized is convex then things become considerably\nsimpler.  As  we  will  see  shortly,  the  key  advantage  of  dealing  with  convex\nfunctions is that a local optima is also the global optima. Therefore, well\ndeveloped tools exist to find the global minima of a convex function. Conse-\nquently, many machine learning algorithms are now formulated in terms of\nconvex optimization problems. We briefly review the concept of convex sets\nand functions in this section.\n91\n\n923  Optimization\n3.1.1  Convex Sets\nDefinition 3.1 (Convex Set)A  subsetCofR\nn\nis  said  to  be  convex  if\n(1−λ)x+λy∈Cwheneverx∈C,y∈Cand0< λ <1.\nIntuitively, what this means is that the line joining any two pointsxandy\nfrom the setClies insideC(see Figure 3.1). It is easy to see (Exercise 3.1)\nthat intersections of convex sets are also convex.\nFig. 3.1.  The convex set (left) contains the line joining any two points that belong\nto the set. A non-convex set (right) does not satisfy this property.\nA vector sum\n∑\ni\nλ\ni\nx\ni\nis called a convex combination ifλ\ni\n≥0 and\n∑\ni\nλ\ni\n=\n1. Convex combinations are helpful in defining a convex hull:\nDefinition 3.2 (Convex Hull)The convex hull,conv(X), of a finite sub-\nsetX={x\n1\n,...,x\nn\n}ofR\nn\nconsists of all convex combinations ofx\n1\n,...,x\nn\n.\n3.1.2  Convex Functions\nLetfbe a real valued function defined on a setX⊂R\nn\n. The set\n{(x,μ) :x∈X,μ∈R,μ≥f(x)}(3.3)\nis called theepigraphoff. The functionfis defined to be a convex function\nif its epigraph is a convex set inR\nn+1\n. An equivalent, and more commonly\nused,  definition  (Exercise  3.5)  is  as  follows  (see  Figure  3.2  for  geometric\nintuition):\nDefinition 3.3 (Convex Function)A  functionfdefined  on  a  setXis\ncalled  convex  if,  for  anyx,x\n′\n∈Xand  any0< λ <1such  thatλx+ (1−\nλ)x\n′\n∈X, we have\nf(λx+ (1−λ)x\n′\n)≤λf(x) + (1−λ)f(x\n′\n).(3.4)\n\n3.1  Preliminaries93\nA functionfis calledstrictlyconvex if\nf(λx+ (1−λ)x\n′\n)< λf(x) + (1−λ)f(x\n′\n)(3.5)\nwheneverx6=x\n′\n.\nIn fact, the above definition can be extended to show that iffis a convex\nfunction andλ\ni\n≥0 with\n∑\ni\nλ\ni\n= 1 then\nf\n(\n∑\ni\nλ\ni\nx\ni\n)\n≤\n∑\ni\nλ\ni\nf(x\ni\n).(3.6)\nThe above inequality is called theJensen’s inequality(problem ).\n6\n4\n202\n4\n6\nx\n0\n200\n400\n600\n800\n1000\nf(x)\n32\n1\n0\n1\n23\nx\n1.5\n1.0\n0.5\n0.0\n0.5\n1.0\n1.5\nf(x)\nFig. 3.2.  A convex function (left) satisfies (3.4); the shaded region denotes its epi-\ngraph. A nonconvex function (right) does not satisfy (3.4).\nIff:X→Ris differentiable, thenfis convex if, and only if,\nf(x\n′\n)≥f(x) +\n〈\nx\n′\n−x,∇f(x)\n〉\nfor allx,x\n′\n∈X.(3.7)\nIn other words, the first order Taylor approximation lower bounds the convex\nfunction  universally  (see  Figure  3.4).  Here  and  in  the  rest  of  the  chapter\n〈x,y〉denotes the Euclidean dot product between vectorsxandy, that is,\n〈x,y〉:=\n∑\ni\nx\ni\ny\ni\n.(3.8)\nIffis twice differentiable, thenfis convex if, and only if, its Hessian is\npositive semi-definite, that is,\n∇\n2\nf(x)\u00170.(3.9)\nFor twice differentiable strictly convex functions, the Hessian matrix is pos-\nitive definite, that is,∇\n2\nf(x)\u001f0. We briefly summarize some operations\nwhich preserve convexity:\n\n943  Optimization\nAdditionIff\n1\nandf\n2\nare convex, thenf\n1\n+f\n2\nis also convex.\nScalingIffis convex, thenαfis convex forα >0.\nAffine TransformIffis convex, theng(x) =f(Ax+b) for some matrix\nAand vectorbis also convex.\nAdding a Linear FunctionIffis convex, theng(x) =f(x)+〈a,x〉for some vector\nais also convex.\nSubtracting a Linear FunctionIffis convex, theng(x) =f(x)−〈a,x〉for some vector\nais also convex.\nPointwise MaximumIff\ni\nare convex, theng(x) = max\ni\nf\ni\n(x) is also convex.\nScalar CompositionIff(x) =h(g(x)), thenfis convex if a)gis convex,\nandhis convex, non-decreasing or b)gis concave, and\nhis convex, non-increasing.\n-3\n-2\n-1\n 0\n 1\n 2\n 3\n-3\n-2\n-1\n 0\n 1\n 2\n 3\n 0\n 2\n 4\n 6\n 8\n 10\n 12\n 14\n 16\n 18\n-3-2-1 0 1 2 3\n-3\n-2\n-1\n 0\n 1\n 2\n 3\nFig. 3.3.  Left: Convex Function in two variables. Right: the corresponding convex\nbelow-sets{x|f(x)≤c}, for different values ofc. This is also called a contour plot.\nThere is an intimate relation between convex functions and convex sets.\nFor instance, the following lemma show that thebelow  sets(level sets) of\nconvex functions, sets for whichf(x)≤c, are convex.\nLemma 3.4 (Below-Sets of Convex Functions)Denote byf:X→R\na convex function. Then the set\nX\nc\n:={x|x∈Xandf(x)≤c},for allc∈R,(3.10)\nis convex.\nProofFor anyx,x\n′\n∈X\nc\n, we havef(x),f(x\n′\n)≤c. Moreover, sincefis\nconvex, we also have\nf(λx+ (1−λ)x\n′\n)≤λf(x) + (1−λ)f(x\n′\n)≤cfor all 0< λ <1.(3.11)\nHence, for all 0< λ <1, we have (λx+ (1−λ)x\n′\n)∈X\nc\n, which proves the\nclaim. Figure 3.3 depicts this situation graphically.\n\n3.1  Preliminaries95\nAs we hinted in the introduction of this chapter, minimizing an arbitrary\nfunction on a (possibly not even compact) set of arguments can be a difficult\ntask, and will most likely exhibit many local minima. In contrast, minimiza-\ntion of a convex objective function on a convex set exhibits exactly oneglobal\nminimum. We now prove this property.\nTheorem 3.5 (Minima on Convex Sets)If the convex functionf:X→\nRattains its minimum, then the set ofx∈X, for which the minimum value\nis  attained,  is  a  convex  set.  Moreover,  iffis  strictly  convex,  then  this  set\ncontains a single element.\nProofDenote bycthe minimum offonX. Then the setX\nc\n:={x|x∈\nXandf(x)≤c}is clearly convex.\nIffis strictly convex, then for any two distinctx,x\n′\n∈X\nc\nand any 0<\nλ <1 we have\nf(λx+ (1−λ)x\n′\n)< λf(x) + (1−λ)f(x\n′\n) =λc+ (1−λ)c=c,\nwhich contradicts the assumption thatfattains its minimum onX\nc\n. There-\nforeX\nc\nmust contain only a single element.\nAs  the  following  lemma  shows,  the  minimum  point  can  be  characterized\nprecisely.\nLemma 3.6Letf:X→Rbe a differentiable convex function. Thenxis\na minimizer off, if, and only if,\n〈\nx\n′\n−x,∇f(x)\n〉\n≥0for allx\n′\n.(3.12)\nProofTo  show  the  forward  implication,  suppose  thatxis  the  optimum\nbut (3.12) does not hold, that is, there exists anx\n′\nfor which\n〈\nx\n′\n−x,∇f(x)\n〉\n<0.\nConsider the line segmentz(λ) = (1−λ)x+λx\n′\n, with 0< λ <1. SinceX\nis convex,z(λ) lies inX. On the other hand,\nd\ndλ\nf(z(λ))\n∣\n∣\n∣\n∣\nλ=0\n=\n〈\nx\n′\n−x,∇f(x)\n〉\n<0,\nwhich shows that for small values ofλwe havef(z(λ))< f(x), thus showing\nthatxis not optimal.\nThe reverse implication follows from (3.7) by noting thatf(x\n′\n)≥f(x),\nwhenever (3.12) holds.\n\n963  Optimization\nOne way to ensure that (3.12) holds is to set∇f(x) = 0. In other words,\nminimizing a convex function is equivalent to finding axsuch that∇f(x) =\n0.  Therefore,  the  first  order  conditions  are  both  necessary  and  sufficient\nwhen minimizing a convex function.\n3.1.3  Subgradients\nSo far, we worked with differentiable convex functions. The subgradient is a\ngeneralization of gradients appropriate for convex functions, including those\nwhich are not necessarily smooth.\nDefinition 3.7 (Subgradient)Supposexis a point where a convex func-\ntionfis  finite.  Then  a  subgradient  is  the  normal  vector  of  any  tangential\nsupporting hyperplane offatx. Formallyμis called a subgradient offat\nxif, and only if,\nf(x\n′\n)≥f(x) +\n〈\nx\n′\n−x,μ\n〉\nfor allx\n′\n.(3.13)\nThe set of all subgradients at a point is called the subdifferential, and is de-\nnoted by∂\nx\nf(x). If this set is not empty thenfis said to besubdifferentiable\natx. On the other hand, if this set is a singleton then, the function is said\nto bedifferentiableatx. In this case we use∇f(x) to denote the gradient\noff. Convex functions are subdifferentiable everywhere in their domain. We\nnow state some simple rules of subgradient calculus:\nAddition∂\nx\n(f\n1\n(x) +f\n2\n(x)) =∂\nx\nf\n1\n(x) +∂\nx\nf\n2\n(x)\nScaling∂\nx\nαf(x) =α∂\nx\nf(x), forα >0\nAffine TransformIfg(x) =f(Ax+b) for some matrixAand vectorb,\nthen∂\nx\ng(x) =A\n>\n∂\ny\nf(y).\nPointwise MaximumIfg(x) = max\ni\nf\ni\n(x) then∂g(x) = conv(∂\nx\nf\ni\n′\n) where\ni\n′\n∈argmax\ni\nf\ni\n(x).\nThe definition of a subgradient can also be understood geometrically. As\nillustrated  by  Figure  3.4,  a  differentiable  convex  function  is  always  lower\nbounded by its first order Taylor approximation. This concept can be ex-\ntended to non-smooth functions via subgradients, as Figure 3.5 shows.\nBy using more involved concepts, the proof of Lemma 3.6 can be extended\nto subgradients. In this case, minimizing a convex nonsmooth function en-\ntails finding axsuch that 0∈∂f(x).\n\n3.1  Preliminaries97\n3.1.4  Strongly Convex Functions\nWhen analyzing optimization algorithms, it is sometimes easier to work with\nstrongly convex functions, which generalize the definition of convexity.\nDefinition 3.8 (Strongly Convex Function)A convex functionfisσ-\nstrongly  convex  if,  and  only  if,  there  exists  a  constantσ >0such  that  the\nfunctionf(x)−\nσ\n2\n‖x‖\n2\nis convex.\nThe constantσis called the modulus of strong convexity off. Iffis twice\ndifferentiable, then there is an equivalent, and perhaps easier, definition of\nstrong convexity:fis strongly convex if there exists aσsuch that\n∇\n2\nf(x)\u0017σI.(3.14)\nIn  other  words,  the  smallest  eigenvalue  of  the  Hessian  offisuniformly\nlower boundedbyσeverywhere. Some important examples of strongly con-\nvex functions include:\nExample 3.1 (Squared Euclidean Norm)The functionf(x) =\nλ\n2\n‖x‖\n2\nisλ-strongly convex.\nExample 3.2 (Negative Entropy)Let∆\nn\n={xs.t.\n∑\ni\nx\ni\n= 1andx\ni\n≥0}\nbe thendimensional simplex, andf: ∆\nn\n→Rbe the negative entropy:\nf(x) =\n∑\ni\nx\ni\nlogx\ni\n.(3.15)\nThenfis  1-strongly  convex  with  respect  to  the‖·‖\n1\nnorm  on  the  simplex\n(see Problem 3.7).\nIffis aσ-strongly convex function then one can show the following prop-\nerties (Exercise 3.8). Herex,x\n′\nare arbitrary andμ∈∂f(x) andμ\n′\n∈∂f(x\n′\n).\nf(x\n′\n)≥f(x) +\n〈\nx\n′\n−x,μ\n〉\n+\nσ\n2\n∥\n∥\nx\n′\n−x\n∥\n∥\n2\n(3.16)\nf(x\n′\n)≤f(x) +\n〈\nx\n′\n−x,μ\n〉\n+\n1\n2σ\n∥\n∥\nμ\n′\n−μ\n∥\n∥\n2\n(3.17)\n〈\nx−x\n′\n,μ−μ\n′\n〉\n≥σ\n∥\n∥\nx−x\n′\n∥\n∥\n2\n(3.18)\n〈\nx−x\n′\n,μ−μ\n′\n〉\n≤\n1\nσ\n∥\n∥\nμ−μ\n′\n∥\n∥\n2\n.(3.19)\n\n983  Optimization\n3.1.5  Convex Functions with Lipschitz Continous Gradient\nA somewhat symmetric concept to strong convexity is the Lipschitz conti-\nnuity  of  the  gradient.  As  we  will  see  later  they  are  connected  by  Fenchel\nduality.\nDefinition 3.9 (Lipschitz Continuous Gradient)A differentiable con-\nvex functionfis said to have a Lipschitz continuous gradient, if there exists\na constantL >0, such that\n∥\n∥\n∇f(x)−∇f(x\n′\n)\n∥\n∥\n≤L\n∥\n∥\nx−x\n′\n∥\n∥\n∀x,x\n′\n.(3.20)\nAs before, iffis twice differentiable, then there is an equivalent, and perhaps\neasier, definition of Lipschitz continuity of the gradient:fhas a Lipschitz\ncontinuous gradient strongly convex if there exists aLsuch that\nLI\u0017∇\n2\nf(x).(3.21)\nIn other words, the largest eigenvalue of the Hessian offisuniformly upper\nboundedbyLeverywhere.  Iffhas  a  Lipschitz  continuous  gradient  with\nmodulusL, then one can show the following properties (Exercise 3.9).\nf(x\n′\n)≤f(x) +\n〈\nx\n′\n−x,∇f(x)\n〉\n+\nL\n2\n∥\n∥\nx−x\n′\n∥\n∥\n2\n(3.22)\nf(x\n′\n)≥f(x) +\n〈\nx\n′\n−x,∇f(x)\n〉\n+\n1\n2L\n∥\n∥\n∇f(x)−∇f(x\n′\n)\n∥\n∥\n2\n(3.23)\n〈\nx−x\n′\n,∇f(x)−∇f(x\n′\n)\n〉\n≤L\n∥\n∥\nx−x\n′\n∥\n∥\n2\n(3.24)\n〈\nx−x\n′\n,∇f(x)−∇f(x\n′\n)\n〉\n≥\n1\nL\n∥\n∥\n∇f(x)−∇f(x\n′\n)\n∥\n∥\n2\n.(3.25)\n3.1.6  Fenchel Duality\nThe Fenchel conjugate of a functionfis given by\nf\n∗\n(x\n∗\n) = sup\nx\n{〈x,x\n∗\n〉−f(x)}.(3.26)\nEven iffis not convex, the Fechel conjugate which is written as a supremum\nover  linear  functions  is  always  convex.  Some  rules  for  computing  Fenchel\nduals are summarized in Table 3.1.6. Iffis convex and its epigraph (3.3) is\na closed convex set, thenf\n∗∗\n=f. Iffandf\n∗\nare convex, then they satisfy\nthe so-called Fenchel-Young inequality\nf(x) +f\n∗\n(x\n∗\n)≥〈x,x\n∗\n〉for allx,x\n∗\n.(3.27)\n\n3.1  Preliminaries99\nFig. 3.4.  A convex function is always lower bounded by its first order Taylor ap-\nproximation. This is true even if the function is not differentiable (see Figure 3.5)\n4\n32\n1\n0\n1\n23\n4\n1\n0\n1\n2\n3\n4\n5\nFig.  3.5.  Geometric  intuition  of  a  subgradient.  The  nonsmooth  convex  function\n(solid blue) is only subdifferentiable at the “kink” points. We illustrate two of its\nsubgradients (dashed green and red lines) at a “kink” point which are tangential to\nthe function. The normal vectors to these lines are subgradients. Observe that the\nfirst order Taylor approximations obtained by using the subgradients lower bounds\nthe convex function.\nThis inequality becomes an equality wheneverx\n∗\n∈∂f(x), that is,\nf(x) +f\n∗\n(x\n∗\n) =〈x,x\n∗\n〉for allxandx\n∗\n∈∂f(x).(3.28)\nStrong convexity (Section 3.1.4) and Lipschitz continuity of the gradient\n\n1003  Optimization\nTable 3.1.Rules for computing Fenchel Duals\nScalar AdditionIfg(x) =f(x) +αtheng\n∗\n(x\n∗\n) =f\n∗\n(x\n∗\n)−α.\nFunction ScalingIfα >0 andg(x) =αf(x) theng\n∗\n(x\n∗\n) =αf\n∗\n(x\n∗\n/α).\nParameter ScalingIfα6= 0 andg(x) =f(αx) theng\n∗\n(x\n∗\n) =f\n∗\n(x\n∗\n/α)\nLinear TransformationIfAis an invertible matrix then (f◦A)\n∗\n=f\n∗\n◦(A\n−1\n)\n∗\n.\nShiftIfg(x) =f(x−x\n0\n) theng\n∗\n(x\n∗\n) =f\n∗\n(x\n∗\n) +〈x\n∗\n,x\n0\n〉.\nSumIfg(x)=f\n1\n(x)   +f\n2\n(x)    theng\n∗\n(x\n∗\n)=\ninf{f\n∗\n1\n(x\n∗\n1\n) +f\n∗\n2\n(x\n∗\n2\n) s.t.x\n∗\n1\n+x\n∗\n2\n=x\n∗\n}.\nPointwise InfimumIfg(x) = inff\ni\n(x) theng\n∗\n(x\n∗\n) = sup\ni\nf\n∗\ni\n(x\n∗\n).\n(Section  3.1.5)  are  related  by  Fenchel  duality  according  to  the  following\nlemma, which we state without proof.\nLemma 3.10 (Theorem 4.2.1 and 4.2.2 [HUL93])\n(i)Iffisσ-strongly convex, thenf\n∗\nhas a Lipschitz continuous gradient\nwith modulus\n1\nσ\n.\n(ii)Iffis convex and has a Lipschitz continuous gradient with modulus\nL, thenf\n∗\nis\n1\nL\n-strongly convex.\nNext we describe some convex functions and their Fenchel conjugates.\nExample 3.3 (Squared Euclidean Norm)Wheneverf(x) =\n1\n2\n‖x‖\n2\nwe\nhavef\n∗\n(x\n∗\n) =\n1\n2\n‖x\n∗\n‖\n2\n, that is, the squared Euclidean norm is its own con-\njugate.\nExample 3.4 (Negative Entropy)The Fenchel conjugate of the negative\nentropy(3.15)is\nf\n∗\n(x\n∗\n) = log\n∑\ni\nexp(x\n∗\ni\n).\n3.1.7  Bregman Divergence\nLetfbe a differentiable convex function. The Bregman divergence defined\nbyfis given by\n∆\nf\n(x,x\n′\n) =f(x)−f(x\n′\n)−\n〈\nx−x\n′\n,∇f(x\n′\n)\n〉\n.(3.29)\nAlso see Figure 3.6. Here are some well known examples.\nExample 3.5 (Square Euclidean Norm)Setf(x)  =\n1\n2\n‖x‖\n2\n.  Clearly,\n∇f(x) =xand therefore\n∆\nf\n(x,x\n′\n) =\n1\n2\n‖x‖\n2\n−\n1\n2\n∥\n∥\nx\n′\n∥\n∥\n2\n−\n〈\nx−x\n′\n,x\n′\n〉\n=\n1\n2\n∥\n∥\nx−x\n′\n∥\n∥\n2\n.\n\n3.1  Preliminaries101\nf(x\n′\n)\nf(x)\nf(x\n′\n) +\n〈\nx−x\n′\n,∇f(x\n′\n)\n〉\n∆\nf\n(x,x\n′\n)\nFig. 3.6.f(x) is the value of the function atx, whilef(x\n′\n)+〈x−x\n′\n,∇f(x\n′\n)〉denotes\nthe  first  order  Taylor  expansion  offaroundx\n′\n,  evaluated  atx.  The  difference\nbetween these two quantities is the Bregman divergence, as illustrated.\nExample 3.6 (Relative Entropy)Letfbe the un-normalized entropy\nf(x) =\n∑\ni\n(x\ni\nlogx\ni\n−x\ni\n).(3.30)\nOne  can  calculate∇f(x) = logx,  wherelogxis  the  component  wise  loga-\nrithm of the entries ofx, and write the Bregman divergence\n∆\nf\n(x,x\n′\n) =\n∑\ni\nx\ni\nlogx\ni\n−\n∑\ni\nx\ni\n−\n∑\ni\nx\n′\ni\nlogx\n′\ni\n+\n∑\ni\nx\n′\ni\n−\n〈\nx−x\n′\n,logx\n′\n〉\n=\n∑\ni\n(\nx\ni\nlog\n(\nx\ni\nx\n′\ni\n)\n+x\n′\ni\n−x\ni\n)\n.\nExample 3.7 (p-norm)Letfbe the squarep-norm\nf(x) =\n1\n2\n‖x‖\n2\np\n=\n1\n2\n(\n∑\ni\nx\np\ni\n)\n2/p\n.(3.31)\n\n1023  Optimization\nWe say that theq-norm is dual to thep-norm whenever\n1\np\n+\n1\nq\n= 1. One can\nverify (Problem 3.12) that thei-th component of the gradient∇f(x)is\n∇\nx\ni\nf(x) =\nsign(x\ni\n)|x\ni\n|\np−1\n‖x‖\np−2\np\n.(3.32)\nThe corresponding Bregman divergence is\n∆\nf\n(x,x\n′\n) =\n1\n2\n‖x‖\n2\np\n−\n1\n2\n∥\n∥\nx\n′\n∥\n∥\n2\np\n−\n∑\ni\n(x\ni\n−x\n′\ni\n)\nsign(x\n′\ni\n)|x\n′\ni\n|\np−1\n‖x\n′\n‖\np−2\np\n.\nThe following properties of the Bregman divergence immediately follow:\n•∆\nf\n(x,x\n′\n) is convex inx.\n•∆\nf\n(x,x\n′\n)≥0.\n•∆\nf\nmay not be symmetric, that is, in general ∆\nf\n(x,x\n′\n)6= ∆\nf\n(x\n′\n,x).\n• ∇\nx\n∆\nf\n(x,x\n′\n) =∇f(x)−∇f(x\n′\n).\nThe next lemma establishes another important property.\nLemma 3.11The  Bregman  divergence(3.29)defined  by  a  differentiable\nconvex functionfsatisfies\n∆\nf\n(x,y) + ∆\nf\n(y,z)−∆\nf\n(x,z) =〈∇f(z)−∇f(y),x−y〉.(3.33)\nProof\n∆\nf\n(x,y) + ∆\nf\n(y,z) =f(x)−f(y)−〈x−y,∇f(y)〉+f(y)−f(z)−〈y−z,∇f(z)〉\n=f(x)−f(z)−〈x−y,∇f(y)〉−〈y−z,∇f(z)〉\n= ∆\nf\n(x,z) +〈∇f(z)−∇f(y),x−y〉.\n3.2  Unconstrained Smooth Convex Minimization\nIn this section we will describe various methods to minimize a smooth convex\nobjective function.\n3.2.1  Minimizing a One-Dimensional Convex Function\nAs a warm up let us consider the problem of minimizing a smooth one di-\nmensional convex functionJ:R→Rin the interval [L,U]. This seemingly\n\n3.2  Unconstrained Smooth Convex Minimization103\nAlgorithm 3.1Interval Bisection\n1:Input:L,U, precision\u000f\n2:Sett= 0,a\n0\n=Landb\n0\n=U\n3:while(b\nt\n−a\nt\n)·J\n′\n(U)> \u000fdo\n4:ifJ\n′\n(\na\nt\n+b\nt\n2\n)>0then\n5:a\nt+1\n=a\nt\nandb\nt+1\n=\na\nt\n+b\nt\n2\n6:else\n7:a\nt+1\n=\na\nt\n+b\nt\n2\nandb\nt+1\n=b\nt\n8:end if\n9:t=t+ 1\n10:end while\n11:Return:\na\nt\n+b\nt\n2\nsimple problem has many applications. As we will see later, many optimiza-\ntion methods find a direction of descent and minimize the objective function\nalong this direction\n1\n; this subroutine is called a line search. Algorithm 3.1\ndepicts a simple line search routine based on interval bisection.\nBefore we show that Algorithm 3.1 converges, let us first derive an im-\nportant  property  of  convex  functions  of  one  variable.  For  a  differentiable\none-dimensional convex functionJ(3.7) reduces to\nJ(w)≥J(w\n′\n) + (w−w\n′\n)·J\n′\n(w\n′\n),(3.34)\nwhereJ\n′\n(w) denotes the gradient ofJ. Exchanging the role ofwandw\n′\nin\n(3.34), we can write\nJ(w\n′\n)≥J(w) + (w\n′\n−w)·J\n′\n(w).(3.35)\nAdding the above two equations yields\n(w−w\n′\n)·(J\n′\n(w)−J\n′\n(w\n′\n))≥0.(3.36)\nIfw≥w\n′\n, then this implies thatJ\n′\n(w)≥J\n′\n(w\n′\n). In other words, the gradient\nof a one dimensional convex function is monotonically non-decreasing.\nRecall that minimizing a convex function is equivalent to findingw\n∗\nsuch\nthatJ\n′\n(w\n∗\n) = 0. Furthermore, it is easy to see that the interval bisection\nmaintains  the  invariantJ\n′\n(a\nt\n)<0  andJ\n′\n(b\nt\n)>0.  This  along  with  the\nmonotonicity  of  the  gradient  suffices  to  ensure  thatw\n∗\n∈(a\nt\n,b\nt\n).  Setting\nw=w\n∗\nin (3.34), and using the monotonicity of the gradient allows us to\n1\nIf the objective function is convex, then the one dimensional function obtained by restricting\nit along the search direction is also convex (Exercise 3.10).\n\n1043  Optimization\nwrite for anyw\n′\n∈(a\nt\n,b\nt\n)\nJ(w\n′\n)−J(w\n∗\n)≤(w\n′\n−w\n∗\n)·J\n′\n(w\n′\n)≤(b\nt\n−a\nt\n)·J\n′\n(U).(3.37)\nSince we halve the interval (a\nt\n,b\nt\n) at every iteration, it follows that (b\nt\n−a\nt\n) =\n(U−L)/2\nt\n. Therefore\nJ(w\n′\n)−J(w\n∗\n)≤\n(U−L)·J\n′\n(U)\n2\nt\n,(3.38)\nfor allw\n′\n∈(a\nt\n,b\nt\n). In other words, to find an\u000f-accurate solution, that is,\nJ(w\n′\n)−J(w\n∗\n)≤\u000fwe only need log(U−L) + logJ\n′\n(U) + log(1/\u000f)< titera-\ntions. An algorithm which converges to an\u000faccurate solution inO(log(1/\u000f))\niterations is said to be linearly convergent.\nFor multi-dimensional objective functions, one cannot rely on the mono-\ntonicity property of the gradient. Therefore, one needs more sophisticated\noptimization algorithms, some of which we now describe.\n3.2.2  Coordinate Descent\nCoordinate descent is conceptually the simplest algorithm for minimizing a\nmultidimensional smooth convex functionJ:R\nn\n→R. At every iteration\nselect a coordinate, sayi, and update\nw\nt+1\n=w\nt\n−η\nt\ne\ni\n.(3.39)\nHeree\ni\ndenotes thei-th basis vector, that is, a vector with one at thei-th co-\nordinate and zeros everywhere else, whileη\nt\n∈Ris a non-negative scalar step\nsize. One could, for instance, minimize the one dimensional convex function\nJ(w\nt\n−ηe\ni\n) to obtain the stepsizeη\nt\n. The coordinates can either be selected\ncyclically, that is, 1,2,...,n,1,2,...or greedily, that is, the coordinate which\nyields the maximum reduction in function value.\nEven though coordinate descent can be shown to converge ifJhas a Lip-\nschitz continuous gradient [LT92], in practice it can be quite slow. However,\nif a high precision solution is not required, as is the case in some machine\nlearning applications, coordinate descent is often used because a) the cost\nper iteration is very low and b) the speed of convergence may be acceptable\nespecially if the variables are loosely coupled.\n3.2.3  Gradient Descent\nGradient descent (also widely known as steepest descent) is an optimization\ntechnique  for  minimizing  multidimensional  smooth  convex  objective  func-\ntions of the formJ:R\nn\n→R. The basic idea is as follows: Given a location\n\n3.2  Unconstrained Smooth Convex Minimization105\nw\nt\nat iterationt, compute the gradient∇J(w\nt\n), and update\nw\nt+1\n=w\nt\n−η\nt\n∇J(w\nt\n),(3.40)\nwhereη\nt\nis a scalar stepsize. See Algorithm 3.2 for details. Different variants\nof gradient descent depend on howη\nt\nis chosen:\nExact Line Search:SinceJ(w\nt\n−η∇J(w\nt\n)) is a one dimensional convex\nfunction inη, one can use the Algorithm 3.1 to compute:\nη\nt\n= argmin\nη\nJ(w\nt\n−η∇J(w\nt\n)).(3.41)\nInstead of the simple bisecting line search more sophisticated line searches\nsuch as the More-Thuente line search or the golden bisection rule can also\nbe used to speed up convergence (see [NW99] Chapter 3 for an extensive\ndiscussion).\nInexact Line Search:Instead of minimizingJ(w\nt\n−η∇J(w\nt\n)) we could\nsimply look for a stepsize which results in sufficient decrease in the objective\nfunction value. One popular set of sufficient decrease conditions is the Wolfe\nconditions\nJ(w\nt+1\n)≤J(w\nt\n) +c\n1\nη\nt\n〈∇J(w\nt\n),w\nt+1\n−w\nt\n〉(sufficient decrease)   (3.42)\n〈∇J(w\nt+1\n),w\nt+1\n−w\nt\n〉 ≥c\n2\n〈∇J(w\nt\n),w\nt+1\n−w\nt\n〉(curvature)   (3.43)\nwith 0< c\n1\n< c\n2\n<1 (see Figure 3.7). The Wolfe conditions are also called\nthe Armijio-Goldstein conditions. If only sufficient decrease (3.42) alone is\nenforced, then it is called the Armijio rule.\nacceptable stepsize\nacceptable stepsize\nFig.  3.7.  The  sufficient  decrease  condition  (left)  places  an  upper  bound  on  the\nacceptable stepsizes while the curvature condition (right) places a lower bound on\nthe acceptable stepsizes.\n\n1063  Optimization\nAlgorithm 3.2Gradient Descent\n1:Input:Initial pointw\n0\n, gradient norm tolerance\u000f\n2:Sett= 0\n3:while‖∇J(w\nt\n)‖≥\u000fdo\n4:w\nt+1\n=w\nt\n−η\nt\n∇J(w\nt\n)\n5:t=t+ 1\n6:end while\n7:Return:w\nt\nDecaying  Stepsize:Instead  of  performing  a  line  search  at  every  itera-\ntion, one can use a stepsize which decays according to a fixed schedule, for\nexample,η\nt\n= 1/\n√\nt. In Section 3.2.4 we will discuss the decay schedule and\nconvergence rates of a generalized version of gradient descent.\nFixed Stepsize:SupposeJhas a Lipschitz continuous gradient with mod-\nulusL. Using (3.22) and the gradient descent updatew\nt+1\n=w\nt\n−η\nt\n∇J(w\nt\n)\none can write\nJ(w\nt+1\n)≤J(w\nt\n) +〈∇J(w\nt\n),w\nt+1\n−w\nt\n〉+\nL\n2\n‖w\nt+1\n−w\nt\n‖(3.44)\n=J(w\nt\n)−η\nt\n‖∇J(w\nt\n)‖\n2\n+\nLη\n2\nt\n2\n‖∇J(w\nt\n)‖\n2\n.(3.45)\nMinimizing (3.45) as a function ofη\nt\nclearly shows that the upper bound on\nJ(w\nt+1\n) is minimized when we setη\nt\n=\n1\nL\n, which is the fixed stepsize rule.\nTheorem 3.12SupposeJhas a Lipschitz continuous gradient with modu-\nlusL. Then Algorithm 3.2 with a fixed stepsizeη\nt\n=\n1\nL\nwill return a solution\nw\nt\nwith‖∇J(w\nt\n)‖≤\u000fin at mostO(1/\u000f\n2\n)iterations.\nProofPlugging inη\nt\n=\n1\nL\nand rearranging (3.45) obtains\n1\n2L\n‖∇J(w\nt\n)‖\n2\n≤J(w\nt\n)−J(w\nt+1\n)(3.46)\nSumming this inequality\n1\n2L\nT\n∑\nt=0\n‖∇J(w\nt\n)‖\n2\n≤J(w\n0\n)−J(w\nT\n)≤J(w\n0\n)−J(w\n∗\n),\nwhich clearly shows that‖∇J(w\nt\n)‖ →0 ast→ ∞. Furthermore, we can\nwrite the following simple inequality:\n‖∇J(w\nT\n)‖≤\n√\n2L(J(w\n0\n)−J(w\n∗\n))\nT+ 1\n.\n\n3.2  Unconstrained Smooth Convex Minimization107\nSolving for\n√\n2L(J(w\n0\n)−J(w\n∗\n))\nT+ 1\n=\u000f\nshows thatTisO(1/\u000f\n2\n) as claimed.\nIf in addition to having a Lipschitz continuous gradient, ifJisσ-strongly\nconvex,  then  more  can  be  said.  First,  one  can  translate  convergence  in\n‖∇J(w\nt\n)‖to convergence in function values. Towards this end, use (3.17) to\nwrite\nJ(w\nt\n)≤J(w\n∗\n) +\n1\n2σ\n‖∇J(w\nt\n)‖\n2\n.\nTherefore, it follows that whenever‖∇J(w\nt\n)‖< \u000fwe haveJ(w\nt\n)−J(w\n∗\n)<\n\u000f\n2\n/2σ. Furthermore, we can strengthen the rates of convergence.\nTheorem 3.13Assume  everything  as  in  Theorem  3.12.  Moreover  assume\nthatJisσ-strongly  convex,  and  letc:= 1−\nσ\nL\n.  ThenJ(w\nt\n)−J(w\n∗\n)≤\u000f\nafter at most\nlog((J(w\n0\n)−J(w\n∗\n))/\u000f)\nlog(1/c)\n(3.47)\niterations.\nProofCombining (3.46) with‖∇J(w\nt\n)‖\n2\n≥2σ(J(w\nt\n)−J(w\n∗\n)), and using\nthe definition ofcone can write\nc(J(w\nt\n)−J(w\n∗\n))≥J(w\nt+1\n)−J(w\n∗\n).\nApplying the above equation recursively\nc\nT\n(J(w\n0\n)−J(w\n∗\n))≥J(w\nT\n)−J(w\n∗\n).\nSolving for\n\u000f=c\nT\n(J(w\n0\n)−J(w\n∗\n))\nand rearranging yields (3.47).\nWhen applied to practical problems which are not strongly convex gra-\ndient descent yields a low accuracy solution within a few iterations. How-\never, as the iterations progress the method “stalls” and no further increase\nin  accuracy  is  obtained  because  of  theO(1/\u000f\n2\n)  rates  of  convergence.  On\nthe  other  hand,  if  the  function  is  strongly  convex,  then  gradient  descent\nconverges linearly, that is, inO(log(1/\u000f)) iterations. However, the number\n\n1083  Optimization\nof  iterations  depends  inversely  on  log(1/c).  If  we  approximate  log(1/c)  =\n−log(1−σ/L)≈σ/L, then it shows that convergence depends on the ratio\nL/σ. This ratio is called thecondition numberof a problem. If the problem\nis well conditioned,i.e.,σ≈Lthen gradient descent converges extremely\nfast. In contrast, ifσ\u001cLthen gradient descent requires many iterations.\nThis is best illustrated with an example: Consider the quadratic objective\nfunction\nJ(w) =\n1\n2\nw\n>\nAw−bw,(3.48)\nwhereA∈R\nn×n\nis a symmetric positive definite matrix, andb∈R\nn\nis any\narbitrary vector.\nRecall that a twice differentiable function isσ-strongly convex and has a\nLipschitz continuous gradient with modulusLif and only if its Hessian sat-\nisfiesLI\u0017∇\n2\nJ(w)\u0017σI(see (3.14) and (3.21)). In the case of the quadratic\nfunction (3.48)∇\n2\nJ(w) =Aand henceσ=λ\nmin\nandL=λ\nmax\n, whereλ\nmin\n(respectivelyλ\nmax\n)  denotes  the  minimum  (respectively  maximum)  eigen-\nvalue ofA. One can thus change the condition number of the problem by\nvarying  the  eigen-spectrum  of  the  matrixA.  For  instance,  if  we  setAto\nthen×nidentity matrix, thenλ\nmax\n=λ\nmin\n= 1 and hence the problem is\nwell conditioned. In this case, gradient descent converges very quickly to the\noptimal solution. We illustrate this behavior on a two dimensional quadratic\nfunction in Figure 3.8 (right).\nOn  the  other  hand,  if  we  chooseAsuch  thatλ\nmax\n\u001dλ\nmin\nthen  the\nproblem (3.48) becomes ill-conditioned. In this case gradient descent exhibits\nzigzagging and slow convergence as can be seen in Figure 3.8 (left). Because\nof  these  shortcomings,  gradient  descent  is  not  widely  used  in  practice.  A\nnumber  of  different  algorithms  we  described  below  can  be  understood  as\nexplicitly  or  implicitly  changing  the  condition  number  of  the  problem  to\naccelerate convergence.\n3.2.4  Mirror Descent\nOne way to motivate gradient descent is to use the following quadratic ap-\nproximation of the objective function\nQ\nt\n(w) :=J(w\nt\n) +〈∇J(w\nt\n),w−w\nt\n〉+\n1\n2\n(w−w\nt\n)\n>\n(w−w\nt\n),(3.49)\nwhere,  as  in  the  previous  section,∇J(·)  denotes  the  gradient  ofJ.  Mini-\nmizing this quadratic model at every iteration entails taking gradients with\n\n3.2  Unconstrained Smooth Convex Minimization109\nFig. 3.8.  Convergence of gradient descent with exact line search on two quadratic\nproblems (3.48). The problem on the left is ill-conditioned, whereas the problem\non  the  right  is  well-conditioned.  We  plot  the  contours  of  the  objective  function,\nand the steps taken by gradient descent. As can be seen gradient descent converges\nfast on the well conditioned problem, while it zigzags and takes many iterations to\nconverge on the ill-conditioned problem.\nrespect towand setting it to zero, which gives\nw−w\nt\n:=−∇J(w\nt\n).(3.50)\nPerforming a line search along the direction−∇J(w\nt\n) recovers the familiar\ngradient descent update\nw\nt+1\n=w\nt\n−η\nt\n∇J(w\nt\n).(3.51)\nThe closely related mirror descent method replaces the quadratic penalty\nin  (3.49)  by  a  Bregman  divergence  defined  by  some  convex  functionfto\nyield\nQ\nt\n(w) :=J(w\nt\n) +〈∇J(w\nt\n),w−w\nt\n〉+ ∆\nf\n(w,w\nt\n).(3.52)\nComputing the gradient, setting it to zero, and using∇\nw\n∆\nf\n(w,w\nt\n) =∇f(w)−\n∇f(w\nt\n), the minimizer of the above model can be written as\n∇f(w)−∇f(w\nt\n) =−∇J(w\nt\n).(3.53)\nAs before, by using a stepsizeη\nt\nthe resulting updates can be written as\nw\nt+1\n=∇f\n−1\n(∇f(w\nt\n)−η\nt\n∇J(w\nt\n)).(3.54)\nIt is easy to verify that choosingf(·) =\n1\n2\n‖·‖\n2\nrecovers the usual gradient\ndescent updates. On the other hand if we choosefto be the un-normalized\nentropy (3.30) then∇f(·) = log and therefore (3.54) specializes to\nw\nt+1\n= exp(log(w\nt\n)−η\nt\n∇J(w\nt\n)) =w\nt\nexp(−η\nt\n∇J(w\nt\n)),(3.55)\nwhich is sometimes called the Exponentiated Gradient (EG) update.\n\n1103  Optimization\nTheorem 3.14LetJbe a convex function andJ(w\n∗\n)denote its minimum\nvalue. The mirror descent updates(3.54)with aσ-strongly convex function\nfsatisfy\n∆\nf\n(w\n∗\n,w\n1\n) +\n1\n2σ\n∑\nt\nη\n2\nt\n‖∇J(w\nt\n)‖\n2\n∑\nt\nη\nt\n≥min\nt\nJ(w\nt\n)−J(w\n∗\n).\nProofUsing the convexity ofJ(see (3.7)) and (3.54) we can write\nJ(w\n∗\n)≥J(w\nt\n) +〈w\n∗\n−w\nt\n,∇J(w\nt\n)〉\n≥J(w\nt\n)−\n1\nη\nt\n〈w\n∗\n−w\nt\n,f(w\nt+1\n)−f(w\nt\n)〉.\nNow applying Lemma 3.11 and rearranging\n∆\nf\n(w\n∗\n,w\nt\n)−∆\nf\n(w\n∗\n,w\nt+1\n) + ∆\nf\n(w\nt\n,w\nt+1\n)≥η\nt\n(J(w\nt\n)−J(w\n∗\n)).\nSumming overt= 1,...,T\n∆\nf\n(w\n∗\n,w\n1\n)−∆\nf\n(w\n∗\n,w\nT+1\n) +\n∑\nt\n∆\nf\n(w\nt\n,w\nt+1\n)≥\n∑\nt\nη\nt\n(J(w\nt\n)−J(w\n∗\n)).\nNoting that ∆\nf\n(w\n∗\n,w\nT+1\n)≥0,J(w\nt\n)−J(w\n∗\n)≥min\nt\nJ(w\nt\n)−J(w\n∗\n), and\nrearranging it follows that\n∆\nf\n(w\n∗\n,w\n1\n) +\n∑\nt\n∆\nf\n(w\nt\n,w\nt+1\n)\n∑\nt\nη\nt\n≥min\nt\nJ(w\nt\n)−J(w\n∗\n).(3.56)\nUsing (3.17) and (3.54)\n∆\nf\n(w\nt\n,w\nt+1\n)≤\n1\n2σ\n‖∇f(w\nt\n)−∇f(w\nt+1\n)‖\n2\n=\n1\n2σ\nη\n2\nt\n‖∇J(w\nt\n)‖\n2\n.(3.57)\nThe proof is completed by plugging in (3.57) into (3.56).\nCorollary 3.15IfJhas  a  Lipschitz  continuous  gradient  with  modulusL,\nand the stepsizesη\nt\nare chosen as\nη\nt\n=\n√\n2σ∆\nf\n(w\n∗\n,w\n1\n)\nL\n1\n√\nt\nthen(3.58)\nmin\n1≤t≤T\nJ(w\nt\n)−J(w\n∗\n)≤L\n√\n2∆\nf\n(w\n∗\n,w\n1\n)\nσ\n1\n√\nT\n.\nProofSince∇Jis Lipschitz continuous\nmin\n1≤t≤T\nJ(w\nt\n)−J(w\n∗\n)≤\n∆\nf\n(w\n∗\n,w\n1\n) +\n1\n2σ\n∑\nt\nη\n2\nt\nL\n2\n∑\nt\nη\nt\n.\n\n3.2  Unconstrained Smooth Convex Minimization111\nPlugging in (3.58) and using Problem 3.15\nmin\n1≤t≤T\nJ(w\nt\n)−J(w\n∗\n)≤L\n√\n∆\nf\n(w\n∗\n,w\n1\n)\n2σ\n(1 +\n∑\nt\n1\nt\n)\n∑\nt\n1\n√\nt\n≤L\n√\n∆\nf\n(w\n∗\n,w\n1\n)\n2σ\n1\n√\nT\n.\n3.2.5  Conjugate Gradient\nLet us revisit the problem of minimizing the quadratic objective function\n(3.48). Since∇J(w) =Aw−b, at the optimum∇J(w) = 0 (see Lemma 3.6)\nand hence\nAw=b.(3.59)\nIn  fact,  the  Conjugate  Gradient  (CG)  algorithm  was  first  developed  as  a\nmethod to solve the above linear system.\nAs we already saw, updatingwalong the negative gradient direction may\nlead to zigzagging. Therefore CG uses the so-calledconjugate directions.\nDefinition 3.16 (Conjugate Directions)Non zero vectorsp\nt\nandp\nt\n′\nare\nsaid  to  be  conjugate  with  respect  to  a  symmetric  positive  definite  matrixA\nifp\n>\nt\n′\nAp\nt\n= 0ift6=t\n′\n.\nConjugate  directions{p\n0\n,...,p\nn−1\n}are  linearly  independent  and  form  a\nbasis. To see this, suppose thep\nt\n’s are not linearly independent. Then there\nexists non-zero coefficientsσ\nt\nsuch that\n∑\nt\nσ\nt\np\nt\n= 0. Thep\nt\n’s are conjugate\ndirections, thereforep\n>\nt\n′\nA(\n∑\nt\nσ\nt\np\nt\n) =\n∑\nt\nσ\nt\np\n>\nt\n′\nAp\nt\n=σ\nt\n′\np\n>\nt\n′\nAp\nt\n′\n= 0 for allt\n′\n.\nSinceAis positive definite this implies thatσ\nt\n′\n= 0 for allt\n′\n, a contradiction.\nAs it turns out, the conjugate directions can be generated iteratively as\nfollows: Starting with anyw\n0\n∈R\nn\ndefinep\n0\n=−g\n0\n=b−Aw\n0\n, and set\nα\nt\n=−\ng\n>\nt\np\nt\np\n>\nt\nAp\nt\n(3.60a)\nw\nt+1\n=w\nt\n+α\nt\np\nt\n(3.60b)\ng\nt+1\n=Aw\nt+1\n−b(3.60c)\nβ\nt+1\n=\ng\n>\nt+1\nAp\nt\np\n>\nt\nAp\nt\n(3.60d)\np\nt+1\n=−g\nt+1\n+β\nt+1\np\nt\n(3.60e)\n\n1123  Optimization\nThe following theorem asserts that thep\nt\ngenerated by the above procedure\nare indeed conjugate directions.\nTheorem 3.17Suppose thet-th iterate generated by the conjugate gradient\nmethod(3.60)is  not  the  solution  of(3.59),  then  the  following  properties\nhold:\nspan{g\n0\n,g\n1\n,...,g\nt\n}= span{g\n0\n,Ag\n0\n,...,A\nt\ng\n0\n}.(3.61)\nspan{p\n0\n,p\n1\n,...,p\nt\n}= span{g\n0\n,Ag\n0\n,...,A\nt\ng\n0\n}.(3.62)\np\n>\nj\ng\nt\n= 0for allj < t(3.63)\np\n>\nj\nAp\nt\n= 0for allj < t.(3.64)\nProofThe proof is by induction. The induction hypothesis holds trivially\natt= 0. Assuming that (3.61) to (3.64) hold for somet, we prove that they\ncontinue to hold fort+ 1.\nStep 1:We first prove that (3.63) holds. Using (3.60c), (3.60b) and (3.60a)\np\n>\nj\ng\nt+1\n=p\n>\nj\n(Aw\nt+1\n−b)\n=p\n>\nj\n(Aw\nt\n+α\nt\np\nt\n−b)\n=p\n>\nj\n(\nAw\nt\n−\ng\n>\nt\np\nt\np\n>\nt\nAp\nt\nAp\nt\n−b\n)\n=p\n>\nj\ng\nt\n−\np\n>\nj\nAp\nt\np\n>\nt\nAp\nt\ng\n>\nt\np\nt\n.\nForj=t, both terms cancel out, while forj < tboth terms vanish due to\nthe induction hypothesis.\nStep 2:Next we prove that (3.61) holds. Using (3.60c) and (3.60b)\ng\nt+1\n=Aw\nt+1\n−b=Aw\nt\n+α\nt\nAp\nt\n−b=g\nt\n+α\nt\nAp\nt\n.\nBy  our  induction  hypothesis,g\nt\n∈span{g\n0\n,Ag\n0\n,...,A\nt\ng\n0\n},  whileAp\nt\n∈\nspan{Ag\n0\n,A\n2\ng\n0\n,...,A\nt+1\ng\n0\n}. Combining the two we conclude thatg\nt+1\n∈\nspan{g\n0\n,Ag\n0\n,...,A\nt+1\ng\n0\n}. On the other hand, we already showed thatg\nt+1\nis orthogonal to{p\n0\n,p\n1\n,...,p\nt\n}. Therefore,g\nt+1\n/∈span{p\n0\n,p\n1\n,...,p\nt\n}. Thus\nour induction assumption implies thatg\nt+1\n/∈span{g\n0\n,Ag\n0\n,...,A\nt\ng\n0\n}. This\nallows us to conclude that span{g\n0\n,g\n1\n,...,g\nt+1\n}= span{g\n0\n,Ag\n0\n,...,A\nt+1\ng\n0\n}.\n\n3.2  Unconstrained Smooth Convex Minimization113\nStep 3We now prove (3.64) holds. Using (3.60e)\np\n>\nt+1\nAp\nj\n=−g\n>\nt+1\nAp\nj\n+β\nt+1\np\n>\nt\nAp\nj\n.\nBy the definition ofβ\nt+1\n(3.60d) the above expression vanishes forj=t. For\nj < t, the first term is zero becauseAp\nj\n∈span{p\n0\n,p\n1\n,...,p\nj+1\n}, a subspace\northogonal  tog\nt+1\nas  already  shown  in  Step  1.  The  induction  hypothesis\nguarantees that the second term is zero.\nStep 4Clearly, (3.61) and (3.60e) imply (3.62). This concludes the proof.\nA  practical  implementation  of  (3.60)  requires  two  more  observations:\nFirst, using (3.60e) and (3.63)\n−g\n>\nt\np\nt\n=g\n>\nt\ng\nt\n−β\nt\ng\n>\nt\np\nt−1\n=g\n>\nt\ng\nt\n.\nTherefore (3.60a) simplifies to\nα\nt\n=\ng\n>\nt\ng\nt\np\n>\nt\nAp\nt\n.(3.65)\nSecond, using (3.60c) and (3.60b)\ng\nt+1\n−g\nt\n=A(w\nt+1\n−w\nt\n) =α\nt\nAp\nt\n.\nButg\nt\n∈span{p\n0\n,...,p\nt\n}, a subspace orthogonal tog\nt+1\nby (3.63). Therefore\ng\n>\nt+1\nAp\nt\n=\n1\nα\nt\n(g\n>\nt+1\ng\nt+1\n). Substituting this back into (3.60d) and using (3.65)\nyields\nβ\nt+1\n=\ng\n>\nt+1\ng\nt+1\ng\n>\nt\ng\nt\n.(3.66)\nWe summarize the CG algorithm in Algorithm 3.3. Unlike gradient descent\nwhose  convergence  rates  for  minimizing  the  quadratic  objective  function\n(3.48)  depend  upon  the  condition  number  ofA,  as  the  following  theorem\nshows, the CG iterates converge in at mostnsteps.\nTheorem 3.18The CG iterates(3.60)converge to the minimizer of(3.48)\nafter at mostnsteps.\nProofLetwdenote the minimizer of (3.48). Since thep\nt\n’s form a basis\nw−w\n0\n=σ\n0\np\n0\n+...+σ\nn−1\np\nn−1\n,\nfor some scalarsσ\nt\n. Our proof strategy will be to show that the coefficients\n\n1143  Optimization\nAlgorithm 3.3Conjugate Gradient\n1:Input:Initial pointw\n0\n, residual norm tolerance\u000f\n2:Sett= 0,g\n0\n=Aw\n0\n−b, andp\n0\n=−g\n0\n3:while‖Aw\nt\n−b‖≥\u000fdo\n4:α\nt\n=\ng\n>\nt\ng\nt\np\n>\nt\nAp\nt\n5:w\nt+1\n=w\nt\n+α\nt\np\nt\n6:g\nt+1\n=g\nt\n+α\nt\nAp\nt\n7:β\nt+1\n=\ng\n>\nt+1\ng\nt+1\ng\n>\nt\ng\nt\n8:p\nt+1\n=−g\nt+1\n+β\nt+1\np\nt\n9:t=t+ 1\n10:end while\n11:Return:w\nt\nσ\nt\ncoincide withα\nt\ndefined in (3.60a). Towards this end premultiply with\np\n>\nt\nAand use conjugacy to obtain\nσ\nt\n=\np\n>\nt\nA(w−w\n0\n)\np\n>\nt\nAp\nt\n.(3.67)\nOn the other hand, following the iterative process (3.60b) fromw\n0\nuntilw\nt\nyields\nw\nt\n−w\n0\n=α\n0\np\n0\n+...+α\nt−1\np\nt−1\n.\nAgain premultiplying withp\n>\nt\nAand using conjugacy\np\n>\nt\nA(w\nt\n−w\n0\n) = 0.(3.68)\nSubstituting (3.68) into (3.67) produces\nσ\nt\n=\np\n>\nt\nA(w−w\nt\n)\np\n>\nt\nAp\nt\n=−\ng\n>\nt\np\nt\np\n>\nt\nAp\nt\n,(3.69)\nthus showing thatσ\nt\n=α\nt\n.\nObserve that theg\nt+1\ncomputed via (3.60c) is nothing but the gradient of\nJ(w\nt+1\n). Furthermore, consider the following one dimensional optimization\nproblem:\nmin\nα∈R\nφ\nt\n(α) :=J(w\nt\n+αp\nt\n).\nDifferentiatingφ\nt\nwith respect toα\nφ\n′\nt\n(α) =p\n>\nt\n(Aw\nt\n+αAp\nt\n−b) =p\n>\nt\n(g\nt\n+αAp\nt\n).\n\n3.2  Unconstrained Smooth Convex Minimization115\nThe gradient vanishes if we setα=−\ng\n>\nt\np\nt\np\n>\nt\nAp\nt\n, which recovers (3.60a). In other\nwords, every iteration of CG minimizesJ(w) along a conjugate directionp\nt\n.\nContrast this with gradient descent which minimizesJ(w) along the negative\ngradient directiong\nt\nat every iteration.\nIt  is  natural  to  ask  if  this  idea  of  generating  conjugate  directions  and\nminimizing the objective function along these directions can be applied to\ngeneral convex functions. The main difficulty here is that Theorems 3.17 and\n3.18 do not hold. In spite of this, extensions of CG are effective even in this\nsetting. Basically the update rules forg\nt\nandp\nt\nremain the same, but the\nparametersα\nt\nandβ\nt\nare computed differently. Table 3.2 gives an overview\nof different extensions. See [NW99, Lue84] for details.\nTable 3.2.Non-Quadratic modifications of Conjugate Gradient Descent\nGeneric MethodCompute HessianK\nt\n:=∇\n2\nJ(w\nt\n) and updateα\nt\nandβ\nt\nwith\nα\nt\n=−\ng\n>\nt\np\nt\np\n>\nt\nK\nt\np\nt\nandβ\nt\n=−\ng\n>\nt+1\nK\nt\np\nt\np\n>\nt\nK\nt\np\nt\nFletcher-ReevesSetα\nt\n= argmin\nα\nJ(w\nt\n+αp\nt\n) andβ\nt\n=\ng\n>\nt+1\ng\nt+1\ng\n>\nt\ng\nt\n.\nPolak-Ribi`ereSetα\nt\n= argmin\nα\nJ(w\nt\n+αp\nt\n),y\nt\n=g\nt+1\n−g\nt\n, and\nβ\nt\n=\ny\n>\nt\ng\nt+1\ng\n>\nt\ng\nt\n.\nIn practice, Polak-Ribi`ere tends to be better than\nFletcher-Reeves.\nHestenes-StiefelSetα\nt\n= argmin\nα\nJ(w\nt\n+αp\nt\n),y\nt\n=g\nt+1\n−g\nt\n, and\nβ\nt\n=\ny\n>\nt\ng\nt+1\ny\n>\nt\np\nt\n.\n3.2.6  Higher Order Methods\nRecall the motivation for gradient descent as the minimizer of the quadratic\nmodel\nQ\nt\n(w) :=J(w\nt\n) +〈∇J(w\nt\n),w−w\nt\n〉+\n1\n2\n(w−w\nt\n)\n>\n(w−w\nt\n),\nThe quadratic penalty in the above equation uniformly penalizes deviation\nfromw\nt\nin  different  dimensions.  When  the  function  is  ill-conditioned  one\nwould intuitively want to penalize deviations in different directions differ-\nently. One way to achieve this is by using the Hessian, which results in the\n\n1163  Optimization\nAlgorithm 3.4Newton’s Method\n1:Input:Initial pointw\n0\n, gradient norm tolerance\u000f\n2:Sett= 0\n3:while‖∇J(w\nt\n)‖> \u000fdo\n4:Computep\nt\n:=−∇\n2\nJ(w\nt\n)\n−1\n∇J(w\nt\n)\n5:Computeη\nt\n= argmin\nη\nJ(w\nt\n+ηp\nt\n)e.g.,via Algorithm 3.1.\n6:w\nt+1\n=w\nt\n+η\nt\np\nt\n7:t=t+ 1\n8:end while\n9:Return:w\nt\nfollowing second order Taylor approximation:\nQ\nt\n(w) :=J(w\nt\n) +〈∇J(w\nt\n),w−w\nt\n〉+\n1\n2\n(w−w\nt\n)\n>\n∇\n2\nJ(w\nt\n)(w−w\nt\n).\n(3.70)\nOf course, this requires thatJbe twice differentiable. We will also assume\nthatJis strictly convex and hence its Hessian is positive definite and in-\nvertible. MinimizingQ\nt\nby taking gradients with respect towand setting it\nzero obtains\nw−w\nt\n:=−∇\n2\nJ(w\nt\n)\n−1\n∇J(w\nt\n),(3.71)\nSince we are only minimizing a model of the objective function, we perform\na line search along the descent direction (3.71) to compute the stepsizeη\nt\n,\nwhich yields the next iterate:\nw\nt+1\n=w\nt\n−η\nt\n∇\n2\nJ(w\nt\n)\n−1\n∇J(w\nt\n).(3.72)\nDetails can be found in Algorithm 3.4.\nSupposew\n∗\ndenotes  the  minimum  ofJ(w).  We  say  that  an  algorithm\nexhibits quadratic convergence if the sequences of iterates{w\nk\n}generated\nby the algorithm satisfies:\n‖w\nk+1\n−w\n∗\n‖≤C‖w\nk\n−w\n∗\n‖\n2\n(3.73)\nfor  some  constantC >0.  We  now  show  that  Newton’s  method  exhibits\nquadratic convergence close to the optimum.\nTheorem 3.19 (Quadratic convergence of Newton’s Method)Suppose\nJis  twice  differentiable,  strongly  convex,  and  the  Hessian  ofJis  bounded\nand  Lipschitz  continuous  with  modulusMin  a  neighborhood  of  the  so-\nlutionw\n∗\n.  Furthermore,  assume  that\n∥\n∥\n∇\n2\nJ(w)\n−1\n∥\n∥\n≤N.  The  iterations\n\n3.2  Unconstrained Smooth Convex Minimization117\nw\nt+1\n=w\nt\n−∇\n2\nJ(w\nt\n)\n−1\n∇J(w\nt\n)converge quadratically tow\n∗\n, the minimizer\nofJ.\nProofFirst notice that\n∇J(w\nt\n)−∇J(w\n∗\n) =\n∫\n1\n0\n∇\n2\nJ(w\nt\n+t(w\n∗\n−w\nt\n))(w\nt\n−w\n∗\n)dt.(3.74)\nNext using the fact that∇\n2\nJ(w\nt\n) is invertible and the gradient vanishes at\nthe optimum (∇J(w\n∗\n) = 0), write\nw\nt+1\n−w\n∗\n=w\nt\n−w\n∗\n−∇\n2\nJ(w\nt\n)\n−1\n∇J(w\nt\n)\n=∇\n2\nJ(w\nt\n)\n−1\n[∇\n2\nJ(w\nt\n)(w\nt\n−w\n∗\n)−(∇J(w\nt\n)−∇J(w\n∗\n))].(3.75)\nUsing (3.75), (3.74), and the Lipschitz continuity of∇\n2\nJ\n∥\n∥\n∇J(w\nt\n)−∇J(w\n∗\n)−∇\n2\nJ(w\nt\n)(w\nt\n−w\n∗\n)\n∥\n∥\n=\n∥\n∥\n∥\n∥\n∫\n1\n0\n[∇\n2\nJ(w\nt\n+t(w\nt\n−w\n∗\n))−∇\n2\nJ(w\nt\n)](w\nt\n−w\n∗\n)dt\n∥\n∥\n∥\n∥\n≤\n∫\n1\n0\n∥\n∥\n[∇\n2\nJ(w\nt\n+t(w\nt\n−w\n∗\n))−∇\n2\nJ(w\nt\n)]\n∥\n∥\n‖(w\nt\n−w\n∗\n)‖dt\n≤‖w\nt\n−w\n∗\n‖\n2\n∫\n1\n0\nMtdt=\nM\n2\n‖w\nt\n−w\n∗\n‖\n2\n.(3.76)\nFinally use (3.75) and (3.76) to conclude that\n‖w\nt+1\n−w\n∗\n‖≤\nM\n2\n∥\n∥\n∇\n2\nJ(w\nt\n)\n−1\n∥\n∥\n‖w\nt\n−w\n∗\n‖\n2\n≤\nNM\n2\n‖w\nt\n−w\n∗\n‖\n2\n.\nNewton’s  method  as  we  described  it  suffers  from  two  major  problems.\nFirst, it applies only to twice differentiable, strictly convex functions. Sec-\nond,  it  involves  computing  and  inverting  of  then×nHessian  matrix  at\nevery  iteration,  thus  making  it  computationally  very  expensive.  Although\nNewton’s method can be extended to deal with positive semi-definite Hes-\nsian matrices, the computational burden often makes it unsuitable for large\nscale applications. In such cases one resorts to Quasi-Newton methods.\n3.2.6.1  Quasi-Newton Methods\nUnlike Newton’s method, which computes the Hessian of the objective func-\ntion at every iteration, quasi-Newton methods never compute the Hessian;\nthey approximate it from past gradients. Since they do not require the ob-\njective function to be twice differentiable, quasi-Newton methods are much\n\n1183  Optimization\n6\n4\n202\n4\n6\n400\n200\n0\n200\n400\n600\n800\n1000\n1200\nFig. 3.9.  The blue solid line depicts the one dimensional convex functionJ(w) =\nw\n4\n+ 20w\n2\n+w.  The  green  dotted-dashed  line  represents  the  first  order  Taylor\napproximation toJ(w), while the red dashed line represents the second order Taylor\napproximation, both evaluated atw= 2.\nmore  widely  applicable.  They  are  widely  regarded  as  the  workhorses  of\nsmooth nonlinear optimization due to their combination of computational ef-\nficiency and good asymptotic convergence. The most popular quasi-Newton\nalgorithm is BFGS, named after its discoverers Broyde, Fletcher, Goldfarb,\nand Shanno. In this section we will describe BFGS and its limited memory\ncounterpart LBFGS.\nSuppose we are given a smooth (not necessarily strictly) convex objective\nfunctionJ:R\nn\n→Rand  a  current  iteratew\nt\n∈R\nn\n.  Just  like  Newton’s\nmethod, BFGS forms a local quadratic model of the objective function,J:\nQ\nt\n(w)  :=J(w\nt\n) +〈∇J(w\nt\n),w−w\nt\n〉+\n1\n2\n(w−w\nt\n)\n>\nH\nt\n(w−w\nt\n).(3.77)\nUnlike Newton’s method which uses the Hessian to build its quadratic model\n(3.70), BFGS uses the matrixH\nt\n\u001f0, which is a positive-definiteestimate\nof the Hessian. A quasi-Newton direction of descent is found by minimizing\nQ\nt\n(w):\nw−w\nt\n=−H\n−1\nt\n∇J(w\nt\n).(3.78)\nThe stepsizeη\nt\n>0 is found by a line search obeying the Wolfe conditions\n\n3.2  Unconstrained Smooth Convex Minimization119\n(3.42) and (3.43). The final update is given by\nw\nt+1\n=w\nt\n−η\nt\nH\n−1\nt\n∇J(w\nt\n).(3.79)\nGivenw\nt+1\nwe need to update our quadratic model (3.77) to\nQ\nt+1\n(w)  :=J(w\nt+1\n) +〈∇J(w\nt+1\n),w−w\nt+1\n〉+\n1\n2\n(w−w\nt+1\n)\n>\nH\nt+1\n(w−w\nt+1\n).\n(3.80)\nWhen  updating  our  model  it  is  reasonable  to  expect  that  the  gradient  of\nQ\nt+1\nshould match the gradient ofJatw\nt\nandw\nt+1\n. Clearly,\n∇Q\nt+1\n(w)  =∇J(w\nt+1\n) +H\nt+1\n(w−w\nt+1\n),(3.81)\nwhich implies that∇Q\nt+1\n(w\nt+1\n) =∇J(w\nt+1\n), and hence our second con-\ndition is automatically satisfied. In order to satisfy our first condition, we\nrequire\n∇Q\nt+1\n(w\nt\n)  =∇J(w\nt+1\n) +H\nt+1\n(w\nt\n−w\nt+1\n) =∇J(w\nt\n).(3.82)\nBy rearranging, we obtain the so-calledsecant equation:\nH\nt+1\ns\nt\n=y\nt\n,(3.83)\nwheres\nt\n:=w\nt+1\n−w\nt\nandy\nt\n:=∇J(w\nt+1\n)−∇J(w\nt\n) denote the most recent\nstep  along  the  optimization  trajectory  in  parameter  and  gradient  space,\nrespectively.  SinceH\nt+1\nis  a  positive  definite  matrix,  pre-multiplying  the\nsecant equation bys\nt\nyields thecurvature condition\ns\n>\nt\ny\nt\n>0.(3.84)\nIf the curvature condition is satisfied, then there are an infinite number\nof  matricesH\nt+1\nwhich  satisfy  the  secant  equation  (the  secant  equation\nrepresentsnlinear equations, but the symmetric matrixH\nt+1\nhasn(n+ 1)/2\ndegrees of freedom). To resolve this issue we choose the closest matrix to\nH\nt\nwhich satisfies the secant equation. The key insight of the BFGS comes\nfrom the observation that the descent direction computation (3.78) involves\nthe inverse matrixB\nt\n:=H\n−1\nt\n. Therefore, we choose a matrixB\nt+1\n:=H\n−1\nt+1\nsuch that it is close toB\nt\nand also satisfies the secant equation:\nmin\nB\n‖B−B\nt\n‖(3.85)\ns. t.B=B\n>\nandBy\nt\n=s\nt\n.(3.86)\nIf the matrix norm‖·‖is appropriately chosen [NW99], then it can be shown\nthat\nB\nt+1\n= (1−ρ\nt\ns\nt\ny\n>\nt\n)B\nt\n(1−ρ\nt\ny\nt\ns\n>\nt\n) +ρ\nt\ns\nt\ns\n>\nt\n,(3.87)\n\n1203  Optimization\nAlgorithm 3.5LBFGS\n1:Input:Initial pointw\n0\n, gradient norm tolerance\u000f >0\n2:Sett= 0 andB\n0\n=I\n3:while‖∇J(w\nt\n)‖> \u000fdo\n4:p\nt\n=−B\nt\n∇J(w\nt\n)\n5:Findη\nt\nthat obeys (3.42) and (3.43)\n6:s\nt\n=η\nt\np\nt\n7:w\nt+1\n=w\nt\n+s\nt\n8:y\nt\n:=∇J(w\nt+1\n)−∇J(w\nt\n)\n9:ift= 0 :B\nt\n:=\ns\n>\nt\ny\nt\ny\n>\nt\ny\nt\nI\n10:ρ\nt\n= (s\n>\nt\ny\nt\n)\n−1\n11:B\nt+1\n= (I−ρ\nt\ns\nt\ny\n>\nt\n)B\nt\n(I−ρ\nt\ny\nt\ns\n>\nt\n) +ρ\nt\ns\nt\ns\n>\nt\n12:t=t+ 1\n13:end while\n14:Return:w\nt\nwhereρ\nt\n:=  (y\n>\nt\ns\nt\n)\n−1\n.  In  other  words,  the  matrixB\nt\nis  modified  via  an\nincremental rank-two update, which is very efficient to compute, to obtain\nB\nt+1\n.\nThere exists an interesting connection between the BFGS update (3.87)\nand the Hestenes-Stiefel variant of Conjugate gradient. To see this assume\nthat an exact line search was used to computew\nt+1\n, and therefores\n>\nt\n∇J(w\nt+1\n) =\n0. Furthermore, assume thatB\nt\n=1, and use (3.87) to write\np\nt+1\n=−B\nt+1\n∇J(w\nt+1\n) =−∇J(w\nt+1\n) +\ny\n>\nt\n∇J(w\nt+1\n)\ny\n>\nt\ns\nt\ns\nt\n,(3.88)\nwhich recovers the Hestenes-Stiefel update (see (3.60e) and Table 3.2).\nLimited-memory BFGS (LBFGS) is a variant of BFGS designed for solv-\ning large-scale optimization problems where theO(d\n2\n) cost of storing and\nupdatingB\nt\nwould  be  prohibitively  expensive.  LBFGS  approximates  the\nquasi-Newton direction (3.78) directly from the lastmpairs ofs\nt\nandy\nt\nvia\na matrix-free approach. This reduces the cost toO(md) space and time per\niteration, withmfreely chosen. Details can be found in Algorithm 3.5.\n3.2.6.2  Spectral Gradient Methods\nAlthough spectral gradient methods do not use the Hessian explicitly, they\nare motivated by arguments very reminiscent of the Quasi-Newton methods.\nRecall the update rule (3.79) and secant equation (3.83). Suppose we want\n\n3.2  Unconstrained Smooth Convex Minimization121\na very simple matrix which approximates the Hessian. Specifically, we want\nH\nt+1\n=α\nt+1\nI(3.89)\nwhereα\nt+1\nis a scalar andIdenotes the identity matrix. Then the secant\nequation (3.83) becomes\nα\nt+1\ns\nt\n=y\nt\n.(3.90)\nIn general, the above equation cannot be solved. Therefore we use theα\nt+1\nwhich minimizes‖α\nt+1\ns\nt\n−y\nt\n‖\n2\nwhich yields the Barzilai-Borwein (BB) step-\nsize\nα\nt+1\n=\ns\n>\nt\ny\nt\ns\n>\nt\ns\nt\n.(3.91)\nAs it turns out,α\nt+1\nlies between the minimum and maximum eigenvalue of\nthe average Hessian in the directions\nt\n, hence the name Spectral Gradient\nmethod. The parameter update (3.79) is now given by\nw\nt+1\n=w\nt\n−\n1\nα\nt\n∇J(w\nt\n).(3.92)\nA practical implementation uses safeguards to ensure that the stepsizeα\nt+1\nis neither too small nor too large. Given 0< α\nmin\n< α\nmax\n<∞we compute\nα\nt+1\n= min\n(\nα\nmax\n,max\n(\nα\nmin\n,\ns\n>\nt\ny\nt\ns\n>\nt\ns\nt\n))\n.(3.93)\nOne  of  the  peculiar  features  of  spectral  gradient  methods  is  their  use\nof  a  non-monotone  line  search.  In  all  the  algorithms  we  have  seen  so  far,\nthe stepsize is chosen such that the objective functionJdecreases at every\niteration. In contrast, non-monotone line searches employ a parameterM≥\n1 and ensure that the objective function decreases in everyMiterations. Of\ncourse, settingM= 1 results in the usual monotone line search. Details can\nbe found in Algorithm 3.6.\n3.2.7  Bundle Methods\nThe methods we discussed above are applicable for minimizing smooth, con-\nvex objective functions. Some regularized risk minimization problems involve\na  non-smooth  objective  function.  In  such  cases,  one  needs  to  use  bundle\nmethods. In order to lay the ground for bundle methods we first describe\ntheir precursor the cutting plane method [Kel60]. Cutting plane method is\nbased on a simple observation: A convex function is bounded from below by\n\n1223  Optimization\nAlgorithm 3.6Spectral Gradient Method\n1:Input:w\n0\n,M≥1,α\nmax\n> α\nmin\n>0,γ∈(0,1),  1> σ\n2\n> σ\n1\n>0,\nα\n0\n∈[α\nmin\n,α\nmax\n], and\u000f >0\n2:Initialize:t= 0\n3:while‖∇J(w\nt\n)‖> \u000fdo\n4:λ= 1\n5:while TRUE do\n6:d\nt\n=−\n1\nα\nt\n∇J(w\nt\n)\n7:w\n+\n=w\nt\n+λd\nt\n8:δ=〈d\nt\n,∇J(w\nt\n)〉\n9:ifJ(w\n+\n)≤min\n0≤j≤min(t,M−1)\nJ(x\nt−j\n) +γλδthen\n10:w\nt+1\n=w\n+\n11:s\nt\n=w\nt+1\n−w\nt\n12:y\nt\n=∇J(w\nt+1\n)−∇J(w\nt\n)\n13:break\n14:else\n15:λ\ntmp\n=−\n1\n2\nλ\n2\nδ/(J(w\n+\n)−J(w\nt\n)−λδ)\n16:ifλ\ntmp\n> σ\n1\nandλ\ntmp\n< σ\n2\nλthen\n17:λ=λ\ntmp\n18:else\n19:λ=λ/2\n20:end if\n21:end if\n22:end while\n23:α\nt+1\n= min(α\nmax\n,max(α\nmin\n,\ns\n>\nt\ny\nt\ns\n>\nt\ns\nt\n))\n24:t=t+ 1\n25:end while\n26:Return:w\nt\nits linearization (i.e.,first order Taylor approximation). See Figures 3.4 and\n3.5 for geometric intuition, and recall (3.7) and (3.13):\nJ(w)≥J(w\n′\n) +\n〈\nw−w\n′\n,s\n′\n〉\n∀wands\n′\n∈∂J(w\n′\n).(3.94)\nGiven subgradientss\n1\n,s\n2\n,...,s\nt\nevaluated at locationsw\n0\n,w\n1\n,...,w\nt−1\n, we\ncan construct a tighter (piecewise linear) lower bound forJas follows (also\nsee Figure 3.10):\nJ(w)≥J\nCP\nt\n(w) :=  max\n1≤i≤t\n{J(w\ni−1\n) +〈w−w\ni−1\n,s\ni\n〉}.(3.95)\n\n3.2  Unconstrained Smooth Convex Minimization123\nGiven iterates{w\ni\n}\nt−1\ni=0\n, the cutting plane method minimizesJ\nCP\nt\nto obtain\nthe next iteratew\nt\n:\nw\nt\n:= argmin\nw\nJ\nCP\nt\n(w).(3.96)\nThis iteratively refines the piecewise linear lower boundJ\nCP\nand allows us\nto get close to the minimum ofJ(see Figure 3.10 for an illustration).\nIfw\n∗\ndenotes the minimizer ofJ, then clearly eachJ(w\ni\n)≥J(w\n∗\n) and\nhence  min\n0≤i≤t\nJ(w\ni\n)≥J(w\n∗\n).  On  the  other  hand,  sinceJ≥J\nCP\nt\nit  fol-\nlows thatJ(w\n∗\n)≥J\nCP\nt\n(w\nt\n). In other words,J(w\n∗\n) is sandwiched between\nmin\n0≤i≤t\nJ(w\ni\n) andJ\nCP\nt\n(w\nt\n) (see Figure 3.11 for an illustration). The cutting\nplane method monitors the monotonically decreasing quantity\n\u000f\nt\n:=  min\n0≤i≤t\nJ(w\ni\n)−J\nCP\nt\n(w\nt\n),(3.97)\nand terminates whenever\u000f\nt\nfalls below a predefined threshold\u000f. This ensures\nthat the solutionJ(w\nt\n) is\u000foptimum, that is,J(w\nt\n)≤J(w\n∗\n) +\u000f.\nFig. 3.10.  A convex function (blue solid curve) is bounded from below by its lin-\nearizations (dashed lines). The gray area indicates the piecewise linear lower bound\nobtained by using the linearizations. We depict a few iterations of the cutting plane\nmethod. At each iteration the piecewise linear lower bound is minimized and a new\nlinearization is added at the minimizer (red rectangle). As can be seen, adding more\nlinearizations improves the lower bound.\nAlthough cutting plane method was shown to be convergent [Kel60], it is\n\n1243  Optimization\nFig. 3.11.  A convex function (blue solid curve) with four linearizations evaluated at\nfour different locations (magenta circles). The approximation gap\u000f\n3\nat the end of\nfourth iteration is indicated by the height of the cyan horizontal bandi.e.,difference\nbetween lowest value ofJ(w) evaluated so far and the minimum ofJ\nCP\n4\n(w) (red\ndiamond).\nwell known (seee.g.,[LNN95, Bel05]) that it can be very slow when new\niterates  move  too  far  away  from  the  previous  ones  (i.e.,causing  unstable\n“zig-zag”  behavior  in  the  iterates).  In  fact,  in  the  worst  case  the  cutting\nplane method might require exponentially many steps to converge to an\u000f\noptimum solution.\nBundle methods stabilize CPM by augmenting the piecewise linear lower\n(e.g.,J\nCP\nt\n(w) in (3.95)) with a prox-function (i.e.,proximity control func-\ntion)  which  prevents  overly  large  steps  in  the  iterates  [Kiw90].  Roughly\nspeaking,  there  are  3  popular  types  of  bundle  methods,  namely,proximal\n[Kiw90],trust  region[SZ92], andlevel  set[LNN95]. All three versions use\n1\n2\n‖·‖\n2\nas their prox-function, but differ in the way they compute the new\niterate:\nproximal:w\nt\n:= argmin\nw\n{\nζ\nt\n2\n‖w−ˆw\nt−1\n‖\n2\n+J\nCP\nt\n(w)},(3.98)\ntrust region:w\nt\n:= argmin\nw\n{J\nCP\nt\n(w)|\n1\n2\n‖w−ˆw\nt−1\n‖\n2\n≤κ\nt\n},(3.99)\nlevel set:w\nt\n:= argmin\nw\n{\n1\n2\n‖w−ˆw\nt−1\n‖\n2\n|J\nCP\nt\n(w)≤τ\nt\n},(3.100)\nwhere  ˆw\nt−1\nis the current prox-center, andζ\nt\n,κ\nt\n,andτ\nt\nare positive trade-\noff  parameters  of  the  stabilization.  Although  (3.98)  can  be  shown  to  be\nequivalent to (3.99) for appropriately chosenζ\nt\nandκ\nt\n, tuningζ\nt\nis rather\ndifficult while a trust region approach can be used for automatically tuning\n\n3.3  Constrained Optimization125\nκ\nt\n. Consequently the trust region algorithm BT of [SZ92] is widely used in\npractice.\n3.3  Constrained Optimization\nSo  far  our  focus  was  on  unconstrained  optimization  problems.  Many  ma-\nchine learning problems involve constraints, and can often be written in the\nfollowing canonical form:\nmin\nw\nJ(w)(3.101a)\ns. t.c\ni\n(w)≤0 fori∈I(3.101b)\ne\ni\n(w) = 0 fori∈E(3.101c)\nwhere bothc\ni\nande\ni\nare convex functions. We say thatwis feasible if and\nonly if it satisfies the constraints, that is,c\ni\n(w)≤0 fori∈Iande\ni\n(w) = 0\nfori∈E.\nRecall thatwis the minimizer of an unconstrained problem if and only if\n‖∇J(w)‖= 0 (see Lemma 3.6). Unfortunately, when constraints are present\none cannot use this simple characterization of the solution. For instance, the\nwat which‖∇J(w)‖= 0 may not be a feasible point. To illustrate, consider\nthe following simple minimization problem (see Figure 3.12):\nmin\nw\n1\n2\nw\n2\n(3.102a)\ns. t.  1≤w≤2.(3.102b)\nClearly,\n1\n2\nw\n2\nis minimized atw= 0, but because of the presence of the con-\nstraints, the minimum of  (3.102) is attained atw= 1 where∇J(w) =wis\nequal to 1. Therefore, we need other ways to detect convergence. In Section\n3.3.1 we discuss some general purpose algorithms based on the concept of or-\nthogonal projection. In Section 3.3.2 we will discuss Lagrange duality, which\ncan be used to further characterize the solutions of constrained optimization\nproblems.\n3.3.1  Projection Based Methods\nSuppose we are interested in minimizing a smooth convex function of the\nfollowing form:\nmin\nw∈Ω\nJ(w),(3.103)\n\n1263  Optimization\n6\n4\n202\n4\n6\nw\n0\n2\n4\n6\n8\n10\n12\n14\nJ(w)\nFig. 3.12.  The unconstrained minimum of the quadratic function\n1\n2\nw\n2\nis attained\natw= 0 (red circle). But, if we enforce the constraints 1≤w≤2 (illustrated by\nthe shaded area) then the minimizer is attained atw= 1 (green diamond).\nwhere Ω is a convex feasible region. For instance, Ω may be described by\nconvex functionsc\ni\nande\ni\nas in (3.101). The algorithms we describe in this\nsection are applicable when Ω is a relatively simple set onto which we can\ncompute an orthogonal projection. Given a pointw\n′\nand a feasible region\nΩ, the orthogonal projectionP\nΩ\n(w\n′\n) ofw\n′\non Ω is defined as\nP\nΩ\n(w\n′\n) := argmin\nw∈Ω\n∥\n∥\nw\n′\n−w\n∥\n∥\n2\n.(3.104)\nGeometrically speaking,P\nΩ\n(w\n′\n) is the closest point tow\n′\nin Ω. Of course, if\nw\n′\n∈Ω thenP\nΩ\n(w\n′\n) =w\n′\n.\nWe are interested in finding an approximate solution of  (3.103), that is,\naw∈Ω such that\nJ(w)−min\nw∈Ω\nJ(w) =J(w)−J\n∗\n≤\u000f,(3.105)\nfor some pre-defined tolerance\u000f >0. Of course,J\n∗\nis unknown and hence the\ngapJ(w)−J\n∗\ncannot be computed in practice. Furthermore, as we showed\nin  Section  3.3,  for  constrained  optimization  problems‖∇J(w)‖does  not\nvanish at the optimal solution. Therefore, we will use the following stopping\n\n3.3  Constrained Optimization127\nAlgorithm 3.7Basic Projection Based Method\n1:Input:Initial  pointw\n0\n∈Ω,  and  projected  gradient  norm  tolerance\n\u000f >0\n2:Initialize:t= 0\n3:while‖P\nΩ\n(w\nt\n−∇J(w\nt\n))−w\nt\n‖> \u000fdo\n4:Find direction of descentd\nt\n5:w\nt+1\n=P\nΩ\n(w\nt\n+η\nt\nd\nt\n)\n6:t=t+ 1\n7:end while\n8:Return:w\nt\ncriterion in our algorithms\n‖P\nΩ\n(w\nt\n−∇J(w\nt\n))−w\nt\n‖≤\u000f.(3.106)\nThe  intuition  here  is  as  follows:  Ifw\nt\n− ∇J(w\nt\n)∈Ω  thenP\nΩ\n(w\nt\n−\n∇J(w\nt\n)) =w\nt\nif, and only if,∇J(w\nt\n) = 0, that is,w\nt\nis the global minimizer\nofJ(w). On the other hand, ifw\nt\n−∇J(w\nt\n)/∈Ω butP\nΩ\n(w\nt\n−∇J(w\nt\n)) =w\nt\n,\nthen  the  constraints  are  preventing  us  from  making  any  further  progress\nalong the descent direction−∇J(w\nt\n) and hence we should stop.\nThe  basic  projection  based  method  is  described  in  Algorithm  3.7.  Any\nunconstrained optimization algorithm can be used to generate the direction\nof  descentd\nt\n.  A  line  search  is  used  to  find  the  stepsizeη\nt\n.  The  updated\nparameterw\nt\n−η\nt\nd\nt\nis projected onto Ω to obtainw\nt+1\n. Ifd\nt\nis chosen to\nbe the negative gradient direction−∇J(w\nt\n), then the resulting algorithm\nis  called  the  projected  gradient  method.  One  can  show  that  the  rates  of\nconvergence  of  gradient  descent  with  various  line  search  schemes  is  also\npreserved by projected gradient descent.\n3.3.2  Lagrange Duality\nLagrange  duality  plays  a  central  role  in  constrained  convex  optimization.\nThe  basic  idea  here  is  to  augment  the  objective  function  (3.101)  with  a\nweighted sum of the constraint functions by defining the Lagrangian:\nL(w,α,β) =J(w) +\n∑\ni∈I\nα\ni\nc\ni\n(w) +\n∑\ni∈E\nβ\ni\ne\ni\n(w)(3.107)\nforα\ni\n≥0 andβ\ni\n∈R. In the sequel, we will refer toα(respectivelyβ) as the\nLagrange multipliers associated with the inequality (respectively equality)\nconstraints. Furthermore, we will callαandβdual feasible if and only if\n\n1283  Optimization\nα\ni\n≥0  andβ\ni\n∈R.  The  Lagrangian  satisfies  the  following  fundamental\nproperty, which makes it extremely useful for constrained optimization.\nTheorem 3.20The Lagrangian(3.107)of(3.101)satisfies\nmax\nα≥0,β\nL(w,α,β) =\n{\nJ(w)ifwis feasible\n∞otherwise.\nIn particular, ifJ\n∗\ndenotes the optimal value of(3.101), then\nJ\n∗\n= min\nw\nmax\nα≥0,β\nL(w,α,β).\nProofFirst  assume  thatwis  feasible,  that  is,c\ni\n(w)≤0  fori∈Iand\ne\ni\n(w) = 0 fori∈E. Sinceα\ni\n≥0 we have\n∑\ni∈I\nα\ni\nc\ni\n(w) +\n∑\ni∈E\nβ\ni\ne\ni\n(w)≤0,(3.108)\nwith equality being attained by settingα\ni\n= 0 wheneverc\ni\n(w)<0. Conse-\nquently,\nmax\nα≥0,β\nL(w,α,β) =  max\nα≥0,β\nJ(w) +\n∑\ni∈I\nα\ni\nc\ni\n(w) +\n∑\ni∈E\nβ\ni\ne\ni\n(w) =J(w)\nwheneverwis feasible. On the other hand, ifwis not feasible then either\nc\ni\n′\n(w)>0 ore\ni\n′\n(w)6= 0 for somei\n′\n. In the first case simply letα\ni\n′\n→∞to\nsee that max\nα≥0,β\nL(w,α,β)→ ∞. Similarly, whene\ni\n′\n(w)6= 0 letβ\ni\n′\n→ ∞\nife\ni\n′\n(w)>0 orβ\ni\n′\n→−∞ife\ni\n′\n(w)<0 to arrive at the same conclusion.\nIf define the Lagrange dual function\nD(α,β) = min\nw\nL(w,α,β),(3.109)\nforα≥0 andβ, then one can prove the following property, which is often\ncalled asweak duality.\nTheorem 3.21 (Weak Duality)The Lagrange dual function(3.109)sat-\nisfies\nD(α,β)≤J(w)\nfor all feasiblewandα≥0andβ. In particular\nD\n∗\n:=  max\nα≥0,β\nmin\nw\nL(w,α,β)≤min\nw\nmax\nα≥0,β\nL(w,α,β) =J\n∗\n.(3.110)\n\n3.3  Constrained Optimization129\nProofAs before, observe that wheneverwis feasible\n∑\ni∈I\nα\ni\nc\ni\n(w) +\n∑\ni∈E\nβ\ni\ne\ni\n(w)≤0.\nTherefore\nD(α,β) = min\nw\nL(w,α,β) = min\nw\nJ(w) +\n∑\ni∈I\nα\ni\nc\ni\n(w) +\n∑\ni∈E\nβ\ni\ne\ni\n(w)≤J(w)\nfor all feasiblewandα≥0 andβ. In particular, one can choosewto be\nthe minimizer of  (3.101) andα≥0 andβto be maximizers ofD(α,β) to\nobtain (3.110).\nWeak duality holds for any arbitrary function, not-necessarily convex. When\nthe objective function and constraints are convex, and certain technical con-\nditions, also known as Slater’s conditions hold, then we can say more.\nTheorem 3.22 (Strong Duality)Supposed  the  objective  functionfand\nconstraintsc\ni\nfori∈Iande\ni\nfori∈Ein(3.101)are  convex  and  the\nfollowing constraint qualification holds:\nThere exists awsuch thatc\ni\n(w)<0for alli∈I.\nThen the Lagrange dual function(3.109)satisfies\nD\n∗\n:=  max\nα≥0,β\nmin\nw\nL(w,α,β) = min\nw\nmax\nα≥0,β\nL(w,α,β) =J\n∗\n.(3.111)\nThe  proof  of  the  above  theorem  is  quite  technical  and  can  be  found  in\nany standard reference (e.g.,[BV04]). Therefore we will omit the proof and\nproceed to discuss various implications of strong duality. First note that\nmin\nw\nmax\nα≥0,β\nL(w,α,β) =  max\nα≥0,β\nmin\nw\nL(w,α,β).(3.112)\nIn other words, one can switch the order of minimization overwwith max-\nimization overαandβ. This is called thesaddle  point  propertyof convex\nfunctions.\nSuppose strong duality holds. Given anyα≥0 andβsuch thatD(α,β)>\n−∞and a feasiblewwe can immediately write theduality gap\nJ(w)−J\n∗\n=J(w)−D\n∗\n≤J(w)−D(α,β),\nwhereJ\n∗\nandD\n∗\nwere defined in (3.111). Below we show that ifw\n∗\nis primal\noptimal  and  (α\n∗\n,β\n∗\n)  are  dual  optimal  thenJ(w\n∗\n)−D(α\n∗\n,β\n∗\n)  =  0.  This\nprovides a non-heuristic stopping criterion for constrained optimization: stop\nwhenJ(w)−D(α,β)≤\u000f, where\u000fis a pre-specified tolerance.\n\n1303  Optimization\nSuppose  the  primal  and  dual  optimal  values  are  attained  atw\n∗\nand\n(α\n∗\n,β\n∗\n) respectively, and consider the following line of argument:\nJ(w\n∗\n) =D(α\n∗\n,β\n∗\n)(3.113a)\n= min\nw\nJ(w) +\n∑\ni∈I\nα\n∗\ni\nc\ni\n(w) +\n∑\ni∈E\nβ\n∗\ni\ne\nj\n(w)(3.113b)\n≤J(w\n∗\n) +\n∑\ni∈I\nα\n∗\ni\nc\ni\n(w\n∗\n) +\n∑\ni∈E\nβ\n∗\ni\ne\ni\n(w\n∗\n)(3.113c)\n≤J(w\n∗\n).(3.113d)\nTo write (3.113a) we used strong duality, while (3.113c) obtains by setting\nw=w\n∗\nin (3.113c). Finally, to obtain (3.113d) we used the fact thatw\n∗\nis\nfeasible and hence (3.108) holds. Since (3.113) holds with equality, one can\nconclude that the followingcomplementary slackness condition:\n∑\ni∈I\nα\n∗\ni\nc\ni\n(w\n∗\n) +\n∑\ni∈E\nβ\n∗\ni\ne\ni\n(w\n∗\n) = 0.\nIn other words,α\n∗\ni\nc\ni\n(w\n∗\n) = 0 or equivalentlyα\n∗\ni\n= 0 wheneverc\ni\n(w)<0.\nFurthermore,  sincew\n∗\nminimizesL(w,α\n∗\n,β\n∗\n)  overw,  it  follows  that  its\ngradient must vanish atw\n∗\n, that is,\n∇J(w\n∗\n) +\n∑\ni∈I\nα\n∗\ni\n∇c\ni\n(w\n∗\n) +\n∑\ni∈E\nβ\n∗\ni\n∇e\ni\n(w\n∗\n) = 0.\nPutting everything together, we obtain\nc\ni\n(w\n∗\n)≤0∀i∈I(3.114a)\ne\nj\n(w\n∗\n) = 0∀i∈E(3.114b)\nα\n∗\ni\n≥0(3.114c)\nα\n∗\ni\nc\ni\n(w\n∗\n) = 0(3.114d)\n∇J(w\n∗\n) +\n∑\ni∈I\nα\n∗\ni\n∇c\ni\n(w\n∗\n) +\n∑\ni∈E\nβ\n∗\ni\n∇e\ni\n(w\n∗\n) = 0.(3.114e)\nThe above conditions are called the KKT conditions. If the primal problem is\nconvex, then the KKT conditions are both necessary and sufficient. In other\nwords, if  ˆwand ( ˆα,\nˆ\nβ) satisfy (3.114) then  ˆwand ( ˆα,\nˆ\nβ) are primal and dual\noptimal with zero duality gap. To see this note that the first two conditions\nshow that  ˆwis feasible. Sinceα\ni\n≥0,L(w,α,β) is convex inw. Finally the\nlast  condition  states  that  ˆwminimizesL(w,ˆα,\nˆ\nβ).  Since  ˆα\ni\nc\ni\n( ˆw)  =  0  and\n\n3.3  Constrained Optimization131\ne\nj\n( ˆw) = 0, we have\nD( ˆα,\nˆ\nβ) = min\nw\nL(w,ˆα,\nˆ\nβ)\n=J( ˆw) +\nn\n∑\ni=1\nˆα\ni\nc\ni\n( ˆw) +\nm\n∑\nj=1\nˆ\nβ\nj\ne\nj\n( ˆw)\n=J( ˆw).\n3.3.3  Linear and Quadratic Programs\nSo far we discussed general constrained optimization problems. Many ma-\nchine learning problems have special structure which can be exploited fur-\nther. We discuss the implication of duality for two such problems.\n3.3.3.1  Linear Programming\nAn optimization problem with a linear objective function and (both equality\nand  inequality)  linear  constraints  is  said  to  be  a  linear  program  (LP).  A\ncanonical linear program is of the following form:\nmin\nw\nc\n>\nw(3.115a)\ns. t.Aw=b,w≥0.(3.115b)\nHerewandcarendimensional vectors, whilebis amdimensional vector,\nandAis am×nmatrix withm < n.\nSuppose we are given a LP of the form:\nmin\nw\nc\n>\nw(3.116a)\ns. t.Aw≥b,(3.116b)\nwe can transform it into a canonical LP by introducing non-negative slack\nvariables\nmin\nw,ξ\nc\n>\nw(3.117a)\ns. t.Aw−ξ=b,ξ≥0.(3.117b)\nNext,  we  splitwinto  its  positive  and  negative  partsw\n+\nandw\n−\nrespec-\ntively by settingw\n+\ni\n= max(0,w\ni\n) andw\n−\ni\n= max(0,−w\ni\n). Using these new\n\n1323  Optimization\nvariables we rewrite (3.117) as\nmin\nw\n+\n,w\n−\n, ξ\n\n\nc\n−c\n0\n\n\n>\n\n\nw\n+\nw\n−\nξ\n\n\n(3.118a)\ns. t.\n[\nA−A−I\n]\n\n\nw\n+\nw\n−\nξ\n\n\n=b,\n\n\nw\n+\nw\n−\nξ\n\n\n≥0,(3.118b)\nthus yielding a canonical LP (3.115) in the variablesw\n+\n,w\n−\nandξ.\nBy introducing non-negative Lagrange multipliersαandβone can write\nthe Lagrangian of (3.115) as\nL(w,β,s) =c\n>\nw+β\n>\n(Aw−b)−α\n>\nw.(3.119)\nTaking gradients with respect to the primal and dual variables and setting\nthem to zero obtains\nA\n>\nβ−α=c(3.120a)\nAw=b(3.120b)\nα\n>\nw= 0(3.120c)\nw≥0(3.120d)\nα≥0.(3.120e)\nCondition (3.120c) can be simplified by noting that bothwandαare con-\nstrained to be non-negative, thereforeα\n>\nw= 0 if, and only if,α\ni\nw\ni\n= 0 for\ni= 1,...,n.\nUsing (3.120a), (3.120c), and (3.120b) we can write\nc\n>\nw= (A\n>\nβ−α)\n>\nw=β\n>\nAw=β\n>\nb.\nSubstituting this into (3.115) and eliminating the primal variablewyields\nthe following dual LP\nmax\nα,β\nb\n>\nβ(3.121a)\ns.t.A\n>\nβ−α=c,α≥0.(3.121b)\nAs  before,  we  letβ\n+\n=  max(β,0)  andβ\n−\n=  max(0,−β)  and  convert  the\n\n3.3  Constrained Optimization133\nabove LP into the following canonical LP\nmax\nα,β\n+\n,β\n−\n\n\nb\n−b\n0\n\n\n>\n\n\nβ\n+\nβ\n−\nα\n\n\n(3.122a)\ns.t.\n[\nA\n>\n−A\n>\n−I\n]\n\n\nβ\n+\nβ\n−\nα\n\n\n=c,\n\n\nβ\n+\nβ\n−\nα\n\n\n≥0.(3.122b)\nIt can be easily verified that the primal-dual problem is symmetric; by taking\nthe dual of the dual we recover the primal (Problem 3.17). One important\nthing  to  note  however  is  that  the  primal  (3.115)  involvesnvariables  and\nn+mconstraints,  while  the  dual  (3.122)  involves  2m+nvariables  and\n4m+ 2nconstraints.\n3.3.3.2  Quadratic Programming\nAn optimization problem with a convex quadratic objective function and lin-\near constraints is said to be a convex quadratic program (QP). The canonical\nconvex QP can be written as follows:\nmin\nw\n1\n2\nw\n>\nGx+w\n>\nd(3.123a)\ns.t.a\n>\ni\nw=b\ni\nfori∈E(3.123b)\na\n>\ni\nw≤b\ni\nfori∈I(3.123c)\nHereG\u00170 is an×npositive semi-definite matrix,EandIare finite set of\nindices, whiledanda\ni\narendimensional vectors, andb\ni\nare scalars.\nAs a warm up let us consider the arguably simpler equality constrained\nquadratic programs. In this case, we can stack thea\ni\ninto a matrixAand\ntheb\ni\ninto a vectorbto write\nmin\nw\n1\n2\nw\n>\nGw+w\n>\nd(3.124a)\ns.t.Aw=b(3.124b)\nBy introducing non-negative Lagrange multipliersβthe Lagrangian of the\nabove optimization problem can be written as\nL(w,β) =\n1\n2\nw\n>\nGw+w\n>\nd+β(Aw−b).(3.125)\nTo find the saddle point of the Lagrangian we take gradients with respect\n\n1343  Optimization\ntowandβand set them to zero. This obtains\nGw+d+A\n>\nβ= 0\nAw=b.\nPutting these two conditions together yields the following linear system of\nequations\n[\nG A\n>\nA0\n][\nw\nβ\n]\n=\n[\n−d\nb\n]\n.(3.126)\nThe matrix in the above equation is called the KKT matrix, and we can use\nit to characterize the conditions under which (3.124) has a unique solution.\nTheorem 3.23LetZbe an×(n−m)matrix whose columns form a basis\nfor  the  null  space  ofA,  that  is,AZ=  0.  IfAhas  full  row  rank,  and  the\nreduced-Hessian matrixZ\n>\nGZis positive definite, then there exists a unique\npair(w\n∗\n,β\n∗\n)which solves(3.126). Furthermore,w\n∗\nalso minimizes(3.124).\nProofNote  that  a  unique  (w\n∗\n,β\n∗\n)  exists  whenever  the  KKT  matrix  is\nnon-singular. Suppose this is not the case, then there exist non-zero vectors\naandbsuch that\n[\nG A\n>\nA0\n][\na\nb\n]\n= 0.\nSinceAa= 0 this implies thatalies in the null space ofAand hence there\nexists ausuch thata=Zu. Therefore\n[\nZu0\n]\n[\nG A\n>\nA0\n][\nZu\n0\n]\n=u\n>\nZ\n>\nGZu= 0.\nPositive definiteness ofZ\n>\nGZimplies thatu= 0 and hencea= 0. On the\nother  hand,  the  full  row  rank  ofAandA\n>\nb=  0  implies  thatb=  0.  In\nsummary, bothaandbare zero, a contradiction.\nLetw6=w\n∗\nbe any other feasible point and ∆w=w\n∗\n−w. SinceAw\n∗\n=\nAw=bwe have thatA∆w= 0. Hence, there exists a non-zerousuch that\n∆w=Zu. The objective functionJ(w) can be written as\nJ(w) =\n1\n2\n(w\n∗\n−∆w)\n>\nG(w\n∗\n−∆w) + (w\n∗\n−∆w)\n>\nd\n=J(w\n∗\n) +\n1\n2\n∆w\n>\nG∆w−(Gw\n∗\n+d)\n>\n∆w.\nFirst note that\n1\n2\n∆w\n>\nG∆w=\n1\n2\nu\n>\nZ\n>\nGZu >0 by positive definiteness of\nthe reduced Hessian. Second, sincew\n∗\nsolves (3.126) it follows that (Gw\n∗\n+\n\n3.4  Stochastic Optimization135\nd)\n>\n∆w=β\n>\nA∆w= 0. Together these two observations imply thatJ(w)>\nJ(w\n∗\n).\nIf the technical conditions of the above theorem are met, then solving the\nequality constrained QP (3.124) is equivalent to solving the linear system\n(3.126).  See  [NW99]  for  a  extensive  discussion  of  algorithms  that  can  be\nused for this task.\nNext we turn our attention to the general QP (3.123) which also contains\ninequality constraints. The Lagrangian in this case can be written as\nL(w,β) =\n1\n2\nw\n>\nGw+w\n>\nd+\n∑\ni∈I\nα\ni\n(a\n>\ni\nw−b\ni\n) +\n∑\ni∈E\nβ\ni\n(a\n>\ni\nw−b\ni\n).(3.127)\nLetw\n∗\ndenote the minimizer of (3.123). If we define the active setA(w\n∗\n) as\nA(w\n∗\n) =\n{\nis.t.i∈Ianda\n>\ni\nw\n∗\n=b\ni\n}\n,\nthen the KKT conditions (3.114) for this problem can be written as\na\n>\ni\nw−b\ni\n<0∀i∈I\\A(w\n∗\n)(3.128a)\na\n>\ni\nw−b\ni\n= 0∀i∈E∪A(w\n∗\n)(3.128b)\nα\n∗\ni\n≥0∀i∈A(w\n∗\n)(3.128c)\nGw\n∗\n+d+\n∑\ni∈A(w\n∗\n)\nα\n∗\ni\na\ni\n+\n∑\ni∈E\nβ\ni\na\ni\n= 0.(3.128d)\nConceptually the main difficulty in solving (3.123) is in identifying the active\nsetA(w\n∗\n). This is becauseα\n∗\ni\n= 0 for alli∈I\\A(w\n∗\n). Most algorithms\nfor solving (3.123) can be viewed as different ways to identify the active set.\nSee [NW99] for a detailed discussion.\n3.4  Stochastic Optimization\nRecall that regularized risk minimization involves a data-driven optimization\nproblem in which the objective function involves the summation of loss terms\nover a set of data to be modeled:\nmin\nf\nJ(f) :=λΩ(f) +\n1\nm\nm\n∑\ni=1\nl(f(x\ni\n),y\ni\n).\nClassical optimization techniques must compute this sum in its entirety for\neach evaluation of the objective, respectively its gradient. As available data\nsets grow ever larger, such “batch” optimizers therefore become increasingly\ninefficient. They are also ill-suited for the incremental setting, where partial\ndata must be modeled as it arrives.\n\n1363  Optimization\nStochastic gradient-based methods, by contrast, work with gradient esti-\nmates obtained from small subsamples (mini-batches) of training data. This\ncan  greatly  reduce  computational  requirements:  on  large,  redundant  data\nsets, simple stochastic gradient descent routinely outperforms sophisticated\nsecond-order batch methods by orders of magnitude.\nThe key idea here is thatJ(w) is replaced by an instantaneous estimate\nJ\nt\nwhich is computed from a mini-batch of sizekcomprising of a subset of\npoints (x\nt\ni\n,y\nt\ni\n) withi= 1,...,kdrawn from the dataset:\nJ\nt\n(w) =λΩ(w) +\n1\nk\nk\n∑\ni=1\nl(w,x\nt\ni\n,y\nt\ni\n).(3.129)\nSettingk=  1  obtains  an  algorithm  which  processes  data  points  as  they\narrive.\n3.4.1  Stochastic Gradient Descent\nPerhaps the simplest stochastic optimization algorithm is Stochastic Gradi-\nent Descent (SGD). The parameter update of SGD takes the form:\nw\nt+1\n=w\nt\n−η\nt\n∇J\nt\n(w\nt\n).(3.130)\nIfJ\nt\nis not differentiable, then one can choose an arbitrary subgradient from\n∂J\nt\n(w\nt\n) to compute the update. It has been shown that SGD asymptotically\nconverges to the true minimizer ofJ(w) if the stepsizeη\nt\ndecays asO(1/\n√\nt).\nFor instance, one could set\nη\nt\n=\n√\nτ\nτ+t\n,(3.131)\nwhereτ >0 is a tuning parameter. See Algorithm 3.8 for details.\n3.4.1.1  Practical Considerations\nOne simple yet effective rule of thumb to tuneτis to select a small subset\nof data, try various values ofτon this subset, and choose theτthat most\nreduces the objective function.\nIn some cases lettingη\nt\nto decay asO(1/t) has been found to be more\neffective:\nη\nt\n=\nτ\nτ+t\n.(3.132)\nThe free parameterτ >0 can be tuned as described above. If Ω(w) isσ-\nstrongly convex, then dividing the stepsizeη\nt\nbyσλyields good practical\nperformance.\n\n3.5  Nonconvex Optimization137\nAlgorithm 3.8Stochastic Gradient Descent\n1:Input:Maximum iterationsT, batch sizek, andτ\n2:Sett= 0 andw\n0\n= 0\n3:whilet < Tdo\n4:Choose a subset ofkdata points (x\nt\ni\n,y\nt\ni\n) and compute∇J\nt\n(w\nt\n)\n5:Compute stepsizeη\nt\n=\n√\nτ\nτ+t\n6:w\nt+1\n=w\nt\n−η\nt\n∇J\nt\n(w\nt\n)\n7:t=t+ 1\n8:end while\n9:Return:w\nT\n3.5  Nonconvex Optimization\nOur focus in the previous sections was on convex objective functions. Some-\ntimes non-convex objective functions also arise in machine learning applica-\ntions. These problems are significantly harder and tools for minimizing such\nobjective functions are not as well developed. We briefly describe one algo-\nrithm which can be applied whenever we can write the objective function as\na difference of two convex functions.\n3.5.1  Concave-Convex Procedure\nAny function with a bounded Hessian can be decomposed into the difference\nof two (non-unique) convex functions, that is, one can write\nJ(w) =f(w)−g(w),(3.133)\nwherefandgare  convex  functions.  Clearly,Jis  not  convex,  but  there\nexists a reasonably simple algorithm namely the Concave-Convex Procedure\n(CCP)  for  finding  a  local  minima  ofJ.  The  basic  idea  is  simple:  In  the\nt\nth\niteration  replacegby  its  first  order  Taylor  expansion  atw\nt\n,  that  is,\ng(w\nt\n) +〈w−w\nt\n,∇g(w\nt\n)〉and minimize\nJ\nt\n(w) =f(w)−g(w\nt\n)−〈w−w\nt\n,∇g(w\nt\n)〉.(3.134)\nTaking gradients and setting it to zero shows thatJ\nt\nis minimized by setting\n∇f(w\nt+1\n) =∇g(w\nt\n).(3.135)\nThe iterations of CCP on a toy minimization problem is illustrated in Figure\n3.13, while the complete algorithm listing can be found in Algorithm 3.9.\n\n1383  Optimization\n1.0\n1.5\n2.02.53.03.54.0\n80\n70\n60\n50\n40\n30\n20\n10\n1.0\n1.5\n2.02.53.03.54.0\n50\n0\n50\n100\n150\n200\nFig. 3.13.  Given the function on the left we decompose it into the difference of two\nconvex functions depicted on the right panel. The CCP algorithm generates iterates\nby matching points on the two convex curves which have the same tangent vectors.\nAs can be seen, the iterates approach the solutionx= 2.0.\nAlgorithm 3.9Concave-Convex Procedure\n1:Input:Initial pointw\n0\n, maximum iterationsT, convex functionsf,g\n2:Sett= 0\n3:whilet < Tdo\n4:Setw\nt+1\n= argmin\nw\nf(w)−g(w\nt\n)−〈w−w\nt\n,∇g(w\nt\n)〉\n5:t=t+ 1\n6:end while\n7:Return:w\nT\nTheorem 3.24LetJbe a function which can be decomposed into a differ-\nence of two convex functionse.g., (3.133). The iterates generated by(3.135)\nmonotically decreaseJ. Furthermore, the stationary point of the iterates is\na local minima ofJ.\nProofSincefandgare convex\nf(w\nt\n)≥f(w\nt+1\n) +〈w\nt\n−w\nt+1\n,∇f(w\nt+1\n)〉\ng(w\nt+1\n)≥g(w\nt\n) +〈w\nt+1\n−w\nt\n,∇g(w\nt\n)〉.\nAdding the two inequalities, rearranging, and using (3.135) shows thatJ(w\nt\n) =\nf(w\nt\n)−g(w\nt\n)≥f(w\nt+1\n)−g(w\nt+1\n) =J(w\nt+1\n), as claimed.\nLetw\n∗\nbe  a  stationary  point  of  the  iterates.  Then∇f(w\n∗\n)  =∇g(w\n∗\n),\nwhich in turn implies thatw\n∗\nis a local minima ofJbecause∇J(w\n∗\n) = 0.\nThere are a number of extensions to CCP. We mention only a few in the\npassing. First, it can be shown that all instances of the EM algorithm (Sec-\ntion??) can be shown to be special cases of CCP. Second, the rate of con-\n\n3.6  Some Practical Advice139\nvergence of CCP is related to the eigenvalues of the positive semi-definite\nmatrix∇\n2\n(f+g). Third, CCP can also be extended to solve constrained\nproblems of the form:\nmin\nw\nf\n0\n(w)−g\n0\n(w)\ns.t.f\ni\n(w)−g\ni\n(w)≤c\ni\nfori= 1,...,n.\nwhere, as before,f\ni\nandg\ni\nfori= 0,1,...,nare assumed convex. At every\niteration, we replaceg\ni\nby its first order Taylor approximation and solve the\nfollowing constrained convex problem:\nmin\nw\nf\n0\n(w)−g\n0\n(w\nt\n) +〈w−w\nt\n,∇g\n0\n(w\nt\n)〉\ns.t.f\ni\n(w)−g\ni\n(w\nt\n) +〈w−w\nt\n,∇g\ni\n(w\nt\n)〉≤c\ni\nfori= 1,...,n.\n3.6  Some Practical Advice\nThe range of optimization algorithms we presented in this chapter might be\nsomewhat  intimidating  for  the  beginner.  Some  simple  rules  of  thumb  can\nalleviate this anxiety\nCode Reuse:Implementing an efficient optimization algorithm correctly\nis both time consuming and error prone. Therefore, as far as possible use\nexisting libraries. A number of high class optimization libraries both com-\nmercial and open source exist.\nUnconstrained Problems:For unconstrained minimization of a smooth\nconvex function LBFGS (Section 3.2.6.1 is the algorithm of choice. In many\npractical  situations  the  spectral  gradient  method  (Section  3.2.6.2)  is  also\nvery competitive. It also has the added advantage of being easy to imple-\nment. If the function to be minimized is non-smooth then Bundle methods\n(Section 3.2.7) are to be preferred. Amongst the different formulations, the\nBundle Trust algorithm tends to be quite robust.\nConstrained Problems:For constrained problems it is very important\nto understand the nature of the constraints. Simple equality (Ax=b) and\nbox  (l≤x≤u)  constraints  are  easier  to  handle  than  general  non-linear\nconstraints. If the objective function is smooth, the constraint set Ω is simple,\nand orthogonal projectionsP\nΩ\nare easy to compute, then spectral projected\ngradient (Section 3.3.1) is the method of choice. If the optimization problem\nis a QP or an LP then specialized solvers tend to be much faster than general\npurpose solvers.\n\n1403  Optimization\nLarge Scale Problems:If your parameter vector is high dimensional then\nconsider coordinate descent (Section 3.2.2) especially if the one dimensional\nline search along a coordinate can be carried out efficiently. If the objective\nfunction  is  made  up  of  a  summation  of  large  number  of  terms,  consider\nstochastic gradient descent (Section 3.4.1). Although both these algorithms\ndo not guarantee a very accurate solution, practical experience shows that\nfor large scale machine learning problems this is rarely necessary.\nDuality:Sometimes problems which are hard to optimize in the primal\nmay become simpler in the dual. For instance, if the objective function is\nstrongly  convex  but  non-smooth,  its  Fenchel  conjugate  is  smooth  with  a\nLipschitz continuous gradient.\nProblems\nProblem 3.1 (Intersection of Convex Sets{1})IfC\n1\nandC\n2\nare con-\nvex sets, then show thatC\n1\n∩C\n2\nis also convex. Extend your result to show\nthat\n⋂\nn\ni=1\nC\ni\nare convex ifC\ni\nare convex.\nProblem 3.2 (Linear Transform of Convex Sets{1})Given a setC⊂\nR\nn\nand  a  linear  transformA∈R\nm×n\n,  defineAC:={y=Ax:x∈C}.  If\nCis convex then show thatACis also convex.\nProblem 3.3 (Convex Combinations{1})Show that a subset ofR\nn\nis\nconvex if and only if it contains all the convex combination of its elements.\nProblem 3.4 (Convex Hull{2})Show that the convex hull,conv(X)is\nthe smallest convex set which containsX.\nProblem 3.5 (Epigraph of a Convex Function{2})Show that a func-\ntion satisfies Definition 3.3 if, and only if, its epigraph is convex.\nProblem 3.6Prove the Jensen’s inequality(3.6).\nProblem 3.7 (Strong convexity of the negative entropy{3})Show that\nthe negative entropy(3.15)is 1-strongly convex with respect to the‖·‖\n1\nnorm\non  the  simplex.  Hint:  First  show  thatφ(t) := (t−1) logt−2\n(t−1)\n2\nt+1\n≥0for\nallt≥0. Next substitutet=x\ni\n/y\ni\nto show that\n∑\ni\n(x\ni\n−y\ni\n) log\nx\ni\ny\ni\n≥‖x−y‖\n2\n1\n.\n\n3.6  Some Practical Advice141\nProblem 3.8 (Strongly Convex Functions{2})Prove 3.16, 3.17, 3.18\nand 3.19.\nProblem 3.9 (Convex Functions with Lipschitz Continuous Gradient{2})\nProve 3.22, 3.23, 3.24 and 3.25.\nProblem 3.10 (One Dimensional Projection{1})Iff:R\nd\n→Ris\nconvex, then show that for an arbitraryxandpinR\nd\nthe one dimensional\nfunctionΦ(η) :=f(x+ηp)is also convex.\nProblem 3.11 (Quasi-Convex Functions{2})In Section 3.1 we showed\nthat the below-sets of a convex functionX\nc\n:={x|f(x)≤c}are convex. Give\na counter-example to show that the converse is not true, that is, there exist\nnon-convex functions whose below-sets are convex. This class of functions is\ncalled Quasi-Convex.\nProblem 3.12 (Gradient of thep-norm{1})Show that the gradient of\nthep-norm(3.31)is given by(3.32).\nProblem 3.13Derive the Fenchel conjugate of the following functions\nf(x) =\n{\n0ifx∈C\n∞otherwise.\nwhereCis a convex set\nf(x) =ax+b\nf(x) =\n1\n2\nx\n>\nAxwhereAis a positive definite matrix\nf(x) =−log(x)\nf(x) = exp(x)\nf(x) =xlog(x)\nProblem 3.14 (Convergence of gradient descent{2})SupposeJhas\na Lipschitz continuous gradient with modulusL. Then show that Algorithm\n3.2  with  an  inexact  line  search  satisfying  the  Wolfe  conditions(3.42)and\n(3.43)will return a solutionw\nt\nwith‖∇J(w\nt\n)‖≤\u000fin at mostO(1/\u000f\n2\n)iter-\nations.\nProblem 3.15Show that\n1 +\n∑\nT\nt=1\n1\nt\n∑\nT\nt=1\n1\n√\nt\n≤\n1\n√\nT\n\n1423  Optimization\nProblem 3.16 (Coordinate Descent for Quadratic Programming{2})\nDerive a projection based method which uses coordinate descent to generate\ndirections of descent for solving the following box constrained QP:\nmin\nw∈R\nn\n1\n2\nw\n>\nQw+c\n>\nw\ns.t.l≤w≤u.\nYou may assume thatQis positive definite andlanduare scalars.\nProblem 3.17 (Dual of a LP{1})Show that the dual of the LP(3.122)\nis(3.115).  In  other  words,  we  recover  the  primal  by  computing  the  dual  of\nthe dual.\n\n4\nOnline Learning and Boosting\nSo far the learning algorithms we considered assumed that all the training\ndata is available before building a model for predicting labels on unseen data\npoints. In many modern applications data is available only in a streaming\nfashion, and one needs to predict labels on the fly. To describe a concrete\nexample, consider the task of spam filtering. As emails arrive the learning\nalgorithm needs to classify them as spam or ham. Tasks such as these are\ntackled  via  online  learning.  Online  learning  proceeds  in  rounds.  At  each\nround a training example is revealed to the learning algorithm, which uses\nits  current  model  to  predict  the  label.  The  true  label  is  then  revealed  to\nthe learner which incurs a loss and updates its model based on the feedback\nprovided. This protocol is summarized in Algorithm 4.1. The goal of online\nlearning  is  to  minimize  the  total  loss  incurred.  By  an  appropriate  choice\nof  labels  and  loss  functions,  this  setting  encompasses  a  large  number  of\ntasks such as classification, regression, and density estimation. In our spam\ndetection example, if an email is misclassified the user can provide feedback\nwhich  is  used  to  update  the  spam  filter,  and  the  goal  is  to  minimize  the\nnumber of misclassified emails.\n4.1  Halving Algorithm\nThe halving algorithm is conceptually simple, yet it illustrates many of the\nconcepts in online learning. Suppose we have access to a set ofnexperts,\nthat is, functionsf\ni\nwhich map from the input spaceXto the output space\nY={±1}. Furthermore, assume that one of the experts is consistent, that\nis, there exists aj∈ {1,...,n}such thatf\nj\n(x\nt\n) =y\nt\nfort= 1,...,T. The\nhalving algorithm maintains a setC\nt\nof consistent experts at timet. Initially\nC\n0\n={1,...,n}, and it is updated recursively as\nC\nt+1\n={i∈C\nt\ns.t.f\ni\n(x\nt+1\n) =y\nt+1\n}.(4.1)\nThe prediction on a new data point is computed via a majority vote amongst\nthe consistent experts: ˆy\nt\n= majority(C\nt\n).\nLemma 4.1The Halving algorithm makes at mostlog\n2\n(n)mistakes.\n143\n\n1444  Online Learning and Boosting\nAlgorithm 4.1Protocol of Online Learning\n1:fort= 1,...,Tdodo\n2:Get training instancex\nt\n3:Predict label ˆy\nt\n4:Get true labely\nt\n5:Incur lossl(ˆy\nt\n,x\nt\n,y\nt\n)\n6:Update model\n7:end for\nProofLetMdenote the total number of mistakes. The halving algorithm\nmakes a mistake at iterationtif at least half the consistent expertsC\nt\npredict\nthe wrong label. This in turn implies that\n|C\nt+1\n|≤\n|C\nt\n|\n2\n≤\n|C\n0\n|\n2\nM\n=\nn\n2\nM\n.\nOn  the  other  hand,  since  one  of  the  experts  is  consistent  it  follows  that\n1≤|C\nt+1\n|. Therefore, 2\nM\n≤n. Solving forMcompletes the proof.\n4.2  Weighted Majority\nWe now turn to the scenario where none of the experts is consistent. There-\nfore, the aim here is not to minimize the number mistakes but to minimize\nregret.\nIn this chapter we will consider online methods for solving the following\noptimization problem:\nmin\nw∈Ω\nJ(w) whereJ(w) =\nT\n∑\nt=1\nf\nt\n(w).(4.2)\nSuppose we have access to a functionψwhich is continuously differentiable\nand strongly convex with modulus of strong convexityσ >0 (see Section\n3.1.4  for  definition  of  strong  convexity),  then  we  can  define  the  Bregman\ndivergence (3.29) corresponding toψas\n∆\nψ\n(w,w\n′\n) =ψ(w)−ψ(w\n′\n)−\n〈\nw−w\n′\n,∇ψ(w\n′\n)\n〉\n.\nWe can also generalize the orthogonal projection (3.104) by replacing the\nsquare Euclidean norm with the above Bregman divergence:\nP\nψ,Ω\n(w\n′\n) = argmin\nw∈Ω\n∆\nψ\n(w,w\n′\n).(4.3)\n\n4.2  Weighted Majority145\nAlgorithm 4.2Stochastic (sub)gradient Descent\n1:Input:Initial pointx\n1\n, maximum iterationsT\n2:fort= 1,...,Tdo\n3:Compute  ˆw\nt+1\n=∇ψ\n∗\n(∇ψ(w\nt\n)−η\nt\ng\nt\n) withg\nt\n=∂\nw\nf\nt\n(w\nt\n)\n4:Setw\nt+1\n=P\nψ,Ω\n( ˆw\nt+1\n)\n5:end for\n6:Return:w\nT+1\nDenotew\n∗\n=P\nψ,Ω\n(w\n′\n). Just like the Euclidean distance is non-expansive, the\nBregman projection can also be shown to be non-expansive in the following\nsense:\n∆\nψ\n(w,w\n′\n)≥∆\nψ\n(w,w\n∗\n) + ∆\nψ\n(w\n∗\n,w\n′\n)(4.4)\nfor allw∈Ω. The diameter of Ω as measured by ∆\nψ\nis given by\ndiam\nψ\n(Ω) =  max\nw,w\n′\n∈Ω\n∆\nψ\n(w,w\n′\n).(4.5)\nFor the rest of this chapter we will make the following standard assumptions:\n•Eachf\nt\nis convex and revealed at time instancet.\n•Ω is a closed convex subset ofR\nn\nwith non-empty interior.\n•The diameter diam\nψ\n(Ω) of Ω is bounded byF <∞.\n•The set of optimal solutions of (4.2) denoted by Ω\n∗\nis non-empty.\n•The subgradient∂\nw\nf\nt\n(w) can be computed for everytandw∈Ω.\n•The Bregman projection (4.3) can be computed for everyw\n′\n∈R\nn\n.\n•The gradient∇ψ, and its inverse (∇ψ)\n−1\n=∇ψ\n∗\ncan be computed.\nThe  method  we  employ  to  solve  (4.2)  is  given  in  Algorithm  4.2.  Before\nanalyzing the performance of the algorithm we would like to discuss three\nspecial  cases.  First,  Euclidean  distance  squared  which  recovers  projected\nstochastic gradient descent, second Entropy which recovers Exponentiated\ngradient descent, and third thep-norms forp >2 which recovers thep-norm\nPerceptron. BUGBUG TODO.\nOur key result is Lemma 4.3 given below. It can be found in various guises\nin different places most notably Lemma 2.1 and 2.2 in [?], Theorem 4.1 and\nEq. (4.21) and (4.15) in [?], in the proof of Theorem 1 of [?], as well as Lemma\n3 of [?]. We prove a slightly general variant; we allow for projections with\nan arbitrary Bregman divergence and also take into account a generalized\nversion of strong convexity off\nt\n. Both these modifications will allow us to\ndeal with general settings within a unified framework.\n\n1464  Online Learning and Boosting\nDefinition 4.2We  say  that  a  convex  functionfis  strongly  convex  with\nrespect to another convex functionψwith modulusλif\nf(w)−f(w\n′\n)−\n〈\nw−w\n′\n,μ\n〉\n≥λ∆\nψ\n(w,w\n′\n)for allμ∈∂f(w\n′\n).(4.6)\nThe usual notion of strong convexity is recovered by settingψ(·) =\n1\n2\n‖·‖\n2\n.\nLemma 4.3Letf\nt\nbe strongly convex with respect toψwith modulusλ≥0\nfor allt. For anyw∈Ωthe sequences generated by Algorithm 4.2 satisfy\n∆\nψ\n(w,w\nt+1\n)≤∆\nψ\n(w,w\nt\n)−η\nt\n〈g\nt\n,w\nt\n−w〉+\nη\n2\nt\n2σ\n‖g\nt\n‖\n2\n(4.7)\n≤(1−η\nt\nλ)∆\nψ\n(w,w\nt\n)−η\nt\n(f\nt\n(w\nt\n)−f\nt\n(w)) +\nη\n2\nt\n2σ\n‖g\nt\n‖\n2\n.(4.8)\nProofWe prove the result in three steps. First we upper bound ∆\nψ\n(w,w\nt+1\n)\nby ∆\nψ\n(w,ˆw\nt+1\n). This is a consequence of (4.4) and the non-negativity of the\nBregman divergence which allows us to write\n∆\nψ\n(w,w\nt+1\n)≤∆\nψ\n(w,ˆw\nt+1\n).(4.9)\nIn the next step we use Lemma 3.11 to write\n∆\nψ\n(w,w\nt\n) + ∆\nψ\n(w\nt\n,ˆw\nt+1\n)−∆\nψ\n(w,ˆw\nt+1\n) =〈∇ψ( ˆw\nt+1\n)−∇ψ(w\nt\n),w−w\nt\n〉.\nSince∇ψ\n∗\n= (∇ψ)\n−1\n, the update in step 3 of Algorithm 4.2 can equivalently\nbe  written  as∇ψ( ˆw\nt+1\n)− ∇ψ(w\nt\n)  =−η\nt\ng\nt\n.  Plugging  this  in  the  above\nequation and rearranging\n∆\nψ\n(w,ˆw\nt+1\n) = ∆\nψ\n(w,w\nt\n)−η\nt\n〈g\nt\n,w\nt\n−w〉+ ∆\nψ\n(w\nt\n,ˆw\nt+1\n).(4.10)\nFinally we upper bound ∆\nψ\n(w\nt\n,ˆw\nt+1\n). For this we need two observations:\nFirst,〈x,y〉 ≤\n1\n2σ\n‖x‖\n2\n+\nσ\n2\n‖y‖\n2\nfor allx,y∈R\nn\nandσ >0. Second, theσ\nstrong convexity ofψallows us to bound ∆\nψ\n( ˆw\nt+1\n,w\nt\n)≥\nσ\n2\n‖w\nt\n−ˆw\nt+1\n‖\n2\n.\nUsing these two observations\n∆\nψ\n(w\nt\n,ˆw\nt+1\n) =ψ(w\nt\n)−ψ( ˆw\nt+1\n)−〈∇ψ( ˆw\nt+1\n),w\nt\n−ˆw\nt+1\n〉\n=−(ψ( ˆw\nt+1\n)−ψ(w\nt\n)−〈∇ψ(w\nt\n),ˆw\nt+1\n−w\nt\n〉) +〈η\nt\ng\nt\n,w\nt\n−ˆw\nt+1\n〉\n=−∆\nψ\n( ˆw\nt+1\n,w\nt\n) +〈η\nt\ng\nt\n,w\nt\n−ˆw\nt+1\n〉\n≤−\nσ\n2\n‖w\nt\n−ˆw\nt+1\n‖\n2\n+\nη\n2\nt\n2σ\n‖g\nt\n‖\n2\n+\nσ\n2\n‖w\nt\n−ˆw\nt+1\n‖\n2\n=\nη\n2\nt\n2σ\n‖g\nt\n‖\n2\n.(4.11)\nInequality (4.7) follows by putting together (4.9), (4.10), and (4.11), while\n(4.8) follows by using (4.6) withf=f\nt\nandw\n′\n=w\nt\nand substituting into\n\n4.2  Weighted Majority147\n(4.7).\nNow we are ready to prove regret bounds.\nLemma 4.4Letw\n∗\n∈Ω\n∗\ndenote  the  best  parameter  chosen  in  hindsight,\nand let‖g\nt\n‖≤Lfor allt. Then the regret of Algorithm 4.2 can be bounded\nvia\nT\n∑\nt=1\nf\nt\n(w\nt\n)−f\nt\n(w\n∗\n)≤F\n(\n1\nη\nT\n−Tλ\n)\n+\nL\n2\n2σ\nT\n∑\nt=1\nη\nt\n.(4.12)\nProofSetw=w\n∗\nand rearrange (4.8) to obtain\nf\nt\n(w\nt\n)−f\nt\n(w\n∗\n)≤\n1\nη\nt\n((1−λη\nt\n)∆\nψ\n(w\n∗\n,w\nt\n)−∆\nψ\n(w\n∗\n,w\nt+1\n)) +\nη\nt\n2σ\n‖g\nt\n‖\n2\n.\nSumming overt\nT\n∑\nt=1\nf\nt\n(w\nt\n)−f\nt\n(w\n∗\n)≤\nT\n∑\nt=1\n1\nη\nt\n((1−η\nt\nλ)∆\nψ\n(w\n∗\n,w\nt\n)−∆\nψ\n(w\n∗\n,w\nt+1\n))\n︸︷︷︸\nT\n1\n+\nT\n∑\nt=1\nη\nt\n2σ\n‖g\nt\n‖\n2\n︸︷︷︸\nT\n2\n.\nSince the diameter of Ω is bounded byFand ∆\nψ\nis non-negative\nT\n1\n=\n(\n1\nη\n1\n−λ\n)\n∆\nψ\n(w\n∗\n,w\n1\n)−\n1\nη\nT\n∆\nψ\n(w\n∗\n,w\nT+1\n) +\nT\n∑\nt=2\n∆\nψ\n(w\n∗\n,w\nt\n)\n(\n1\nη\nt\n−\n1\nη\nt−1\n−λ\n)\n≤\n(\n1\nη\n1\n−λ\n)\n∆\nψ\n(w\n∗\n,w\n1\n) +\nT\n∑\nt=2\n∆\nψ\n(w\n∗\n,w\nt\n)\n(\n1\nη\nt\n−\n1\nη\nt−1\n−λ\n)\n≤\n(\n1\nη\n1\n−λ\n)\nF+\nT\n∑\nt=2\nF\n(\n1\nη\nt\n−\n1\nη\nt−1\n−λ\n)\n=F\n(\n1\nη\nT\n−Tλ\n)\n.\nOn  the  other  hand,  since  the  subgradients  are  Lipschitz  continuous  with\nconstantLit follows that\nT\n2\n≤\nL\n2\n2σ\nT\n∑\nt=1\nη\nt\n.\nPutting together the bounds forT\n1\nandT\n2\nyields (4.12).\nCorollary 4.5Ifλ >0and we setη\nt\n=\n1\nλt\nthen\nT\n∑\nt=1\nf\nt\n(x\nt\n)−f\nt\n(x\n∗\n)≤\nL\n2\n2σλ\n(1 + log(T)),\n\n1484  Online Learning and Boosting\nOn the other hand, whenλ= 0, if we setη\nt\n=\n1\n√\nt\nthen\nT\n∑\nt=1\nf\nt\n(x\nt\n)−f\nt\n(x\n∗\n)≤\n(\nF+\nL\n2\nσ\n)\n√\nT.\nProofFirst  considerλ >0  withη\nt\n=\n1\nλt\n.  In  this  case\n1\nη\nT\n=Tλ,  and\nconsequently (4.12) specializes to\nT\n∑\nt=1\nf\nt\n(w\nt\n)−f\nt\n(w\n∗\n)≤\nL\n2\n2σλ\nT\n∑\nt=1\n1\nt\n≤\nL\n2\n2σλ\n(1 + log(T)).\nWhenλ= 0, and we setη\nt\n=\n1\n√\nt\nand use problem 4.2 to rewrite (4.12) as\nT\n∑\nt=1\nf\nt\n(w\nt\n)−f\nt\n(w\n∗\n)≤F\n√\nT+\nL\n2\nσ\nT\n∑\nt=1\n1\n2\n√\nt\n≤F\n√\nT+\nL\n2\nσ\n√\nT.\nProblems\nProblem 4.1 (Generalized Cauchy-Schwartz{1})Show that〈x,y〉≤\n1\n2σ\n‖x‖\n2\n+\nσ\n2\n‖y‖\n2\nfor allx,y∈R\nn\nandσ >0.\nProblem 4.2 (Bounding sum of a series{1})Show  that\n∑\nb\nt=a\n1\n2\n√\nt\n≤\n√\nb−a+ 1.Hint:Upper bound the sum by an integral.\n\n5\nConditional Densities\nA  number  of  machine  learning  algorithms  can  be  derived  by  using  condi-\ntional  exponential  families  of  distribution  (Section  2.3).  Assume  that  the\ntraining  set{(x\n1\n,y\n1\n),...,(x\nm\n,y\nm\n)}was  drawn  iid  from  some  underlying\ndistribution. Using Bayes rule (1.15) one can write the likelihood\np(θ|X,Y)∝p(θ)p(Y|X,θ) =p(θ)\nm\n∏\ni=1\np(y\ni\n|x\ni\n,θ),(5.1)\nand hence the negative log-likelihood\n−logp(θ|X,Y) =−\nm\n∑\ni=1\nlogp(y\ni\n|x\ni\n,θ)−logp(θ) + const.(5.2)\nBecause we do not have any prior knowledge about the data, we choose a\nzero mean unit variance isotropic normal distribution forp(θ). This yields\n−logp(θ|X,Y) =\n1\n2\n‖θ‖\n2\n−\nm\n∑\ni=1\nlogp(y\ni\n|x\ni\n,θ) + const.(5.3)\nFinally, if we assume a conditional exponential family model forp(y|x,θ),\nthat is,\np(y|x,θ) = exp (〈φ(x,y),θ〉−g(θ|x)),(5.4)\nthen\n−logp(θ|X,Y) =\n1\n2\n‖θ‖\n2\n+\nm\n∑\ni=1\ng(θ|x\ni\n)−〈φ(x\ni\n,y\ni\n),θ〉+ const.(5.5)\nwhere\ng(θ|x) = log\n∑\ny∈Y\nexp (〈φ(x,y),θ〉),(5.6)\nis  the  log-partition  function.  Clearly,  (5.5)  is  a  smooth  convex  objective\nfunction,  and  algorithms  for  unconstrained  minimization  from  Chapter  3\n149\n\n1505  Conditional Densities\ncan be used to obtain the maximum aposteriori (MAP) estimate forθ. Given\nthe optimalθ, the class label at any givenxcan be predicted using\ny\n∗\n= argmax\ny\np(y|x,θ).(5.7)\nIn  this  chapter  we  will  discuss  a  number  of  these  algorithms  that  can  be\nderived  by  specializing  the  above  setup.  Our  discussion  unifies  seemingly\ndisparate algorithms, which are often discussed separately in literature.\n5.1  Logistic Regression\nWe begin with the simplest case namely binary classification\n1\n. The key ob-\nservation here is that the labelsy∈{±1}and hence\ng(θ|x) = log (exp (〈φ(x,+1),θ〉) + exp (〈φ(x,−1),θ〉)).(5.8)\nDefine\nˆ\nφ(x)  :=φ(x,+1)−φ(x,−1).  Plugging  (5.8)  into  (5.4),  using  the\ndefinition of\nˆ\nφand rearranging\np(y= +1|x,θ) =\n1\n1 + exp\n(〈\n−\nˆ\nφ(x),θ\n〉)\nand\np(y=−1|x,θ) =\n1\n1 + exp\n(〈\nˆ\nφ(x),θ\n〉)\n,\nor more compactly\np(y|x,θ) =\n1\n1 + exp\n(〈\n−y\nˆ\nφ(x),θ\n〉)\n.(5.9)\nSincep(y|x,θ) is a logistic function, hence the name logistic regression. The\nclassification rule (5.7) in this case specializes as follows: predict +1 when-\neverp(y= +1|x,θ)≥p(y=−1|x,θ) otherwise predict−1. However\nlog\np(y= +1|x,θ)\np(y=−1|x,θ)\n=\n〈\nˆ\nφ(x),θ\n〉\n,\ntherefore one can equivalently use sign\n(〈\nˆ\nφ(x),θ\n〉)\nas our prediction func-\ntion. Using (5.9) we can write the objective function of logistic regression\nas\n1\n2\n‖θ‖\n2\n+\nm\n∑\ni=1\nlog\n(\n1 + exp\n(〈\n−y\ni\nˆ\nφ(x\ni\n),θ\n〉))\n1\nThe name logisticregressionis a misnomer!\n\n5.2  Regression151\nTo minimize the above objective function we first compute the gradient.\n∇J(θ) =θ+\nm\n∑\ni=1\nexp\n(〈\n−y\ni\nˆ\nφ(x\ni\n),θ\n〉)\n1 + exp\n(〈\n−y\ni\nˆ\nφ(x\ni\n),θ\n〉)\n(−y\ni\nˆ\nφ(x\ni\n))\n=θ+\nm\n∑\ni=1\n(p(y\ni\n|x\ni\n,θ)−1)y\ni\nˆ\nφ(x\ni\n).\nNotice that the second term of the gradient vanishes wheneverp(y\ni\n|x\ni\n,θ) =\n1. Therefore, one way to interpret logistic regression is to view it as a method\nto maximizep(y\ni\n|x\ni\n,θ) for each point (x\ni\n,y\ni\n) in the training set. Since the\nobjective function of logistic regression is twice differentiable one can also\ncompute its Hessian\n∇\n2\nJ(θ) =I−\nm\n∑\ni=1\np(y\ni\n|x\ni\n,θ)(1−p(y\ni\n|x\ni\n,θ))\nˆ\nφ(x\ni\n)\nˆ\nφ(x\ni\n)\n>\n,\nwhere  we  usedy\n2\ni\n=  1.  The  Hessian  can  be  used  in  the  Newton  method\n(Section 3.2.6) to obtain the optimal parameterθ.\n5.2  Regression\n5.2.1  Conditionally Normal Models\nfixed variance\n5.2.2  Posterior Distribution\nintegrating out vs. Laplace approximation, efficient estimation (sparse greedy)\n5.2.3  Heteroscedastic Estimation\nexplain that we have two parameters. not too many details (do that as an\nassignment).\n5.3  Multiclass Classification\n5.3.1  Conditionally Multinomial Models\njoint feature map\n\n1525  Conditional Densities\n5.4  What is a CRF?\n•Motivation with learning a digit example\n•general definition\n•Gaussian process + structure = CRF\n5.4.1  Linear Chain CRFs\n•Graphical model\n•Applications\n•Optimization problem\n5.4.2  Higher Order CRFs\n•2-d CRFs and their applications in vision\n•Skip chain CRFs\n•Hierarchical CRFs (graph transducers, sutton et. al. JMLR etc)\n5.4.3  Kernelized CRFs\n•From feature maps to kernels\n•The clique decomposition theorem\n•The representer theorem\n•Optimization strategies for kernelized CRFs\n5.5  Optimization Strategies\n5.5.1  Getting Started\n•three things needed to optimize\n–MAP estimate\n–log-partition function\n–gradient of log-partition function\n•Worked out example (linear chain?)\n5.5.2  Optimization Algorithms\n- Optimization algorithms (LBFGS, SGD, EG (Globerson et. al))\n5.5.3  Handling Higher order CRFs\n- How things can be done for higher order CRFs (briefly)\n\n5.6  Hidden Markov Models153\n5.6  Hidden Markov Models\n•Definition\n•Discuss that they are modeling joint distributionp(x,y)\n•The way they predict is by marginalizing outx\n•Why they are wasteful and why CRFs generally outperform them\n5.7  Further Reading\nWhat we did not talk about:\n•Details of HMM optimization\n•CRFs applied to predicting parse trees via matrix tree theorem (collins,\nkoo et al)\n•CRFs for graph matching problems\n•CRFs with Gaussian distributions (yes they exist)\n5.7.1  Optimization\nissues in optimization (blows up with number of classes). structure is not\nthere. can we do better?\nProblems\nProblem 5.1Poisson models\nProblem 5.2Bayes Committee Machine\nProblem 5.3Newton / CG approach\n\n\n\n6\nKernels and Function Spaces\nKernels are measures of similarity. Broadly speaking, machine learning al-\ngorithms which rely only on the dot product between instances can be “ker-\nnelized”  by  replacing  all  instances  of〈x,x\n′\n〉by  a  kernel  functionk(x,x\n′\n).\nWe saw examples of such algorithms in Sections 1.3.3 and 1.3.4 and we will\nsee many more examples in Chapter 7. Arguably, the design of a good ker-\nnel underlies the success of machine learning in many applications. In this\nchapter we will lay the ground for the theoretical properties of kernels and\npresent a number of examples. Algorithms which use these kernels can be\nfound in later chapters.\n6.1  The Basics\nLetXdenote the space of inputs andk:X×X→Rbe a function which\nsatisfies\nk(x,x\n′\n) =〈Φ(x),Φ(x)〉(6.1)\nwhere Φ is a feature map which mapsXinto some dot product spaceH. In\nother words, kernels correspond to dot products in some dot product space.\nThe main advantage of using a kernel as a similarity measure are threefold:\nFirst,  if  the  feature  space  is  rich  enough,  then  simple  estimators  such  as\nhyperplanes and half-spaces may be sufficient. For instance, to classify the\npoints  in  Figure  BUGBUG,  we  need  a  nonlinear  decision  boundary,  but\nonce  we  map  the  points  to  a  3  dimensional  space  a  hyperplane  suffices.\nSecond,  kernels  allow  us  to  construct  machine  learning  algorithms  in  the\ndot product spaceHwithout explicitly computing Φ(x). Third, we need not\nmake any assumptions about the input spaceXother than for it to  be  a\nset. As we will see later in this chapter, this allows us to compute similarity\nbetween discrete objects such as strings, trees, and graphs. In the first half\nof this chapter we will present some examples of kernels, and discuss some\ntheoretical properties of kernels in the second half.\n155\n\n1566  Kernels and Function Spaces\n6.1.1  Examples\n6.1.1.1  Linear Kernel\nLinear kernels are perhaps the simplest of all kernels. We assume thatx∈R\nn\nand define\nk(x,x\n′\n) =\n〈\nx,x\n′\n〉\n=\n∑\ni\nx\ni\nx\n′\ni\n.\nIfxandx\n′\nare dense then computing the kernel takesO(n) time. On the\nother hand, for sparse vectors this can be reduced toO(|nnz(x)∩nnz(x\n′\n)|),\nwherennz(·)  denotes  the  set  of  non-zero  indices  of  a  vector  and|·|de-\nnotes the size of a set. Linear kernels are a natural representation to use for\nvectorial data. They are also widely used in text mining where documents\nare represented by a vector containing the frequency of occurrence of words\n(Recall  that  we  encountered  this  so-called  bag  of  words  representation  in\nChapter 1). Instead of a simple bag of words, one can also map a text to the\nset of pairs of words that co-occur in a sentence for a richer representation.\n6.1.1.2  Polynomial Kernel\nGivenx∈R\nn\n,  we  can  compute  a  feature  map  Φ  by  taking  all  thed-th\norder products (also called the monomials) of the entries ofx. To illustrate\nwith a concrete example, let us considerx= (x\n1\n,x\n2\n) andd= 2, in which\ncase  Φ(x)  =\n(\nx\n2\n1\n,x\n2\n2\n,x\n1\nx\n2\n,x\n2\nx\n1\n)\n.  Although  it  is  tedious  to  compute  Φ(x)\nand Φ(x\n′\n) explicitly in order to computek(x,x), there is a shortcut as the\nfollowing proposition shows.\nProposition 6.1LetΦ(x)(resp.Φ(x\n′\n))  denote  the  vector  whose  entries\nare  all  possibled-th  degree  ordered  products  of  the  entries  ofx(resp.x\n′\n).\nThen\nk(x,x\n′\n) =\n〈\nΦ(x),Φ(x\n′\n)\n〉\n=\n(〈\nx,x\n′\n〉)\nd\n.(6.2)\nProofBy direct computation\n〈\nΦ(x),Φ(x\n′\n)\n〉\n=\n∑\nj\n1\n...\n∑\nj\nd\nx\nj\n1\n...x\nj\nd\n·x\n′\nj\n1\n...x\n′\nj\nd\n=\n∑\nj\n1\nx\nj\n1\n·x\n′\nj\n1\n...\n∑\nj\nd\nx\nj\nd\n·x\n′\nj\nd\n=\n\n\n∑\nj\nx\nj\n·x\n′\nj\n\n\nd\n=\n(〈\nx,x\n′\n〉)\nd\n\n6.1  The Basics157\nThe kernel (6.2) is called the polynomial kernel. An useful extension is the\ninhomogeneous polynomial kernel\nk(x,x\n′\n) =\n(〈\nx,x\n′\n〉\n+c\n)\nd\n,(6.3)\nwhich computes all monomials up to degreed(problem 6.2).\n6.1.1.3  Radial Basis Function Kernels\n6.1.1.4  Convolution Kernels\nThe framework of convolution kernels is a general way to extend the notion\nof kernels to structured objects such as strings, trees, and graphs. Letx∈X\nbe a discrete object which can be decomposed intoPpartsx\np\n∈X\np\nin many\ndifferent ways. As a concrete example consider the stringx=abcwhich can\nbe split into two sets of substrings of size two namely{a,bc}and{ab,c}.\nWe denote the set of all such decompositions asR(x), and use it to build a\nkernel onXas follows:\n[k\n1\n? ... ? k\nP\n] (x,x\n′\n) =\n∑\n ̄x∈R(x), ̄x\n′\n∈R(x\n′\n)\nP\n∏\np=1\nk\np\n( ̄x\np\n, ̄x\n′\np\n).(6.4)\nHere, the sum is over all possible ways in which we can decomposexand\nx\n′\ninto   ̄x\n1\n,..., ̄x\nP\nand   ̄x\n′\n1\n,..., ̄x\n′\nP\nrespectively. If the cardinality ofR(x) is\nfinite, then it can be shown that (6.4) results in a valid kernel. Although\nconvolution kernels provide the abstract framework, specific instantiations\nof  this  idea  lead  to  a  rich  set  of  kernels  on  discrete  objects.  We  will  now\ndiscuss some of them in detail.\n6.1.1.5  String Kernels\nThe  basic  idea  behind  string  kernels  is  simple:  Compare  the  strings  by\nmeans of the subsequences they contain. More the number of common sub-\nsequences, the more similar two strings are. The subsequences need not have\nequal weights. For instance, the weight of a subsequence may be given by the\ninverse frequency of its occurrence. Similarly, if the first and last characters\nof  a  subsequence  are  rather  far  apart,  then  its  contribution  to  the  kernel\nmust be down-weighted.\nFormally, a stringxis composed of characters from a finite alphabet Σ\nand|x|denotes its length. We say thatsis a subsequence ofx=x\n1\nx\n2\n...x\n|x|\nifs=x\ni\n1\nx\ni\n2\n...x\ni\n|s|\nfor some 1≤i\n1\n< i\n2\n< ... < i\n|s|\n≤ |x|. In particular, if\ni\ni+1\n=i\ni\n+ 1 thensis a substring ofx. For example,acbis not a subsequence\nofadbcwhileabcis a subsequence andadcis a substring. Assume that there\nexists a function #(x,s) which returns the number of times a subsequence\n\n1586  Kernels and Function Spaces\nsoccurs inxand a non-negative weighting functionw(s)≥0 which returns\nthe weight associated withs. Then the basic string kernel can be written as\nk(x,x\n′\n) =\n∑\ns\n#(x,s) #(x\n′\n,s)w(s).(6.5)\nDifferent string kernels are derived by specializing the above equation:\nAll substrings kernel:If we restrict the summation in (6.5) to sub-\nstrings then [VS04] provide a suffix tree based algorithm which allows one\nto compute for arbitraryw(s) the kernelk(x,x\n′\n) inO(|x|+|x\n′\n|) time and\nmemory.\nk-Spectrum kernel:Thek-spectrum kernel is obtained by restricting\nthe summation in (6.5) to substrings of lengthk. A slightly general variant\nconsiders  all  substrings  of  length  up  tok.  Herekis  a  tuning  parameter\nwhich is typically set to be a small number (e.g.,5). A simple trie based\nalgorithm can be used to compute thek-spectrum kernel inO((|x|+|x\n′\n|)k)\ntime (problem 6.3).\nInexact  substring  kernel:Sometimes  the  input  strings  might  have\nmeasurement errors and therefore it is desirable to take into account inexact\nmatches.  This  is  done  by  replacing  #(x,s)  in  (6.5)  by  another  function\n#(x,s,\u000f) which reports the number of approximate matches ofsinx. Here\n\u000fdenotes the number of mismatches allowed, typically a small number (e.g.,\n3). By trading off computational complexity with storage the kernel can be\ncomputed efficiently. See [LK03] for details.\nMismatch kernel:Instead of simply counting the number of occurrences\nof a substring if we use a weighting scheme which down-weights the contribu-\ntions of longer subsequences then this yields the so-called mismatch kernel.\nGiven an index sequenceI= (i\n1\n,...,i\nk\n) with 1≤i\n1\n< i\n2\n< ... < i\nk\n≤ |x|\nwe can associate the subsequencex(I) =x\ni\n1\nx\ni\n2\n...x\ni\nk\nwithI. Furthermore,\ndefine|I|=i\nk\n−i\n1\n+ 1. Clearly,|I|> kifIis not contiguous. Letλ≤1 be\na decay factor. Redefine\n#(x,s) =\n∑\ns=x(I)\nλ\n|I|\n,(6.6)\nthat is, we count all occurrences ofsinxbut now the weight associated with\na subsequence depends on its length. To illustrate, consider the subsequence\nabcwhich occurs in the stringabcebctwice, namely,abc\nebcandabcebc. The\nfirst  occurrence  is  counted  with  weightλ\n3\nwhile  the  second  occurrence  is\ncounted with the weightλ\n6\n. As it turns out, this kernel can be computed\nby a dynamic programming algorithm (problem BUGBUG) inO(|x|·|x\n′\n|)\ntime.\n\n6.1  The Basics159\n6.1.1.6  Graph Kernels\nThere  are  two  different  notions  of  graph  kernels.  First,  kernelsongraphs\nare used to compare nodes of a single graph. In contrast, kernelsbetween\ngraphs focus on comparing two graphs. A random walk (or its continuous\ntime limit, diffusion) underlie both types of kernels. The basic intuition is\nthat  two  nodes  are  similar  if  there  are  a  number  of  paths  which  connect\nthem while two graphs are similar if they share many common paths. To\ndescribe these kernels formally we need to introduce some notation.\nA graphGconsists of an ordered set ofnverticesV={v\n1\n,v\n2\n,...,v\nn\n},\nand a set of directed edgesE⊂V×V. A vertexv\ni\nis said to be a neighbor\nof another vertexv\nj\nif they are connected by an edge,i.e.,if (v\ni\n,v\nj\n)∈E;\nthis is also denotedv\ni\n∼v\nj\n. The adjacency matrix of a graph is then×n\nmatrixAwithA\nij\n= 1 ifv\ni\n∼v\nj\n, and 0 otherwise. A walk of lengthkonG\nis a sequence of indicesi\n0\n,i\n1\n,...i\nk\nsuch thatv\ni\nr−1\n∼v\ni\nr\nfor all 1≤r≤k.\nThe adjacency matrix has a normalized cousin, defined\n ̃\nA:=D\n−1\nA, which\nhas  the  property  that  each  of  its  rows  sums  to  one,  and  it  can  therefore\nserve as the transition matrix for a stochastic process. Here,Dis a diag-\nonal matrix  of node  degrees,i.e.,D\nii\n=d\ni\n=\n∑\nj\nA\nij\n. A  random walk on\nGis a process generating sequences of verticesv\ni\n1\n,v\ni\n2\n,v\ni\n3\n,...according to\nP(i\nk+1\n|i\n1\n,...i\nk\n) =\n ̃\nA\ni\nk\n,i\nk+1\n. Thet\nth\npower of\n ̃\nAthus describest-length walks,\ni.e.,(\n ̃\nA\nt\n)\nij\nis the probability of a transition from vertexv\nj\nto vertexv\ni\nvia\na walk of lengtht(problem BUGBUG). Ifp\n0\nis an initial probability dis-\ntribution  over  vertices,  then  the  probability  distributionp\nt\ndescribing  the\nlocation of our random walker at timetisp\nt\n=\n ̃\nA\nt\np\n0\n. Thej\nth\ncomponent of\np\nt\ndenotes the probability of finishing at-length walk at vertexv\nj\n. A random\nwalk need not continue indefinitely; to model this, we associate every node\nv\ni\nk\nin the graph with a stopping probabilityq\ni\nk\n. The overall probability of\nstopping aftertsteps is given byq\n>\np\nt\n.\nGiven  two  graphsG(V,E)  andG\n′\n(V\n′\n,E\n′\n),  their  direct  productG\n×\nis  a\ngraph with vertex set\nV\n×\n={(v\ni\n,v\n′\nr\n) :v\ni\n∈V, v\n′\nr\n∈V\n′\n},(6.7)\nand edge set\nE\n×\n={((v\ni\n,v\n′\nr\n),(v\nj\n,v\n′\ns\n))  :  (v\ni\n,v\nj\n)∈E∧(v\n′\nr\n,v\n′\ns\n)∈E\n′\n}.(6.8)\nIn  other  words,G\n×\nis  a  graph  over  pairs  of  vertices  fromGandG\n′\n,  and\ntwo vertices inG\n×\nare neighbors if and only if the corresponding vertices\ninGandG\n′\nare both neighbors; see Figure 6.1 for an illustration. IfAand\nA\n′\nare the respective adjacency matrices ofGandG\n′\n, then the adjacency\n\n1606  Kernels and Function Spaces\nG\n1\n1\n2\n3\nG\n2\n1’2’\n3’4’\nG\n×\n11’21’31’\n34’12’\n24’22’\n14’32’\n33’23’13’\nFig. 6.1.  Two graphs (G\n1\n&G\n2\n) and their direct product (G\n×\n). Each node of the\ndirect  product  graph  is  labeled  with  a  pair  of  nodes  (6.7);  an  edge  exists  in  the\ndirect product if and only if the corresponding nodes are adjacent in both original\ngraphs (6.8). For instance, nodes 11\n′\nand 32\n′\nare adjacent because there is an edge\nbetween nodes 1 and 3 in the first, and 1\n′\nand 2\n′\nin the second graph.\nmatrix ofG\n×\nisA\n×\n=A⊗A\n′\n. Similarly,\n ̃\nA\n×\n=\n ̃\nA⊗\n ̃\nA\n′\n. Performing a random\nwalk on the direct product graph is equivalent to performing a simultaneous\nrandom walk onGandG\n′\n. Ifpandp\n′\ndenote initial probability distributions\nover  the  vertices  ofGandG\n′\n,  then  the  corresponding  initial  probability\ndistribution on the direct product graph isp\n×\n:=p⊗p\n′\n. Likewise, ifqand\nq\n′\nare  stopping  probabilities  (that  is,  the  probability  that  a  random  walk\nends at a given vertex), then the stopping probability on the direct product\ngraph isq\n×\n:=q⊗q\n′\n.\nTo define a kernel which computes the similarity betweenGandG\n′\n, one\nnatural idea is to simply sum upq\n>\n×\n ̃\nA\nt\n×\np\n×\nfor all values oft. However, this\nsum might not converge, leaving the kernel value undefined. To overcome\nthis  problem,  we  introduce  appropriately  chosen  non-negative  coefficients\nμ(t), and define the kernel betweenGandG\n′\nas\nk(G,G\n′\n) :=\n∞\n∑\nt=0\nμ(t)q\n>\n×\n ̃\nA\nt\n×\np\n×\n.(6.9)\nThis idea can be extended to graphs whose nodes are associated with labels\nby replacing the matrix\n ̃\nA\n×\nwith a matrix of label similarities. For appro-\npriate choices ofμ(t) the above sum converges and efficient algorithms for\ncomputing the kernel can be devised. See [?] for details.\nAs it turns out, the simple idea of performing a random walk on the prod-\n\n6.2  Kernels161\nuct graph can be extended to compute kernels on Auto Regressive Moving\nAverage (ARMA) models [VSV07]. Similarly, it can also be used to define\nkernels between transducers. Connections between the so-called rational ker-\nnels on transducers and the graph kernels defined via (6.9) are made explicit\nin [?].\n6.2  Kernels\n6.2.1  Feature Maps\ngive examples, linear classifier, nonlinear ones with r2-r3 map\n6.2.2  The Kernel Trick\n6.2.3  Examples of Kernels\ngaussian, polynomial, linear, texts, graphs\n- stress the fact that there is a difference between structure in the input\nspace and structure in the output space\n6.3  Algorithms\n6.3.1  Kernel Perceptron\n6.3.2  Trivial Classifier\n6.3.3  Kernel Principal Component Analysis\n6.4  Reproducing Kernel Hilbert Spaces\nAs it turns out, this class of functions coincides with the class of positive\nsemi-definite  functions.  Intuitively,  the  notion  of  a  positive  semi-definite\nfunction  is  an  extension  of  the  familiar  notion  of  a  positive  semi-definite\nmatrix (also see Appendix BUGBUG):\nDefinition 6.2A realn×nsymmetric matrixKsatisfying\n∑\ni,j\nα\ni\nα\nj\nK\ni,j\n≥0(6.10)\nfor allα\ni\n,α\nj\n∈Ris called positive semi-definite. If equality in(6.10)occurs\nonly whenα\n1\n,...,α\nn\n= 0, thenKis said to be positive definite.\nDefinition 6.3Given a set of pointsx\n1\n,...,x\nn\n∈Xand a functionk, the\nmatrix\nK\ni,j\n=k(x\ni\n,x\nj\n)(6.11)\n\n1626  Kernels and Function Spaces\nis called the Gram matrix or the kernel matrix ofkwith respect tox\n1\n,...,x\nn\n.\nDefinition 6.4LetXbe a nonempty set,k:X×X→Rbe a function. If\nkgives rise to a positive (semi-)definite Gram matrix for allx\n1\n,...,x\nn\n∈X\nandn∈Nthenkis said to be positive (semi-)definite.\nClearly, every kernel functionkof the form (6.1) is positive semi-definite.\nTo see this simply write\n∑\ni,j\nα\ni\nα\nj\nk(x\ni\n,x\nj\n) =\n∑\ni,j\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉=\n〈\n∑\ni\nα\ni\nx\ni\n,\n∑\nj\nα\nj\nx\nj\n〉\n≥0.\nWe now establish the converse, that is, we show that every positive semi-\ndefinite kernel function can be written as (6.1). Towards this end, define a\nmap Φ fromXinto the space of functions mappingXtoR(denotedR\nX\n) via\nΦ(x) =k(·,x). In other words, Φ(x) :X→Ris a function which assigns the\nvaluek(x\n′\n,x) tox\n′\n∈X. Next construct a vector space by taking all possible\nlinear combinations of Φ(x)\nf(·) =\nn\n∑\ni=1\nα\ni\nΦ(x\ni\n) =\nn\n∑\ni=1\nα\ni\nk(·,x\ni\n),(6.12)\nwherei∈N,α\ni\n∈R, andx\ni\n∈Xare arbitrary. This space can be endowed\nwith a natural dot product\n〈f,g〉=\nn\n∑\ni=1\nn\n′\n∑\nj=1\nα\ni\nβ\nj\nk(x\ni\n,x\n′\nj\n).(6.13)\nTo see that the above dot product is well defined even though it contains\nthe  expansion  coefficients  (which  need  not  be  unique),  note  that〈f,g〉=\n∑\nn\n′\nj=1\nβ\nj\nf(x\n′\nj\n), independent ofα\ni\n. Similarly, forg, note that〈f,g〉=\n∑\nn\ni=1\nα\ni\nf(x\ni\n),\nthis time independent ofβ\nj\n. This also shows that〈f,g〉is bilinear. Symme-\ntry follows because〈f,g〉=〈g,f〉, while the positive semi-definiteness ofk\nimplies that\n〈f,f〉=\n∑\ni,j\nα\ni\nα\nj\nk(x\ni\n,x\nj\n)≥0.(6.14)\nApplying (6.13) shows that for all functions (6.12) we have\n〈f,k(·,x)〉=f(x).(6.15)\nIn particular\n〈\nk(·,x),k(·,x\n′\n)\n〉\n=k(x,x\n′\n).(6.16)\n\n6.4  Reproducing Kernel Hilbert Spaces163\nIn view of these properties,kis called a reproducing kernel. By using (6.15)\nand the following property of positive semi-definite functions (problem 6.1)\nk(x,x\n′\n)\n2\n≤k(x,x)·k(x\n′\n,x\n′\n)(6.17)\nwe can now write\n|f(x)|\n2\n=|〈f,k(·,x)〉|≤k(x,x)·〈f,f〉.(6.18)\nFrom  the  above  inequality,f=  0  whenever〈f,f〉=  0,  thus  establishing\n〈·,·〉as a valid dot product. In fact, one can complete the space of functions\n(6.12) in the norm corresponding to the dot product (6.13), and thus get a\nHilbert spaceH, called thereproducing kernel Hilbert Space (RKHS).\nAn alternate way to define a RKHS is as a Hilbert spaceHon functions\nfrom some input spaceXtoRwith the property that for anyf∈Hand\nx∈X,  the  point  evaluationsf→f(x)  are  continuous  (in  particular,  all\npoints valuesf(x) are well defined, which already distinguishes an RKHS\nfrom manyL\n2\nHilbert spaces). Given the point evaluation functional, one\ncan  then  construct  the  reproducing  kernel  using  the  Riesz  representation\ntheorem. The Moore-Aronszajn theorem states that, for every positive semi-\ndefinite kernel onX×X, there exists a unique RKHS and vice versa.\nWe finish this section by noting that〈·,·〉is a positive semi-definite func-\ntion in the vector space of functions (6.12). This follows directly from the\nbilinearity of the dot product and (6.14) by which we can write for functions\nf\n1\n,...,f\np\nand coefficientsγ\n1\n,...,γ\np\n∑\ni\n∑\nj\nγ\ni\nγ\nj\n〈f\ni\n,f\nj\n〉=\n〈\n∑\ni\nγ\ni\nf\ni\n,\n∑\nj\nγ\nj\nf\nj\n〉\n≥0.(6.19)\n6.4.1  Hilbert Spaces\nevaluation functionals, inner products\n6.4.2  Theoretical Properties\nMercer’s theorem, positive semidefiniteness\n6.4.3  Regularization\nRepresenter theorem, regularization\n\n1646  Kernels and Function Spaces\n6.5  Banach Spaces\n6.5.1  Properties\n6.5.2  Norms and Convex Sets\n-  smoothest  function  (L2)  -  smallest  coefficients  (L1)  -  structured  priors\n(CAP formalism)\nProblems\nProblem 6.1Show that(6.17)holds for an arbitrary positive semi-definite\nfunctionk.\nProblem 6.2Show  that  the  inhomogeneous  polynomial  kernel(6.3)is  a\nvalid kernel and that it computes all monomials of degree up tod.\nProblem 6.3 (k-spectrum kernel{2})Given two stringsxandx\n′\nshow\nhow  one  can  compute  thek-spectrum  kernel  (section  6.1.1.5)  inO((|x|+\n|x\n′\n|)k)time.Hint:You need to use a trie.\n\n7\nLinear Models\nA hyperplane in a spaceHendowed with a dot product〈·,·〉is described by\nthe set\n{x∈H|〈w,x〉+b= 0}(7.1)\nwherew∈Handb∈R. Such a hyperplane naturally dividesHinto two\nhalf-spaces:{x∈H|〈w,x〉+b≥0}and{x∈H|〈w,x〉+b <0},  and\nhence  can  be  used  as  the  decision  boundary  of  a  binary  classifier.  In  this\nchapter  we  will  study  a  number  of  algorithms  which  employ  such  linear\ndecision boundaries. Although such models look restrictive at first glance,\nwhen combined with kernels (Chapter 6) they yield a large class of useful\nalgorithms.\nAll  the  algorithms  we  will  study  in  this  chapter  maximize  the  margin.\nGiven a setX={x\n1\n,...,x\nm\n}, the margin is the distance of the closest point\ninXto the hyperplane (7.1). Elementary geometric arguments (Problem 7.1)\nshow that the distance of a pointx\ni\nto a hyperplane is given by|〈w,x\ni\n〉+\nb|/‖w‖, and hence the margin is simply\nmin\ni=1,...,m\n|〈w,x\ni\n〉+b|\n‖w‖\n.(7.2)\nNote that the parameterization of the hyperplane (7.1) is not unique; if we\nmultiply bothwandbby the same non-zero constant, then we obtain the\nsame hyperplane. One way to resolve this ambiguity is to set\nmin\ni=1,...m\n|〈w,x\ni\n〉+b|= 1.\nIn this case, the margin simply becomes 1/‖w‖. We postpone justification\nof margin maximization for later and jump straight ahead to the description\nof various algorithms.\n7.1  Support Vector Classification\nConsider  a  binary  classification  task,  where  we  are  given  a  training  set\n{(x\n1\n,y\n1\n),...,(x\nm\n,y\nm\n)}withx\ni\n∈Handy\ni\n∈ {±1}.  Our  aim  is  to  find\na linear decision boundary parameterized by (w,b) such that〈w,x\ni\n〉+b≥0\n165\n\n1667  Linear Models\nx\n1\nw\nx\n2\ny\ni\n=−1\ny\ni\n= +1\n{x| 〈w,x〉+b=−1}\n{x| 〈w,x〉+b= 1}\n{x| 〈w,x〉+b= 0}\n〈w,x\n1\n〉+b= +1\n〈w,x\n2\n〉+b=−1\n〈w,x\n1\n−x\n2\n〉= 2\n〈\nw\n‖w‖\n,x\n1\n−x\n2\n〉\n=\n2\n‖w‖\nFig.  7.1.  A  linearly  separable  toy  binary  classification  problem  of  separating  the\ndiamonds from the circles. We normalize (w,b) to ensure that min\ni=1,...m\n|〈w,x\ni\n〉+\nb|= 1. In this case, the margin is given by\n1\n‖w‖\nas the calculation in the inset shows.\nwhenevery\ni\n= +1 and〈w,x\ni\n〉+b <0 whenevery\ni\n=−1. Furthermore, as dis-\ncussed above, we fix the scaling ofwby requiring min\ni=1,...m\n|〈w,x\ni\n〉+b|= 1.\nA compact way to write our desiderata is to requirey\ni\n(〈w,x\ni\n〉+b)≥1 for\nalli(also see Figure 7.1). The problem of maximizing the margin therefore\nreduces to\nmax\nw,b\n1\n‖w‖\n(7.3a)\ns.t.y\ni\n(〈w,x\ni\n〉+b)≥1 for alli,(7.3b)\nor equivalently\nmin\nw,b\n1\n2\n‖w‖\n2\n(7.4a)\ns.t.y\ni\n(〈w,x\ni\n〉+b)≥1 for alli.(7.4b)\nThis is a constrained convex optimization problem with a quadratic objec-\ntive function and linear constraints (see Section 3.3). In deriving (7.4) we\nimplicitly  assumed  that  the  data  is  linearly  separable,  that  is,  there  is  a\nhyperplane which correctly classifies the training data. Such a classifier is\ncalled  ahard  margin  classifier.  If  the  data  is  not  linearly  separable,  then\n(7.4)  does  not  have  a  solution.  To  deal  with  this  situation  we  introduce\n\n7.1  Support Vector Classification167\nnon-negative slack variablesξ\ni\nto relax the constraints:\ny\ni\n(〈w,x\ni\n〉+b)≥1−ξ\ni\n.\nGiven anywandbthe constraints can now be satisfied by makingξ\ni\nlarge\nenough. This renders the whole optimization problem useless. Therefore, one\nhas to penalize largeξ\ni\n. This is done via the following modified optimization\nproblem:\nmin\nw,b,ξ\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nξ\ni\n(7.5a)\ns.t.y\ni\n(〈w,x\ni\n〉+b)≥1−ξ\ni\nfor alli(7.5b)\nξ\ni\n≥0,(7.5c)\nwhereC >0 is a penalty parameter. The resultant classifier is said to be a\nsoft margin classifier. By introducing non-negative Lagrange multipliersα\ni\nandβ\ni\none can write the Lagrangian (see Section 3.3)\nL(w,b,ξ,α,β) =\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nξ\ni\n+\nm\n∑\ni=1\nα\ni\n(1−ξ\ni\n−y\ni\n(〈w,x\ni\n〉+b))−\nm\n∑\ni=1\nβ\ni\nξ\ni\n.\nNext take gradients with respect tow,bandξand set them to zero.\n∇\nw\nL=w−\nm\n∑\ni=1\nα\ni\ny\ni\nx\ni\n= 0(7.6a)\n∇\nb\nL=−\nm\n∑\ni=1\nα\ni\ny\ni\n= 0(7.6b)\n∇\nξ\ni\nL=\nC\nm\n−α\ni\n−β\ni\n= 0.(7.6c)\nSubstituting (7.6) into the Lagrangian and simplifying yields the dual ob-\njective function:\n−\n1\n2\n∑\ni,j\ny\ni\ny\nj\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉+\nm\n∑\ni=1\nα\ni\n,(7.7)\nwhich needs to be maximized with respect toα. For notational convenience\nwe will minimize the negative of  (7.7) below. Next we turn our attention\nto the dual constraints. Recall thatα\ni\n≥0 andβ\ni\n≥0, which in conjunc-\ntion  with  (7.6c)  immediately  yields  0≤α\ni\n≤\nC\nm\n.  Furthermore,  by  (7.6b)\n∑\nm\ni=1\nα\ni\ny\ni\n= 0. Putting everything together, the dual optimization problem\n\n1687  Linear Models\nboils down to\nmin\nα\n1\n2\n∑\ni,j\ny\ni\ny\nj\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉−\nm\n∑\ni=1\nα\ni\n(7.8a)\ns.t.\nm\n∑\ni=1\nα\ni\ny\ni\n= 0(7.8b)\n0≤α\ni\n≤\nC\nm\n.(7.8c)\nIf we letHbe am×mmatrix with entriesH\nij\n=y\ni\ny\nj\n〈x\ni\n,x\nj\n〉, whilee,α,\nandybem-dimensional vectors whosei-th components are one,α\ni\n, andy\ni\nrespectively, then the above dual can be compactly written as the following\nQuadratic Program (QP) (Section 3.3.3):\nmin\nα\n1\n2\nα\n>\nHα−α\n>\ne(7.9a)\ns.t.α\n>\ny= 0(7.9b)\n0≤α\ni\n≤\nC\nm\n.(7.9c)\nBefore  turning  our  attention  to  algorithms  for  solving  (7.9),  a  number  of\nobservations are in order. First, note that computingHonly requires com-\nputing dot products between training examples. If we map the input data to\na Reproducing Kernel Hilbert Space (RKHS) via a feature mapφ, then we\ncan still compute the entries ofHand solve for the optimalα. In this case,\nH\nij\n=y\ni\ny\nj\n〈φ(x\ni\n),φ(x\nj\n)〉=y\ni\ny\nj\nk(x\ni\n,x\nj\n),  wherekis  the  kernel  associated\nwith the RKHS. Given the optimalα, one can easily recover the decision\nboundary. This is a direct consequence of (7.6a), which allows us to writew\nas a linear combination of the training data:\nw=\nm\n∑\ni=1\nα\ni\ny\ni\nφ(x\ni\n),\nand hence the decision boundary as\n〈w,x〉+b=\nm\n∑\ni=1\nα\ni\ny\ni\nk(x\ni\n,x) +b.(7.10)\nBy the KKT conditions (Section 3.3) we have\nα\ni\n(1−ξ\ni\n−y\ni\n(〈w,x\ni\n〉+b)) = 0 andβ\ni\nξ\ni\n= 0.\nWe now consider three cases fory\ni\n(〈w,x\ni\n〉+b) and the implications of the\nKKT conditions (see Figure 7.2).\n\n7.1  Support Vector Classification169\n{x| 〈w,x〉+b=−1}\n{x| 〈w,x〉+b= 1}\nFig. 7.2.  The picture depicts the well classified points (y\ni\n(〈w,x\ni\n〉+b)>1 in black,\nthe support vectorsy\ni\n(〈w,x\ni\n〉+b) = 1 in blue, and margin errorsy\ni\n(〈w,x\ni\n〉+b)<1\nin red.\ny\ni\n(〈w,x\ni\n〉+b)<1:In  this  case,ξ\ni\n>0,  and  hence  the  KKT  conditions\nimply thatβ\ni\n= 0. Consequently,α\ni\n=\nC\nm\n(see (7.6c)). Such points\nare said to be margin errors.\ny\ni\n(〈w,x\ni\n〉+b)>1:In this case,ξ\ni\n= 0, (1−ξ\ni\n−y\ni\n(〈w,x\ni\n〉+b))<0, and by\nthe KKT conditionsα\ni\n= 0. Such points are said to be well classified.\nIt is easy to see that the decision boundary (7.10) does not change\neven if these points are removed from the training set.\ny\ni\n(〈w,x\ni\n〉+b) =1:In this caseξ\ni\n= 0 andβ\ni\n≥0. Sinceα\ni\nis non-negative\nand satisfies (7.6c) it follows that 0≤α\ni\n≤\nC\nm\n. Such points are said\nto be on the margin. They are also sometimes calledsupport vectors.\nSince the support vectors satisfyy\ni\n(〈w,x\ni\n〉+b) = 1 andy\ni\n∈{±1}it follows\nthatb=y\ni\n− 〈w,x\ni\n〉for  any  support  vectorx\ni\n.  However,  in  practice  to\nrecoverbwe average\nb=y\ni\n−\n∑\ni\n〈w,x\ni\n〉.(7.11)\nover all support vectors, that is, pointsx\ni\nfor which 0< α\ni\n<\nC\nm\n. Because\nit  uses  support  vectors,  the  overall  algorithm  is  called  C-Support  Vector\nclassifier or C-SV classifier for short.\n\n1707  Linear Models\n7.1.1  A Regularized Risk Minimization Viewpoint\nA closer examination of (7.5) reveals thatξ\ni\n= 0 whenevery\ni\n(〈w,x\ni\n〉+b)>1.\nOn  the  other  hand,ξ\ni\n=  1−y\ni\n(〈w,x\ni\n〉+b)  whenevery\ni\n(〈w,x\ni\n〉+b)<\n1.  In  short,ξ\ni\n=  max(0,1−y\ni\n(〈w,x\ni\n〉+b)).  Using  this  observation  one\ncan  eliminateξ\ni\nfrom  (7.5),  and  write  it  as  the  following  unconstrained\noptimization problem:\nmin\nw,b\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nmax(0,1−y\ni\n(〈w,x\ni\n〉+b)).(7.12)\nWriting  (7.5)  as  (7.12)  is  particularly  revealing  because  it  shows  that  a\nsupport vector classifier is nothing but a regularized risk minimizer. Here\nthe  regularizer  is  the  square  norm  of  the  decision  hyperplane\n1\n2\n‖w‖\n2\n,  and\nthe loss function is the so-called binary hinge loss (Figure 7.3):\nl(w,x,y) = max(0,1−y(〈w,x〉+b)).(7.13)\nIt  is  easy  to  verify  that  the  binary  hinge  loss  (7.13)  is  convex  but  non-\ndifferentiable (see Figure 7.3) which renders the overall objective function\n(7.12) to be convex but non-smooth. There are two different strategies to\nminimize such an objective function. If minimizing (7.12) in the primal, one\ncan employ non-smooth convex optimizers such as bundle methods (Section\n3.2.7). This yields addimensional problem wheredis the dimension ofx.\nOn the other hand, since (7.12) is strongly convex because of the presence\nof  the\n1\n2\n‖w‖\n2\nterm,  its  Fenchel  dual  has  a  Lipschitz  continuous  gradient\n(see Lemma 3.10). The dual problem ismdimensional and contains linear\nconstraints. This strategy is particularly attractive when the kernel trick is\nused or wheneverd\u001dm. In fact, the dual problem obtained via Fenchel\nduality is very related to the Quadratic programming problem (7.9) obtained\nvia Lagrange duality (problem 7.4).\n7.1.2  An Exponential Family Interpretation\nOur  motivating  arguments  for  deriving  the  SVM  algorithm  have  largely\nbeen geometric. We now show that an equally elegant probabilistic interpre-\ntation  also  exists.  Assuming  that  the  training  set{(x\n1\n,y\n1\n),...,(x\nm\n,y\nm\n)}\nwas drawn iid from some underlying distribution, and using the Bayes rule\n(1.15) one can write the likelihood\np(θ|X,Y)∝p(θ)p(Y|X,θ) =p(θ)\nm\n∏\ni=1\np(y\ni\n|x\ni\n,θ),(7.14)\n\n7.1  Support Vector Classification171\ny(〈w,x〉+b)\nloss\nFig. 7.3.  The binary hinge loss. Note that the loss is convex but non-differentiable\nat the kink point. Furthermore, it increases linearly as the distance from the decision\nhyperplaney(〈w,x〉+b) decreases.\nand hence the negative log-likelihood\n−logp(θ|X,Y) =−\nm\n∑\ni=1\nlogp(y\ni\n|x\ni\n,θ)−logp(θ) + const.(7.15)\nIn  the  absence  of  any  prior  knowledge  about  the  data,  we  choose  a  zero\nmean unit variance isotropic normal distribution forp(θ). This yields\n−logp(θ|X,Y) =\n1\n2\n‖θ‖\n2\n−\nm\n∑\ni=1\nlogp(y\ni\n|x\ni\n,θ) + const.(7.16)\nThe maximum aposteriori (MAP) estimate forθis obtained by minimizing\n(7.16) with respect toθ. Given the optimalθ, we can predict the class label\nat any givenxvia\ny\n∗\n= argmax\ny\np(y|x,θ).(7.17)\nOf  course,  our  aim  is  not  just  to  maximizep(y\ni\n|x\ni\n,θ)  but  also  to  ensure\nthatp(y|x\ni\n,θ) is small for ally6=y\ni\n. This, for instance, can be achieved by\nrequiring\np(y\ni\n|x\ni\n,θ)\np(y|x\ni\n,θ)\n≥η,for ally6=y\ni\nand someη≥1.(7.18)\nAs we saw in Section 2.3 exponential families of distributions are rather flex-\nible modeling tools. We could, for instance, modelp(y\ni\n|x\ni\n,θ) as a conditional\nexponential family distribution. Recall the definition:\np(y|x,θ) = exp (〈φ(x,y),θ〉−g(θ|x)).(7.19)\n\n1727  Linear Models\nHereφ(x,y) is ajointfeature map which depends on both the input datax\nand the labely, whileg(θ|x) is the log-partition function. Now (7.18) boils\ndown to\np(y\ni\n|x\ni\n,θ)\nmax\ny6=y\ni\np(y|x\ni\n,θ)\n= exp\n(〈\nφ(x\ni\n,y\ni\n)−max\ny6=y\ni\nφ(x\ni\n,y),θ\n〉)\n≥η.(7.20)\nIf we chooseηsuch that logη= 1, setφ(x,y) =\ny\n2\nφ(x), and observe that\ny∈{±1}we can rewrite (7.20) as\n〈\ny\ni\n2\nφ(x\ni\n)−\n(\n−\ny\ni\n2\n)\nφ(x\ni\n),θ\n〉\n=y\ni\n〈φ(x\ni\n),θ〉≥1.(7.21)\nBy replacing−logp(y\ni\n|x\ni\n,θ) in (7.16) with the condition (7.21) we obtain\nthe following objective function:\nmin\nθ\n1\n2\n‖θ‖\n2\n(7.22a)\ns.t.y\ni\n〈φ(x\ni\n),θ〉≥1 for alli,(7.22b)\nwhich  recovers  (7.4),  but  without  the  biasb.  The  prediction  function  is\nrecovered by noting that (7.17) specializes to\ny\n∗\n= argmax\ny∈{±1}\n〈φ(x,y),θ〉= argmax\ny∈{±1}\ny\n2\n〈φ(x),θ〉= sign(〈φ(x),θ〉).(7.23)\nAs before, we can replace (7.21) by a linear penalty for constraint viola-\ntion in order to recover (7.5). The quantity log\np(y\ni\n|x\ni\n,θ)\nmax\ny6=y\ni\np(y|x\ni\n,θ)\nis sometimes\ncalled  thelog-odds  ratio,  and  the  above  discussion  shows  that  SVMs  can\nbe interpreted as maximizing the log-odds ratio in the exponential family.\nThis interpretation will be developed further when we consider extensions of\nSVMs to tackle multiclass, multilabel, and structured prediction problems.\n7.1.3  Specialized Algorithms for Training SVMs\nThe main task in training SVMs boils down to solving  (7.9). Them×m\nmatrixHis usually dense and cannot be stored in memory. Decomposition\nmethods  are  designed  to  overcome  these  difficulties.  The  basic  idea  here\nis  to  identify  and  update  a  smallworking  setBby  solving  a  small  sub-\nproblem at every iteration. Formally, letB⊂{1,...,m}be the working set\nandα\nB\nbe the corresponding sub-vector ofα. Define\n ̄\nB={1,...,m}\\B\nandα\n ̄\nB\nanalogously. In order to updateα\nB\nwe need to solve the following\n\n7.1  Support Vector Classification173\nsub-problem of (7.9) obtained by freezingα\n ̄\nB\n:\nmin\nα\nB\n1\n2\n[\nα\n>\nB\nα\n>\n ̄\nB\n]\n[\nH\nBB\nH\nB\n ̄\nB\nH\n ̄\nBB\nH\n ̄\nB\n ̄\nB\n][\nα\nB\nα\n ̄\nB\n]\n−\n[\nα\n>\nB\nα\n>\n ̄\nB\n]\ne(7.24a)\ns.t.\n[\nα\n>\nB\nα\n>\n ̄\nB\n]\ny= 0(7.24b)\n0≤α\ni\n≤\nC\nm\nfor alli∈B.(7.24c)\nHere,\n[\nH\nBB\nH\nB\n ̄\nB\nH\n ̄\nBB\nH\n ̄\nB\n ̄\nB\n]\nis  a  permutation  of  the  matrixH.  By  eliminating\nconstant terms and rearranging, one can simplify the above problem to\nmin\nα\nB\n1\n2\nα\n>\nB\nH\nBB\nα\nB\n+α\n>\nB\n(H\n ̄\nBB\nα\n ̄\nB\n−e)(7.25a)\ns.t.α\n>\nB\ny\nB\n=−α\n>\n ̄\nB\ny\n ̄\nB\n(7.25b)\n0≤α\ni\n≤\nC\nm\nfor alli∈B.(7.25c)\nAn extreme case of a decomposition method is the Sequential Minimal Op-\ntimization (SMO) algorithm of Platt [Pla99], which updates only two coef-\nficients per iteration. The advantage of this strategy as we will see below is\nthat the resultant sub-problem can be solved analytically. Without loss of\ngenerality letB={i,j}, and defines=y\ni\n/y\nj\n,\n[\nc\ni\nc\nj\n]\n= (H\n ̄\nBB\nα\n ̄\nB\n−e)\n>\nandd= (−α\n>\n ̄\nB\ny\n ̄\nB\n/y\nj\n). Then (7.25) specializes to\nmin\nα\ni\n,α\nj\n1\n2\n(H\nii\nα\n2\ni\n+H\njj\nα\n2\nj\n+ 2H\nij\nα\nj\nα\ni\n) +c\ni\nα\ni\n+c\nj\nα\nj\n(7.26a)\ns.t.sα\ni\n+α\nj\n=d(7.26b)\n0≤α\ni\n,α\nj\n≤\nC\nm\n.(7.26c)\nThis QP in two variables has an analytic solution.\nLemma 7.1 (Analytic solution of 2 variable QP)Define bounds\nL=\n{\nmax(0,\nd−\nC\nm\ns\n)ifs >0\nmax(0,\nd\ns\n)otherwise\n(7.27)\nH=\n{\nmin(\nC\nm\n,\nd\ns\n)ifs >0\nmin(\nC\nm\n,\nd−\nC\nm\ns\n)otherwise,\n(7.28)\n\n1747  Linear Models\nand auxiliary variables\nχ= (H\nii\n+H\njj\ns\n2\n−2sH\nij\n)and(7.29)\nρ= (c\nj\ns−c\ni\n−H\nij\nd+H\njj\nds).(7.30)\nThe optimal value of(7.26)can be computed analytically as follows: Ifχ= 0\nthen\nα\ni\n=\n{\nLifρ <0\nHotherwise.\nIfχ >0, thenα\ni\n= max(L,min(H,ρ/χ)). In both cases,α\nj\n= (d−sα\ni\n).\nProofEliminate the equality constraint by settingα\nj\n= (d−sα\ni\n). Due to\nthe  constraint  0≤α\nj\n≤\nC\nm\nit  follows  thatsα\ni\n=d−α\nj\ncan  be  bounded\nviad−\nC\nm\n≤sα\ni\n≤d.  Combining  this  with  0≤α\ni\n≤\nC\nm\none  can  write\nL≤α\ni\n≤HwhereLandHare given by (7.27) and (7.28) respectively.\nSubstitutingα\nj\n= (d−sα\ni\n) into the objective function, dropping the terms\nwhich do not depend onα\ni\n, and simplifying by substitutingχandρyields\nthe following optimization problem inα\ni\n:\nmin\nα\ni\n1\n2\nα\n2\ni\nχ−α\ni\nρ\ns.t.L≤α\ni\n≤H.\nFirst consider the case whenχ= 0. In this case,α\ni\n=Lifρ <0 otherwise\nα\ni\n=H. On other hand, ifχ >0 then the unconstrained optimum of the\nabove optimization problem is given byρ/χ. The constrained optimum is\nobtained  by  clipping  appropriately:  max(L,min(H,ρ/χ)).  This  concludes\nthe proof.\nTo complete the description of SMO we need a valid stopping criterion as\nwell as a scheme for selecting the working set at every iteration. In order\nto derive a stopping criterion we will use the KKT gap, that is, the extent\nto which the KKT conditions are violated. Towards this end introduce non-\nnegative Lagrange  multipliersb∈R,λ∈R\nm\nandμ∈R\nm\nand write the\nLagrangian of (7.9).\nL(α,b,λ,μ) =\n1\n2\nα\n>\nHα−α\n>\ne+bα\n>\ny−λ\n>\nα+μ\n>\n(α−\nC\nm\ne).(7.31)\nIf  we  letJ(α)  =\n1\n2\nα\n>\nHα−α\n>\nebe  the  objective  function  and∇J(α)  =\nHα−eits gradient, then taking gradient of the Lagrangian with respect to\nαand setting it to 0 shows that\n∇J(α) +by=λ−μ.(7.32)\n\n7.1  Support Vector Classification175\nFurthermore, by the KKT conditions we have\nλ\ni\nα\ni\n= 0 andμ\ni\n(\nC\nm\n−α\ni\n) = 0,(7.33)\nwithλ\ni\n≥0  andμ\ni\n≥0.  Equations  (7.32)  and  (7.33)  can  be  compactly\nrewritten as\n∇J(α)\ni\n+by\ni\n≥0 ifα\ni\n= 0(7.34a)\n∇J(α)\ni\n+by\ni\n≤0 ifα\ni\n=\nC\nm\n(7.34b)\n∇J(α)\ni\n+by\ni\n= 0 if 0< α\ni\n<\nC\nm\n.(7.34c)\nSincey\ni\n∈{±1}, we can further rewrite (7.34) as\n−y\ni\n∇J(α)\ni\n≤bfor alli∈I\nup\n−y\ni\n∇J(α)\ni\n≥bfor alli∈I\ndown\n,\nwhere the index setsI\nup\nandI\ndown\nare defined as\nI\nup\n={i:α\ni\n<\nC\nm\n,y\ni\n= 1 orα\ni\n>0,y\ni\n=−1}(7.35a)\nI\ndown\n={i:α\ni\n<\nC\nm\n,y\ni\n=−1 orα\ni\n>0,y\ni\n= 1}.(7.35b)\nIn summary, the KKT conditions imply thatαis a solution of  (7.9) if and\nonly if\nm(α)≤M(α)\nwhere\nm(α) = max\ni∈I\nup\n−y\ni\n∇J(α)\ni\nandM(α) =   min\ni∈I\ndown\n−y\ni\n∇J(α)\ni\n.(7.36)\nTherefore, a natural stopping criterion is to stop when the KKT gap falls\nbelow a desired tolerance\u000f, that is,\nm(α)≤M(α) +\u000f.(7.37)\nFinally, we turn our attention to the issue of working set selection. The\nfirst order approximation to the objective functionJ(α) can be written as\nJ(α+d)≈J(α) +∇J(α)\n>\nd.\nSince we are only interested in updating coefficients in the working setB\nwe setd\n>\n=\n[\nd\n>\nB\n0\n]\n, in which case we can rewrite the above first order\n\n1767  Linear Models\napproximation as\n∇J(α)\n>\nB\nd\nB\n≈J(α+d)−J(α).\nFrom among all possible directionsd\nB\nwe wish to choose one which decreases\nthe  objective  function  the  most  while  maintaining  feasibility.  This  is  best\nexpressed as the following optimization problem:\nmin\nd\nB\n∇J(α)\n>\nB\nd\nB\n(7.38a)\ns.t.y\n>\nB\nd\nB\n= 0(7.38b)\nd\ni\n≥0 ifα\ni\n= 0 andi∈B(7.38c)\nd\ni\n≤0 ifα\ni\n=\nC\nm\nandi∈B(7.38d)\n−1≤d\ni\n≤1.(7.38e)\nHere  (7.38b)  comes  fromy\n>\n(α+d)  =  0  andy\n>\nα=  0,  while  (7.38c)  and\n(7.38d)  comes  from  0≤α\ni\n≤\nC\nm\n.  Finally,  (7.38e)  prevents  the  objective\nfunction from diverging to−∞. If we specialize (7.38) to SMO, we obtain\nmin\ni,j\n∇J(α)\ni\nd\ni\n+∇J(α)\nj\nd\nj\n(7.39a)\ns.t.y\ni\nd\ni\n+y\nj\nd\nj\n= 0(7.39b)\nd\nk\n≥0 ifα\nk\n= 0 andk∈{i,j}(7.39c)\nd\nk\n≤0 ifα\nk\n=\nC\nm\nandk∈{i,j}(7.39d)\n−1≤d\nk\n≤1 fork∈{i,j}.(7.39e)\nAt  first  glance,  it  seems  that  choosing  the  optimaliandjfrom  the  set\n{1,...,m}×{1,...m}requiresO(m\n2\n) effort. We now show thatO(m) effort\nsuffices.\nDefine  new  variables\nˆ\nd\nk\n=y\nk\nd\nk\nfork∈ {i,j},  and  use  the  observation\ny\nk\n∈{±1}to rewrite the objective function as\n(−y\ni\n∇J(α)\ni\n+y\nj\n∇J(α)\nj\n)\nˆ\nd\nj\n.\nConsider  the  case−∇J(α)\ni\ny\ni\n≥ −∇J(α)\nj\ny\nj\n.  Because  of  the  constraints\n(7.39c) and (7.39d) if we choosei∈I\nup\nandj∈I\ndown\n, then\nˆ\nd\nj\n=−1 and\nˆ\nd\ni\n= 1 is feasible and the objective function attains a negative value. For\nall other choices ofiandj(i,j∈I\nup\n;i,j∈I\ndown\n;i∈I\ndown\nandj∈I\nup\n)\nthe  objective  function  value  of  0  is  attained  by  setting\nˆ\nd\ni\n=\nˆ\nd\nj\n=  0.  The\ncase−∇J(α)\nj\ny\nj\n≥ −∇J(α)\ni\ny\ni\nis analogous. In summary, the optimization\n\n7.2  Extensions177\nproblem (7.39) boils down to\nmin\ni∈I\nup\n,j∈I\ndown\ny\ni\n∇J(α)\ni\n−y\nj\n∇J(α)\nj\n= min\ni∈I\nup\ny\ni\n∇J(α)\ni\n−max\nj∈I\ndown\ny\nj\n∇J(α)\nj\n,\nwhich clearly can be solved inO(m) time. Comparison with (7.36) shows\nthat at every iteration of SMO we choose to update coefficientsα\ni\nandα\nj\nwhich maximally violate the KKT conditions.\n7.2  Extensions\n7.2.1  Theνtrick\nIn the soft margin formulation the parameterCis a trade-off between two\nconflicting requirements namely maximizing the margin and minimizing the\ntraining error. Unfortunately, this parameter is rather unintuitive and hence\ndifficult to tune. Theν-SVM was proposed to address this issue. As Theorem\n7.3 below shows,νcontrols the number of support vectors and margin errors.\nThe primal problem for theν-SVM can be written as\nmin\nw,b,ξ,ρ\n1\n2\n‖w‖\n2\n−ρ+\n1\nνm\nm\n∑\ni=1\nξ\ni\n(7.40a)\ns.t.y\ni\n(〈w,x\ni\n〉+b)≥ρ−ξ\ni\nfor alli(7.40b)\nξ\ni\n≥0,andρ≥0.(7.40c)\nAs before, if we write the Lagrangian by introducing non-negative Lagrange\nmultipliers, take gradients with respect to the primal variables and set them\nto zero, and substitute the result back into the Lagrangian we obtain the\nfollowing dual:\nmin\nα\n1\n2\n∑\ni,j\ny\ni\ny\nj\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉(7.41a)\ns.t.\nm\n∑\ni=1\nα\ni\ny\ni\n= 0(7.41b)\nm\n∑\ni=1\nα\ni\n≥1(7.41c)\n0≤α\ni\n≤\n1\nνm\n.(7.41d)\nIt turns out that the dual can be further simplified via the following lemma.\n\n1787  Linear Models\nLemma 7.2Letν∈[0,1]and(7.41)be feasible. Then there is at least one\nsolutionαwhich satisfies\n∑\ni\nα\ni\n= 1. Furthermore, if the final objective value\nof(7.41)is non-zero then all solutions satisfy\n∑\ni\nα\ni\n= 1.\nProofThe feasible region of  (7.41) is bounded, therefore if it is feasible\nthen there exists an optimal solution. Letαdenote this solution and assume\nthat\n∑\ni\nα\ni\n>1. In this case we can define\n ̄α=\n1\n∑\nj\nα\nj\nα,\nand easily check that   ̄αis also feasible. As before, letHdenote am×m\nmatrix withH\nij\n=y\ni\ny\nj\n〈x\ni\n,x\nj\n〉. Sinceαis the optimal solution of  (7.41) it\nfollows that\n1\n2\nα\n>\nHα≤\n1\n2\n ̄α\n>\nH ̄α=\n(\n1\n∑\nj\nα\nj\n)\n2\n1\n2\nα\n>\nHα≤\n1\n2\nα\n>\nHα.\nThis implies that either\n1\n2\nα\n>\nHα= 0, in which case  ̄αis an optimal solution\nwith the desired property or\n1\n2\nα\n>\nHα6= 0, in which case all optimal solutions\nsatisfy\n∑\ni\nα\ni\n= 1.\nIn  view  of  the  above  theorem  one  can  equivalently  replace  (7.41)  by  the\nfollowing simplified optimization problem with two equality constraints\nmin\nα\n1\n2\n∑\ni,j\ny\ni\ny\nj\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉(7.42a)\ns.t.\nm\n∑\ni=1\nα\ni\ny\ni\n= 0(7.42b)\nm\n∑\ni=1\nα\ni\n= 1(7.42c)\n0≤α\ni\n≤\n1\nνm\n.(7.42d)\nThe following theorems, which we state without proof, explain the signif-\nicance ofνand the connection betweenν-SVM and the soft margin formu-\nlation.\nTheorem 7.3Suppose  we  runν-SVM  with  kernelkon  some  data  and\nobtainρ >0. Then\n(i)νis  an  upper  bound  on  the  fraction  of  margin  errors,  that  is  points\nfor whichy\ni\n(〈w,x\ni\n〉+b\ni\n)< ρ.\n\n7.2  Extensions179\n(ii)νis  a  lower  bound  on  the  fraction  of  support  vectors,  that  is  points\nfor whichy\ni\n(〈w,x\ni\n〉+b\ni\n) =ρ.\n(iii)Suppose the data(X,Y)were generated iid from a distributionp(x,y)\nsuch  that  neitherp(x,y= +1)orp(x,y=−1)contain  any  discrete\ncomponents. Moreover, assume that the kernelkis analytic and non-\nconstant. With probability 1, asympotically,νequals both the fraction\nof support vectors and fraction of margin errors.\nTheorem 7.4If(7.40)leads to a decision function withρ >0, then(7.5)\nwithC=\n1\nρ\nleads to the same decision function.\n7.2.2  Squared Hinge Loss\nIn binary classification, the actual loss which one would like to minimize is\nthe so-called 0-1 loss\nl(w,x,y) =\n{\n0ify(〈w,x〉+b)≥1\n1otherwise.\n(7.43)\nThis loss is difficult to work with because it is non-convex (see Figure 7.4). In\ny(〈w,x〉+b)\nloss\nFig. 7.4.  The 0-1 loss which is non-convex and intractable is depicted in red. The\nhinge loss is a convex upper bound to the 0-1 loss and shown in blue. The square\nhinge loss is a differentiable convex upper bound to the 0-1 loss and is depicted in\ngreen.\nfact, it has been shown that finding the optimal (w,b) pair which minimizes\nthe 0-1 loss on a training dataset ofmlabeled points is NP hard [BDEL03].\nTherefore various proxy functions such as the binary hinge loss (7.13) which\nwe discussed in Section 7.1.1 are used. Another popular proxy is the square\n\n1807  Linear Models\nhinge loss:\nl(w,x,y) = max(0,1−y(〈w,x〉+b))\n2\n.(7.44)\nBesides  being  a  proxy  for  the  0-1  loss,  the  squared  hinge  loss,  unlike  the\nhinge loss, is also differentiable everywhere. This sometimes makes the opti-\nmization in the primal easier. Just like in the case of the hinge loss one can\nderive the dual of the regularized risk minimization problem and show that\nit is a quadratic programming problem (problem 7.5).\n7.2.3  Ramp Loss\nThe ramp loss\nl(w,x,y) = min(1−s,max(0,1−y(〈w,x〉+b)))(7.45)\nparameterized bys≤0 is another proxy for the 0-1 loss (see Figure 7.5).\nAlthough  not  convex,  it  can  be  expressed  as  the  difference  of  two  convex\nfunctions\nl\nconc\n(w,x,y) = max(0,1−y(〈w,x〉+b)) and\nl\ncave\n(w,x,y) = max(0,s−y(〈w,x〉+b)).\nTherefore the Convex-Concave procedure (CCP) we discussed in Section\nFig.  7.5.  The  ramp  loss  depicted  here  withs=−0.3  can  be  viewed  as  the  sum\nof  a  convex  function  namely  the  binary  hinge  loss  (left)  and  a  concave  function\nmin(0,1−y(〈w,x〉+b)) (right). Viewed alternatively, the ramp loss can be written\nas the difference of two convex functions.\n3.5.1 can be used to solve the resulting regularized risk minimization problem\nwith the ramp loss. Towards this end write\nJ(w) =\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nl\nconc\n(w,x\ni\n,y\ni\n)\n︸︷︷︸\nJ\nconc\n(w)\n−\nC\nm\nm\n∑\ni=1\nl\ncave\n(w,x\ni\n,y\ni\n)\n︸︷︷︸\nJ\ncave\n(w)\n.(7.46)\n\n7.3  Support Vector Regression181\nRecall  that  at  every  iteration  of  the  CCP  we  replaceJ\ncave\n(w)  by  its  first\norder Taylor approximation, computing which requires\n∂\nw\nJ(w) =\nC\nm\nm\n∑\ni=1\n∂\nw\nl\ncave\n(w,x\ni\n,y\ni\n).(7.47)\nThis in turn can be computed as\n∂\nw\nl\ncave\n(w,x\ni\n,y\ni\n) =δ\ni\ny\ni\nx\ni\nwithδ\ni\n=\n{\n−1ifs > y(〈w,x〉+b)\n0otherwise.\n(7.48)\nIgnoring constant terms, each iteration of the CCP algorithm involves solv-\ning the following minimization problem (also see (3.134))\nJ(w) =\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nl\nconc\n(w,x\ni\n,y\ni\n)−\n(\nC\nm\nm\n∑\ni=1\nδ\ni\ny\ni\nx\ni\n)\nw.(7.49)\nLetδdenote a vector inR\nm\nwith componentsδ\ni\n. Using the same notation\nas in (7.9) we can write the following dual optimization problem which is\nvery closely related to the standard SVM dual (7.9) (see problem 7.6)\nmin\nα\n1\n2\nα\n>\nHα−α\n>\ne(7.50a)\ns.t.α\n>\ny= 0(7.50b)\n−\nC\nm\nδ≤α\ni\n≤\nC\nm\n(e−δ).(7.50c)\nIn fact, this problem can be solved by a SMO solver with minor modifica-\ntions. Putting everything together yields Algorithm 7.1.\nAlgorithm 7.1CCP for Ramp Loss\n1:Initializeδ\n0\nandα\n0\n2:repeat\n3:Solve (7.50) to findα\nt+1\n4:Computeδ\nt+1\nusing (7.48)\n5:untilδ\nt+1\n=δ\nt\n7.3  Support Vector Regression\nAs  opposed  to  classification  where  the  labelsy\ni\nare  binary  valued,  in  re-\ngression they are real valued. Given a tolerance\u000f, our aim here is to find a\n\n1827  Linear Models\ny−(〈w,x〉+b)\nloss\n\u000f\nFig.  7.6.  The\u000finsensitive  loss.  All  points  which  lie  within  the\u000ftube  shaded  in\ngray incur zero loss while points outside incur a linear loss.\nhyperplane parameterized by (w,b) such that\n|y\ni\n−(〈w,x\ni\n〉+b)|≤\u000f.(7.51)\nIn other words, we want to find a hyperplane such that all the training data\nlies within an\u000ftube around the hyperplane. We may not always be able to\nfind such a hyperplane, hence we relax the above condition by introducing\nslack variablesξ\n+\ni\nandξ\n−\ni\nand write the corresponding primal problem as\nmin\nw,b,ξ\n+\n,ξ\n−\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\n(ξ\n+\ni\n+ξ\n−\ni\n)(7.52a)\ns.t.y\ni\n−(〈w,x\ni\n〉+b)≤\u000f+ξ\n+\ni\nfor alli(7.52b)\n(〈w,x\ni\n〉+b)−y\ni\n≤\u000f+ξ\n−\ni\nfor alli(7.52c)\nξ\n+\ni\n≥0,andξ\n−\ni\n≥0.(7.52d)\nThe Lagrangian can be written by introducing non-negative Lagrange mul-\ntipliersα\n+\ni\n,α\n−\ni\n,β\n+\ni\nandβ\n−\ni\n:\nL(w,b,ξ\n+\n,ξ\n−\n,α\n+\n,α\n−\n,β\n+\n,β\n−\n) =\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\n(ξ\n+\ni\n+ξ\n−\ni\n)−\nm\n∑\ni=1\n(β\n+\ni\nξ\n+\ni\n+β\n−\ni\nξ\n−\ni\n)\n+\nm\n∑\ni=1\nα\n+\ni\n(y\ni\n−(〈w,x\ni\n〉+b)−\u000f−ξ\n+\n)\n+\nm\n∑\ni=1\nα\n−\ni\n((〈w,x\ni\n〉+b)−y\ni\n−\u000f−ξ\n−\n).\n\n7.3  Support Vector Regression183\nTaking gradients with respect to the primal variables and setting them to\n0, we obtain the following conditions:\nw=\nm\n∑\ni=1\n(α\n+\ni\n−α\n−\ni\n)x\ni\n(7.53)\nm\n∑\ni=1\nα\n+\ni\n=\nm\n∑\ni=1\nα\n−\ni\n(7.54)\nα\n+\ni\n+β\n+\ni\n=\nC\nm\n(7.55)\nα\n−\ni\n+β\n−\ni\n=\nC\nm\n.(7.56)\nNoting thatα\n{+,−}\ni\n,β\n{+,−}\ni\n≥0 and substituting the above conditions into\nthe Lagrangian yields the dual\nmin\nα\n+\n,α\n−\n1\n2\n∑\ni,j\n(α\n+\ni\n−α\n−\ni\n)(α\n+\nj\n−α\n−\nj\n)〈x\ni\n,x\nj\n〉(7.57a)\n+\u000f\nm\n∑\ni=1\n(α\n+\ni\n+α\n−\ni\n)−\nm\n∑\ni=1\ny\ni\n(α\n+\ni\n−α\n−\ni\n)\ns.t.\nm\n∑\ni=1\nα\n+\ni\n=\nm\n∑\ni=1\nα\n−\ni\n(7.57b)\n0≤α\n+\ni\n≤\nC\nm\n(7.57c)\n0≤α\n−\ni\n≤\nC\nm\n.(7.57d)\nThis is a quadratic programming problem with one equality constraint, and\nhence  a  SMO  like  decomposition  method  can  be  derived  for  finding  the\noptimal coefficientsα\n+\nandα\n−\n(Problem 7.7).\nAs a consequence of  (7.53), analogous to the classification case, one can\nmap the data via a feature mapφinto an RKHS with kernelkand recover\nthe decision boundaryf(x) =〈w,φ(x)〉+bvia\nf(x) =\nm\n∑\ni=1\n(α\n+\ni\n−α\n−\ni\n)〈φ(x)\ni\n,φ(x)〉+b=\nm\n∑\ni=1\n(α\n+\ni\n−α\n−\ni\n)k(x\ni\n,x) +b.(7.58)\nFinally, the KKT conditions\n(\nC\nm\n−α\n+\ni\n)\nξ\n+\ni\n= 0\n(\nC\nm\n−α\n−\ni\n)\nξ\n−\ni\n= 0 and\nα\n−\ni\n((〈w,x\ni\n〉+b)−y\ni\n−\u000f−ξ\n−\n) = 0α\n+\ni\n(y\ni\n−(〈w,x\ni\n〉+b)−\u000f−ξ\n+\n) = 0,\n\n1847  Linear Models\nallow us to draw many useful conclusions:\n•Whenever|y\ni\n−(〈w,x\ni\n〉+b)|< \u000f,  this  implies  thatξ\n+\ni\n=ξ\n−\ni\n=α\n+\ni\n=\nα\n−\ni\n=  0.  In  other  words,  points  which  lie  inside  the\u000ftube  around  the\nhyperplane〈w,x〉+bdo  not  contribute  to  the  solution  thus  leading  to\nsparse expansions in terms ofα.\n•If (〈w,x\ni\n〉+b)−y\ni\n> \u000fwe haveξ\n−\ni\n>0 and thereforeα\n−\ni\n=\nC\nm\n. On the other\nhand,ξ\n+\n= 0 andα\n+\ni\n= 0. The casey\ni\n−(〈w,x\ni\n〉+b)> \u000fis symmetric\nand yieldsξ\n−\n= 0,ξ\n+\ni\n>0,α\n+\ni\n=\nC\nm\n, andα\n−\ni\n= 0.\n•Finally, if (〈w,x\ni\n〉+b)−y\ni\n=\u000fwe haveξ\n−\ni\n= 0 and 0≤α\n−\ni\n≤\nC\nm\n, while\nξ\n+\n=  0  andα\n+\ni\n=  0.  Similarly,  wheny\ni\n−(〈w,x\ni\n〉+b)  =\u000fwe  obtain\nξ\n+\ni\n= 0, 0≤α\n+\ni\n≤\nC\nm\n,ξ\n−\n= 0 andα\n−\ni\n= 0.\nNote thatα\n+\ni\nandα\n−\ni\nare never simultaneously non-zero.\n7.3.1  Incorporating General Loss Functions\nUsing the same reasoning as in Section 7.1.1 we can deduce from (7.52) that\nthe loss function of support vector regression is given by\nl(w,x,y) = max(0,|y−〈w,x〉|−\u000f).(7.59)\nIt  turns  out  that  the  support  vector  regression  framework  can  be  easily\nextended to handle other, more general, convex loss functions such as the\nones found in Table 7.1. Different losses have different properties and hence\nlead to different estimators. For instance, the square loss leads to penalized\nleast squares (LS) regression, while the Laplace loss leads to the penalized\nleast absolute deviations (LAD) estimator. Huber’s loss on the other hand is\na combination of the penalized LS and LAD estimators, and the pinball loss\nwith parameterτ∈[0,1] is used to estimateτ-quantiles. Settingτ= 0.5\nin the pinball loss leads to a scaled version of the Laplace loss. If we define\nξ=y−〈w,x〉, then it is easily verified that all these losses can all be written\nas\nl(w,x,y) =\n\n\n\n\n\nl\n+\n(ξ−\u000f)ifξ > \u000f\nl\n−\n(−ξ−\u000f)ifξ < \u000f\n0ifξ∈[−\u000f,\u000f].\n(7.60)\nFor all these different loss functions, the support vector regression formu-\n\n7.3  Support Vector Regression185\nlation can be written in a unified fashion as follows\nmin\nw,b,ξ\n+\n,ξ\n−\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nl\n+\n(ξ\n+\ni\n) +l\n−\n(ξ\n−\ni\n)(7.61a)\ns.t.y\ni\n−(〈w,x\ni\n〉+b)≤\u000f+ξ\n+\ni\nfor alli(7.61b)\n(〈w,x\ni\n〉+b)−y\ni\n≤\u000f+ξ\n−\ni\nfor alli(7.61c)\nξ\n+\ni\n≥0,andξ\n−\ni\n≥0.(7.61d)\nThe dual in this case is given by\nmin\nα\n+\n,α\n−\n1\n2\n∑\ni,j\n(α\n+\ni\n−α\n−\ni\n)(α\n+\nj\n−α\n−\nj\n)〈x\ni\n,x\nj\n〉(7.62a)\n−\nC\nm\nm\n∑\ni=1\nT\n+\n(ξ\n+\n) +T\n−\n(ξ\n−\n) +\u000f\nm\n∑\ni=1\n(α\n+\ni\n+α\n−\ni\n)−\nm\n∑\ni=1\ny\ni\n(α\n+\ni\n−α\n−\ni\n)\ns.t.\nm\n∑\ni=1\nα\n+\ni\n=\nm\n∑\ni=1\nα\n−\ni\n(7.62b)\n0≤α\n{+,−}\ni\n≤\nC\nm\n∂\nξ\nl\n{+,−}\n(ξ\n{+,−}\ni\n)(7.62c)\n0≤ξ\n{+,−}\ni\n(7.62d)\nξ\n{+,−}\ni\n= inf\n{\nξ\n{+,−}\n|\nC\nm\n∂\nξ\nl\n{+,−}\n≥α\n{+,−}\ni\n}\n.(7.62e)\nHereT\n+\n(ξ) =l\n+\n(ξ)−ξ∂\nξ\nl\n+\n(ξ) andT\n−\n(ξ) =l\n−\n(ξ)−ξ∂\nξ\nl\n−\n(ξ). We now show\nhow (7.62) can be specialized to the pinball loss. Clearly,l\n+\n(ξ) =τξwhile\nl\n−\n(−ξ) = (τ−1)ξ, and hencel\n−\n(ξ) = (1−τ)ξ. Therefore,T\n+\n(ξ) = (τ−1)ξ−\nξ(τ−1) = 0. SimilarlyT\n−\n(ξ) = 0. Since∂\nξ\nl\n+\n(ξ) =τand∂\nξ\nl\n−\n(ξ) = (1−τ)\nfor  allξ≥0,  it  follows  that  the  bounds  onα\n{+,−}\ncan  be  computed  as\n0≤α\n+\ni\n≤\nC\nm\nτand  0≤α\n−\ni\n≤\nC\nm\n(1−τ).  If  we  denoteα=α\n+\n−α\n−\nand\nTable 7.1.Various loss functions which can be used in support vector\nregression. For brevity we denotey−〈w,x〉asξand write the loss\nl(w,x,y)in terms ofξ.\n\u000f-insensitive lossmax(0,|ξ|−\u000f)\nLaplace loss|ξ|\nSquare loss\n1\n2\n|ξ|\n2\nHuber’s robust loss\n{\n1\n2σ\nξ\n2\nif|ξ|≤σ\n|ξ|−\nσ\n2\notherwise\nPinball loss\n{\nτξifξ≥0\n(τ−1)ξotherwise.\n\n1867  Linear Models\nobserve that\u000f= 0 for the pinball loss then (7.62) specializes as follows:\nmin\nα\n1\n2\n∑\ni,j\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉−\nm\n∑\ni=1\ny\ni\nα\ni\n(7.63a)\ns.t.\nm\n∑\ni=1\nα\ni\n= 0(7.63b)\nC\nm\n(τ−1)≤α\ni\n≤\nC\nm\nτ.(7.63c)\nSimilar specializations of (7.62) for other loss functions in Table 7.1 can be\nderived.\n7.3.2  Incorporating theνTrick\nOne  can  also  incorporate  theνtrick  into  support  vector  regression.  The\nprimal problem obtained after incorporating theνtrick can be written as\nmin\nw,b,ξ\n+\n,ξ\n−\n,\u000f\n1\n2\n‖w‖\n2\n+\n(\n\u000f+\n1\nνm\nm\n∑\ni=1\n(ξ\n+\ni\n+ξ\n−\ni\n)\n)\n(7.64a)\ns.t.    (〈w,x\ni\n〉+b)−y\ni\n≤\u000f+ξ\n+\ni\nfor alli(7.64b)\ny\ni\n−(〈w,x\ni\n〉+b)≤\u000f+ξ\n−\ni\nfor alli(7.64c)\nξ\n+\ni\n≥0,ξ\n−\ni\n≥0,and\u000f≥0.(7.64d)\nProceeding as before we obtain the following simplified dual\nmin\nα\n+\n,α\n−\n1\n2\n∑\ni,j\n(α\n−\ni\n−α\n+\ni\n)(α\n−\nj\n−α\n+\nj\n)〈x\ni\n,x\nj\n〉−\nm\n∑\ni=1\ny\ni\n(α\n−\ni\n−α\n+\ni\n)(7.65a)\ns.t.\nm\n∑\ni=1\n(α\n−\ni\n−α\n+\ni\n) = 0(7.65b)\nm\n∑\ni=1\n(α\n−\ni\n+α\n+\ni\n) = 1(7.65c)\n0≤α\n+\ni\n≤\n1\nνm\n(7.65d)\n0≤α\n−\ni\n≤\n1\nνm\n.(7.65e)\n7.4  Novelty Detection\nThe large margin approach can also be adapted to perform novelty detection\nor quantile estimation. Novelty detection is an unsupervised task where one\n\n7.4  Novelty Detection187\nis interested in flagging a small fraction of the inputX={x\n1\n,...,x\nm\n}as\natypical or novel. It can be viewed as a special case of the quantile estimation\ntask, where we are interested in estimating asimplesetCsuch thatPr(x∈\nC)≥μfor  someμ∈[0,1].  One  way  to  measure  simplicity  is  to  use  the\nvolume  of  the  set.  Formally,  if|C|denotes  the  volume  of  a  set,  then  the\nquantile estimation task is to estimate\narginf{|C|s.t.Pr(x∈C)≥μ}.(7.66)\nGiven the input dataXone can compute the empirical density\nˆp(x) =\n{\n1\nm\nifx∈X\n0otherwise,\nand  estimate  its  (not  necessarily  unique)μ-quantiles.  Unfortunately,  such\nestimates are very brittle and do not generalize well to unseen data. One\npossible way to address this issue is to restrictCto be simple subsets such\nas  spheres  or  half  spaces.  In  other  words,  we  estimate  simple  sets  which\ncontainμfraction  of  the  dataset.  For  our  purposes,  we  specifically  work\nwith half-spaces defined by hyperplanes. While half-spaces may seem rather\nrestrictive  remember  that  the  kernel  trick  can  be  used  to  map  data  into\na  high-dimensional  space;  half-spaces  in  the  mapped  space  correspond  to\nnon-linear decision boundaries in the input space. Furthermore, instead of\nexplicitly identifyingCwe will learn an indicator function forC, that is, a\nfunctionfwhich takes on values−1 insideCand−1 elsewhere.\nWith\n1\n2\n‖w‖\n2\nas a regularizer, the problem of estimating a hyperplane such\nthat a large fraction of the points in the input dataXlie on one of its sides\ncan be written as:\nmin\nw,ξ,ρ\n1\n2\n‖w‖\n2\n+\n1\nνm\nm\n∑\ni=1\nξ\ni\n−ρ(7.67a)\ns.t.〈w,x\ni\n〉≥ρ−ξ\ni\nfor alli(7.67b)\nξ\ni\n≥0.(7.67c)\nClearly, we wantρto be as large as possible so that the volume of the half-\nspace〈w,x〉≥ρis minimized. Furthermore,ν∈[0,1] is a parameter which\nis analogous toνwe introduced for theν-SVM earlier. Roughly speaking,\nit denotes the fraction of input data for which〈w,x\ni\n〉 ≤ρ. An alternative\ninterpretation of  (7.67) is to assume that we are separating the data setX\nfrom the origin (See Figure 7.7 for an illustration). Therefore, this method\nis also widely known as the one-class SVM.\n\n1887  Linear Models\nFig. 7.7.  The novelty detection problem can be viewed as finding a large margin\nhyperplane which separatesνfraction of the data points away from the origin.\nThe  Lagrangian  of  (7.67)  can  be  written  by  introducing  non-negative\nLagrange multipliersα\ni\n, andβ\ni\n:\nL(w,ξ,ρ,α,β) =\n1\n2\n‖w‖\n2\n+\n1\nνm\nm\n∑\ni=1\nξ\ni\n−ρ+\nm\n∑\ni=1\nα\ni\n(ρ−ξ\ni\n−〈w,x\ni\n〉)−\nm\n∑\ni=1\nβ\ni\nξ\ni\n.\nBy taking gradients with respect to the primal variables and setting them\nto 0 we obtain\nw=\nm\n∑\ni=1\nα\ni\nx\ni\n(7.68)\nα\ni\n=\n1\nνm\n−β\ni\n≤\n1\nνm\n(7.69)\nm\n∑\ni=1\nα\ni\n= 1.(7.70)\nNoting thatα\ni\n,β\ni\n≥0 and substituting the above conditions into the La-\ngrangian yields the dual\nmin\nα\n1\n2\n∑\ni,j\nα\ni\nα\nj\n〈x\ni\n,x\nj\n〉(7.71a)\ns.t.  0≤α\ni\n≤\n1\nνm\n(7.71b)\nm\n∑\ni=1\nα\ni\n= 1.(7.71c)\n\n7.5  Margins and Probability189\nThis  can  easily  be  solved  by  a  straightforward  modification  of  the  SMO\nalgorithm (see Section 7.1.3 and Problem 7.7). Like in the previous sections,\nan analysis of the KKT conditions shows that 0< αif and only if〈w,x\ni\n〉≤ρ;\nsuch points are called support vectors. As before, we can replace〈x\ni\n,x\nj\n〉by\na kernelk(x\ni\n,x\nj\n) to transform half-spaces in the feature space to non-linear\nshapes in the input space. The following theorem explains the significance\nof the parameterν.\nTheorem 7.5Assume that the solution of(7.71)satisfiesρ6= 0, then the\nfollowing statements hold:\n(i)νis an upper bound on the fraction of support vectors, that is points\nfor which〈w,x\ni\n〉≤ρ.\n(ii)Suppose the dataXwere generated independently from a distribution\np(x)which does not contain discrete components. Moreover, assume\nthat  the  kernelkis  analytic  and  non-constant.  With  probability  1,\nasympotically,νequals the fraction of support vectors.\n7.5  Margins and Probability\ndiscuss  the  connection  between  probabilistic  models  and  linear  classifiers.\nissues of consistency, optimization, efficiency, etc.\n7.6  Beyond Binary Classification\nIn contrast to binary classification where there are only two possible ways\nto label a training sample, in some of the extensions we discuss below each\ntraining  sample  may  be  associated  with  one  or  more  ofkpossible  labels.\nTherefore, we will use the decision function\ny\n∗\n=  argmax\ny∈{1,...,k}\nf(x,y) wheref(x,y) =〈φ(x,y),w〉.(7.72)\nRecall  that  the  joint  feature  mapφ(x,y)  was  introduced  in  section  7.1.2.\nOne way to interpret the above equation is to viewf(x,y) as a compatibility\nscore between instancexand labely; we assign the label with the highest\ncompatibility  score  tox.  There  are  a  number  of  extensions  of  the  binary\nhinge loss (7.13) which can be used to estimate this score function. In all\nthese cases the objective function is written as\nmin\nw\nJ(w) :=\nλ\n2\n‖w‖\n2\n+\n1\nm\nm\n∑\ni=1\nl(w,x\ni\n,y\ni\n).(7.73)\n\n1907  Linear Models\nHereλis a scalar which trades off the regularizer\n1\n2\n‖w‖\n2\nwith the empirical\nrisk\n1\nm\n∑\nm\ni=1\nl(w,x\ni\n,y\ni\n). Plugging in different loss functions yields classifiers\nfor different settings. Two strategies exist for finding the optimalw. Just\nlike  in  the  binary  SVM  case,  one  can  compute  and  maximize  the  dual  of\n(7.73). However, the number of dual variables becomesm|Y|, wheremis the\nnumber of training points and|Y|denotes the size of the label set. The second\nstrategy is to optimize (7.73) directly. However, the loss functions we discuss\nbelow are non-smooth, therefore non-smooth optimization algorithms such\nas bundle methods (section 3.2.7) need to be used.\n7.6.1  Multiclass Classification\nIn multiclass classification a training example is labeled with one ofkpos-\nsible labels, that is,Y={1,...,k}. We discuss two different extensions of\nthe binary hinge loss to the multiclass setting. It can easily be verified that\nsettingY={±1}andφ(x,y) =\ny\n2\nφ(x) recovers the binary hinge loss in both\ncases.\n7.6.1.1  Additive Multiclass Hinge Loss\nA  natural  generalization  of  the  binary  hinge  loss  is  to  penalize  all  labels\nwhich have been misclassified. The loss can now be written as\nl(w,x,y) =\n∑\ny\n′\n6=y\nmax\n(\n0,1−(\n〈\nφ(x,y)−φ(x,y\n′\n),w\n〉\n)\n)\n.(7.74)\n7.6.1.2  Maximum Multiclass Hinge Loss\nAnother variant of (7.13) penalizes only the maximally violating label:\nl(w,x,y) := max\n(\n0,max\ny\n′\n6=y\n(1−\n〈\nφ(x,y)−φ(x,y\n′\n),w\n〉\n)\n)\n.(7.75)\nNote that both (7.74) and (7.75) are zero whenever\nf(x,y) =〈φ(x,y),w〉≥1 + max\ny\n′\n6=y\n〈\nφ(x,y\n′\n),w\n〉\n= 1 + max\ny\n′\n6=y\nf(x,y\n′\n).(7.76)\nIn other words, they both ensure an adequate margin of separation, in this\ncase  1,  between  the  score  of  the  true  labelf(x,y)  and  every  other  label\nf(x,y\n′\n). However, they differ in the way they penalize violators, that is, la-\nbelsy\n′\n6=yfor whichf(x,y)≤1 +f(x,y\n′\n). In one case we linearly penalize\nthe violators and sum up their contributions while in the other case we lin-\nearly penalize only the maximum violator. In fact, (7.75) can be interpreted\n\n7.6  Beyond Binary Classification191\nas the log odds ratio in the exponential family. Towards this end chooseη\nsuch that logη= 1 and rewrite (7.20):\nlog\np(y|x,w)\nmax\ny\n′\n6=y\np(y\n′\n|x,w)\n=\n〈\nφ(x,y)−max\ny\n′\n6=y\nφ(x,y\n′\n),w\n〉\n≥1.\nRearranging yields (7.76).\n7.6.2  Multilabel Classification\nIn multilabel classification one or more ofkpossible labels are assigned to\na training example. Just like in the multiclass case two different losses can\nbe defined.\n7.6.2.1  Additive Multilabel Hinge Loss\nIf we letY\nx\n⊆Ydenote the labels assigned tox, and generalize the hinge\nloss to penalize all labelsy\n′\n/∈Y\nx\nwhich have been assigned higher score than\nsomey∈Y\nx\n, then the loss can be written as\nl(w,x,y) =\n∑\ny∈Y\nx\nandy\n′\n/∈Y\nx\nmax\n(\n0,1−(\n〈\nφ(x,y)−φ(x,y\n′\n),w\n〉\n)\n)\n.(7.77)\n7.6.2.2  Maximum Multilabel Hinge Loss\nAnother variant only penalizes the maximum violating pair. In this case the\nloss can be written as\nl(w,x,y) = max\n(\n0,max\ny∈Y\nx\n,y\n′\n/∈Y\nx\n[\n1−\n(〈\nφ(x,y)−φ(x,y\n′\n),w\n〉)]\n)\n.(7.78)\nOne can immediately verify that specializing the above losses to the mul-\nticlass  case  recovers  (7.74)  and  (7.75)  respectively,  while  the  binary  case\nrecovers (7.13). The above losses are zero only when\nmin\ny∈Y\nx\nf(x,y) = min\ny∈Y\nx\n〈φ(x,y),w〉≥1 + max\ny\n′\n/∈Y\nx\n〈\nφ(x,y\n′\n),w\n〉\n= 1 + max\ny\n′\n/∈Y\nx\nf(x,y\n′\n).\nThis  can  be  interpreted  as  follows:  The  losses  ensure  that  all  the  labels\nassigned toxhave larger scores compared to labels not assigned toxwith\nthe margin of separation of at least 1.\nAlthough  the  above  loss  functions  are  compatible  with  multiple  labels,\nthe  prediction  function  argmax\ny\nf(x,y)  only  takes  into  account  the  label\nwith the highest score. This is a significant drawback of such models, which\ncan  be  overcome  by  using  a  multiclass  approach  instead.  Let|Y|be  the\nsize of the label set andz∈R\n|Y|\ndenote a vector with±1 entries. We set\n\n1927  Linear Models\nz\ny\n= +1 if they∈Y\nx\nandz\ny\n=−1 otherwise, and use the multiclass loss\n(7.75) onz. To predict we computez\n∗\n= argmax\nz\nf(x,z) and assign tox\nthe  labels  corresponding  to  components  ofz\n∗\nwhich  are  +1.  Sincezcan\ntake on 2\n|Y|\npossible values, this approach is not feasible if|Y|is large. To\ntackle such problems, and to further reduce the computational complexity\nwe assume that the labels correlations are captured via a|Y|×|Y|positive\nsemi-definite  matrixP,  andφ(x,y)  can  be  written  asφ(x)⊗Py.  Here⊗\ndenotes  the  Kronecker  product.  Furthermore,  we  express  the  vectorwas\nan×|Y|matrixW,  wherendenotes  the  dimension  ofφ(x).  With  these\nassumptions〈φ(x)⊗P(z−z\n′\n),w〉can be rewritten as\n〈\nφ(x)\n>\nWP,(z−z\n′\n)\n〉\n=\n∑\ni\n[\nφ(x)\n>\nWP\n]\ni\n(z\ni\n−z\n′\ni\n),\nand (7.78) specializes to\nl(w,x,z) := max\n(\n0,\n(\n1−\n∑\ni\nmin\nz\n′\ni\n6=z\ni\n[\nφ(x)\n>\nWP\n]\ni\n(z\ni\n−z\n′\ni\n)\n))\n.(7.79)\nA analogous specialization of  (7.77) can also be derived wherein the mini-\nmum is replaced by a summation. Since the minimum (or summation as the\ncase may be) is over|Y|possible labels, computing the loss is tractable even\nif the set of labelsYis large.\n7.6.3  Ordinal Regression and Ranking\nWe  can  generalize  our  above  discussion  to  consider  slightly  more  general\nranking problems. Denote byYthe set of all directed acyclic graphs onN\nnodes. The presence of an edge (i,j) iny∈Yindicates thatiis preferred\ntoj. The goal is to find a functionf(x,i) which imposes a total order on\n{1,...,N}which is in close agreement withy. Specifically, if the estimation\nerror is given by the number of subgraphs ofywhich are in disagreement\nwith the total order imposed byf, then the additive version of the loss can\nbe written as\nl(w,x,y) =\n∑\nG∈A(y)\nmax\n(i,j)∈G\n(0,1−(f(x,i)−f(x,j))),(7.80)\nwhereA(y) denotes the set of all possible subgraphs ofy. The maximum\nmargin version, on the other hand, is given by\nl(w,x,y) =   max\nG∈A(y)\nmax\n(i,j)∈G\n(0,1−(f(x,i)−f(x,j))).(7.81)\n\n7.7  Large Margin Classifiers with Structure193\nIn other words, we test for each subgraphGofyif the ranking imposed byG\nis satisfied byf. Selecting specific types of directed acyclic graphs recovers\nthe multiclass and multilabel settings (problem 7.9).\n7.7  Large Margin Classifiers with Structure\n7.7.1  Margin\ndefine margin pictures\n7.7.2  Penalized Margin\ndifferent types of loss, rescaling\n7.7.3  Nonconvex Losses\nthe max - max loss\n7.8  Applications\n7.8.1  Sequence Annotation\n7.8.2  Matching\n7.8.3  Ranking\n7.8.4  Shortest Path Planning\n7.8.5  Image Annotation\n7.8.6  Contingency Table Loss\n7.9  Optimization\n7.9.1  Column Generation\nsubdifferentials\n7.9.2  Bundle Methods\n7.9.3  Overrelaxation in the Dual\nwhen we cannot do things exactly\n\n1947  Linear Models\n7.10  CRFs vs Structured Large Margin Models\n7.10.1  Loss Function\n7.10.2  Dual Connections\n7.10.3  Optimization\nProblems\nProblem 7.1 (Deriving the Margin{1})Show  that  the  distance  of  a\npointx\ni\nto  a  hyperplaneH={x|〈w,x〉+b= 0}is  given  by|〈w,x\ni\n〉+\nb|/‖w‖.\nProblem 7.2 (SVM without Bias{1})A homogeneous hyperplane is one\nwhich passes through the origin, that is,\nH={x|〈w,x〉= 0}.(7.82)\nIf we devise a soft margin classifier which uses the homogeneous hyperplane\nas a decision boundary, then the corresponding primal optimization problem\ncan be written as follows:\nmin\nw,ξ\n1\n2\n‖w‖\n2\n+C\nm\n∑\ni=1\nξ\ni\n(7.83a)\ns.t.y\ni\n〈w,x\ni\n〉≥1−ξ\ni\nfor alli(7.83b)\nξ\ni\n≥0,(7.83c)\nDerive  the  dual  of(7.83)and  contrast  it  with(7.9).  What  changes  to  the\nSMO algorithm would you make to solve this dual?\nProblem 7.3 (Deriving the simplifiedν-SVM dual{2})In Lemma 7.2\nwe  used(7.41)to  show  that  the  constraint\n∑\ni\nα\ni\n≥1can  be  replaced  by\n∑\ni\nα\ni\n= 1. Show that an equivalent way to arrive at the same conclusion is\nby arguing that the constraintρ≥0is redundant in the primal(7.40).Hint:\nObserve that wheneverρ <0the objective function is always non-negative.\nOn  the  other  hand,  settingw=ξ=b=ρ= 0yields  an  objective  function\nvalue of0.\nProblem 7.4 (Fenchel and Lagrange Duals{2})We  derived  the  La-\ngrange dual of(7.12)in Section 7.1 and showed that it is(7.9). Derive the\nFenchel  dual  of(7.12)and  relate  it  to(7.9).Hint:See  theorem  3.3.5  of\n[BL00].\n\n7.10  CRFs vs Structured Large Margin Models195\nProblem 7.5 (Dual of the square hinge loss{1})The analog of(7.5)\nwhen working with the square hinge loss is the following\nmin\nw,b,ξ\n1\n2\n‖w‖\n2\n+\nC\nm\nm\n∑\ni=1\nξ\n2\ni\n(7.84a)\ns.t.y\ni\n(〈w,x\ni\n〉+b)≥1−ξ\ni\nfor alli(7.84b)\nξ\ni\n≥0,(7.84c)\nDerive  the  Lagrange  dual  of  the  above  optimization  problem  and  show  that\nit a Quadratic Programming problem.\nProblem 7.6 (Dual of the ramp loss{1})Derive the Lagrange dual of\n(7.49)and show that it the Quadratic Programming problem(7.50).\nProblem 7.7 (SMO for various SVM formulations{2})Derive an SMO\nlike decomposition algorithm for solving the dual of the following problems:\n•ν-SVM(7.41).\n•SV regression(7.57).\n•SV novelty detection(7.71).\nProblem 7.8 (Novelty detection with Balls{2})In Section 7.4 we as-\nsumed that we wanted to estimate a halfspace which contains a major frac-\ntion  of  the  input  data.  An  alternative  approach  is  to  use  balls,  that  is,  we\nestimate a ball of small radius in feature space which encloses a majority of\nthe input data. Write the corresponding optimization problem and its dual.\nShow that if the kernel is translation invariant, that is,k(x,x\n′\n)depends only\non‖x−x\n′\n‖then the optimization problem with balls is equivalent to(7.71).\nExplain why this happens geometrically.\nProblem 7.9 (Multiclass and Multilabel loss from Ranking Loss{1})\nShow  how  the  multiclass  (resp.  multilabel)  losses(7.74)and(7.75)(resp.\n(7.77)and(7.79))  can  be  derived  as  special  cases  of(7.80)and(7.81)re-\nspectively.\nProblem 7.10Invariances (basic loss)\nProblem 7.11Polynomial transformations - SDP constraints\n\n\n\nAppendix 1\nLinear Algebra and Functional Analysis\nA1.1  Johnson Lindenstrauss Lemma\nLemma 1.1 (Johnson Lindenstrauss)LetXbe a set ofnpoints inR\nd\nrepresented as an×dmatrixA. Given\u000f,β >0let\nk≥\n4 + 2β\n\u000f\n2\n/2−\u000f\n3\n/3\nlogn(1.1)\nbe a positive integer. Construct ad×krandom matrixRwith independent\nstandard normal random variables, that is,R\nij\n∼N(0,1), and let\nE=\n1\n√\nk\nAR.(1.2)\nDefinef:R\nd\n→R\nk\nas  the  function  which  maps  the  rows  ofAto  the  rows\nofE. With probability at least1−n\n−β\n, for allu,v∈Xwe have\n(1−\u000f)‖u−v‖\n2\n≤‖f(u)−f(v)‖\n2\n≤(1 +\u000f)‖u−v‖\n2\n.(1.3)\nOur proof presentation by and large follows [?]. We first show that\nLemma 1.2For any arbitrary vectorα∈R\nd\nletq\ni\ndenote thei-th compo-\nnent off(α). Thenq\ni\n∼N(0,‖α‖\n2\n/k)and hence\nE\n[\n‖f(α)‖\n2\n]\n=\nk\n∑\ni=1\nE\n[\nq\n2\ni\n]\n=‖α‖\n2\n.(1.4)\nIn other words, the expected length of vectors are preserved even after em-\nbedding them in akdimensional space. Next we show that the lengths of\nthe embedded vectors are tightly concentrated around their mean.\nLemma 1.3For any\u000f >0and any unit vectorα∈R\nd\nwe have\nPr\n(\n‖f(α)‖\n2\n>1 +\u000f\n)\n<exp\n(\n−\nk\n2\n(\n\u000f\n2\n/2−\u000f\n3\n/3\n)\n)\n(1.5)\nPr\n(\n‖f(α)‖\n2\n<1−\u000f\n)\n<exp\n(\n−\nk\n2\n(\n\u000f\n2\n/2−\u000f\n3\n/3\n)\n)\n.(1.6)\n197\n\n1981  Linear Algebra and Functional Analysis\nCorollary 1.4If we choosekas in(1.1)then for anyα∈R\nd\nwe have\nPr\n(\n(1−\u000f)‖α‖\n2\n≤‖f(α)‖\n2\n≤(1 +\u000f)‖α‖\n2\n)\n≥1−\n2\nn\n2+β\n.(1.7)\nProofFollows immediately from Lemma 1.3 by setting\n2 exp\n(\n−\nk\n2\n(\n\u000f\n2\n/2−\u000f\n3\n/3\n)\n)\n≤\n2\nn\n2+β\n,\nand solving fork.\nThere are\n(\nn\n2\n)\npairs of vectorsu,vinX, and their corresponding distances\n‖u−v‖are  preserved  within  1±\u000ffactor  as  shown  by  the  above  lemma.\nTherefore, the probability of not satisfying (1.3) is bounded by\n(\nn\n2\n)\n·\n2\nn\n2+β\n<\n1/n\nβ\nas claimed in the Johnson Lindenstrauss Lemma. All that remains is\nto prove Lemma 1.2 and 1.3.\nProof(Lemma 1.2). Sinceq\ni\n=\n1\n√\nk\n∑\nj\nR\nij\nα\nj\nis a linear combination of stan-\ndard normal random variablesR\nij\nit follows thatq\ni\nis normally distributed.\nTo compute the mean note that\nE[q\ni\n] =\n1\n√\nk\n∑\nj\nα\nj\nE[R\nij\n] = 0.\nSinceR\nij\nare independent zero mean unit variance random variables,E[R\nij\nR\nil\n] =\n1 ifj=land 0 otherwise. Using this\nE\n[\nq\n2\ni\n]\n=\n1\nk\nE\n\n\nd\n∑\nj=1\nR\nij\nα\nj\n\n\n2\n=\n1\nk\nd\n∑\nj=1\nd\n∑\nl=1\nα\nj\nα\nl\nE[R\nij\nR\nil\n] =\n1\nk\nd\n∑\nj=1\nα\n2\nj\n=\n1\nk\n‖α‖\n2\n.\nProof(Lemma 1.3). Clearly, for allλ\nPr\n[\n‖f(α)‖\n2\n>1 +\u000f\n]\n=Pr\n[\nexp\n(\nλ‖f(α)‖\n2\n)\n>exp(λ(1 +\u000f))\n]\n.\n\nA1.1  Johnson Lindenstrauss Lemma199\nUsing Markov’s inequality (Pr[X≥a]≤E[X]/a) we obtain\nPr\n[\nexp\n(\nλ‖f(α)‖\n2\n)\n>exp(λ(1 +\u000f))\n]\n≤\nE\n[\nexp\n(\nλ‖f(α)‖\n2\n)]\nexp(λ(1 +\u000f))\n=\nE\n[\nexp\n(\nλ\n∑\nk\ni=1\nq\n2\ni\n)]\nexp(λ(1 +\u000f))\n=\nE\n[\n∏\nk\ni=1\nexp\n(\nλq\n2\ni\n)\n]\nexp(λ(1 +\u000f))\n=\n(\nE\n[\nexp\n(\nλq\n2\ni\n)]\nexp\n(\nλ\nk\n(1 +\u000f)\n)\n)\nk\n.(1.8)\nThe last equality is because theq\ni\n’s are i.i.d. Sinceαis a unit vector, from\nthe previous lemmaq\ni\n∼N(0,1/k). Therefore,kq\n2\ni\nis aχ\n2\nrandom variable\nwith moment generating function\nE\n[\nexp\n(\nλq\n2\ni\n)]\n=E\n[\nexp\n(\nλ\nk\nkq\n2\ni\n)]\n=\n1\n√\n1−\n2λ\nk\n.\nPlugging this into (1.8)\nPr\n[\nexp\n(\nλ‖f(α)‖\n2\n)\n>exp (λ(1 +\u000f))\n]\n≤\n\n\nexp\n(\n−\nλ\nk\n(1 +\u000f)\n)\n√\n1−\n2λ\nk\n\n\nk\n.\nSettingλ=\nk\u000f\n2(1+\u000f)\nin the above inequality and simplifying\nPr\n[\nexp\n(\nλ‖f(α)‖\n2\n)\n>exp(λ(1 +\u000f))\n]\n≤(exp(−\u000f)(1 +\u000f))\nk/2\n.\nUsing the inequality\nlog(1 +\u000f)< \u000f−\u000f\n2\n/2 +\u000f\n3\n/3\nwe can write\nPr\n[\nexp\n(\nλ‖f(α)‖\n2\n)\n>exp(λ(1 +\u000f))\n]\n≤exp\n(\n−\nk\n2\n(\n\u000f\n2\n/2−\u000f\n3\n/3\n)\n)\n.\nThis proves (1.5). To prove (1.6) we need to repeat the above steps and use\nthe inequality\nlog(1−\u000f)<−\u000f−\u000f\n2\n/2.\nThis is left as an exercise to the reader.\n\n2001  Linear Algebra and Functional Analysis\nA1.2  Spectral Properties of Matrices\nA1.2.1  Basics\nA1.2.2  Special Matrices\nunitary, hermitean, positive semidefinite\nA1.2.3  Normal Forms\nJacobi\nA1.3  Functional Analysis\nA1.3.1  Norms and Metrics\nvector space, norm, triangle inequality\nA1.3.2  Banach Spaces\nnormed vector space, evaluation functionals, examples, dual space\nA1.3.3  Hilbert Spaces\nsymmetric inner product\nA1.3.4  Operators\nspectrum, norm, bounded, unbounded operators\nA1.4  Fourier Analysis\nA1.4.1  Basics\nA1.4.2  Operators\n\nAppendix 2\nConjugate Distributions\n201\n\n2022  Conjugate Distributions\nBinomial — Beta\nφ(x) =x\ne\nh(nν,n)\n=\nΓ(nν+ 1)Γ(n(1−ν) + 1)\nΓ(n+ 2)\n=B(nν+ 1,n(1−ν) + 1)\nIn traditional notation one represents the conjugate as\np(z;α,β) =\nΓ(α+β)\nΓ(α)Γ(β)\nz\nα−1\n(1−z)\nβ−1\nwhereα=nν+ 1 andβ=n(1−bν) + 1.\nMultinomial — Dirichlet\nφ(x) =e\nx\ne\nh(nν,n)\n=\n∏\nd\ni=1\nΓ(nν\ni\n+ 1)\nΓ(n+d)\nIn traditional notation one represents the conjugate as\np(z;α) =\nΓ(\n∑\nd\ni=1\nα\ni\n)\n∏\nd\ni=1\nΓ(α\ni\n)\nd\n∏\ni=1\nz\nα\ni\n−1\ni\nwhereα\ni\n=nν\ni\n+ 1\nPoisson — Gamma\nφ(x) =x\ne\nh(nν,n)\n=n\n−nν\nΓ(nν)\nIn traditional notation one represents the conjugate as\np(z;α) =β\n−α\nΓ(α)z\nα−1\ne\n−βx\nwhereα=nνandβ=n.\n•Multinomial / Binomial\n•Gaussian\n•Laplace\n•Poisson\n•Dirichlet\n•Wishart\n•Student-t\n•Beta\n•Gamma\n\nAppendix 3\nLoss Functions\nA3.1  Loss Functions\nA multitude of loss functions are commonly used to derive seemingly differ-\nent algorithms. This often blurs the similarities as well as subtle differences\nbetween them, often for historic reasons: Each new loss is typically accompa-\nnied by at least one publication dedicated to it. In many cases, the loss is not\nspelled out explicitly either but instead, it is only given by means of a con-\nstrained optimization problem. A case in point are the papers introducing\n(binary) hinge loss [BM92, CV95] and structured loss [TGK04, TJHA05].\nLikewise, a geometric description obscures the underlying loss function, as\nin novelty detection [SPST\n+\n01].\nIn this section we give an expository yet unifying presentation of many\nof  those  loss  functions.  Many  of  them  are  well  known,  while  others,  such\nas  multivariate  ranking,  hazard  regression,  or  Poisson  regression  are  not\ncommonly used in machine learning. Tables A3.1 and A3.1 contain a choice\nsubset of simple scalar and vectorial losses. Our aim is to put the multitude\nof  loss  functions  in  an  unified  framework,  and  to  show  how  these  losses\nand  their  (sub)gradients  can  be  computed  efficiently  for  use  in  our  solver\nframework.\nNote that not all losses, while convex, are continuously differentiable. In\nthis  situation  we  giveasubgradient.  While  this  may  not  be  optimal,  the\nconvergence rates of our algorithm do not depend on which element of the\nsubdifferential we provide: in all cases the first order Taylor approximation\nis a lower bound which is tight at the point of expansion.\nIn this setion, with little abuse of notation,v\ni\nis understood as thei-th\ncomponent of vectorvwhenvis clearly not an element of a sequence or a\nset.\nA3.1.1  Scalar Loss Functions\nIt is well known [Wah97] that the convex optimization problem\nmin\nξ\nξsubject toy〈w,x〉≥1−ξandξ≥0(3.1)\n203\n\n2043  Loss Functions\nScalar loss functions and their derivatives, depending on\nf\n:=\n〈\nw,x\n〉\n, and\ny\n.\nLoss\n ̄\nl\n(\nf,y\n)\nDerivative\n ̄\nl\n′\n(\nf,y\n)\nHinge [BM92]\nmax(0\n,\n1\n−\nyf\n)\n0 if\nyf\n≥\n1 and\n−\ny\notherwise\nSquared Hinge [KD05]\n12\nmax(0\n,\n1\n−\nyf\n)\n2\n0 if\nyf\n≥\n1 and\nf\n−\ny\notherwise\nExponential [CDLS99]\nexp(\n−\nyf\n)\n−\ny\nexp(\n−\nyf\n)\nLogistic [CSS00]\nlog(1 + exp(\n−\nyf\n))\n−\ny/\n(1 + exp(\n−\nyf\n))\nNovelty [SPST\n+\n01]\nmax(0\n,ρ\n−\nf\n)\n0 if\nf\n≥\nρ\nand\n−\n1 otherwise\nLeast mean squares [Wil98]\n12\n(\nf\n−\ny\n)\n2\nf\n−\ny\nLeast absolute deviation\n|\nf\n−\ny\n|\nsign(\nf\n−\ny\n)\nQuantile regression [Koe05]\nmax(\nτ\n(\nf\n−\ny\n)\n,\n(1\n−\nτ\n)(\ny\n−\nf\n))\nτ\nif\nf > y\nand\nτ\n−\n1 otherwise\n\u000f\n-insensitive [VGS97]\nmax(0\n,\n|\nf\n−\ny\n|−\n\u000f\n)\n0 if\n|\nf\n−\ny\n|≤\n\u000f\n, else sign(\nf\n−\ny\n)\nHuber’s robust loss [MSR\n+\n97]\n1\n2\n(\nf\n−\ny\n)\n2\nif\n|\nf\n−\ny\n|≤\n1, else\n|\nf\n−\ny\n|−\n1\n2\nf\n−\ny\nif\n|\nf\n−\ny\n|≤\n1, else sign(\nf\n−\ny\n)\nPoisson regression [Cre93]\nexp(\nf\n)\n−\nyf\nexp(\nf\n)\n−\ny\nVectorial loss functions and their derivatives, depending on the vector\nf\n:=\nWx\nand on\ny\n.\nLoss\nDerivative\nSoft-Margin Multiclass [TGK04]    max\ny\n′\n(\nf\ny\n′\n−\nf\ny\n+ ∆(\ny,y\n′\n))\ne\ny\n∗\n−\ne\ny\n[CS03]\nwhere\ny\n∗\nis the argmax of the loss\nScaled Soft-Margin Multiclass\nmax\ny\n′\nΓ(\ny,y\n′\n)(\nf\ny\n′\n−\nf\ny\n+ ∆(\ny,y\n′\n))\nΓ(\ny,y\n′\n)(\ne\ny\n∗\n−\ne\ny\n)\n[TJHA05]\nwhere\ny\n∗\nis the argmax of the loss\nSoftmax Multiclass [CDLS99]\nlog\n∑\ny\n′\nexp(\nf\ny\n′\n)\n−\nf\ny\n[\n∑\ny\n′\ne\ny\n′\nexp(\nf\n′\ny\n)\n]\n/\n∑\ny\n′\nexp(\nf\n′\ny\n)\n−\ne\ny\nMultivariate Regression\n12\n(\nf\n−\ny\n)\n>\nM\n(\nf\n−\ny\n) where\nM\n\u0017\n0\nM\n(\nf\n−\ny\n)\n\nA3.1  Loss Functions205\ntakes on the value max(0,1−y〈w,x〉). The latter is a convex function in\nwandx.  Likewise,  we  may  rewrite  the\u000f-insensitive  loss,  Huber’s  robust\nloss, the quantile regression loss, and the novelty detection loss in terms of\nloss functions rather than a constrained optimization problem. In all cases,\n〈w,x〉will play a key role insofar as the loss is convex in terms of thescalar\nquantity〈w,x〉.  A  large  number  of  loss  functions  fall  into  this  category,\nas  described  in  Table  A3.1.  Note  that  not  all  functions  of  this  type  are\ncontinuously differentiable. In this case we adopt the convention that\n∂\nx\nmax(f(x),g(x)) =\n{\n∂\nx\nf(x)iff(x)≥g(x)\n∂\nx\ng(x)otherwise.\n(3.2)\nSince we are only interested in obtaining an arbitrary element of the subd-\nifferential this convention is consistent with our requirements.\nLet us discuss the issue of efficient computation. For all scalar losses we\nmay writel(x,y,w) =\n ̄\nl(〈w,x〉,y), as described in Table A3.1. In this case a\nsimple application of the chain rule yields that∂\nw\nl(x,y,w) =\n ̄\nl\n′\n(〈w,x〉,y)·x.\nFor instance, for squared loss we have\n ̄\nl(〈w,x〉,y) =\n1\n2\n(〈w,x〉−y)\n2\nand\n ̄\nl\n′\n(〈w,x〉,y) =〈w,x〉−y.\nConsequently, the derivative of the empirical risk term is given by\n∂\nw\nR\nemp\n(w) =\n1\nm\nm\n∑\ni=1\n ̄\nl\n′\n(〈w,x\ni\n〉,y\ni\n)·x\ni\n.(3.3)\nThis  means  that  if  we  want  to  computeland∂\nw\nlon  a  large  number  of\nobservationsx\ni\n,  represented  as  matrixX,  we  can  make  use  of  fast  linear\nalgebra routines to pre-compute the vectors\nf=Xwandg\n>\nXwhereg\ni\n=\n ̄\nl\n′\n(f\ni\n,y\ni\n).(3.4)\nThis is possible for any of the loss functions listed in Table A3.1, and many\nother similar losses. The advantage of this unified representation is that im-\nplementation  of  each  individual  loss  can  be  done  in  very  little  time.  The\ncomputational infrastructure for computingXwandg\n>\nXis shared. Eval-\nuating\n ̄\nl(f\ni\n,y\ni\n)  and\n ̄\nl\n′\n(f\ni\n,y\ni\n)  for  allican  be  done  inO(m)  time  and  it  is\nnot time-critical in comparison to the remaining operations. Algorithm 3.1\ndescribes the details.\nAn important but often neglected issue is worth mentioning. Computingf\nrequires us torightmultiply the matrixXwith the vectorwwhile computing\ngrequires theleftmultiplication ofXwith the vectorg\n>\n. IfXis stored in a\nrow major format thenXwcan be computed rather efficiently whileg\n>\nXis\n\n2063  Loss Functions\nAlgorithm 3.1ScalarLoss(w,X,y)\n1:input:Weight vectorw, feature matrixX, and labelsy\n2:Computef=Xw\n3:Computer=\n∑\ni\n ̄\nl(f\ni\n,y\ni\n) andg=\n ̄\nl\n′\n(f,y)\n4:g←g\n>\nX\n5:returnRiskrand gradientg\nexpensive. This is particularly true ifXcannot fit in main memory. Converse\nis the case whenXis stored in column major format. Similar problems are\nencountered whenXis a sparse matrix and stored in either compressed row\nformat or in compressed column format.\nA3.1.2  Structured Loss\nIn recent years structured estimation has gained substantial popularity in\nmachine learning [TJHA05, TGK04, BHS\n+\n07]. At its core it relies on two\ntypes of convex loss functions: logistic loss:\nl(x,y,w) = log\n∑\ny\n′\n∈Y\nexp\n(〈\nw,φ(x,y\n′\n)\n〉)\n−〈w,φ(x,y)〉,(3.5)\nand soft-margin loss:\nl(x,y,w) = max\ny\n′\n∈Y\nΓ(y,y\n′\n)\n〈\nw,φ(x,y\n′\n)−φ(x,y)\n〉\n+ ∆(y,y\n′\n).(3.6)\nHereφ(x,y) is ajointfeature map, ∆(y,y\n′\n)≥0 describes the cost of mis-\nclassifyingybyy\n′\n, and Γ(y,y\n′\n)≥0 is a scaling term which indicates by how\nmuch the large margin property should be enforced. For instance, [TGK04]\nchoose Γ(y,y\n′\n) = 1. On the other hand [TJHA05] suggest Γ(y,y\n′\n) = ∆(y,y\n′\n),\nwhich reportedly yields better performance. Finally, [McA07] recently sug-\ngested generic functions Γ(y,y\n′\n).\nThe logistic loss can also be interpreted as the negative log-likelihood of\na conditional exponential family model:\np(y|x;w) := exp(〈w,φ(x,y)〉−g(w|x)),(3.7)\nwhere the normalizing constantg(w|x), often called the log-partition func-\ntion, reads\ng(w|x) := log\n∑\ny\n′\n∈Y\nexp\n(〈\nw,φ(x,y\n′\n)\n〉)\n.(3.8)\n\nA3.1  Loss Functions207\nAs a consequence of the Hammersley-Clifford theorem [Jor08] every expo-\nnential family distribution corresponds to a undirected graphical model. In\nour case this implies that the labelsyfactorize according to an undirected\ngraphical model. A large number of problems have been addressed by this\nsetting, amongst them named entity tagging [LMP01], sequence alignment\n[TJHA05], segmentation [RSS\n+\n07] and path planning [RBZ06]. It is clearly\nimpossible to give examples of all settings in this section, nor would a brief\nsummary do this field any justice. We therefore refer the reader to the edited\nvolume [BHS\n+\n07] and the references therein.\nIf the underlying graphical model is tractable then efficient inference al-\ngorithms based on dynamic programming can be used to compute (3.5) and\n(3.6). We discuss intractable graphical models in Section A3.1.2.1, and now\nturn our attention to the derivatives of the above structured losses.\nWhen it comes to computing derivatives of the logistic loss, (3.5), we have\n∂\nw\nl(x,y,w) =\n∑\ny\n′\nφ(x,y\n′\n) exp〈w,φ(x,y\n′\n)〉\n∑\ny\n′\nexp〈w,φ(x,y\n′\n)〉\n−φ(x,y)(3.9)\n=E\ny\n′\n∼p(y\n′\n|x)\n[\nφ(x,y\n′\n)\n]\n−φ(x,y).(3.10)\nwherep(y|x) is the exponential family model (3.7). In the case of  (3.6) we\ndenote by  ̄y(x) the argmax of the RHS, that is\n ̄y(x) := argmax\ny\n′\nΓ(y,y\n′\n)\n〈\nw,φ(x,y\n′\n)−φ(x,y)\n〉\n+ ∆(y,y\n′\n).(3.11)\nThis allows us to compute the derivative ofl(x,y,w) as\n∂\nw\nl(x,y,w) = Γ(y, ̄y(x)) [φ(x, ̄y(x))−φ(x,y)].(3.12)\nIn the case where the loss is maximized for more than one distinct value  ̄y(x)\nwe may average over the individual values, since any convex combination of\nsuch terms lies in the subdifferential.\nNote  that  (3.6)  majorizes  ∆(y,y\n∗\n),  wherey\n∗\n:=  argmax\ny\n′\n〈w,φ(x,y\n′\n)〉\n[TJHA05]. This can be seen via the following series of inequalities:\n∆(y,y\n∗\n)≤Γ(y,y\n∗\n)〈w,φ(x,y\n∗\n)−φ(x,y)〉+ ∆(y,y\n∗\n)≤l(x,y,w).\nThe first inequality follows because Γ(y,y\n∗\n)≥0 andy\n∗\nmaximizes〈w,φ(x,y\n′\n)〉\nthus implying that Γ(y,y\n∗\n)〈w,φ(x,y\n∗\n)−φ(x,y)〉 ≥0. The second inequal-\nity follows by definition of the loss.\nWe conclude this section with a simple lemma which is at the heart of\nseveral derivations of [Joa05]. While the proof in the original paper is far\nfrom trivial, it is straightforward in our setting:\n\n2083  Loss Functions\nLemma 3.1Denote byδ(y,y\n′\n)a loss and letφ(x\ni\n,y\ni\n)be a feature map for\nobservations(x\ni\n,y\ni\n)with1≤i≤m.  Moreover,  denote  byX,Ythe  set  of\nallmpatterns and labels respectively. Finally let\nΦ(X,Y) :=\nm\n∑\ni=1\nφ(x\ni\n,y\ni\n)and∆(Y,Y\n′\n) :=\nm\n∑\ni=1\nδ(y\ni\n,y\n′\ni\n).(3.13)\nThen the following two losses are equivalent:\nm\n∑\ni=1\nmax\ny\n′\n〈\nw,φ(x\ni\n,y\n′\n)−φ(x\ni\n,y\ni\n)\n〉\n+δ(y\ni\n,y\n′\n)andmax\nY\n′\n〈\nw,Φ(X,Y\n′\n)−Φ(X,Y)\n〉\n+ ∆(Y,Y\n′\n).\nThis is immediately obvious, since both feature map and loss decompose,\nwhich allows us to perform maximization overY\n′\nby maximizing each of its\nmcomponents. In doing so, we showed that aggregating all data and labels\ninto  a  single  feature  map  and  loss  yields  results  identical  to  minimizing\nthe sum over all individual losses. This holds, in particular, for the sample\nerror loss of [Joa05]. Also note that this equivalence doesnothold whenever\nΓ(y,y\n′\n) is not constant.\nA3.1.2.1  Intractable Models\nWe now discuss cases where computingl(x,y,w) itself is too expensive. For\ninstance, for intractable graphical models, the computation of\n∑\ny\nexp〈w,φ(x,y)〉\ncannot be computed efficiently. [WJ03] propose the use of a convex majoriza-\ntion of the log-partition function in those cases. In our setting this means\nthat instead of dealing with\nl(x,y,w) =g(w|x)−〈w,φ(x,y)〉whereg(w|x) := log\n∑\ny\nexp〈w,φ(x,y)〉\n(3.14)\none uses a more easily computable convex upper bound ongvia\nsup\nμ∈MARG(x)\n〈w,μ〉+H\nGauss\n(μ|x).(3.15)\nHere  MARG(x)  is  an  outer  bound  on  the  conditional  marginal  polytope\nassociated with the mapφ(x,y). Moreover,H\nGauss\n(μ|x) is an upper bound\non  the  entropy  by  using  a  Gaussian  with  identical  variance.  More  refined\ntree decompositions exist, too. The key benefit of our approach is that the\nsolutionμof the optimization problem (3.15) can immediately be used as a\ngradient of the upper bound. This is computationally rather efficient.\n\nA3.1  Loss Functions209\nLikewise note that [TGK04] use relaxations when solving structured esti-\nmation problems of the form\nl(x,y,w) = max\ny\n′\nΓ(y,y\n′\n)\n〈\nw,φ(x,y\n′\n)−φ(x,y)\n〉\n+ ∆(y,y\n′\n),(3.16)\nby enlarging the domain of maximization with respect toy\n′\n. For instance,\ninstead of an integer programming problem we might relax the setting to\na linear program which is much cheaper to solve. This, again, provides an\nupper bound on the original loss function.\nIn summary, we have demonstrated that convex relaxation strategies are\nwell applicable for bundle methods. In fact, the results of the corresponding\noptimization procedures can be used directly for further optimization steps.\nA3.1.3  Scalar Multivariate Performance Scores\nWe now discuss a series of structured loss functions and how they can be\nimplemented efficiently. For the sake of completeness, we give a concise rep-\nresentation of previous work on multivariate performance scores and ranking\nmethods. All these loss functions rely on having access to〈w,x〉, which can\nbe computed efficiently by using the same operations as in Section A3.1.1.\nA3.1.3.1  ROC Score\nDenote byf=Xwthe vector of function values on the training set. It is\nwell known that the area under the ROC curve is given by\nAUC(x,y,w) =\n1\nm\n+\nm\n−\n∑\ny\ni\n<y\nj\nI(〈w,x\ni\n〉<〈w,x\nj\n〉),(3.17)\nwherem\n+\nandm\n−\nare the numbers of positive and negative observations\nrespectively, andI(·) is indicator function. Directly optimizing the cost 1−\nAUC(x,y,w) is difficult as it is not continuous inw. By using max(0,1 +\n〈w,x\ni\n−x\nj\n〉) as the surrogate loss function for all pairs (i,j) for whichy\ni\n< y\nj\nwe have the following convex multivariate empirical risk\nR\nemp\n(w) =\n1\nm\n+\nm\n−\n∑\ny\ni\n<y\nj\nmax(0,1 +〈w,x\ni\n−x\nj\n〉) =\n1\nm\n+\nm\n−\n∑\ny\ni\n<y\nj\nmax(0,1 +f\ni\n−f\nj\n).\n(3.18)\nObviously, we could computeR\nemp\n(w) and its derivative by anO(m\n2\n) op-\neration. However [Joa05] showed that both can be computed inO(mlogm)\ntime using a sorting operation, which we now describe.\nDenote byc=f−\n1\n2\nyan auxiliary variable and letiandjbe indices such\n\n2103  Loss Functions\nAlgorithm 3.2ROCScore(X,y,w)\n1:input:Feature matrixX, labelsy, and weight vectorw\n2:initialization:s\n−\n=m\n−\nands\n+\n= 0 andl=0\nm\nandc=Xw−\n1\n2\ny\n3:π←{1,...,m}sorted in ascending order ofc\n4:fori= 1tomdo\n5:ify\nπ\ni\n=−1then\n6:l\nπ\ni\n←s\n+\nands\n−\n←s\n−\n−1\n7:else\n8:l\nπ\ni\n←−s\n−\nands\n+\n←s\n+\n+ 1\n9:end if\n10:end for\n11:Rescalel←l/(m\n+\nm\n−\n) and computer=〈l,c〉andg=l\n>\nX.\n12:returnRiskrand subgradientg\nthaty\ni\n=−1 andy\nj\n= 1. It follows thatc\ni\n−c\nj\n= 1 +f\ni\n−f\nj\n. The efficient\nalgorithm is due to the observation that there are at mostmdistinct terms\nc\nk\n, k= 1,...,m, each with different frequencyl\nk\nand sign, appear in (3.18).\nThese frequenciesl\nk\ncan be determined by first sortingcin ascending order\nthen  scanning  through  the  labels  according  to  the  sorted  order  ofcand\nkeeping running statistics such as the numbers\n−\nof negative labels yet to\nencounter, and the numbers\n+\nof positive labels encountered. When visiting\ny\nk\n, we knowc\nk\nshould appearss\n+\n(ors\n−\n) times with positive (or negative)\nsign in (3.18) ify\nk\n=−1 (ory\nk\n= 1). Algorithm 3.2 spells out explicitly how\nto computeR\nemp\n(w) and its subgradient.\nA3.1.3.2  Ordinal Regression\nEssentially  the  same  preference  relationships  need  to  hold  for  ordinal  re-\ngression. The only difference is thaty\ni\nneed not take on binary values any\nmore. Instead, we may have an arbitrary number of different valuesy\ni\n(e.g.,\n1 corresponding to ’strong reject’ up to 10 corresponding to ’strong accept’,\nwhen it comes to ranking papers for a conference). That is, we now have\ny\ni\n∈{1,...,n}rather thany\ni\n∈{±1}. Our goal is to find somewsuch that\n〈w,x\ni\n−x\nj\n〉<0 whenevery\ni\n< y\nj\n. Whenever this relationship is not satis-\nfied, we incur a costC(y\ni\n,y\nj\n) for preferringx\ni\ntox\nj\n. For examples,C(y\ni\n,y\nj\n)\ncould be constanti.e.,C(y\ni\n,y\nj\n) = 1 [Joa06] or lineari.e.,C(y\ni\n,y\nj\n) =y\nj\n−y\ni\n.\nDenote bym\ni\nthe number ofx\nj\nfor whichy\nj\n=i. In this case, there are\n ̄\nM=m\n2\n−\n∑\nn\ni=1\nm\n2\ni\npairs (y\ni\n,y\nj\n) for whichy\ni\n6=y\nj\n; this implies that there\nareM=\n ̄\nM/2  pairs  (y\ni\n,y\nj\n)  such  thaty\ni\n< y\nj\n.  Normalizing  by  the  total\n\nA3.1  Loss Functions211\nnumber of comparisons we may write the overall cost of the estimator as\n1\nM\n∑\ny\ni\n<y\nj\nC(y\ni\n,y\nj\n)I(〈w,x\ni\n〉>〈w,x\nj\n〉) whereM=\n1\n2\n[\nm\n2\n−\nn\n∑\ni\nm\n2\ni\n]\n.(3.19)\nUsing the same convex majorization as above when we were maximizing the\nROC score, we obtain an empirical risk of the form\nR\nemp\n(w) =\n1\nM\n∑\ny\ni\n<y\nj\nC(y\ni\n,y\nj\n) max(0,1 +〈w,x\ni\n−x\nj\n〉)(3.20)\nNow the goal is to find an efficient algorithm for obtaining the number of\ntimes when the individual losses are nonzero such as to compute both the\nvalue and the gradient ofR\nemp\n(w). The complication arises from the fact\nthat observationsx\ni\nwith labely\ni\nmay appear in either side of the inequality\ndepending on whethery\nj\n< y\ni\nory\nj\n> y\ni\n. This problem can be solved as\nfollows: sortf=Xwin ascending order and traverse it while keeping track\nof how many items with a lower valuey\nj\nare no more than 1 apart in terms\nof their value off\ni\n. This way we may compute the count statistics efficiently.\nAlgorithm 3.3 describes the details, generalizing the results of [Joa06]. Again,\nits runtime isO(mlogm), thus allowing for efficient computation.\nA3.1.3.3  Preference Relations\nIn general, our loss may be described by means of a set of preference relations\nj\u0017ifor arbitrary pairs (i,j)∈ {1,...m}\n2\nassociated with a costC(i,j)\nwhich is incurred wheneveriis ranked abovej. This set of preferences may\nor may not form a partial or a total order on the domain of all observations.\nIn these cases efficient computations along the lines of Algorithm 3.3 exist.\nIn general, this is not the case and we need to rely on the fact that the set\nPcontaining all preferences is sufficiently small that it can be enumerated\nefficiently. The risk is then given by\n1\n|P|\n∑\n(i,j)∈P\nC(i,j)I(〈w,x\ni\n〉>〈w,x\nj\n〉)(3.21)\n\n2123  Loss Functions\nAlgorithm 3.3OrdinalRegression(X,y,w,C)\n1:input:Feature matrixX, labelsy, weight vectorw, and score matrixC\n2:initialization:l=0\nn\nandu\ni\n=m\ni\n∀i∈[n] andr= 0 andg=0\nm\n3:Computef=Xwand setc= [f−\n1\n2\n,f+\n1\n2\n]∈R\n2m\n(concatenate the\nvectors)\n4:ComputeM= (m\n2\n−\n∑\nn\ni=1\nm\n2\ni\n)/2\n5:RescaleC←C/M\n6:π←{1,...,2m}sorted in ascending order ofc\n7:fori= 1to2mdo\n8:j=π\ni\nmodm\n9:ifπ\ni\n≤mthen\n10:fork= 1toy\nj\n−1do\n11:r←r−C(k,y\nj\n)u\nk\nc\nj\n12:g\nj\n←g\nj\n−C(k,y\nj\n)u\nk\n13:end for\n14:l\ny\nj\n←l\ny\nj\n+ 1\n15:else\n16:fork=y\nj\n+ 1tondo\n17:r←r+C(y\nj\n,k)l\nk\nc\nj+m\n18:g\nj\n←g\nj\n+C(y\nj\n,k)l\nk\n19:end for\n20:u\ny\nj\n←u\ny\nj\n−1\n21:end if\n22:end for\n23:g←g\n>\nX\n24:return:Riskrand subgradientg\nAgain, the same majorization argument as before allows us to write a convex\nupper bound\nR\nemp\n(w) =\n1\n|P|\n∑\n(i,j)∈P\nC(i,j) max (0,1 +〈w,x\ni\n〉−〈w,x\nj\n〉)  (3.22)\nwhere∂\nw\nR\nemp\n(w) =\n1\n|P|\n∑\n(i,j)∈P\nC(i,j)\n{\n0if〈w,x\nj\n−x\ni\n〉≥1\nx\ni\n−x\nj\notherwise\n(3.23)\nThe implementation is straightforward, as given in Algorithm 3.4.\n\nA3.1  Loss Functions213\nAlgorithm 3.4Preference(X,w,C,P)\n1:input:Feature matrixX, weight vectorw, score matrixC, and prefer-\nence setP\n2:initialization:r= 0 andg=0\nm\n3:Computef=Xw\n4:while(i,j)∈Pdo\n5:iff\nj\n−f\ni\n<1then\n6:r←r+C(i,j)(1 +f\ni\n−f\nj\n)\n7:g\ni\n←g\ni\n+C(i,j) andg\nj\n←g\nj\n−C(i,j)\n8:end if\n9:end while\n10:g←g\n>\nX\n11:returnRiskrand subgradientg\nA3.1.3.4  Ranking\nIn webpage and document ranking we are often in a situation similar to that\ndescribed in Section A3.1.3.2, however with the difference that we do not\nonly care about objectsx\ni\nbeing ranked according to scoresy\ni\nbut moreover\nthat different degrees of importance are placed on different documents.\nThe information retrieval literature is full with a large number of differ-\nent scoring functions. Examples are criteria such asNormalized Discounted\nCumulative Gain (NDCG),Mean Reciprocal Rank (MRR),Precision@n, or\nExpected Rank Utility (ERU). They are used to address the issue of evaluat-\ning rankers, search engines or recommender sytems [Voo01, JK02, BHK98,\nBH04].  For  instance,  in  webpage  ranking  only  the  firstkretrieved  docu-\nments that matter, since users are unlikely to look beyond the firstk, say\n10, retrieved webpages in an internet search. [LS07] show that these scores\ncan be optimized directly by minimizing the following loss:\nl(X,y,w) = max\nπ\n∑\ni\nc\ni\n〈\nw,x\nπ(i)\n−x\ni\n〉\n+〈a−a(π),b(y)〉.(3.24)\nHerec\ni\nis a monotonically decreasing sequence, the documents are assumed\nto  be  arranged  in  order  of  decreasing  relevance,πis  a  permutation,  the\nvectorsaandb(y) depend on the choice of a particular ranking measure, and\na(π) denotes the permutation ofaaccording toπ. Pre-computingf=Xw\nwe may rewrite (3.24) as\nl(f,y) = max\nπ\n[\nc\n>\nf(π)−a(π)\n>\nb(y)\n]\n−c\n>\nf+a\n>\nb(y)(3.25)\n\n2143  Loss Functions\nAlgorithm 3.5Ranking(X,y,w)\n1:input:Feature matrixX, relevancesy, and weight vectorw\n2:Compute vectorsaandb(y) according to some ranking measure\n3:Computef=Xw\n4:Compute elements of matrixC\nij\n=c\ni\nf\nj\n−b\ni\na\nj\n5:π= LinearAssignment(C)\n6:r=c\n>\n(f(π)−f) + (a−a(π))\n>\nb\n7:g=c(π\n−1\n)−candg←g\n>\nX\n8:returnRiskrand subgradientg\nand consequently the derivative ofl(X,y,w) with respect towis given by\n∂\nw\nl(X,y,w) = (c( ̄π\n−1\n)−c)\n>\nXwhere  ̄π= argmax\nπ\nc\n>\nf(π)−a(π)\n>\nb(y).\n(3.26)\nHereπ\n−1\ndenotes the inverse permutation, such thatπ◦π\n−1\n= 1. Finding the\npermutation maximizingc\n>\nf(π)−a(π)\n>\nb(y) is a linear assignment problem\nwhich can be easily solved by the Hungarian Marriage algorithm, that is,\nthe Kuhn-Munkres algorithm.\nThe original papers by [Kuh55] and [Mun57] implied an algorithm with\nO(m\n3\n) cost in the number of terms. Later, [Kar80] suggested an algorithm\nwith expected quadratic time in the size of the assignment problem (ignor-\ning  log-factors).  Finally,  [OL93]  propose  a  linear  time  algorithm  for  large\nproblems. Since in our case the number of pages is fairly small (in the order\nof 50 to 200per query) the scaling behavior per query is not too important.\nWe used an existing implementation due to [JV87].\nNote also that training sets consist of acollectionof ranking problems,\nthat  is,  we  have  several  ranking  problems  of  size  50  to  200.  By  means  of\nparallelization we are able to distribute the work onto a cluster of worksta-\ntions, which is able to overcome the issue of the rather costly computation\nper collection of queries. Algorithm 3.5 spells out the steps in detail.\nA3.1.3.5  Contingency Table Scores\n[Joa05] observed thatF\nβ\nscores and related quantities dependent on a con-\ntingency table can also be computed efficiently by means of structured es-\ntimation.  Such  scores  depend  in  general  on  the  number  of  true  and  false\npositives and negatives alike. Algorithm 3.6 shows how a corresponding em-\npirical risk and subgradient can be computed efficiently. As with the pre-\nvious  losses,  here  again  we  use  convex  majorization  to  obtain  a  tractable\noptimization problem.\n\nA3.1  Loss Functions215\nGiven a set of labelsyand an estimatey\n′\n, the numbers of true positives\n(T\n+\n), true negatives (T\n−\n), false positives (F\n+\n), and false negatives (F\n−\n) are\ndetermined according to a contingency table as follows:\ny >0y <0\ny\n′\n>0T\n+\nF\n+\ny\n′\n<0F\n−\nT\n−\nIn the sequel, we denote bym\n+\n=T\n+\n+F\n−\nandm\n−\n=T\n−\n+F\n+\nthe numbers\nof positives and negative labels iny, respectively. We note thatF\nβ\nscore can\nbe computed based on the contingency table [Joa05] as\nF\nβ\n(T\n+\n,T\n−\n) =\n(1 +β\n2\n)T\n+\nT\n+\n+m\n−\n−T\n−\n+β\n2\nm\n+\n.(3.27)\nIf we want to use〈w,x\ni\n〉to estimate the label of observationx\ni\n, we may use\nthe following structured loss to “directly” optimize w.r.t.F\nβ\nscore [Joa05]:\nl(X,y,w) = max\ny\n′\n[\n(y\n′\n−y)\n>\nf+ ∆(T\n+\n,T\n−\n)\n]\n,(3.28)\nwheref=Xw, ∆(T\n+\n,T\n−\n) := 1−F\nβ\n(T\n+\n,T\n−\n), and (T\n+\n,T\n−\n) is determined\nby usingyandy\n′\n. Since ∆ does not depend on the specific choice of (y,y\n′\n)\nbut rather just on which sets they disagree,lcan be maximized as follows:\nEnumerating all possiblem\n+\nm\n−\ncontingency tables in a way such that given\na configuration (T\n+\n,T\n−\n),T\n+\n(T\n−\n) positive (negative) observationsx\ni\nwith\nlargest  (lowest)  value  of〈w,x\ni\n〉are  labeled  as  positive  (negative).  This  is\neffectively implemented as a nested loop hence run inO(m\n2\n) time. Algorithm\n3.6 describes the procedure in details.\nA3.1.4  Vector Loss Functions\nNext we discuss “vector” loss functions,i.e.,functions wherewis best de-\nscribed as a matrix (denoted byW) and the loss depends onWx. Here, we\nhave feature vectorx∈R\nd\n, labely∈R\nk\n, and weight matrixW∈R\nd×k\n. We\nalso denote feature matrixX∈R\nm×d\nas a matrix ofmfeature vectorsx\ni\n,\nand stack up the columnsW\ni\nofWas a vectorw.\nSome of the most relevant cases are multiclass classification using both\nthe exponential families model and structured estimation, hierarchical mod-\nels,i.e.,ontologies,  and  multivariate  regression.  Many  of  those  cases  are\nsummarized in Table A3.1.\n\n2163  Loss Functions\nAlgorithm 3.6F\nβ\n(X,y,w)\n1:input:Feature matrixX, labelsy, and weight vectorw\n2:Computef=Xw\n3:π\n+\n←{i:y\ni\n= 1}sorted in descending order off\n4:π\n−\n←{i:y\ni\n=−1}sorted in ascending order off\n5:Letp\n0\n= 0 andp\ni\n= 2\n∑\nm\n+\nk=i\nf\nπ\n+\nk\n, i= 1,...,m\n+\n6:Letn\n0\n= 0 andn\ni\n= 2\n∑\nm\n−\nk=i\nf\nπ\n−\nk\n, i= 1,...,m\n−\n7:y\n′\n←−yandr←−∞\n8:fori= 0tom\n+\ndo\n9:forj= 0tom\n−\ndo\n10:r\ntmp\n= ∆(i,j)−p\ni\n+n\nj\n11:ifr\ntmp\n> rthen\n12:r←r\ntmp\n13:T\n+\n←iandT\n−\n←j\n14:end if\n15:end for\n16:end for\n17:y\n′\nπ\n+\ni\n←1, i= 1,...,T\n+\n18:y\n′\nπ\n−\ni\n←−1, i= 1,...,T\n−\n19:g←(y\n′\n−y)\n>\nX\n20:returnRiskrand subgradientg\nA3.1.4.1  Unstructured Setting\nThe simplest loss is multivariate regression, wherel(x,y,W) =\n1\n2\n(y−x\n>\nW)\n>\nM(y−\nx\n>\nW). In this case it is clear that by pre-computingXWsubsequent calcu-\nlations of the loss and its gradient are significantly accelerated.\nA second class of important losses is given by plain multiclass classification\nproblems,e.g.,recognizing digits of a postal code or categorizing high-level\ndocument categories. In this case,φ(x,y) is best represented bye\ny\n⊗x(using\na  linear  model).  Clearly  we  may  view〈w,φ(x,y)〉as  an  operation  which\nchooses a column indexed byyfromxW, since all labelsycorrespond to\na different weight vectorW\ny\n. Formally we set〈w,φ(x,y)〉= [xW]\ny\n. In this\ncase, structured estimation losses can be rewritten as\nl(x,y,W) = max\ny\n′\nΓ(y,y\n′\n)\n〈\nW\ny\n′\n−W\ny\n,x\n〉\n+ ∆(y,y\n′\n)(3.29)\nand∂\nW\nl(x,y,W) = Γ(y,y\n∗\n)(e\ny\n∗\n−e\ny\n)⊗x.(3.30)\nHere Γ and ∆ are defined as in Section A3.1.2 andy\n∗\ndenotes the value ofy\n′\n\nA3.1  Loss Functions217\nfor which the RHS of (3.29) is maximized. This means that for unstructured\nmulticlass settings we may simply computexW. Since this needs to be per-\nformed for all observationsx\ni\nwe may take advantage of fast linear algebra\nroutines and computef=XWfor efficiency. Likewise note that comput-\ning the gradient overmobservations is now a matrix-matrix multiplication,\ntoo: denote byGthe matrix of rows of gradients Γ(y\ni\n,y\n∗\ni\n)(e\ny\n∗\ni\n−e\ny\ni\n). Then\n∂\nW\nR\nemp\n(X,y,W)  =G\n>\nX.  Note  thatGis  very  sparse  with  at  most  two\nnonzero entries per row, which makes the computation ofG\n>\nXessentially\nas expensive as two matrix vector multiplications. Whenever we have many\nclasses, this may yield significant computational gains.\nLog-likelihood scores of exponential families share similar expansions. We\nhave\nl(x,y,W) = log\n∑\ny\n′\nexp\n〈\nw,φ(x,y\n′\n)\n〉\n−〈w,φ(x,y)〉= log\n∑\ny\n′\nexp\n〈\nW\ny\n′\n,x\n〉\n−〈W\ny\n,x〉\n(3.31)\n∂\nW\nl(x,y,W) =\n∑\ny\n′\n(e\ny\n′\n⊗x) exp\n〈\nW\ny\n′\n,x\n〉\n∑\ny\n′\nexp\n〈\nW\ny\n′\n,x\n〉\n−e\ny\n⊗x.(3.32)\nThe  main  difference  to  the  soft-margin  setting  is  that  the  gradients  are\nnotsparse  in  the  number  of  classes.  This  means  that  the  computation  of\ngradients is slightly more costly.\nA3.1.4.2  Ontologies\nFig. A3.1.  Two ontologies.Left:a binary hierarchy with internal nodes{1,...,7}\nand labels{8,...15}.Right:a generic directed acyclic graph with internal nodes\n{1,...,6,12}and labels{7,...,11,13,...,15}. Note that node 5 has two parents,\nnamely nodes 2 and 3. Moreover, the labels need not be found at the same level of\nthe tree: nodes 14 and 15 are one level lower than the rest of the nodes.\nAssume that the labels we want to estimate can be found to belong to\na directed acyclic graph. For instance, this may be a gene-ontology graph\n\n2183  Loss Functions\n[ABB\n+\n00] a patent hierarchy [CH04], or a genealogy. In these cases we have a\nhierarchy of categories to which an elementxmay belong. Figure A3.1 gives\ntwo examples of such directed acyclic graphs (DAG). The first example is\na  binary  tree,  while  the  second  contains  nodes  with  different  numbers  of\nchildren (e.g.,node 4 and 12), nodes at different levels having children (e.g.,\nnodes 5 and 12), and nodes which have more than one parent (e.g.,node 5).\nIt is a well known fundamental property of trees that they have at most as\nmany internal nodes as they have leaf nodes.\nIt is now our goal to build a classifier which is able to categorize observa-\ntions according to which leaf node they belong to (each leaf node is assigned\na labely). Denote byk+ 1 the number of nodes in the DAG including the\nroot node. In this case we may design a feature mapφ(y)∈R\nk\n[CH04] by\nassociating with every labelythe vector describing the path from the root\nnode toy, ignoring the root node itself. For instance, for the first DAG in\nFigure A3.1 we have\nφ(8) = (1,0,1,0,0,0,1,0,0,0,0,0,0,0) andφ(13) = (0,1,0,0,1,0,0,0,0,0,0,1,0,0)\nWhenever several paths are admissible, as in the right DAG of Figure A3.1\nwe average over all possible paths. For example, we have\nφ(10) = (0.5,0.5,0,1,0,0,0,0,1,0,0,0,0,0) andφ(15) = (0,1,0,0,1,0,0,0,0,0,0,1,0,0,1).\nAlso  note  that  the  lengths  of  the  paths  need  not  be  the  same  (e.g.,to\nreach 15 it takes a longer path than to reach 13). Likewise, it is natural to\nassume that ∆(y,y\n′\n),i.e.,the cost for mislabelingyasy\n′\nwill depend on the\nsimilarity of the path. In other words, it is likely that the cost for placing\nxinto the wrong sub-sub-category is less than getting the main category of\nthe object wrong.\nTo  complete  the  setting,  note  that  forφ(x,y)  =φ(y)⊗xthe  cost  of\ncomputing all labels iskinner products, since the value of〈w,φ(x,y)〉for a\nparticularycan be obtained by the sum of the contributions for the segments\nof the path. This means that the values forallterms can be computed by\na simple breadth first traversal through the graph. As before, we may make\nuse of vectorization in our approach, since we may computexW∈R\nk\nto\nobtain the contributions on all segments of the DAG before performing the\ngraph traversal. Since we havempatternsx\ni\nwe may vectorize matters by\npre-computingXW.\nAlso note thatφ(y)−φ(y\n′\n) is nonzero only for those edges where the paths\nforyandy\n′\ndiffer. Hence we only change weights on those parts of the graph\nwhere the categorization differs. Algorithm 3.7 describes the subgradient and\nloss computation for the soft-margin type of loss function.\n\nA3.1  Loss Functions219\nAlgorithm 3.7Ontology(X,y,W)\n1:input:Feature  matrixX∈R\nm×d\n,  labelsy,  and  weight  matrixW∈\nR\nd×k\n2:initialization:G=0∈R\nm×k\nandr= 0\n3:Computef=XWand letf\ni\n=x\ni\nW\n4:fori= 1tomdo\n5:LetD\ni\nbe the DAG with edges annotated with the values off\ni\n6:TraverseD\ni\nto find nodey\n∗\nthat maximize sum off\ni\nvalues on the\npath plus ∆(y\ni\n,y\n′\n)\n7:G\ni\n=φ(y\n∗\n)−φ(y\ni\n)\n8:r←r+z\ny\n∗\n−z\ny\ni\n9:end for\n10:g=G\n>\nX\n11:returnRiskrand subgradientg\nThe same reasoning applies to estimation when using an exponential fam-\nilies  model.  The  only  difference  is  that  we  need  to  compute  asoft-max\nover  paths  rather  than  exclusively  choosing  the  best  path  over  the  ontol-\nogy.  Again,  a  breadth-first  recursion  suffices:  each  of  the  leavesyof  the\nDAG is associated with a probabilityp(y|x). To obtainE\ny∼p(y|x)\n[φ(y)] all\nwe need to do is perform a bottom-up traversal of the DAG summing over\nall  probability  weights  on  the  path.  Wherever  a  node  has  more  than  one\nparent, we distribute the probability weight equally over its parents.\n\n\n\nBibliography\n[ABB\n+\n00]  M.  Ashburner,  C.  A.  Ball,  J.  A.  Blake,  D.  Botstein,  H.  Butler,  J.  M.\nCherry,  A.  P.  Davis,  K.  Dolinski,  S.  S.  Dwight,  J.  T.  Eppig,  M.  A.  Harris,\nD. P. Hill, L. Issel-Tarver, A. Kasarskis, S. Lewis, J. C. Matese, J. E. Richard-\nson, M. Ringwald, G. M. Rubin, and G. Sherlock,Gene ontology: tool for the\nunification of biology. the gene ontology consortium, Nat Genet25(2000), 25–\n29.\n[AGML90]  S.  F.  Altschul,  W.  Gish,  E.  W.  Myers,  and  D.  J.  Lipman,Basic  local\nalignment  search  tool,  Journal of  Molecular  Biology215(1990),  no. 3,  403–\n410.\n[BBL05]  O. Bousquet, S. Boucheron, and G. Lugosi,Theory of classification: a sur-\nvey of recent advances, ESAIM: Probab. Stat.9(2005), 323– 375.\n[BCR84]  C. Berg, J. P. R. Christensen, and P. Ressel,Harmonic analysis on semi-\ngroups, Springer, New York, 1984.\n[BDEL03]  S. Ben-David, N. Eiron, and P.M. Long,On the difficulty of approximately\nmaximizing agreements, J. Comput. System Sci.66(2003), no. 3, 496–514.\n[Bel61]  R.  E.  Bellman,Adaptive  control  processes,  Princeton  University  Press,\nPrinceton, NJ, 1961.\n[Bel05]  Alexandre Belloni,Introduction to bundle methods, Tech. report, Operation\nResearch Center, M.I.T., 2005.\n[Ber85]  J.  O.  Berger,Statistical  decision  theory  and  Bayesian  analysis,  Springer,\nNew York, 1985.\n[BH04]  J. Basilico and T. Hofmann,Unifying collaborative and content-based filter-\ning, Proc. Intl. Conf. Machine Learning (New York, NY), ACM Press, 2004,\npp. 65–72.\n[BHK98]  J. S. Breese, D. Heckerman, and C. Kardie,Empirical analysis of predictive\nalgorithms  for  collaborative  filtering,  Proceedings  of  the  14th  Conference  on\nUncertainty in Artificial Intelligence, 1998, pp. 43–52.\n[BHS\n+\n07]  G. Bakir, T. Hofmann, B. Sch ̈olkopf, A. Smola, B. Taskar, and S. V. N.\nVishwanathan,Predicting   structured   data,   MIT   Press,   Cambridge,   Mas-\nsachusetts, 2007.\n[Bil68]  Patrick  Billingsley,Convergence  of  probability  measures,  John  Wiley  and\nSons, 1968.\n[Bis95]  C.  M.  Bishop,Neural  networks  for  pattern  recognition,  Clarendon  Press,\nOxford, 1995.\n[BK07]  R. M. Bell and Y. Koren,Lessons from the netflix prize challenge, SIGKDD\nExplorations9(2007), no. 2, 75–79.\n[BKL06]  A. Beygelzimer, S. Kakade, and J. Langford,Cover trees for nearest neigh-\nbor, International Conference on Machine Learning, 2006.\n[BL00]  J. M. Borwein and A. S. Lewis,Convex analysis and nonlinear optimization:\nTheory  and  examples,  CMS  books  in  Mathematics,  Canadian  Mathematical\nSociety, 2000.\n221\n\n2223  Bibliography\n[BM92]  K. P. Bennett and O. L. Mangasarian,Robust linear programming discrimi-\nnation of two linearly inseparable sets, Optim. Methods Softw.1(1992), 23–34.\n[BNJ03]  D. Blei, A. Ng, and M. Jordan,Latent Dirichlet allocation, Journal of Ma-\nchine Learning Research3(2003), 993–1022.\n[BT03]  D.P. Bertsekas and J.N. Tsitsiklis,Introduction  to  probability, Athena Sci-\nentific, 2003.\n[BV04]  S. Boyd and L. Vandenberghe,Convex optimization, Cambridge University\nPress, Cambridge, England, 2004.\n[CDLS99]  R.  Cowell,  A.  Dawid,  S.  Lauritzen,  and  D.  Spiegelhalter,Probabilistic\nnetworks and expert sytems, Springer, New York, 1999.\n[CH04]  Lijuan Cai and T. Hofmann,Hierarchical document categorization with sup-\nport vector machines, Proceedings of the Thirteenth ACM conference on Infor-\nmation and knowledge management (New York, NY, USA), ACM Press, 2004,\npp. 78–87.\n[Cra46]  H. Cram ́er,Mathematical methods of statistics, Princeton University Press,\n1946.\n[Cre93]  N. A. C. Cressie,Statistics for spatial data, John Wiley and Sons, New York,\n1993.\n[CS03]  K. Crammer and Y. Singer,Ultraconservative  online  algorithms  for  multi-\nclass problems, Journal of Machine Learning Research3(2003), 951–991.\n[CSS00]  M.  Collins,  R.  E.  Schapire,  and  Y.  Singer,Logistic  regression,  AdaBoost\nand  Bregman  distances,  Proc.  13th  Annu.  Conference  on  Comput.  Learning\nTheory, Morgan Kaufmann, San Francisco, 2000, pp. 158–169.\n[CV95]  Corinna Cortes and V. Vapnik,Support vector networks, Machine Learning\n20(1995), no. 3, 273–297.\n[DG03]  S. Dasgupta and A. Gupta,An  elementary  proof  of  a  theorem  of  johnson\nand lindenstrauss, Random Struct. Algorithms22(2003), no. 1, 60–65.\n[DG08]  J. Dean and S. Ghemawat,MapReduce:  simplified  data  processing  on  large\nclusters, CACM51(2008), no. 1, 107–113.\n[DGL96]  L.  Devroye,  L.  Gy ̈orfi,  and  G.  Lugosi,A  probabilistic  theory  of  pattern\nrecognition, Applications of mathematics, vol. 31, Springer, New York, 1996.\n[Fel71]  W. Feller,An  introduction  to  probability  theory  and  its  applications, 2 ed.,\nJohn Wiley and Sons, New York, 1971.\n[FJ95]  A. Frieze and M. Jerrum,An  analysis  of  a  monte  carlo  algorithm  for  esti-\nmating the permanent, Combinatorica15(1995), no. 1, 67–83.\n[FS99]  Y. Freund and R. E. Schapire,Large margin classification using the percep-\ntron algorithm, Machine Learning37(1999), no. 3, 277–296.\n[FT94]  L. Fahrmeir and G. Tutz,Multivariate statistical modelling based on gener-\nalized linear models, Springer, 1994.\n[GIM99]  A. Gionis, P. Indyk, and R. Motwani,Similarity search in high dimensions\nvia hashing, Proceedings of the 25th VLDB Conference (Edinburgh, Scotland)\n(M. P. Atkinson, M. E. Orlowska, P. Valduriez, S. B. Zdonik, and M. L. Brodie,\neds.), Morgan Kaufmann, 1999, pp. 518–529.\n[GS04]  T.L. Griffiths and M. Steyvers,Finding scientific topics, Proceedings of the\nNational Academy of Sciences101(2004), 5228–5235.\n[GW92]  P. Groeneboom and J. A. Wellner,Information bounds and nonparametric\nmaximum likelihood estimation, DMV, vol. 19, Springer, 1992.\n[Hal92]  P. Hall,The bootstrap and edgeworth expansions, Springer, New York, 1992.\n[Hay98]  S. Haykin,Neural networks : A comprehensive foundation, Macmillan, New\nYork, 1998, 2nd edition.\n\nBibliography223\n[Heb49]  D. O. Hebb,The organization of behavior, John Wiley and Sons, New York,\n1949.\n[Hoe63]  W. Hoeffding,Probability inequalities for sums of bounded random variables,\nJournal of the American Statistical Association58(1963), 13–30.\n[HUL93]  J.B. Hiriart-Urruty and C. Lemar ́echal,Convex analysis and minimization\nalgorithms, I and II, vol. 305 and 306, Springer-Verlag, 1993.\n[IM98]  P. Indyk and R. Motawani,Approximate nearest neighbors: Towards remov-\ning the curse of dimensionality, Proceedings of the 30\nth\nSymposium on Theory\nof Computing, 1998, pp. 604–613.\n[JK02]  K. Jarvelin and J. Kekalainen,IR  evaluation  methods  for  retrieving  highly\nrelevant documents, ACM Special Interest Group in Information Retrieval (SI-\nGIR), New York: ACM, 2002, pp. 41–48.\n[Joa05]  T.  Joachims,A  support  vector  method  for  multivariate  performance  mea-\nsures, Proc. Intl. Conf. Machine Learning (San Francisco, California), Morgan\nKaufmann Publishers, 2005, pp. 377–384.\n[Joa06]\n,Training linear SVMs in linear time, Proc. ACM Conf. Knowledge\nDiscovery and Data Mining (KDD), ACM, 2006.\n[Jor08]  M. I. Jordan,An  introduction  to  probabilistic  graphical  models, MIT Press,\n2008, To Appear.\n[JV87]  R. Jonker and A. Volgenant,A shortest augmenting path algorithm for dense\nand sparse linear assignment problems, Computing38(1987), 325–340.\n[Kar80]  R.M. Karp,An algorithm to solve them×nassignment problem in expected\ntimeO(mnlogn), Networks10(1980), no. 2, 143–152.\n[KD05]  S.  S.  Keerthi  and  D.  DeCoste,A  modified  finite  Newton  method  for  fast\nsolution of large scale linear SVMs, J. Mach. Learn. Res.6(2005), 341–361.\n[Kel60]  J. E. Kelly,The cutting-plane method for solving convex programs, Journal\nof the Society for Industrial and Applied Mathematics8(1960), no. 4, 703–712.\n[Kiw90]  Krzysztof C. Kiwiel,Proximity  control  in  bundle  methods  for  convex  non-\ndifferentiable minimization, Mathematical Programming46(1990), 105–122.\n[KM00]  Paul Komarek and Andrew Moore,A  dynamic  adaptation  of  AD-trees  for\nefficient machine learning on large data sets, Proc. Intl. Conf. Machine Learn-\ning, Morgan Kaufmann, San Francisco, CA, 2000, pp. 495–502.\n[Koe05]  R. Koenker,Quantile regression, Cambridge University Press, 2005.\n[Kuh55]  H.W. Kuhn,The Hungarian method for the assignment problem, Naval Re-\nsearch Logistics Quarterly2(1955), 83–97.\n[Lew98]  D. D. Lewis,Naive  (Bayes)  at  forty:  The  independence  assumption  in  in-\nformation  retrieval, Proceedings of ECML-98, 10th European Conference on\nMachine Learning (Chemnitz, DE) (C. N ́edellec and C. Rouveirol, eds.), no.\n1398, Springer Verlag, Heidelberg, DE, 1998, pp. 4–15.\n[LK03]  C.  Leslie  and  R.  Kuang,Fast  kernels  for  inexact  string  matching,  Proc.\nAnnual Conf. Computational Learning Theory, 2003.\n[LMP01]  J. D. Lafferty, A. McCallum, and F. Pereira,Conditional  random  fields:\nProbabilistic modeling for segmenting and labeling sequence data, Proceedings\nof International Conference on Machine Learning (San Francisco, CA), vol. 18,\nMorgan Kaufmann, 2001, pp. 282–289.\n[LNN95]  Claude Lemar ́echal, Arkadii Nemirovskii, and Yurii Nesterov,New variants\nof bundle methods, Mathematical Programming69(1995), 111–147.\n[LS07]  Q.  Le  and  A.J.  Smola,Direct  optimization  of  ranking  measures,  J.  Mach.\nLearn. Res. (2007), submitted.\n[LT92]  Z. Q. Luo and P. Tseng,On  the  convergence  of  coordinate  descent  method\n\n2243  Bibliography\nfor  convex  differentiable  minimization,  Journal  of  Optimization  Theory  and\nApplications72(1992), no. 1, 7–35.\n[Lue84]  D. G. Luenberger,Linear and nonlinear programming, second ed., Addison-\nWesley, Reading, May 1984.\n[Mar61]  M.E. Maron,Automatic indexing: An experimental inquiry, Journal of the\nAssociation for Computing Machinery8(1961), 404–417.\n[McA07]  David  McAllester,Generalization  bounds  and  consistency  for  structured\nlabeling, Predicting Structured Data (Cambridge, Massachusetts), MIT Press,\n2007.\n[McD89]  C. McDiarmid,On the method of bounded differences, Survey in Combina-\ntorics, Cambridge University Press, 1989, pp. 148–188.\n[Mit97]  T. M. Mitchell,Machine learning, McGraw-Hill, New York, 1997.\n[MN83]  P. McCullagh and J. A. Nelder,Generalized  linear  models, Chapman and\nHall, London, 1983.\n[MSR\n+\n97]  K.-R. M ̈uller, A. J. Smola, G. R ̈atsch, B. Sch ̈olkopf, J. Kohlmorgen, and\nV. Vapnik,Predicting time series with support vector machines, Artificial Neu-\nral Networks ICANN’97 (Berlin) (W. Gerstner, A. Germond, M. Hasler, and\nJ.-D. Nicoud, eds.), Lecture Notes in Comput. Sci., vol. 1327, Springer-Verlag,\n1997, pp. 999–1004.\n[Mun57]  J.  Munkres,Algorithms  for  the  assignment  and  transportation  problems,\nJournal of SIAM5(1957), no. 1, 32–38.\n[MYA94]  N. Murata, S. Yoshizawa, and S. Amari,Network information criterion —\ndetermining  the  number  of  hidden  units  for  artificial  neural  network  models,\nIEEE Transactions on Neural Networks5(1994), 865–872.\n[Nad65]  E. A. Nadaraya,On  nonparametric  estimates  of  density  functions  and  re-\ngression curves, Theory of Probability and its Applications10(1965), 186–190.\n[NW99]  J.  Nocedal  and  S.  J.  Wright,Numerical  optimization,  Springer  Series  in\nOperations Research, Springer, 1999.\n[OL93]  J.B. Orlin and Y. Lee,Quickmatch: A very fast algorithm for the assignment\nproblem, Working Paper 3547-93, Sloan School of Management, Massachusetts\nInstitute of Technology, Cambridge, MA, March 1993.\n[Pap62]  A.  Papoulis,The  fourier  integral  and  its  applications,  McGraw-Hill,  New\nYork, 1962.\n[Pla99]  J. Platt,Fast training of support vector machines using sequential minimal\noptimization, Advances in Kernel Methods — Support Vector Learning (Cam-\nbridge, MA) (B. Sch ̈olkopf, C. J. C. Burges, and A. J. Smola, eds.), MIT Press,\n1999, pp. 185–208.\n[PTVF94]  W.  H.  Press,  S.  A.  Teukolsky,  W.  T.  Vetterling,  and  B.  P.  Flannery,\nNumerical recipes in c. the art of scientific computation, Cambridge University\nPress, Cambridge, UK, 1994.\n[Rao73]  C. R. Rao,Linear statistical inference and its applications, John Wiley and\nSons, New York, 1973.\n[RBZ06]  N. Ratliff, J. Bagnell, and M. Zinkevich,Maximum margin planning, Inter-\nnational Conference on Machine Learning, July 2006.\n[Ros58]  F. Rosenblatt,The perceptron: A probabilistic model for information storage\nand organization in the brain, Psychological Review65(1958), no. 6, 386–408.\n[RPB06]  M. Richardson, A. Prakash, and E. Brill,Beyond pagerank: machine learn-\ning  for  static  ranking,  Proceedings  of  the  15th  international  conference  on\nWorld  Wide  Web,  WWW  (L.  Carr,  D.  De  Roure,  A.  Iyengar,  C.A.  Goble,\nand M. Dahlin, eds.), ACM, 2006, pp. 707–715.\n\nBibliography225\n[RSS\n+\n07]  G.  R ̈atsch,  S.  Sonnenburg,  J.  Srinivasan,  H.  Witte,  K.-R.  M ̈uller,  R.  J.\nSommer, and B. Sch ̈olkopf,Improving the Caenorhabditis elegans genome an-\nnotation using machine learning, PLoS Computational Biology3(2007), no. 2,\ne20 doi:10.1371/journal.pcbi.0030020.\n[Rud73]  W. Rudin,Functional analysis, McGraw-Hill, New York, 1973.\n[Sil86]  B. W. Silverman,Density estimation for statistical and data analysis, Mono-\ngraphs on statistics and applied probability, Chapman and Hall, London, 1986.\n[SPST\n+\n01]  B.  Sch ̈olkopf,  J.  Platt,  J.  Shawe-Taylor,  A.  J.  Smola,  and  R.  C.\nWilliamson,Estimating  the  support  of  a  high-dimensional  distribution,  Neu-\nral Comput.13(2001), no. 7, 1443–1471.\n[SS02]  B. Sch ̈olkopf and A. Smola,Learning  with  kernels, MIT Press, Cambridge,\nMA, 2002.\n[SW86]  G.R.  Shorack  and  J.A.  Wellner,Empirical  processes  with  applications  to\nstatistics, Wiley, New York, 1986.\n[SZ92]  Helga Schramm and Jochem Zowe,A version of the bundle idea for minimiz-\ning  a  nonsmooth  function:  Conceptual  idea,  convergence  analysis,  numerical\nresults, SIAM J. Optimization2(1992), 121–152.\n[TGK04]  B.  Taskar,  C.  Guestrin,  and  D.  Koller,Max-margin  Markov  networks,\nAdvances  in  Neural  Information  Processing  Systems  16  (Cambridge,  MA)\n(S. Thrun, L. Saul, and B. Sch ̈olkopf, eds.), MIT Press, 2004, pp. 25–32.\n[TJHA05]  I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun,Large margin\nmethods  for  structured  and  interdependent  output  variables,  J.  Mach.  Learn.\nRes.6(2005), 1453–1484.\n[Vap82]  V.  Vapnik,Estimation  of  dependences  based  on  empirical  data,  Springer,\nBerlin, 1982.\n[Vap95]\n,The nature of statistical learning theory, Springer, New York, 1995.\n[Vap98],Statistical learning theory, John Wiley and Sons, New York, 1998.\n[vdG00]  S. van de Geer,Empirical processes in M-estimation, Cambridge University\nPress, 2000.\n[vdVW96]  A. W. van der Vaart and J. A. Wellner,Weak convergence and empirical\nprocesses, Springer, 1996.\n[VGS97]  V. Vapnik, S. Golowich, and A. J. Smola,Support vector method for func-\ntion approximation, regression estimation, and signal processing, Advances in\nNeural  Information  Processing  Systems  9  (Cambridge,  MA)  (M.  C.  Mozer,\nM. I. Jordan, and T. Petsche, eds.), MIT Press, 1997, pp. 281–287.\n[Voo01]  E.  Voorhees,Overview  of  the  TRECT  2001  question  answering  track,\nTREC, 2001.\n[VS04]  S.  V.  N.  Vishwanathan  and  A.  J.  Smola,Fast  kernels  for  string  and\ntree  matching,  Kernel  Methods  in  Computational  Biology  (Cambridge,  MA)\n(B. Sch ̈olkopf, K. Tsuda, and J. P. Vert, eds.), MIT Press, 2004, pp. 113–130.\n[VSV07]  S. V. N. Vishwanathan, A. J. Smola, and R. Vidal,Binet-Cauchy  kernels\non  dynamical  systems  and  its  application  to  the  analysis  of  dynamic  scenes,\nInternational Journal of Computer Vision73(2007), no. 1, 95–119.\n[Wah97]  G. Wahba,Support vector machines, reproducing kernel Hilbert spaces and\nthe randomized GACV, Tech. Report 984, Department of Statistics, University\nof Wisconsin, Madison, 1997.\n[Wat64]  G. S. Watson,Smooth regression analysis, Sankhya A26(1964), 359–372.\n[Wil98]  C. K. I. Williams,Prediction with Gaussian processes: From linear regression\nto  linear  prediction  and  beyond, Learning and Inference in Graphical Models\n(M. I. Jordan, ed.), Kluwer Academic, 1998, pp. 599–621.\n\n2263  Bibliography\n[WJ03]  M.  J.  Wainwright  and  M.  I.  Jordan,Graphical  models,  exponential  fami-\nlies, and variational inference, Tech. Report 649, UC Berkeley, Department of\nStatistics, September 2003.\n\n## Document Information\n- **Source**: PDF Document (234 pages)\n- **Category**: lab-material\n- **Difficulty**: advanced\n- **Relevant Labs**: lab5\n- **Topics**: classification, clustering, coordinate system, gee, gis, machine learning, mapping, projection, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain anintroductiontomachinelearning\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- classification\n- clustering\n- coordinate system\n- gee\n- gis\n- machine learning\n- mapping\n- projection\n- vector\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "advanced",
      "lab": "lab5",
      "topics": [
        "classification",
        "clustering",
        "coordinate system",
        "gee",
        "gis",
        "machine learning",
        "mapping",
        "projection",
        "vector"
      ],
      "source": "concepts\\ml_book.md",
      "filename": "ml_book.md"
    }
  },
  {
    "id": "concepts-qgis-3.22-desktopuserguide-en",
    "title": "QGIS Desktop 3.22 User Guide",
    "content": "\n# QGIS Desktop 3.22 User Guide\n\n\n\nQGIS Desktop 3.22 User Guide\nQGIS Project\nMar 21, 2023\n\n\n\nCONTENTS\n1  Preamble1\n1.1  What is new in QGIS 3.22. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1\n2  Foreword3\n3  Conventions5\n3.1  GUI Conventions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5\n3.2  Text or Keyboard Conventions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5\n3.3  Platform-specific instructions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .6\n4  Features7\n4.1  View data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7\n4.2  Explore data and compose maps. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7\n4.3  Create, edit, manage and export data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .8\n4.4  Analyze data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .8\n4.5  Publish maps on the Internet. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n4.6  Extend QGIS functionality through plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n4.6.1   Core Plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n4.6.2   External Python Plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n4.7  Python Console. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9\n4.8  Known Issues. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .10\n4.8.1   Number of open files limitation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .10\n5  Getting Started11\n5.1  Installing QGIS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .11\n5.1.1   Installing from binaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .11\n5.1.2   Installing from source. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .11\n5.1.3   Installing on external media. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .11\n5.1.4   Downloading sample data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .12\n5.2  Starting and stopping QGIS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .12\n5.3  Sample Session: Loading raster and vector layers. . . . . . . . . . . . . . . . . . . . . . . . . .13\n6  Working with Project Files19\n6.1  Introducing QGIS projects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19\n6.2  Handling broken file paths. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21\n6.3  Generating output. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .22\n7  QGIS GUI23\n7.1  Menu Bar. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24\n7.1.1   Project. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24\n7.1.2   Edit. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .25\n7.1.3   View. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .29\n7.1.4   Layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .32\n7.1.5   Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\n7.1.6   Plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\ni\n\n7.1.7   Vector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\n7.1.8   Raster. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36\n7.1.9   Database. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .37\n7.1.10  Web. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .37\n7.1.11  Mesh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .37\n7.1.12  Processing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .37\n7.1.13  Help. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .38\n7.1.14  QGIS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .38\n7.2  Panels and Toolbars. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .38\n7.2.1   Toolbars. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .38\n7.2.2   Panels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .39\n7.3  Map View. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .40\n7.3.1   Exploring the map view. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .40\n7.3.2   Setting additional map views. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41\n7.3.3   Time-based control on the map canvas. . . . . . . . . . . . . . . . . . . . . . . . . . .42\n7.3.4   Exporting the map view. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .44\n7.4  3D Map View. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .47\n7.4.1   Scene Configuration. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48\n7.4.2   Navigation options. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .51\n7.4.3   Creating an animation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .52\n7.4.4   3D vector layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .52\n7.5  Status Bar. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .52\n7.5.1   Locator bar. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .52\n7.5.2   Reporting actions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\n7.5.3   Control the map canvas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\n7.5.4   Messaging. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .54\n8  The Browser panel55\n8.1  Resources that can be opened / run from the Browser. . . . . . . . . . . . . . . . . . . . . . . .58\n8.2  Browser panel top-level entries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .58\n8.2.1   Favorites. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .58\n8.2.2   Spatial Bookmarks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .58\n8.2.3   Project Home. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .58\n8.2.4   Drives and file system. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .59\n8.2.5   Database entries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .59\n8.2.6   Tiles and Web Services. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .61\n8.3  Resources. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .61\n9  QGIS Configuration63\n9.1  Options. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .63\n9.1.1   General Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .64\n9.1.2   System Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .66\n9.1.3   CRS Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .68\n9.1.4   Transformations Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .69\n9.1.5   Data Sources Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .70\n9.1.6   Rendering Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .72\n9.1.7   Canvas and Legend Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\n9.1.8   Map tools Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\n9.1.9   3D Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .76\n9.1.10  Colors Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\n9.1.11  Digitizing Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78\n9.1.12  Layouts Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80\n9.1.13  GDAL Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80\n9.1.14  Variables Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .83\n9.1.15  Authentication Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84\n9.1.16  Network Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .85\n9.1.17  Locator Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .86\n9.1.18  Acceleration Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .88\nii\n\n9.1.19  Processing Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .88\n9.1.20  Python Console Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .89\n9.1.21  Code Editor Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .91\n9.1.22  Advanced Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .92\n9.2  Working with User Profiles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .92\n9.3  Project Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .93\n9.3.1   General Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .93\n9.3.2   Metadata Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .95\n9.3.3   View Settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .96\n9.3.4   CRS Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .96\n9.3.5   Transformations Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .97\n9.3.6   Default Styles Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .97\n9.3.7   Data Sources Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .98\n9.3.8   Relations Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\n9.3.9   Variables Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .100\n9.3.10  Macros Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .100\n9.3.11  QGIS Server Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .101\n9.3.12  Temporal Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .102\n9.4  Customization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .103\n9.5  Keyboard shortcuts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .104\n9.6  Running QGIS with advanced settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .105\n9.6.1   Command line and environment variables. . . . . . . . . . . . . . . . . . . . . . . . . .105\n9.6.2   Deploying QGIS within an organization. . . . . . . . . . . . . . . . . . . . . . . . . . .110\n10 Working with Projections113\n10.1  Overview of Projection Support. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .113\n10.2  Layer Coordinate Reference Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .113\n10.3  Project Coordinate Reference Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .115\n10.4  Coordinate Reference System Selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .116\n10.5  Custom Coordinate Reference System. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .117\n10.5.1  Integrate an NTv2-transformation in QGIS. . . . . . . . . . . . . . . . . . . . . . . . .118\n10.6  Datum Transformations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .119\n11 General Tools121\n11.1  Context help. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121\n11.2  Panels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121\n11.2.1  Layers Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121\n11.2.2  Layer Styling Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126\n11.2.3  Layer Order Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .129\n11.2.4  Overview Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .129\n11.2.5  Log Messages Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .130\n11.2.6  Undo/Redo Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .130\n11.2.7  Statistical Summary Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .130\n11.2.8  Debugging/Development Tools Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . .131\n11.3  Embedding layers from external projects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\n11.4  Working with the map canvas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\n11.4.1  Rendering. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\n11.4.2  Zooming and Panning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .136\n11.4.3  Spatial Bookmarks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .138\n11.4.4  Decorations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .139\n11.4.5  Annotation Tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .147\n11.4.6  Measuring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .149\n11.5  Interacting with features. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .151\n11.5.1  Selecting features. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .151\n11.5.2  Identifying Features. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .154\n11.6  Save and Share Layer Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .158\n11.6.1  Managing Custom Styles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .158\n11.6.2  Storing Styles in a File or a Database. . . . . . . . . . . . . . . . . . . . . . . . . . . .159\niii\n\n11.6.3  Layer definition file. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .161\n11.7  Documenting your data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .161\n11.7.1  Metadata. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .161\n11.7.2  Layer notes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .161\n11.8  Storing values in Variables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .162\n11.9  Authentication. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .164\n11.10 Common widgets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .164\n11.10.1 Color Selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .164\n11.10.2 Symbol Widget. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169\n11.10.3 Remote or embedded file selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169\n11.10.4 Spatial Extent Selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .170\n11.10.5 Font Selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .170\n11.10.6 Unit Selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .171\n11.10.7 Number Formatting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172\n11.10.8 Blending Modes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173\n11.10.9 Data defined override setup. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .174\n12 Level up with Expressions177\n12.1  Expressions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .177\n12.1.1  The Expression string builder. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .177\n12.1.2  Function Editor. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .182\n12.2  List of functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .184\n12.2.1  Aggregates Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .184\n12.2.2  Array Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .194\n12.2.3  Color Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .205\n12.2.4  Conditional Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .211\n12.2.5  Conversions Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214\n12.2.6  Custom Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .218\n12.2.7  Date and Time Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\n12.2.8  Fields and Values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .228\n12.2.9  Files and Paths Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .229\n12.2.10 Form Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .231\n12.2.11 Fuzzy Matching Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .232\n12.2.12 General Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .233\n12.2.13 Geometry Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .235\n12.2.14 Layout Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .288\n12.2.15 Map Layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289\n12.2.16 Maps Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .290\n12.2.17 Mathematical Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .293\n12.2.18 Meshes Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .301\n12.2.19 Operators. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .302\n12.2.20 Processing Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\n12.2.21 Rasters Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\n12.2.22 Record and Attributes Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .311\n12.2.23 Relations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\n12.2.24 String Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\n12.2.25 User Expressions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .326\n12.2.26 Variables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .326\n12.2.27 Recent Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330\n13 The Style Library331\n13.1  The Style Manager. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .331\n13.1.1  The Style Manager dialog. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .331\n13.1.2  Setting a Color Ramp. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .336\n13.1.3  Creating a Legend Patch Shape. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .338\n13.2  The Symbol Selector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .340\n13.2.1  The symbol layer tree. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .341\n13.2.2  Configuring a symbol. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .342\niv\n\n13.3  Setting a label. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .352\n13.3.1  Formatting the label text. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\n13.3.2  Configuring interaction with labels. . . . . . . . . . . . . . . . . . . . . . . . . . . . .362\n13.4  Creating 3D Symbols. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .370\n13.4.1  Point Layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .371\n13.4.2  Line layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .372\n13.4.3  Polygon Layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .373\n13.4.4  Shading the texture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .375\n13.4.5  Application example. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .375\n14 Managing Data Source377\n14.1  Opening Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .377\n14.1.1  The Browser Panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .379\n14.1.2  The DB Manager. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .382\n14.1.3  Provider-based loading tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .383\n14.1.4  QGIS Custom formats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .402\n14.1.5  QLR - QGIS Layer Definition File. . . . . . . . . . . . . . . . . . . . . . . . . . . . .402\n14.1.6  Connecting to web services. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .402\n14.2  Creating Layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .406\n14.2.1  Creating new vector layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .406\n14.2.2  Creating new layers from an existing layer. . . . . . . . . . . . . . . . . . . . . . . . .413\n14.2.3  Creating new DXF files. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .416\n14.2.4  Creating new layers from the clipboard. . . . . . . . . . . . . . . . . . . . . . . . . . .417\n14.2.5  Creating virtual layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .418\n14.3  Exploring Data Formats and Fields. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .420\n14.3.1  Raster data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .420\n14.3.2  Vector Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .421\n15 Working with Vector Data431\n15.1  The Vector Properties Dialog. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .431\n15.1.1  Information Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .432\n15.1.2  Source Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .432\n15.1.3  Symbology Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435\n15.1.4  Labels Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .456\n15.1.5  Diagrams Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .467\n15.1.6  Masks Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .471\n15.1.7  3D View Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .472\n15.1.8  Fields Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .473\n15.1.9  Attributes Form Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .474\n15.1.10 Joins Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .481\n15.1.11 Auxiliary Storage Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .483\n15.1.12 Actions Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .492\n15.1.13 Display Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .497\n15.1.14 Rendering Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .499\n15.1.15 Temporal Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .500\n15.1.16 Variables Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .501\n15.1.17 Metadata Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .501\n15.1.18 Dependencies Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .501\n15.1.19 Legend Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .502\n15.1.20 QGIS Server Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .502\n15.1.21 Digitizing Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .503\n15.2  Working with the Attribute Table. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .506\n15.2.1  Foreword: Spatial and non-spatial tables. . . . . . . . . . . . . . . . . . . . . . . . . .506\n15.2.2  Introducing the attribute table interface. . . . . . . . . . . . . . . . . . . . . . . . . . .506\n15.2.3  Interacting with features in an attribute table. . . . . . . . . . . . . . . . . . . . . . . .511\n15.2.4  Using action on features. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .514\n15.2.5  Editing attribute values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .515\n15.2.6  Creating one or many to many relations. . . . . . . . . . . . . . . . . . . . . . . . . . .519\nv\n\n15.2.7  Storing and fetching an external resource. . . . . . . . . . . . . . . . . . . . . . . . . .532\n15.3  Editing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .533\n15.3.1  Setting the snapping tolerance and search radius. . . . . . . . . . . . . . . . . . . . . .534\n15.3.2  Snapping and Digitizing Options. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .534\n15.3.3  Topological editing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .537\n15.3.4  Digitizing an existing layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .538\n15.3.5  Advanced digitizing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .546\n15.3.6  Shape digitizing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .555\n15.3.7  The Advanced Digitizing panel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .557\n15.3.8  The Processing in-place layer modifier. . . . . . . . . . . . . . . . . . . . . . . . . . .563\n16 Working with Raster Data567\n16.1  Raster Properties Dialog. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .567\n16.1.1  Information Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .567\n16.1.2  Source Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .568\n16.1.3  Symbology Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .568\n16.1.4  Transparency Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .579\n16.1.5  Histogram Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .580\n16.1.6  Rendering Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .581\n16.1.7  Temporal Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .582\n16.1.8  Pyramids Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .583\n16.1.9  Metadata Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .585\n16.1.10 Legend Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .585\n16.1.11 QGIS Server Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .586\n16.2  Raster Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .587\n16.2.1  Raster Calculator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .587\n16.2.2  Raster Alignment. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .590\n16.3  Georeferencer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .591\n16.3.1  Usual procedure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .592\n17 Working with Mesh Data599\n17.1  What’s a mesh?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .599\n17.2  Supported formats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .601\n17.3  Mesh Dataset Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .601\n17.3.1  Information Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .602\n17.3.2  Source Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .603\n17.3.3  Symbology Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .604\n17.3.4  3D View Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .609\n17.3.5  Rendering Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .611\n17.3.6  Temporal Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .611\n17.3.7  Metadata Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .612\n17.4  Editing a mesh layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .612\n17.4.1  Overview of the mesh digitizing tools. . . . . . . . . . . . . . . . . . . . . . . . . . . .612\n17.4.2  Exploring the Z value assignment logic. . . . . . . . . . . . . . . . . . . . . . . . . . .613\n17.4.3  Selecting mesh elements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .614\n17.4.4  Modifying mesh elements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .615\n17.4.5  Reindexing meshes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .618\n17.5  Mesh Calculator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .618\n18 Working with Vector Tiles621\n18.1  What are Vector Tiles?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .621\n18.2  Supported Formats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .622\n18.3  Vector Tiles Dataset Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .623\n18.3.1  Information Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .623\n18.3.2  Symbology and Label Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .623\n18.3.3  Metadata Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .624\n19 Laying out the maps625\n19.1  Overview of the Print Layout. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .625\nvi\n\n19.1.1  Sample Session for beginners. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .625\n19.1.2  The Layout Manager. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .626\n19.1.3  Menus, tools and panels of the print layout. . . . . . . . . . . . . . . . . . . . . . . . .627\n19.2  Layout Items. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .641\n19.2.1  Layout Items Common Options. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .641\n19.2.2  The Map Item. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .646\n19.2.3  The 3D Map Item. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .656\n19.2.4  The Label Item. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .657\n19.2.5  The Legend Item. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .660\n19.2.6  The Scale Bar Item. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .668\n19.2.7  The Table Items. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .672\n19.2.8  The Marker, Picture and North Arrow Items. . . . . . . . . . . . . . . . . . . . . . . .681\n19.2.9  The HTML Frame Item. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .685\n19.2.10 The Shape Items. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .688\n19.3  Creating an Output. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .691\n19.3.1  Export settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .691\n19.3.2  Export as Image. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .692\n19.3.3  Export as SVG. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .693\n19.3.4  Export as PDF. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .694\n19.3.5  Generate an Atlas. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .695\n19.4  Creating a Report. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .701\n19.4.1  What is it?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .701\n19.4.2  Get started. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .701\n19.4.3  Layout Report Workspace. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .702\n19.4.4  Export settings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .717\n20 Working with OGC / ISO protocols719\n20.1  WMS/WMTS Client. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .719\n20.1.1  Overview of WMS Support. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .719\n20.1.2  Overview of WMTS Support. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .720\n20.1.3  Selecting WMS/WMTS Servers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .721\n20.1.4  Loading WMS/WMTS Layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .723\n20.1.5  Tilesets. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .725\n20.1.6  Using the Identify Tool. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .726\n20.1.7  Show WMS legend graphic in table of contents and layout. . . . . . . . . . . . . . . . .727\n20.1.8  WMS Client Limitations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .728\n20.2  WCS Client. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .728\n20.3  WFS and WFS-T Client. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .729\n21 Working with GPS Data733\n21.1  GPS Plugin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .733\n21.1.1  What is GPS?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .733\n21.1.2  Loading GPS data from a file. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .733\n21.1.3  GPSBabel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .734\n21.1.4  Importing GPS data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .734\n21.1.5  Downloading GPS data from a device. . . . . . . . . . . . . . . . . . . . . . . . . . . .734\n21.1.6  Uploading GPS data to a device. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .735\n21.1.7  Defining new device types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .735\n21.1.8  Download of points/tracks from GPS units. . . . . . . . . . . . . . . . . . . . . . . . .736\n21.2  Live GPS tracking. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .737\n21.2.1  Position and additional attributes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .738\n21.2.2  GPS signal strength. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .738\n21.2.3  GPS options. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .740\n21.2.4  Connect to a Bluetooth GPS for live tracking. . . . . . . . . . . . . . . . . . . . . . . .741\n21.2.5  Using GPSMAP 60cs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .742\n21.2.6  Using BTGP-38KM datalogger (only Bluetooth). . . . . . . . . . . . . . . . . . . . . .742\n21.2.7  Using BlueMax GPS-4044 datalogger (both BT and USB). . . . . . . . . . . . . . . . .742\nvii\n\n22 Authentication System745\n22.1  Authentication System Overview. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .745\n22.1.1  Authentication database. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .745\n22.1.2  Master password. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .746\n22.1.3  Authentication Configurations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .747\n22.1.4  Authentication Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .749\n22.1.5  Master Password and Auth Config Utilities. . . . . . . . . . . . . . . . . . . . . . . . .753\n22.1.6  Using authentication configurations. . . . . . . . . . . . . . . . . . . . . . . . . . . . .754\n22.1.7  Python bindings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .754\n22.2  User Authentication Workflows. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .755\n22.2.1  HTTP(S) authentication. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .755\n22.2.2  Database authentication. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .756\n22.2.3  PKI authentication. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .757\n22.2.4  Handling bad layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .764\n22.2.5  Changing authentication config ID. . . . . . . . . . . . . . . . . . . . . . . . . . . . .765\n22.2.6  QGIS Server support. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .766\n22.2.7  SSL server exceptions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .766\n22.3  Security Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .769\n22.3.1  Restrictions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .770\n23 GRASS GIS Integration771\n23.1  Demo dataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .771\n23.2  Loading GRASS raster and vector layers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .771\n23.3  Importing data into a GRASS LOCATION via drag and drop. . . . . . . . . . . . . . . . . . . .772\n23.4  Managing GRASS data in QGIS Browser. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .772\n23.5  GRASS Options. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .772\n23.6  Starting the GRASS plugin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .772\n23.7  Opening GRASS mapset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .773\n23.8  GRASS LOCATION and MAPSET. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .773\n23.9  Importing data into a GRASS LOCATION. . . . . . . . . . . . . . . . . . . . . . . . . . . . .773\n23.9.1  Creating a new GRASS LOCATION. . . . . . . . . . . . . . . . . . . . . . . . . . . .774\n23.9.2  Adding a new MAPSET. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .775\n23.10 The GRASS vector data model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .776\n23.11 Creating a new GRASS vector layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .776\n23.12 Digitizing and editing a GRASS vector layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . .777\n23.13 The GRASS region tool. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .779\n23.14 The GRASS Toolbox. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .779\n23.14.1 Working with GRASS modules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .780\n23.14.2 GRASS module examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .783\n23.14.3 Customizing the GRASS Toolbox. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .786\n24 QGIS processing framework789\n24.1  Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .789\n24.2  Configuring the Processing Framework. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .791\n24.3  The Toolbox. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .793\n24.3.1  The algorithm dialog. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .795\n24.3.2  Data objects generated by algorithms. . . . . . . . . . . . . . . . . . . . . . . . . . . .800\n24.4  The history manager. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .801\n24.4.1  The processing history. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .801\n24.4.2  The processing log. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .802\n24.5  The graphical modeler. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .802\n24.5.1  The graphical modeler interface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .803\n24.5.2  Creating a model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .806\n24.5.3  Saving and loading models. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .815\n24.5.4  Editing a model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .815\n24.6  The batch processing interface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .817\n24.6.1  Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .817\n24.6.2  The parameters table. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .818\nviii\n\n24.6.3  Filling the parameters table. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .819\n24.6.4  Executing the batch process. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .820\n24.7  Using processing algorithms from the console. . . . . . . . . . . . . . . . . . . . . . . . . . . .820\n24.7.1  Calling algorithms from the Python console. . . . . . . . . . . . . . . . . . . . . . . . .821\n24.7.2  Creating scripts and running them from the toolbox. . . . . . . . . . . . . . . . . . . .825\n24.7.3  Pre- and post-execution script hooks. . . . . . . . . . . . . . . . . . . . . . . . . . . .828\n24.8  Using processing from the command line. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .828\n24.9  Writing new Processing algorithms as Python scripts. . . . . . . . . . . . . . . . . . . . . . . . .830\n24.9.1  Extending QgsProcessingAlgorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . .830\n24.9.2  The @alg decorator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .834\n24.9.3  Input and output types for Processing Algorithms. . . . . . . . . . . . . . . . . . . . . .836\n24.9.4  Handing algorithm output. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .838\n24.9.5  Communicating with the user. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .838\n24.9.6  Documenting your scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .838\n24.9.7  Flags. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .838\n24.9.8  Best practices for writing script algorithms. . . . . . . . . . . . . . . . . . . . . . . . .839\n24.10 Configuring external applications. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .839\n24.10.1 A note for Windows users. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .839\n24.10.2 A note on file formats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .839\n24.10.3 A note on vector layer selections. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .840\n24.10.4 SAGA. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .840\n24.10.5 R scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .841\n24.10.6 R libraries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .848\n24.10.7 GRASS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .848\n24.10.8 LAStools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .848\n24.10.9 OTB Applications. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .849\n25 Processing providers and algorithms851\n25.1  QGIS algorithm provider. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .851\n25.1.1  Cartography. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .851\n25.1.2  Database. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .866\n25.1.3  File tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .873\n25.1.4  GPS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .874\n25.1.5  Interpolation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .877\n25.1.6  Layer tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .888\n25.1.7  Mesh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .892\n25.1.8  Modeler tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .902\n25.1.9  Network analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .912\n25.1.10 Plots. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .922\n25.1.11 Raster analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .928\n25.1.12 Raster Creation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .977\n25.1.13 Raster terrain analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .990\n25.1.14 Raster tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1001\n25.1.15 Vector analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1006\n25.1.16 Vector creation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1028\n25.1.17 Vector general. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1052\n25.1.18 Vector geometry. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1087\n25.1.19 Vector overlay. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1195\n25.1.20 Vector selection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1210\n25.1.21 Vector table. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1225\n25.1.22 Vector Tiles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1239\n25.2  GDAL algorithm provider. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1242\n25.2.1  Raster analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1242\n25.2.2  Raster conversion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1269\n25.2.3  Raster extraction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1276\n25.2.4  Raster miscellaneous. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1282\n25.2.5  Raster projections. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1299\n25.2.6  Vector conversion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1303\nix\n\n25.2.7  Vector geoprocessing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1309\n25.2.8  Vector miscellaneous. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1317\n25.3  OTB applications provider. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1326\n26 Plugins1327\n26.1  QGIS Plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1327\n26.1.1  Core and External plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1327\n26.1.2  The Plugins Dialog. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1327\n26.2  Using QGIS Core Plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1333\n26.2.1  DB Manager Plugin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1333\n26.2.2  Geometry Checker Plugin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1335\n26.2.3  MetaSearch Catalog Client. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1339\n26.2.4  Offline Editing Plugin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1346\n26.2.5  Topology Checker Plugin. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1348\n26.3  QGIS Python console. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1350\n26.3.1  The Interactive Console. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1350\n26.3.2  The Code Editor. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1351\n27 Help and Support1353\n27.1  Mailing lists. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1353\n27.1.1  QGIS Users. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1353\n27.1.2  QGIS Developers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1353\n27.1.3  QGIS Community Team. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1353\n27.1.4  QGIS Translations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1353\n27.1.5  QGIS Project Steering Committee (PSC). . . . . . . . . . . . . . . . . . . . . . . . . .1354\n27.1.6  QGIS User groups. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1354\n27.2  IRC. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1354\n27.3  Commercial support. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1354\n27.4  BugTracker. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1354\n27.5  Blog. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1354\n27.6  Plugins. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1355\n27.7  Wiki. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1355\n28 Contributors1357\n28.1  Authors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1357\n28.2  Translators. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1358\n28.3  Statistics of translation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1359\n29 Appendices1361\n29.1  Appendix A: GNU General Public License. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1361\n29.2  Appendix B: GNU Free Documentation License. . . . . . . . . . . . . . . . . . . . . . . . . . .1364\n29.3  Appendix C: QGIS File Formats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1369\n29.3.1  QGS/QGZ - The QGIS Project File Format. . . . . . . . . . . . . . . . . . . . . . . .1369\n29.3.2  QLR - The QGIS Layer Definition file. . . . . . . . . . . . . . . . . . . . . . . . . . .1371\n29.3.3  QML - The QGIS Style File Format. . . . . . . . . . . . . . . . . . . . . . . . . . . .1372\n29.4  Appendix D: QGIS R script syntax. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1373\n29.4.1  Inputs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1374\n29.4.2  Outputs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1374\n29.4.3  Syntax Summary for QGIS R scripts. . . . . . . . . . . . . . . . . . . . . . . . . . . .1374\n29.4.4  Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1376\n29.5  Appendix E: QGIS Application Network Connections. . . . . . . . . . . . . . . . . . . . . . . .1378\n30 Literature and Web References1381\nx\n\nCHAPTER\nONE\nPREAMBLE\nThis is the user guide for the geographical information system (GIS) software QGIS. QGIS is subject to the GNU\nGeneral Public License. More information is available on the QGIS homepage,https://www.qgis.org.\nThe contents of this document have been written and verified to the best of the knowledge of the authors and editors.\nNevertheless, mistakes are possible.\nTherefore, the authors, editors and publishers do not take any responsibility or liability for errors in this document\nand their possible consequences. We encourage you to report possible mistakes.\nThis document has been typeset with reStructuredText. It is available as reST source code on\ngithub, and online\nas HTML and PDF viahttps://www.qgis.org/en/docs/. Translated versions of this document can be browsed and\ndownloaded via the documentation area of the QGIS project as well.\nFor more information about contributing to this document and about translation, please visit\nhttps://qgis.org/en/site/\ngetinvolved/index.html.\nLinks in this Document\nThis document contains internal and external links. Clicking on an internal link moves within the document, while\nclicking on an external link opens an internet address.\nDocumentation Authors and Editors\nThe list of the persons who have contributed with writing, reviewing and translating the following documentation is\navailable at\nContributors.\nCopyright (c) 2004 - 2020 QGIS Development Team\nInternet:\nhttps://www.qgis.org\nLicense of this document\nPermission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documenta-\ntion License, Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections,\nno Front-Cover Texts and no Back-Cover Texts. A copy of the license is included in AppendixAppendix B: GNU\nFree Documentation License\n.\n1.1What is new in QGIS 3.22\nThis release of QGIS includes hundreds of bug fixes and many new features and enhancements, compared toQGIS\n3.16. For a list of new features, visit the visual changelogs athttps://qgis.org/en/site/forusers/visualchangelogs.html.\n1\n\nQGIS Desktop 3.22 User Guide\n2Chapter 1. Preamble\n\nCHAPTER\nTWO\nFOREWORD\nWelcome to the wonderful world of Geographical Information Systems (GIS)!\nQGIS is an Open Source Geographic Information System. The project was born in May 2002 and was established as\na project on SourceForge in June the same year. We have worked hard to make GIS software (which is traditionally\nexpensive proprietary software) available to anyone with access to a personal computer. QGIS currently runs on most\nUnix platforms, Windows, and macOS. QGIS is developed using the Qt toolkit (https://www.qt.io) and C++. This\nmeans that QGIS feels snappy and has a pleasing, easy-to-use graphical user interface (GUI).\nQGIS aims to be a user-friendly GIS, providing common functions and features. The initial goal of the project was\nto provide a GIS data viewer. QGIS has reached the point in its evolution where it is being used for daily GIS data-\nviewing needs, for data capture, for advanced GIS analysis, and for presentations in the form of sophisticated maps,\natlases and reports. QGIS supports a wealth of raster and vector data formats, with new format support easily added\nusing the plugin architecture.\nQGIS is released under the GNU General Public License (GPL). Developing QGIS under this license means that you\ncan inspect and modify the source code, and guarantees that you, our happy user, will always have access to a GIS\nprogram that is free of cost and can be freely modified. You should have received a full copy of the license with your\ncopy of QGIS, and you can also find it in Appendix\nAppendix A: GNU General Public License.\nTip: Up-to-date Documentation\nThe latest version of this document can always be found in the documentation area of the QGIS website athttps:\n//www.qgis.org/en/docs/\n.\n3\n\nQGIS Desktop 3.22 User Guide\n4Chapter 2. Foreword\n\nCHAPTER\nTHREE\nCONVENTIONS\nThis section describes the uniform styles that will be used throughout this manual.\n3.1GUI Conventions\nThe GUI convention styles are intended to mimic the appearance of the GUI. In general, a style will reflect the\nnon-hover appearance, so a user can visually scan the GUI to find something that looks like the instruction in the\nmanual.\n•Menu Options:Layer►Add a Raster LayerorSettings►Toolbars►Digitizing\n•Tool:\nAdd a Raster Layer\n•Button :Save as Default\n•Dialog Box Title:Layer Properties\n•Tab:General\n•Checkbox:Render\n•Radio Button:Postgis SRIDEPSG ID\n•Select a number:\n•Select a string:\n•Browse for a file:...\n•Select a color:\n•Slider:\n•Input Text:\nA shadow indicates a clickable GUI component.\n3.2Text or Keyboard Conventions\nThis manual also includes styles related to text, keyboard commands and coding to indicate different entities, such as\nclasses or methods. These styles do not correspond to the actual appearance of any text or coding within QGIS.\n•Hyperlinks:https://qgis.org\n•Keystroke Combinations: PressCtrl+B, meaning press and hold the Ctrl key and then press the B key.\n•Name of a File:lakes.shp\n•Name of a Class:NewLayer\n5\n\nQGIS Desktop 3.22 User Guide\n•Method:classFactory\n•Server:myhost.de\n•User Text:qgis --help\nLines of code are indicated by a fixed-width font:\nPROJCS[\"NAD_1927_Albers\",\nGEOGCS[\"GCS_North_American_1927\",\n3.3Platform-specific instructions\nGUI sequences and small amounts of text may be formatted inline: ClickFileQGIS►Quit to close QGIS.\nThis indicates that on Linux, Unix and Windows platforms, you should click the File menu first, then Quit, while on\nmacOS platforms, you should click the QGIS menu first, then Quit.\nLarger amounts of text may be formatted as a list:\n•Do this\n•Do that\n•Or do that\nor as paragraphs:\nDo this and this and this. Then do this and this and this, and this and this and this, and this and this and this.\nDo that. Then do that and that and that, and that and that and that, and that and that and that, and that and that.\nScreenshots that appear throughout the user guide have been created on different platforms.\n6Chapter 3. Conventions\n\nCHAPTER\nFOUR\nFEATURES\nQGIS offers a wealth of GIS functions, provided by core features and plugins. The locator bar makes it easy to search\nfor functions, datasets and more.\nA short summary of six general categories of features and plugins is presented below, followed by first insights into\nthe integrated Python console.\n4.1View data\nYou can view combinations of vector and raster data (in 2D or 3D) in different formats and projections without\nconversion to an internal or common format. Supported formats include:\n•Spatially-enabled tables and views using PostGIS, SpatiaLite and MS SQL Spatial, Oracle Spatial, vector for-\nmats supported by the installed OGR library, including GeoPackage, ESRI Shapefile, MapInfo, SDTS, GML\nand many more. See section\nWorking with Vector Data.\n•Raster and imagery formats supported by the installed GDAL (Geospatial Data Abstraction Library) library,\nsuch as GeoTIFF, ERDAS IMG, ArcInfo ASCII GRID, JPEG, PNG and many more. See sectionWorking\nwith Raster Data\n.\n•Mesh data (TINs and regular grids are supported). SeeWorking with Mesh Data.\n•Vector tiles\n•GRASS raster and vector data from GRASS databases (location/mapset). See sectionGRASS GIS Integration.\n•Online spatial data served as OGC Web Services, including WMS, WMTS, WCS, WFS, and WFS-T. See\nsectionWorking with OGC / ISO protocols.\nThe QGIS authentication infrastructure helps you manage user/password, certificates and keys for web services\nand other resources.\n•Spreadsheets (ODS / XLSX)\nTemporal data are supported.\n4.2Explore data and compose maps\nYou can compose maps and interactively explore spatial data with a friendly GUI. The many helpful tools available\nin the GUI include:\n•QGIS browser\n•On-the-fly reprojection\n•2D and 3D map rendering\n•DB Manager\n•Print layout\n7\n\nQGIS Desktop 3.22 User Guide\n•Report\n•Overview panel\n•Spatial bookmarks\n•Annotation tools\n•Identify/select features\n•Edit/view/search attributes\n•Data-defined feature labeling\n•Data-defined vector and raster symbology tools\n•Atlas map composition with graticule layers\n•North arrow, scale bar and copyright label for maps\n•Support for saving and restoring projects\n4.3Create, edit, manage and export data\nYou can create, edit, manage and export vector and raster layers in several formats. QGIS offers the following:\n•Vector digitizing tools\n•Ability to create and edit multiple file formats and GRASS vector layers\n•Georeferencer plugin to geocode images\n•GPS tools to import and export GPX format, and convert other GPS formats to GPX or down/upload directly\nto a GPS unit (on Linux, usb: has been added to list of GPS devices)\n•Support for visualizing and editing OpenStreetMap data\n•Ability to create spatial database tables from files with the DB Manager plugin\n•Improved handling of spatial database tables\n•Tools for managing vector attribute tables\n•Option to save screenshots as georeferenced images\n•DXF-Export tool with enhanced capabilities to export styles and plugins to perform CAD-like functions\n4.4Analyze data\nYou can perform spatial data analysis on spatial databases and other OGR-supported formats. QGIS currently offers\nvector analysis, raster analysis, sampling, geoprocessing, geometry and database management tools. You can also\nuse the integrated GRASS tools, which include the complete GRASS functionality of more than 400 modules (see\nsection\nGRASS GIS Integration). Or, you can work with the Processing plugin, which provides a powerful geospatial\nanalysis framework to call native and third-party algorithms from QGIS, such as GDAL, SAGA, GRASS, OTB, R,\nand more (see section\nIntroduction). All analysis functions are run in the background, allowing you to continue your\nwork before the processing has finished.\nThe graphical modeller allows you to combine / chain functions into a complete workflow in an intuitive graphical\nenvironment.\n8Chapter 4. Features\n\nQGIS Desktop 3.22 User Guide\n4.5Publish maps on the Internet\nQGIS can be used as a WMS, WMTS, WMS-C, WFS, OAPIF and WFS-T client (see sectionWorking with OGC /\nISO protocols), and QGIS Server (see QGIS-Server-manual) allows you to publish your data through the WMS, WCS,\nWFS and OAPIF protocols on the Internet using a webserver.\n4.6Extend QGIS functionality through plugins\nQGIS can be adapted to your special needs with the extensible plugin architecture and libraries that can be used to\ncreate plugins. You can even create new applications with C++ or Python!\n4.6.1Core Plugins\nCore plugins include:\n1.DB Manager (exchange, edit and view layers and tables from/to databases; execute SQL queries)\n2.Geometry Checker (check geometries for errors)\n3.Georeferencer GDAL (add projection information to rasters using GDAL)\n4.GPS Tools (load and import GPS data)\n5.GRASS (integrate GRASS GIS)\n6.MetaSearch Catalogue Client (interacting with metadata catalog services supporting the OGC Catalog Service\nfor the Web (CSW) standard)\n7.Offline Editing (allow offline editing and synchronizing with databases)\n8.Processing (the spatial data processing framework for QGIS)\n9.Topology Checker (find topological errors in vector layers)\n4.6.2External Python Plugins\nQGIS offers a growing number of external Python plugins that are provided by the community. These plugins reside\nin the official Plugins Repository and can be easily installed using the Python Plugin Installer. See SectionThe Plugins\nDialog.\n4.7Python Console\nFor scripting, it is possible to take advantage of an integrated Python console, which can be opened with:Plugins►\nPython Console. The console opens as a non-modal utility window. For interaction with the QGIS environment, there\nis theqgis.utils.ifacevariable, which is an instance of\nQgisInterface. This interface provides access\nto the map canvas, menus, toolbars and other parts of the QGIS application. You can create a script, then drag and\ndrop it into the QGIS window and it will be executed automatically.\nFor further information about working with the Python console and programming QGIS plugins and applications,\nplease refer to\nQGIS Python consoleand PyQGIS-Developer-Cookbook.\n4.5. Publish maps on the Internet9\n\nQGIS Desktop 3.22 User Guide\n4.8Known Issues\n4.8.1Number of open files limitation\nIf you are opening a large QGIS project and you are sure that all layers are valid, but some layers are flagged as\nbad, you are probably faced with this issue. Linux (and other OSs, likewise) has a limit of opened files by process.\nResource limits are per-process and inherited. Theulimitcommand, which is a shell built-in, changes the limits\nonly for the current shell process; the new limit will be inherited by any child processes.\nYou can see all current ulimit info by typing:\n$ulimit-aS\nYou can see the current allowed number of opened files per process with the following command on a console:\n$ulimit-Sn\nTo change the limits for anexisting session, you may be able to use something like:\n$ulimit-Sn#number_of_allowed_open_files\n$ulimit-Sn\n$qgis\nTo fix it forever\nOn most Linux systems, resource limits are set on login by thepam_limitsmodule according to the settings\ncontained in/etc/security/limits.confor/etc/security/limits.d/*.conf. You should be\nable to edit those files if you have root privilege (also via sudo), but you will need to log in again before any changes\ntake effect.\nMore info:\nhttps://www.cyberciti.biz/faq/linux-increase-the-maximum-number-of-open-files/https://linuxaria.com/article/\nopen-files-in-linux\n10Chapter 4. Features\n\nCHAPTER\nFIVE\nGETTING STARTED\nThis chapter provides a quick overview of installing QGIS, downloading QGIS sample data, and running a first simple\nsession visualizing raster and vector data.\n5.1Installing QGIS\nQGIS project provides different ways to install QGIS depending on your platform.\n5.1.1Installing from binaries\nStandard installers are available forMS Windows andmacOS. Binary packages (rpm and deb) or software\nrepositories are provided for many flavors of GNU/Linux\n.\nFor more information and instructions for your operating system checkhttps://download.qgis.org.\n5.1.2Installing from source\nIf you need to build QGIS from source, please refer to the installation instructions. They are distributed with the\nQGIS source code in a file calledINSTALL. You can also find them online athttps://github.com/qgis/QGIS/blob/\nrelease-3_22/INSTALL.md.\nIf you want to build a particular release and not the version in development, you should replacemasterwith the\nrelease branch (commonly in therelease-X_Yform) in the above-mentioned link (installation instructions may\ndiffer).\n5.1.3Installing on external media\nIt is possible to install QGIS (with all plugins and settings) on a flash drive. This is achieved by defining a–profiles-\npathoption that overrides the defaultuser profilepath and forcesQSettingsto use this directory, too. See section\nSystem Settingsfor additional information.\n11\n\nQGIS Desktop 3.22 User Guide\n5.1.4Downloading sample data\nThis user guide contains examples based on the QGIS sample dataset (also called theAlaska dataset). Down-\nload the sample data fromhttps://github.com/qgis/QGIS-Sample-Data/archive/master.zipand unzip the archive on\nany convenient location on your system.\nThe Alaska dataset includes all GIS data that are used for the examples and screenshots in this user guide; it also\nincludes a small GRASS database. The projection for the QGIS sample datasets is Alaska Albers Equal Area with\nunits feet. The EPSG code is 2964.\nPROJCS[\"Albers Equal Area\",\nGEOGCS[\"NAD27\",\nDATUM[\"North_American_Datum_1927\",\nSPHEROID[\"Clarke 1866\",6378206.4,294.978698213898,\nAUTHORITY[\"EPSG\",\"7008\"]],\nTOWGS84[-3,142,183,0,0,0,0],\nAUTHORITY[\n\"EPSG\",\"6267\"]],\nPRIMEM[\"Greenwich\",0,\nAUTHORITY[\"EPSG\",\"8901\"]],\nUNIT[\"degree\",0.0174532925199433,\nAUTHORITY[\"EPSG\",\"9108\"]],\nAUTHORITY[\"EPSG\",\"4267\"]],\nPROJECTION[\"Albers_Conic_Equal_Area\"],\nPARAMETER[\"standard_parallel_1\",55],\nPARAMETER[\"standard_parallel_2\",65],\nPARAMETER[\"latitude_of_center\",50],\nPARAMETER[\"longitude_of_center\",-154],\nPARAMETER[\"false_easting\",0],\nPARAMETER[\"false_northing\",0],\nUNIT[\"us_survey_feet\",0.3048006096012192]]\nIf you intend to use QGIS as a graphical front end for GRASS, you can find a selection of sample locations (e.g.,\nSpearfish or South Dakota) at the official GRASS GIS website,\nhttps://grass.osgeo.org/download/data/.\n5.2Starting and stopping QGIS\nQGIS can be started like any other application on your computer. This means that you can launch QGIS by:\n•usingthe Applications menu,the Start menu, orthe Dock\n•double clicking the icon in your Applications folder or desktop shortcut\n•double clicking an existing QGIS project file (with.qgzor.qgsextension). Note that this will also open\nthe project.\n•typingqgisin a command prompt (assuming that QGIS is added to your PATH or you are in its installation\nfolder)\nTo stop QGIS, use:\n•the menu optionProject►Exit QGISor use the shortcutCtrl+Q\n•QGIS►Quit QGIS, or use the shortcutCmd+Q\n•or use the red cross at the top-right corner of the main interface of the application.\n12Chapter 5. Getting Started\n\nQGIS Desktop 3.22 User Guide\n5.3Sample Session: Loading raster and vector layers\nNow that you haveQGIS installedand asample datasetavailable, we will demonstrate a first sample session. In this\nexample, we will visualize a raster and a vector layer. We will use:\n•thelandcoverraster layer (qgis_sample_data/raster/landcover.img)\n•and thelakesvector layer (qgis_sample_data/gml/lakes.gml)\nWhereqgis_sample_datarepresents the path to the unzipped dataset.\n1.Start QGIS as seen inStarting and stopping QGIS.\n2.To load the files in QGIS:\n1.Click on the\nOpen Data Source Manager\nicon. The Data Source Manager should open in Browser mode.\n2.Browse to the folderqgis_sample_data/raster/\n3.Select the ERDAS IMG filelandcover.imgand double-click it. The landcover layer is added in the\nbackground while the Data Source Manager window remains open.\nFig. 5.1: Adding data to a new project in QGIS\n4.To load the lakes data, browse to the folderqgis_sample_data/gml/, and double-click the\nlakes.gmlfile to open it.\n5.ACoordinate Reference System Selectordialog opens. In theFiltermenu, type2964, filtering the list of\nCoordinate Reference Systems below.\n5.3. Sample Session: Loading raster and vector layers13\n\nQGIS Desktop 3.22 User Guide\nFig. 5.2: Select the Coordinate Reference System of data\n6.Select the\nNAD27 / Alaska Albers\nentry\n7.ClickOK\n8.Close the Data Source Manager window\nYou now have the two layers available in your project in some random colours. Let’s do some customization on the\nlakes layer.\n1.Select the\nZoom In\ntool on theNavigationtoolbar\n2.Zoom to an area with some lakes\n3.Double-click thelakeslayer in the map legend to open thePropertiesdialog\n4.To change the lakes color:\n1.Click on theSymbologytab\n2.Select blue as fill color.\n14Chapter 5. Getting Started\n\nQGIS Desktop 3.22 User Guide\nFig. 5.3: Selecting Lakes color\n3.PressOK. Lakes are now displayed in blue in the map canvas.\n5.To display the name of the lakes:\n1.Reopen thelakeslayerPropertiesdialog\n2.Click on theLabelstab\n3.SelectSingle labelsin the drop-down menu to enable labeling.\n4.From theLabel withlist, choose theNAMESfield.\n5.3. Sample Session: Loading raster and vector layers15\n\nQGIS Desktop 3.22 User Guide\nFig. 5.4: Showing Lakes names\n5.PressApply. Names will now load over the boundaries.\n6.You can improve readability of the labels by adding a white buffer around them:\n1.Click theBuffertab in the list on the left\n2.CheckDraw text buffer\n3.Choose3as buffer size\n4.ClickApply\n5.Check if the result looks good, and update the value if needed.\n6.Finally clickOKto close theLayer Propertiesdialog and apply the changes.\nLet’s now add some decorations in order to shape the map and export it out of QGIS:\n1.SelectView►Decorations►Scale Barmenu\n2.In the dialog that opens, checkEnable Scale Baroption\n3.Customize the options of the dialog as you want\n4.PressApply\n5.Likewise, from the decorations menu, add more items (north arrow, copyright...) to the map canvas with\ncustom properties.\n6.ClickProject►Import/Export►Export Map to Image...\n7.PressSavein the opened dialog\n8.Select a file location, a format and confirm by pressingSaveagain.\n16Chapter 5. Getting Started\n\nQGIS Desktop 3.22 User Guide\n9.PressProject►Save...to store your changes as a.qgzproject file.\nThat’s it! You can see how easy it is to visualize raster and vector layers in QGIS, configure them and generate your\nmap in an image format you can use in other softwares. Let’s move on to learn more about the available functionality,\nfeatures and settings, and how to use them.\nNote:To continue learning QGIS through step-by-step exercises, follow the Training manual.\n5.3. Sample Session: Loading raster and vector layers17\n\nQGIS Desktop 3.22 User Guide\n18Chapter 5. Getting Started\n\nCHAPTER\nSIX\nWORKING WITH PROJECT FILES\n6.1Introducing QGIS projects\nThe state of your QGIS session is called a project. QGIS works on one project at a time. A setting can be project-\nspecific or an application-wide default for new projects (see sectionOptions). QGIS can save the state of your\nworkspace into aQGIS project fileusing the menu optionsProject►SaveorProject►Save As....\nNote:If the project has been modified the*symbol will appear in the title bar and QGIS will, by default, ask you\nif you would like to save the changes. This behavior is controlled by thePrompt to save project and data source\nchanges when requiredsetting underSettings►Options►General.\nYou can load existing projects into QGIS from the Browser panel or by throughProject►Open...,Project►\nNew from templateorProject►Open Recent►.\nAt startup, a list ofProject TemplatesandRecent Projectsare displayed, including screenshots, names and file paths\n(for up to ten projects). TheRecent Projectslist is handy to access recently used projects. Double-click an entry to\nopen the project or project template. Right-click an entry toPin to List,Open Directory...orRemove from List. You\ncan also add a layer to create a new project automatically. The lists will then disappear, giving way to the map canvas.\nIf you want to clear your session and start fresh, go toProject►\nNew. This will prompt you to save the existing\nproject if changes have been made since it was opened or last saved.\nWhen you open a fresh project, the title bar will showUntitled Projectuntil you save it.\n19\n\nQGIS Desktop 3.22 User Guide\nFig. 6.1: Starting a new project in QGIS\nThe information saved in a project file includes:\n•Layers added\n•Which layers can be queried\n•Layer properties, including symbolization and styles\n•Layer notes\n•Projection for the map view\n•Last viewed extent\n•Print layouts\n•Print layout elements with settings\n•Print layout atlas settings\n•Digitizing settings\n•Table Relations\n•Project Macros\n•Project default styles\n•Plugins settings\n•QGIS Server settings from the OWS settings tab in the Project properties\n•Queries stored in the DB Manager\nThe project file is saved in XML format (see\nQGS/QGZ - The QGIS Project File Format). This means that it is possible\nto edit the file outside of QGIS if you know what you are doing. The project file format has been updated several\ntimes. Project files from older QGIS versions may not work properly any more.\n20Chapter 6. Working with Project Files\n\nQGIS Desktop 3.22 User Guide\nNote:By default, QGIS will warn you of version differences. This behavior is controlled in theGeneraltab of\nSettings►Options(Warn when opening a project file saved with an older version of QGIS).\nWhenever you save a\n.qgs\nproject file in QGIS, a backup of the file is created in the same directory as the project\nfile, with the extension.qgs~.\nThe extension for QGIS projects is.qgsbut when saving from QGIS, the default is to save using a compressed\nformat with the.qgzextension. The.qgsfile is embedded in the.qgzfile (a zip archive), together with its\nassociated sqlite database (.qgd) forauxiliary data. You can get to these files by unzipping the.qgzfile.\nNote:TheAuxiliary Storage Propertiesmechanism makes a zipped project particularly useful, since it embeds\nauxiliary data.\nProjects can also be saved/loaded to/from a PostgreSQL database using the following Project menu items:\n•Project►Open from\n•Project►Save to\nBoth menu items have a sub-menu with a list of extra project storage implementations (PostgreSQL and GeoPackage).\nClicking the action will open a dialog to pick a GeoPackage connection and project or a PostgreSQL connection,\nschema and project.\nProjects stored in Geopackage or PostgreSQL can also be loaded through the QGIS browser panel, either by double-\nclicking them or by dragging them to the map canvas.\n6.2Handling broken file paths\nWhen opening a project, QGIS may fail to reach some data sources due to unavailable service/database, or to a\nrenamed or moved file. QGIS then opens theHandle Unavailable Layersdialog, referencing the unfound layers. You\ncan:\n•Double-click in theDatasourcefield, adjust the path of each layer and clickApply changes;\n•Select a row, pressBrowseto indicate the correct location and clickApply changes;\n•PressAuto-Findto browse the folders and try to automatically fix all or selected broken path(s). Be aware that\nthe browsing may take some time. Then clickApply changes.\n•Ignore the message and open your project with the broken path(s) by clickingKeep Unavailable Layers. Your\nlayer is then displayed in theLayerspanel, but without any data until you fix the path using the\nUnavailable layer!\nicon next to it in theLayerspanel, orRepair Data Source...in the layer contextual menu.\nWith theRepair Data Source...tool, once a layer path has been fixed, QGIS scans through all other broken\npaths and tries to auto-fix those that have the same broken file path.\n•Remove Unavailable Layersfrom the project.\n6.2. Handling broken file paths21\n\nQGIS Desktop 3.22 User Guide\n6.3Generating output\nThere are several ways to generate output from your QGIS session. We have already discussed saving as a project file\ninIntroducing QGIS projects. Other ways to produce output files are:\n•Creating images:Project►Import/Export►Export Map to Image...outputs the map canvas rendering\nto an image format (PNG, JPG, TIFF...) at custom scale, resolution, size, ... Georeferencing the image is\npossible. SeeExporting the map viewfor more details.\n•Exporting to PDF files:Project►Import/Export►Export Map to PDF...outputs the map canvas rendering\nto PDF at custom scale, resolution, and with some advanced settings (simplification, georeferencing, ...). See\nExporting the map viewfor more details.\n•Exporting to DXF files:Project►Import/Export►Export Project to DXF...opens a dialog where you can\ndefine the ‘Symbology mode’, the ‘Symbology scale’ and vector layers you want to export to DXF. Through the\n‘Symbology mode’, symbols from the original QGIS Symbology can be exported with high fidelity (see section\nCreating new DXF files).\n•Designing maps:Project►New Print Layout...opens a dialog where you can layout and print the current\nmap canvas (see sectionLaying out the maps).\n22Chapter 6. Working with Project Files\n\nCHAPTER\nSEVEN\nQGIS GUI\nThe QGIS graphical user interface (GUI) is shown in the figure below (the numbers 1 through 5 in yellow circles\nindicate important elements of the QGIS GUI, and are discussed below).\nFig. 7.1: QGIS GUI with Alaska sample data\nNote:Your window decorations (title bar, etc.) may appear different depending on your operating system and\nwindow manager.\nThe main QGIS GUI (Fig. 7.1) consists of five components / component types:\n1.Menu Bar\n2.Toolbars\n3.Panels\n4.Map View\n5.Status Bar\nScroll down for detailed explanations of these.\n23\n\nQGIS Desktop 3.22 User Guide\n7.1Menu Bar\nThe Menu bar provides access to QGIS functions using standard hierarchical menus. The Menus, their options,\nassociated icons and keyboard shortcuts are described below. The keyboard shortcuts can be reconfigured (Settings\n►Keyboard Shortcuts).\nMost menu options have a corresponding tool and vice-versa. However, the Menus are not organized exactly like the\ntoolbars. The locations of menu options in the toolbars are indicated below in the table. Plugins may add new options\nto Menus. For more information about tools and toolbars, seeToolbars.\nNote:QGIS is a cross-platform application. Tools are generally available on all platforms, but they may be placed\nin different menus, depending on the operating systems. The lists below show the most common locations, including\nknown variations.\n7.1.1Project\nTheProjectmenu provides access and exit points forproject files. It provides tools to:\n•Create aNewproject file from scratch or use another project file as a template (seeProject files optionsfor\ntemplate configuration)\n•Open...a project from a file, a GeoPackage or a PostgreSQL database\n•Closea project or revert it to its last saved state\n•Savea project in.qgsor.qgzfile format, either as a file or within a GeoPackage or PostgreSQL database\n•Export the map canvas to different formats or use aprint layoutfor more complex output\n•Set project properties and snapping options for geometry editing.\n24Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nMenu OptionShortcutTool-\nbar\nReference\nNewCtrl+NProjectIntroducing QGIS projects\nNew from template►Introducing QGIS projects\nOpen...Ctrl+OProjectIntroducing QGIS projects\nOpen from►\n►GeoPackage...Introducing QGIS projects\n►PostgreSQL...Introducing QGIS projects\nOpen Recent►Alt+J+RIntroducing QGIS projects\nCloseIntroducing QGIS projects\nSaveCtrl+SProjectIntroducing QGIS projects\nSave As...Ctrl+Shift+SProjectIntroducing QGIS projects\nSave to►\n►Templates...Introducing QGIS projects\n►GeoPackage...Introducing QGIS projects\n►PostgreSQL...Introducing QGIS projects\nRevert...\nProperties...Ctrl+Shift+PProject Properties\nSnapping Options...Snapping and Digitizing Options\nImport/Export►\n►Export Map to Image...Exporting the map view\n►Export Map to PDF...Exporting the map view\n►Export Project to DXF...Creating new DXF files\n►Import Layers from DWG/DXF...Importing a DXF or DWG file\nNew Print Layout...Ctrl+PProjectLaying out the maps\nNew Report...Creating a Report\nLayout Manager...ProjectLaying out the maps\nLayouts►Laying out the maps\nExit QGISCtrl+Q\nUndermacOS, theExit QGIScommand corresponds toQGIS►Quit QGIS(Cmd+Q).\n7.1.2Edit\nTheEditmenu provides most of the native tools needed to edit layer attributes or geometry (seeEditingfor details).\nMenu OptionShortcutToolbarReference\nUndoCtrl+ZDigitizingUndo and Redo\nRedoCtrl+Shift+ZDigitizingUndo and Redo\nCut FeaturesCtrl+XDigitizingCutting,  Copying  and\nPasting Features\nCopy FeaturesCtrl+CDigitizingCutting,  Copying  and\nPasting Features\nPaste FeaturesCtrl+VDigitizingCutting,  Copying  and\nPasting Features\ncontinues on next page\n7.1. Menu Bar25\n\nQGIS Desktop 3.22 User Guide\nTable 7.1 – continued from previous page\nMenu OptionShortcutToolbarReference\nPaste Features as►Working  with  the  At-\ntribute Table\n►New Vector Layer...Working  with  the  At-\ntribute Table\n►Temporary Scratch Layer...Ctrl+Alt+VWorking  with  the  At-\ntribute Table\nDelete SelectedDigitizingDeleting  Selected  Fea-\ntures\nSelect►Selecting features\n►Select Feature(s)SelectionSelecting features\n►Select Features by PolygonSelectionSelecting features\n►Select Features by FreehandSelectionSelecting features\n►Select Features by RadiusSelectionSelecting features\n►Select Features by Value...F3SelectionSelecting features\n►Select Features by Expression...Ctrl+F3SelectionSelecting features\n►Deselect Features from All LayersCtrl+Alt+ASelectionSelecting features\n►Deselect Features from the Current Active\nLayer\nCtrl+Shift+ASelectionSelecting features\n►Reselect FeaturesSelecting features\n►Select All FeaturesCtrl+ASelectionSelecting features\n►Invert Feature SelectionSelectionSelecting features\nAdd RecordCtrl+.Digitizing\nAdd Point FeatureCtrl+.DigitizingAdding Features\nAdd Line FeatureCtrl+.DigitizingAdding Features\nAdd Polygon FeatureCtrl+.DigitizingAdding Features\nAdd Circular StringShape Digi-\ntizing\nAdd Circular string\nAdd Circular String by RadiusShape Digi-\ntizing\nAdd Circular string\nAdd Circle►Shape Digi-\ntizing\nDraw Circles\n►Add Circle from 2 PointsShape Digi-\ntizing\nDraw Circles\n►Add Circle from 3 PointsShape Digi-\ntizing\nDraw Circles\n►Add Circle from 3 TangentsShape Digi-\ntizing\nDraw Circles\n►Add Circle from 2 Tangents and a PointShape Digi-\ntizing\nDraw Circles\n►Add Circle by a Center Point and Another\nPoint\nShape Digi-\ntizing\nDraw Circles\ncontinues on next page\n26Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nTable 7.1 – continued from previous page\nMenu OptionShortcutToolbarReference\nAdd Rectangle►Shape Digi-\ntizing\nDraw Rectangles\n►Add Rectangle from ExtentShape Digi-\ntizing\nDraw Rectangles\n►Add Rectangle from Center and a PointShape Digi-\ntizing\nDraw Rectangles\n►Add Rectangle from 3 Points (Distance\nfrom 2nd and 3rd point)\nShape Digi-\ntizing\nDraw Rectangles\n►Add Rectangle from 3 Points (Distance\nfrom projected point on segment p1 and p2)\nShape Digi-\ntizing\nDraw Rectangles\nAdd Regular Polygon►Shape Digi-\ntizing\nDraw Regular Polygons\n►Add Regular Polygon from Center and a\nPoint\nShape Digi-\ntizing\nDraw Regular Polygons\n►Add Regular Polygon from Center and a\nCorner\nShape Digi-\ntizing\nDraw Regular Polygons\n►Add Regular Polygon from 2 PointsShape Digi-\ntizing\nDraw Regular Polygons\nAdd Ellipse►Shape Digi-\ntizing\nDraw Ellipses\n►Add Ellipse from Center and 2 PointsShape Digi-\ntizing\nDraw Ellipses\n►Add Ellipse from Center and a PointShape Digi-\ntizing\nDraw Ellipses\n►Add Ellipse from ExtentShape Digi-\ntizing\nDraw Ellipses\n►Add Ellipse from FociShape Digi-\ntizing\nDraw Ellipses\nAdd Annotation►Annotation Tools\n►Text AnnotationAnnotationsAnnotation Tools\n►Form AnnotationAnnotationsAnnotation Tools\n►HTML AnnotationAnnotationsAnnotation Tools\n►SVG AnnotationAnnotationsAnnotation Tools\nEdit Attributes►\n►Modify Attributes of Selected FeaturesDigitizingEditing attribute values\n►Merge Attributes of Selected FeaturesAdvanced\nDigitizing\nMerge attributes of se-\nlected features\nEdit Geometry►\n►Move Feature(s)Advanced\nDigitizing\nMove Feature(s)\n►Copy and Move Feature(s)Advanced\nDigitizing\nMove Feature(s)\ncontinues on next page\n7.1. Menu Bar27\n\nQGIS Desktop 3.22 User Guide\nTable 7.1 – continued from previous page\nMenu OptionShortcutToolbarReference\n►Rotate Feature(s)Advanced\nDigitizing\nRotate Feature(s)\n►Scale Feature(s)Advanced\nDigitizing\nScale Feature\n►Simplify FeatureAdvanced\nDigitizing\nSimplify Feature\n►Add RingAdvanced\nDigitizing\nAdd Ring\n►Add PartAdvanced\nDigitizing\nAdd Part\n►Fill RingAdvanced\nDigitizing\nFill Ring\n►Delete RingAdvanced\nDigitizing\nDelete Ring\n►Delete PartAdvanced\nDigitizing\nDelete Part\n►Reshape FeaturesAdvanced\nDigitizing\nReshape Features\n►Offset CurveAdvanced\nDigitizing\nOffset Curves\n►Split FeaturesAdvanced\nDigitizing\nSplit Features\n►Split PartsAdvanced\nDigitizing\nSplit parts\n►Merge Selected FeaturesAdvanced\nDigitizing\nMerge selected features\n►Vertex Tool (All Layers)DigitizingVertex tool\n►Vertex Tool (Current Layer)DigitizingVertex tool\n►Reverse LineAdvanced\nDigitizing\nReverse Line\n►Trim/extend FeatureAdvanced\nDigitizing\nTrim/Extend Feature\nRotate Point SymbolsAdvanced\nDigitizing\nRotate Point Symbols\nOffset Point SymbolsAdvanced\nDigitizing\nOffset Point Symbols\nTools that depend on the selected layer geometry type i.e. point, polyline or polygon, are activated accordingly:\nMenu OptionPointPolylinePolygon\nMove Feature(s)\nCopy and Move Feature(s)\n28Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\n7.1.3View\nThe map is rendered in map views. You can interact with these views using theViewtools (seeWorking with the map\ncanvasfor more information). For example, you can:\n•Create new 2D or 3D map views next to the main map canvas\n•Zoom or panto any place\n•Query displayed features’ attributes or geometry\n•Enhance the map view with preview modes, annotations or decorations\n•Access any panel or toolbar\nThe menu also allows you to reorganize the QGIS interface itself using actions like:\n•Toggle Full Screen Mode: covers the whole screen while hiding the title bar\n•Toggle Panel Visibility: shows or hides enabledpanels- useful when digitizing features (for maximum canvas\nvisibility) as well as for (projected/recorded) presentations using QGIS’ main canvas\n•Toggle Map Only: hides panels, toolbars, menus and status bar and only shows the map canvas. Combined with\nthe full screen option, it makes your screen display only the map\nMenu OptionShortcutToolbarReference\nNew Map ViewCtrl+MMap View\nNew 3D Map ViewCtrl+Alt+M3D Map View\nPan MapMap Navi-\ngation\nZooming and Panning\nPan Map to SelectionMap Navi-\ngation\nZoom InCtrl+Alt++Map Navi-\ngation\nZooming and Panning\nZoom OutCtrl+Alt+-Map Navi-\ngation\nZooming and Panning\nIdentify FeaturesCtrl+Shift+IAttributesIdentifying Features\nMeasure►AttributesMeasuring\n►Measure LineCtrl+Shift+MAttributesMeasuring\n►Measure AreaCtrl+Shift+JAttributesMeasuring\n►Measure AngleAttributesMeasuring\nStatistical SummaryAttributesStatisticalSummary\nPanel\nZoom FullCtrl+Shift+FMap Navi-\ngation\nZooming and Panning\nZoom To SelectionCtrl+JMap Navi-\ngation\nZooming and Panning\nZoom To Layer(s)Map Navi-\ngation\nZooming and Panning\nZoom To Native Resolution (100%)Map Navi-\ngation\nZooming and Panning\ncontinues on next page\n7.1. Menu Bar29\n\nQGIS Desktop 3.22 User Guide\nTable 7.2 – continued from previous page\nMenu OptionShortcutToolbarReference\nZoom LastMap Navi-\ngation\nZooming and Panning\nZoom NextMap Navi-\ngation\nZooming and Panning\nDecorations►Alt+V+DDecorations\n►Grid...Grid\n►Scale Bar...Scale Bar\n►Image...Image Decoration\n►North Arrow...North Arrow\n►Title Label...Title Label\n►Copyright Label...Copyright Label\n►Layout Extents...Layout Extents\nPreview mode►\n►Normal\n►Simulate Monochrome\n►Simulate Achromatopsia Color Blindness\n(Grayscale)\n►Simulate Protanopia Color Blindness (No\nRed)\n►Simulate Deuteranopia Color Blindness (No\nGreen)\n►Simulate Tritanopia Color Blindness (No\nBlue)\nShow Map TipsAttributesDisplay Properties\nNew Spatial Bookmark...Ctrl+BMap Navi-\ngation\nSpatial Bookmarks\nShow Spatial BookmarksCtrl+Shift+BMap Navi-\ngation\nSpatial Bookmarks\nShow Spatial Bookmark ManagerSpatial Bookmarks\nRefreshF5Map Navi-\ngation\nLayer Visibility►Layers Panel\n►Show All LayersCtrl+Shift+ULayers Panel\n►Hide All LayersCtrl+Shift+HLayers Panel\n►Show Selected LayersLayers Panel\n►Hide Selected LayersLayers Panel\n►Toggle Selected LayersLayers Panel\n►Toggle Selected Layers IndependentlyLayers Panel\n►Hide Deselected LayersLayers Panel\nPanels►Panels and Toolbars\n►Advanced DigitizingThe Advanced Digitizing\npanel\n►BrowserThe Browser Panel\ncontinues on next page\n30Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nTable 7.2 – continued from previous page\nMenu OptionShortcutToolbarReference\n►Browser (2)The Browser Panel\n►Debugging/Development ToolsF12Debugging/Development\nTools Panel\n►Geometry ValidationDigitizing Properties\n►GPS InformationLive GPS tracking\n►GRASS ToolsGRASS GIS Integration\n►Layer OrderLayer Order Panel\n►Layer StylingLayer Styling Panel\n►LayersLayers Panel\n►Log MessagesLog Messages Panel\n►OverviewOverview Panel\n►Processing ToolboxThe Toolbox\n►Results ViewerThe Toolbox\n►Snapping and Digitizing OptionsSetting the snapping tol-\nerance and search radius\n►Spatial Bookmark ManagerSpatial Bookmarks\n►StatisticsStatisticalSummary\nPanel\n►Temporal ControllerThe temporal controller\npanel\n►Tile ScaleTilesets\n►Undo/RedoUndo/Redo Panel\nToolbars►Panels and Toolbars\n►Advanced Digitizing ToolbarAdvanced digitizing\n►Annotations Toolbar\n►Attributes Toolbar\n►Data Source Manager ToolbarManaging Data Source\n►Database Toolbar\n►Digitizing ToolbarDigitizing  an  existing\nlayer\n►Help Toolbar\n►Label ToolbarThe Label Toolbar\n►Manage Layers ToolbarManaging Data Source\n►Map Navigation Toolbar\n►Mesh Digitizing Toolbar\n►Plugins ToolbarPlugins\n►Project Toolbar\n►Raster Toolbar\n►Selection ToolbarSelecting features\n►Shape Digitizing ToolbarShape digitizing\n►Snapping ToolbarSetting the snapping tol-\nerance and search radius\n►Vector Toolbar\n►Web Toolbar\n►GRASSGRASS GIS Integration\nToggle Full Screen ModeF11\nToggle Panel VisibilityCtrl+Tab\nToggle Map OnlyCtrl+Shift+Tab\nUnderLinux KDE,Panels►,Toolbars► andToggle Full Screen Modeare in theSettingsmenu.\n7.1. Menu Bar31\n\nQGIS Desktop 3.22 User Guide\n7.1.4Layer\nTheLayermenu provides a large set of tools tocreatenew data sources,addthem to a project orsave modifications\nto them. Using the same data sources, you can also:\n•Duplicatea layer to generate a copy where you can modify the name, style (symbology, labels, ...), joins, ...\nThe copy uses the same data source as the original.\n•CopyandPastelayers or groups from one project to another as a new instance whose properties can be modified\nindependently. As forDuplicate, the layers are still based on the same data source.\n•orEmbed Layers and Groups...from another project, as read-only copies which you cannot modify (seeEm-\nbedding layers from external projects)\nTheLayermenu also contains tools to configure, copy or paste layer properties (style, scale, CRS...).\nMenu OptionShortcutToolbarReference\nData Source ManagerCtrl+LDataSource\nManager\nOpening Data\nCreate Layer►Creating new vector layers\n►New GeoPackage Layer...Ctrl+Shift+NDataSource\nManager\nCreating a new GeoPackage\nlayer\n►New Shapefile Layer...DataSource\nManager\nCreating  a  new  Shapefile\nlayer\n►New SpatiaLite Layer...DataSource\nManager\nCreating a new SpatiaLite\nlayer\n►New Temporary Scratch Layer...DataSource\nManager\nCreating a new Temporary\nScratch Layer\n►New Mesh Layer...DataSource\nManager\nCreating a new Mesh layer\n►New GPX Layer...DataSource\nManager\nCreating a new GPX layer\n►New Virtual Layer...DataSource\nManager\nCreating virtual layers\nAdd Layer►Opening Data\n►Add Vector Layer......Ctrl+Shift+VManage LayersLoading a layer from a file\n►Add Raster Layer...Ctrl+Shift+RManage LayersLoading a layer from a file\n►Add Mesh Layer...Manage LayersLoading a mesh layer\n►Add Delimited Text Layer...Ctrl+Shift+TManage LayersImporting a delimited text\nfile\n►Add PostGIS Layer...Ctrl+Shift+DManage LayersDatabase related tools\n►Add SpatiaLite Layer...Ctrl+Shift+LManage LayersSpatiaLite Layers\n►Add MSSQL Spatial Layer...Manage LayersDatabase related tools\n►Add Oracle Spatial Layer...Manage LayersDatabase related tools\n►Add/Edit Virtual Layer...Manage LayersCreating virtual layers\n►Add WMS/WMTS Layer...Ctrl+Shift+WManage LayersLoading WMS/WMTS Lay-\ners\ncontinues on next page\n32Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nTable 7.3 – continued from previous page\nMenu OptionShortcutToolbarReference\n►Add XYZ Layer...Using XYZ Tile services\n►Add  ArcGIS  REST  Service\nLayer...\nManage Layers\n►Add WCS Layer...Manage LayersWCS Client\n►Add WFS Layer...Manage LayersWFS and WFS-T Client\n►Add Vector Tile Layer...Using Vector Tiles services\nEmbed Layers and Groups...Embedding layers from ex-\nternal projects\nAdd from Layer Definition File...Layer definition file\nCopy StyleSave and Share Layer Prop-\nerties\nPaste StyleSave and Share Layer Prop-\nerties\nCopy Layer\nPaste Layer/Group\nOpen Attribute TableF6AttributesWorking with the Attribute\nTable\nFilter Attribute Table►Working with the Attribute\nTable\n►Open Attribute Table (Selected\nFeatures)\nShift+F6AttributesWorking with the Attribute\nTable\n►Open Attribute Table (Visible\nFeatures)\nCtrl+F6AttributesWorking with the Attribute\nTable\n►Open Attribute Table (Edited and\nNew Features)\nAttributesWorking with the Attribute\nTable\nToggle EditingDigitizingDigitizing an existing layer\nSave Layer EditsDigitizingSaving Edited Layers\nCurrent Edits►DigitizingSaving Edited Layers\n►Save for Selected Layer(s)DigitizingSaving Edited Layers\n►Rollback for Selected Layer(s)DigitizingSaving Edited Layers\n►Cancel for Selected Layer(s)DigitizingSaving Edited Layers\n►Save for all LayersDigitizingSaving Edited Layers\n►Rollback for all LayersDigitizingSaving Edited Layers\n►Cancel for all LayersDigitizingSaving Edited Layers\nSave As...Creating new layers from an\nexisting layer\nSave As Layer Definition File...Layer definition file\nRemove Layer/GroupCtrl+D\nDuplicate Layer(s)\nSet Scale Visibility of Layer(s)\nSet CRS of Layer(s)Ctrl+Shift+CLayer Coordinate Reference\nSystems\nSet Project CRS from LayerProject  Coordinate  Refer-\nence Systems\ncontinues on next page\n7.1. Menu Bar33\n\nQGIS Desktop 3.22 User Guide\nTable 7.3 – continued from previous page\nMenu OptionShortcutToolbarReference\nLayer Properties...The Vector Properties Dia-\nlog,Raster Properties Dia-\nlog,Mesh Dataset Properties\nFilter...Ctrl+FQuery Builder\nLabelingLabels Properties\nShow in OverviewOverview Panel\nShow All in OverviewOverview Panel\nHide All from OverviewOverview Panel\n7.1.5Settings\nMenu OptionReference\nUser Profiles►Working with User Profiles\n►defaultWorking with User Profiles\n►Open Active Profile FolderWorking with User Profiles\n►New Profile...Working with User Profiles\nStyle Manager...The Style Manager\nCustom Projections...Custom Coordinate Reference System\nKeyboard Shortcuts...Keyboard shortcuts\nInterface Customization...Customization\nOptions...Options\nUnderLinux KDE, you’ll find more tools in the\nSettings\nmenu such as\nPanels\n►,\nToolbars\n► and\nToggle Full\nScreen Mode.\n7.1.6Plugins\nMenu OptionShortcutToolbarReference\nManage and Install Plugins...The Plugins Dialog\n“Python ConsoleCtrl+Alt+PPluginsQGIS Python console\nWhen starting QGIS for the first time not all core plugins are loaded.\n7.1.7Vector\nThis is what theVectormenu looks like if all core plugins are enabled.\nMenu OptionShortcutTool-\nbar\nReference\nCheck Geometries...Geometry Checker Plugin\nGPS ToolsAlt+O+GVectorGPS Plugin\nTopology CheckerVectorTopology Checker Plugin\ncontinues on next page\n34Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nTable 7.4 – continued from previous page\nMenu OptionShortcutTool-\nbar\nReference\nGeoprocessing Tools►Alt+O+G\n►Buffer...Buffer\n►Clip...Clip\n►Convex Hull...Convex hull\n►Difference...Difference\n►Dissolve...Dissolve\n►Intersection...Intersection\n►Symmetrical Difference...Symmetrical difference\n►Union...Union\n►Eliminate Selected Polygons...Eliminate selected polygons\nGeometry Tools►Alt+O+E\n►Centroids...Centroids\n►Collect Geometries...Collect geometries\n►Extract Vertices...Extract vertices\n►Multipart to Singleparts...Multipart to singleparts\n►Polygons to Lines...Polygons to lines\n►Simplify...Simplify\n►Check Validity...Check validity\n►Delaunay Triangulation...Delaunay triangulation\n►Densify by Count...Densify by count\n►Add Geometry Attributes...Add geometry attributes\n►Lines to Polygons...Lines to polygons\n►Voronoi Polygons...Voronoi polygons\nAnalysis Tools►Alt+O+A\n►Line Intersection...Line intersections\n►Mean Coordinate(s)...Mean coordinate(s)\n►Basic Statistics for Fields...Basic statistics for fields\n►Count Points in Polygon...Count points in polygon\n►Distance Matrix...Distance matrix\n►List Unique Values...List unique values\n►Nearest Neighbour Analysis...Nearest neighbour analysis\n►Sum Line Lengths...Sum line lengths\nData Management Tools►Alt+O+D\n►Merge Vector Layers...Merge vector layers\n►Reproject Layer...Reproject layer\n►Create Spatial Index...Create spatial index\n►Join Attributes by Location...Join attributes by location\n►Split Vector Layer...Split vector layer\nResearch Tools►Alt+O+R\n►Select by Location...Select by location\n►Extract Layer Extent...Extract layer extent\n►Random Points in Extent...Random points in extent\n►Random Points in Layer Bounds...Random points in layer bounds\n►Random Points Inside Polygons...Random points inside polygons\n►Random Selection...Random selection\n►Random Selection Within Subsets...Random selection within subsets\n►Regular Points...Regular points\nBy default, QGIS addsProcessingalgorithms to theVectormenu, grouped by sub-menus. This provides shortcuts for\nmany common vector-based GIS tasks from different providers. If not all these sub-menus are available, enable the\nProcessing plugin inPlugins►Manage and Install Plugins....\nNote that the list of algorithms and their menu can be modified/extended with any Processing algorithms (read\nCon-\nfiguring the Processing Framework) or some externalplugins.\n7.1. Menu Bar35\n\nQGIS Desktop 3.22 User Guide\n7.1.8Raster\nThis is what theRastermenu looks like if all core plugins are enabled.\nMenu OptionShortcutTool-\nbar\nReference\nRaster calculator...Raster Calculator\nAlign Raster...Raster Alignment\nGeoreferencerAlt+R+GRasterGeoreferencer\nAnalysis►\n►Aspect...Aspect\n►Fill nodata...Fill nodata\n►Grid (Moving Average)...Grid (Moving average)\n►Grid (Data Metrics)...Grid (Data metrics)\n►Grid (Inverse Distance to a Power)...Grid (Inverse distance to a power)\n►Grid (Nearest Neighbor)...Grid (IDW with nearest neighbor search-\ning)\n►Hillshade...Hillshade\n►Proximity (Raster Distance)...Proximity (raster distance)\n►Roughness...Roughness\n►Sieve...Sieve\n►Slope...Slope\n►Topographic Position Index (TPI)...Topographic Position Index (TPI)\n►Terrain Ruggedness Index (TRI)...Terrain Ruggedness Index (TRI)\nProjections►\n►Assign Projection...Assign projection\n►Extract Projection...Extract projection\n►Warp (Reproject)...Warp (reproject)\nMiscellaneous►\n►Build Virtual Raster...Build virtual raster\n►Raster Information...Raster information\n►Merge...Merge\n►Build Overviews (Pyramids)...Build overviews (pyramids)\n►Tile Index...Tile index\nExtraction►\n►Clip Raster by Extent...Clip raster by extent\n►Clip Raster by Mask Layer...Clip raster by mask layer\n►\nContour...\nContour\nConversion►\n►PCT to RGB...PCT to RGB\n►\nPolygonize (Raster to Vector)...\nPolygonize (raster to vector)\n►Rasterize (Vector to Raster)...Rasterize (vector to raster)\n►RGB to PCT...RGB to PCT\n►\nTranslate (Convert Format)...\nTranslate (convert format)\nBy default, QGIS addsProcessingalgorithms to theRastermenu, grouped by sub-menus. This provides a shortcut\nfor many common raster-based GIS tasks from different providers. If not all these sub-menus are available, enable\nthe Processing plugin inPlugins►Manage and Install Plugins....\nNote that the list of algorithms and their menu can be modified/extended with any Processing algorithms (readCon-\nfiguring the Processing Framework\n) or some externalplugins.\n36Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\n7.1.9Database\nThis is what theDatabasemenu looks like if all the core plugins are enabled. If no database plugins are enabled,\nthere will be noDatabasemenu.\nMenu OptionShortcutToolbarReference\nOffline editing...Alt+D+OOffline Editing Plugin\n►Convert to Offline Project...DatabaseOffline Editing Plugin\n►SynchronizeDatabaseOffline Editing Plugin\nDB Manager...DatabaseDB Manager Plugin\nWhen starting QGIS for the first time not all core plugins are loaded.\n7.1.10Web\nThis is what theWebmenu looks like if all the core plugins are enabled. If no web plugins are enabled, there will be\nnoWebmenu.\nMenu OptionShortcutToolbarReference\nMetaSearch►Alt+W+MMetaSearch Catalog Client\n►MetasearchWebMetaSearch Catalog Client\n►HelpMetaSearch Catalog Client\nWhen starting QGIS for the first time not all core plugins are loaded.\n7.1.11Mesh\nTheMeshmenu provides tools needed to manipulatemesh layers.\nMenu OptionShortcutToolbarReference\nMesh Calculator...Mesh Calculator\nReindex Faces and VerticesReindexing meshes\n7.1.12Processing\nMenu OptionShortcutTool-\nbar\nReference\nToolboxCtrl+Alt+TThe Toolbox\nGraphical Modeler...Ctrl+Alt+GThe graphical modeler\nHistory...Ctrl+Alt+HThe history manager\nResults ViewerCtrl+Alt+RConfiguring external applications\nEdit Features In-PlaceThe Processing in-place layer modifier\nWhen starting QGIS for the first time not all core plugins are loaded.\n7.1. Menu Bar37\n\nQGIS Desktop 3.22 User Guide\n7.1.13Help\nMenu OptionShortcutToolbarReference\nHelp ContentsF1Help\nAPI Documentation\nPlugins►\nReport an Issue\nNeed commercial support?\nQGIS Home PageCtrl+H\nCheck QGIS Version\nAbout\nQGIS Sustaining Members\n7.1.14QGIS\nThis menu is only available undermacOS and contains some OS related commands.\nMenu OptionShortcut\nPreferences\nAbout QGIS\nHide QGIS\nShow All\nHide Others\nQuit QGISCmd+Q\nPreferences\ncorrespond to\nSettings\n►\nOptions\n,\nAbout QGIS\ncorresponds to\nHelp\n►\nAbout\nand\nQuit QGIS\ncorresponds\ntoProject►Exit QGISfor other platforms.\n7.2Panels and Toolbars\nFrom theViewmenu (orSettings), you can switch QGIS widgets (Panels►) and toolbars (Toolbars►) on and\noff. To (de)activate any of them, right-click the menu bar or toolbar and choose the item you want. Panels and\ntoolbars can be moved and placed wherever you like within the QGIS interface. The list can also be extended with\nthe activation of\nCore or external plugins.\n7.2.1Toolbars\nThe toolbars provide access to most of the functions in the menus, plus additional tools for interacting with the map.\nEach toolbar item has pop-up help available. Hover your mouse over the item and a short description of the tool’s\npurpose will be displayed.\nEvery toolbar can be moved around according to your needs. Additionally, they can be switched off using the right\nmouse button context menu, or by holding the mouse over the toolbars.\nAvailable toolbars are:\n38Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nNameMain Reference for tools\nAdvanced Digitizing ToolbarAdvanced digitizing\nAnnotations Toolbar\nAttributesWorking with the Attribute Table,General Tools\nData Source ManagerManaging Data Source\nDatabaseDB Manager Plugin\nDigitizingDigitizing an existing layer\nHelp\nLabelThe Label Toolbar\nManage LayersOpening Data\nMap NavigationWorking with the map canvas\nMesh Digitizing Toolbar\nPluginsPlugins\nProjectWorking with Project Files,Laying out the maps,The Style Library\nProcessing AlgorithmsConfiguring the Processing Framework\nRasterPlugins\nSelectionSelecting features\nShape digitizingShape digitizing\nSnappingSetting the snapping tolerance and search radius\nVectorPlugins\nWebPlugins,MetaSearch Catalog Client\nNote:Third-party plugins can extend the default toolbar with their own tools or provide their own toolbar.\nTip: Restoring toolbars\nIf you have accidentally hidden a toolbar, you can get it back usingView►Toolbars► (orSettings►Toolbars\n►). If, for some reason, a toolbar (or any other widget) totally disappears from the interface, you’ll find tips to get it\nback atrestoring initial GUI.\n7.2.2Panels\nQGIS provides many panels. Panels are special widgets that you can interact with (selecting options, checking boxes,\nfilling values...) to perform more complex tasks.\nBelow is a list of the default panels provided by QGIS:\n•theAdvanced Digitizing Panel\n•theBrowser Panel\n•theDebugging/Development Tools\n•theGeometry Validation Panel\n•theGPS Information Panel\n•theIdentify Panel\n•theLayer Order Panel\n•theLayer Styling Panel\n•theLayers Panel\n•theLog Messages Panel\n•theOverview Panel\n7.2. Panels and Toolbars39\n\nQGIS Desktop 3.22 User Guide\n•theProcessing Toolbox\n•theResult Viewer Panel\n•theSpatial Bookmark Manager Panel\n•theStatistics Panel\n•theTemporal Controller\n•theTile Scale Panel\n•theUndo/Redo Panel\n7.3Map View\n7.3.1Exploring the map view\nThe map view (also calledMap canvas) is the “business end” of QGIS — maps are displayed in this area, in 2D.\nThe map displayed in this window will reflect the rendering (symbology, labeling, visibilities...) you applied to the\nlayers you have loaded. It also depends on the layers and the project’s Coordinate Reference System (CRS).\nWhen you add a layer (see e.g.Opening Data), QGIS automatically looks for its CRS. If a different CRS is set by\ndefault for the project (see\nProject Coordinate Reference Systems) then the layer extent is “on-the-fly” translated to that\nCRS, and the map view is zoomed to that extent if you start with a blank QGIS project. If there are already layers in\nthe project, no map canvas resize is performed, so only features falling within the current map canvas extent will be\nvisible.\nClick on the map view and you should be able to interact with it:\n•it can be panned, shifting the display to another region of the map: this is performed using the\nPan Map\ntool,\nthe arrow keys, moving the mouse while any of theSpacekey, the middle mouse button or the mouse wheel\nis held down. When the mouse is used, the distance and direction of the pan action are shown in the status bar\nat the bottom.\n•it can be zoomed in and out, with the dedicated\nZoom In\nand\nZoom Out\ntools. Hold theAltkey to switch\nfrom one tool to the other. Zooming is also performed by rolling the wheel forward to zoom in and backwards\nto zoom out. The zoom is centered on the mouse cursor position. You can customize theZoom factorunder\ntheSettings►Options►Map toolsmenu.\n•it can be zoomed to the full extent of all loaded layers (\nZoom Full\n), to the extent of all the selected layers\nin theLayerspanel (\nZoom to Layer(s)\n) or to the extent of the selected features of all the selected layers in the\nLayerspanel (\nZoom to Selection\n)\n•you can navigate back/forward through the canvas view history with the\nZoom Last\nand\nZoom Next\nbuttons\nor using the back/forward mouse buttons.\nRight-click over the map and you should be able to\nCopy coordinatesof the clicked point in the map CRS, in\nWGS84 or in a custom CRS. The copied information can then be pasted in an expression, a script, text editor or\nspreadsheet...\nBy default, QGIS opens a single map view (called “main map”), which is tightly bound to theLayerspanel; the main\nmapautomaticallyreflects the changes you do in theLayerspanel area. But it is also possible to open additional map\nviews whose content could diverge from theLayerspanel current state. They can be of 2D or\n3Dtype, show different\nscale or extent, or display a different set of the loaded layers thanks tomap themes.\n40Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\n7.3.2Setting additional map views\nTo add a new map view, go toView►New Map View. A new floating widget, mimicking the main map view’s\nrendering, is added to QGIS. You can add as many map views as you need. They can be kept floating, placed side by\nside or stacked on top of each other.\nFig. 7.2: Multiple map views with different settings\nAt the top of an additional map canvas, there’s a toolbar with the following capabilities:\n•\nZoom Full\n,\nZoom to Selection\nand\nZoom to Layer(s)\nto navigate within the view\n•\nSet View Theme\nto select themap themeto display in the map view. If set to(none), the view will follow\ntheLayerspanel changes.\n•\nView settings\nto configure the map view:\n–Synchronize view center with main map: syncs the center of the map views without changing the\nscale. This allows you to have an overview style or magnified map which follows the main canvas center.\n–Synchronize view to selection: same as zoom to selection\n–Scale\n–Rotation\n–Magnification\n–Synchronize scalewith the main map scale. AScale factorcan then be applied, allowing you to have\na view which is e.g. always 2x the scale of the main canvas.\n–Show annotations\n–Show cursor position\n–Show main canvas extent\n7.3. Map View41\n\nQGIS Desktop 3.22 User Guide\n–Show labels: allows to hide labels regardless they are set in the displayed layers’ properties\n–Change map CRS...\n–Rename view...\n7.3.3Time-based control on the map canvas\nQGIS can handle temporal control on loaded layers, i.e. modify the map canvas rendering based on a time variation.\nTo achieve this, you need:\n1.Layers that have dynamic temporal properties set. QGIS supports temporal control for different data providers,\nwith custom settings. It’s mainly about setting the time range in which the layer would display:\n•raster layers: controls whether to display or not the layer.\n•vector layers: features are filtered based on time values associated to their attributes\n•mesh layers: displays dynamically the active dataset groups values\nWhen dynamic temporal options are enabled for a layer, anicon is displayed next to the layer in theLayers\npanel to remind you that the layer is temporally controlled. Click the icon to update the temporal settings.\n2.Enable the temporal navigation of the map canvas using theTemporal controller panel. The panel is activated:\n•using the\nTemporal controller panel\nicon located in theMap Navigationtoolbar\n•or from theView►Panels►Temporal controller panelmenu\nThe temporal controller panel\nTheTemporal controllerpanel has the following modes:\nFig. 7.3: Temporal Controller Panel in navigation mode\n•\nTurn off temporal navigation\n: all the temporal settings are disabled and visible layers are rendered as usual\n•\nFixed range temporal navigation\n: a time range is set and only layers (or features) whose temporal range overlaps\nwith this range are displayed on the map.\n•\nAnimated temporal navigation\n: a time range is set, split into steps, and only layers (or features) whose temporal\nrange overlaps with each frame are displayed on the map\n•\nSettings\nfor general control of the animation\n–Frames rate: number of steps that are shown per second\n–Cumulative range: all animation frames will have the same start date-time but different end dates and\ntimes. This is useful if you wish to accumulate data in your temporal visualisation instead of showing a\n‘moving time window’ across your data.\n42Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nAnimating a temporal navigation\nAn animation is based on a varying set of visible layers at particular times within a time range. To create a temporal\nanimation:\n1.Toggle on the\nAnimated temporal navigation\n, displaying the animation player widget\n2.Enter theTime rangeto consider. Using thebutton, this can be defined as:\n•Set to full rangeof all the time enabled layers\n•Set to preset project rangeas defined in theproject properties\n•Set to single layer’s rangetaken from a time-enabled layer\n3.Fill in the timeStepto split the time range. Different units are supported, fromsecondstocenturies. A\nsource timestampsoption is also available as step: when selected, this causes the temporal navigation to\nstep between all available time ranges from layers in the project. It’s useful when a project contains layers with\nnon-contiguous available times, such as a WMS-T service which provides images that are available at irregular\ndates. This option will allow you to only step between time ranges where the next available image is shown.\n4.Click thebutton to preview the animation. QGIS will generate scenes using the layers rendering at the set\ntimes. Layers display depends on whether they overlap any individual time frame.\nThe animation can also be previewed by moving the time slider. Keeping the\nLoop\nbutton pressed will\nrepeatedly run the animation while clickingstops a running animation. A full set of video player buttons\nis available.\nHorizontal scrolling using the mouse wheel (where supported) with the cursor on the map canvas will also allow\nyou to navigate, or “scrub”, the temporal navigation slider backwards and forwards.\n5.Click the\nExport animation\nbutton if you want to generate a series of images representing the scene. They can\nbe later combined in a video editor software:\n7.3. Map View43\n\nQGIS Desktop 3.22 User Guide\nFig. 7.4: Exporting map canvas animation scenes to images\n•The filenameTemplate: the####are replaced with frame sequence number\n•TheOutput directory\n•UnderMap settings, you can:\n–redefine thespatial extentto use\n–control theResolutionof the image (Output widthandOutput height)\n–Draw active decorations: whether activedecorationsshould be kept in the output\n•UnderTemporal settings, you can redefine:\n–the timeRangefor the animation\n–theStep (frame length)in the unit of your choice\n7.3.4Exporting the map view\nMaps you make can be layout and exported to various formats using the advanced capabilities of theprint layout or\nreport. It’s also possible to directly export the current rendering, without a layout. This quick “screenshot” of the map\nview has some convenient features.\nTo export the map canvas with the current rendering:\n1.Go toProject►Import/Export\n2.Depending on your output format, select either\n•Export Map to Image...\n•orExport Map to PDF...\n44Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nThe two tools provide you with a common set of options. In the dialog that opens:\nFig. 7.5: The Save Map as Image dialog\n1.Choose theExtentto export: it can be the current view extent (the default), the extent of a layer or a custom\nextent drawn over the map canvas. Coordinates of the selected area are displayed and manually editable.\n2.Enter theScaleof the map or select it from thepredefined scales: changing the scale will resize the extent to\nexport (from the center).\n3.Set theResolutionof the output\n4.Control theOutput widthandOutput heightin pixels of the image: based by default on the current resolution\nand extent, they can be customized and will resize the map extent (from the center). The size ratio can be\nlocked, which may be particularly convenient when drawing the extent on the canvas.\n5.Draw active decorations: in usedecorations(scale bar, title, grid, north arrow...) are exported with the\nmap\n6.Draw annotationsto export anyannotation\n7.Append georeference information (embedded or via world file): depending on the output format, a world\nfile of the same name (with extensionPNGWforPNGimages,JPGWforJPG, ...) is saved in the same folder\nas your image. ThePDFformat embeds the information in the PDF file.\n8.When exporting to PDF, more options are available in theSave map as PDF...dialog:\n7.3. Map View45\n\nQGIS Desktop 3.22 User Guide\nFig. 7.6: The Save Map as PDF dialog\n•Export RDF metadataof the document such as the title, author, date, description...\n•Create Geospatial PDF (GeoPDF): Generate ageoreferenced PDF file(requires GDAL version 3 or\nlater). You can:\n–Choose the GeoPDFFormat\n–Include vector feature informationin the GeoPDF file: will include all the geometry and attribute\ninformation from features visible within the map in the output GeoPDF file.\nNote:Since QGIS 3.10, with GDAL 3 a GeoPDF file can also be used as a data source. For more on\nGeoPDF support in QGIS, seehttps://north-road.com/2019/09/03/qgis-3-10-loves-geopdf/.\n•Rasterize map\n•Simplify geometries to reduce output file size: Geometries will be simplified while exporting the map by\nremoving vertices that are not discernably different at the export resolution (e.g. if the export resolution\nis300 dpi, vertices that are less than1/600 inchapart will be removed). This can reduce the size\nand complexity of the export file (very large files can fail to load in other applications).\n•Set theText export: controls whether text labels are exported as proper text objects (Always export texts\nas text objects) or as paths only (Always export texts as paths). If they are exported as text objects then\nthey can be edited in external applications (e.g. Inkscape) as normal text. BUT the side effect is that\n46Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nthe rendering quality is decreased, AND there are issues with rendering when certain text settings like\nbuffers are in place. That’s why exporting as paths is recommended.\n9.ClickSaveto select file location, name and format.\nWhen exporting to image, it’s also possible toCopy to clipboardthe expected result of the above settings and\npaste the map in another application such as LibreOffice, GIMP...\n7.43D Map View\n3D visualization support is offered through the 3D map view. You create and open a 3D map view viaView►\nNew 3D Map View. A floating QGIS panel will appear. The panel can be docked.\nTo begin with, the 3D map view has the same extent and view as the 2D main map canvas. A set of navigation tools\nare available to turn the view into 3D.\nFig. 7.7: The 3D Map View dialog\nThe following tools are provided at the top of the 3D map view panel:\n•\nCamera control\n: moves the view, keeping the same angle and direction of the camera\n•\nZoom Full\n: resizes the view to the whole layers’ extent\n•\nToggle on-screen notification\n: shows/hides the navigation widget (that is meant to ease controlling of the map view)\n•\nIdentify\n: returns information on the clicked point of the terrain or the clicked 3D feature(s) – More details\natIdentifying Features\n7.4. 3D Map View47\n\nQGIS Desktop 3.22 User Guide\n•\nMeasurement line\n: measures the horizontal distance between points\n•\nAnimations\n: shows/hides theanimation playerwidget\n•\nSave as image...\n: exports the current view to an image file format\n•\nExport 3D Scene...\n: exports the current view as a 3D scene (.objfile), allowing post-processing in applications\nlike Blender... The terrain and vector features are exported as 3D objects. The export settings, overriding the\nlayers\npropertiesor map viewconfiguration, include:\n–Scene nameand destinationFolder\n–Terrain resolution\n–Terrain texture resolution\n–Model scale\n–Smooth edges\n–Export normals\n–Export textures\n•\nSet View Theme\n: Allows you to select the set of layers to display in the map view from predefined\nmap themes.\n•\nConfigure\nthe map view\nsettings\n7.4.1Scene Configuration\nThe 3D map view opens with some default settings you can customize. To do so, click the\nConfigure...\nbutton at the\ntop of the 3D canvas panel to open the3D configurationwindow.\nFig. 7.8: The 3D Map Configuration dialog\nIn the 3D Configuration window there are various options to fine-tune the 3D scene:\n48Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nTerrain\n•Terrain: Before diving into the details, it is worth noting that the terrain in a 3D view is represented by a\nhierarchy of terrain tiles and as the camera moves closer to the terrain, existing tiles that do not have sufficient\ndetails are replaced by smaller tiles with more details. Each tile has mesh geometry derived from the elevation\nraster layer and texture from 2D map layers.\n–The elevation terrainTypecan be:\n∗aFlat terrain\n∗a loadedDEM (Raster Layer)\n∗anOnlineservice, loadingelevation tilesproduced by Mapzen tools – more details athttps://registry.\nopendata.aws/terrain-tiles/\n∗a loadedMeshdataset\n–Elevation: Raster or mesh layer to be used for generation of the terrain. The raster layer must contain a\nband that represents elevation. For a mesh layer, the Z values of the vertices are used.\n–Vertical scale: Scale factor for vertical axis. Increasing the scale will exaggerate the height of the land-\nforms.\n–Tile resolution: How many samples from the terrain raster layer to use for each tile. A value of 16px\nmeans that the geometry of each tile will consist of 16x16 elevation samples. Higher numbers create\nmore detailed terrain tiles at the expense of increased rendering complexity.\n–Skirt height: Sometimes it is possible to see small cracks between tiles of the terrain. Raising this value\nwill add vertical walls (“skirts”) around terrain tiles to hide the cracks.\n–Terrain elevation offset: moves the terrain up or down, e.g. to adjust its elevation with respect to the\nground level of other objects in the scene.\nThis can be useful when there is a discrepancy between the height of the terrain and the height of layers in\nyour scene (e.g. point clouds which use a relative vertical height only). In this case adjusting the terrain\nelevation manually to coincide with the elevation of objects in your scene can improve the navigation\nexperience.\n•When a mesh layer is used as terrain, you can configure theTriangles settings(wireframe display, smooth\ntriangles, level of detail) and theRendering colors settings(as a uniform color or\ncolor ramp based). More\ndetails in the\nMesh layer 3D propertiessection.\n•Terrain shading: Allows you to choose how the terrain should be rendered:\n–Shading disabled - terrain color is determined only from map texture\n–Shading enabled - terrain color is determined using Phong’s shading model, taking into account map\ntexture, the terrain normal vector, scene light(s) and the terrain material’sAmbientandSpecularcolors\nandShininess\nLights\nFrom theLightstab, press themenu to add\n•up to eightPoint lights: emits light in all directions, like a sphere of light filling an area. Objects closer to the\nlight will be brighter, and objects further away will be darker. A point light has a set position (\nX\n,\nY\nand\nZ\n), a\nColor, anIntensityand anAttenuation\n•up to fourDirectional lights: mimics the lighting that you would get from a giant flash light very far away from\nyour objects, always centered and that never dies off (e.g. the sun). It emits parallel light rays in a single\ndirection but the light reaches out into infinity. A directional light can be rotated given anAzimuth, have an\nAltitude, aColorand anIntensity.\n7.4. 3D Map View49\n\nQGIS Desktop 3.22 User Guide\nFig. 7.9: The 3D Map Lights Configuration dialog\nShadow\nCheckShow shadowto display shadow within your scene, given:\n•aDirectional light\n•aShadow rendering maximum distance: to avoid rendering shadow of too distant objects, particularly when the\ncamera looks up along the horizon\n•aShadow bias: to avoidself-shadowingeffectsthatcouldmakesomeareasdarkerthanothers, duetodifferences\nbetween map sizes. The lower the better\n•aShadow map resolution: to make shadows look sharper. It may result in less performance if the resolution\nparameter is too high.\nCamera & Skybox\nIn this tab, you can override somedefault camera settingsmade in theSettings►Options►3Ddialog.\nFurthermore, checkShow skyboxto enable skybox rendering in the scene. The skybox type can be:\n•Panoramic texture, with a single file providing sight on 360°\n•Distinct faces, with a texture file for each of the six sides of a box containing the scene\nTexture image files of the skybox can be files on the disk, remote URLs or embedded in the project (more details).\n50Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\nAdvanced\n•Map tile resolution: Width and height of the 2D map images used as textures for the terrain tiles. 256px means\nthat each tile will be rendered into an image of 256x256 pixels. Higher numbers create more detailed terrain\ntiles at the expense of increased rendering complexity.\n•Max. screen error: Determines the threshold for swapping terrain tiles with more detailed ones (and vice versa)\n- i.e. how soon the 3D view will use higher quality tiles. Lower numbers mean more details in the scene at the\nexpense of increased rendering complexity.\n•Max. ground error: The resolution of the terrain tiles at which dividing tiles into more detailed ones will stop\n(splitting them would not introduce any extra detail anyway). This value limits the depth of the hierarchy of\ntiles: lower values make the hierarchy deep, increasing rendering complexity.\n•Zoom levels: Shows the number of zoom levels (depends on the map tile resolution and max. ground error).\n•Show labels: Toggles map labels on/off\n•Show map tile info: Include border and tile numbers for the terrain tiles (useful for troubleshooting terrain\nissues)\n•Show bounding boxes: Show 3D bounding boxes of the terrain tiles (useful for troubleshooting terrain\nissues)\n•Show camera’s view center\n•Show light sources: shows a sphere at light source origins, allowing easier repositioning and placement of\nlight sources relative to the scene contents\n7.4.2Navigation options\nTo explore the map view in 3D:\n•Tilt the terrain (rotating it around a horizontal axis that goes through the center of the window)\n–Press the\nTilt up\nand\nTilt down\ntools\n–PressShiftand use the up/down keys\n–Drag the mouse forward/backward with the middle mouse button pressed\n–PressShiftand drag the mouse forward/backward with the left mouse button pressed\n•Rotate the terrain (around a vertical axis that goes through the center of the window)\n–Turn the compass of the navigation widget to the watching direction\n–PressShiftand use the left/right keys\n–Drag the mouse right/left with the middle mouse button pressed\n–PressShiftand drag the mouse right/left with the left mouse button pressed\n•Change the camera position (and the view center), moving it around in a horizontal plan\n–Drag the mouse with the left mouse button pressed, and the\nCamera control\nbutton enabled\n–Press the directional arrows of the navigation widget\n–Use the up/down/left/right keys to move the camera forward, backward, right and left, respectively\n•Change the camera altitude: press thePage Up/Page Downkeys\n•Change the camera orientation (the camera is kept at its position but the view center point moves)\n–PressCtrland use the arrow keys to turn the camera up, down, left and right\n–PressCtrland drag the mouse with the left mouse button pressed\n7.4. 3D Map View51\n\nQGIS Desktop 3.22 User Guide\n•Zoom in and out\n–Press the corresponding\nZoom In\nand\nZoom Out\ntools of the navigation widget\n–Scroll the mouse wheel (keepCtrlpressed results in finer zooms)\n–Drag the mouse with the right mouse button pressed to zoom in (drag down) and out (drag up)\nTo reset the camera view, click the\nZoom Full\nbutton on the top of the 3D canvas panel.\n7.4.3Creating an animation\nAn animation is based on a set of keyframes - camera positions at particular times. To create an animation:\n1.Toggle on the\nAnimations\ntool, displaying the animation player widget\n2.Click the\nAdd keyframe\nbutton and enter aKeyframe timein seconds. TheKeyframecombo box now displays\nthe time set.\n3.Using the navigation tools, move the camera to the position to associate with the current keyframe time.\n4.Repeat the previous steps to add as many keyframes (with time and position) as necessary.\n5.Click thebutton to preview the animation. QGIS will generate scenes using the camera positions/rotations\nat set times, and interpolating them in between these keyframes. VariousInterpolationmodes for animations are\navailable (eg, linear, inQuad, outQuad, inCirc... – more details at\nhttps://doc.qt.io/qt-5/qeasingcurve.html#\nEasingFunction-typedef).\nThe animation can also be previewed by moving the time slider. Keeping theLoopbox checked will repeatedly\nrun the animation while clickingstops a running animation.\nClick\nExport animation frames\nto generate a series of images representing the scene. Other than the filenameTemplate\nand theOutput directory, you can set the number ofFrames per second, theOutput widthandOutput height.\n7.4.43D vector layers\nA vector layer with elevation values can be shown in the 3D map view by checkingEnable 3D Rendererin the3D\nViewsection of the vector layer properties. A number of options are available for controlling the rendering of the 3D\nvector layer.\n7.5Status Bar\nThe status bar provides you with general information about the map view and processed or available actions, and\noffers you tools to manage the map view.\n7.5.1Locator bar\nOn the left side of the status bar, the locator bar, a quick search widget, helps you find and run any feature or options\nin QGIS:\n1.Click in the text widget to activate the locator search bar or pressCtrl+K.\n2.Type a text associated with the item you are looking for (name, tag, keyword, ...). By default, results are\nreturned for the enabled locator filters, but you can limit the search to a certain scope by prefixing your text\nwith the\nlocator filtersprefix, ie. typingl cadwill return only the layers whose name containscad.\nThe filter can also be selected with a double-click in the menu that shows when accessing the locator widget.\n52Chapter 7. QGIS GUI\n\nQGIS Desktop 3.22 User Guide\n3.Click on a result to execute the corresponding action, depending on the type of item.\nTip: Limit the lookup to particular field(s) of the active layer\nBy default, a search with the “active layer features” filter (f) runs through the whole attribute table of the layer. You\ncan limit the search to a particular field using the@prefix. E.g.,f @name salor@name salreturns only the\nfeatures whose “name” attribute contains ‘sal’. Text autocompletion is active when writing and the suggestion can be\napplied usingTabkey.\nA more advanced control on the queried fields is possible from the layerFieldstab. ReadFields Propertiesfor details.\nSearching is handled using threads, so that results always become available as quickly as possible, even if slow search\nfilters are installed. They also appear as soon as they are encountered by a filter, which means that e.g. a file search\nfilter will show results one by one as the file tree is scanned. This ensures that the UI is always responsive, even if a\nvery slow search filter is present (e.g. one which uses an online service).\nNote:The Nominatim locator tool may behave differently (no autocompletion search, delay of fetching results, ...)\nwith respect to the OpenStreetMap Nominatimusage policy.\nTip: Quick access to the locator’s configurations\nClick on theicon inside the locator widget on the status bar to display the list of filters you can use and aConfigure\nentry that opens theLocatortab of theSettings►Options...menu.\n7.5.2Reporting actions\nIn the area next to the locator bar, a summary of actions you’ve carried out will be shown when needed (such as\nselecting features in a layer, removing layer, pan distance and direction) or a long description of the tool you are\nhovering over (not available for all tools).\nIn case of lengthy operations, such as gathering of statistics in raster layers, executing Processing algorithms or\nrendering several layers in the map view, a progress bar is displayed in the status bar.\n7.5.3Control the map canvas\nTheCoordinateoption shows the current position of the mouse, following it while moving across the map view.\nYou can set the units (and precision) in theProject►Properties...►Generaltab. Click on the small button at the\nleft of the textbox to toggle between the Coordinate option and the\nExtentsoption that displays the coordinates\nof the current bottom-left and top-right corners of the map view in map units.\nNext to the coordinate display you will find theScaledisplay. It shows the scale of the map view. There is a scale\nselector, which allows you to choose between\npredefined and custom scales.\nOn the right side of the scale display, press thebutton to lock the scale to use the magnifier to zoom in or out.\nThe magnifier allows you to zoom in to a map without altering the map scale, making it easier to tweak the positions\nof labels and symbols accurately. The magnification level is expressed as a percentage. If theMagnifierhas a level\nof 100%, then the current map is not magnified, i.e. is rendered at accurate scale relative to the monitor’s resolution\n(DPI). A default magnification value can be defined withinSettings►Options►Rendering►Rendering behavior,\nwhich is very useful for high-resolution screens to enlarge small symbols. In addition, a setting inSettings►Options\n►Canvas & Legend►DPIcontrols whether QGIS respects each monitor’s physical DPI or uses the overall system\nlogical DPI.\nTo the right of the magnifier tool you can define a current clockwise rotation for your map view in degrees.\n7.5. Status Bar53\n\nQGIS Desktop 3.22 User Guide\nOn the right side of the status bar, there is a small checkbox which can be used temporarily to prevent layers being\nrendered to the map view (see sectionRendering).\nTo the right of the render functions, you find theEPSG:codebutton showing the current project CRS. Clicking\non this opens theProject Propertiesdialog and lets you apply another CRS to the map view.\nTip: Calculating the Correct Scale of Your Map Canvas\nWhen you start QGIS, the default CRS isWGS 84 (EPSG 4326)and units are degrees. This means that QGIS\nwill interpret any coordinate in your layer as specified in degrees. To get correct scale values, you can either manually\nchange this setting in theGeneraltab underProject►Properties...(e.g. to meters), or you can use the\nEPSG:code\nicon seen above. In the latter case, the units are set to what the project projection specifies (e.g.,\n+units=us-ft\n).\nNote that CRS choice on startup can be set inSettings►Options►CRS.\n7.5.4Messaging\nThe\nMessages\nbutton next to it opens theLog Messages Panelwhich has information on underlying processes (QGIS\nstartup, plugins loading, processing tools...)\nDepending on the\nPlugin Manager settings, the status bar can sometimes show icons to the right to inform you about\nthe availability of new () or upgradeable () plugins. Click the icon to open the Plugin Manager dialog.\n54Chapter 7. QGIS GUI\n\nCHAPTER\nEIGHT\nTHE BROWSER PANEL\n•Resources that can be opened / run from the Browser\n•Browser panel top-level entries\n–Favorites\n–Spatial Bookmarks\n–Project Home\n–Drives and file system\n–Database entries\n–Tiles and Web Services\n•Resources\nThe QGIS Browser panel is a great tool for browsing, searching, inspecting, copying and loading QGIS resources.\nOnly resources that QGIS knows how to handle are shown in the browser.\nUsing the Browser panel you can locate, inspect and add data, as described in\nThe Browser Panel. In addition, the\nBrowser panel supports drag and drop of many QGIS resources, such as project files, Python scripts, Processing\nscripts and Processing models.\nPython scripts, Processing scripts and Processing models can also be opened for editing in an external editor and the\ngraphical modeller.\nYou can drag and drop layers from theLayerspanel to theBrowserpanel, for instance into a GeoPackage or a PostGIS\ndatabase.\n55\n\nQGIS Desktop 3.22 User Guide\nFig. 8.1: The Browser panel\nThe browser panel (Fig. 8.1) is organised as an expandable hierarchy with some fixed top-level entries that organise\nthe resources handled by the browser. Node entries are expanded by clicking on\nto the left of the entry name. A\nbranch is collapsed by clicking on. The\nCollapse All\nbutton collapses all top-level entries.\nInSettings►Interface Customizationit is possible to disable resources. If you, for instance, would not like to show\nPython scripts in the browser, you can uncheck theBrowser►pyentry, and if you want to get rid of your home\nfolder in the browser, you can uncheck theBrowser►special:Homeentry.\nA filter (\nFilter Browser\n) can be used for searching based on entry names (both leaf entries and node entries in the\nhierarchy). Using the\nOptions\npull-down menu next to the filter text field, you can\n•toggleCase Sensitivesearch\n•set theFilter pattern syntaxto one of\n–Normal\n–Wildcard(s)\n56Chapter 8. The Browser panel\n\nQGIS Desktop 3.22 User Guide\n–Regular Expressions\nTheProperties widget, showing useful information about some entries / resources, can be enabled / disabled using the\nEnable/disable properties widget\nbutton. When enabled, it opens at the bottom of the browser panel, as shown inFig. 8.2.\nFig. 8.2: The properties widget\nA second browser panel can be opened by activating theBrowser (2)panel inView►Panels. Having two browser\npanels can be useful when copying layers between resources that are locationed deep down in different branches of\nthe browser hierarchy.\n57\n\nQGIS Desktop 3.22 User Guide\n8.1Resources that can be opened / run from the Browser\nA lot can be accomplished in the Browser panel\n•Add vector, raster and mesh layers to your map by double-clicking, dragging onto the map canvas or clicking\nthe\nAdd Selected Layers\nbutton (after selecting layers)\n•Run Python scripts (including Processing algorithms) by double-clicking or dragging onto the map canvas\n•Run models by double-clicking or dragging onto the map canvas\n•Extract Symbols...from QGIS Project files using the context menu\n•Open files with their default applications (Open <file type> Externally...in the context menu). Examples:\nHTML files, spreadsheets, images, PDFs, text files, ...\n•Copy entries\n•Rename and delete (multiple) layers (context menu:Manage►)\n•Open a file explorer window and directly select the fileShow in Files\nResource specific actions are listed for the different resource groups sorted under the top-level entries listed below.\n8.2Browser panel top-level entries\n8.2.1Favorites\nOften used file system locations can be tagged as favorites. The ones you have tagged will appear here.\nIn addition to the operations described underHome, the context menu allows you toRename Favorite...andRemove\nFavorite.\n8.2.2Spatial Bookmarks\nThis is where you will find your spatial bookmarks, organised intoProject BookmarksandUser Bookmarks.\nFrom the top level context menu, you can create a bookmark (New Spatial Bookmark...),Show the Spatial Bookmark\nManager,Import Spatial Bookmarks...andExport Spatial Bookmarks....\nFor bookmark entries you canZoom to Bookmark,Edit Spatial Bookmark...andDelete Spatial Bookmark\n8.2.3Project Home\nAvailable once the project file has been saved, theProject homeentry is a folder containing data and other contents\n(scripts, models, text, ...) that may be used within the current project. Displayed in theBrowserpanel, it allows you\nto quickly access data and other files of the project.\nIt defaults to the project file folder but can be changed through theProject►Properties...►General►Project\nhomeoption, or by right-clicking on theProject Homeitem of the Browser panel and selectingSet project home....\nCustomizing that folder is especially useful in contexts where QGIS projects are not stored in the root folder of an\norganisational ‘project’, along with datasets.\n58Chapter 8. The Browser panel\n\nQGIS Desktop 3.22 User Guide\n8.2.4Drives and file system\nThe next items of theBrowserpanel depend on the OS in use and concern the top level entries of its file system.\nThey are mainly:\n•TheHomefolder, pointing to the current user home folder\n•on Unix-based machines, the root/folder\n•the connected drives, either local or network. Depending on the OS, they are directly listed (eg,C:\\,D:\\) or\nthrough the/Volumesentry.\nFrom the contextual menu of each of these folders or drives, you can:\n•refresh the contents\n•create aNew► subitem that is aDirectory,GeoPackageor ESRIShapefileformat dataset\n•hide the directory (Hide from Browser)\n•Set color: customize the folder icon color, aiding in rapid browser navigation of complex folder structures\n•enableScanning:\n–Monitor for changes: allows to manually control whether a particular directory should be monitored\nand automatically updated. This setting applies to the selected directory and all subdirectories. This\nmeans that you can manually opt-in to monitoring of network drives if you know there’s no issue, or\nmanually opt-out of monitoring of large directories which you don’t want monitored for other reasons.\nBy default, remote or network drives are not automatically monitored.\n–Fast scan this directory\n•open the directory in your file manager (Open Directory...)\n•open the directory in a terminal window (Open in Terminal...)\n•inspect theProperties...or the parentDirectory Properties...\n8.2.5Database entries\nDepending on your OS and installed drivers, you might have access to different database types to use in QGIS. Below\nare listed the different entries of contextual menu at each level of the dataset tree.\nLevelContext\nmenu\nType of database\nGeoPackageSpatiaLitePostGISSAP HANAMSSQLOracle\nTop menuCreate aNew Connection...to an existing database\nCreate Database...\nSave Connections...details to a file\nLoad Connections...\nConnec-\ntion   /\nDatabase\nRefresha connection\nEdit Connection...settings\nDelete Connection\nDelete <database_name>\nCompact Database (VACUUM)\nCreate aNew Schema...\nCreate aNew Table...\ncontinues on next page\n8.2. Browser panel top-level entries59\n\nQGIS Desktop 3.22 User Guide\nTable 8.1 – continued from previous page\nLevelContext\nmenu\nType of database\nGeoPackageSpatiaLitePostGISSAP HANAMSSQLOracle\nExecute SQL...query\nSchemaRefresha schema\nSchema Operations►Rename Schema...\nSchema Operations►Delete Schema...\nCreate aNew Table...\nExecute SQL...query\nTable /\nLayer\nTable Operations►Rename Table...\nTable Operations►Truncate Table...\nExecute SQL...query\nExport Layer►To file...\nManage►Rename Layer <layer_name>...\nManage►Delete Layer <layer_name>...\nManage►Delete Selected Layers\nManage►Add Layer to Project\nManage►Add Selected Layers to Project\nOpenLayer Properties...dialog\nOpenFile Properties...dialog\nFieldsAdd New Field...\nFieldDelete Field...\n60Chapter 8. The Browser panel\n\nQGIS Desktop 3.22 User Guide\n8.2.6Tiles and Web Services\nLevelContext menuType of services\nWMS /\nWMTS\nVector\nTiles\nXYZ\nTiles\nWCS\nWFS /\nOGC API -\nFeatures\nAr-\ncGIS\nREST\nServers\nGeoN-\node\nTop\nmenu\nCreate aNew Connec-\ntion...\nCreate aNew Generic\nConnection...\nCreate aNew ArcGIS\nVector  Tile  Service\nConnection...\nSave   Connections...\ndetails to a file\nLoad Connections...\nCon-\nnec-\ntion\nRefreshconnection\nEdit...connection set-\ntings\nDeleteconnection\nView Service Infoin\nWeb browser\nTa-\nble /\nLayer\nExport  Layer►To\nFile...\nAdd layer to Project\nOpenLayer  proper-\nties...dialog\nView Service Infoin\nWeb browser\n8.3Resources\n•Project files. The context menu for QGIS project files allows you to:\n–open it (Open Project)\n–extract symbols (Extract Symbols...) - opens the style manager that allows you to export symbols to an\nXML file, add symbols to the default style or export as PNG or SVG.\n–inspect properties (File Properties...)\nYou can expand the project file to see its layers. The context menu of a layer offers the same actions as elsewhere\nin the browser.\n•QGIS Layer Definition files (QLR). The following actions are available from the context menu:\n–export it (Export Layer►To file)\n–add it to the project (Add Layer to Project)\n–inspect properties (Layer Properties...)\n•Processing models (.model3). The following actions are available from the context menu:\n8.3. Resources61\n\nQGIS Desktop 3.22 User Guide\n–Run Model...)\n–Edit Model...)\n•QGIS print composer templates (QPT). The following action is available from the context menu:\n–(New Layout from Template)\n•Python scripts (.py). The following actions are available from the context menu:\n–(Run script...)\n–(Open in External Editor)\n•Recognized raster formats. The following actions are available from the context menu:\n–delete it (Delete File <dataset name>)\n–export it (Export Layer►To file)\n–add it to the project (Add Layer to Project)\n–inspect properties (Layer Properties...,File Properties...)\nFor some formats you can alsoOpen <file type> Externally...\n•Recognized vector formats. The following actions are available from the context menu:\n–delete it (Delete File <dataset name>)\n–export it (Export Layer►To file)\n–add it to the project (Add Layer to Project)\n–inspect properties (Layer Properties...,File Properties...)\nFor some formats you can alsoOpen <file type> Externally...\n62Chapter 8. The Browser panel\n\nCHAPTER\nNINE\nQGIS CONFIGURATION\nQGIS is highly configurable. Through theSettingsmenu, it provides different tools to:\n•Style Manager...: create and managesymbols, styles and color ramps.\n•Custom Projections...: create your owncoordinate reference systems.\n•Keyboard Shortcuts...: define your own set ofkeyboard shortcuts. Also, they can be overridden during\neach QGIS session by theproject properties(accessible underProjectmenu).\n•Interface Customization...: configure theapplication interface, hiding dialogs or tools you may not need.\n•Options...: set globaloptionsto apply in different areas of the software. These preferences are saved in the\nactiveUser profilesettings and applied by default whenever you open a new project with this profile.\n9.1Options\nSome basic options for QGIS can be selected using theOptionsdialog. Select the menu optionSettings►\nOptions. You can modify the options according to your needs. Some of the changes may require a restart of QGIS\nbefore they will be effective.\nThe tabs where you can customize your options are described below.\nNote: Plugins can embed their settings within the Options dialog\nWhile only Core settings are presented below, note that this list can be extended byinstalled pluginsimplementing\ntheir own options into the standard Options dialog. This avoids each plugin having their own config dialog with extra\nmenu items just for them...\n63\n\nQGIS Desktop 3.22 User Guide\n9.1.1General Settings\nFig. 9.1: General Settings in QGIS\nOverride System Locale\nBy default, QGIS relies on your Operating System configuration to set language and manipulate numerical values.\nEnabling this group allows you to customize the behavior.\n•Select fromUser interface translationthe language to apply to the GUI\n•Select inLocale (number, date and currency formats)the system on which date and numeric values should be\ninput and rendered\n•Show group (thousand) separator\nA summary of the selected settings and how they would be interpreted is displayed at the bottom of the frame.\nApplication\n•Select theStyle (QGIS restart required)ie, the widgets look and placement in dialogs. Possible values depend\non your Operating System.\n64Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n•Define theUI theme (QGIS restart required). It can be ‘default’, ‘Night Mapping’, or ‘Blend of Gray’\n•Define theIcon size\n•Define theFontand itsSize. The font can beQt defaultor a user-defined one\n•Change theTimeout for timed messages or dialogs\n•Hide splash screen at startup\n•Show QGIS news feed on welcome page: displays a curated QGIS news feed on the welcome page, giving\nyou a direct way to be aware of project news (user/developer meetings date and summary, community surveys,\nreleases announcements, various tips...)\n•Check QGIS version at startupto keep you informed if a newer version is released\n•Use native color chooser dialogs(seeColor Selector)\n•Modeless data source manager dialogto keep thedata source managerdialog opened and allow interaction\nwith QGIS interface while adding layers to project\nProject files\n•Open project on launch\n–‘Welcome Page’ (default): can display the “News” feed, the project template(s) and the most recent\nprojects (with thumbnails) of theuser profile. No project is opened by default.\n–‘New’: opens a new project, based on the default template\n–‘Most recent’: reopens the last saved project\n–and ‘Specific’: opens a particular project. Use the...button to define the project to use by default.\n•Create new project from default project. You have the possibility to press onSet current project as default\nor onReset default. You can browse through your files and define a directory where you find your user-defined\nproject templates. This will be added toProject►New From Template. If you first activateCreate new\nproject from default projectand then save a project in the project templates folder.\n•Prompt to save project and data source changes when requiredto avoid losing changes you made.\n•Prompt for confirmation when a layer is to be removed\n•Warn when opening a project file saved with an older version of QGIS. You can always open projects created\nwith older version of QGIS but once the project is saved, trying to open with older release may fail because of\nfeatures not available in that version.\n•Enable macros. This option was created to handle macros that are written to perform an action on project\nevents. You can choose between ‘Never’, ‘Ask’, ‘For this session only’ and ‘Always (not recommended)’.\n•Default paths: defines whether paths to files and layers used in new projects are stored as ‘Absolute’ or ‘Relative’\nto the project file. This setting can be overwritten at the project level.\n•Default project file format\n–QGZ Archive file format, embeds auxiliary data(seeauxiliary data)\n–QGS Project saved in a clear text, does not embed auxiliary data: the auxiliary data is stored in a\nseparate.qgdfile along with the project file.\n9.1. Options65\n\nQGIS Desktop 3.22 User Guide\n9.1.2System Settings\nSVG paths\nAdd or RemovePath(s) to search for Scalable Vector Graphic (SVG) symbols. These SVG files are then available to\nsymbolize or label the features or decorate your map composition.\nAlso readRemote or embedded file selectorfor different ways to refer to svg files in a QGIS path.\nPlugin paths\nAdd or RemovePath(s) to search for additional C++ plugin libraries.\nDocumentation paths\nAdd or RemoveDocumentation Path(s)to use for QGIS help. By default, a link to the official online User Manual\ncorresponding to the version being used is added. You can however add other links and prioritize them from top to\nbottom: each time you click on aHelpbutton in a dialog, the topmost link is checked and if no corresponding page\nis found, the next one is tried, and so on.\nNote:Documentation is versioned and translated only for QGIS Long Term Releases (LTR), meaning that if you\nare running a regular release (eg, QGIS 3.0), the help button will by default open the next LTR manual page (ie.\n3.4 LTR), which may contain description of features in newer releases (3.2 and 3.4). If no LTR documentation is\navailable then thetestingdoc, with features from newer and development versions, is used.\nSettings\nIt helps youReset user interface to default settings (restart required)if you made anycustomization.\nEnvironment\n66Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nFig. 9.2: System environment variables in QGIS\nSystem environment variables can be viewed, and many configured, in theEnvironmentgroup. This is useful for\nplatforms, such as Mac, where a GUI application does not necessarily inherit the user’s shell environment. It’s also\nuseful for setting and viewing environment variables for the external tool sets controlled by the Processing toolbox\n(e.g., SAGA, GRASS), and for turning on debugging output for specific sections of the source code.\nUse custom variables (restart required - include separators). You canAddandRemovevariables. Already defined\nenvironment variables are displayed inCurrent environment variables, and it’s possible to filter them by activating\nShow only QGIS-specific variables.\n9.1. Options67\n\nQGIS Desktop 3.22 User Guide\n9.1.3CRS Settings\nNote:For more information on how QGIS handles layer projection, please read the dedicated section atWorking\nwith Projections\n.\nFig. 9.3: CRS Settings in QGIS\nCRS for projects\nThere is an option to automatically set new project’s CRS:\n•Use CRS from first layer added: the CRS of the project will be set to the CRS of the first layer loaded into\nit\n•Use a default CRS: a preselected CRS is applied by default to any new project and is left unchanged when\nadding layers to the project.\nThe choice will be saved for use in subsequent QGIS sessions. The Coordinate Reference System of the project can\nstill be overridden from theProject►Properties...►CRStab.\nCRS for layers\nDefault CRS for layers: select a default CRS to use when you create a layer\nYou can also define the action to take when a new layer is created, or when a layer without a CRS is loaded.\n•Leave as unknown CRS (take no action)\n•Prompt for CRS\n•Use project CRS\n•Use a default CRS\n68Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nAccuracy warnings\nOnly show warnings for CRS inaccuracies which exceeda given distance: occurs when you are explicitly creating or\nmodifying a dataset and select a CRS based on a datum ensemble with lower accuracy. The default is toAlways\nshowthe warning if any inaccuracy. Requires a QGIS version using at leastPROJ 8.0.\nShow warning for CRS inaccuracies for layers in project legend: If checked, any layer with a CRS with accuracy\nissues (i.e. a dynamic crs with no coordinate epoch available, or a CRS based on a datum ensemble with inherent\ninaccuracy exceeding the user-set limit) will have thewarning icon in theLayerspanel reflecting that it is a\nlow-accuracy layer.\nThis is designed for use in engineering, BIM, asset management, and other fields where inaccuracies of me-\nter/submeter level are potentially very dangerous or expensive!\nPlanimetric measurements: setsthedefaultforthe“planimetricmeasurements”propertyfornewlycreatedprojects.\n9.1.4Transformations Settings\nTheTransformationstab helps you set coordinate transformations and operations to apply when loading a layer\nto a project or reprojecting a layer.\nFig. 9.4: Transformations Settings\nDefault datum transformations\nIn this group, you can control whether reprojecting layers to another CRS should be:\n•automatically processed using QGIS default transformations settings;\n•and/or more controlled by you with custom preferences such as:\n–Ask for datum transformation if several are available\n–a predefined list of datum transformations to apply by default. SeeDatum Transformationsfor more\ndetails.\n9.1. Options69\n\nQGIS Desktop 3.22 User Guide\n9.1.5Data Sources Settings\nFig. 9.5: Data Sources Settings in QGIS\nFeature attributes and table\n•Open new attribute tables as docked windows\n•Copy features as\n‘Plain text, no geometry’, ‘Plain text, WKT geometry’, or ‘GeoJSON’ when pasting features\nin other applications.\n•Attribute table behavior: set filter on the attribute table at the opening. There are three possibilities:\n‘Show all features’, ‘Show selected features’ and ‘Show features visible on map’.\n•Default view: define the view mode of the attribute table at every opening. It can be ‘Remember last view’,\n‘Table view’ or ‘Form view’.\n•Attribute table row cache. This row cache makes it possible to save the last loaded N attribute rows so\nthat working with the attribute table will be quicker. The cache will be deleted when closing the attribute table.\n•Representation for NULL values. Here, you can define a value for data fields containing a NULL value.\nTip: Improve opening of big data attribute table\nWhen working with layers with big amount of records, opening the attribute table may be slow as the dialog request\nall the rows in the layer. Setting theAttribute table behaviortoShow features visible on mapwill make QGIS\nrequest only the features in the current map canvas when opening the table, allowing a quick data loading.\n70Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nNote that data in this attribute table instance will be always tied to the canvas extent it was opened with, meaning\nthat selectingShow All Featureswithin such a table will not display new features. You can however update the set\nof displayed features by changing the canvas extent and selectingShow Features Visible On Mapoption in the\nattribute table.\nData source handling\n•Scan for valid items in the browser dock. You can choose between ‘Check extension’ and ‘Check file\ncontents’.\n•Scan for contents of compressed files (.zip) in browser dockdefines how detailed is the widget information\nat the bottom of the Browser panel when querying such files. ‘No’, ‘Basic scan’ and ‘Full scan’ are possible\noptions.\n•Prompt for raster sublayers when opening. Some rasters support sublayers — they are called subdatasets in\nGDAL. An example is netCDF files — if there are many netCDF variables, GDAL sees every variable as a\nsubdataset. The option allows you to control how to deal with sublayers when a file with sublayers is opened.\nYou have the following choices:\n–‘Always’: Always ask (if there are existing sublayers)\n–‘If needed’: Ask if layer has no bands, but has sublayers\n–‘Never’: Never prompt, will not load anything\n–‘Load all’: Never prompt, but load all sublayers\n•Automatically refresh directories in browser dock when their contents change: Allows you to manually opt-\nout of monitoring directories in theBrowserpanel by default (eg, to avoid potential slow down due to network\nlatency).\nLocalized data paths\nIt is possible to use localized paths for any kind of file based data source.  They are a list of paths which\nare used to abstract the data source location.  For instance, ifC:\\my_mapsis listed in the localized paths,\na layer havingC:\\my_maps\\my_country\\ortho.tifas data source will be saved in the project using\nlocalized:my_country\\ortho.tif.\nThe paths are listed by order of preference, in other words QGIS will first look for the file in the first path, then in\nthe second one, etc.\nHidden browser paths\nThis widget lists all the folders you chose to hide from theBrowser panel. Removing a folder from the list will make\nit available in theBrowserpanel.\n9.1. Options71\n\nQGIS Desktop 3.22 User Guide\n9.1.6Rendering Settings\nFig. 9.6: Rendering tab of Project Properties dialog\nRendering behavior\n•By default new layers added to the map should be displayed: unchecking this option can be handy when\nloading multiple layers to avoid each new layer being rendered in the canvas and slow down the process\n72Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n•Use render caching where possible to speed up redraws\n•Render layers in parallel using many CPU cores\n•Max cores to use\n•Map update interval (default to 250 ms)\n•Enable feature simplification by default for newly added layers\n•Simplification threshold\n•Simplification algorithm: This option performs a local “on-the-fly” simplification on feature’s and speeds up\ngeometry rendering. It doesn’t change the geometry fetched from the data providers. This is important when\nyou have expressions that use the feature geometry (e.g. calculation of area) - it ensures that these calculations\nare done on the original geometry, not on the simplified one. For this purpose, QGIS provides three algorithms:\n‘Distance’ (default), ‘SnapToGrid’ and ‘Visvalingam’.\n•Simplify on provider side if possible: the geometries are simplified by the provider (PostGIS, Oracle...) and\nunlike the local-side simplification, geometry-based calculations may be affected\n•Maximum scale at which the layer should be simplified\n•Magnification level(see themagnifier)\nNote:Besides the global setting, feature simplification can be set for any specific layer from itsLayer properties►\nRenderingmenu.\nRendering quality\n•Make lines appear less jagged at the expense of some drawing performance\nCurve segmentation\n•Segmentation tolerance: this setting controls the way circular arcs are rendered.The smallermaximum angle\n(between the two consecutive vertices and the curve center, in degrees) or maximum difference (distance\nbetween the segment of the two vertices and the curve line, in map units), themore straight linesegments\nwill be used during rendering.\n•Tolerance type: it can beMaximum angleorMaximum differencebetween approximation and curve.\nRasters\n•WithRGB band selection, you can define the number for the Red, Green and Blue band.\n•TheZoomed in resamplingand theZoomed out resamplingmethods can be defined. ForZoomed in resampling\nyou can choose between three resampling methods: ‘Nearest Neighbour’, ‘Bilinear’ and ‘Cubic’. ForZoomed\nout resamplingyou can choose between ‘Nearest Neighbour’ and ‘Average’. You can also set theOversampling\nvalue (between 0.0 and 99.99 - a large value means more work for QGIS - the default value is 2.0).\nContrast enhancement\nContrast enhancement options can be applied toSingle band gray,Multi band color (byte/band)orMulti band color\n(>byte/band). For each, you can set:\n•theAlgorithmto use, whose values can be ‘No stretch’, ‘Stretch to MinMax’, ‘Stretch and Clip to MinMax’ or\n‘Clip to MinMax’\n•theLimits (minimum/maximum)to apply, with values such as ‘Cumulative pixel count cut’, ‘Mini-\nmum/Maximum’, ‘Mean +/- standard deviation’.\nFor rasters rendering, you can also define the following options:\n•Cumulative pixel count cut limits\n•Standard deviation multiplier\n9.1. Options73\n\nQGIS Desktop 3.22 User Guide\nDebugging\n•Map canvas refreshto debug rendering duration in theLog Messagespanel.\n9.1.7Canvas and Legend Settings\nFig. 9.7: Canvas and Legend Settings\nThese properties let you set:\n•theDefault map appearance (overridden by project properties): theSelection colorandBackground color.\n•Layer legendinteraction:\n–Double click action in legend. You can either ‘Open layer properties’, ‘Open attribute table’ or\n‘Open layer styling dock’ with the double click.\n–Display classification attribute namesin the Layers panel, e.g. when applying a categorized or rule-\nbased renderer (seeSymbology Propertiesfor more information).\n–theWMS getLegendGraphic Resolution\n–MinimumandMaximum legend symbol sizeto control symbol size display in theLayerspanel\n•theDelayin milliseconds of layersmap tipsdisplay\n•Whether QGIS shouldRespect screen DPI\n: If enabled, QGIS will attempt to display the canvas with physi-\ncally accurate scale on screen, depending on the monitor’s physical DPI. Symbology with specified display size\nwill also be rendered accurately, e.g. a 10mm symbol will show as 10mm on screen. However, label font sizes\non canvas may differ from those in QGIS’ UI or other applications. If this setting is turned off, QGIS will use\nthe operating system’s logical DPI, which will be consistent with other applications on the system. However,\ncanvas scale and symbology size may be physically inaccurate on screen. In particular, on high-dpi screens,\nsymbology is likely to appear too small.\nFor best experience, it is recommended to enable\nRespect screen DPI, especially when using multiple or\ndifferent monitors and preparing visually high-quality maps. DisablingRespect screen DPIwill generate\noutput that may be more suitable for mapping intended for on-screen use only, especially where font sizes\nshould match other applications.\n74Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nNote:Rendering in layouts is not affected by theRespect screen DPIsetting; it always respects the specified DPI for\nthe target output device. Also note that this setting uses the physical screen DPI as reported by the operating system,\nwhich may not be accurate for all displays.\n9.1.8Map tools Settings\nFig. 9.8: Map tools Settings in QGIS\nThis tab offers some options regarding the behavior of theIdentify tool.\n•Search radius for identifying features and displaying map tipsis a tolerance distance within which the identify\ntool will depict results as long as you click within this tolerance.\n•Highlight colorallows you to choose with which color features being identified should be highlighted.\n•Bufferdetermines a buffer distance to be rendered from the outline of the identify highlight.\n•Minimum widthdetermines how thick should the outline of a highlighted object be.\nMeasure tool\n•DefineRubberband colorfor measure tools\n9.1. Options75\n\nQGIS Desktop 3.22 User Guide\n•DefineDecimal places\n•Keep base unitto not automatically convert large numbers (e.g., meters to kilometers)\n•Preferred distance units: options are ‘Meters’, ‘Kilometers’, ‘Feet’, ‘Yards’, ‘Miles’, ‘Nautical Miles’, ‘Centime-\nters’, ‘Millimeters’, ‘Degrees’ or ‘Map Units’\n•Preferred area units: options are ‘Square meters’, ‘Square kilometers’, ‘Square feet’, ‘Square yards’, ‘Square\nmiles’, ‘Hectares’, ‘Acres’, ‘Square nautical miles’, ‘Square centimeters’, ‘Square millimeters’, ‘Square degrees’\nor ‘Map Units’\n•Preferred angle units: options are ‘Degrees’, ‘Radians’, ‘Gon/gradians’, ‘Minutes of arc’, ‘Seconds of arc’,\n‘Turns/revolutions’, milliradians (SI definition) or mil (NATO/military definition)\nCoordinate and Bearing Display\n•DefineDefault bearing format for new projects: used to display the mouse coordinate in the status bar when\npanning the map canvas. It can be overridden in the project properties dialog.\nPanning and zooming\n•Define aZoom factorfor zoom tools or wheel mouse\nPredefined scales\nHere, you find a list of predefined scales to display in the status barScaledrop-down widget, for quick zoom. With\ntheandbuttons you can add or remove your personal scales. You can also import or export scales from/to a\n.XMLfile. Note that you still have the possibility to remove your changes and reset to the predefined list.\n9.1.93D Settings\nFig. 9.9: 3D Settings\nThe3Dmenu helps you configure some default settings to use for any3D Map view. These can refer toDefault\nCamera Settings:\n•Projection type: allowing to view the 3D scene in a:\n–Perspective projection(default): Parallel lines appear to meet in the distance. Objects appear to shrink the\nfarther they are from the camera.\n–or anOrthogonal projection: Parallel lines appear parallel. Objects appear the same size regardless of\ndistance.\n76Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n•Camera’sField of view: only relevant in perspective projection, specifies the current vertical field of view in\ndegrees and determines how much of the scene is visible to the camera. Default value is 45°.\n•Navigation mode: provides different means to interact with the 3D scene. Available modes are:\n–Terrain based: the camera follows around a fixed position on the surface of the terrain as the scene is\nnavigated.\n–Walk mode (first person)\nDepending on the selected mode,navigation commandsdiffer.\n•Movement speed\n•Invert vertical axis: Controls whether vertical axis movements should be inverted from their normal behaviour.\nOnly affects movement in theWalk mode. It can be set to:\n–Never\n–Only when dragging: causes the vertical motion to inverted only when performing a click-and-drag camera\nrotation\n–andAlways: causes the motions to be inverted when both click-and-dragging and when the camera move-\nment is locked to the cursor (via a~key press)\n9.1.10Colors Settings\nFig. 9.10: Colors Settings\nThis menu allows you to create or update palettes of colors used throughout the application in thecolor selector widget.\nYou can choose from:\n•Recent colorsshowing recently used colors\n•Standard colors, the default palette of colors\n•Project colors, a set of colors specific to the current project (seeDefault Styles Propertiesfor more details)\n•New layer colors, a set of colors to use by default when new layers are added to QGIS\n•or custom palette(s) you can create or import using the...button next to the palette combobox.\nBy default,Recent colors,Standard colorsandProject colorspalettes can not be removed and are set to appear in the\ncolor button drop-down. Custom palettes can also be added to this widget thanks to theShow in Color Buttonsoption.\n9.1. Options77\n\nQGIS Desktop 3.22 User Guide\nFor any of the palettes, you can manage the list of colors using the set of tools next to the frame, ie:\n•AddorRemovecolor\n•CopyorPastecolor\n•ImportorExportthe set of colors from/to.gplfile.\nDouble-click a color in the list to tweak or replace it in theColor Selectordialog. You can also rename it by double-\nclicking in theLabelcolumn.\n9.1.11Digitizing Settings\nFig. 9.11: Digitizing Settings in QGIS\nThis tab helps you configure general settings whenediting vector layer(attributes and geometry).\nFeature creation\n78Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n•Suppress attribute form pop-up after feature creation: this choice can be overridden in each layer properties\ndialog.\n•Reuse last entered attribute values: remember the last used value of every attribute and use it as default for\nthe next feature being digitized. Works per layer. This behavior can also be controled on a per-field basis (see\nConfigure the field behavior).\n•Validate geometries. Editing complex lines and polygons with many nodes can result in very slow rendering.\nThis is because the default validation procedures in QGIS can take a lot of time. To speed up rendering, it is\npossible to select GEOS geometry validation (starting from GEOS 3.3) or to switch it off. GEOS geometry\nvalidation is much faster, but the disadvantage is that only the first geometry problem will be reported.\nNote that depending on the selection, reports of geometry errors may differ (seeTypes of error messages and\ntheir meanings)\n•Default Z valueto use when creating new 3D features.\nRubberband\n•Define RubberbandLine width,Line colorandFill color.\n•Don’t update rubberband during vertex editing.\nSnapping\n•Enable snapping by defaultactivates snapping when a project is opened\n•DefineDefault snap mode(‘Vertex’, ‘Segment’, ‘Centroid’, ‘Middle of segments’, Line endpoints’, ‘Area’)\n•DefineDefault snapping tolerancein map units or pixels\n•Define theSearch radius for vertex editsin map units or pixels\n•Display main dialog as (restart required): set whether the Advanced Snapping dialog should be shown as ‘Dialog’\nor ‘Dock’.\n•Snapping marker color\n•Show snapping tooltipssuch as name of the layer whose feature you are about to snap. Helpful when multiple\nfeatures overlap.\n•Enable snapping on invisible features (not shown on the map canvas)\nVertex markers\n•Show markers only for selected features\n•Define vertexMarker style(‘Cross’ (default), ‘Semi transparent circle’ or ‘None’)\n•Define vertexMarker size (in millimeter)\nCurve offset tool\nThe next 3 options refer to the\nOffset Curve\ntool in\nAdvanced digitizing. Through the various settings, it is possible\nto influence the shape of the line offset. These options are possible starting from GEOS 3.3.\n•Join style: ‘Round’, ‘Mitre’ or ‘Bevel’\n•Quadrant segments\n•Miter limit\nTracing\nBy activating the\nConvert tracing to curveyou can create curve segments while digitizing. Keep in mind that your\ndata provider must support this feature.\n9.1. Options79\n\nQGIS Desktop 3.22 User Guide\n9.1.12Layouts Settings\nFig. 9.12: Layouts Settings in QGIS\nComposition defaults\nYou can define theDefault fontused within theprint layout.\nGrid appearance\n•Define theGrid style(‘Solid’, ‘Dots’, ‘Crosses’)\n•Define theGrid color\nGrid and guide defaults\n•Define theGrid spacing\n•Define theGrid offsetfor X and Y\n•Define theSnap tolerance\nLayout Paths\n•DefinePath(s) to search for extra print templates: a list of folders with custom layout templates to use while\ncreating new one.\n9.1.13GDAL Settings\nGDALis a data exchange library for geospatial data that supports a large number of vector and raster formats. It\nprovides drivers to read and (often) write data in these formats. TheGDALtab exposes the drivers for raster and\nvector formats with their capabilities.\n80Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nGDAL raster and vector drivers\nTheRaster DriversandVector Driverstabs allow you to define which GDAL driver is enabled to read and/or write\nfiles, as in some cases more than one GDAL driver is available.\nFig. 9.13: GDAL Settings in QGIS - Raster drivers\nTip:Double-click a raster driver that allows read and write access (rw+(v)) opens theEdit Create optionsdialog\nfor customization.\n9.1. Options81\n\nQGIS Desktop 3.22 User Guide\nRaster driver options\nThis frame provides ways to customize the behavior of raster drivers that support read and write access:\n•Edit create options: allows you to edit or add different profiles of file transformation, i.e. a set of predefined\ncombinations of parameters (type and level of compression, blocks size, overview, colorimetry, alpha...) to\nuse when outputting raster files. The parameters depend on the driver.\nFig. 9.14: Sample of create options profile (for GeoTiff)\nThe upper part of the dialog lists the current profile(s) and allows you to add new ones or remove any of them.\nYou can also reset the profile to its default parameters if you have changed them. Some drivers (eg, GeoTiff)\nhave some sample of profiles you can work with.\nAt the bottom of the dialog:\n–Thebutton lets you add rows to fill with the parameter name and value\n–Thebutton deletes the selected parameter\n–Click theValidatebutton to check that the creation options entered for the given format are valid\n–Use theHelpbutton to find the parameters to use, or refer to theGDAL raster drivers documentation.\n•Edit Pyramids Options\n82Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nFig. 9.15: Sample of Pyramids profile\n9.1.14Variables Settings\nTheVariablestab lists all the variables available at the global-level.\nIt also allows the user to manage global-level variables. Click the\nbutton to add a new custom global-level variable.\nLikewise, select a custom global-level variable from the list and click the\nbutton to remove it.\nMore information about variables in theStoring values in Variablessection.\n9.1. Options83\n\nQGIS Desktop 3.22 User Guide\nFig. 9.16: Variables Settings in QGIS\n9.1.15Authentication Settings\nIn theAuthenticationtab you can set authentication configurations and manage PKI certificates. SeeAuthentication\nSystemfor more details.\nFig. 9.17: Authentication Settings in QGIS\n84Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n9.1.16Network Settings\nGeneral\n•DefineTimeout for network requests (ms)- default is 60000\n•DefineDefault expiration period for WMS Capabilities (hours)- default is 24\n•DefineDefault expiration period for WMS-C/WMTS tiles (hours)- default is 24\n•DefineMax retry in case of tile or feature request errors\n•DefineUser-Agent\nFig. 9.18: Proxy-settings in QGIS\nCache settings\nDefines theDirectoryand aSizefor the cache. Also offers tools toautomatically clear the connection authentication\ncache on SSL errors (recommended).\nProxy for web access\n•Use proxy for web access\n9.1. Options85\n\nQGIS Desktop 3.22 User Guide\n•Set theProxy typeaccording to your needs and define ‘Host’ and ‘Port’. Available proxy types are:\n–Default Proxy: Proxy is determined based on system’s proxy\n–Socks5Proxy: Generic proxy for any kind of connection. Supports TCP, UDP, binding to a port (incoming\nconnections) and authentication.\n–HttpProxy: Implemented using the “CONNECT” command, supports only outgoing TCP connections;\nsupports authentication.\n–HttpCachingProxy: Implemented using normal HTTP commands, it is useful only in the context of HTTP\nrequests.\n–FtpCachingProxy: Implemented using an FTP proxy, it is useful only in the context of FTP requests.\nCredentials of proxy are set using theauthentication widget.\nExcluding some URLs can be added to the text box below the proxy settings (seeFig. 9.18). No proxy will be used\nif the target url starts with one of the string listed in this text box.\nIf you need more detailed information about the different proxy settings, please refer to the manual of the underlying\nQT library documentation athttps://doc.qt.io/archives/qt-5.9/qnetworkproxy.html#ProxyType-enum\nTip: Using Proxies\nUsing proxies can sometimes be tricky. It is useful to proceed by ‘trial and error’ with the above proxy types, to check\nif they succeed in your case.\n9.1.17Locator Settings\nTheLocatortab lets you configure theLocator bar, a quick search widget available on the status bar to help you\nperform searches in the application. It provides some default filters (with prefix) to use:\nFig. 9.19: Locator Settings in QGIS\n•Project layers (l): finds and selects a layer in theLayerspanel.\n•Project layouts (pl): finds and opens a print layout.\n86Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n•Actions (.): finds and executes a QGIS action; actions can be any tool or menu in QGIS, opening a panel...\n•Active layer features (f): searches for matching attributes in any field from the current active layer and zooms\nto the selected feature. Pressto configure the maximum number of results.\n•Features in all layers (af): searches for matching attributes in thedisplay nameof eachsearchable layers\nand zooms to the selected feature. Pressto configure the maximum number of results and the maximum\nnumber of results per layer.\n•Calculator (=): allows evaluation of any QGIS expression and, if valid, gives an option to copy the result to the\nclipboard.\n•Spatial bookmarks (b): finds and zooms to the bookmark extent.\n•Settings (set): browses and opens project and application-wide properties dialogs.\n•Go to coordinate (go): pans the map canvas to a location defined by a comma or space separated pair of x\nand y coordinates or a formatted URL (e.g., OpenStreetMap, Leaflet, OpenLayer, Google Maps, ...). The\ncoordinate is expected in WGS 84 (epsg:4326) and/or map canvas CRS.\n•Nominatim geocoder (>): geocodes using theNominatimgeocoding service of the OpenStreetMap Founda-\ntion.\n•Processing algorithms (a): searches and opens a Processing algorithm dialog.\n•Edit selected features (ef): gives quick access and runs a compatiblemodify-in-placeProcessing algorithm on\nthe active layer.\nIn the dialog, you can:\n•customize the filterPrefix, i.e. the keyword to use to trigger the filter\n•set whether the filter isEnabled: the filter can be used in the searches and a shortcut is available in the locator\nbar menu\n•set whether the filter isDefault: a search not using a filter returns results from only the default filters categories.\n•Some filters provide a way to configure the number of results in a search.\nThe set of default locator filters can be extended by plugins, eg for OSM nominatim searches, direct database search-\ning, layer catalog searches, ...\n9.1. Options87\n\nQGIS Desktop 3.22 User Guide\n9.1.18Acceleration Settings\nOpenCL acceleration settings.\nFig. 9.20: Acceleration tab\nDepending on your hardware and software, you may have to install additional libraries to enable OpenCL acceleration.\n9.1.19Processing Settings\nTheProcessingtab provides you with general settings of tools and data providers that are used in the QGIS\nProcessing framework. More information atQGIS processing framework.\n88Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nFig. 9.21: Processing Settings tab in QGIS\n9.1.20Python Console Settings\nThePython Consolesettings help you manage and control the behavior of the Python editors (interactive console,\ncode editor,project macros,custom expressions, ...). It can also be accessed using the\nOptions...\nbutton from:\n•thePython consoletoolbar\n•the contextual menu of thePython consolewidget\n•and the contextual menu of the code editor.\n9.1. Options89\n\nQGIS Desktop 3.22 User Guide\nFig. 9.22: Python Console Settings tab\nYou can specify:\n•Autocompletion: Enables code completion. You can get autocompletion from the current document, the\ninstalled API files or both.\n–Autocompletion threshold: Sets the threshold for displaying the autocompletion list (in characters)\n•underTyping\n–Automatic parentheses insertion: Enables autoclosing for parentheses\n–Automatic insertion of the ‘import’ string on ‘from xxx’: Enables insertion of ‘import’ when specifying\nimports\n•underRun and Debug\n–Enable Object Inspector (switching between tabs may be slow): Enable the object inspector.\n–Auto-save script before running: Saves the script automatically when executed. This action will store\na temporary file (in the temporary system directory) that will be deleted automatically after running.\nForAPIsyou can specify:\n•Using preloaded APIs file: You can choose if you would like to use the preloaded API files. If this is not\nchecked you can add API files and you can also choose if you would like to use prepared API files (see next\noption).\n•Using prepared APIs file: If checked, the chosen*.papfile will be used for code completion. To generate\na prepared API file you have to load at least one*.apifile and then compile it by clicking theCompile APIs...\n90Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nbutton.\nUnderGitHub access token, you can generate a personal token allowing you to share code snippets from within the\nPython code editor. More details onGitHub authentication\n9.1.21Code Editor Settings\nIn theCode Editortab, you can control the appearance and behaviour of code editor widgets (Python interactive\nconsole and editor, expression widget and function editor, ...).\nFig. 9.23: Code Editor Settings tab\nAt the top of the dialog, a widget provides a live preview of the current settings, in various coding languages (Python,\nQGIS expression, HTML, SQL, JavaScript). A convenient way to adjust settings.\n•CheckOverride code editor fontto modify the defaultFontfamily andSize.\n•Under theColorsgroup, you can:\n–select aColor scheme: predefined settings areDefault,Solarized  DarkandSolarized\nLight. ACustomscheme is triggered as soon as you modify a color and can be reset with select-\ning a predefined scheme.\n–change thecolorof each element in code writing, such as the colors to use for comments, quotes, func-\ntions, background, ...\n9.1. Options91\n\nQGIS Desktop 3.22 User Guide\n9.1.22Advanced Settings\nFig. 9.24: Advanced Settings tab in QGIS\nAll the settings related to QGIS (UI, tools, data providers, Processing configurations, default values and paths, plu-\ngins options, expressions, geometry checks...) are saved in aQGIS/QGIS3.inifile under the activeuser profile\ndirectory. Configurations can be shared by copying this file to other installations.\nFrom within QGIS, theAdvancedtab offers a way to manage these settings through theAdvanced Settings Editor.\nAfter you promise to be careful, the widget is populated with a tree of all the existing settings, and you can edit their\nvalue. Right-click over a setting or a group and you can delete it (to add a setting or group, you have to edit the\nQGIS3.inifile). Changes are automatically saved in theQGIS3.inifile.\nWarning: Avoid using the Advanced tab settings blindly\nBe careful while modifying items in this dialog given that changes are automatically applied. Doing changes\nwithout knowledge can break your QGIS installation in various ways.\n9.2Working with User Profiles\nTheSettings►User Profilesmenu provides functions to set and access user profiles. A user profile is a unified\napplication configuration that allows to store in a single folder:\n•all theglobal settings, including locale, projections, authentication settings, color palettes, shortcuts...\n•GUI configurations andcustomization\n•grid files and other proj helper files installed for datum transformation\n•installedpluginsand their configurations\n•project templates and history of saved project with their image preview\n92Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n•processing settings, logs, scripts, models.\nBy default, a QGIS installation contains a single user profile nameddefault. But you can create as many user\nprofiles as you want:\n1.Click theNew profile...entry.\n2.You’ll be prompted to provide a profile name, creating a folder of the same name under~/\n<UserProfiles>/where:\n•~represents theHOMEdirectory, which onWindows is usually something likeC:\\Users\\\n<username>.\n•and<UserProfiles>represents the main profiles folder, i.e.:\n–.local/share/QGIS/QGIS3/profiles/\n–%AppData%\\Roaming\\QGIS\\QGIS3\\profiles\\\n–Library/Application Support/QGIS/QGIS3/profiles/\nThe user profile folder can be opened from within QGIS using theOpen Active Profile Folder.\n3.A new instance of QGIS is started, using a clean configuration. You can then set your custom configurations.\nIf you have more than one profile in your QGIS installation, the name of the active profile is shown in the application\ntitle bar between square brackets.\nAs each user profile contains isolated settings, plugins and history they can be great for different workflows, demos,\nusers of the same machine, or testing settings, etc. And you can switch from one to the other by selecting them in\ntheSettings►User Profilesmenu. You can also run QGIS with a specific user profile from the\ncommand line.\nUnless changed, the profile of the last closed QGIS session will be used in the following QGIS sessions.\nTip: Run QGIS under a new user profile to check for bug persistence\nWhen you encounter weird behavior with some functions in QGIS, create a new user profile and run the commands\nagain. Sometimes, bugs are related to some leftovers in the current user profile and creating a new one may fix them\nas it restarts QGIS with the new (clean) profile.\n9.3Project Properties\nIn the properties window for the project underProject►Project Properties, you can set project-specific options. The\nproject-specific options overwrite their equivalent in theOptionsdialog described above.\n9.3.1General Properties\nIn theGeneraltab, theGeneral settingslet you:\n•see the location of the project file\n•set the folder for the project home (available in theProject homeitem of theBrowserpanel). The path can be\nrelative to the folder of the project file (type it in) or absolute. The project home can be used for storing data\nand other content that is useful for the project. Convenient when dataset and project files are not stored at the\nsame place. If not filled, theProject homedefaults to the project file folder.\n•give a title to the project beside the project file path\n•choose the color to use for features when they are selected\n•choose the background color: the color to use for the map canvas\n9.3. Project Properties93\n\nQGIS Desktop 3.22 User Guide\n•set whether the path to layers in the project should be saved as absolute (full) or as relative to the project file\nlocation. You may prefer relative path when both layers and project files can be moved or shared or if the\nproject is accessed from computers on different platforms.\n•choose to avoid artifacts when project is rendered as map tiles. Note that checking this option can lead to\nperformance degradation.\nCalculating areas and distances is a common need in GIS. However, these values are really tied to the underlying\nprojection settings. TheMeasurementsframe lets you control these parameters. You can indeed choose:\n•theEllipsoid, on which distance and area calculations are entirely based; it can be:\n–None/Planimetric: returned values are in this case cartesian measurements.\n–aCustomone: you’ll need to set values of the semi-major and semi-minor axes.\n–or an existing one from a predefined list (Clarke 1866, Clarke 1880 IGN, New International 1967, WGS\n84...).\n•theunits for distance measurementsfor length and perimeter and theunits for area measurements. These\nsettings, which default to the units set in QGIS options but then overrides it for the current project, are used in:\n–Attribute table field update bar\n–Field calculator calculations\n–Identify tool derived length, perimeter and area values\n–Default unit shown in measure dialog\nTheCoordinate and Bearing displayallows you to choose and customize the bearing format and the format of units\nto use to display the mouse coordinate in the status bar and the derived coordinates shown via the identify tool.\n94Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nFig. 9.25: General tab of the Project Properties dialog\n9.3.2Metadata Properties\nTheMetadatatab allows detailed metadata to be defined, including (among the others): author, creation date,\nlanguage, abstracts, categories, keywords, contact details, links, history. There is also a validation functionality that\nchecks if specific fields were filled, anyway this is not enforced. Seevector layer metadata propertiesfor some details.\n9.3. Project Properties95\n\nQGIS Desktop 3.22 User Guide\n9.3.3View Settings\nFig. 9.26: View Settings tab of the Project Properties dialog\nTheView Settingstab provides means to control the project map canvas. You can:\n•setProject predefined scales: the list of scales to display in the status barScaledrop-down widget. This overrides\nthe global predefined scales.\n•Set Project full Extent: this extent will be used instead of the extent of all layers when zooming to full map\nextent (\n). It’s useful when a project contains web layers/national layers/global layers yet the actual area of\ninterest for the project is a smaller geographic area. The project full extent coordinates can be set with the\nextent selectorwidget.\n9.3.4CRS Properties\nNote:For more information on how QGIS handles project projection, please read the dedicated section atWorking\nwith Projections.\nTheCRStab helps you set the coordinate reference system to use in this project. It can be:\n•No CRS (or unknown/non-Earth projection): layers are drawn based on their raw coordinates\n•or an existing coordinate reference system that can begeographic,projectedoruser-defined. Layers added to\nthe project are translated on-the-fly to this CRS in order to overlay them regardless their original CRS.\n96Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n9.3.5Transformations Properties\nTheTransformationstab helps you control the layers reprojection settings by configuring the datum transfor-\nmation preferences to apply in the current project. As usual, these override any corresponding global settings. See\nDatum Transformationsfor more details.\n9.3.6Default Styles Properties\nTheDefault Stylestab lets you control how new layers will be drawn in the project when they do not have an\nexisting.qmlstyle defined. You can:\n•Set default symbols (Marker,Line,Fill) to apply depending on the layer geometry type as well as a defaultColor\nRamp\n•Apply a defaultOpacityto new layers\n•Assign random colors to symbols, modifying the symbols fill colors, hence avoiding same rendering for all\nlayers.\nFig. 9.27: Default Styles tab\nUsing theStyle Managerbutton, you can also quickly access theStyle Managerdialog and configure symbols and\ncolor ramps.\nThere is also an additional section where you can define specific colors for the running project. Like theglobal colors,\nyou can:\n•AddorRemovecolor\n•CopyorPastecolor\n9.3. Project Properties97\n\nQGIS Desktop 3.22 User Guide\n•ImportorExportthe set of colors from/to.gplfile.\nDouble-click a color in the list to tweak or replace it in theColor Selectordialog. You can also rename it by double-\nclicking in theLabelcolumn.\nThese colors are identified asProject colorsand listed as part ofcolor widgets.\nTip: Use project colors to quickly assign and update color widgets\nProject colors can be refered to using their label and the color widgets they are used in are bound to them. This means\nthat instead of repeatedly setting the same color for many properties and, to avoid a cumbersome update you can:\n1.Define the color as a project color\n2.Click thedata defined override widgetnext to the color property you want to set\n3.Hover over theColormenu and select the project color.  The property is then assigned the expression\nproject_color('color_label')and the color widget reflects that color.\n4.Repeat steps 2 and 3 as much as needed\n5.Update the project color once and the change is reflected EVERYWHERE it’s in use.\n9.3.7Data Sources Properties\nIn theData Sourcestab, you can:\n•Automatically create transaction groups where possible: When this mode is turned on, all layers from the\nsame database are synchronised in their edit state, i.e. when one layer is put into edit state, all are, when one\nlayer is committed or one layer is rolled back, so are the others. Also, instead of buffering edit changes locally,\nthey are directly sent to a transaction in the database which gets committed when the user clicks save layer.\nNote that you can (de)activate this option only if no layer is being edited in the project.\n•Evaluate default values on provider side: When adding new features in a PostgreSQL table, fields with\ndefault value constraint are evaluated and populated at the form opening, and not at the commit moment.\nThis means that instead of an expression likenextval('serial'), the field in theAdd Featureform will\ndisplay expected value (e.g.,25).\n•Trust project when data source has no metadata: To speed up project loading by skipping data checks.\nUseful in QGIS Server context or in projects with huge database views/materialized views. The extent of layers\nwill be read from the QGIS project file (instead of data sources) and when using the PostgreSQL provider the\nprimary key unicity will not be checked for views and materialized views.\n•Configure theLayers Capabilities, i.e.:\n–Set (or disable) which layers areidentifiable, i.e. will respond to theidentify tool. By default,\nlayers are set queryable.\n–Set whether a layer should appear asread-only, meaning that it can not be edited by the user, regard-\nless of the data provider’s capabilities. Although this is a weak protection, it remains a quick and handy\nconfiguration to avoid end-users modifying data when working with file-based layers.\n–Define which layers aresearchable, i.e. could be queried using thelocator widget. By default, layers\nare set searchable.\n–Define which layers are defined asrequired. Checked layers in this list are protected from inadvertent\nremoval from the project.\n–Define which layers areprivate, i.e. hidden from theLayerspanel. This is meant for accessory layers\n(basemap, join, lookups for value-relations, most probably aspatial layers, ...) that you still need in a\nproject but you don’t want them to pollute the legend tree and other layer selection tools. If set visible,\nthey are still displayed in the map canvas and rendered in the print layout legend. Use theFilter\n98Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nlegend►Show private layersoption in theLayerspanel top toolbar to temporarily turned them on for\nany interaction.\nTheLayers Capabilitiestable provides some convenient tools to:\n–Select multiple cells and pressToggle Selectionto have them change their checkbox state;\n–Show spatial layers only, filtering out non-spatial layers from the layers list;\n–Filter layers...and quickly find a particular layer to configure.\nFig. 9.28: Data Sources tab\n9.3.8Relations Properties\nTheRelationstab is used to define 1:n relations and polymorphic relations. The relations are defined in the\nproject properties dialog. Once relations exist for a layer, a new user interface element in the form view (e.g. when\nidentifying a feature and opening its form) will list the related entities. This provides a powerful way to express e.g.\nthe inspection history on a length of pipeline or road segment. You can find out more about 1:n relations support in\nSectionCreating one or many to many relations.\n9.3. Project Properties99\n\nQGIS Desktop 3.22 User Guide\nFig. 9.29: Relations tab\n9.3.9Variables Properties\nTheVariablestab lists all the variables available at the project’s level (which includes all global variables). Besides,\nit also allows the user to manage project-level variables. Click the\nbutton to add a new custom project-level\nvariable. Likewise, select a custom project-level variable from the list and click thebutton to remove it. More\ninformation on variables usage in the General Tools\nStoring values in Variablessection.\n9.3.10Macros Properties\nTheMacrostab is used to edit Python macros for projects. Currently, only three macros are available:open-\nProject(),saveProject()andcloseProject().\n100Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nFig. 9.30: Macro settings in QGIS\n9.3.11QGIS Server Properties\nTheQGIS Servertab allows you to configure your project in order to publish it online. Here you can define\ninformation about the QGIS Server WMS and WFS capabilities, extent and CRS restrictions. More information\navailable in section Creatingwmsfromproject and subsequent.\n9.3. Project Properties101\n\nQGIS Desktop 3.22 User Guide\nFig. 9.31: QGIS Server settings tab\n9.3.12Temporal Properties\nTheTemporaltab is used to set the temporal range of your project, either by using manualStart dateandEnd\ndateinputs or by calculating it from the current project temporal layers. The project time range can then be used in\ntheTemporal controller panelto manage the map canvas\ntemporal navigation.\nFig. 9.32: Project Temporal tab\n102Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n9.4Customization\nTheCustomizationdialog lets you (de)activate almost every element in the QGIS user interface. This can be very\nuseful if you want to provide your end-users with a ‘light’ version of QGIS, containing only the icons, menus or panels\nthey need.\nNote:Before your changes are applied, you need to restart QGIS.\nFig. 9.33: The Customization dialog\nTicking theEnable customizationcheckbox is the first step on the way to QGIS customization. This enables the\ntoolbar and the widget panel from which you can uncheck and thus disable some GUI items.\nThe configurable item can be:\n•aMenuor some of its sub-menus from theMenu Bar\n•a wholePanel(seePanels and Toolbars)\n9.4. Customization103\n\nQGIS Desktop 3.22 User Guide\n•theStatus bardescribed inStatus Baror some of its items\n•aToolbar: the whole bar or some of its icons\n•or anywidgetfrom any dialog in QGIS: label, button, combobox...\nWith\nSwitch to catching widgets in main application\n, you can click on an item in QGIS interface that you want to be hidden\nand QGIS automatically unchecks the corresponding entry in the Customization dialog. You can also use theSearch\nbox to find items by their name or label.\nOnce you setup your configuration, clickApplyorOKto validate your changes. This configuration becomes the one\nused by default by QGIS at the next startup.\nThe modifications can also be saved in a.inifile using\nSave To File\nbutton. This is a handy way to share a common\nQGIS interface among multiple users. Just click on\nLoad from File\nfrom the destination computer in order to import\nthe.inifile. You can also runcommand line toolsand save various setups for different use cases as well.\nTip: Easily restore predefined QGIS\nThe initial QGIS GUI configuration can be restored by one of the methods below:\n•uncheckingEnable customizationoption in the Customization dialog or click the\nCheck All\nbutton\n•pressing theResetbutton in theSettingsframe underSettings►Optionsmenu,Systemtab\n•launching QGIS at a command prompt with the following command lineqgis --nocustomization\n•settingtofalsethevalueofUI►Customization►EnabledvariableunderSettings►Optionsmenu,Advanced\ntab (see the\nwarning).\nIn most cases, you need to restart QGIS in order to have the change applied.\n9.5Keyboard shortcuts\nQGIS provides default keyboard shortcuts for many features. You can find them in sectionMenu Bar. Additionally,\nthe menu optionSettings►\nKeyboard Shortcuts...allows you to change the default keyboard shortcuts and add\nnew ones to QGIS features.\n104Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nFig. 9.34: Define shortcut options\nConfiguration is very simple. Use the search box at the top of the dialog to find a particular action, select it from the\nlist and click on :\n•Changeand press the new combination you want to assign as new shortcut\n•Set Noneto clear any assigned shortcut\n•orSet Defaultto backup the shortcut to its original and default value.\nProceed as above for any other tools you wish to customize. Once you have finished your configuration, simplyClose\nthe dialog to have your changes applied. You can alsoSavethe changes either as an.XMLfile with only the User\nShortcuts or with all Shortcuts or as an.PDFfile with all Shortcuts andLoadthem into another QGIS installation.\n9.6Running QGIS with advanced settings\n9.6.1Command line and environment variables\nWe’ve seen thatlaunching QGISis done as for any application on your OS. QGIS provides command line options for\nmore advanced use cases (in some cases you can use an environment variable instead of the command line option).\nTo get a list of the options, enterqgis --helpon the command line, which returns:\nQGISisa user friendly Open Source Geographic Information System.\nUsage:/usr/bin/qgis.bin [OPTION] [FILE]\nOPTION:\n(continues on next page)\n9.6. Running QGIS with advanced settings105\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n[--version]display version informationandexit\n[--snapshot filename]   emit snapshot of loaded datasets to given file\n[--width width] width of snapshot to emit\n[--height height]height of snapshot to emit\n[--lang language]use languageforinterface text (changes existing␣\n,→override)\n[--project projectfile] load the given QGIS project\n[--extent xmin,ymin,xmax,ymax]setinitialmapextent\n[\n--nologo]hide splash screen\n[--noversioncheck]don't check for new version of QGIS at startup\n[--noplugins]   don't restore plugins on startup\n[--nocustomization]don't apply GUI customization\n[--customizationfile path]use the given ini fileasGUI customization\n[--globalsettingsfile path]use the given ini fileasGlobal Settings␣\n,→(defaults)\n[\n--authdbdirectory path] use the given directoryforauthentication␣\n,→database\n[--code path]   run the given python file on load\n[--defaultui]   start by resetting user ui settings to default\n[--hide-browser]hide the browser widget\n[--dxf-export filename.dxf]     emit dxf output of loaded datasets to␣\n,→given file\n[--dxf-extent xmin,ymin,xmax,ymax]setextent to export to dxf\n[--dxf-symbology-mode none|symbollayer|feature] symbology modefordxf␣\n,→output\n[\n--dxf-scale-denom scale]scalefordxf output\n[--dxf-encoding encoding]encoding to usefordxf output\n[--dxf-map-theme maptheme]maptheme to usefordxf output\n[--take-screenshots output_path]take screen shotsforthe user␣\n,→documentation\n[--screenshots-categories categories]   specify the categories of␣\n,→screenshot to be used (see QgsAppScreenShots::Categories).\n[--profile name]load a named profilefromtheuser's profiles␣\n,→folder.\n[--profiles-path path]  path to store user profile folders.Will create␣\n,→profiles inside a {path}\\profiles folder\n[\n--version-migration]   force the settings migrationfromolderversionif␣\n,→found\n[--openclprogramfolder]path to the folder containing the sources␣\n,→forOpenCL programs.\n[--help]this text\n[--]treatallfollowing argumentsasFILEs\nFILE:\nFiles specified on the command line can include rasters,\nvectors,andQGIS project files (.qgsand.qgz):\n1.Rasters-supported formats include GeoTiff, DEM\nandothers supported by GDAL\n2.Vectors-supported formats include ESRI Shapefiles\nandothers supported by OGRandPostgreSQL layers using\nthe PostGIS extension\nTip: Example Using command line arguments\nYou can start QGIS by specifying one or more data files on the command line. For example, assuming you are in the\nqgis_sample_datadirectory, you could start QGIS with a vector layer and a raster file set to load on startup\nusing the following command:qgis ./raster/landcover.img ./gml/lakes.gml\n106Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n--version\nThis option returns QGIS version information.\n--snapshot\nThis option allows you to create a snapshot in PNG format from the current view. This comes in handy when you\nhave many projects and want to generate snapshots from your data, or when you need to create snapshots of the same\nproject with updated data.\nCurrently, it generates a PNG file with 800x600 pixels. The size can be adjusted using the--widthand--height\narguments. The filename can be added after--snapshot. For example:\nqgis--snapshot my_image.png--width1000--height600--project my_project.qgs\n--width\nThis option returns the width of the snapshot to be emitted (used with--snapshot).\n--height\nThis option returns the height of the snapshot to be emitted (used with--snapshot).\n--lang\nBased on your locale, QGIS selects the correct localization. If you would like to change your language, you can\nspecify a language code. For example,qgis --lang itstarts QGIS in Italian localization.\n--project\nStarting QGIS with an existing project file is also possible. Just add the command line option--projectfollowed\nby your project name and QGIS will open with all layers in the given file loaded.\n--extent\nTo start with a specific map extent use this option. You need to add the bounding box of your extent in the following\norder separated by a comma:\n--extent xmin,ymin,xmax,ymax\nThis option probably makes more sense when paired with the--projectoption to open a specific project at the\ndesired extent.\n--nologo\nThis option hides the splash screen when you start QGIS.\n9.6. Running QGIS with advanced settings107\n\nQGIS Desktop 3.22 User Guide\n--noversioncheck\nSkip searching for a new version of QGIS at startup.\n--noplugins\nIf you have trouble at start-up with plugins, you can avoid loading them at start-up with this option. They will still be\navailable from the Plugins Manager afterwards.\n--nocustomization\nUsing this option, any existingGUI customizationwill not be applied at startup. This means that any hidden buttons,\nmenu items, toolbars, and so on, will show up on QGIS start up. This is not a permanent change. The customization\nwill be applied again if QGIS is launched without this option.\nThis option is useful for temporarily allowing access to tools that have been removed by customization.\n--customizationfile\nUsing this option, you can define a UI customization file, that will be used at startup.\n--globalsettingsfile\nThe equivalent environment variable isQGIS_GLOBAL_SETTINGS_FILE.\nUsing this option, you can specify the path for a Global Settings file (.ini), also known as the Default Settings. The\nsettings in the specified file replace the original inline default ones, but the user profiles’ settings will be set on top of\nthose.\nQGIS looks for the default global settings file in the following order and only the first found file will be used:\n•path specified by the commandline parameter\n•path defined by the environment variable\n•the AppDataLocation folder, where persistent application data can be stored; it is managed by the user or\nsystem administrator and is not touched by installer and does not require any additional setup like passing\ncommandline parameters or settings environment variable. Depending on the OS, it is:\n–$HOME/.local/share/QGIS/QGIS3/\n–C:\\Users\\<username>\\%AppData%\\Roaming\\QGIS\\QGIS3\\\n–$HOME/Library/Application Support/QGIS/QGIS3/\n•the    installation    directory,i.e.your_QGIS_package_path/resources/\nqgis_global_settings.ini.\nPresently, there’s no way to specify a file to write settings to; therefore, you can create a copy of an original settings\nfile, rename, and adapt it.\nSetting theqgis_global_setting.inifile path to a network shared folder, allows a system administrator to\nchange global settings and defaults in several machines by only editing one file.\n108Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\n--authdbdirectory\nThis option is similar to--globalsettingsfile, but defines the path to the directory where the authentication\ndatabase will be stored and loaded.\n--code\nThis option can be used to run a given python file directly after QGIS has started.\nFor example, when you have a python file namedload_alaska.pywith following content:\nfromqgis.utilsimportiface\nraster_file=\"/home/gisadmin/Documents/qgis_sample_data/raster/landcover.img\"\nlayer_name=\"Alaska\"\niface.addRasterLayer(raster_file, layer_name)\nAssuming you are in the directory where the fileload_alaska.pyis located, you can start QGIS, load the raster\nfilelandcover.imgand give the layer the name ‘Alaska’ using the following command:\nqgis--code load_alaska.py\n--defaultui\nOn load,permanently resetsthe user interface (UI) to the default settings. This option will restore the panels and\ntoolbars visibility, position, and size. Unless it’s changed again, the default UI settings will be used in the following\nsessions.\nNotice that this option doesn’t have any effect onGUI customization. Items hidden by GUI customization (e.g. the\nstatus bar) will remain hidden even using the--defaultuioption. See also the--nocustomizationoption.\n--hide-browser\nOn load, hides theBrowserpanel from the user interface. The panel can be enabled by right-clicking a space in the\ntoolbars or using theView►Panels(Settings►PanelsinLinux KDE).\nUnless it’s enabled again, the Browser panel will remain hidden in the following sessions.\n--dxf-*\nThese options can be used to export a QGIS project into a DXF file. Several options are available:\n•–dxf-export: the DXF filename into which to export the layers;\n•–dxf-extent: the extent of the final DXF file;\n•–dxf-symbology-mode: several values can be used here:none(no symbology),symbollayer(Symbol layer\nsymbology),feature(feature symbology);\n•–dxf-scale-denom: the scale denominator of the symbology;\n•–dxf-encoding: the file encoding;\n•–dxf-map-theme: choose amap themefrom the layer tree configuration.\n9.6. Running QGIS with advanced settings109\n\nQGIS Desktop 3.22 User Guide\n--take-screenshots\nTakes screenshots for the user documentation. Can be used together with--screenshots-categories\nto filter which categories/sections of the documentation screenshots should be created (see QgsAppScreen-\nShots::Categories).\n--profile\nLoads QGIS using a specific profile from the user’s profile folder. Unless changed, the selected profile will be used\nin the following QGIS sessions.\n--profiles-path\nWith this option, you can choose a path to load and save the profiles (user settings). It creates profiles inside a\n{path}\\profilesfolder, which includes settings, installed plugins, processing models and scripts, and so on.\nThis option allows you to, for instance, carry all your plugins and settings in a flash drive, or, for example, share the\nsettings between different computers using a file sharing service.\nThe equivalent environment variable isQGIS_CUSTOM_CONFIG_PATH.\n--version-migration\nIf settings from an older version are found (e.g., the.qgis2folder from QGIS 2.18), this option will import them\ninto the default QGIS profile.\n--openclprogramfolder\nUsing this option, you can specify an alternative path for your OpenCL programs. This is useful for developers while\ntesting new versions of the programs without needing to replace the existing ones.\nThe equivalent environment variable isQGIS_OPENCL_PROGRAM_FOLDER.\n9.6.2Deploying QGIS within an organization\nIf you need to deploy QGIS within an organization with a custom configuration file, first you need to\ncopy/paste the content of the default settings file located inyour_QGIS_package_path/resources/\nqgis_global_settings.ini. This file already contains some default sections identified by a block starting\nwith[]. We recommend that you keep these defaults values and add your own sections at the bottom of the file. If\na section is duplicated in the file, QGIS will take the last one from top to bottom.\nYou can changeallowVersionCheck=falseto disable the QGIS version check.\nIf you do not want to display the migration window after a fresh install, you need the following section:\n[migration]\nfileVersion=2\nsettings=true\nIf you want to add a custom variable in the global scope:\n[variables]\norganisation=\"Your organization\"\n110Chapter 9. QGIS Configuration\n\nQGIS Desktop 3.22 User Guide\nTo discover the possibilities of the settingsINIfile, we suggest that you set the config you would like in QGIS Desktop\nand then search for it in yourINIfile located in your profile using a text editor. A lot of settings can be set using the\nINIfile such as WMS/WMTS, PostGIS connections, proxy settings, maptips...\nFinally, you need to set the environment variableQGIS_GLOBAL_SETTINGS_FILEto the path of your cus-\ntomized file.\nIn addition, you can also deploy files such as Python macros, color palettes, layout templates, project templates...\neither in the QGIS system directory or in the QGIS user profile.\n•Layout templates must be deployed in thecomposer_templatesdirectory.\n•Project templates must be deployed in theproject_templatesdirectory.\n•Custom Python macros must be deployed in thepythondirectory.\n9.6. Running QGIS with advanced settings111\n\nQGIS Desktop 3.22 User Guide\n112Chapter 9. QGIS Configuration\n\nCHAPTER\nTEN\nWORKING WITH PROJECTIONS\nA Coordinate Reference System, or CRS, is a method of associating numerical coordinates with a position on the\nsurface of the Earth. QGIS has support for approximately 7,000 standard CRSs, each with different use cases, pros\nand cons! Choosing an appropriate reference system for your QGIS projects and data can be a complex task, but\nfortunately QGIS helps guide you through this choice, and makes working with different CRSs as transparent and\naccurate as possible.\n10.1Overview of Projection Support\nQGIS has support for approximately 7,000 known CRSs. These standard CRSs are based on those defined by the\nEuropean Petroleum Search Group (EPSG) and the Institut Geographique National de France (IGNF), and are made\navailable in QGIS through the underlying “Proj” projection library. Commonly, these standard projections are iden-\ntified through use of an authority:code combination, where the authority is an organisation name such as “EPSG” or\n“IGNF”, and the code is a unique number associated with a specific CRS. For instance, the common WGS 84 lati-\ntude/longitude CRS is known by the identifierEPSG:4326, and the web mapping standard CRS isEPSG:3857.\nCustom, user-created CRSs are stored in a user CRS database. See section\nCustom Coordinate Reference Systemfor\ninformation on managing your custom coordinate reference systems.\n10.2Layer Coordinate Reference Systems\nIn order to correctly project data into a specific target CRS, either your data must contain information about its\ncoordinate reference system or you will need to manually assign the correct CRS to the layer. For PostGIS layers,\nQGIS uses the spatial reference identifier that was specified when that PostGIS layer was created. For data supported\nby OGR or GDAL, QGIS relies on the presence of a recognized means of specifying the CRS. For instance, for the\nShapefile format this is a file containing an ESRI Well-Known Text (WKT) representation of the layer’s CRS. This\nprojection file has the same base name as the.shpfile and a.prjextension. For example,alaska.shpwould\nhave a corresponding projection file namedalaska.prj.\nWhenever a layer is loaded into QGIS, QGIS attempts to automatically determine the correct CRS for that layer.\nIn some cases this is not possible, e.g. when a layer has been provided without retaining this information. You can\nconfigure QGIS behavior whenever it cannot automatically determine the correct CRS for a layer:\n1.OpenSettings►Options...►CRS\n113\n\nQGIS Desktop 3.22 User Guide\nFig. 10.1: The CRS tab in the QGIS Options Dialog\n2.Under theCRS for layersgroup, set the action to dowhen a new layer is created, or when a layer is loaded that\nhas no CRS. One of:\n•Leave as unknown CRS (take no action): there will be no prompt to select a CRS when a layer without\nCRS is loaded, defering CRS choice to a later time. Convenient when loading a lot of layers at once. Such\nlayers will be identifiable in theLayerspanel by theicon next to them. They’ll also be un-referenced,\nwith coordinates from the layer treated as purely numerical, non-earth values, i.e. the same behavior as\nall layers get whena project is set to have no CRS.\n•Prompt for CRS: it will prompt you to manually select the CRS. Selecting the correct choice is\ncrucial, as a wrong choice will place your layer in the wrong position on the Earth’s surface! Sometimes,\naccompanying metadata will describe the correct CRS for a layer, in other cases you will need to contact\nthe original author of the data to determine the correct CRS to use.\n•Use project CRS\n•Use default layer CRS, as set in theDefault CRS for layerscombobox above.\nTip:To assign the same CRS to multiple layers that have no crs or have a wrong one in one operation:\n1.Select the layers in theLayerspanel\n2.PressCtrl+Shift+C. You could also right-click over one of the selected layers or go toLayer►Set CRS\nof layer(s)\n3.Find and select the right CRS to use\n4.And pressOK. You can confirm that it has been set correctly in theSourcetab of the layers’ properties dialog.\nNote that changing the CRS in this setting does not alter the underlying data source in any way, rather it just changes\nhow QGIS interprets the raw coordinates from the layer in the current QGIS project.\n114Chapter 10. Working with Projections\n\nQGIS Desktop 3.22 User Guide\n10.3Project Coordinate Reference Systems\nEvery project in QGIS also has an associated Coordinate Reference System. The project CRS determines how data\nis projected from its underlying raw coordinates to the flat map rendered within your QGIS map canvas.\nQGIS supports “on the fly” CRS transformation for both raster and vector data. This means that regardless of the\nunderlying CRS of particular map layers in your project, they will always be automatically transformed into the\ncommon CRS defined for your project. Behind the scenes, QGIS transparently reprojects all layers contained within\nyour project into the project’s CRS, so that they will all be rendered in the correct position with respect to each other!\nIt is important to make an appropriate choice of CRS for your QGIS projects. Choosing an inappropriate CRS can\ncause your maps to look distorted, and poorly reflect the real-world relative sizes and positions of features. Usually,\nwhile working in smaller geographic areas, there will be a number of standard CRSs used within a particular country\nor administrative area. It’s important to research which CRSs are appropriate or standard choices for the area you\nare mapping, and ensure that your QGIS project follows these standards.\nBy default, QGIS starts each new project using a global default projection. This default CRS isEPSG:4326(also\nknown as “WGS 84”), and it is a global latitude/longitude based reference system. This default CRS can be changed\nvia theCRS for New Projectssetting in theCRStab underSettings►\nOptions...(seeFig. 10.1). There is an option to\nautomatically set the project’s CRS to match the CRS of the first layer loaded into a new project, or alternatively you\ncan select a different default CRS to use for all newly created projects. This choice will be saved for use in subsequent\nQGIS sessions.\nThe project CRS can also be set through theCRStab of theProject►Properties...dialog. It will also be shown in the\nlower-right of the QGIS status bar.\nFig. 10.2: Project Properties Dialog\nAvailable options are:\n•No CRS (or unknown/non-Earth projection): Checking this setting will disable ALL projection handling\nwithin the QGIS project, causing all layers and map coordinates to be treated as simple 2D Cartesian coor-\ndinates, with no relation to positions on the Earth’s surface. It can be used to guess a layer CRS (based on\n10.3. Project Coordinate Reference Systems115\n\nQGIS Desktop 3.22 User Guide\nits raw coordinates or when using QGIS for non earth uses like role-playing game maps, building mapping or\nmicroscopic stuff. In this case:\n–No reprojection is done while rendering the layers: features are just drawn using their raw coordinates.\n–The ellipsoid is locked out and forced toNone/Planimetric.\n–The distance and area units, and the coordinate display are locked out and forced to “unknown units”; all\nmeasurements are done in unknown map units, and no conversion is possible.\n•or an existing coordinate reference system that can begeographic,projectedoruser-defined. A preview of\nthe CRS extent on earth is displayed to help you select the appropriate one. Layers added to the project are\ntranslated on-the-fly to this CRS in order to overlay them regardless their original CRS. Use of units and\nellipsoid setting are available and make sense and you can perform calculations accordingly.\nWhenever you select a new CRS for your QGIS project, the measurement units will automatically be changed in the\nGeneraltab of theProject propertiesdialog (Project►Properties...) to match the selected CRS. For instance, some\nCRSs define their coordinates in feet instead of meters, so setting your QGIS project to one of these CRSs will also\nset your project to measure using feet by default.\nTip: Setting the project CRS from a layer\nYou can assign a CRS to the project using a layer CRS:\n1.In theLayerspanel, right-click on the layer you want to pick the CRS\n2.SelectSet project CRS from Layer.\nThe project’s CRS is redefined using the layer’s CRS. Map canvas extent, coordinates display are updated accordingly\nand all the layers in the project are on-the-fly translated to the new project CRS.\n10.4Coordinate Reference System Selector\nThis dialog helps you assign a Coordinate Reference System to a project or a layer, provided a set of projection\ndatabases. Items in the dialog are:\n•Filter: If you know the EPSG code, the identifier, or the name for a Coordinate Reference System, you can\nuse the search feature to find it. Enter the EPSG code, the identifier or the name.\n•Recently used coordinate reference systems: If you have certain CRSs that you frequently use in your\neveryday GIS work, these will be displayed in this list. Click on one of these items to select the associated\nCRS.\n•Coordinate reference systems of the world: This is a list of all CRSs supported by QGIS, including Ge-\nographic, Projected and Custom coordinate reference systems. To define a CRS, select it from the list by\nexpanding the appropriate node and selecting the CRS. The active CRS is preselected.\n•PROJ text: This is the CRS string used by the PROJ projection engine. This text is read-only and provided\nfor informational purposes.\nThe CRS selector also shows a rough preview of the geographic area for which a selected CRS is valid for use. Many\nCRSs are designed only for use in small geographic areas, and you should not use these outside of the area they were\ndesigned for. The preview map shades an approximate area of use whenever a CRS is selected from the list. In\naddition, this preview map also shows an indicator of the current main canvas map extent.\n116Chapter 10. Working with Projections\n\nQGIS Desktop 3.22 User Guide\n10.5Custom Coordinate Reference System\nIf QGIS does not provide the coordinate reference system you need, you can define a custom CRS. To define a CRS,\nselectCustom CRS...from theSettingsmenu. Custom CRSs are stored in your QGIS user database. In addition\nto your custom CRSs, this database also contains your spatial bookmarks and other custom data.\nDefining a custom CRS in QGIS requires a good understanding of the PROJ projection library. To begin, refer to\n“Cartographic Projection Procedures for the UNIX Environment - A User’s Manual” by Gerald I. Evenden, U.S.\nGeological Survey Open-File Report 90-284, 1990 (available athttps://pubs.usgs.gov/of/1990/of90-284/ofr90-284.\npdf).\nThis manual describes the use ofprojand related command line utilities. The cartographic parameters used with\nprojare described in the user manual and are the same as those used by QGIS.\nTheCustom Coordinate Reference System Definitiondialog requires only two parameters to define a user CRS:\n1.A descriptive name\n2.The cartographic parameters in PROJ or WKT format\nTo create a new CRS:\n1.Click the\nAdd new CRS\nbutton\n2.Enter a descriptive name\n3.Select the format: it can beProj StringorWKT\n4.Add the CRSParameters.\nNote: Prefer storing the CRS definition in WKT format\nAlthough bothProj StringandWKTformats are supported, it’s highly recommended to store projection\ndefinitions in the WKT format. Therefore, if the available definition is in the proj format, select that format,\nenter the parameters and then switch to WKT format. QGIS will convert the definition to the WKT format\nthat you can later save.\n5.ClickValidateto test whether the CRS definition is an acceptable projection definition.\n10.5. Custom Coordinate Reference System117\n\nQGIS Desktop 3.22 User Guide\nFig. 10.3: Custom CRS Dialog\nYou can test your CRS parameters to see if they give sane results. To do this, enter known WGS 84 latitude and\nlongitude values inNorthandEastfields, respectively. Click onCalculate, and compare the results with the known\nvalues in your coordinate reference system.\n10.5.1Integrate an NTv2-transformation in QGIS\nTo integrate an NTv2 transformation file in QGIS you need one more step:\n1.Place the NTv2 file (.gsb) in the CRS/Proj folder that QGIS uses (e.g.C:\\OSGeo4W64\\share\\projfor\nwindows users)\n2.Addnadgrids(+nadgrids=nameofthefile.gsb) to the Proj definition in theParametersfield of the\nCustom Coordinate Reference System Definition(Settings►Custom Projections...).\nFig. 10.4: Setting an NTv2 transformation\n118Chapter 10. Working with Projections\n\nQGIS Desktop 3.22 User Guide\n10.6Datum Transformations\nIn QGIS, ‘on-the-fly’ CRS transformation is enabled by default, meaning that whenever you use layers with different\ncoordinate systems QGIS transparently reprojects them to the project CRS. For some CRS, there are a number of\npossible transforms available to reproject to the project’s CRS!\nBy default, QGIS will attempt to use the most accurate transformation available. However, in some cases this may not\nbe possible, e.g. whenever additional support files are required to use a transformation. Whenever a more accurate\ntransformation is available, but is not currently usable, QGIS will show an informative warning message advising\nyou of the more accurate transformation and how to enable it on your system. Usually, this requires download of\nan external package of transformation support files, and extracting these to theprojfolder under your QGISuser\nprofilefolder.\nIf desired, QGIS can also prompt you whenever multiple possible transformations can be made between two CRSs,\nand allow you to make an informed selection of which is the most appropriate transformation to use for your data.\nThis customization is done in theSettings►Options►Transformationstab menu under theDefault datum trans-\nformationsgroup:\n•usingAsk for datum transformation if several are available: when more than one appropriate datum trans-\nformation exist for a source/destination CRS combination, a dialog will automatically be opened prompting\nusers to choose which of these datum transformations to use for the project. If theMake defaultcheckbox\nis ticked when selecting a transformation from this dialog, then the choice is remembered and automatically\napplied to any newly created QGIS projects.\n•or defining a list of appropriate datum transformations to use as defaults when loading a layer to a project or\nreprojecting a layer.\nUse thebutton to open theSelect Datum Transformationsdialog. Then:\n1.Choose theSource CRSof the layer, using the drop-down menu or the\nSelect CRS\nwidget.\n2.Provide theDestination CRSin the same way.\n3.A list of available transformations from source to destination will be shown in the table. Clicking a row\nshows details on the settings applied and the corresponding accuracy and area of use of the transformation.\n10.6. Datum Transformations119\n\nQGIS Desktop 3.22 User Guide\nFig. 10.5: Selecting a preferred default datum transformation\nIn some cases a transformation may not be available for use on your system. In this case, the transfor-\nmation will still be shown (greyed) in this list but can not be picked until you install the required package\nof transformation support. Usually, a button is provided to download and install the corresponding grid,\nwhich is then stored under theprojfolder in the active\nuser profiledirectory.\n4.Find your preferred transformation and select it\n5.Set whether youAllow fallback transforms if preferred operation fails\n6.Click\nOK\n.\nA row is added to the table underDefault Datum Transformationswith information about theSource CRS,\ntheDestination CRS, theOperationapplied for the transformation and whetherAllow fallback Transforms\nis enabled.\nFrom now, QGIS automatically uses the selected datum transformations for further transformation between\nthese two CRSs until you remove it (\n) from the list or change the entry () in the list.\nDatum transformations set in theSettings►\nOptions►Transformationstab will be inherited by all new QGIS\nprojects created on the system. Additionally, a particular project may have its own specific set of transformations\nspecified via the\nCRS\ntab of the\nProject properties\ndialog (\nProject\n►\nProperties...\n). These settings apply to the current\nproject only.\n120Chapter 10. Working with Projections\n\nCHAPTER\nELEVEN\nGENERAL TOOLS\n11.1Context help\nWhenever you need help on a specific topic, you can access the corresponding page in the current User Manual via\ntheHelpbutton available in most dialogs — please note that third-party plugins can point to dedicated web pages.\n11.2Panels\nBy default, QGIS provides many panels to work with. Some of these panels are described below while others may\nbe found in different parts of the document. A complete list of default panels provided by QGIS is available via the\nView►Panels► menu and mentioned atPanels.\n11.2.1Layers Panel\nTheLayerspanel (also called themap legend) lists all the layers in the project and helps you manage their visibility.\nYou can show or hide it by pressingCtrl+1. A layer can be selected and dragged up or down in the legend to change\nthe Z-ordering. Z-ordering means that layers listed nearer the top of the legend are drawn over layers listed lower\ndown in the legend. Also a layer or a group of layers can be dragged across several QGIS instances.\nNote:The Z-ordering behavior can be overridden by theLayer Orderpanel.\nAt the top of the Layers panel, a toolbar allows you to:\n•\nOpen the layer styling dock (F7)\n: toggle the layer styling panel on and off.\n•\nAdd new group\n: see\nInteract with groups and layers\n•\nManage Map Themes\n: control visibility of layers and arrange them in different map themes.\n•filter layers in the legend tree:\n–Filter Legend by Map Content: only the layers that are set visible and whose features intersect the current\nmap canvas have their style rendered in the layers panel. Otherwise, a generic NULL symbol is applied\nto the layer. Based on the layer symbology, this is a convenient way to identify which kind of features\nfrom which layers cover your area of interest.\n–Show Private Layers: a convenient shortcut to display and interact withprivate layersin theLayerspanel\nwithout modifying the project settings.\n•\nFilter Legend by Expression\n: apply an expression to remove styles from the selected layer tree that have no feature\nsatisfying the condition. This can be used to highlight features that are within a given area/feature of another\nlayer. From the drop-down list, you can edit and clear the expression currently applied.\n121\n\nQGIS Desktop 3.22 User Guide\n•\nExpand All\nor\nCollapse All\nlayers and groups in the layers panel.\n•\nRemove Layer/Group\ncurrently selected.\nFig. 11.1: Layer Toolbar in Layers Panel\nNote:Tools to manage the layers panel are also available for map and legend items in print layouts\nConfiguring map themes\nThe\nManage Map Themes\ndrop-down button provides access to convenient shortcuts to manipulate visibility of the\nlayers in theLayerspanel:\n•Show All Layers\n•Hide All Layers\n•Show Selected Layers\n•Hide Selected Layers\n•Toggle Selected Layers: changes the visibility of the first selected layer in the panel, and applies that state\nto the other selected layers. Also accesible throughSpaceshortcut.\n•Toggle Selected Layers Independently: changes the visibility status of each selected layer\n•Hide Deselected Layers\nBeyond the simple control of layer visibility, the\nManage Map Themes\nmenu allows you to configureMap Themesin\nthe legend and switch from one map theme to another. A map theme is asnapshotof the current map legend that\nrecords:\n•the layers set as visible in theLayerspanel\n•andfor each visible layer:\n–the reference to thestyleapplied to the layer\n–the visible classes of the style, ie the layer checked node items in theLayers panel. This applies to\nsymbologiesother than the single symbol rendering\n–the collapsed/expanded state of the layer node(s) and the group(s) it’s placed inside\nTo create a map theme:\n1.Check a layer you want to show\n2.Configure the layer properties (symbology, diagram, labels...) as usual\n3.Expand theStyle► menu at the bottom and click onAdd...to store the settings asa new style embedded in the\nproject\nNote:A map theme does not remember the current details of the properties: only a reference to the style name\nis saved, so whenever you apply modifications to the layer while this style is enabled (eg change the symbology\nrendering), the map theme is updated with new information.\n122Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n4.Repeat the previous steps as necessary for the other layers\n5.If applicable, expand or collapse groups or visible layer nodes in theLayerspanel\n6.Click on the\nManage Map Themes\nbutton on top of the panel, andAdd Theme...\n7.Enter the map theme’s name and clickOK\nThe new theme is listed in the lower part of thedrop-down menu.\nYou can create as many map themes as you need: whenever the current combination in the map legend (visible layers,\ntheir active style, the map legend nodes) does not match any existing map theme contents as defined above, click on\nAdd Theme...to create a new map theme, or useReplace Theme► to update a map theme. You can rename the\nactive map theme withRename Current Theme...or use theRemove Current Themebutton to delete it.\nMap themes are helpful to switch quickly between different preconfigured combinations: select a map theme in the\nlist to restore its combination. All configured themes are also accessible in the print layout, allowing you to create\ndifferent map items based on specific themes and independent of the current main canvas rendering (seeMap item\nlayers\n).\nOverview of the context menu of the Layers panel\nAt the bottom of the toolbar, the main component of the Layers panel is the frame listing vector or raster layers\nadded to the project, optionally organized in groups. Depending on the item selected in the panel, a right-click shows\na dedicated set of options presented below.\nOptionVector LayerRaster LayerGroup\nZoom to Layer(s)/Group\nZoom to Selection\nShow in Overview\nShow Feature Count\nShow Label\nCopy Layer/Group\nRename Layer/Group\nZoom to Native Resolution (100%)\nStretch Using Current Extent\nUpdate SQL Layer...\nAdd Group\nDuplicate Layer\nRemove Layer/Group...\nMove Out of Group\nMove to Top\nMove to Bottom\nCheck and all its Parents\nGroup Selected\nOpen Attribute Table\nToggle Editing\nCurrent Edits►\ncontinues on next page\n11.2. Panels123\n\nQGIS Desktop 3.22 User Guide\nTable 11.1 – continued from previous page\nOptionVector LayerRaster LayerGroup\nFilter...\nChange Data Source...\nRepair Data Source...\nActions on selections► (in edit mode)\n►Duplicate Feature\n►Duplicate Feature and Digitize\nSet Layer Scale Visibility...\nZoom to Visible Scale\nSet CRS►\n►Set Layer/Group CRS...\n►Set Project CRS from Layer\nSet Group WMS Data...\nMutually Exclusive Group\nCheck and all its children (Ctrl-click)\nUncheck and all its children (Ctrl-click)\nMake Permanent\nExport►\n►Save As...\n►Save Features As...\n►Save Selected Features As...\n►Save As Layer Definition File...\n►Save As QGIS Layer Style File...\nStyles►\n►Copy Style\n►Paste Style\n►Add...\n►Rename Current...\n►Edit symbol...\n►Copy Symbol\n►Paste Symbol\nAdd Layer Notes...\nEdit Layer Notes...\nRemove Layer Notes\nProperties...\nTable: Context menu from Layers Panel items\nFor GRASS vector layers,\nToggle editing\nis not available. See sectionDigitizing and editing a GRASS vector layerfor\ninformation on editing GRASS vector layers.\n124Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nInteract with groups and layers\nLayers in the legend window can be organized into groups. There are two ways to do this:\n1.Press theicon to add a new group. Type in a name for the group and pressEnter. Now click on an\nexisting layer and drag it onto the group.\n2.Select some layers, right-click in the legend window and chooseGroup Selected. The selected layers will\nautomatically be placed in a new group.\nTo move a layer out of a group, drag it out, or right-click on it and chooseMove Out of Group: the layer is moved\nfrom the group and placed above it. Groups can also be nested inside other groups. If a layer is placed in a nested\ngroup,Move Out of Groupwill move the layer out of all nested groups.\nTo move a group or layer to the top of the layer panel, either drag it to the top, or chooseMove to Top. If you use\nthis option on a layer nested in a group, the layer is moved to the top in its current group. TheMove to Bottomoption\nfollows the same logic to move layers and groups down.\nThe checkbox for a group will show or hide the checked layers in the group with one click. WithCtrlpressed, the\ncheckbox will also turn on or off all the layers in the group and its sub-groups.\nCtrl-click on a checked / unchecked layer will uncheck / check the layer and all its parents.\nEnabling theMutually Exclusive Groupoption means you can make a group have only one layer visible at the same\ntime. Whenever a layer within the group is set visible the others will be toggled not visible.\nIt is possible to select more than one layer or group at the same time by holding down theCtrlkey while clicking\nadditional layers. You can then move all selected layers to a new group at the same time.\nYou may also delete more than one layer or group at once by selecting several items with theCtrlkey and then\npressingCtrl+D: all selected layers or groups will be removed from the layers list.\nMore information on layers and groups using indicator icon\nIn some circumstances, icons appears next to the layer or group in theLayerspanel to give more information about\nthe layer/group. These symbols are:\n•to indicate that the layer is in edit mode and you can modify the data\n•to indicate that the layer being edited has some unsaved changes\n•to indicatea filterapplied to the layer. Hover over the icon to see the filter expression and double-click to\nupdate the query\n•to identify layers that arerequiredin the project, hence non removable\n•to identify anembedded group or layerand the path to their original project file\n•to identify a layer whose data source was not available at the project file opening (seeHandling broken file\npaths). Click the icon to update the source path or selectRepair Data Source...entry from the layer contextual\nmenu.\n•to remind you that the layer is atemporary scratch layerand its content will be discarded when you close\nthis project. To avoid data loss and make the layer permanent, click the icon to store the layer in any of the\nOGR vector formats supported by QGIS.\n•to identify a layer used inoffline editing mode.\n•to identify a layer that has no/unknown CRS\n•for layers with coordinates stored in a coordinate reference system which is inherently low accuracy (re-\nquires the\ncorresponding settingto be enabled)\n11.2. Panels125\n\nQGIS Desktop 3.22 User Guide\n•to identify a temporal layer controlled by canvas animation\n•to identify a layer that hasnotesassociated\nEditing vector layer style\nFrom the Layers panel, you have shortcuts to change the layer rendering quickly and easily. Right-click on a vector\nlayer and selectStyles► in the list in order to:\n•see thestylescurrently applied to the layer. If you defined many styles for the layer, you can switch from one\nto another and your layer rendering will automatically be updated on the map canvas.\n•copy part or all of the current style, and when applicable, paste a copied style from another layer\nTip: Quickly share a layer style\nFrom the context menu, copy the style of a layer and paste it to a group or a selection of layers: the style is\napplied to all the layers that are of the same type (vector/raster) as the original layer and, for vector layers, have\nthe same geometry type (point, line or polygon).\n•rename the current style, add a new style (which is actually a copy of the current one) or delete the current style\n(when multiple styles are available).\nNote:The previous options are also available for raster or mesh layers.\n•update thesymbol colorusing aColor Wheel. For convenience, the recently used colors are also available at\nthe bottom of the color wheel.\n•Edit Symbol...: open theSymbol Selectordialog and change feature symbol (symbol, size, color...).\nWhen using a classification symbology type (based oncategorized,graduatedorrule-based), the aforementioned\nsymbol-level options are available from the class entry context menu. Also provided are the\nToggle Items,\nShow All ItemsandHide All Itemsentries to switch the visibility of all the classes of features. These avoid\n(un)checking items one by one.\nTip:Double-clicking a class leaf entry also opens theSymbol Selectordialog.\n11.2.2Layer Styling Panel\nTheLayer Stylingpanel (also enabled withCtrl+3) is a shortcut to some of the functionalities of theLayer Properties\ndialog. It provides a quick and easy way to define the rendering and the behavior of a layer, and to visualize its effects\nwithout having to open the layer properties dialog.\nIn addition to avoiding the blocking (or “modal”) layer properties dialog, the layer styling panel also avoids cluttering\nthe screen with dialogs, and contains most style functions (color selector, effects properties, rule edit, label substitu-\ntion...): e.g., clicking color buttons inside the layer style panel causes the color selector dialog to be opened inside\nthe layer style panel itself rather than as a separate dialog.\nFrom a drop-down list of current layers in the layer panel, select an item and:\n•Depending on the layer type, set:\n–Symbology,Transparency, andHistogramproperties for raster layer. These options are the\nsame as in theRaster Properties Dialog.\n126Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n–Symbology,Labels,Maskand3D Viewproperties for vector layer. These options are\nthe same as in theThe Vector Properties Dialogand can be extended by custom properties introduced by\nthird-party plugins.\n–Symbologyand3D Viewproperties for mesh layer. These options are the same as in theMesh\nDataset Properties.\n•Manage the associated style(s) in theStyle Manager(more details atManaging Custom Styles).\n•See theHistoryof changes you applied to the layer style in the current project: you can therefore cancel\nor restore to any state by selecting it in the list and clicking\nApply\n.\nAnother powerful feature of this panel is theLive updatecheckbox. Tick it to render your changes immediately\non the map canvas: you no longer need to click theApplybutton.\n11.2. Panels127\n\nQGIS Desktop 3.22 User Guide\nFig. 11.2: Defining a layer’s symbology from the layer styling panel\n128Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n11.2.3Layer Order Panel\nBy default, layers shown on the QGIS map canvas are drawn following their order in theLayerspanel: the higher a\nlayer is in the panel, the higher (hence, more visible) it’ll be in the map view.\nYou can define a drawing order for the layers independent of the order in the layers panel with theLayer Orderpanel\nenabled inView►Panels► menu or withCtrl+9. CheckControl rendering orderunderneath the list of layers\nand reorganize the layers in the panel as you want. This order becomes the one applied to the map canvas. For\nexample, inFig. 11.3, you can see that theairportsfeatures are displayed over thealaskapolygon despite\nthose layers’ respective placement in the Layers panel.\nUncheckingControl rendering orderwill revert to default behavior.\nFig. 11.3: Define a layer order independent of the legend\n11.2.4Overview Panel\nTheOverviewpanel (Ctrl+8) displays a map with a full extent view of some of the layers. The Overview map is\nfilled with layers using theShow in Overviewoption from theLayermenu or in the layer contextual menu. Within\nthe view, a red rectangle shows the current map canvas extent, helping you quickly to determine which area of the\nwhole map you are currently viewing. If you click-and-drag the red rectangle in the overview frame, the main map\nview extent will update accordingly.\nNote that labels are not rendered to the map overview even if the layers used in the map overview have been set up\nfor labeling.\n11.2. Panels129\n\nQGIS Desktop 3.22 User Guide\n11.2.5Log Messages Panel\nWhen loading or processing some operations, you can track and follow messages that appear in different tabs using\ntheLog Messages Panel. It can be activated using the most right icon in the bottom status bar.\n11.2.6Undo/Redo Panel\nFor each layer being edited, theUndo/Redo(Ctrl+5) panel shows the list of actions carried out, allowing you quickly\nto undo a set of actions by selecting the action listed above. More details atUndo and Redo edits.\n11.2.7Statistical Summary Panel\nTheStatisticspanel (Ctrl+6) provides summarized information on any vector layer. This panel allows you to select:\n•the vector layer to compute the statistics on\n•the column to use, or anexpression\n•the statistics to return using the drop-down button at the bottom-right of the dialog. Depending on the field’s\n(or expression’s values) type, available statistics are:\nStatisticsStringIntegerFloatDate\nCount\nCount Distinct Value\nCount Missing value\nSum\nMean\nStandard Deviation\nStandard Deviation on Sample\nMinimal value\nMaximal value\nRange\nMinority\nMajority\nVariety\nFirst Quartile\nThird Quartile\nInter Quartile Range\nMinimum Length\nMaximum Length\nMean Length\nTable: Statistics available for each field type\nThe statistical summary can be:\n•returned for the whole layer orselected features only\n130Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n•recalculated using thebutton when the underlying data source changes (eg, new or removed features/fields,\nattribute modification)\n•copied to the clipboard and pasted as a table in another application\nFig. 11.4: Show statistics on a field\n11.2.8Debugging/Development Tools Panel\nTheDebugging/Development Toolspanel (F12) provides aNetwork Loggerand aProfiler.\nNetwork Logger\nTheNetwork Loggerprovides a list of ongoing and completed network requests, along with a whole load of useful\ndetail like request and reply status, header, errors, SSL configuration errors, timeouts, cache status, etc.\nIt also allows you to:\n•Record Logwhich will start or stop the logging.\n•Clear Logwill clear the log history.\n•Save Log...will first show a big warning that the log is sensitive and should be treated as confidential and\nthan allow you to save the log.\n•Settingswill allow you toShow Successful RequestsandShow Timeouts.\n11.2. Panels131\n\nQGIS Desktop 3.22 User Guide\n•Disable cachewill disable the cache so that every request has to be performed.\n•Filter requests\nBy right clicking on a request you can:\n•Open URLwhich will open the URL in your default browser.\n•Copy URL\n•Copy As cURLto use it in the terminal.\n•Copy as JSONwill copy the whole log from one request.\nFig. 11.5: Network Logger output for GET Request\n132Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nProfiler\nTheProfilerallows to get load times for the CategoriesStartupandProject Load, to identify causes of slow load times.\nFig. 11.6: Profiler for QGIS Startup\n11.2. Panels133\n\nQGIS Desktop 3.22 User Guide\n11.3Embedding layers from external projects\nSometimes, you’d like to keep some layers in different projects, but with the same style. You can either create a\ndefault stylefor these layers or embed them from another project to save time and effort.\nEmbed layers and groups from an existing project has some advantages over styling:\n•All types of layers (vector or raster, local or online...) can be added\n•Fetching groups and layers, you can keep the same tree structure of the “background” layers in your different\nprojects\n•While the embedded layers are editable, you can’t change their properties such as symbology, labels, forms,\ndefault values and actions, ensuring consistency across projects\n•Modify the items in the original project and changes are propagated to all the other projects\nIf you want to embed content from other project files into your project, selectLayer►Embed Layers and Groups:\n1.Click the...button to look for a project: you can see the content of the project (seeFig. 11.7)\n2.Hold downCtrl( orCmd) and click on the layers and groups you wish to retrieve\n3.ClickOK\nThe selected layers and groups are embedded in theLayerspanel and displayed on the map canvas. Anicon is\nadded next to their name for recognition and hovering over displays a tooltip with the original project file path.\nFig. 11.7: Select layers and groups to embed\nLike any other layer, an embedded layer can be removed from the project by right-clicking on the layer and clicking\nRemove\n.\nTip: Change rendering of an embedded layer\nIt’s not possible to change the rendering of an embedded layer, unless you make the changes in the original project file.\nHowever, right-clicking on a layer and selectingDuplicatecreates a layer which is fully-featured and not dependent\non the original project. You can then safely remove the linked layer.\n11.4Working with the map canvas\n11.4.1Rendering\nBy default, QGIS renders all visible layers whenever the map canvas is refreshed. The events that trigger a refresh of\nthe map canvas include:\n•adding a layer\n•panning or zooming\n134Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n•resizing the QGIS window\n•changing the visibility of a layer or layers\nQGIS allows you to control the rendering process in a number of ways.\nScale Dependent Rendering\nScale-dependent rendering allows you to specify the minimum and maximum scales at which a layer (raster or vector)\nwill be visible. To set scale-dependent rendering, open thePropertiesdialog by double-clicking on the layer in the\nlegend. On theRenderingtab, tickScale dependent visibilityand enter theMinimum (exclusive)andMaximum\n(inclusive)scale values.\nYou can also activate scale dependent visibility on a layer from the Layers panel. Right-click on the layer and in the\ncontext menu, selectSet Layer Scale Visibility.\nThe\nSet to current canvas scale\nbutton allow you to use the current map canvas scale as boundary of the range visibility.\nNote:When a layer is not rendered in the map canvas because the map scale is out of its visibility scale range, the\nlayer is greyed in the Layers panel and a new optionZoom to Visible Scaleappears in the layer context menu. Select\nit and the map is zoomed to the layer’s nearest visibility scale.\nControlling Map Rendering\nMap rendering can be controlled in various ways, as described below.\nSuspending Rendering\nTo suspend rendering, click theRendercheckbox in the bottom-right corner of the status bar. WhenRender\nis not checked, QGIS does not redraw the canvas in response to any of the events described in the sectionRendering.\nExamples of when you might want to suspend rendering include:\n•adding many layers and symbolizing them prior to drawing\n•adding one or more large layers and setting scale dependency before drawing\n•adding one or more large layers and zooming to a specific view before drawing\n•any combination of the above\nChecking theRendercheckbox enables rendering and causes an immediate refresh of the map canvas.\nSetting Layer Add Option\nYou can set an option to always load new layers without drawing them. This means the layer will be added to the\nmap, but its visibility checkbox in the legend will be unchecked by default. To set this option, choose menu option\nSettings►Optionsand click on theRenderingtab. UncheckBy default new layers added to the map should be\ndisplayed. Any layer subsequently added to the map will be off (invisible) by default.\n11.4. Working with the map canvas135\n\nQGIS Desktop 3.22 User Guide\nStopping Rendering\nTo stop the map drawing, press theEsckey. This will halt the refresh of the map canvas and leave the map partially\ndrawn. It may take a bit of time between pressingEscfor the map drawing to halt.\nInfluence Rendering Quality\nQGIS has an option to influence the rendering quality of the map. Choose menu optionSettings►Options, click on\ntheRenderingtab and select or deselectMake lines appear less jagged at the expense of some drawing performance.\nSpeed-up rendering\nThere are some settings that allow you to improve rendering speed. Open the QGIS options dialog usingSettings►\nOptions, go to theRenderingtab and select or deselect the following checkboxes:\n•Use render caching where possible to speed up redraws.\n•Render layers in parallel using many CPU coresand then set theMax cores to use.\n•The map renders in the background onto a separate image and eachMap Update interval, the content from\nthis (off-screen) image will be taken to update the visible screen representation. However, if rendering finishes\nfaster than this duration, it will be shown instantaneously.\n•WithEnable Feature simplification by default for newly added layers, you simplify features’ geometry (fewer\nnodes) and as a result, they display more quickly. Be aware that this can cause rendering inconsistencies.\n11.4.2Zooming and Panning\nThere are multiple ways to zoom and pan to an area of interest. You can use theMap Navigationtoolbar, the mouse\nand keyboard on the map canvas and also the menu actions from theViewmenu and the layers’ contextual menu in\nthe\nLayers\npanel.\nIconLabelUsageView\nmenu\nMap\nNav-\ni-\nga-\ntion\nTool-\nbar\nLayer\nCon-\ntex-\ntual\nMenu\nPan MapWhen activated, left click anywhere on the map canvas to pan the map at\nthe cursor position. You can also pan the map by holding down the left\nmouse button and dragging the map canvas.\nZoom InWhen activated, left click anywhere on the map canvas to zoom in one\nlevel. The mouse cursor position will be the center of the zoomed area\nof interest. You can also zoom in to an area by dragging a rectangle on\nthe map canvas with the left mouse button.\nZoom OutWhen activated, left click anywhere on the map canvas to zoom out one\nlevel. The mouse cursor position will be the center of the zoomed area\nof interest. You can also zoom out from an area by dragging a rectangle\non the map canvas with the left mouse button.\nPan Map to\nSelection\nPan the map to the selected features of all the selected layers in theLayers\npanel.\ncontinues on next page\n136Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nTable 11.2 – continued from previous page\nIconLabelUsageView\nmenu\nMap\nNav-\ni-\nga-\ntion\nTool-\nbar\nLayer\nCon-\ntex-\ntual\nMenu\nZoom To Se-\nlection\nZoom to the selected features of all the selected layers in theLayerspanel.\nZoom    To\nLayer(s)\nZoom to the extent of all the selected layers in theLayerspanel.\nZoom FullZoom to the extent of all the layers in the project or to theproject full\nextent.\nZoom LastZoom the map to the previous extent in history.\nZoom NextZoom the map to the next extent in history.\nZoomto\nNative Reso-\nlution\nZoom the map to a level where one pixel of the active raster layer covers\none screen pixel.\nAZoom factorcan be set under theSettings►Options►Map toolsmenu to define the scale behavior while\nzooming. There, you can also set a list ofPredefined Scalesthat will be available at the bottom of the map canvas.\nWith the Mouse on the Map Canvas\nIn addition to using the\nPanZoom In\nand\nZoom Out\ntools described above, you can hold the mouse wheel\ninside of the map canvas and drag the mouse cursor (on macOS, you may need to hold down thecmdkey). You can\nalso roll the mouse wheel to zoom in and out on the map. The mouse cursor position will be the center of the zoomed\narea of interest. Holding downCtrlwhile rolling the mouse wheel results in a finer zoom.\nWith the Keyboard on the Map Canvas\nHolding downspacebaron the keyboard and moving the mouse cursor will pan the map the same way dragging\nthe map canvas with\nPan\ndoes.\nPanning the map is possible with the arrow keys. Place the mouse cursor inside the map area, and press on the arrow\nkeys to pan up, down, left and right.\nThePgUpandPgDownkeys on the keyboard will cause the map display to zoom in or out following the zoom factor\nset. PressingCtrl++orCtrl+-also performs an immediate zoom in/out on the map canvas.\nWhen certain map tools are active (Identify, Measure...), you can perform a zoom by holding downShiftand\ndragging a rectangle on the map to zoom to that area. This is not enabled for selection tools (since they useShift\nfor adding to selection) or edit tools.\n11.4. Working with the map canvas137\n\nQGIS Desktop 3.22 User Guide\n11.4.3Spatial Bookmarks\nSpatial Bookmarks allow you to “bookmark” a geographic location and return to it later. By default, bookmarks\nare saved in the user’s profile (asUser Bookmarks), meaning that they are available from any project the user opens.\nThey can also be saved for a single project (named\nProject Bookmarks\n) and stored within the project file, which can\nbe helpful if the project is to be shared with other users.\nCreating a Bookmark\nTo create a bookmark:\n1.Zoom and pan to the area of interest.\n2.Select the menu optionView►New Spatial Bookmark..., pressCtrl+Bor right-click theSpatial\nBookmarksentry in theBrowserpanel and selectNew Spatial Bookmark. TheBookmark Editordialog opens.\nFig. 11.8: The Bookmark Editor Dialog\n3.Enter a descriptive name for the bookmark\n4.Enter or select a group name in which to store related bookmarks\n5.Select the extent of the area you wish to save, using theextent selectorwidget\n6.Indicate theCRSto use for the extent\n7.Select whether the bookmark will beSaved in User BookmarksorProject Bookmarks\n8.PressSaveto add the bookmark to the list\nNote that you can have multiple bookmarks with the same name.\n138Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nWorking with Bookmarks\nTo use and manage bookmarks, you can either use theSpatial Bookmarkspanel orBrowser.\nSelectView►Show Spatial Bookmark Manageror pressCtrl+7to open theSpatial Bookmarks Managerpanel.\nSelectView►Show BookmarksorCtrl+Shift+Bto show theSpatial Bookmarksentry in theBrowser\npanel.\nYou can perform the following tasks:\nTaskSpatial Bookmark ManagerBrowser\nZoom to a Book-\nmark\nDouble-click on it, or select the bookmark\nand press theZoom to bookmark\nbut-\nton.\nDouble-click on it, drag and drop it to the\nmap canvas, or right-click the bookmark\nand selectZoom to Bookmark.\nDelete  a  book-\nmark\nSelect the bookmark and click the\nDelete bookmarkbutton.  Confirm your\nchoice.\nRight-click the bookmark and selectDelete\nSpatial Bookmark. Confirm your choice.\nExport    book-\nmarks to XML\nClick theImport/Export Bookmarks\nbutton and selectExport. All the book-\nmarks (user or project) are saved in an xml\nfile.\nSelect one or more folders (user or project)\nor subfolders (groups), then right-click and\nselect\nExport Spatial Bookmarks....\nThe selected bookmark subset is saved.\nImport    book-\nmarks from XML\nClick theImport/Export Bookmarks\nbutton and selectImport. All book-\nmarks in the XML file are imported as user\nbookmarks.\nRight-click theSpatial Bookmarksentry or\none of its folders (user or project) or sub-\nfolders (groups) to determine where to im-\nport the bookmarks, then select\nImport\nSpatial Bookmarks.  If performed on the\nSpatial Bookmarksentry, the bookmarks\nare added toUser Bookmarks.\nEdit bookmarkYou can change a bookmark by changing\nthe values in the table. You can edit the\nname, the group, the extent and if it is\nstored in the project or not.\nRight-click the desired bookmark and se-\nlectEdit Spatial Bookmark.... TheBook-\nmark Editorwill open, allowing you to re-\ndefine every aspect of the bookmark as if\nyou were creating it for the first time.\nYou can also drag and drop the bookmark\nbetween folders (user and project) and sub-\nfolders (groups).\nYou can also zoom to bookmarks by typing the bookmark name in thelocator.\n11.4.4Decorations\nDecorations include Grid, Title Label, Copyright Label, Image, North Arrow, Scale Bar and Layout Extents. They\nare used to ‘decorate’ the map by adding cartographic elements.\n11.4. Working with the map canvas139\n\nQGIS Desktop 3.22 User Guide\nGrid\nGridallows you to add a coordinate grid and coordinate annotations to the map canvas.\n1.Select menu optionView►Decorations►Grid...to open the dialog.\nFig. 11.9: The Grid Dialog\n2.TickEnable gridand set grid definitions according to the layers loaded in the map canvas:\n•TheGrid type: it can beLineorMarker\n•The associatedLine symbolormarker symbolused to represent the grid marks\n•TheInterval XandInterval Ybetween the grid marks, in map units\n•AnOffset XandOffset Ydistance of the grid marks from the bottom left corner of the map canvas, in\nmap units\n•The interval and offset parameters can be set based on the:\n–Canvas Extents: generates a grid with an interval that is approximatively 1/5 of the canvas width\n–Active Raster Layerresolution\n3.TickDraw annotationsto display the coordinates of the grid marks and set:\n•TheAnnotation direction, ie how the labels would be placed relative to their grid line. It can be:\n–HorizontalorVerticalfor all the labels\n–Horizontal and Vertical, ie each label is parallel to the grid mark it refers to\n–Boundary direction, ie each label follows the canvas boundary, and is perpendicular to the grid mark\nit refers to\n•TheAnnotation font(text formatting, buffer, shadow...) using thefont selector widget\n140Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n•TheDistance to map frame, margin between annotations and map canvas limits. Convenient whenex-\nporting the map canvaseg to an image format or PDF, and avoid annotations to be on the “paper” limits.\n•TheCoordinate precision\n4.ClickApplyto verify that it looks as expected orOKif you’re satisfied.\nTitle Label\nTitle Labelallows you to decorate your map with aTitle.\nTo add a Title Label decoration:\n1.Select menu optionView►Decorations►Title Label...to open the dialog.\nFig. 11.10: The Title Decoration Dialog\n2.Make sureEnable Title Labelis checked\n3.Enter the title text you want to place on the map. You can make it dynamic using theInsert or Edit an Expres-\nsion...button.\n4.Choose theFontfor the label using thefont selector widgetwith full access to QGIStext formattingoptions.\nQuickly set the font color and opacity by clicking the black arrow to the right of the font combo box.\n5.Select thecolorto apply to the title’sBackground bar color.\n6.Choose thePlacementof the label in the canvas: options areTop left,Top Center(default),Top Right,Bottom\nleft,Bottom CenterandBottom Right.\n7.Refine the placement of the item by setting a horizontal and/or verticalMargin from Edge. These values can\nbe inMillimetersorPixelsor set as aPercentageof the width or height of the map canvas.\n8.ClickApplyto verify that it looks as expected orOKif you’re satisfied.\n11.4. Working with the map canvas141\n\nQGIS Desktop 3.22 User Guide\nCopyright Label\nCopyright Labelcan be used to decorate your map with aCopyrightlabel.\nTo add this decoration:\n1.Select menu optionView►Decorations►Copyright Label...to open the dialog.\nFig. 11.11: The Copyright Decoration Dialog\n2.Make sureEnable Copyright Labelis checked\n3.Enter the copyright text you want to place on the map. You can make it dynamic using theInsert or Edit an\nExpression...button.\n4.Choose theFontfor the label using thefont selector widgetwith full access to QGIStext formattingoptions.\nQuickly set the font color and opacity by clicking the black arrow to the right of the font combo box.\n5.Choose thePlacementof the label in the canvas: options areTop left,Top Center,Top Right,Bottom left,Bottom\nCenter, andBottom Right(default for Copyright decoration)\n6.Refine the placement of the item by setting a horizontal and/or verticalMargin from Edge. These values can\nbe inMillimetersorPixelsor set as aPercentageof the width or height of the map canvas.\n7.ClickApplyto verify that it looks as expected orOKif you’re satisfied.\nImage Decoration\nImageallows you to add an image (logo, legend, ..) on the map canvas.\nTo add an image:\n1.Select menu optionView►Decorations►Image...to open the dialog.\n142Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nFig. 11.12: The Image Decoration Dialog\n2.Make sureEnable Imageis checked\n3.Select a bitmap (e.g. png or jpg) or SVG image using the...\nBrowse\nbutton\n4.If you have chosen a parameter enabled SVG then you can also set aFillorStroke(outline) color. For bitmap\nimages, the color settings are disabled.\n5.Set aSizeof the image in mm. The width of selected image is used to resize it to givenSize.\n6.Choose where you want to place the image on the map canvas with thePlacementcombo box. The default\nposition isTop Left.\n7.Set the\nHorizontal\nand\nVertical Margin from (Canvas) Edge\n. These values can be set in\nMillimeters\n,\nPixels\nor\nas aPercentageof the width or height of the map canvas.\n8.ClickApplyto verify that it looks as expected andOKif you’re satisfied.\nNorth Arrow\nNorth Arrowallows you to add a north arrow on the map canvas.\nTo add a north arrow:\n1.Select menu optionView►Decorations►North Arrow...to open the dialog.\n11.4. Working with the map canvas143\n\nQGIS Desktop 3.22 User Guide\nFig. 11.13: The North Arrow Dialog\n2.Make sureEnable north arrowis checked\n3.Optionally change the color and size, or choose a custom SVG\n4.Optionally change the angle or chooseAutomaticto let QGIS determine the direction\n5.Optionally choose the placement from the Placement combo box\n6.Optionally refine the placement of the arrow by setting a horizontal and/or verticalMargin from (Canvas) Edge.\nThese values can be inMillimetersorPixelsor set as aPercentageof the width or height of the map canvas.\n7.ClickApplyto verify that it looks as expected andOKif you’re satisfied.\nScale Bar\nScale Baradds a simple scale bar to the map canvas. You can control the style and placement, as well as the\nlabelling of the bar.\nQGIS only supports displaying the scale in the same units as your map frame. So, if the units of your project’s CRS\nare meters, you can’t create a scale bar in feet. Likewise, if you are using decimal degrees, you can’t create a scale\nbar to display distance in meters.\nTo add a scale bar:\n1.Select menu optionView►Decorations►Scale Bar...to open the dialog\n144Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nFig. 11.14: The Scale Bar Dialog\n2.Make sureEnable scale baris checked\n3.Choose a style from theScale bar stylecombo box\n4.Select theColor of barby choosing a fill color (default: black) and an outline color\n(default: white). The scale bar fill and outline can be made opaque by clicking on the down arrow to the right\nof the color input.\n5.Select the font for the scale bar from theFont of barcombo box\n6.Set theSize of bar\n7.Optionally checkAutomatically snap to round number on resizeto display easy-to-read values\n8.Choose the placement from thePlacementcombo box\n9.You can refine the placement of the item by setting a horizontal and/or verticalMargin from (Canvas) Edge.\nThese values can be inMillimetersorPixelsor set as aPercentageof the width or height of the map canvas.\n10.ClickApplyto verify that it looks as expected orOKif you’re satisfied.\nLayout Extents\nLayout Extentsadds the extents ofmap item(s)in print layout(s) to the canvas. When enabled, the extents of all\nmap items within all print layouts are shown using a lightly dotted border labeled with the name of the print layout\nand map item. You can control the style and labeling of the displayed layout extents. This decoration is useful when\nyou are tweaking the positioning of map elements such as labels, and need to know the actual visible region of print\nlayouts.\n11.4. Working with the map canvas145\n\nQGIS Desktop 3.22 User Guide\nFig. 11.15: Example of layout extents displayed in a QGIS project with two print layouts. The print layout named\n‘Sights’ contains two map items, while the other print layout contains one map item.\nTo add layout extent(s):\n1.SelectView►Decorations►Layout Extentsto open the dialog\nFig. 11.16: The Layout Extents Dialog\n2.Make sureShow layout extentsis checked.\n146Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n3.Optionally change the symbol and labeling of the extents.\n4.ClickApplyto verify that it looks as expected andOKif you’re satisfied.\nTip: Decorations Settings\nWhen you save a QGIS project file, any changes you have made to Grid, North Arrow, Scale Bar, Copyright and\nLayout Extents will be saved in the project and restored the next time you load the project.\n11.4.5Annotation Tools\nAnnotations are information added to the map canvas and shown within a balloon. This information can be of different\ntypes and annotations are added using the corresponding tools in theAnnotations Toolbar:\n•\nText Annotation\nfor custom formatted text\n•\nHTML Annotation\nto place the content of anhtmlfile\n•\nSVG Annotation\nto add anSVGsymbol\n•\nForm Annotation\n: useful to display attributes of a vector layer in a customizeduifile (see\nFig. 11.17). This\nis similar to thecustom attribute forms, but displayed in an annotation item. Also see this videohttps://www.\nyoutube.com/watch?v=0pDBuSbQ02o&feature=youtu.be&t=2m25sfrom Tim Sutton for more information.\nFig. 11.17: Customized QT Designer annotation form\nTo add an annotation, select the corresponding tool and click on the map canvas. An empty balloon is added. Double-\nclick on it and a dialog opens with various options. This dialog is almost the same for all the annotation types:\n•At the top, a file selector to fill with the path to anhtml,svgoruifile depending on the type of annotation.\nFor text annotation, you can enter your message in a text box and set its rendering with the normal font tools.\n•Fixed map position: when unchecked, the balloon placement is based on a screen position (instead of the\nmap), meaning that it’s always shown regardless the map canvas extent.\n•Linked layer: associates the annotation with a map layer, making it visible only when that layer is visible.\n11.4. Working with the map canvas147\n\nQGIS Desktop 3.22 User Guide\n•Map marker: usingQGIS symbols, sets the symbol to display at the balloon anchor position (shown only when\nFixed map positionis checked).\n•Frame style: sets the frame background color, transparency, stroke color or width of the balloon using QGIS\nsymbols.\n•Contents margins: sets interior margins of the annotation frame.\nFig. 11.18: Annotation text dialog\nAnnotations can be selected when an annotation tool is enabled. They can then be moved by map position (by dragging\nthe map marker) or by moving only the balloon. The\nMove Annotation\ntool also allows you to move the balloon on\nthe map canvas.\nTo delete an annotation, select it and either press theDelorBackspacebutton, or double-click it and press the\nDeletebutton in the properties dialog.\nNote:If you pressCtrl+Twhile anAnnotationtool (move annotation, text annotation, form annotation) is active,\nthe visibility states of the items are inverted.\nTip: Layout the map with annotations\n148Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nYou can print or export annotations with your map to various formats using:\n•map canvas export tools available in theProjectmenu\n•print layout, in which case you need to checkDraw map canvas itemsin the corresponding map item properties\n11.4.6Measuring\nGeneral information\nQGIS provides four means of measuring geometries:\n•interactive measurement tools\n•measuring in the\nField Calculator\n•derived measurements in theIdentifying Featurestool\n•the vector analysis tool:Vector►Geometry Tools►Export/Add Geometry Columns\nMeasuring works within projected coordinate systems (e.g., UTM) and unprojected data. The first three measuring\ntools behave equally to global project settings:\n•Unlike most other GIS, the default measurement metric is ellipsoidal, using the ellipsoid defined inProject►\nProperties...►General. This is true both when geographic and projected coordinate systems are defined for\nthe project.\n•If you want to calculate the projected/planimetric area or distance using cartesian maths, the measurement\nellipsoid has to be set to “None/Planimetric” (Project►Properties...►General). However, with a geographic\n(ie unprojected) CRS defined for the data and project, area and distance measurement will be ellipsoidal.\nHowever, neithertheidentifytoolnorthefieldcalculatorwilltransformyourdatatotheprojectCRSbeforemeasuring.\nIf you want to achieve this, you have to use the vector analysis tool:Vector►Geometry Tools►Add Geometry\nAttributes.... Here, measurement is planimetric, unless you choose the ellipsoidal measurement.\nMeasure length, areas, bearings and angles interactively\nClick theicon in the Attribute toolbar to begin measurements. The down arrow near the icon switches between\nlength,area,bearing orangle. The default unit used in the dialog is the one set inProject►\nProperties...►Generalmenu.\nFor theMeasure Lineand theMeasure Areathe measurements can be done inCartesianorEllipsoidal\nmeasure.\nNote: Configuring the measure tool\nWhile measuring length or area, clicking theConfigurationbutton at the bottom of the widget opens theSettings►\nOptions►Map Toolsmenu, where you can select the rubberband color, the precision of the measurements and the\nunit behavior. You can also choose your preferred measurement or angle units, but keep in mind that those values\nare overridden in the current project by the selection made in theProject►Properties...►Generalmenu, and by the\nselection made in the measurement widget.\nAll measuring modules use the snapping settings from the digitizing module (see sectionSetting the snapping tolerance\nand search radius). So, if you want to measure exactly along a line feature, or around a polygon feature, first set its\nlayer snapping tolerance. Now, when using the measuring tools, each mouse click (within the tolerance setting) will\nsnap to that layer.\n11.4. Working with the map canvas149\n\nQGIS Desktop 3.22 User Guide\nThe\nMeasure Line\nmeasures distances between given points. The tool then allows you to click points on the map.\nEach segment length, as well as the total, shows up in the measure window. To stop measuring, click the right mouse\nbutton. Now it is possible to copy all your line measurements at once to the clipboard using theCopy Allbutton.\nNote that you can use the drop-down list near the total to change the measurement units interactively while working\nwith the measure tool (‘Meters’, ‘Kilometers’, ‘Feet’, ‘Yards’, ‘Miles’, ‘Nautical miles’, ‘Centimeters’, ‘Millimeters’,\n‘Degrees’, ‘Map units’). This unit is retained for the widget until a new project is created or another project is opened.\nTheInfosection in the dialog explains how calculations are made according to the CRS settings available.\nFig. 11.19: Measure Distance\nMeasure Area\n: Areas can also be measured. In the measure window, the accumulated area size appears. Right-click\nto stop drawing. The Info section is also available as well as the ability to switch between different area units (‘Square\nmeters’, ‘Square kilometers’, ‘Square feet’, ‘Square yards’, ‘Square miles’, ‘Hectares’, ‘Acres’, ‘Square centimeters’,\n‘Square millimeters’, ‘Square nautical miles’, ‘Square degrees’, ‘Map units’).\nFig. 11.20: Measure Area\nMeasure Bearing\n: You can also measure bearings. The cursor becomes cross-shaped. Click to draw the first point of\nthe bearing, then move the cursor to draw the second point. The measurement is displayed in a pop-up dialog.\n150Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nFig. 11.21: Measure Bearing\nMeasure Angle\n: You can also measure angles. The cursor becomes cross-shaped. Click to draw the first segment of\nthe angle you wish to measure, then move the cursor to draw the desired angle. The measurement is displayed in a\npop-up dialog.\nFig. 11.22: Measure Angle\n11.5Interacting with features\n11.5.1Selecting features\nQGIS provides several tools to select features on the map canvas. Selection tools are available in theEdit►Select\nmenu or in theSelection Toolbar.\nNote:Selection tools work with the currently active layer.\nSelecting manually on the map canvas\nTo select one or more features with the mouse, you can use one of the following tools:\n•\nSelect Features by area or single click\n•\nSelect Features by Polygon\n•\nSelect Features by Freehand\n•\nSelect Features by Radius\nNote:Other than\nSelect Features by Polygon\n, these manual selection tools allow you to select feature(s) on the map\ncanvas with a single click.\n11.5. Interacting with features151\n\nQGIS Desktop 3.22 User Guide\nNote:Use the\nSelect Features by Polygon\ntool to use an existing polygon feature (from any layer) to select overlapping\nfeatures in the active layer. Right-click in the polygon and choose it from the context menu that shows a list of all the\npolygons that contain the clicked point. All the overlapping features from the active layer are selected.\nTip:Use theEdit►Select►Reselect Featurestool to redo your latest selection. Very useful when you have\npainstakingly made a selection, and then click somewhere else accidentally and clear your selection.\nWhile using theSelect Feature(s)tool, holdingShiftorCtrltoggles whether a feature is selected (ie either\nadds to the current selection or remove from it).\nFor the other tools, different behaviors can be performed by holding down:\n•Shift: add features to the current selection\n•Ctrl: substract features from the current selection\n•Ctrl+Shift: intersect with current selection, ie only keep overlapping features from the current selection\n•Alt: select features that are totally within the selection shape. Combined withShiftorCtrlkeys, you can\nadd or substract features to/from the current selection.\nAutomatic selection\nThe other selection tools, most of them available from theAttribute table, perform a selection based on a feature’s\nattribute or its selection state (note that attribute table and map canvas show the same information, so if you select\none feature in the attribute table, it will be selected on the map canvas too):\n•\nSelect By Expression...\nselect features using expression dialog\n•\nSelect Features By Value...\nor pressF3\n•\nDeselect Features from All Layers\nor pressCtrl+Alt+Ato deselect all selected features in all layers\n•\nDeselect Features from the Current Active Layer\nor pressCtrl+Shift+A\n•\nSelect All Features\nor pressCtrl+Ato select all features in the current layer\n•\nInvert Feature Selection\nto invert the selection in the current layer\n•\nSelect by Location\nto select the features based on their spatial relationship with other features (in the same or\nanother layer - seeSelect by location)\nFor example, if you want to find regions that are boroughs fromregions.shpof the QGIS sample data, you can:\n1.Use the\nSelect features using an Expression\nicon\n2.Expand theFields and Valuesgroup\n3.Double-click the field that you want to query (“TYPE_2”)\n4.ClickAll Uniquein the panel that shows up on the right\n5.From the list, double-click ‘Borough’. In theExpressioneditor field, write the following query:\n\"TYPE_2\"='Borough'\n6.ClickSelect Features\n152Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nFrom the expression builder dialog, you can also useFunction list►Recent (Selection)to make a selection that you\nhave used before. The dialog remembers the last 20 expressions used. SeeExpressionsfor more information and\nexamples.\nTip: Save your selection into a new file\nUsers can save selected features into aNew Temporary Scratch Layeror aNew Vector LayerusingEdit►Copy\nFeaturesandEdit►Paste Features asin the desired format.\nSelect Features By Value\nThis selection tool opens the layer’s feature form allowing the user to choose which value to look for for each field,\nwhether the search should be case-sensitive, and the operation that should be used. The tool has also autocompletes,\nautomatically filling the search box with existing values.\nFig. 11.23: Filter/Select features using form dialog\nAlongside each field, there is a drop-down list with options to control the search behaviour:\n11.5. Interacting with features153\n\nQGIS Desktop 3.22 User Guide\nField search optionStringNumericDate\nExclude Fieldfrom the search\nEqual to (=)\nNot equal to (̸=)\nGreater than (>)\nLess than (<)\nGreater than or equal to (≥)\nLess than or equal to (≤)\nBetween (inclusive)\nNot between (inclusive)\nContains\nDoes not contain\nIs missing (null)\nIs not missing (not null)\nStarts with\nEnds with\nFor string comparisons, it is also possible to use theCase sensitiveoption.\nAfter setting all search options, clickSelect featuresto select the matching features. The drop-down options are:\n•Select features\n•Add to current selection\n•Remove from current selection\n•Filter current selection\nYou can also clear all search options using theReset formbutton.\nOnce the conditions are set, you can also either:\n•Zoom to featureson the map canvas without the need of a preselection\n•Flash features, highlighting the matching features. This is a handy way to identify a feature without selection\nor using the Identify tool. Note that the flash does not alter the map canvas extent and would be visible only if\nthe feature is within the bounds of the current map canvas.\n11.5.2Identifying Features\nThe Identify tool allows you to interact with the map canvas and get information on features in a pop-up window. To\nidentify features, use:\n•View►Identify Features\n•Ctrl+Shift+I(orCmd+Shift+I),\n•\nIdentify Features\nicon on the Attributes toolbar\n154Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nUsing the Identify Features tool\nQGIS offers several ways to identify features with the\nIdentify Features\ntool:\n•left clickidentifies features according to theselection modeand theselection maskset in theIdentify Results\npanel\n•right clickwithIdentify Feature(s)asselection modeset in theIdentify Resultspanel fetches all snapped features\nfrom all visible layers. This opens a context menu, allowing the user to choose more precisely the features to\nidentify or the action to execute on them.\n•rightclickwithIdentify Features by Polygonasselection modein theIdentify Resultspanel identifies the features\nthat overlap with the chosen existing polygon, according to theselection maskset in theIdentify Resultspanel\nTip: Filter the layers to query with the Identify Features tool\nUnderLayer CapabilitiesinProject►Properties...►Data Sources, uncheck theIdentifiablecolumn next to a layer\nto avoid it being queried when using the\nIdentify Features\ntool in a mode other thanCurrent Layer. This is a handy\nway to return features from only layers that are of interest for you.\nIf you click on feature(s), theIdentify Resultsdialog will list information about the feature(s) clicked. The default\nview is a tree view in which the first item is the name of the layer and its children are its identified feature(s). Each\nfeature is described by the name of a field along with its value. This field is the one set inLayer Properties►Display.\nAll the other information about the feature follows.\nFeature information\nThe Identify Results dialog can be customized to display custom fields, but by default it will display the following\ninformation:\n•The featuredisplay name;\n•Actions: Actions can be added to the identify feature windows. The action is run by clicking on the action\nlabel. By default, only one action is added, namelyView feature formfor editing. You can define more\nactions in the layer’s properties dialog (seeActions Properties).\n•Derived: This information is calculated or derived from other information. It includes:\n–general information about the feature’s geometry:\n∗depending on the geometry type, the cartesian measurements of length, perimeter or area in the\nlayer’s CRS units. For 3D line vectors the cartesian line length is available.\n∗depending on the geometry type and if an ellipsoid is set in the project properties dialog forMea-\nsurements, the ellipsoidal values of length, perimeter or area using the specified units\n∗the count of geometry parts in the feature and the number of the part clicked\n∗the count of vertices in the feature\n–coordinate information, using the project propertiesCoordinates displaysettings:\n∗XandYcoordinate values of the point clicked\n∗the number of the closest vertex to the point clicked\n∗XandYcoordinate values of the closest vertex (andZ/Mif applicable)\n∗if you click on a curved segment, the radius of that section is also displayed.\n•Data attributes: This is the list of attribute fields and values for the feature that has been clicked.\n•information about the related child feature if you defined arelation:\n–the name of the relation\n11.5. Interacting with features155\n\nQGIS Desktop 3.22 User Guide\n–the entry in reference field, e.g. the name of the related child feature\n–Actions: lists actions defined in the layer’s properties dialog (seeActions Properties) and the default action\nisView feature form.\n–Data attributes: This is the list of attributes fields and values of the related child feature.\nNote:Links in the feature’s attributes are clickable from theIdentify Resultspanel and will open in your default web\nbrowser.\nFig. 11.24: Identify Results dialog\n156Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nThe Identify Results dialog\nAt the top of the window, you have a handful of tools:\n•\nOpen Form\nof the current feature\n•\nExpand tree\n•\nCollapse tree\n•\nExpand New Results by Default\nto define whether the next identified feature’s information should be collapsed or\nexpanded\n•\nClear Results\n•\nCopy selected feature to clipboard\n•\nPrint selected HTML response\n•selection mode to use to fetch features to identify:\n–\nIdentify Features by area or single click\n–\nIdentify Features by Polygon\n–\nIdentify Features by Freehand\n–\nIdentify Features by Radius\nNote:When using\nIdentify Features by Polygon\n, you can right-click any existing polygon and use it to identify\noverlapping features in another layer.\nAt the bottom of the window are theModeandViewcombo boxes.Modedefines from which layers features should\nbe identified:\n•Current layer: only features from the selected layers are identified. If a group is selected, features from its\nvisible layers are identified. If there is no selection then only the current layer is identified.\n•Top down, stop at first: only features from the upper visible layer.\n•Top down: all features from the visible layers. The results are shown in the panel.\n•Layer selection: opens a context menu where the user selects the layer to identify features from, similar to a\nright-click. Only the chosen features will be shown in the result panel.\nTheViewcan be set asTree,TableorGraph. ‘Table’ and ‘Graph’ views can only be set for raster layers.\nThe identify tool allows you toAuto open form for single feature results, found under\nIdentify Settings\n. If checked,\neach time a single feature is identified, a form opens showing its attributes. This is a handy way to quickly edit a\nfeature’s attributes.\nOther functions can be found in the context menu of the identified item. For example, from the context menu you\ncan:\n•View the feature form\n•Zoom to feature\n•Copy feature: Copy all feature geometry and attributes\n•Toggle feature selection: Add identified feature to selection\n•Copy attribute value: Copy only the value of the attribute that you click on\n•Copy feature attributes: Copy the attributes of the feature\n11.5. Interacting with features157\n\nQGIS Desktop 3.22 User Guide\n•Clear result: Remove results in the window\n•Clear highlights: Remove features highlighted on the map\n•Highlight all\n•Highlight layer\n•Activate layer: Choose a layer to be activated\n•Layer properties: Open layer properties window\n•Expand all\n•Collapse all\n11.6Save and Share Layer Properties\n11.6.1Managing Custom Styles\nWhen a vector layer is added to the map canvas, QGIS by default uses a random symbol/color to render its features.\nHowever, you can set a default symbol in\nProject\n►\nProperties...\n►\nDefault styles\nthat will be applied to each newly\nadded layer according to its geometry type.\nMost of the time, though, you’d rather have a custom and more complex style that can be applied automatically or\nmanually to the layers (with less effort). You can achieve this by using theStylemenu at the bottom of the Layer\nProperties dialog. This menu provides you with functions to create, load and manage styles.\nA style stores any information set in the layer properties dialog to render or interact with the layer (including sym-\nbology, labeling, fields and form definitions, actions, diagrams...) for vector layers, or the pixels (band or color\nrendering, transparency, pyramids, histogram ...) for raster.\nFig. 11.25: Vector layer style combo box options\n158Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nBy default, the style applied to a loaded layer is nameddefault. Once you have got the ideal and appropriate\nrendering for your layer, you can save it by clicking theStylecombo box and choosing:\n•Rename Current: The active style is renamed and updated with the current options\n•Add: A new style is created using the current options. By default, it will be saved in the QGIS project file. See\nbelow to save the style in another file or a database\n•Remove: Delete unwanted style, in case you have more than one style defined for the layer.\nAt the bottom of the Style drop-down list, you can see the styles set for the layer with the active one checked.\nNote that each time you validate the layer properties dialog, the active style is updated with the changes you’ve made.\nYou can create as many styles as you wish for a layer but only one can be active at a time. In combination withMap\nThemes, this offers a quick and powerful way to manage complex projects without the need to duplicate any layer in\nthe map legend.\nNote:Given that whenever you apply modifications to the layer properties, changes are stored in the active style,\nalways ensure you are editing the right style to avoid mistakenly altering a style used in amap theme.\nTip: Manage styles from layer context menu\nRight-click on the layer in theLayerspanel to copy, paste, add or rename layer styles.\n11.6.2Storing Styles in a File or a Database\nWhile styles created from theStylecombo box are by default saved inside the project and can be copied and pasted\nfrom layer to layer in the project, it’s also possible to save them outside the project so that they can be loaded in\nanother project.\nSave as text file\nClicking theStyle►Save Style, you can save the style as a:\n•QGIS layer style file (.qml)\n•SLD file (.sld), only available for vector layers\nUsed on file-based format layers (.shp,.tab...),Save as Defaultgenerates a.qmlfile for the layer (with the\nsame name). SLDs can be exported from any type of renderer – single symbol, categorized, graduated or rule-based\n– but when importing an SLD, either a single symbol or rule-based renderer is created. This means that categorized\nor graduated styles are converted to rule-based. If you want to preserve those renderers, you have to use the QML\nformat. On the other hand, it can be very handy sometimes to have this easy way of converting styles to rule-based.\nSave in database\nVector layer styles can also be stored in a database if the layer datasource is a database provider. Supported for-\nmats are PostGIS, GeoPackage, SpatiaLite, MSSQL and Oracle. The layer style is saved inside a table (named\nlayer_styles) in the database. Click onSave Style...►Save in databasethen fill in the dialog to define a style\nname, add a description, a.uifile if applicable and to check if the style should be the default style.\nYou can save several styles for a single table in the database. However, each table can have only one default style.\nDefault styles can be saved in the layer database or inqgis.db, a local SQLite database in the active\nuser profile\ndirectory.\n11.6. Save and Share Layer Properties159\n\nQGIS Desktop 3.22 User Guide\nFig. 11.26: Save Style in database Dialog\nTip: Sharing style files between databases\nYou can only save your style in a database if the layer comes from such a database. You can’t mix databases (layer\nin Oracle and style in MSSQL for instance). Use instead a plain text file if you want the style to be shared among\ndatabases.\nNote:You may encounter issues restoring thelayer_stylestable from a PostgreSQL database backup. Follow\nQGIS layer_style table and database backupto fix that.\nLoad style\nWhen loading a layer in QGIS, if a default style already exists for this layer, QGIS loads the layer with this style. Also\nStyle►Restore Defaultlooks for and loads that file, replacing the layer’s current style.\nStyle►Load Stylehelps you apply any saved style to a layer. While text-file styles (.sldor.qml) can be applied to\nany layer whatever its format, loading styles stored in a database is only possible if the layer is from the same database\nor the style is stored in the QGIS local database.\nTheDatabase Styles Managerdialog displays a list of styles related to the layer found in the database and all the other\nstyles saved in it, with name and description.\nTip: Quickly share a layer style within the project\nYou can also share layer styles within a project without importing a file or database style: right-click on the layer in\ntheLayers Paneland, from theStylescombo box , copy the style of a layer and paste it to a group or a selection of\nlayers: the style is applied to all the layers that are of the same type (vector vs raster) as the original layer and, in the\ncase of vector layers, have the same geometry type (point, line or polygon).\n160Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n11.6.3Layer definition file\nLayer definitions can be saved as aLayer Definition File(.qlr) usingExport►Save As Layer Definition\nFile...in the active layers’ context menu. A layer definition file (.qlr) includes references to the data source of the\nlayers and their styles.\n.qlr\nfiles are shown in the Browser Panel and can be used to add the layers (with the saved\nstyle) to the Layers Panel. You can also drag and drop.qlrfiles from the system file manager into the map canvas.\n11.7Documenting your data\nIn addition to displaying and symbolizing the data in the layers, QGIS allows you to fill:\n•metadata: information to help people find and understand the dataset, how they can access and use it... these\nare properties of the datasource and can live out of the QGIS project.\n•notes: instructions and comments regarding the layer in the current project\n11.7.1Metadata\nIn the layer properties dialog, theMetadatatab provides you with options to create and edit a metadata report on\nyour layer.\nInformation to fill concern:\n•the dataIdentification: basic attribution of the dataset (parent, identifier, title, abstract, language...);\n•theCategoriesthe data belongs to. Alongside theISOcategories, you can add custom ones;\n•theKeywordsto retrieve the data and associated concepts following a standard based vocabulary;\n•theAccessto the dataset (licenses, rights, fees, and constraints);\n•theExtentof the dataset, either spatial one (CRS, map extent, altitudes) or temporal;\n•theContactof the owner(s) of the dataset;\n•theLinksto ancillary resources and related information;\n•theHistoryof the dataset.\nA summary of the filled information is provided in theValidationtab and helps you identify potential issues related\nto the form. You can then either fix them or ignore them.\nMetadata are currently saved in the project file. They can also be saved in a.qmdfile alongside file based layers or\nin a local.sqlitedatabase for remote layers (e.g. PostGIS).\n11.7.2Layer notes\nLayer notes allow you to document the layer within the current project. They can be place to store important messages\nfor users of the project like to do lists, instructions, warnings, ...\nFrom the layer’s contextual menu inLayerspanel, selectAdd layer notes...and fill the open dialog with necessary\ntexts.\n11.7. Documenting your data161\n\nQGIS Desktop 3.22 User Guide\nFig. 11.27: Adding notes to a layer\nTheAdd layer notesdialog provides a html-based multiline text box with a complete set of tools for:\n•text manipulation: cut, copy, paste, undo, redo\n•characters formatting, applied to all or parts of the contents: font size and color, bold, italic, underline,\nstrikethrough, background color, URL highlighting\n•paragraph structuring: bullet and numbered lists, indentation, predefined headings\n•file insertion, even with drag-and-drop\n•editing with HTML coding\nFrom the...drop-down at the far right of the toolbar, you can:\n•Remove all formatting\n•Remove character formatting\n•Clear all content\nIn theLayerspanel, a layer with a note is assigned theicon which, upon hover, displays the note. Click the icon\nto edit the note. You can as well right-click the layer andEdit layer note...orRemove layer note.\nNote:Notes are part of thelayer styleand can be saved in the.qmlor.qlrfile. They can also be transferred\nfrom one layer to another while copy-pasting the layer style.\n11.8Storing values in Variables\nIn QGIS, you can use variables to store useful recurrent values (e.g. the project’s title, or the user’s full name) that can\nbe used in expressions. Variables can be defined at the application’s global level, project level, layer level, processing\nmodeler level, layout level, and layout item’s level. Just like CSS cascading rules, variables can be overwritten - e.g.,\na project level variable will overwrite any application global level variables set with the same name. You can use\nthese variables to build text strings or other custom expressions using the@character before the variable name. For\nexample in print layout creating a label with this content:\nThismapwas made using QGIS [%@qgis_version%].The project fileforthis\nmapis: [%@project_path%]\nWill render the label like this:\n162Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nThismapwas made using QGIS3.4.4-Madeira.The project fileforthismapis:\n/gis/qgis-user-conference-2019.qgs\nBesides thepreset read-only variables, you can define your own custom variables for any of the levels mentioned\nabove. You can manage:\n•global variablesfrom theSettings►Optionsmenu\n•project variablesfrom theProject Propertiesdialog (seeProject Properties)\n•vector layer variablesfrom theLayer Propertiesdialog (seeThe Vector Properties Dialog);\n•modeler variablesfrom theGraphical Modelerdialog (seeThe graphical modeler);\n•layout variablesfrom theLayoutpanel in the Print layout (seeThe Layout Panel);\n•andlayout item variablesfrom theItem Propertiespanel in the Print layout (seeLayout Items Common Op-\ntions\n).\nTo differentiate from editable variables, read-only variable names and values are displayed in italic. On the other\nhand, higher level variables overwritten by lower level ones are strike through.\nFig. 11.28: Variables editor at the project level\n11.8. Storing values in Variables163\n\nQGIS Desktop 3.22 User Guide\nNote:You can read more about variables and find some examples in Nyall Dawson’sExploring variables in QGIS\n2.12, part 1,part 2andpart 3blog posts.\n11.9Authentication\nQGIS has the facility to store/retrieve authentication credentials in a secure manner. Users can securely save creden-\ntials into authentication configurations, which are stored in a portable database, can be applied to server or database\nconnections, and are safely referenced by their ID tokens in project or settings files. For more information seeAu-\nthentication System.\nA master password needs to be set up when initializing the authentication system and its portable database.\n11.10Common widgets\nIn QGIS, there are some options you’ll often have to work with. For convenience, QGIS provides you with special\nwidgets that are presented below.\n11.10.1Color Selector\nThe color dialog\nTheSelect Colordialog will appear whenever you click theicon to choose a color. The features\nof this dialog depend on the state of theUse native color chooser dialogsparameter checkbox inSettings►Options...\n►General. When checked, the color dialog used is the native one of the OS on which QGIS is running. Otherwise,\nthe QGIS custom color chooser is used.\nThe custom color chooser dialog has four different tabs which allow you to select colors by\nColor ramp\n,\nColor wheel\n,\nColor swatches\nor\nColor picker\n. With the first two tabs, you can browse to all possible color combinations and apply\nyour choice to the item.\n164Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nFig. 11.29: Color selector ramp tab\nIn the\nColor swatches\ntab, you can choose from a list of color palettes (seeColors Settingsfor details). All but the\nRecent colorspalette can be modified with the\nAdd current color\nand\nRemove selected color\nbuttons at the bottom of\nthe frame.\nThe...button next to the palette combo box also offers several options to:\n•copy, paste, import or export colors\n•create, import or remove color palettes\n•add the custom palette to the color selector widget with theShow in Color Buttonsitem (seeFig. 11.31)\n11.10. Common widgets165\n\nQGIS Desktop 3.22 User Guide\nFig. 11.30: Color selector swatches tab\nAnother option is to use the\nColor picker\nwhich allows you to sample a color from under your mouse cursor at any\npart of the QGIS UI or even from another application: press the space bar while the tab is active, move the mouse\nover the desired color and click on it or press the space bar again. You can also click theSample Colorbutton to\nactivate the picker.\nWhatever method you use, the selected color is always described through color sliders forHSV(Hue, Saturation,\nValue) andRGB(Red, Green, Blue) values. The color is also identifiable inHTML notation.\nModifying a color is as simple as clicking on the color wheel or ramp or on any of the color parameters sliders. You\ncan adjust such parameters with the spinbox beside or by scrolling the mouse wheel over the corresponding slider.\nYou can also type the color in HTML notation. Finally, there is anOpacityslider to set transparency level.\nThe dialog also provides a visual comparison between theOldcolor (applied to object) and theCurrentone (being\nselected). Using drag-and-drop or pressing the\nAdd color to swatch\nbutton, any of these colors can be saved in a slot\nfor easy access.\nTip: Quick color modification\nDrag-and-drop a color selector widget onto another one to apply its color.\n166Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nThe color drop-down shortcut\nClick the drop-down arrow to the right of thecolor button to display a widget for quick color\nselection. This shortcut provides access to:\n•a color wheel to pick a color from\n•an alpha slider to change color opacity\n•the color palettes previously set toShow in Color Buttons\n•copy the current color and paste it into another widget\n•pick a color from anywhere on your computer display\n•choose a color from the color selector dialog\n•drag-and-drop the color from one widget to another for quick modification\nNote:\nWhen the color widget is set to a\nproject colorthrough the data-defined override properties, the above functions\nfor changing the color are unavailable. You’d first need toUnlink colororClearthe definition.\nFig. 11.31: Quick color selector menu\n11.10. Common widgets167\n\nQGIS Desktop 3.22 User Guide\nThe color ramp drop-down shortcut\nColor ramps are a practical way to apply a set of colors to one or many features. Their creation is described in theSet-\nting a Color Rampsection. As for the colors, pressing thecolor ramp button opens the corresponding\ncolor ramp type dialog allowing you to change its properties.\nFig. 11.32: Customizing a colorbrewer ramp\nThe drop-down menu to the right of the button gives quick access to a wider set of color ramps and options:\n•Invert Color Ramp\n•Random Colors: available only in some contexts (e.g., when a color ramp is being used for a layer symbol-\nogy), checking this entry creates and applies a color ramp with random colors. It also enables a\nShuffle random\ncolorsentry to regenerate a new random color ramp if the current one is not satisfactory.\n•a preview of thegradientorcatalog:  cpt-citycolor ramps flagged asFavoritesin theStyle\nManagerdialog\n•All Color Rampsto access the compatible color ramps database\n•Create New Color Ramp...of any supported type that could be used in the current widget (note that this color\nramp will not be available elsewhere unless you save it in the library)\n•Edit Color Ramp..., the same as clicking the whole color ramp button\n•Save Color Ramp..., to save the current color ramp with its customizations in the style library\n168Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\nFig. 11.33: Quick color ramp selection widget\n11.10.2Symbol Widget\nTheSymbolselector widget is a convenient shortcut when you want to set symbol properties of a feature. Clicking\nthe drop-down arrow shows the following symbol options, together with the features of thecolor drop-down widget:\n•Configure Symbol...: the same as pressing the symbol selector widget. It opens a dialog to set thesymbol\nparameters.\n•Copy Symbolfrom the current item\n•Paste Symbolto the current item, speeding configuration\n11.10.3Remote or embedded file selector\nAlong with the file selector widget, the...button will sometimes show a drop-down arrow. This is usually available\nwhen using:\n•an SVG file in a symbol or a label\n•a raster image to customize symbols, labels, textures or decorations\nPressing the arrow will provide you with a menu to:\n•load the file from the file system: the file is identified through the file path and QGIS needs to resolve the path\nin order to display the corresponding image\n•load the file from a remote URL: as above, the image will only be loaded on successful retrieval of the remote\nresource\n•embed the file into the item: the file is embedded inside the current project, style database, or print layout\ntemplate. The file is then always rendered as part of the item. This is a convenient way to create self-contained\nprojects with custom symbols which can be easily shared amongst different users and installations of QGIS.\n•extract the embedded file from the widget and save it on disk.\n11.10. Common widgets169\n\nQGIS Desktop 3.22 User Guide\n11.10.4Spatial Extent Selector\nTheExtentselector widget is a convenient shortcut when you want to select a spatial extent to assign to a layer or to\nlimit the actions to run on. Depending on the context, it offers selection between:\n•Current layer extent, e.g. when exporting a layer\n•Calculate from layer►: uses extent of a layer loaded in the current project\n•Use currentMap canvas extent\n•Draw on canvasa rectangle whose coordinates are then used\n•Enter or edit the coordinates asxmin, xmax, ymin, ymax\nFig. 11.34: Extent selector widget\n11.10.5Font Selector\nTheFontselector widget is a convenient shortcut when you want to set font properties for textual information (feature\nlabels, decoration labels, map legend text, ...). Clicking the drop-down arrow shows some or all of the following\noptions:\nFig. 11.35: Font selector drop-down menu\n•Font Sizein the associated unit\n170Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n•Recent Fonts► menu with the active font checked (at the top)\n•Configure Format...: same as pressing the font selector widget. It opens a dialog to set text format parameters.\nDepending on the context, it can be the OS defaultText formatdialog or the QGIS custom dialog with advanced\nformatting options (opacity, orientation, buffer, background, shadow, ...) as described in sectionFormatting\nthe label text.\n•Copy Formatof the text\n•Paste Formatto the text, speeding configuration\n•thecolor widgetfor quick color setting\n11.10.6Unit Selector\nSize properties of the items (labels, symbols, layout elements, ...) in QGIS are not necessarily bound to either the\nproject units or the units of a particular layer. For a large set of properties, the\nUnit\nselector drop-down menu allows\nyou to tweak their values according to the rendering you want (based on screen resolution, paper size, or the terrain).\nAvailable units are:\n•Millimeters\n•Points\n•Pixels\n•Inches\n•Meters at Scale: This allows you to always set the size in meters, regardless of what the underlying map units\nare (e.g. they can be in inches, feet, geographic degrees, ...). The size in meters is calculated based on\nthe current project ellipsoid setting and a projection of the distances in meters at the center of the current\nmap extent. For maps in a projected coordinate system this is calculated using projected units. For maps\nin a geographic (latitude/longitude) based system the size is approximated by calculating meter sizes using\nellipsoidal calculations for the vertical scale of the map.\n•andMap Units: The size is scaled according to the map view scale. Because this can lead to too big or too\nsmall values, use thebutton next to the entry to constrain the size to a range of values based on:\n–TheMinimum scaleand theMaximum scale: The value is scaled based on the map view scale until you\nreach any of these scale limits. Out of the range of scale, the value at the nearest scale limit is kept.\n–and/or TheMinimum sizeand theMaximum sizeinmm: The value is scaled based on the map view scale\nuntil it reaches any of these limits; Then the limit size is kept.\nFig. 11.36: Adjust scaling range dialog\n11.10. Common widgets171\n\nQGIS Desktop 3.22 User Guide\n11.10.7Number Formatting\nNumeric formatters allow formatting of numeric values for display, using a variety of different formatting techniques\n(for instance scientific notation, currency values, percentage values, etc). One use of this is to set text in a layout scale\nbar or fixed table.\nFig. 11.37: Formatting numeric value\nDifferent categories of formats are supported. For most of them, you can set part or all of the following numeric\noptions:\n•Show thousands separator\n•Show plus sign\n•Show trailing zeros\nBut they can also have their custom settings. Provided categories are:\n•General, the default category: has no setting and displays values as set in the parent widget properties or using\nthe global settings.\n•Number\n–The value can beRound toa self defined number ofDecimal placesor theirSignificant figures\n–customize theThousands separatorandDecimal separator\n•Bearingfor a text representation of a direction/bearing using:\n–Format: possible ranges of values are0 to 180°, with E/W suffix,-180 to +180°and\n0 to 360°\n–number ofDecimal places\n•Currencyfor a text representation of a currency value.\n–Prefix\n–Suffix\n–number ofDecimal places\n•Fractionfor a vulgar fractional representation of a decimal value (e.g.1/2instead of0.5)\n–Use unicode super/subscriptto show. For example\n1/2\ninstead of 1/2\n172Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n–Use dedicated Unicode characters\n–customize theThousands separator\n•Percentage- appends%to the values, with setting of:\n–number ofDecimal places\n–Scalingto indicate whether the actual values already represent percentages (then they will be kept as is)\nor fractions (then they are converted)\n•Scientificnotation in the form2.56e+03. The number ofDecimal placescan be set.\nA live preview of the settings is displayed under theSamplesection.\n11.10.8Blending Modes\nQGIS offers different options for special rendering effects with these tools that you may previously only know from\ngraphics programs. Blending modes can be applied on layers and features, and also on print layout items:\n•Normal: This is the standard blend mode, which uses the alpha channel of the top pixel to blend with the pixel\nbeneath it. The colors aren’t mixed.\n•Lighten: This selects the maximum of each component from the foreground and background pixels. Be aware\nthat the results tend to be jagged and harsh.\n•Screen: Light pixels from the source are painted over the destination, while dark pixels are not. This mode is\nmost useful for mixing the texture of one item with another item (such as using a hillshade to texture another\nlayer).\n•Dodge: Brighten and saturate underlying pixels based on the lightness of the top pixel. Brighter top pixels\ncause the saturation and brightness of the underlying pixels to increase. This works best if the top pixels aren’t\ntoo bright. Otherwise the effect is too extreme.\n•Addition: Adds pixel values of one item to the other. In case of values above the maximum value (in the case\nof RGB), white is displayed. This mode is suitable for highlighting features.\n•Darken: Retains the lowest values of each component of the foreground and background pixels. Like lighten,\nthe results tend to be jagged and harsh.\n•Multiply: Pixel values of the top item are multiplied with the corresponding values for the bottom item. The\nresults are darker.\n•Burn: Darker colors in the top item cause the underlying items to darken. Burn can be used to tweak and\ncolorize underlying layers.\n•Overlay: Combines multiply and screen blending modes. Light parts become lighter and dark parts become\ndarker.\n•Soft light: Very similar to overlay, but instead of using multiply/screen it uses color burn/dodge. This is\nsupposed to emulate shining a soft light onto an image.\n•Hard light: Hard light is also very similar to the overlay mode. It’s supposed to emulate projecting a very\nintense light onto an image.\n•Difference: Subtracts the top pixel from the bottom pixel, or the other way around, in order always to get a\npositive value. Blending with black produces no change, as the difference with all colors is zero.\n•Subtract: Subtracts pixel values of one item from the other. In the case of negative values, black is displayed.\n11.10. Common widgets173\n\nQGIS Desktop 3.22 User Guide\n11.10.9Data defined override setup\nNext to many options in the vector layer properties dialog or settings in the print layout, you will find a\nData defined override\nicon. Usingexpressionsbased on layer attributes or item settings, prebuilt or custom functions and\nvariables, this tool allows you to set dynamic values for parameters. When enabled, the value returned by this widget\nis applied to the parameter regardless of its normal value (checkbox, textbox, slider...).\nThe data defined override widget\nClicking the\nData defined override\nicon shows the following entries:\n•Description...that indicates if the option is enabled, which input is expected, the valid input type and the current\ndefinition. Hovering over the widget also pops up this information.\n•Store data in the project: a button allowing the property to be stored using to theAuxiliary Storage Properties\nmechanism.\n•Field type: an entry to select from the layer’s fields that match the valid input type.\n•Color: when the widget is linked to a color property, this menu gives access to the colors defined as part of the\ncurrentproject’s colorsscheme.\n•Variable: a menu to access the available user-definedvariables\n•Edit...button to create or edit the expression to apply, using theExpression String Builderdialog. To help you\ncorrectly fill in the expression, a reminder of the expected output’s format is provided in the dialog.\n•PasteandCopybuttons.\n•Clearbutton to remove the setup.\n•For numeric and color properties,Assistant...to rescale how the feature data is applied to the property (more\ndetailsbelow)\nTip: Use right-click to (de)activate the data override\nWhen the data-defined override option is set up correctly the icon is yellow\nor. If it is broken, the icon is red\nor.\nYou can enable or disable a configured\nData-defined override\nbutton by simply clicking the widget with the right mouse\nbutton.\nUsing the data-defined assistant interface\nWhen the\nData-defined override\nbutton is associated with a size, a rotation, an opacity or a color property, it has an\nAssistant...option that helps you change how the data is applied to the parameter for each feature. The assistant\nallows you to:\n•Define theInputdata, ie:\n–Source: the attribute to represent, using a field or anexpression\n–the range of values to represent: you can manually enter the values or use the\nFetch value range from layer\nbutton to fill these fields automatically with the minimum and maximum values returned by theSource\nexpression applied to your data\n174Chapter 11. General Tools\n\nQGIS Desktop 3.22 User Guide\n•Apply transform curve: by default, output values (see below for setting) are applied to input features fol-\nlowing a linear scale. You can override this logic: enable the transform option, click on the graphic to add\nbreak point(s) and drag the point(s) to apply a custom distribution.\n•Define theOutputvalues: the options vary according to the parameter to define. You can globally set:\n–for a color setting, thecolor rampto apply to values and the single color to use for NULL values\n–for the others, the minimum and maximum values to apply to the selected property as well as the\nsize/angle/opacity value for ignored or NULL source features\n–for size properties, theScale methodof representation which can beFlannery,Exponential,Surface,\nRadiusorLinear\n–theExponentto use for data scaling when theScale methodis of exponential type or when tweaking the\nopacity\nWhen compatible with the property, a live-update preview is displayed in the right-hand side of the dialog to help\nyou control the value scaling.\nFig. 11.38: Scaling feature size based on passengers field’s value\nThe values presented in the varying size assistant above will set the size ‘Data-defined override’ with:\ncoalesce(scale_exp(\"passengers\",9,2000,1,10,0.57),0)\n11.10. Common widgets175\n\nQGIS Desktop 3.22 User Guide\n176Chapter 11. General Tools\n\nCHAPTER\nTWELVE\nLEVEL UP WITH EXPRESSIONS\n12.1Expressions\nBased on layer data and prebuilt or user defined functions,Expressionsoffer a powerful way to manipulate attribute\nvalue, geometry and variables in order to dynamically change the geometry style, the content or position of the label,\nthe value for diagram, the height of a layout item, select some features, create virtual field, ...\nNote:A list of the default functions and variables for writing expressions can be found atList of functions, with\ndetailed information and examples.\n12.1.1The Expression string builder\nMain dialog to build expressions, theExpression string builderis available from many parts in QGIS and, can partic-\nularly be accessed when:\n•clicking thebutton;\n•selecting featureswith the\nSelect By Expression...\ntool;\n•editing attributeswith e.g. the\nField calculator\ntool;\n•manipulating symbology, label or layout item parameters with the\nData defined override\ntool (seeData defined\noverride setup);\n•building ageometry generatorsymbol layer;\n•doing somegeoprocessing.\nThe Expression builder dialog offers access to the:\n•Expression tabwhich, thanks to a list of predefined functions, helps to write and check the expression to use;\n•Function Editor tabwhich helps to extend the list of functions by creating custom ones.\n177\n\nQGIS Desktop 3.22 User Guide\nThe Interface\nTheExpressiontab provides the main interface to write expressions using functions, layer fields and values. It contains\nthe following widgets:\nFig. 12.1: The Expression tab\n•An expression editor area for typing or pasting expressions. Autocompletion is available to speed expression\nwriting:\n–Corresponding variables, function names and field names to the input text are shown below: use theUp\nandDownarrows to browse the items and pressTabto insert in the expression or simply click on the\nwished item.\n–Function parameters are shown while filling them.\nQGIS also checks the expression rightness and highlights all the errors using:\n–Underline: for unknown functions, wrong or invalid arguments;\n–Marker: for every other error (eg, missing parenthesis, unexpected character) at a single location.\nTip: Document your expression with comments\nWhen using complex expression, it is good practice to add text either as a multiline comment or inline comments\nto help you remember.\n/*\nLabels each region with its highest (in altitude) airport(s)\nand altitude, eg 'AMBLER : 264m' for the 'Northwest Artic' region\n*/\nwith_variable(\n'airport_alti', -- stores the highest altitude of the region\naggregate(\n'airports',\n'max',\n\"ELEV\", -- the field containing the altitude\n-- and limit the airports to the region they are within\nfilter := within( $geometry, geometry( @parent ) )\n),\n(continues on next page)\n178Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\naggregate( -- finds airports at the same altitude in the region\n'airports',\n'concatenate',\n\"NAME\",\nfilter := within( $geometry, geometry( @parent ) )\nand \"ELEV\" = @airport_alti\n)\n|| ' : ' || @airport_alti || 'm'\n-- using || allows regions without airports to be skipped\n)\n•Above the expression editor, a set of tools helps you:\n–\nClear the expression editor\n–create and manageuser expressions\n•Under the expression editor, you find:\n–a set of basic operators to help you build the expression\n–an indication of the expected format of output when you are data-defining feature properties\n–a liveOutput previewof the expression, evaluated on the first feature of the Layer by default. You can\nbrowse and evaluate other features of the layer using theFeaturecombobox (the values are taken from\nthedisplay nameproperty of the layer).\nIn case of error, it indicates it and you can access the details with the provided hyperlink.\n•A function selector displays the list of functions, variables, fields... organized in groups. A search box is\navailable to filter the list and quickly find a particular function or field. Double-clicking an item adds it to the\nexpression editor.\n•A help panel displays help for each selected item in the function selector.\nTip:PressCtrl+Clickwhen hovering a function name in an expression to automatically display its help\nin the dialog.\nA field’s values widget shown when a field is selected in the function selector helps to fetch features attributes:\n–Look for a particular field value\n–Display the list ofAll Uniqueor10 Samplesvalues. Also available from right-click.\nWhen the field is mapped with another layer or a set of values, i.e. if thefield widgetis ofRelationRef-\nerence,ValueRelationorValueMaptype, it’s possible to list all the values of the mapped field (from the\nreferenced layer, table or list). Moreover, you can filter this list toOnly show values in usein the\ncurrent field.\nDouble-clicking a field value in the widget adds it to the expression editor.\nTip:The right panel, showing functions help or field values, can be collapsed (invisible) in the dialog. Press\ntheShow ValuesorShow Helpbutton to get it back.\n12.1. Expressions179\n\nQGIS Desktop 3.22 User Guide\nWriting an expression\nQGIS expressions are used to select features or set values. Writing an expression in QGIS follows some rules:\n1.The dialog defines the context: if you are used to SQL, you probably know queries of the typeselect features\nfrom layer where conditionorupdate layer set field = new_value where condition. A QGIS expression also\nneeds all these information but the tool you use to open the expression builder dialog provides parts of them.\nFor example, giving a layer (buildings) with a field (height):\n•pressing the\nSelect by expression\ntool means that you want to “select features from buildings”. Thecondi-\ntionis the only information you need to provide in the expression text widget, e.g. type\"height\" >\n20to select buildings that are higher than 20.\n•with this selection made, pressing the\nField calculator\nbutton and choosing “height” asUpdate existing\nfield, you already provide the command “update buildings set height = ??? where height > 20”. The only\nremaining bits you have to provide in this case is thenew value, e.g. just enter50in the expression\neditor textbox to set the height of the previously selected buildings.\n2.Pay attention to quotes: single quotes return a literal, so a text placed between single quotes ('145') is\ninterpreted as a string. Double quotes will give you the value of that text so use them for fields (\"myfield\").\nFields can also be used without quotes (myfield). No quotes for numbers (3.16).\nNote:Functions normally take as argument a string for field name. Do:\nattribute(@atlas_feature,'height')--returns the value storedinthe\n,→\"height\"attribute of the current atlas feature\nAnd not:\nattribute(@atlas_feature,\"height\")--fetches the value of the attribute␣\n,→named\"height\"(e.g.100),anduse that valueasa field\n--fromwhichtoreturnthe atlas␣\n,→feature value.Probably wrongasa field named\"100\"maynotexist.\nTip: Use named parameters to ease expression reading\nSome functions require many parameters to be set. The expression engine supports the use of named parameters.\nThis means that instead of writing the cryptic expressionclamp( 1, 2, 9), you can useclamp( min:=1,\nvalue:=2, max:=9). This also allows arguments to be switched, e.g.clamp( value:=2, max:=9,\nmin:=1). Using named parameters helps clarify what the arguments for an expression function refer to, which is\nhelpful when you are trying to interpret an expression later!\nSome use cases of expressions\n•From the Field Calculator, calculate a “pop_density” field using the existing “total_pop” and “area_km2” fields:\n\"total_pop\"/\"area_km2\"\n•Label or categorize features based on their area:\nCASE WHEN $area > 10 000 THEN 'Larger' ELSE 'Smaller' END\n•Update the field “density_level” with categories according to the “pop_density” values:\nCASE WHEN\"pop_density\"<50THEN'Low population density'\nWHEN\"pop_density\">=50and\"pop_density\"<150THEN'Medium population␣\n,→density'\n(continues on next page)\n180Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\nWHEN\"pop_density\">=150THEN'High population density'\nEND\n•Apply a categorized style to all the features according to whether their average house price is smaller or higher\nthan 10000€ per square metre:\n\"price_m2\">10000\n•Using the “Select By Expression...” tool, select all the features representing areas of “High population density”\nand whose average house price is higher than 10000€ per square metre:\n\"density_level\"='High population density'and\"price_m2\">10000\nThe previous expression could also be used to define which features to label or show on the map.\n•Create a different symbol (type) for the layer, using the geometry generator:\npoint_on_surface( $geometry )\n•Given a point feature, generate a closed line (usingmake_line) around its geometry:\nmake_line(\n-- using an array of points placed around the original\narray_foreach(\n-- list of angles for placing the projected points (every 90°)\narray:=generate_series( 0, 360, 90 ),\n-- translate the point 20 units in the given direction (angle)\nexpression:=project( $geometry, distance:=20, azimuth:=radians( @element )␣\n,→)\n)\n)\n•In a print layout label, display the name of the “airports” features that are within the layout “Map 1” item:\nwith_variable( 'extent',\nmap_get( item_variables( 'Map 1' ), 'map_extent' ),\naggregate( 'airports', 'concatenate', \"NAME\",\nintersects( $geometry, @extent ), ' ,'\n)\n)\nSaving Expressions\nUsing the\nAdd current expression to user expressions\nbutton above the expression editor frame, you can save important ex-\npressions you want to have quick access to. These are available from theUser expressionsgroup in the middle panel.\nThey are saved under the\nuser profile(<userprofile>/QGIS/QGIS3.inifile) and available in all expression\ndialogs inside all projects of the current user profile.\nA set of tools available above the expression editor frame helps you manage the user expressions:\n•\nAdd the current expression to user expressions\n: store the expression in the user profile. A label and a help text can be\nadded for easy identification.\n•\nEdit selected expression from user expressions\n, as well as their help and label\n•\nRemove selected expression from user expressions\n•\nImport user expressions\nfrom a.jsonfile into the active user profile folder\n12.1. Expressions181\n\nQGIS Desktop 3.22 User Guide\n•\nExport user expressions\nas a.jsonfile; all the user expressions in the user profileQGIS3.inifile are shared\n12.1.2Function Editor\nWith theFunction Editortab, you are able to write your own functions in Python language. This provides a handy\nand comfortable way to address particular needs that would not be covered by the predefined functions.\nFig. 12.2: The Function Editor tab\nTo create a new function:\n1.Press the\nNew File\nbutton.\n2.Enter a name to use in the form that pops up and pressOK.\nA new item of the name you provide is added in the left panel of theFunction Editortab; this is a Python.py\nfile based on QGIS template file and stored in the/python/expressionsfolder under the active\nuser\nprofiledirectory.\n3.The right panel displays the content of the file: a python script template. Update the code and its help according\nto your needs.\n4.Press theSave and Load Functionsbutton. The function you wrote is added to the functions tree in the\nExpressiontab, by default under theCustomgroup.\n5.Enjoy your new function.\n6.If the function requires improvements, enable theFunction Editortab, do the changes and press again the\nSave and Load Functionsbutton to make them available in the file, hence in any expression tab.\nCustom Python functions are stored under the user profile directory, meaning that at each QGIS startup, it will auto\nload all the functions defined with the current user profile. Be aware that new functions are only saved in the/\npython/expressionsfolder and not in the project file. If you share a project that uses one of your custom\nfunctions you will need to also share the.pyfile in the/python/expressionsfolder.\nTo delete a custom function:\n1.Enable theFunction Editortab\n182Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n2.Select the function in the list\n3.Press the\nRemove selected function\n. The function is removed from the list and the corresponding.pyfile deleted\nfrom the user profile folder.\nExample\nHere’s a short example on how to create your ownmy_sumfunction that will operate with two values.\nfromqgis.coreimport*\nfromqgis.guiimport*\n@qgsfunction(args='auto', group='Custom')\ndefmy_sum(value1, value2, feature, parent):\n\"\"\"\nCalculates the sum of the two parameters value1 and value2.\n<h2>Example usage:</h2>\n<ul>\n<li>my_sum(5, 8) -> 13</li>\n<li>my_sum(\"field1\", \"field2\") -> 42</li>\n</ul>\n\"\"\"\nreturnvalue1+value2\nWhen using theargs='auto'function argument the number of function arguments required will be calculated\nby the number of arguments the function has been defined with in Python (minus 2 -feature, andparent). The\ngroup='Custom'argument indicates the group in which the function should be listed in the Expression dialog.\nIt is also possible to add keywords arguments like:\n•usesgeometry=Trueif the expression requires access to the features geometry. By defaultFalse.\n•handlesnull=Trueif the expression has custom handling for NULL values. IfFalse(default), the\nresult will always be NULL as soon as any parameter is NULL.\n•referenced_columns=[list]: An array of attribute names that are required to the function. Defaults\nto[QgsFeatureRequest.ALL_ATTRIBUTES].\nThe previous example function can then be used in expressions:\nFig. 12.3: Custom Function added to the Expression tab\nFurther information about creating Python code can be found in the PyQGIS-Developer-Cookbook.\n12.1. Expressions183\n\nQGIS Desktop 3.22 User Guide\n12.2List of functions\nThe functions, operators and variables available in QGIS are listed below, grouped by categories.\n12.2.1Aggregates Functions\nThis group contains functions which aggregate values over layers and fields.\naggregate\nReturns an aggregate value calculated using features from another layer.\n184Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxaggregate(layer, aggregate, expression, [filter], [concatenator=’’], [order_by])\n[] marks optional arguments\nArguments\n•layer- a string, representing either a layer name or layer ID\n•aggregate- a string corresponding to the aggregate to calculate. Valid options are:\n–count\n–count_distinct\n–count_missing\n–min\n–max\n–sum\n–mean\n–median\n–stdev\n–stdevsample\n–range\n–minority\n–majority\n–q1: first quartile\n–q3: third quartile\n–iqr: inter quartile range\n–min_length: minimum string length\n–max_length: maximum string length\n–concatenate: join strings with a concatenator\n–concatenate_unique: join unique strings with a concatenator\n–collect: create an aggregated multipart geometry\n–array_agg: create an array of aggregated values\n•expression- sub expression or field name to aggregate\n•filter- optional filter expression to limit the features used for calculating the aggregate.\nFields and geometry are from the features on the joined layer. The source feature can be\naccessed with the variable @parent.\n•concatenator- optional string to use to join values for ‘concatenate’ aggregate\n•order_by- optional filter expression to order the features used for calculating the ag-\ngregate. Fields and geometry are from the features on the joined layer. By default, the\nfeatures will be returned in an unspecified order.\nExamples\n•aggregate(layer:='rail_stations',aggregate:='sum',\nexpression:=\"passengers\")→ sum of all values from the passengers\nfield in the rail_stations layer\n•aggregate('rail_stations','sum', \"passengers\"/7)→ calculates a\ndaily average of “passengers” by dividing the “passengers” field by 7 before summing the\nvalues\n•aggregate(layer:='rail_stations',aggregate:='sum',\nexpression:=\"passengers\",filter:=\"class\">3)→  sums  up  all\nvalues from the “passengers” field from features where the “class” attribute is greater than\n3 only\n•aggregate(layer:='rail_stations',aggregate:='concatenate',\nexpression:=\"name\",  concatenator:=',')→ comma separated list of\nthe name field for all features in the rail_stations layer\n•aggregate(layer:='countries',aggregate:='max',\nexpression:=\"code\",  filter:=intersects(  $geometry,  ge-\nometry(@parent) ) )→ The country code of an intersecting country on the layer\n‘countries’\n•aggregate(layer:='rail_stations',aggregate:='sum',\nexpression:=\"passengers\",filter:=contains(\n@atlas_geometry,  $geometry  )  )→ sum of all values from the pas-\nsengers field in the rail_stations within the current atlas feature\n•aggregate(layer:='rail_stations',    aggregate:='collect',\nexpression:=centroid($geometry),  filter:=\"region_name\"  =\nattribute(@parent,'name')  )→ aggregates centroid geometries of the\nrail_stations of the same region as current feature\n12.2. List of functions185\n\nQGIS Desktop 3.22 User Guide\narray_agg\nReturns an array of aggregated values from a field or expression.\nSyntaxarray_agg(expression, [group_by], [filter], [order_by])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\n•order_by- optional expression to use to order features used to calculate aggregate. By\ndefault, the features will be returned in an unspecified order.\nExamples\n•array_agg(\"name\",group_by:=\"state\")→ list of name values, grouped by\nstate field\ncollect\nReturns the multipart geometry of aggregated geometries from an expression\nSyntaxcollect(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- geometry expression to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•collect( $geometry )→ multipart geometry of aggregated geometries\n•collect( centroid($geometry), group_by:=\"region\", filter:=\n\"use\" = 'civilian' )→ aggregated centroids of the civilian features based on\ntheir region value\nconcatenate\nReturns all aggregated strings from a field or expression joined by a delimiter.\nSyntaxconcatenate(expression, [group_by], [filter], [concatenator], [order_by])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\n•concatenator- optional string to use to join values. Empty by default.\n•order_by- optional expression to use to order features used to calculate aggregate. By\ndefault, the features will be returned in an unspecified order.\nExamples\n•concatenate(\"town_name\",group_by:=\"state\",\nconcatenator:=',')→ comma separated list of town_names, grouped by\nstate field\n186Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nconcatenate_unique\nReturns all unique strings from a field or expression joined by a delimiter.\nSyntaxconcatenate_unique(expression, [group_by], [filter], [concatenator], [order_by])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\n•concatenator- optional string to use to join values. Empty by default.\n•order_by- optional expression to use to order features used to calculate aggregate. By\ndefault, the features will be returned in an unspecified order.\nExamples\n•concatenate_unique(\"town_name\",group_by:=\"state\",\nconcatenator:=',')→ comma separated list of unique town_names, grouped by\nstate field\ncount\nReturns the count of matching features.\nSyntaxcount(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression\n- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•count(\"stations\",group_by:=\"state\")→ count of stations, grouped by\nstate field\ncount_distinct\nReturns the count of distinct values.\nSyntaxcount_distinct(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•count_distinct(\"stations\",group_by:=\"state\")→ count of distinct\nstations values, grouped by state field\n12.2. List of functions187\n\nQGIS Desktop 3.22 User Guide\ncount_missing\nReturns the count of missing (NULL) values.\nSyntaxcount_missing(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•count_missing(\"stations\",group_by:=\"state\")→ count of missing\n(NULL) station values, grouped by state field\niqr\nReturns the calculated inter quartile range from a field or expression.\nSyntaxiqr(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•iqr(\"population\",group_by:=\"state\")→ inter quartile range of popula-\ntion value, grouped by state field\nmajority\nReturns the aggregate majority of values (most commonly occurring value) from a field or expression.\nSyntaxmajority(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•majority(\"class\",group_by:=\"state\")→ most commonly occurring class\nvalue, grouped by state field\n188Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nmax_length\nReturns the maximum length of strings from a field or expression.\nSyntaxmax_length(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•max_length(\"town_name\",group_by:=\"state\")→ maximum length of\ntown_name, grouped by state field\nmaximum\nReturns the aggregate maximum value from a field or expression.\nSyntaxmaximum(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•maximum(\"population\",group_by:=\"state\")→ maximum population\nvalue, grouped by state field\nmean\nReturns the aggregate mean value from a field or expression.\nSyntaxmean(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•mean(\"population\",group_by:=\"state\")→  mean  population  value,\ngrouped by state field\n12.2. List of functions189\n\nQGIS Desktop 3.22 User Guide\nmedian\nReturns the aggregate median value from a field or expression.\nSyntaxmedian(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•median(\"population\",group_by:=\"state\")→ median population value,\ngrouped by state field\nmin_length\nReturns the minimum length of strings from a field or expression.\nSyntaxmin_length(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•min_length(\"town_name\",group_by:=\"state\")→ minimum length of\ntown_name, grouped by state field\nminimum\nReturns the aggregate minimum value from a field or expression.\nSyntaxminimum(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•minimum(\"population\",group_by:=\"state\")→ minimum population\nvalue, grouped by state field\n190Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nminority\nReturns the aggregate minority of values (least occurring value) from a field or expression.\nSyntaxminority(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•minority(\"class\",group_by:=\"state\")→ least occurring class value,\ngrouped by state field\nq1\nReturns the calculated first quartile from a field or expression.\nSyntaxq1(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•q1(\"population\",group_by:=\"state\")→ first quartile of population value,\ngrouped by state field\nq3\nReturns the calculated third quartile from a field or expression.\nSyntaxq3(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•q3(\"population\",group_by:=\"state\")→ third quartile of population value,\ngrouped by state field\n12.2. List of functions191\n\nQGIS Desktop 3.22 User Guide\nrange\nReturns the aggregate range of values (maximum - minimum) from a field or expression.\nSyntaxrange(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•range(\"population\",group_by:=\"state\")→ range of population values,\ngrouped by state field\nrelation_aggregate\nReturns an aggregate value calculated using all matching child features from a layer relation.\n192Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxrelation_aggregate(relation, aggregate, expression, [concatenator=’’], [order_by])\n[] marks optional arguments\nArguments\n•relation- a string, representing a relation ID\n•aggregate- a string corresponding to the aggregate to calculate. Valid options are:\n–count\n–count_distinct\n–count_missing\n–min\n–max\n–sum\n–mean\n–median\n–stdev\n–stdevsample\n–range\n–minority\n–majority\n–q1: first quartile\n–q3: third quartile\n–iqr: inter quartile range\n–min_length: minimum string length\n–max_length: maximum string length\n–concatenate: join strings with a concatenator\n–concatenate_unique: join unique strings with a concatenator\n–collect: create an aggregated multipart geometry\n–array_agg: create an array of aggregated values\n•expression- sub expression or field name to aggregate\n•concatenator- optional string to use to join values for ‘concatenate’ aggregate\n•order_by- optional expression to order the features used for calculating the aggregate.\nFields and geometry are from the features on the joined layer. By default, the features will\nbe returned in an unspecified order.\nExamples\n•relation_aggregate(relation:='my_relation',\naggregate:='mean',expression:=\"passengers\")→ mean value of\nall matching child features using the ‘my_relation’ relation\n•relation_aggregate('my_relation','sum',  \"passengers\"/7)→\nsum of the passengers field divided by 7 for all matching child features using the\n‘my_relation’ relation\n•relation_aggregate('my_relation','concatenate',   \"towns\",\nconcatenator:=',')→ comma separated list of the towns field for all matching\nchild features using the ‘my_relation’ relation\n•relation_aggregate('my_relation','array_agg', \"id\")→ array of\nthe id field from all matching child features using the ‘my_relation’ relation\nFurther reading:Creating one or many to many relations\n12.2. List of functions193\n\nQGIS Desktop 3.22 User Guide\nstdev\nReturns the aggregate standard deviation value from a field or expression.\nSyntaxstdev(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•stdev(\"population\",group_by:=\"state\")→ standard deviation of popu-\nlation value, grouped by state field\nsum\nReturns the aggregate summed value from a field or expression.\nSyntaxsum(expression, [group_by], [filter])\n[] marks optional arguments\nArguments\n•expression- sub expression of field to aggregate\n•group_by- optional expression to use to group aggregate calculations\n•filter- optional expression to use to filter features used to calculate aggregate\nExamples\n•sum(\"population\",group_by:=\"state\")→ summed population value,\ngrouped by state field\n12.2.2Array Functions\nThis group contains functions to create and manipulate arrays (also known as list data structures). The order of values\nwithin the array matters, unlike the‘map’ data structure, where the order of key-value pairs is irrelevant and values\nare identified by their keys.\narray\nReturns an array containing all the values passed as parameter.\nSyntaxarray(value1, value2, ...)\nArguments\n•value- a value\nExamples\n•array(2,10)\n→ [ 2, 10 ]\n•array(2,10)[0]→ 2\n194Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\narray_all\nReturns true if an array contains all the values of a given array.\nSyntaxarray_all(array_a, array_b)\nArguments\n•array_a\n- an array\n•array_b- the array of values to search\nExamples\n•array_all(array(1,2,3),array(2,3))→ true\n•array_all(array(1,2,3),array(1,2,4))→ false\narray_append\nReturns an array with the given value added at the end.\nSyntaxarray_append(array, value)\nArguments\n•array- an array\n•value- the value to add\nExamples\n•array_append(array(1,2,3),4)→ [ 1, 2, 3, 4 ]\narray_cat\nReturns an array containing all the given arrays concatenated.\nSyntaxarray_cat(array1, array2, ...)\nArguments\n•array- an array\nExamples\n•array_cat(array(1,2),array(2,3))→ [ 1, 2, 2, 3 ]\narray_contains\nReturns true if an array contains the given value.\nSyntaxarray_contains(array, value)\nArguments\n•array- an array\n•value- the value to search\nExamples\n•array_contains(array(1,2,3),2)→ true\n12.2. List of functions195\n\nQGIS Desktop 3.22 User Guide\narray_count\nCounts the number of occurrences of a given value in an array.\nSyntaxarray_count(array, value)\nArguments\n•array\n- an array\n•value- the value to count\nExamples\n•array_count(array('a', 'b', 'c', 'b'), 'b')→ 2\narray_distinct\nReturns an array containing distinct values of the given array.\nSyntaxarray_distinct(array)\nArguments\n•array- an array\nExamples\n•array_distinct(array(1,2,3,2,1))→ [ 1, 2, 3 ]\narray_filter\nReturns an array with only the items for which the expression evaluates to true.\nSyntaxarray_filter(array, expression, [limit=0])\n[] marks optional arguments\nArguments\n•array- an array\n•expression- an expression to evaluate on each item. The variable@elementwill be re-\nplaced by the current value.\n•limit- maximum number of elements to be returned. Use 0 to return all values.\nExamples\n•array_filter(array(1,2,3),@element < 3)→ [ 1, 2 ]\n•array_filter(array(1,2,3),@element < 3, 1)→ [ 1 ]\narray_find\nReturns the lowest index (0 for the first one) of a value within an array. Returns -1 if the value is not found.\nSyntaxarray_find(array, value)\nArguments\n•array- an array\n•value- the value to search\nExamples\n•array_find(array('a', 'b', 'c'), 'b')→ 1\n•array_find(array('a', 'b', 'c', 'b'), 'b')→ 1\n196Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\narray_first\nReturns the first value of an array.\nSyntaxarray_first(array)\nArguments\n•array\n- an array\nExamples\n•array_first(array('a','b','c'))→ ‘a’\narray_foreach\nReturns an array with the given expression evaluated on each item.\nSyntaxarray_foreach(array, expression)\nArguments\n•array- an array\n•expression- an expression to evaluate on each item. The variable@elementwill be re-\nplaced by the current value.\nExamples\n•array_foreach(array('a','b','c'),upper(@element))→ [ ‘A’, ‘B’,\n‘C’ ]\n•array_foreach(array(1,2,3),@element + 10)→ [ 11, 12, 13 ]\narray_get\nReturns the Nth value (0 for the first one) or the last -Nth value (-1 for the last one) of an array.\nSyntaxarray_get(array, pos)\nArguments\n•array- an array\n•pos- the index to get (0 based)\nExamples\n•array_get(array('a','b','c'),1)→ ‘b’\n•array_get(array('a','b','c'),-1)→ ‘c’\nHint:You can also use theindex operator ([])to get a value from an array.\narray_insert\nReturns an array with the given value added at the given position.\n12.2. List of functions197\n\nQGIS Desktop 3.22 User Guide\nSyntaxarray_insert(array, pos, value)\nArguments\n•array- an array\n•pos- the position where to add (0 based)\n•value- the value to add\nExamples\n•array_insert(array(1,2,3),1,100)→ [ 1, 100, 2, 3 ]\narray_intersect\nReturns true if at least one element of array1 exists in array2.\nSyntaxarray_intersect(array1, array2)\nArguments\n•array1- an array\n•array2\n- another array\nExamples\n•array_intersect(array(1,2,3,4),array(4,0,2,5))→ true\narray_last\nReturns the last value of an array.\nSyntaxarray_last(array)\nArguments\n•array- an array\nExamples\n•array_last(array('a','b','c'))→ ‘c’\narray_length\nReturns the number of elements of an array.\nSyntaxarray_length(array)\nArguments\n•array- an array\nExamples\n•array_length(array(1,2,3))→ 3\n198Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\narray_majority\nReturns the most common values in an array.\nSyntaxarray_majority(array, [option=’all’])\n[] marks optional arguments\nArguments\n•array- an array\n•option=’all’- a string specifying the return values handling. Valid options are:\n–all: Default, all most common values are returned in an array.\n–any: Returns one of the most common values.\n–median: Returns the median of the most common values. Non arithmetic values are\nignored.\n–real_majority: Returns the value which occurs more than half the size of the array.\nExamples\n•array_majority(array(0,1,42,42,43), 'all')→ [ 42 ]\n•array_majority(array(0,1,42,42,43,1), 'all')→ [ 42, 1 ]\n•array_majority(array(0,1,42,42,43,1), 'any')→ 1 or 42\n•array_majority(array(0,1,1,2,2), 'median')→ 1.5\n•array_majority(array(0,1,42,42,43),    'real_majority')→\nNULL\n•array_majority(array(0,1,42,42,43,42),  'real_majority')→\nNULL\n•array_majority(array(0,1,42,42,43,42,42), 'real_majority')\n→ 42\narray_max\nReturns the maximum value of an array.\nSyntaxarray_max(array)\nArguments\n•array- an array\nExamples\n•array_max(array(0,42,4,2))→ 42\narray_mean\nReturns the mean of arithmetic values in an array. Non numeric values in the array are ignored.\nSyntaxarray_mean(array)\nArguments\n•array- an array\nExamples\n•array_mean(array(0,1,7,66.6,135.4))→ 42\n•array_mean(array(0,84,'a','b','c'))→ 42\n12.2. List of functions199\n\nQGIS Desktop 3.22 User Guide\narray_median\nReturns the median of arithmetic values in an array. Non arithmetic values in the array are ignored.\nSyntaxarray_median(array)\nArguments\n•array\n- an array\nExamples\n•array_median(array(0,1,42,42,43))→ 42\n•array_median(array(0,1,2,42,'a','b'))→ 1.5\narray_min\nReturns the minimum value of an array.\nSyntaxarray_min(array)\nArguments\n•array- an array\nExamples\n•array_min(array(43,42,54))→ 42\narray_minority\nReturns the less common values in an array.\nSyntaxarray_minority(array, [option=’all’])\n[] marks optional arguments\nArguments\n•array- an array\n•option=’all’- a string specifying the return values handling. Valid options are:\n–all: Default, all less common values are returned in an array.\n–any: Returns one of the less common values.\n–median: Returns the median of the less common values. Non arithmetic values are\nignored.\n–real_minority: Returns values which occur less than half the size of the array.\nExamples\n•array_minority(array(0,42,42), 'all')→ [ 0 ]\n•array_minority(array(0,1,42,42), 'all')→ [ 0, 1 ]\n•array_minority(array(0,1,42,42,43,1), 'any')→ 0 or 43\n•array_minority(array(1,2,3,3), 'median')→ 1.5\n•array_minority(array(0,1,42,42,43), 'real_minority')→ [ 42,\n43, 0, 1 ]\n•array_minority(array(0,1,42,42,43,42), 'real_minority')→ [\n42, 43, 0, 1 ]\n•array_minority(array(0,1,42,42,43,42,42), 'real_minority')\n→ [ 43, 0, 1 ]\n200Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\narray_prepend\nReturns an array with the given value added at the beginning.\nSyntaxarray_prepend(array, value)\nArguments\n•array\n- an array\n•value- the value to add\nExamples\n•array_prepend(array(1,2,3),0)→ [ 0, 1, 2, 3 ]\narray_prioritize\nReturns an array sorted using the ordering specified in another array. Values which are present in the first array but\nare missing from the second array will be added to the end of the result.\nSyntaxarray_prioritize(array, array_prioritize)\nArguments\n•array- an array\n•array_prioritize- an array with values ordered by priority\nExamples\n•array_prioritize(array(1, 8, 2, 5), array(5, 4, 2, 1, 3,\n8))\n→ [ 5, 2, 1, 8 ]\n•array_prioritize(array(5, 4, 2, 1, 3, 8), array(1, 8, 6,\n5))→ [ 1, 8, 5, 4, 2, 3 ]\narray_remove_all\nReturns an array with all the entries of the given value removed.\nSyntaxarray_remove_all(array, value)\nArguments\n•array- an array\n•value- the values to remove\nExamples\n•array_remove_all(array('a','b','c','b'),'b')→ [ ‘a’, ‘c’ ]\narray_remove_at\nReturns an array with the given index removed.\nSyntaxarray_remove_at(array, pos)\nArguments\n•array- an array\n•pos- the position to remove (0 based)\nExamples\n•array_remove_at(array(1,2,3),1)→ [ 1, 3 ]\n12.2. List of functions201\n\nQGIS Desktop 3.22 User Guide\narray_replace\nReturns an array with the supplied value, array, or map of values replaced.\nValue & array variant\nReturns an array with the supplied value or array of values replaced by another value or an array of values.\nSyntaxarray_replace(array, before, after)\nArguments\n•array- the input array\n•before- the value or array of values to replace\n•after\n- the value or array of values to use as a replacement\nExamples\n•array_replace(array('QGIS','SHOULD','ROCK'),'SHOULD',\n'DOES')→ [ ‘QGIS’, ‘DOES’, ‘ROCK’ ]\n•array_replace(array(3,2,1),array(1,2,3),array(7,8,9))→ [ 9,\n8, 7 ]\n•array_replace(array('Q','G','I','S'),array('Q','S'),'-')→\n[ ‘-’, ‘G’, ‘I’, ‘-’ ]\nMap variant\nReturns an array with the supplied map keys replaced by their paired values.\nSyntaxarray_replace(array, map)\nArguments\n•array- the input array\n•map- the map containing keys and values\nExamples\n•array_replace(array('APP',  'SHOULD',  'ROCK'),map('APP',\n'QGIS','SHOULD','DOES'))→ [ ‘QGIS’, ‘DOES’, ‘ROCK’ ]\narray_reverse\nReturns the given array with array values in reversed order.\nSyntaxarray_reverse(array)\nArguments\n•array- an array\nExamples\n•array_reverse(array(2,4,0,10))→ [ 10, 0, 4, 2 ]\n202Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\narray_slice\nReturns a portion of the array. The slice is defined by the start_pos and end_pos arguments.\nSyntaxarray_slice(array, start_pos, end_pos)\nArguments\n•array\n- an array\n•start_pos- the index of the start position of the slice (0 based). The start_pos index is\nincluded in the slice. If you use a negative start_pos, the index is counted from the end of\nthe list (-1 based).\n•end_pos- the index of the end position of the slice (0 based). The end_pos index is\nincluded in the slice. If you use a negative end_pos, the index is counted from the end of\nthe list (-1 based).\nExamples\n•array_slice(array(1,2,3,4,5),0,3)→ [ 1, 2, 3, 4 ]\n•array_slice(array(1,2,3,4,5),0,-1)→ [ 1, 2, 3, 4, 5 ]\n•array_slice(array(1,2,3,4,5),-5,-1)→ [ 1, 2, 3, 4, 5 ]\n•array_slice(array(1,2,3,4,5),0,0)→ [ 1 ]\n•array_slice(array(1,2,3,4,5),-2,-1)→ [ 4, 5 ]\n•array_slice(array(1,2,3,4,5),-1,-1)→ [ 5 ]\n•array_slice(array('Dufour','Valmiera','Chugiak',\n'Brighton'),1,2)→ [ ‘Valmiera’, ‘Chugiak’ ]\n•array_slice(array('Dufour','Valmiera','Chugiak',\n'Brighton'),-2,-1)→ [ ‘Chugiak’, ‘Brighton’ ]\narray_sort\nReturns the provided array with its elements sorted.\nSyntaxarray_sort(array, [ascending=true])\n[] marks optional arguments\nArguments\n•array- an array\n•ascending- set this parameter to false to sort the array in descending order\nExamples\n•array_sort(array(3,2,1))→ [ 1, 2, 3 ]\narray_sum\nReturns the sum of arithmetic values in an array. Non numeric values in the array are ignored.\nSyntaxarray_sum(array)\nArguments\n•array- an array\nExamples\n•array_sum(array(0,1,39.4,1.6,'a'))→ 42.0\n12.2. List of functions203\n\nQGIS Desktop 3.22 User Guide\narray_to_string\nConcatenates array elements into a string separated by a delimiter and using optional string for empty values.\nSyntaxarray_to_string(array, [delimiter=’,’], [empty_value=’’])\n[] marks optional arguments\nArguments\n•array- the input array\n•delimiter- the string delimiter used to separate concatenated array elements\n•empty_value- the optional string to use as replacement for empty (zero length) matches\nExamples\n•array_to_string(array('1','2','3'))→ ‘1,2,3’\n•array_to_string(array(1,2,3),'-')→ ‘1-2-3’\n•array_to_string(array('1','','3'),',','0')→ ‘1,0,3’\ngenerate_series\nCreates an array containing a sequence of numbers.\nSyntaxgenerate_series(start, stop, [step=1])\n[] marks optional arguments\nArguments\n•start- first value of the sequence\n•stop- value that ends the sequence once reached\n•step- value used as the increment between values\nExamples\n•generate_series(1,5)→ [ 1, 2, 3, 4, 5 ]\n•generate_series(5,1,-1)→ [ 5, 4, 3, 2, 1 ]\nregexp_matches\nReturns an array of all strings captured by capturing groups, in the order the groups themselves appear in the supplied\nregular expression against a string.\nSyntaxregexp_matches(string, regex, [empty_value=’’])\n[] marks optional arguments\nArguments\n•string- the string to capture groups from against the regular expression\n•regex- the regular expression used to capture groups\n•empty_value- the optional string to use as replacement for empty (zero length) matches\nExamples\n•regexp_matches('QGIS=>rocks','(.*)=>(.*)')→ [ ‘QGIS’, ‘rocks’ ]\n•regexp_matches('key=>','(.*)=>(.*)','empty  value')→ [ ‘key’,\n‘empty value’ ]\n204Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nstring_to_array\nSplits string into an array using supplied delimiter and optional string for empty values.\nSyntaxstring_to_array(string, [delimiter=’,’], [empty_value=’’])\n[] marks optional arguments\nArguments\n•string- the input string\n•delimiter- the string delimiter used to split the input string\n•empty_value- the optional string to use as replacement for empty (zero length) matches\nExamples\n•string_to_array('1,2,3',',')→ [ ‘1’, ‘2’, ‘3’ ]\n•string_to_array('1,,3',',','0')→ [ ‘1’, ‘0’, ‘3’ ]\n12.2.3Color Functions\nThis group contains functions for manipulating colors.\ncolor_cmyk\nReturns a string representation of a color based on its cyan, magenta, yellow and black components\nSyntaxcolor_cmyk(cyan, magenta, yellow, black)\nArguments\n•cyan- cyan component of the color, as a percentage integer value from 0 to 100\n•magenta- magenta component of the color, as a percentage integer value from 0 to 100\n•yellow- yellow component of the color, as a percentage integer value from 0 to 100\n•black- black component of the color, as a percentage integer value from 0 to 100\nExamples\n•color_cmyk(100,50,0,10)→ ‘0,115,230’\ncolor_cmyka\nReturns a string representation of a color based on its cyan, magenta, yellow, black and alpha (transparency) compo-\nnents\nSyntaxcolor_cmyka(cyan, magenta, yellow, black, alpha)\nArguments\n•cyan- cyan component of the color, as a percentage integer value from 0 to 100\n•magenta- magenta component of the color, as a percentage integer value from 0 to 100\n•yellow- yellow component of the color, as a percentage integer value from 0 to 100\n•black- black component of the color, as a percentage integer value from 0 to 100\n•alpha- alpha component as an integer value from 0 (completely transparent) to 255\n(opaque).\nExamples\n•color_cmyka(100,50,0,10,200)→ ‘0,115,230,200’\n12.2. List of functions205\n\nQGIS Desktop 3.22 User Guide\ncolor_grayscale_average\nApplies a grayscale filter and returns a string representation from a provided color.\nSyntaxcolor_grayscale_average(color)\nArguments\n•color- a color string\nExamples\n•color_grayscale_average('255,100,50')→ ‘135,135,135,255’\ncolor_hsl\nReturns a string representation of a color based on its hue, saturation, and lightness attributes.\nSyntaxcolor_hsl(hue, saturation, lightness)\nArguments\n•hue- hue of the color, as an integer value from 0 to 360\n•saturation- saturation percentage of the color as an integer value from 0 to 100\n•lightness- lightness percentage of the color as an integer value from 0 to 100\nExamples\n•color_hsl(100,50,70)→ ‘166,217,140’\ncolor_hsla\nReturns a string representation of a color based on its hue, saturation, lightness and alpha (transparency) attributes\nSyntaxcolor_hsla(hue, saturation, lightness, alpha)\nArguments\n•hue- hue of the color, as an integer value from 0 to 360\n•saturation- saturation percentage of the color as an integer value from 0 to 100\n•lightness- lightness percentage of the color as an integer value from 0 to 100\n•alpha- alpha component as an integer value from 0 (completely transparent) to 255\n(opaque).\nExamples\n•color_hsla(100,50,70,200)→ ‘166,217,140,200’\ncolor_hsv\nReturns a string representation of a color based on its hue, saturation, and value attributes.\nSyntaxcolor_hsv(hue, saturation, value)\nArguments\n•hue- hue of the color, as an integer value from 0 to 360\n•saturation- saturation percentage of the color as an integer value from 0 to 100\n•value- value percentage of the color as an integer from 0 to 100\nExamples\n•color_hsv(40,100,100)→ ‘255,170,0’\n206Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\ncolor_hsva\nReturns a string representation of a color based on its hue, saturation, value and alpha (transparency) attributes.\nSyntaxcolor_hsva(hue, saturation, value, alpha)\nArguments\n•hue- hue of the color, as an integer value from 0 to 360\n•saturation- saturation percentage of the color as an integer value from 0 to 100\n•value- value percentage of the color as an integer from 0 to 100\n•alpha- alpha component as an integer value from 0 (completely transparent) to 255\n(opaque)\nExamples\n•color_hsva(40,100,100,200)→ ‘255,170,0,200’\ncolor_mix_rgb\nReturns a string representing a color mixing the red, green, blue, and alpha values of two provided colors based on a\ngiven ratio.\nSyntaxcolor_mix_rgb(color1, color2, ratio)\nArguments\n•color1- a color string\n•color2- a color string\n•ratio- a ratio\nExamples\n•color_mix_rgb('0,0,0','255,255,255',0.5)→ ‘127,127,127,255’\ncolor_part\nReturns a specific component from a color string, e.g., the red component or alpha component.\nSyntaxcolor_part(color, component)\nArguments\n•color- a color string\n•component- a string corresponding to the color component to return. Valid options are:\n–red: RGB red component (0-255)\n–green: RGB green component (0-255)\n–blue: RGB blue component (0-255)\n–alpha: alpha (transparency) value (0-255)\n–hue: HSV hue (0-360)\n–saturation: HSV saturation (0-100)\n–value: HSV value (0-100)\n–hsl_hue: HSL hue (0-360)\n–hsl_saturation: HSL saturation (0-100)\n–lightness: HSL lightness (0-100)\n–cyan: CMYK cyan component (0-100)\n–magenta: CMYK magenta component (0-100)\n–yellow: CMYK yellow component (0-100)\n–black: CMYK black component (0-100)\nExamples\n•color_part('200,10,30','green')→ 10\n12.2. List of functions207\n\nQGIS Desktop 3.22 User Guide\ncolor_rgb\nReturns a string representation of a color based on its red, green, and blue components.\nSyntaxcolor_rgb(red, green, blue)\nArguments\n•red- red component as an integer value from 0 to 255\n•green- green component as an integer value from 0 to 255\n•blue- blue component as an integer value from 0 to 255\nExamples\n•color_rgb(255,127,0)→ ‘255,127,0’\ncolor_rgba\nReturns a string representation of a color based on its red, green, blue, and alpha (transparency) components.\nSyntaxcolor_rgba(red, green, blue, alpha)\nArguments\n•red- red component as an integer value from 0 to 255\n•green- green component as an integer value from 0 to 255\n•blue- blue component as an integer value from 0 to 255\n•alpha- alpha component as an integer value from 0 (completely transparent) to 255\n(opaque).\nExamples\n•color_rgba(255,127,0,200)→ ‘255,127,0,200’\ncreate_ramp\nReturns a gradient ramp from a map of color strings and steps.\nSyntaxcreate_ramp(map, [discrete=false])\n[] marks optional arguments\nArguments\n•map- a map of color strings and steps\n•discrete- set this parameter to true to create a discrete color ramp\nExamples\n•ramp_color(create_ramp(map(0,'0,0,0',1,'255,0,0')),1)→\n‘255,0,0,255’\ndarker\nReturns a darker (or lighter) color string\n208Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxdarker(color, factor)\nArguments\n•color- a color string\n•factor- an integer corresponding to the darkening factor:\n–if the factor is greater than 100, this function returns a darker color (e.g., setting\nfactor to 200 returns a color that is half the brightness);\n–if the factor is less than 100, the return color is lighter, but using the lighter() function\nfor this purpose is recommended;\n–if the factor is 0 or negative, the return value is unspecified.\nExamples\n•darker('200,10,30', 200)→ ‘100,5,15,255’\nFurther reading:lighter\nlighter\nReturns a lighter (or darker) color string\nSyntaxlighter(color, factor)\nArguments\n•color- a color string\n•factor- an integer corresponding to the lightening factor:\n–if the factor is greater than 100, this function returns a lighter color (e.g., setting\nfactor to 150 returns a color that is 50% brighter);\n–if the factor is less than 100, the return color is darker, but using the darker() function\nfor this purpose is recommended;\n–if the factor is 0 or negative, the return value is unspecified.\nExamples\n•lighter('200,10,30', 200)→ ‘255,158,168,255’\nFurther reading:darker\nproject_color\nReturns a color from the project’s color scheme.\nSyntaxproject_color(name)\nArguments\n•name- a color name\nExamples\n•project_color('Logo color')→ ‘20,140,50’\nFurther reading:setting project colors\n12.2. List of functions209\n\nQGIS Desktop 3.22 User Guide\nramp_color\nReturns a string representing a color from a color ramp.\nSaved ramp variant\nReturns a string representing a color from a saved ramp\nSyntaxramp_color(ramp_name, value)\nArguments\n•ramp_name- the name of the color ramp as a string, for example ‘Spectral’\n•value- the position on the ramp to select the color from as a real number between 0 and\n1\nExamples\n•ramp_color('Spectral',0.3)→ ‘253,190,115,255’\nNote:The color ramps available vary between QGIS installations. This function may not give the expected results\nif you move your QGIS project between installations.\nExpression-created ramp variant\nReturns a string representing a color from an expression-created ramp\nSyntaxramp_color(ramp, value)\nArguments\n•ramp- the color ramp\n•value- the position on the ramp to select the color from as a real number between 0 and\n1\nExamples\n•ramp_color(create_ramp(map(0,'0,0,0',1,'255,0,0')),1)→\n‘255,0,0,255’\nFurther reading:Setting a Color Ramp,The color ramp drop-down shortcut\n210Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nset_color_part\nSets a specific color component for a color string, e.g., the red component or alpha component.\nSyntaxset_color_part(color, component, value)\nArguments\n•color- a color string\n•component- a string corresponding to the color component to set. Valid options are:\n–red: RGB red component (0-255)\n–green: RGB green component (0-255)\n–blue: RGB blue component (0-255)\n–alpha: alpha (transparency) value (0-255)\n–hue: HSV hue (0-360)\n–saturation: HSV saturation (0-100)\n–value: HSV value (0-100)\n–hsl_hue: HSL hue (0-360)\n–hsl_saturation: HSL saturation (0-100)\n–lightness: HSL lightness (0-100)\n–cyan: CMYK cyan component (0-100)\n–magenta: CMYK magenta component (0-100)\n–yellow: CMYK yellow component (0-100)\n–black: CMYK black component (0-100)\n•value- new value for color component, respecting the ranges listed above\nExamples\n•set_color_part('200,10,30','green',50)→ ‘200,50,30,255’\n12.2.4Conditional Functions\nThis group contains functions to handle conditional checks in expressions.\nCASE\nCASE is used to evaluate a series of conditions and return a result for the first condition met. The conditions are\nevaluated sequentially, and if a condition is true, the evaluation stops, and the corresponding result is returned. If\nnone of the conditions are true, the value in the ELSE clause is returned. Furthermore, if no ELSE clause is set and\nnone of the conditions are met, NULL is returned.\nCASE\nWHENconditionTHENresult\n[ ...n ]\n[ ELSEresult]\nEND\n[ ] marks optional components\n12.2. List of functions211\n\nQGIS Desktop 3.22 User Guide\nArguments\n•WHEN condition- A condition expression to evaluate\n•THEN result- Ifconditionevaluates to True thenresultis evaluated and returned.\n•ELSE result- If none of the above conditions evaluated to True thenresultis evaluated\nand returned.\nExamples\n•CASE WHEN \"name\" IS NULL THEN 'None' END→ Returns the string ‘None’\nif the “name” field is NULL\n•CASE WHEN $area > 10000 THEN 'Big property' WHEN $area >\n5000 THEN 'Medium property' ELSE 'Small property' END→\nReturns the string ‘Big property’ if the area is bigger than 10000, ‘Medium property’ if the\narea is between 5000 and 10000, and ‘Small property’ for others\ncoalesce\nReturns the first non-NULL value from the expression list.\nThis function can take any number of arguments.\nSyntaxcoalesce(expression1, expression2, ...)\nArguments\n•expression- any valid expression or value, regardless of type.\nExamples\n•coalesce(NULL, 2)→ 2\n•coalesce(NULL, 2, 3)→ 2\n•coalesce(7, NULL, 3*2)→ 7\n•coalesce(\"fieldA\", \"fallbackField\", 'ERROR')→ value of fieldA if\nit is non-NULL else the value of “fallbackField” or the string ‘ERROR’ if both are NULL\nif\nTests a condition and returns a different result depending on the conditional check.\nSyntaxif(condition, result_when_true, result_when_false)\nArguments\n•condition- the condition which should be checked\n•result_when_true- the result which will be returned when the condition is true or another\nvalue that does not convert to false.\n•result_when_false- the result which will be returned when the condition is false or an-\nother value that converts to false like 0 or ‘’. NULL will also be converted to false.\nExamples\n•if( 1+1=2, 'Yes', 'No' )\n→ ‘Yes’\n•if( 1+1=3, 'Yes', 'No' )→ ‘No’\n•if( 5 > 3, 1, 0)→ 1\n•if( '', 'It is true (not empty)', 'It is false (empty)' )\n→ ‘It is false (empty)’\n•if( ' ', 'It is true (not empty)', 'It is false (empty)' )\n→ ‘It is true (not empty)’\n•if( 0, 'One', 'Zero' )→ ‘Zero’\n•if( 10, 'One', 'Zero' )→ ‘One’\n212Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nnullif\nReturns a NULL value if value1 equals value2; otherwise it returns value1. This can be used to conditionally substitute\nvalues with NULL.\nSyntaxnullif(value1, value2)\nArguments\n•value1- The value that should either be used or substituted with NULL.\n•value2- The control value that will trigger the NULL substitution.\nExamples\n•nullif('(none)', '(none)')→ NULL\n•nullif('text', '(none)')→ ‘text’\n•nullif(\"name\", '')→ NULL, if name is an empty string (or already NULL), the\nname in any other case.\nregexp_match\nReturn the first matching position matching a regular expression within an unicode string, or 0 if the substring is not\nfound.\nSyntaxregexp_match(input_string, regex)\nArguments\n•input_string- the string to test against the regular expression\n•regex- The regular expression to test against. Backslash characters must be double es-\ncaped (e.g., “\\\\s” to match a white space character or “\\\\b” to match a word boundary).\nExamples\n•regexp_match('QGIS ROCKS','\\\\sROCKS')→ 5\n•regexp_match('Budač','udač\\\\b')→ 2\ntry\nTries an expression and returns its value if error-free. If the expression returns an error, an alternative value will be\nreturned when provided otherwise the function will return NULL.\nSyntaxtry(expression, [alternative])\n[] marks optional arguments\nArguments\n•expression- the expression which should be run\n•alternative- the result which will be returned if the expression returns an error.\nExamples\n•try( to_int( '1' ), 0 )→ 1\n•try( to_int( 'a' ), 0 )→ 0\n•try( to_date( 'invalid_date' ) )→ NULL\n12.2. List of functions213\n\nQGIS Desktop 3.22 User Guide\n12.2.5Conversions Functions\nThis group contains functions to convert one data type to another (e.g., string from/to integer, binary from/to string,\nstring to date, ...).\nfrom_base64\nDecodes a string in the Base64 encoding into a binary value.\nSyntaxfrom_base64(string)\nArguments\n•string- the string to decode\nExamples\n•from_base64('UUdJUw==')→ ‘QGIS’\nhash\nCreates a hash from a string with a given method. One byte (8 bits) is represented with two hex ‘’digits’’, so ‘md4’\n(16 bytes) produces a 16 * 2 = 32 character long hex string and ‘keccak_512’ (64 bytes) produces a 64 * 2 = 128\ncharacter long hex string.\nSyntaxhash(string, method)\nArguments\n•string- the string to hash\n•method- The hash method among ‘md4’, ‘md5’, ‘sha1’, ‘sha224’, ‘sha384’, ‘sha512’,\n‘sha3_224’, ‘sha3_256’, ‘sha3_384’, ‘sha3_512’, ‘keccak_224’, ‘keccak_256’, ‘kec-\ncak_384’, ‘keccak_512’\nExamples\n•hash('QGIS', 'md4')→ ‘c0fc71c241cdebb6e888cbac0e2b68eb’\n•hash('QGIS', 'md5')→ ‘57470aaa9e22adaefac7f5f342f1c6da’\n•hash('QGIS', 'sha1')→ ‘f87cfb2b74cdd5867db913237024e7001e62b114’\n•hash('QGIS', 'sha224')→‘4093a619ada631c770f44bc643ead18fb393b93d6a6af1861fcfece0’\n•hash('QGIS', 'sha256')→‘eb045cba7a797aaa06ac58830846e40c8e8c780bc0676d3393605fae50c05309’\n•hash('QGIS', 'sha384')→‘91c1de038cc3d09fdd512e99f9dd9922efadc39ed21d3922e69a4305cc25506033aee388e554b78714c8734f9cd7e610’\n•hash('QGIS', 'sha512')→‘c2c092f2ab743bf8edbeb6d028a745f30fc720408465ed369421f0a4e20fa5e27f0c90ad72d3f1d836eaa5d25cd39897d4cf77e19984668ef58da6e3159f18ac’\n•hash('QGIS', 'sha3_224')→‘467f49a5039e7280d5d42fd433e80d203439e338eaabd701f0d6c17d’\n•hash('QGIS', 'sha3_256')→‘540f7354b6b8a6e735f2845250f15f4f3ba4f666c55574d9e9354575de0e980f’\n•hash('QGIS', 'sha3_384')→‘96052da1e77679e9a65f60d7ead961b287977823144786386eb43647b0901fd8516fa6f1b9d243fb3f28775e6dde6107’\n•hash('QGIS', 'sha3_512')→‘900d079dc69761da113980253aa8ac0414a8bd6d09879a916228f8743707c4758051c98445d6b8945ec854ff90655005e02aceb0a2ffc6a0ebf818745d665349’\n•hash('QGIS', 'keccak_224')→‘5b0ce6acef8b0a121d4ac4f3eaa8503c799ad4e26a3392d1fb201478’\n•hash('QGIS', 'keccak_256')→‘991c520aa6815392de24087f61b2ae0fd56abbfeee4a8ca019c1011d327c577e’\n•hash('QGIS', 'keccak_384')→‘c57a3aed9d856fa04e5eeee9b62b6e027cca81ba574116d3cc1f0d48a1ef9e5886ff463ea8d0fac772ee473bf92f810d’\n214Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nmd5\nCreates a md5 hash from a string.\nSyntaxmd5(string)\nArguments\n•string- the string to hash\nExamples\n•md5('QGIS')\n→ ‘57470aaa9e22adaefac7f5f342f1c6da’\nsha256\nCreates a sha256 hash from a string.\nSyntaxsha256(string)\nArguments\n•string- the string to hash\nExamples\n•sha256('QGIS')→‘eb045cba7a797aaa06ac58830846e40c8e8c780bc0676d3393605fae50c05309’\nto_base64\nEncodes a binary value into a string, using the Base64 encoding.\nSyntaxto_base64(value)\nArguments\n•value- the binary value to encode\nExamples\n•to_base64('QGIS')→ ‘UUdJUw==’\nto_date\nConverts a string into a date object.  An optional format string can be provided to parse the string; see\nQDate::fromStringor the documentation of the format_date function for additional documentation on the format.\nBy default the current QGIS user locale is used.\nSyntaxto_date(string, [format], [language])\n[] marks optional arguments\nArguments\n•string- string representing a date value\n•format- format used to convert the string into a date\n•language- language (lowercase, two- or three-letter, ISO 639 language code) used to\nconvert the string into a date. By default the current QGIS user locale is used.\nExamples\n•to_date('2012-05-04')→ 2012-05-04\n•to_date('June 29, 2019','MMMM d, yyyy')→ 2019-06-29, if the current\nlocale uses the name ‘June’ for the sixth month, otherwise an error occurs\n•to_date('29 juin, 2019','d MMMM, yyyy','fr')→ 2019-06-29\n12.2. List of functions215\n\nQGIS Desktop 3.22 User Guide\nto_datetime\nConverts a string into a datetime object.  An optional format string can be provided to parse the string; see\nQDate::fromString,QTime::fromStringor the documentation of the format_date function for additional documen-\ntation on the format. By default the current QGIS user locale is used.\nSyntaxto_datetime(string, [format], [language])\n[] marks optional arguments\nArguments\n•string- string representing a datetime value\n•format- format used to convert the string into a datetime\n•language- language (lowercase, two- or three-letter, ISO 639 language code) used to\nconvert the string into a datetime. By default the current QGIS user locale is used.\nExamples\n•to_datetime('2012-05-04 12:50:00')→ 2012-05-04T12:50:00\n•to_datetime('June 29, 2019 @ 12:34','MMMM d, yyyy @ HH:mm')\n→ 2019-06-29T12:34, if the current locale uses the name ‘June’ for the sixth month, oth-\nerwise an error occurs\n•to_datetime('29 juin, 2019 @ 12:34','d MMMM, yyyy @ HH:mm',\n'fr')→ 2019-06-29T12:34\nto_decimal\nConverts a degree, minute, second coordinate to its decimal equivalent.\nSyntaxto_decimal(value)\nArguments\n•value- A degree, minute, second string.\nExamples\n•to_decimal('6°21\\'16.445')→ 6.3545680555\nto_dm\nConverts a coordinate to degree, minute.\nSyntaxto_dm(coordinate, axis, precision, [formatting=])\n[] marks optional arguments\nArguments\n•coordinate- A latitude or longitude value.\n•axis- The axis of the coordinate. Either ‘x’ or ‘y’.\n•precision- Number of decimals.\n•formatting- Designates the formatting type. Acceptable values are NULL (default),\n‘aligned’ or ‘suffix’.\nExamples\n•to_dm(6.1545681, 'x', 3)→ 6°9.274\n′\n•to_dm(6.1545681, 'y', 4, 'aligned')→ 6°09.2741\n′\nN\n•to_dm(6.1545681, 'y', 4, 'suffix')→ 6°9.2741\n′\nN\n216Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nto_dms\nConverts a coordinate to degree, minute, second.\nSyntaxto_dms(coordinate, axis, precision, [formatting=])\n[] marks optional arguments\nArguments\n•coordinate- A latitude or longitude value.\n•axis- The axis of the coordinate. Either ‘x’ or ‘y’.\n•precision- Number of decimals.\n•formatting- Designates the formatting type. Acceptable values are NULL (default),\n‘aligned’ or ‘suffix’.\nExamples\n•to_dms(6.1545681, 'x', 3)→ 6°9\n′\n16.445\n′′\n•to_dms(6.1545681, 'y', 4, 'aligned')→ 6°09\n′\n16.4452\n′′\nN\n•to_dms(6.1545681, 'y', 4, 'suffix')→ 6°9\n′\n16.4452\n′′\nN\nto_int\nConverts a string to integer number. Nothing is returned if a value cannot be converted to integer (e.g ‘123asd’ is\ninvalid).\nSyntaxto_int(string)\nArguments\n•string- string to convert to integer number\nExamples\n•to_int('123')→ 123\nto_interval\nConverts a string to an interval type. Can be used to take days, hours, month, etc of a date.\nSyntaxto_interval(string)\nArguments\n•string- a string representing an interval. Allowable formats include {n} days {n} hours\n{n} months.\nExamples\n•to_interval('1 day 2 hours')→ interval: 1.08333 days\n•to_interval( '0.5 hours' )→ interval: 30 minutes\n•to_datetime('2012-05-05 12:00:00') - to_interval('1 day 2\nhours')→ 2012-05-04T10:00:00\n12.2. List of functions217\n\nQGIS Desktop 3.22 User Guide\nto_real\nConverts a string to a real number. Nothing is returned if a value cannot be converted to real (e.g ‘123.56asd’ is\ninvalid). Numbers are rounded after saving changes if the precision is smaller than the result of the conversion.\nSyntaxto_real(string)\nArguments\n•string- string to convert to real number\nExamples\n•to_real('123.45')→ 123.45\nto_string\nConverts a number to string.\nSyntaxto_string(number)\nArguments\n•number- Integer or real value. The number to convert to string.\nExamples\n•to_string(123)→ ‘123’\nto_time\nConverts a string into a time object.  An optional format string can be provided to parse the string; see\nQTime::fromStringfor additional documentation on the format.\nSyntaxto_time(string, [format], [language])\n[] marks optional arguments\nArguments\n•string- string representing a time value\n•format- format used to convert the string into a time\n•language- language (lowercase, two- or three-letter, ISO 639 language code) used to\nconvert the string into a time\nExamples\n•to_time('12:30:01')→ 12:30:01\n•to_time('12:34','HH:mm')→ 12:34:00\n•to_time('12:34','HH:mm','fr')→ 12:34:00\n12.2.6Custom Functions\nThis group contains functions created by the user. SeeFunction Editorfor more details.\n218Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n12.2.7Date and Time Functions\nThisgroupcontainsfunctionsforhandlingdateandtimedata. ThisgroupsharesseveralfunctionswiththeConversions\nFunctions(to_date, to_time, to_datetime, to_interval) andString Functions(format_date) groups.\nNote: Storing date, datetime and intervals on fields\nThe ability to storedate,timeanddatetimevalues directly on fields depends on the data source’s provider (e.g.,\nShapefile acceptsdateformat, but notdatetimeortimeformat). The following are some suggestions to overcome this\nlimitation:\n•date,datetimeandtimecan be converted and stored in text type fields using theformat_date()function.\n•Intervalscan be stored in integer or decimal type fields after using one of the date extraction functions (e.g.,\nday()to get the interval expressed in days)\nage\nReturns the difference between two dates or datetimes.\nThe difference is returned as anIntervaland needs to be used with one of the following functions in order to\nextract useful information:\n•year\n•month\n•week\n•day\n•hour\n•minute\n•second\nSyntaxage(datetime1, datetime2)\nArguments\n•datetime1- a string, date or datetime representing the later date\n•datetime2- a string, date or datetime representing the earlier date\nExamples\n•day(age('2012-05-12','2012-05-02'))→ 10\n•hour(age('2012-05-12','2012-05-02'))→ 240\ndatetime_from_epoch\nReturns a datetime whose date and time are the number of milliseconds, msecs, that have passed since 1970-01-\n01T00:00:00.000, Coordinated Universal Time (Qt.UTC), and converted to Qt.LocalTime.\nSyntaxdatetime_from_epoch(int)\nArguments\n•int- number (milliseconds)\nExamples\n•datetime_from_epoch(1483225200000)→ 2017-01-01T00:00:00\n12.2. List of functions219\n\nQGIS Desktop 3.22 User Guide\nday\nExtracts the day from a date, or the number of days from an interval.\nDate variant\nExtracts the day from a date or datetime.\nSyntaxday(date)\nArguments\n•date- a date or datetime value\nExamples\n•day('2012-05-12')→ 12\nInterval variant\nCalculates the length in days of an interval.\nSyntaxday(interval)\nArguments\n•interval- interval value to return number of days from\nExamples\n•day(to_interval('3 days'))→ 3\n•day(to_interval('3 weeks 2 days'))→ 23\n•day(age('2012-01-01','2010-01-01'))→ 730\nday_of_week\nReturns the day of the week for a specified date or datetime. The returned value ranges from 0 to 6, where 0\ncorresponds to a Sunday and 6 to a Saturday.\nSyntaxday_of_week(date)\nArguments\n•date- date or datetime value\nExamples\n•day_of_week(to_date('2015-09-21'))→ 1\nepoch\nReturns the interval in milliseconds between the unix epoch and a given date value.\nSyntaxepoch(date)\nArguments\n•date- a date or datetime value\nExamples\n•epoch(to_date('2017-01-01'))→ 1483203600000\n220Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nformat_date\nFormats a date type or string into a custom string format. Uses Qt date/time format strings. SeeQDateTime::toString.\nSyntaxformat_date(datetime, format, [language])\n[] marks optional arguments\nArguments\n•datetime- date, time or datetime value\n•format- String template used to format the string.\nExpressionOutput\ndthe day as number without a leading zero (1 to 31)\nddthe day as number with a leading zero (01 to 31)\ndddthe abbreviated localized day name (e.g. ‘Mon’ to ‘Sun’)\nddddthe long localized day name (e.g. ‘Monday’ to ‘Sunday’)\nMthe month as number without a leading zero (1-12)\nMMthe month as number with a leading zero (01-12)\nMMMthe abbreviated localized month name (e.g. ‘Jan’ to ‘Dec’)\nMMMMthe long localized month name (e.g. ‘January’ to ‘December’)\nyythe year as two digit number (00-99)\nyyyythe year as four digit number\nThese expressions may be used for the time part of the format string:\nExpressionOutput\nhthe hour without a leading zero (0 to 23 or 1 to 12 if AM/PM display)\nhhthe hour with a leading zero (00 to 23 or 01 to 12 if AM/PM display)\nHthe hour without a leading zero (0 to 23, even with AM/PM display)\nHHthe hour with a leading zero (00 to 23, even with AM/PM display)\nmthe minute without a leading zero (0 to 59)\nmmthe minute with a leading zero (00 to 59)\nsthe second without a leading zero (0 to 59)\nssthe second with a leading zero (00 to 59)\nzthe milliseconds without trailing zeroes (0 to 999)\nzzzthe milliseconds with trailing zeroes (000 to 999)\nAP or Ainterpret as an AM/PM time.APmust be either ‘AM’ or ‘PM’.\nap or aInterpret as an AM/PM time.apmust be either ‘am’ or ‘pm’.\n•language- language (lowercase, two- or three-letter,ISO 639 language code) used to\nformat the date into a custom string. By default the current QGIS user locale is used.\nExamples\n•format_date('2012-05-15','dd.MM.yyyy')→ ‘15.05.2012’\n•format_date('2012-05-15','d MMMM yyyy','fr')→ ‘15 mai 2012’\n•format_date('2012-05-15','dddd')→ ‘Tuesday’, if the current locale is an\nEnglish variant\n•format_date('2012-05-15 13:54:20','dd.MM.yy')→ ‘15.05.12’\n•format_date('13:54:20','hh:mm AP')→ ‘01:54 PM’\n12.2. List of functions221\n\nQGIS Desktop 3.22 User Guide\nhour\nExtracts the hour part from a datetime or time, or the number of hours from an interval.\nTime variant\nExtracts the hour part from a time or datetime.\nSyntaxhour(datetime)\nArguments\n•datetime- a time or datetime value\nExamples\n•hour( to_datetime('2012-07-22 13:24:57') )→ 13\nInterval variant\nCalculates the length in hours of an interval.\nSyntaxhour(interval)\nArguments\n•interval- interval value to return number of hours from\nExamples\n•hour(to_interval('3 hours'))→ 3\n•hour(age('2012-07-22T13:00:00','2012-07-22T10:00:00'))→ 3\n•hour(age('2012-01-01','2010-01-01'))→ 17520\nmake_date\nCreates a date value from year, month and day numbers.\nSyntaxmake_date(year, month, day)\nArguments\n•year- Year number. Years 1 to 99 are interpreted as is. Year 0 is invalid.\n•month- Month number, where 1=January\n•day- Day number, beginning with 1 for the first day in the month\nExamples\n•make_date(2020,5,4)→ date value 2020-05-04\nmake_datetime\nCreates a datetime value from year, month, day, hour, minute and second numbers.\n222Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxmake_datetime(year, month, day, hour, minute, second)\nArguments\n•year- Year number. Years 1 to 99 are interpreted as is. Year 0 is invalid.\n•month- Month number, where 1=January\n•day- Day number, beginning with 1 for the first day in the month\n•hour- Hour number\n•minute- Minutes\n•second- Seconds (fractional values include milliseconds)\nExamples\n•make_datetime(2020,5,4,13,45,30.5)→ datetime value 2020-05-04\n13:45:30.500\nmake_interval\nCreates an interval value from year, month, weeks, days, hours, minute and seconds values.\nSyntaxmake_interval([years=0], [months=0], [weeks=0], [days=0], [hours=0], [minutes=0], [sec-\nonds=0])\n[] marks optional arguments\nArguments\n•years- Number of years (assumes a 365.25 day year length).\n•months- Number of months (assumes a 30 day month length)\n•weeks- Number of weeks\n•days- Number of days\n•hours- Number of hours\n•minutes- Number of minutes\n•seconds- Number of seconds\nExamples\n•make_interval(hours:=3)→ interval: 3 hours\n•make_interval(days:=2, hours:=3)→ interval: 2.125 days\n•make_interval(minutes:=0.5, seconds:=5)→ interval: 35 seconds\nmake_time\nCreates a time value from hour, minute and second numbers.\nSyntaxmake_time(hour, minute, second)\nArguments\n•hour- Hour number\n•minute- Minutes\n•second- Seconds (fractional values include milliseconds)\nExamples\n•make_time(13,45,30.5)→ time value 13:45:30.500\n12.2. List of functions223\n\nQGIS Desktop 3.22 User Guide\nminute\nExtracts the minutes part from a datetime or time, or the number of minutes from an interval.\nTime variant\nExtracts the minutes part from a time or datetime.\nSyntaxminute(datetime)\nArguments\n•datetime- a time or datetime value\nExamples\n•minute( to_datetime('2012-07-22 13:24:57') )→ 24\nInterval variant\nCalculates the length in minutes of an interval.\nSyntaxminute(interval)\nArguments\n•interval- interval value to return number of minutes from\nExamples\n•minute(to_interval('3 minutes'))→ 3\n•minute(age('2012-07-22T00:20:00','2012-07-22T00:00:00'))→\n20\n•minute(age('2012-01-01','2010-01-01'))→ 1051200\nmonth\nExtracts the month part from a date, or the number of months from an interval.\nDate variant\nExtracts the month part from a date or datetime.\nSyntaxmonth(date)\nArguments\n•date- a date or datetime value\nExamples\n•month('2012-05-12')→ 05\nInterval variant\nCalculates the length in months of an interval.\nSyntaxmonth(interval)\nArguments\n•interval- interval value to return number of months from\nExamples\n•month(to_interval('3 months'))→ 3\n•month(age('2012-01-01','2010-01-01'))→ 4.03333\n224Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nnow\nReturns the current date and time. The function is static and will return consistent results while evaluating. The time\nreturned is the time when the expression is prepared.\nSyntaxnow()\nExamples\n•now()→ 2012-07-22T13:24:57\nsecond\nExtracts the seconds part from a datetime or time, or the number of seconds from an interval.\nTime variant\nExtracts the seconds part from a time or datetime.\nSyntaxsecond(datetime)\nArguments\n•datetime- a time or datetime value\nExamples\n•second( to_datetime('2012-07-22 13:24:57') )→ 57\nInterval variant\nCalculates the length in seconds of an interval.\nSyntaxsecond(interval)\nArguments\n•interval- interval value to return number of seconds from\nExamples\n•second(to_interval('3 minutes'))→ 180\n•second(age('2012-07-22T00:20:00','2012-07-22T00:00:00'))→\n1200\n•second(age('2012-01-01','2010-01-01'))→ 63072000\nto_date\nConverts a string into a date object.  An optional format string can be provided to parse the string; see\nQDate::fromStringor the documentation of the format_date function for additional documentation on the format.\nBy default the current QGIS user locale is used.\n12.2. List of functions225\n\nQGIS Desktop 3.22 User Guide\nSyntaxto_date(string, [format], [language])\n[] marks optional arguments\nArguments\n•string- string representing a date value\n•format- format used to convert the string into a date\n•language- language (lowercase, two- or three-letter, ISO 639 language code) used to\nconvert the string into a date. By default the current QGIS user locale is used.\nExamples\n•to_date('2012-05-04')→ 2012-05-04\n•to_date('June 29, 2019','MMMM d, yyyy')→ 2019-06-29, if the current\nlocale uses the name ‘June’ for the sixth month, otherwise an error occurs\n•to_date('29 juin, 2019','d MMMM, yyyy','fr')→ 2019-06-29\nto_datetime\nConverts a string into a datetime object.  An optional format string can be provided to parse the string; see\nQDate::fromString,QTime::fromStringor the documentation of the format_date function for additional documen-\ntation on the format. By default the current QGIS user locale is used.\nSyntaxto_datetime(string, [format], [language])\n[] marks optional arguments\nArguments\n•string- string representing a datetime value\n•format- format used to convert the string into a datetime\n•language- language (lowercase, two- or three-letter, ISO 639 language code) used to\nconvert the string into a datetime. By default the current QGIS user locale is used.\nExamples\n•to_datetime('2012-05-04 12:50:00')→ 2012-05-04T12:50:00\n•to_datetime('June 29, 2019 @ 12:34','MMMM d, yyyy @ HH:mm')\n→ 2019-06-29T12:34, if the current locale uses the name ‘June’ for the sixth month, oth-\nerwise an error occurs\n•to_datetime('29 juin, 2019 @ 12:34','d MMMM, yyyy @ HH:mm',\n'fr')→ 2019-06-29T12:34\nto_interval\nConverts a string to an interval type. Can be used to take days, hours, month, etc of a date.\nSyntaxto_interval(string)\nArguments\n•string- a string representing an interval. Allowable formats include {n} days {n} hours\n{n} months.\nExamples\n•to_interval('1 day 2 hours')→ interval: 1.08333 days\n•to_interval( '0.5 hours' )→ interval: 30 minutes\n•to_datetime('2012-05-05 12:00:00') - to_interval('1 day 2\nhours')→ 2012-05-04T10:00:00\n226Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nto_time\nConverts a string into a time object.  An optional format string can be provided to parse the string; see\nQTime::fromStringfor additional documentation on the format.\nSyntaxto_time(string, [format], [language])\n[] marks optional arguments\nArguments\n•string- string representing a time value\n•format- format used to convert the string into a time\n•language- language (lowercase, two- or three-letter, ISO 639 language code) used to\nconvert the string into a time\nExamples\n•to_time('12:30:01')→ 12:30:01\n•to_time('12:34','HH:mm')→ 12:34:00\n•to_time('12:34','HH:mm','fr')→ 12:34:00\nweek\nExtracts the week number from a date, or the number of weeks from an interval.\nDate variant\nExtracts the week number from a date or datetime.\nSyntaxweek(date)\nArguments\n•date- a date or datetime value\nExamples\n•week('2012-05-12')→ 19\nInterval variant\nCalculates the length in weeks of an interval.\nSyntaxweek(interval)\nArguments\n•interval- interval value to return number of months from\nExamples\n•week(to_interval('3 weeks'))→ 3\n•week(age('2012-01-01','2010-01-01'))→ 104.285\nyear\nExtracts the year part from a date, or the number of years from an interval.\nDate variant\nExtracts the year part from a date or datetime.\n12.2. List of functions227\n\nQGIS Desktop 3.22 User Guide\nSyntaxyear(date)\nArguments\n•date- a date or datetime value\nExamples\n•year('2012-05-12')→ 2012\nInterval variant\nCalculates the length in years of an interval.\nSyntaxyear(interval)\nArguments\n•interval- interval value to return number of years from\nExamples\n•year(to_interval('3 years'))→ 3\n•year(age('2012-01-01','2010-01-01'))→ 1.9986\nSome examples:\nBesides these functions, subtracting dates, datetimes or times using the-(minus) operator will return an interval.\nAdding or subtracting an interval to dates, datetimes or times, using the+(plus) and-(minus) operators, will return\na datetime.\n•Get the number of days until QGIS 3.0 release:\nto_date('2017-09-29')-to_date(now())\n-- Returns <interval: 203 days>\n•The same with time:\nto_datetime('2017-09-29 12:00:00')-now()\n-- Returns <interval: 202.49 days>\n•Get the datetime of 100 days from now:\nnow()+to_interval('100 days')\n-- Returns <datetime: 2017-06-18 01:00:00>\n12.2.8Fields and Values\nContains a list of fields from the layer, and special values.\nDouble-click a field name to have it added to your expression. You can also type the field name (preferably inside\ndouble quotes) or itsalias.\nTo retrieve fields values to use in an expression, select the appropriate field and, in the shown widget, choose between\n10 SamplesandAll Unique. Requested values are then displayed and you can use theSearchbox at the top of the list\nto filter the result. Sample values can also be accessed via right-clicking on a field.\nTo add a value to the expression you are writing, double-click on it in the list. If the value is of a string type, it should\nbe simple quoted, otherwise no quote is needed.\n228Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nNULL\nEquates to a NULL value.\nSyntaxNULL\nExamples\n•NULL→ a NULL value\nNote:To test for NULL use anIS NULLorIS NOT NULLexpression.\n12.2.9Files and Paths Functions\nThis group contains functions which manipulate file and path names.\nbase_file_name\nReturns the base name of the file without the directory or file suffix.\nSyntaxbase_file_name(path)\nArguments\n•path- a file path\nExamples\n•base_file_name('/home/qgis/data/country_boundaries.shp')→\n‘country_boundaries’\nexif\nRetrieves exif tag values from an image file.\nSyntaxexif(path, [tag])\n[] marks optional arguments\nArguments\n•path- An image file path.\n•tag- The tag to return. If empty, a map with all exif tag values will be returned.\nExamples\n•exif('/my/photo.jpg','Exif.Image.Orientation')→ 0\nfile_exists\nReturns true if a file path exists.\nSyntaxfile_exists(path)\nArguments\n•path- a file path\nExamples\n•file_exists('/home/qgis/data/country_boundaries.shp')\n→ true\n12.2. List of functions229\n\nQGIS Desktop 3.22 User Guide\nfile_name\nReturns the name of a file (including the file extension), excluding the directory.\nSyntaxfile_name(path)\nArguments\n•path- a file path\nExamples\n•file_name('/home/qgis/data/country_boundaries.shp')→ ‘coun-\ntry_boundaries.shp’\nfile_path\nReturns the directory component of a file path. This does not include the file name.\nSyntaxfile_path(path)\nArguments\n•path- a file path\nExamples\n•file_path('/home/qgis/data/country_boundaries.shp')→\n‘/home/qgis/data’\nfile_size\nReturns the size (in bytes) of a file.\nSyntaxfile_size(path)\nArguments\n•path- a file path\nExamples\n•file_size('/home/qgis/data/country_boundaries.geojson')→\n5674\nfile_suffix\nReturns the file suffix (extension) from a file path.\nSyntaxfile_suffix(path)\nArguments\n•path- a file path\nExamples\n•file_suffix('/home/qgis/data/country_boundaries.shp')→\n‘shp’\n230Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nis_directory\nReturns true if a path corresponds to a directory.\nSyntaxis_directory(path)\nArguments\n•path- a file path\nExamples\n•is_directory('/home/qgis/data/country_boundaries.shp')→\nfalse\n•is_directory('/home/qgis/data/')→ true\nis_file\nReturns true if a path corresponds to a file.\nSyntaxis_file(path)\nArguments\n•path- a file path\nExamples\n•is_file('/home/qgis/data/country_boundaries.shp')→ true\n•is_file('/home/qgis/data/')→ false\n12.2.10Form Functions\nThis group contains functions that operate exclusively under the attribute form context. For example, infield’s widgets\nsettings.\ncurrent_parent_value\nOnly usable in an embedded form context, this function returns the current, unsaved value of a field in the parent form\ncurrently being edited. This will differ from the parent feature’s actual attribute values for features which are currently\nbeing edited or have not yet been added to a parent layer. When used in a value-relation widget filter expression, this\nfunction should be wrapped into a ‘coalesce()’ that can retrieve the actual parent feature from the layer when the form\nis not used in an embedded context.\nSyntaxcurrent_parent_value(field_name)\nArguments\n•field_name- a field name in the current parent form\nExamples\n•current_parent_value( 'FIELD_NAME' )→ The current value of a field\n‘FIELD_NAME’ in the parent form.\n12.2. List of functions231\n\nQGIS Desktop 3.22 User Guide\ncurrent_value\nReturns the current, unsaved value of a field in the form or table row currently being edited. This will differ from the\nfeature’s actual attribute values for features which are currently being edited or have not yet been added to a layer.\nSyntaxcurrent_value(field_name)\nArguments\n•field_name- a field name in the current form or table row\nExamples\n•current_value(   'FIELD_NAME'   )→ The current value of field\n‘FIELD_NAME’.\n12.2.11Fuzzy Matching Functions\nThis group contains functions for fuzzy comparisons between values.\nhamming_distance\nReturns the Hamming distance between two strings. This equates to the number of characters at corresponding\npositions within the input strings where the characters are different. The input strings must be the same length, and\nthe comparison is case-sensitive.\nSyntaxhamming_distance(string1, string2)\nArguments\n•string1- a string\n•string2- a string\nExamples\n•hamming_distance('abc','xec')→ 2\n•hamming_distance('abc','ABc')→ 2\n•hamming_distance(upper('abc'),upper('ABC'))→ 0\n•hamming_distance('abc','abcd')→ NULL\nlevenshtein\nReturns the Levenshtein edit distance between two strings. This equates to the minimum number of character edits\n(insertions, deletions or substitutions) required to change one string to another.\nThe Levenshtein distance is a measure of the similarity between two strings. Smaller distances mean the strings are\nmore similar, and larger distances indicate more different strings. The distance is case sensitive.\nSyntaxlevenshtein(string1, string2)\nArguments\n•string1- a string\n•string2- a string\nExamples\n•levenshtein('kittens','mitten')→ 2\n•levenshtein('Kitten','kitten')→ 1\n•levenshtein(upper('Kitten'),upper('kitten'))→ 0\n232Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nlongest_common_substring\nReturns the longest common substring between two strings. This substring is the longest string that is a substring\nof the two input strings. For example, the longest common substring of “ABABC” and “BABCA” is “BABC”. The\nsubstring is case sensitive.\nSyntaxlongest_common_substring(string1, string2)\nArguments\n•string1- a string\n•string2- a string\nExamples\n•longest_common_substring('ABABC','BABCA')→ ‘BABC’\n•longest_common_substring('abcDeF','abcdef')→ ‘abc’\n•longest_common_substring(upper('abcDeF'),upper('abcdex'))\n→ ‘ABCDE’\nsoundex\nReturns the Soundex representation of a string. Soundex is a phonetic matching algorithm, so strings with similar\nsounds should be represented by the same Soundex code.\nSyntaxsoundex(string)\nArguments\n•string- a string\nExamples\n•soundex('robert')→ ‘R163’\n•soundex('rupert')→ ‘R163’\n•soundex('rubin')→ ‘R150’\n12.2.12General Functions\nThis group contains general assorted functions.\nenv\nGets an environment variable and returns its content as a string. If the variable is not found, NULL will be returned.\nThis is handy to inject system specific configuration like drive letters or path prefixes. Definition of environment\nvariables depends on the operating system, please check with your system administrator or the operating system\ndocumentation how this can be set.\nSyntaxenv(name)\nArguments\n•name- The name of the environment variable which should be retrieved.\nExamples\n•env( 'LANG' )→ ‘en_US.UTF-8’\n•env( 'MY_OWN_PREFIX_VAR' )→ ‘Z:’\n•env( 'I_DO_NOT_EXIST' )→ NULL\n12.2. List of functions233\n\nQGIS Desktop 3.22 User Guide\neval\nEvaluates an expression which is passed in a string. Useful to expand dynamic parameters passed as context variables\nor fields.\nSyntaxeval(expression)\nArguments\n•expression- an expression string\nExamples\n•eval('\\'nice\\'')→ ‘nice’\n•eval(@expression_var)→ [whatever the result of evaluating @expression_var\nmight be...]\neval_template\nEvaluates a template which is passed in a string. Useful to expand dynamic parameters passed as context variables\nor fields.\nSyntaxeval_template(template)\nArguments\n•template- a template string\nExamples\n•eval_template('QGIS [% upper(\\'rocks\\') %]')→ QGIS ROCKS\nis_layer_visible\nReturns true if a specified layer is visible.\nSyntaxis_layer_visible(layer)\nArguments\n•layer- a string, representing either a layer name or layer ID\nExamples\n•is_layer_visible('baseraster')→ True\nmime_type\nReturns the mime type of the binary data.\nSyntaxmime_type(bytes)\nArguments\n•bytes- the binary data\nExamples\n•mime_type('<html><body></body></html>')→ text/html\n•mime_type(from_base64('R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAIAOw=='))\n→ image/gif\n234Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nvar\nReturns the value stored within a specified variable.\nSyntaxvar(name)\nArguments\n•name- a variable name\nExamples\n•var('qgis_version')→ ‘2.12’\nFurther reading: List of defaultvariables\nwith_variable\nThis function sets a variable for any expression code that will be provided as 3rd argument. This is only useful for\ncomplicated expressions, where the same calculated value needs to be used in different places.\nSyntaxwith_variable(name, value, expression)\nArguments\n•name- the name of the variable to set\n•value- the value to set\n•expression- the expression for which the variable will be available\nExamples\n•with_variable('my_sum', 1 + 2 + 3, @my_sum * 2 + @my_sum *\n5)→ 42\n12.2.13Geometry Functions\nThis group contains functions that operate on geometry objects (e.g. buffer, transform, $area).\n12.2. List of functions235\n\nQGIS Desktop 3.22 User Guide\naffine_transform\nReturns the geometry after an affine transformation. Calculations are in the Spatial Reference System of this geome-\ntry. The operations are performed in a scale, rotation, translation order. If there is a Z or M offset but the coordinate\nis not present in the geometry, it will be added.\nSyntaxaffine_transform(geometry, delta_x, delta_y, rotation_z, scale_x, scale_y, [delta_z=0],\n[delta_m=0], [scale_z=1], [scale_m=1])\n[] marks optional arguments\nArguments\n•geometry- a geometry\n•delta_x- x-axis translation\n•delta_y- y-axis translation\n•rotation_z- rotation around z-axis in degrees counter-clockwise\n•scale_x- x-axis scale factor\n•scale_y- y-axis scale factor\n•delta_z- z-axis translation\n•delta_m- m-axis translation\n•scale_z- z-axis scale factor\n•scale_m- m-axis scale factor\nExamples\n•geom_to_wkt(affine_transform(geom_from_wkt('LINESTRING(1\n1, 2 2)'), 2, 2, 0, 1, 1))→ ‘LineString (3 3, 4 4)’\n•geom_to_wkt(affine_transform(geom_from_wkt('POLYGON((0  0,\n0 3, 2 2, 0 0))'), 0, 0, -90, 1, 2))→ ‘Polygon ((0 0, 6 0, 4 -2,\n0 0))’\n•geom_to_wkt(affine_transform(geom_from_wkt('POINT(3  1)'),\n0, 0, 0, 1, 1, 5, 0))→ ‘PointZ (3 1 5)’\nangle_at_vertex\nReturns the bisector angle (average angle) to the geometry for a specified vertex on a linestring geometry. Angles are\nin degrees clockwise from north.\nSyntaxangle_at_vertex(geometry, vertex)\nArguments\n•geometry- a linestring geometry\n•vertex- vertex index, starting from 0; if the value is negative, the selected vertex index\nwill be its total count minus the absolute value\nExamples\n•angle_at_vertex(geometry:=geom_from_wkt('LineString(0   0,\n10 0, 10 10)'),vertex:=1)→ 45.0\n236Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n$area\nReturns the area of the current feature. The area calculated by this function respects both the current project’s ellipsoid\nsetting and area unit settings. For example, if an ellipsoid has been set for the project then the calculated area will be\nellipsoidal, and if no ellipsoid is set then the calculated area will be planimetric.\nSyntax$area\nExamples\n•$area→ 42\narea\nReturns the area of a geometry polygon object. Calculations are always planimetric in the Spatial Reference System\n(SRS) of this geometry, and the units of the returned area will match the units for the SRS. This differs from the cal-\nculations performed by the $area function, which will perform ellipsoidal calculations based on the project’s ellipsoid\nand area unit settings.\nSyntaxarea(geometry)\nArguments\n•geometry- polygon geometry object\nExamples\n•area(geom_from_wkt('POLYGON((0 0, 4 0, 4 2, 0 2, 0 0))'))\n→ 8.0\nazimuth\nReturns the north-based azimuth as the angle in radians measured clockwise from the vertical on point_a to point_b.\nSyntaxazimuth(point_a, point_b)\nArguments\n•point_a- point geometry\n•point_b- point geometry\nExamples\n•degrees( azimuth( make_point(25, 45), make_point(75, 100)\n) )→ 42.273689\n•degrees( azimuth( make_point(75, 100), make_point(25,45) )\n)→ 222.273689\nboundary\nReturns the closure of the combinatorial boundary of the geometry (ie the topological boundary of the geometry).\nFor instance, a polygon geometry will have a boundary consisting of the linestrings for each ring in the polygon. Some\ngeometry types do not have a defined boundary, e.g., points or geometry collections, and will return NULL.\n12.2. List of functions237\n\nQGIS Desktop 3.22 User Guide\nSyntaxboundary(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkt(boundary(geom_from_wkt('Polygon((1 1, 0 0, -1\n1, 1 1))')))→ ‘LineString(1 1,0 0,-1 1,1 1)’\n•geom_to_wkt(boundary(geom_from_wkt('LineString(1 1,0 0,-1\n1)')))→ ‘MultiPoint ((1 1),(-1 1))’\nFurther reading:Boundaryalgorithm\nbounds\nReturns a geometry which represents the bounding box of an input geometry. Calculations are in the Spatial Reference\nSystem of this geometry.\nSyntaxbounds(geometry)\nArguments\n•geometry- a geometry\nExamples\n•bounds($geometry)→ bounding box of the current feature’s geometry\n•geom_to_wkt(bounds(geom_from_wkt('Polygon((1 1, 0 0, -1 1,\n1 1))')))→ ‘Polygon ((-1 0, 1 0, 1 1, -1 1, -1 0))’\n238Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nFig. 12.4: Black lines represent the bounding boxes of each polygon feature\nFurther reading:Bounding boxesalgorithm\nbounds_height\nReturns the height of the bounding box of a geometry. Calculations are in the Spatial Reference System of this\ngeometry.\nSyntaxbounds_height(geometry)\nArguments\n•geometry- a geometry\nExamples\n•bounds_height($geometry)→ height of bounding box of the current feature’s\ngeometry\n•bounds_height(geom_from_wkt('Polygon((1 1, 0 0, -1 1, 1\n1))'))→ 1\n12.2. List of functions239\n\nQGIS Desktop 3.22 User Guide\nbounds_width\nReturns the width of the bounding box of a geometry. Calculations are in the Spatial Reference System of this\ngeometry.\nSyntaxbounds_width(geometry)\nArguments\n•geometry- a geometry\nExamples\n•bounds_width($geometry)→ width of bounding box of the current feature’s ge-\nometry\n•bounds_width(geom_from_wkt('Polygon((1  1,  0  0,  -1  1,  1\n1))'))→ 2\nbuffer\nReturns a geometry that represents all points whose distance from this geometry is less than or equal to distance.\nCalculations are in the Spatial Reference System of this geometry.\nSyntaxbuffer(geometry, distance, [segments=8], [cap=’round’], [join=’round’], [miter_limit=2])\n[] marks optional arguments\nArguments\n•geometry- a geometry\n•distance- buffer distance in layer units\n•segments- number of segments to use to represent a quarter circle when a round join\nstyle is used. A larger number results in a smoother buffer with more nodes.\n•cap- end cap style for buffer. Valid values are ‘round’, ‘flat’ or ‘square’\n•join- join style for buffer. Valid values are ‘round’, ‘bevel’ or ‘miter’.\n•miter_limit- miter distance limit, for use when the join style is set to ‘miter’\nExamples\n•buffer($geometry, 10.5)→ polygon of the current feature’s geometry buffered\nby 10.5 units\nFig. 12.5: Buffer (in yellow) of points, line and polygon\nFurther reading:Bufferalgorithm\n240Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nbuffer_by_m\nCreates a buffer along a line geometry where the buffer diameter varies according to the m-values at the line vertices.\nSyntaxbuffer_by_m(geometry, [segments=8])\n[] marks optional arguments\nArguments\n•geometry- input geometry. Must be a (multi)line geometry with m values.\n•segments- number of segments to approximate quarter-circle curves in the buffer.\nExamples\n•buffer_by_m(geometry:=geom_from_wkt('LINESTRINGM(1 2 0.5,\n4 2 0.2)'),segments:=8)→ A variable width buffer starting with a diameter of\n0.5 and ending with a diameter of 0.2 along the linestring geometry.\nFig. 12.6: Buffering line features using the m value on the vertices\nFurther reading:Variable width buffer (by M value)algorithm\n12.2. List of functions241\n\nQGIS Desktop 3.22 User Guide\ncentroid\nReturns the geometric center of a geometry.\nSyntaxcentroid(geometry)\nArguments\n•geometry- a geometry\nExamples\n•centroid($geometry)→ a point geometry\nFurther reading:Centroidsalgorithm\nclose_line\nReturns a closed line string of the input line string by appending the first point to the end of the line, if it is not already\nclosed. If the geometry is not a line string or multi line string then the result will be NULL.\nSyntaxclose_line(geometry)\nArguments\n•geometry- a line string geometry\nExamples\n•geom_to_wkt(close_line(geom_from_wkt('LINESTRING(0 0, 1 0,\n1 1)')))→ ‘LineString (0 0, 1 0, 1 1, 0 0)’\n•geom_to_wkt(close_line(geom_from_wkt('LINESTRING(0 0, 1 0,\n1 1, 0 0)')))→ ‘LineString (0 0, 1 0, 1 1, 0 0)’\nclosest_point\nReturns the point on geometry1 that is closest to geometry2.\nSyntaxclosest_point(geometry1, geometry2)\nArguments\n•geometry1- geometry to find closest point on\n•geometry2- geometry to find closest point to\nExamples\n•geom_to_wkt(closest_point(geom_from_wkt('LINESTRING    (20\n80, 98 190, 110 180, 50 75 )'),geom_from_wkt('POINT(100\n100)')))→ ‘Point(73.0769 115.384)’\ncollect_geometries\nCollects a set of geometries into a multi-part geometry object.\nList of arguments variant\nGeometry parts are specified as separate arguments to the function.\n242Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxcollect_geometries(geometry1, geometry2, ...)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkt(collect_geometries(make_point(1,2),\nmake_point(3,4),  make_point(5,6)))→ ‘MultiPoint ((1 2),(3 4),(5\n6))’\nArray variant\nGeometry parts are specified as an array of geometry parts.\nSyntaxcollect_geometries(array)\nArguments\n•array- array of geometry objects\nExamples\n•geom_to_wkt(collect_geometries(array(make_point(1,2),\nmake_point(3,4), make_point(5,6))))→ ‘MultiPoint ((1 2),(3 4),(5 6))’\nFurther reading:Collect geometriesalgorithm\ncombine\nReturns the combination of two geometries.\nSyntaxcombine(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•geom_to_wkt( combine( geom_from_wkt( 'LINESTRING(3 3, 4 4,\n5 5)' ), geom_from_wkt( 'LINESTRING(3 3, 4 4, 2 1)' ) ) )\n→ ‘MULTILINESTRING((4 4, 2 1), (3 3, 4 4), (4 4, 5 5))’\n•geom_to_wkt( combine( geom_from_wkt( 'LINESTRING(3 3, 4 4)'\n), geom_from_wkt( 'LINESTRING(3 3, 6 6, 2 1)' ) ) )→\n‘LINESTRING(3 3, 4 4, 6 6, 2 1)’\ncontains\nTests whether a geometry contains another. Returns true if and only if no points of geometry2 lie in the exterior of\ngeometry1, and at least one point of the interior of geometry2 lies in the interior of geometry1.\nSyntaxcontains(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•contains( geom_from_wkt( 'POLYGON((0 0, 0 1, 1 1, 1 0, 0\n0))' ), geom_from_wkt( 'POINT(0.5 0.5 )' ) )\n→ true\n•contains( geom_from_wkt( 'POLYGON((0 0, 0 1, 1 1, 1 0, 0\n0))' ), geom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )→ false\n12.2. List of functions243\n\nQGIS Desktop 3.22 User Guide\nFurther reading:overlay_contains\nconvex_hull\nReturns the convex hull of a geometry. It represents the minimum convex geometry that encloses all geometries\nwithin the set.\nSyntaxconvex_hull(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkt( convex_hull( geom_from_wkt( 'LINESTRING(3 3,\n4 4, 4 10)' ) ) )→ ‘POLYGON((3 3, 4 10, 4 4, 3 3))’\nFurther reading:Convex hullalgorithm\ncrosses\nTests whether a geometry crosses another. Returns true if the supplied geometries have some, but not all, interior\npoints in common.\nSyntaxcrosses(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•crosses( geom_from_wkt( 'LINESTRING(3 5, 4 4, 5 3)' ),\ngeom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )→ true\n•crosses(  geom_from_wkt(  'POINT(4  5)'  ),  geom_from_wkt(\n'LINESTRING(3 3, 4 4, 5 5)' ) )→ false\nFurther reading:overlay_crosses\ndifference\nReturns a geometry that represents that part of geometry1 that does not intersect with geometry2.\nSyntaxdifference(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•geom_to_wkt( difference( geom_from_wkt( 'LINESTRING(3 3, 4\n4, 5 5)' ), geom_from_wkt( 'LINESTRING(3 3, 4 4)' ) ) )→\n‘LINESTRING(4 4, 5 5)’\nFurther reading:Differencealgorithm\n244Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\ndisjoint\nTests whether geometries do not spatially intersect. Returns true if the geometries do not share any space together.\nSyntaxdisjoint(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•disjoint( geom_from_wkt( 'POLYGON((0 0, 0 1, 1 1, 1 0, 0 0\n))' ), geom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )→ true\n•disjoint( geom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ),\ngeom_from_wkt( 'POINT(4 4)' ))→ false\nFurther reading:overlay_disjoint\ndistance\nReturns the minimum distance (based on spatial ref) between two geometries in projected units.\nSyntaxdistance(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•distance(  geom_from_wkt(  'POINT(4  4)'  ),  geom_from_wkt(\n'POINT(4 8)' ) )→ 4\ndistance_to_vertex\nReturns the distance along the geometry to a specified vertex.\nSyntaxdistance_to_vertex(geometry, vertex)\nArguments\n•geometry- a linestring geometry\n•vertex- vertex index, starting from 0; if the value is negative, the selected vertex index\nwill be its total count minus the absolute value\nExamples\n•distance_to_vertex(geometry:=geom_from_wkt('LineString(0\n0, 10 0, 10 10)'),vertex:=1)\n→ 10.0\n12.2. List of functions245\n\nQGIS Desktop 3.22 User Guide\nend_point\nReturns the last node from a geometry.\nSyntaxend_point(geometry)\nArguments\n•geometry- geometry object\nExamples\n•geom_to_wkt(end_point(geom_from_wkt('LINESTRING(4 0, 4 2,\n0 2)')))→ ‘Point (0 2)’\nFurther reading:Extract specific verticesalgorithm\nexif_geotag\nCreates a point geometry from the exif geotags of an image file.\nSyntaxexif_geotag(path)\nArguments\n•path- An image file path.\nExamples\n•geom_to_wkt(exif_geotag('/my/photo.jpg'))→ ‘Point (2 4)’\nextend\nExtends the start and end of a linestring geometry by a specified amount. Lines are extended using the bearing of\nthe first and last segment in the line. For a multilinestring, all the parts are extended. Distances are in the Spatial\nReference System of this geometry.\nSyntaxextend(geometry, start_distance, end_distance)\nArguments\n•geometry- a (multi)linestring geometry\n•start_distance- distance to extend the start of the line\n•end_distance- distance to extend the end of the line.\nExamples\n•geom_to_wkt(extend(geom_from_wkt('LineString(0 0, 1 0, 1\n1)'),1,2))→ ‘LineString (-1 0, 1 0, 1 3)’\n•geom_to_wkt(extend(geom_from_wkt('MultiLineString((0 0, 1\n0, 1 1), (2 2, 0 2, 0 5))'),1,2))\n→ ‘MultiLineString ((-1 0, 1 0, 1 3),(3\n2, 0 2, 0 7))’\nFurther reading:Extend linesalgorithm\n246Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nexterior_ring\nReturns a line string representing the exterior ring of a polygon geometry. If the geometry is not a polygon then the\nresult will be NULL.\nSyntaxexterior_ring(geometry)\nArguments\n•geometry- a polygon geometry\nExamples\n•geom_to_wkt(exterior_ring(geom_from_wkt('POLYGON((-1 -1, 4\n0, 4 2, 0 2, -1 -1),( 0.1 0.1, 0.1 0.2, 0.2 0.2, 0.2, 0.1,\n0.1 0.1))')))→ ‘LineString (-1 -1, 4 0, 4 2, 0 2, -1 -1)’\nextrude\nReturns an extruded version of the input (Multi-)Curve or (Multi-)Linestring geometry with an extension specified\nby x and y.\nSyntaxextrude(geometry, x, y)\nArguments\n•geometry- a curve or linestring geometry\n•x- x extension, numeric value\n•y- y extension, numeric value\nExamples\n•geom_to_wkt(extrude(geom_from_wkt('LineString(1 2, 3 2, 4\n3)'), 1, 2))→ ‘Polygon ((1 2, 3 2, 4 3, 5 5, 4 4, 2 4, 1 2))’\n•geom_to_wkt(extrude(geom_from_wkt('MultiLineString((1 2, 3\n2), (4 3, 8 3))'), 1, 2))→ ‘MultiPolygon (((1 2, 3 2, 4 4, 2 4, 1 2)),((4 3,\n8 3, 9 5, 5 5, 4 3)))’\nflip_coordinates\nReturns a copy of the geometry with the x and y coordinates swapped. Useful for repairing geometries which have\nhad their latitude and longitude values reversed.\nSyntaxflip_coordinates(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkt(flip_coordinates(make_point(1, 2)))→ ‘Point (2 1)’\nFurther reading:Swap X and Y coordinatesalgorithm\n12.2. List of functions247\n\nQGIS Desktop 3.22 User Guide\nforce_rhr\nForces a geometry to respect the Right-Hand-Rule, in which the area that is bounded by a polygon is to the right of\nthe boundary. In particular, the exterior ring is oriented in a clockwise direction and the interior rings in a counter-\nclockwise direction.\nSyntaxforce_rhr(geometry)\nArguments\n•geometry- a geometry. Any non-polygon geometries are returned unchanged.\nExamples\n•geom_to_wkt(force_rhr(geometry:=geom_from_wkt('POLYGON((-1\n-1, 4 0, 4 2, 0 2, -1 -1))')))→ ‘Polygon ((-1 -1, 0 2, 4 2, 4 0, -1 -1))’\nFurther reading:Force right-hand-rulealgorithm\ngeom_from_gml\nReturns a geometry from a GML representation of geometry.\nSyntaxgeom_from_gml(gml)\nArguments\n•gml- GML representation of a geometry as a string\nExamples\n•geom_from_gml('<gml:LineString srsName=\"EPSG:4326\"><gml:coordinates>4,\n4 5,5 6,6</gml:coordinates></gml:LineString>')→ a line geometry\nobject\ngeom_from_wkb\nReturns a geometry created from a Well-Known Binary (WKB) representation.\nSyntaxgeom_from_wkb(binary)\nArguments\n•binary- Well-Known Binary (WKB) representation of a geometry (as a binary blob)\nExamples\n•geom_from_wkb( geom_to_wkb( make_point(4,5) ) )→ a point geom-\netry object\ngeom_from_wkt\nReturns a geometry created from a Well-Known Text (WKT) representation.\nSyntaxgeom_from_wkt(text)\nArguments\n•text- Well-Known Text (WKT) representation of a geometry\nExamples\n•geom_from_wkt( 'POINT(4 5)' )→ a geometry object\n248Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\ngeom_to_wkb\nReturns the Well-Known Binary (WKB) representation of a geometry\nSyntaxgeom_to_wkb(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkb( $geometry )→ binary blob containing a geometry object\ngeom_to_wkt\nReturns the Well-Known Text (WKT) representation of the geometry without SRID metadata.\nSyntaxgeom_to_wkt(geometry, [precision=8])\n[] marks optional arguments\nArguments\n•geometry- a geometry\n•precision- numeric precision\nExamples\n•geom_to_wkt( make_point(6, 50) )→ ‘POINT(6 50)’\n•geom_to_wkt(centroid(geom_from_wkt('Polygon((1 1, 0 0, -1\n1, 1 1))')))→ ‘POINT(0 0.66666667)’\n•geom_to_wkt(centroid(geom_from_wkt('Polygon((1 1, 0 0, -1\n1, 1 1))')), 2)→ ‘POINT(0 0.67)’\n$geometry\nReturns the geometry of the current feature. Can be used for processing with other functions.\nSyntax$geometry\nExamples\n•geom_to_wkt( $geometry )→ ‘POINT(6 50)’\ngeometry\nReturns a feature’s geometry.\nSyntaxgeometry(feature)\nArguments\n•feature- a feature object\nExamples\n•`` geometry( $currentfeature )`` → the geometry of the current feature. Prefer using $ge-\nometry.\n•geom_to_wkt( geometry( get_feature_by_id( 'streets', 1 )\n) )→ the geometry in WKT of the feature with the id 1 on the layer “streets”, e.g.\n‘POINT(6 50)’\n•intersects( $geometry, geometry( get_feature( 'streets',\n'name', 'Main St.' ) ) )→ true if the current feature spatially intersects the\n‘Main St.’ named feature in the “streets” layer\n12.2. List of functions249\n\nQGIS Desktop 3.22 User Guide\ngeometry_n\nReturns a specific geometry from a geometry collection, or NULL if the input geometry is not a collection.\nSyntaxgeometry_n(geometry, index)\nArguments\n•geometry- geometry collection\n•index- index of geometry to return, where 1 is the first geometry in the collection\nExamples\n•geom_to_wkt(geometry_n(geom_from_wkt('GEOMETRYCOLLECTION(POINT(0\n1), POINT(0 0), POINT(1 0), POINT(1 1))'),3))→ ‘Point (1 0)’\ngeometry_type\nReturns a string value describing the type of a geometry (Point, Line or Polygon)\nSyntaxgeometry_type(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geometry_type( geom_from_wkt( 'LINESTRING(2 5, 3 6, 4 8)')\n)→ ‘Line’\n•geometry_type( geom_from_wkt( 'MULTILINESTRING((2 5, 3 6,\n4 8), (1 1, 0 0))') )→ ‘Line’\n•geometry_type( geom_from_wkt( 'POINT(2 5)') )→ ‘Point’\n•geometry_type( geom_from_wkt( 'POLYGON((-1 -1, 4 0, 4 2, 0\n2, -1 -1))') )→ ‘Polygon’\nhausdorff_distance\nReturns the Hausdorff distance between two geometries. This is basically a measure of how similar or dissimilar 2\ngeometries are, with a lower distance indicating more similar geometries.\nThe function can be executed with an optional densify fraction argument. If not specified, an approximation to the\nstandard Hausdorff distance is used. This approximation is exact or close enough for a large subset of useful cases.\nExamples of these are:\n•computing distance between Linestrings that are roughly parallel to each other, and roughly equal in length.\nThis occurs in matching linear networks.\n•Testing similarity of geometries.\nIf the default approximate provided by this method is insufficient, specify the optional densify fraction argument.\nSpecifying this argument performs a segment densification before computing the discrete Hausdorff distance. The\nparameter sets the fraction by which to densify each segment. Each segment will be split into a number of equal-\nlength subsegments, whose fraction of the total length is closest to the given fraction. Decreasing the densify fraction\nparameter will make the distance returned approach the true Hausdorff distance for the geometries.\n250Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxhausdorff_distance(geometry1, geometry2, [densify_fraction])\n[] marks optional arguments\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\n•densify_fraction- densify fraction amount\nExamples\n•hausdorff_distance( geometry1:= geom_from_wkt('LINESTRING\n(0 0, 2 1)'),geometry2:=geom_from_wkt('LINESTRING (0 0, 2\n0)'))→ 2\n•hausdorff_distance( geom_from_wkt('LINESTRING (130 0, 0 0,\n0  150)'),geom_from_wkt('LINESTRING  (10  10,  10  150,  130\n10)'))→ 14.142135623\n•hausdorff_distance( geom_from_wkt('LINESTRING (130 0, 0 0,\n0  150)'),geom_from_wkt('LINESTRING  (10  10,  10  150,  130\n10)'),0.5)→ 70.0\ninclination\nReturns the inclination measured from the zenith (0) to the nadir (180) on point_a to point_b.\nSyntaxinclination(point_a, point_b)\nArguments\n•point_a- point geometry\n•point_b- point geometry\nExamples\n•inclination( make_point( 5, 10, 0 ), make_point( 5, 10, 5\n) )→ 0.0\n•inclination( make_point( 5, 10, 0 ), make_point( 5, 10, 0\n) )→ 90.0\n•inclination( make_point( 5, 10, 0 ), make_point( 50, 100,\n0 ) )→ 90.0\n•inclination( make_point( 5, 10, 0 ), make_point( 5, 10, -5\n) )→ 180.0\ninterior_ring_n\nReturns a specific interior ring from a polygon geometry, or NULL if the geometry is not a polygon.\nSyntaxinterior_ring_n(geometry, index)\nArguments\n•geometry- polygon geometry\n•index- index of interior to return, where 1 is the first interior ring\nExamples\n•geom_to_wkt(interior_ring_n(geom_from_wkt('POLYGON((-1 -1,\n4 0, 4 2, 0 2, -1 -1),(-0.1 -0.1, 0.4 0, 0.4 0.2, 0 0.2,\n-0.1 -0.1),(-1 -1, 4 0, 4 2, 0 2, -1 -1))'),1))→ ‘LineString\n(-0.1 -0.1, 0.4 0, 0.4 0.2, 0 0.2, -0.1 -0.1))’\n12.2. List of functions251\n\nQGIS Desktop 3.22 User Guide\nintersection\nReturns a geometry that represents the shared portion of two geometries.\nSyntaxintersection(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•geom_to_wkt( intersection( geom_from_wkt( 'LINESTRING(3 3,\n4 4, 5 5)' ), geom_from_wkt( 'LINESTRING(3 3, 4 4)' ) ) )\n→ ‘LINESTRING(3 3, 4 4)’\n•geom_to_wkt( intersection( geom_from_wkt( 'LINESTRING(3 3,\n4 4, 5 5)' ), geom_from_wkt( 'MULTIPOINT(3.5 3.5, 4 5)' )\n) )→ ‘POINT(3.5 3.5)’\nFurther reading:Intersectionalgorithm\nintersects\nTests whether a geometry intersects another. Returns true if the geometries spatially intersect (share any portion of\nspace) and false if they do not.\nSyntaxintersects(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•intersects( geom_from_wkt( 'POINT(4 4)' ), geom_from_wkt(\n'LINESTRING(3 3, 4 4, 5 5)' ) )→ true\n•intersects( geom_from_wkt( 'POINT(4 5)' ), geom_from_wkt(\n'POINT(5 5)' ) )→ false\nFurther reading:overlay_intersects\nintersects_bbox\nTests whether a geometry’s bounding box overlaps another geometry’s bounding box. Returns true if the geometries\nspatially intersect the bounding box defined and false if they do not.\nSyntaxintersects_bbox(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•intersects_bbox(    geom_from_wkt(    'POINT(4    5)'    ),\ngeom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )\n→ true\n•intersects_bbox(    geom_from_wkt(    'POINT(6    5)'    ),\ngeom_from_wkt(  'POLYGON((3  3,  4  4,  5  5,  3  3))'  )  )→\nfalse\n252Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nis_closed\nReturns true if a line string is closed (start and end points are coincident), or false if a line string is not closed. If the\ngeometry is not a line string then the result will be NULL.\nSyntaxis_closed(geometry)\nArguments\n•geometry- a line string geometry\nExamples\n•is_closed(geom_from_wkt('LINESTRING(0 0, 1 1, 2 2)'))→ false\n•is_closed(geom_from_wkt('LINESTRING(0 0, 1 1, 2 2, 0 0)'))\n→ true\nis_empty\nReturns true if a geometry is empty (without coordinates), false if the geometry is not empty and NULL if there is\nno geometry. See also is_empty_or_null.\nSyntaxis_empty(geometry)\nArguments\n•geometry- a geometry\nExamples\n•is_empty(geom_from_wkt('LINESTRING(0 0, 1 1, 2 2)'))→ false\n•is_empty(geom_from_wkt('LINESTRING EMPTY'))→ true\n•is_empty(geom_from_wkt('POINT(7 4)'))→ false\n•is_empty(geom_from_wkt('POINT EMPTY'))→ true\nis_empty_or_null\nReturns true if a geometry is NULL or empty (without coordinates) or false otherwise. This function is like the\nexpression ‘$geometry IS NULL or is_empty($geometry)’\nSyntaxis_empty_or_null(geometry)\nArguments\n•geometry- a geometry\nExamples\n•is_empty_or_null(NULL)→ true\n•is_empty_or_null(geom_from_wkt('LINESTRING(0  0,  1  1,  2\n2)'))→ false\n•is_empty_or_null(geom_from_wkt('LINESTRING EMPTY'))→ true\n•is_empty_or_null(geom_from_wkt('POINT(7 4)'))→ false\n•is_empty_or_null(geom_from_wkt('POINT EMPTY'))→ true\n12.2. List of functions253\n\nQGIS Desktop 3.22 User Guide\nis_multipart\nReturns true if the geometry is of Multi type.\nSyntaxis_multipart(geometry)\nArguments\n•geometry- a geometry\nExamples\n•is_multipart(geom_from_wkt('MULTIPOINT  ((0  0),(1  1),(2\n2))'))→ true\n•is_multipart(geom_from_wkt('POINT (0 0)'))→ false\nis_valid\nReturns true if a geometry is valid; if it is well-formed in 2D according to the OGC rules.\nSyntaxis_valid(geometry)\nArguments\n•geometry- a geometry\nExamples\n•is_valid(geom_from_wkt('LINESTRING(0 0, 1 1, 2 2, 0 0)'))\n→ true\n•is_valid(geom_from_wkt('LINESTRING(0 0)'))→ false\n$length\nReturns the length of a linestring. If you need the length of a border of a polygon, use $perimeter instead. The length\ncalculated by this function respects both the current project’s ellipsoid setting and distance unit settings. For example,\nif an ellipsoid has been set for the project then the calculated length will be ellipsoidal, and if no ellipsoid is set then\nthe calculated length will be planimetric.\nSyntax$length\nExamples\n•$length→ 42.4711\nlength\nReturns the number of characters in a string or the length of a geometry linestring.\nString variant\nReturns the number of characters in a string.\nSyntaxlength(string)\nArguments\n•string- string to count length of\nExamples\n•length('hello')→ 5\nGeometry variant\n254Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nCalculate the length of a geometry line object. Calculations are always planimetric in the Spatial Reference System\n(SRS) of this geometry, and the units of the returned length will match the units for the SRS. This differs from the\ncalculations performed by the $length function, which will perform ellipsoidal calculations based on the project’s\nellipsoid and distance unit settings.\nSyntaxlength(geometry)\nArguments\n•geometry- line geometry object\nExamples\n•length(geom_from_wkt('LINESTRING(0 0, 4 0)'))→ 4.0\nFurther reading:straight_distance_2d\nlength3D\nCalculates the 3D length of a geometry line object. If the geometry is not a 3D line object, it returns its 2D length.\nCalculations are always planimetric in the Spatial Reference System (SRS) of this geometry, and the units of the\nreturned length will match the units for the SRS. This differs from the calculations performed by the $length function,\nwhich will perform ellipsoidal calculations based on the project’s ellipsoid and distance unit settings.\nSyntaxlength3D(geometry)\nArguments\n•geometry- line geometry object\nExamples\n•length3D(geom_from_wkt('LINESTRINGZ(0 0 0, 3 0 4)'))→ 5.0\nline_interpolate_angle\nReturns the angle parallel to the geometry at a specified distance along a linestring geometry. Angles are in degrees\nclockwise from north.\nSyntaxline_interpolate_angle(geometry, distance)\nArguments\n•geometry- a linestring geometry\n•distance- distance along line to interpolate angle at\nExamples\n•line_interpolate_angle(geometry:=geom_from_wkt('LineString(0\n0, 10 0)'),distance:=5)→ 90.0\nline_interpolate_point\nReturns the point interpolated by a specified distance along a linestring geometry.\nSyntaxline_interpolate_point(geometry, distance)\nArguments\n•geometry- a linestring geometry\n•distance- distance along line to interpolate\nExamples\n•geom_to_wkt(line_interpolate_point(geometry:=geom_from_wkt('LineString(0\n0, 10 0)'),distance:=5))→ ‘Point (5 0)’\n12.2. List of functions255\n\nQGIS Desktop 3.22 User Guide\nFurther reading:Interpolate point on linealgorithm\nline_locate_point\nReturns the distance along a linestring corresponding to the closest position the linestring comes to a specified point\ngeometry.\nSyntaxline_locate_point(geometry, point)\nArguments\n•geometry- a linestring geometry\n•point- point geometry to locate closest position on linestring to\nExamples\n•line_locate_point(geometry:=geom_from_wkt('LineString(0 0,\n10 0)'),point:=geom_from_wkt('Point(5 0)'))→ 5.0\nline_merge\nReturns a LineString or MultiLineString geometry, where any connected LineStrings from the input geometry\nhave been merged into a single linestring. This function will return NULL if passed a geometry which is not a\nLineString/MultiLineString.\nSyntaxline_merge(geometry)\nArguments\n•geometry- a LineString/MultiLineString geometry\nExamples\n•geom_to_wkt(line_merge(geom_from_wkt('MULTILINESTRING((0\n0, 1 1),(1 1, 2 2))')))→ ‘LineString(0 0,1 1,2 2)’\n•geom_to_wkt(line_merge(geom_from_wkt('MULTILINESTRING((0\n0, 1 1),(11 1, 21 2))')))→ ‘MultiLineString((0 0, 1 1),(11 1, 21 2)’\nline_substring\nReturns the portion of a line (or curve) geometry which falls between the specified start and end distances (measured\nfrom the beginning of the line). Z and M values are linearly interpolated from existing values.\nSyntaxline_substring(geometry, start_distance, end_distance)\nArguments\n•geometry- a linestring or curve geometry\n•start_distance- distance to start of substring\n•end_distance- distance to end of substring\nExamples\n•geom_to_wkt(line_substring(geometry:=geom_from_wkt('LineString(0\n0, 10 0)'),start_distance:=2,end_distance:=6))→ ‘LineString (2\n0,6 0)’\nFurther reading:Line substringalgorithm\n256Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nm\nReturns the m value of a point geometry.\nSyntaxm(geometry)\nArguments\n•geometry- a point geometry\nExamples\n•m( geom_from_wkt( 'POINTM(2 5 4)' ) )→ 4\nm_max\nReturns the maximum m (measure) value of a geometry.\nSyntaxm_max(geometry)\nArguments\n•geometry- a geometry containing m values\nExamples\n•m_max( make_point_m( 0,0,1 ) )→ 1\n•m_max(make_line( make_point_m( 0,0,1 ), make_point_m( -1,\n-1,2 ), make_point_m( -2,-2,0 ) ) )→ 2\nm_min\nReturns the minimum m (measure) value of a geometry.\nSyntaxm_min(geometry)\nArguments\n•geometry- a geometry containing m values\nExamples\n•m_min( make_point_m( 0,0,1 ) )\n→ 1\n•m_min(make_line( make_point_m( 0,0,1 ), make_point_m( -1,\n-1,2 ), make_point_m( -2,-2,0 ) ) )→ 0\nmain_angle\nReturns the angle of the long axis (clockwise, in degrees from North) of the oriented minimal bounding rectangle,\nwhich completely covers the geometry.\nSyntaxmain_angle(geometry)\nArguments\n•geometry- a geometry\nExamples\n•main_angle(geom_from_wkt('Polygon ((321577 129614, 321581\n129618, 321585 129615, 321581 129610, 321577 129614))'))→\n38.66\n12.2. List of functions257\n\nQGIS Desktop 3.22 User Guide\nmake_circle\nCreates a circular polygon.\nSyntaxmake_circle(center, radius, [segments=36])\n[] marks optional arguments\nArguments\n•center- center point of the circle\n•radius- radius of the circle\n•segments- optional argument for polygon segmentation. By default this value is 36\nExamples\n•geom_to_wkt(make_circle(make_point(10,10), 5, 4))→ ‘Polygon\n((10 15, 15 10, 10 5, 5 10, 10 15))’\n•geom_to_wkt(make_circle(make_point(10,10,5), 5, 4))→ ‘Poly-\ngonZ ((10 15 5, 15 10 5, 10 5 5, 5 10 5, 10 15 5))’\n•geom_to_wkt(make_circle(make_point(10,10,5,30),  5,  4))→\n‘PolygonZM ((10 15 5 30, 15 10 5 30, 10 5 5 30, 5 10 5 30, 10 15 5 30))’\nmake_ellipse\nCreates an elliptical polygon.\nSyntaxmake_ellipse(center, semi_major_axis, semi_minor_axis, azimuth, [segments=36])\n[] marks optional arguments\nArguments\n•center- center point of the ellipse\n•semi_major_axis- semi-major axis of the ellipse\n•semi_minor_axis- semi-minor axis of the ellipse\n•azimuth- orientation of the ellipse\n•segments- optional argument for polygon segmentation. By default this value is 36\nExamples\n•geom_to_wkt(make_ellipse(make_point(10,10), 5, 2, 90, 4))\n→ ‘Polygon ((15 10, 10 8, 5 10, 10 12, 15 10))’\n•geom_to_wkt(make_ellipse(make_point(10,10,5), 5, 2, 90, 4))\n→ ‘PolygonZ ((15 10 5, 10 8 5, 5 10 5, 10 12 5, 15 10 5))’\n•geom_to_wkt(make_ellipse(make_point(10,10,5,30), 5, 2, 90,\n4))→ ‘PolygonZM ((15 10 5 30, 10 8 5 30, 5 10 5 30, 10 12 5 30, 15 10 5 30))’\nmake_line\nCreates a line geometry from a series of point geometries.\nList of arguments variant\nLine vertices are specified as separate arguments to the function.\n258Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxmake_line(point1, point2, ...)\nArguments\n•point- a point geometry (or array of points)\nExamples\n•geom_to_wkt(make_line(make_point(2,4),make_point(3,5)))→\n‘LineString (2 4, 3 5)’\n•geom_to_wkt(make_line(make_point(2,4),make_point(3,5),\nmake_point(9,7)))→ ‘LineString (2 4, 3 5, 9 7)’\nArray variant\nLine vertices are specified as an array of points.\nSyntaxmake_line(array)\nArguments\n•array- array of points\nExamples\n•geom_to_wkt(make_line(array(make_point(2,4),make_point(3,\n5),make_point(9,7))))→ ‘LineString (2 4, 3 5, 9 7)’\nmake_point\nCreates a point geometry from an x and y (and optional z and m) value.\nSyntaxmake_point(x, y, [z], [m])\n[] marks optional arguments\nArguments\n•x- x coordinate of point\n•y- y coordinate of point\n•z- optional z coordinate of point\n•m- optional m value of point\nExamples\n•geom_to_wkt(make_point(2,4))→ ‘Point (2 4)’\n•geom_to_wkt(make_point(2,4,6))→ ‘PointZ (2 4 6)’\n•geom_to_wkt(make_point(2,4,6,8))→ ‘PointZM (2 4 6 8)’\nmake_point_m\nCreates a point geometry from an x, y coordinate and m value.\nSyntaxmake_point_m(x, y, m)\nArguments\n•x- x coordinate of point\n•y- y coordinate of point\n•m- m value of point\nExamples\n•geom_to_wkt(make_point_m(2,4,6))→ ‘PointM (2 4 6)’\n12.2. List of functions259\n\nQGIS Desktop 3.22 User Guide\nmake_polygon\nCreates a polygon geometry from an outer ring and optional series of inner ring geometries.\nSyntaxmake_polygon(outerRing, [innerRing1], [innerRing2], ...)\n[] marks optional arguments\nArguments\n•outerRing- closed line geometry for polygon’s outer ring\n•innerRing- optional closed line geometry for inner ring\nExamples\n•geom_to_wkt(make_polygon(geom_from_wkt('LINESTRING( 0 0, 0\n1, 1 1, 1 0, 0 0 )')))→ ‘Polygon ((0 0, 0 1, 1 1, 1 0, 0 0))’\n•geom_to_wkt(make_polygon(geom_from_wkt('LINESTRING(  0  0,\n0  1,  1  1,  1  0,  0  0  )'),geom_from_wkt('LINESTRING(\n0.1  0.1,  0.1  0.2,  0.2  0.2,  0.2  0.1,  0.1  0.1  )'),\ngeom_from_wkt('LINESTRING( 0.8 0.8, 0.8 0.9, 0.9 0.9, 0.9\n0.8, 0.8 0.8 )')))→ ‘Polygon ((0 0, 0 1, 1 1, 1 0, 0 0),(0.1 0.1, 0.1 0.2, 0.2 0.2,\n0.2 0.1, 0.1 0.1),(0.8 0.8, 0.8 0.9, 0.9 0.9, 0.9 0.8, 0.8 0.8))’\nmake_rectangle_3points\nCreates a rectangle from 3 points.\nSyntaxmake_rectangle_3points(point1, point2, point3, [option=0])\n[] marks optional arguments\nArguments\n•point1- First point.\n•point2- Second point.\n•point3- Third point.\n•option- An optional argument to construct the rectangle. By default this value is 0. Value\ncan be 0 (distance) or 1 (projected). Option distance: Second distance is equal to the\ndistance between 2nd and 3rd point. Option projected: Second distance is equal to the\ndistance of the perpendicular projection of the 3rd point on the segment or its extension.\nExamples\n•geom_to_wkt(make_rectangle_3points(make_point(0,0),\nmake_point(0,5),  make_point(5,  5),  0))→ ‘Polygon ((0 0, 0 5,\n5 5, 5 0, 0 0))’\n•geom_to_wkt(make_rectangle_3points(make_point(0,0),\nmake_point(0,5),  make_point(5,  3),  1))→ ‘Polygon ((0 0, 0 5,\n5 5, 5 0, 0 0))’\n260Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nmake_regular_polygon\nCreates a regular polygon.\nSyntaxmake_regular_polygon(center, radius, number_sides, [circle=0])\n[] marks optional arguments\nArguments\n•center- center of the regular polygon\n•radius- second point. The first if the regular polygon is inscribed. The midpoint of the\nfirst side if the regular polygon is circumscribed.\n•number_sides- Number of sides/edges of the regular polygon\n•circle\n- Optional argument to construct the regular polygon. By default this value is 0.\nValue can be 0 (inscribed) or 1 (circumscribed)\nExamples\n•geom_to_wkt(make_regular_polygon(make_point(0,0),\nmake_point(0,5),  5))→ ‘Polygon ((0 5, 4.76 1.55, 2.94 -4.05, -2.94 -\n4.05, -4.76 1.55, 0 5))’\n•geom_to_wkt(make_regular_polygon(make_point(0,0),\nproject(make_point(0,0),   4.0451,   radians(36)),   5))→\n‘Polygon ((0 5, 4.76 1.55, 2.94 -4.05, -2.94 -4.05, -4.76 1.55, 0 5))’\nmake_square\nCreates a square from a diagonal.\nSyntaxmake_square(point1, point2)\nArguments\n•point1- First point of the diagonal\n•point2- Last point of the diagonal\nExamples\n•geom_to_wkt(make_square(  make_point(0,0),  make_point(5,\n5)))→ ‘Polygon ((0 0, -0 5, 5 5, 5 0, 0 0))’\n•geom_to_wkt(make_square(  make_point(5,0),  make_point(5,\n5)))→ ‘Polygon ((5 0, 2.5 2.5, 5 5, 7.5 2.5, 5 0))’\nmake_triangle\nCreates a triangle polygon.\nSyntaxmake_triangle(point1, point2, point3)\nArguments\n•point1- first point of the triangle\n•point2- second point of the triangle\n•point3- third point of the triangle\nExamples\n•geom_to_wkt(make_triangle(make_point(0,0),   make_point(5,\n5), make_point(0,10)))→ ‘Triangle ((0 0, 5 5, 0 10, 0 0))’\n•geom_to_wkt(boundary(make_triangle(make_point(0,0),\nmake_point(5,5),  make_point(0,10))))→ ‘LineString (0 0, 5 5, 0\n10, 0 0)’\n12.2. List of functions261\n\nQGIS Desktop 3.22 User Guide\nminimal_circle\nReturns the minimal enclosing circle of a geometry. It represents the minimum circle that encloses all geometries\nwithin the set.\nSyntaxminimal_circle(geometry, [segments=36])\n[] marks optional arguments\nArguments\n•geometry- a geometry\n•segments- optional argument for polygon segmentation. By default this value is 36\nExamples\n•geom_to_wkt( minimal_circle( geom_from_wkt( 'LINESTRING(0\n5, 0 -5, 2 1)' ), 4 ) )→ ‘Polygon ((0 5, 5 -0, -0 -5, -5 0, 0 5))’\n•geom_to_wkt( minimal_circle( geom_from_wkt( 'MULTIPOINT(1\n2, 3 4, 3 2)' ), 4 ) )→ ‘Polygon ((3 4, 3 2, 1 2, 1 4, 3 4))’\nFurther reading:Minimum enclosing circlesalgorithm\nnodes_to_points\nReturns a multipoint geometry consisting of every node in the input geometry.\nSyntaxnodes_to_points(geometry, [ignore_closing_nodes=false])\n[] marks optional arguments\nArguments\n•geometry- geometry object\n•ignore_closing_nodes- optional argument specifying whether to include duplicate nodes\nwhich close lines or polygons rings. Defaults to false, set to true to avoid including these\nduplicate nodes in the output collection.\nExamples\n•geom_to_wkt(nodes_to_points(geom_from_wkt('LINESTRING(0 0,\n1 1, 2 2)')))→ ‘MultiPoint ((0 0),(1 1),(2 2))’\n•geom_to_wkt(nodes_to_points(geom_from_wkt('POLYGON((-1 -1,\n4 0, 4 2, 0 2, -1 -1))'),true))→ ‘MultiPoint ((-1 -1),(4 0),(4 2),(0 2))’\nFurther reading:Extract verticesalgorithm\nnum_geometries\nReturns the number of geometries in a geometry collection, or NULL if the input geometry is not a collection.\nSyntaxnum_geometries(geometry)\nArguments\n•geometry- geometry collection\nExamples\n•num_geometries(geom_from_wkt('GEOMETRYCOLLECTION(POINT(0\n1), POINT(0 0), POINT(1 0), POINT(1 1))'))→ 4\n262Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nnum_interior_rings\nReturns the number of interior rings in a polygon or geometry collection, or NULL if the input geometry is not a\npolygon or collection.\nSyntaxnum_interior_rings(geometry)\nArguments\n•geometry- input geometry\nExamples\n•num_interior_rings(geom_from_wkt('POLYGON((-1 -1, 4 0, 4 2,\n0 2, -1 -1),(-0.1 -0.1, 0.4 0, 0.4 0.2, 0 0.2, -0.1 -0.\n1))'))→ 1\nnum_points\nReturns the number of vertices in a geometry.\nSyntaxnum_points(geometry)\nArguments\n•geometry- a geometry\nExamples\n•num_points($geometry)→ number of vertices in the current feature’s geometry\nnum_rings\nReturns the number of rings (including exterior rings) in a polygon or geometry collection, or NULL if the input\ngeometry is not a polygon or collection.\nSyntaxnum_rings(geometry)\nArguments\n•geometry- input geometry\nExamples\n•num_rings(geom_from_wkt('POLYGON((-1 -1, 4 0, 4 2, 0 2, -1\n-1),(-0.1 -0.1, 0.4 0, 0.4 0.2, 0 0.2, -0.1 -0.1))'))→ 2\noffset_curve\nReturns a geometry formed by offsetting a linestring geometry to the side. Distances are in the Spatial Reference\nSystem of this geometry.\n12.2. List of functions263\n\nQGIS Desktop 3.22 User Guide\nSyntaxoffset_curve(geometry, distance, [segments=8], [join=1], [miter_limit=2.0])\n[] marks optional arguments\nArguments\n•geometry- a (multi)linestring geometry\n•distance- offset distance. Positive values will be buffered to the left of lines, negative\nvalues to the right\n•segments- number of segments to use to represent a quarter circle when a round join\nstyle is used. A larger number results in a smoother line with more nodes.\n•join- join style for corners, where 1 = round, 2 = miter and 3 = bevel\n•miter_limit- limit on the miter ratio used for very sharp corners (when using miter joins\nonly)\nExamples\n•offset_curve($geometry, 10.5)→ line offset to the left by 10.5 units\n•offset_curve($geometry, -10.5)→ line offset to the right by 10.5 units\n•offset_curve($geometry, 10.5, segments:=16, join:=1)→ line\noffset to the left by 10.5 units, using more segments to result in a smoother curve\n•offset_curve($geometry, 10.5, join:=3)→ line offset to the left by 10.5\nunits, using a beveled join\nFurther reading:Offset linesalgorithm\norder_parts\nOrders the parts of a MultiGeometry by a given criteria\nSyntaxorder_parts(geometry, orderby, [ascending=true])\n[] marks optional arguments\nArguments\n•geometry- a multi-type geometry\n•orderby- an expression string defining the order criteria\n•ascending- boolean, True for ascending, False for descending\nExamples\n•geom_to_wkt(order_parts(geom_from_wkt('MultiPolygon   (((1\n1, 5 1, 5 5, 1 5, 1 1)),((1 1, 9 1, 9 9, 1 9, 1 1)))'),\n'area($geometry)', False))→ ‘MultiPolygon (((1 1, 9 1, 9 9, 1 9, 1 1)),((1 1,\n5 1, 5 5, 1 5, 1 1)))’\n•geom_to_wkt(order_parts(geom_from_wkt('LineString(1  2,  3\n2, 4 3)'), '1', True))→ ‘LineString(1 2, 3 2, 4 3)’\noriented_bbox\nReturns a geometry which represents the minimal oriented bounding box of an input geometry.\nSyntaxoriented_bbox(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkt( oriented_bbox( geom_from_wkt( 'MULTIPOINT(1 2,\n3 4, 3 2)' ) ) )→ ‘Polygon ((3 2, 3 4, 1 4, 1 2, 3 2))’\nFurther reading:Oriented minimum bounding boxalgorithm\n264Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\noverlaps\nTests whether a geometry overlaps another. Returns true if the geometries share space, are of the same dimension,\nbut are not completely contained by each other.\nSyntaxoverlaps(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•overlaps( geom_from_wkt( 'LINESTRING(3 5, 4 4, 5 5, 5 3)'\n), geom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )→ true\n•overlaps(  geom_from_wkt(  'LINESTRING(0  0,  1  1)'  ),\ngeom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )→ false\noverlay_contains\nReturns whether the current feature spatially contains at least one feature from a target layer, or an array of expression-\nbased results for the features in the target layer contained in the current feature.\nRead more on the underlying GEOS “Contains” predicate, as described in PostGISST_Containsfunction.\nSyntaxoverlay_contains(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_contains('regions')→ true if the current feature spatially contains\na region\n•overlay_contains('regions', filter:= population > 10000)→\ntrue if the current feature spatially contains a region with a population greater than 10000\n•overlay_contains('regions', name)→ an array of names, for the regions\ncontained in the current feature\n•array_to_string(overlay_contains('regions', name))→ a string\nas a comma separated list of names, for the regions contained in the current feature\n•array_sort(overlay_contains(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions contained in the current feature and with a\npopulation greater than 10000\n•overlay_contains(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions contained in the current feature\nFurther reading:contains,array manipulation,Select by locationalgorithm\n12.2. List of functions265\n\nQGIS Desktop 3.22 User Guide\noverlay_crosses\nReturns whether the current feature spatially crosses at least one feature from a target layer, or an array of expression-\nbased results for the features in the target layer crossed by the current feature.\nRead more on the underlying GEOS “Crosses” predicate, as described in PostGISST_Crossesfunction.\nSyntaxoverlay_crosses(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_crosses('regions')→ true if the current feature spatially crosses a\nregion\n•overlay_crosses('regions', filter:= population > 10000)→\ntrue if the current feature spatially crosses a region with a population greater than 10000\n•overlay_crosses('regions', name)→ an array of names, for the regions\ncrossed by the current feature\n•array_to_string(overlay_crosses('regions', name))→ a string as\na comma separated list of names, for the regions crossed by the current feature\n•array_sort(overlay_crosses(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions crossed by the current feature and with a\npopulation greater than 10000\n•overlay_crosses(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions crossed by the current feature\nFurther reading:crosses,array manipulation,Select by locationalgorithm\noverlay_disjoint\nReturns whether the current feature is spatially disjoint from all the features of a target layer, or an array of expression-\nbased results for the features in the target layer that are disjoint from the current feature.\nRead more on the underlying GEOS “Disjoint” predicate, as described in PostGIS\nST_Disjointfunction.\n266Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxoverlay_disjoint(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_disjoint('regions')→ true if the current feature is spatially disjoint\nfrom all the regions\n•overlay_disjoint('regions', filter:= population > 10000)→\ntrue if the current feature is spatially disjoint from all the regions with a population greater\nthan 10000\n•overlay_disjoint('regions', name)→ an array of names, for the regions\nspatially disjoint from the current feature\n•array_to_string(overlay_disjoint('regions', name))→ a string\nas a comma separated list of names, for the regions spatially disjoint from the current\nfeature\n•array_sort(overlay_disjoint(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions spatially disjoint from the current feature and\nwith a population greater than 10000\n•overlay_disjoint(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions spatially disjoint from the current feature\nFurther reading:disjoint,array manipulation,Select by locationalgorithm\noverlay_equals\nReturns whether the current feature spatially equals to at least one feature from a target layer, or an array of expression-\nbased results for the features in the target layer that are spatially equal to the current feature.\nRead more on the underlying GEOS “Equals” predicate, as described in PostGISST_Equalsfunction.\n12.2. List of functions267\n\nQGIS Desktop 3.22 User Guide\nSyntaxoverlay_equals(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_equals('regions')→ true if the current feature is spatially equal to a\nregion\n•overlay_equals('regions', filter:= population > 10000)→ true\nif the current feature is spatially equal to a region with a population greater than 10000\n•overlay_equals('regions', name)→ an array of names, for the regions spa-\ntially equal to the current feature\n•array_to_string(overlay_equals('regions', name))→ a string as a\ncomma separated list of names, for the regions spatially equal to the current feature\n•array_sort(overlay_equals(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions spatially equal to the current feature and with a\npopulation greater than 10000\n•overlay_equals(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions spatially equal to the current feature\nFurther reading:array manipulation,Select by locationalgorithm\noverlay_intersects\nReturns whether the current feature spatially intersects at least one feature from a target layer, or an array of\nexpression-based results for the features in the target layer intersected by the current feature.\nRead more on the underlying GEOS “Intersects” predicate, as described in PostGISST_Intersectsfunction.\n268Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxoverlay_intersects(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_intersects('regions')→ true if the current feature spatially inter-\nsects a region\n•overlay_intersects('regions', filter:= population > 10000)\n→ true if the current feature spatially intersects a region with a population greater than\n10000\n•overlay_intersects('regions', name)→ an array of names, for the re-\ngions intersected by the current feature\n•array_to_string(overlay_intersects('regions',   name))→ a\nstring as a comma separated list of names, for the regions intersected by the current fea-\nture\n•array_sort(overlay_intersects(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions intersected by the current feature and with a\npopulation greater than 10000\n•overlay_intersects(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions intersected by the current feature\nFurther reading:intersects,array manipulation,Select by locationalgorithm\noverlay_nearest\nReturns whether the current feature has feature(s) from a target layer within a given distance, or an array of expression-\nbased results for the features in the target layer within a distance from the current feature.\nNote: This function can be slow and consume a lot of memory for large layers.\n12.2. List of functions269\n\nQGIS Desktop 3.22 User Guide\nSyntaxoverlay_nearest(layer, [expression], [filter], [limit=1], [max_distance], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the target layer\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nin the target layer will be used.\n•limit- an optional integer to limit the number of matching features. If not set, only the\nnearest feature will be returned. If set to -1, returns all the matching features.\n•max_distance- an optional distance to limit the search of matching features. If not set,\nall the features in the target layer will be used.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_nearest('airports')→ true if the “airports” layer has at least one\nfeature\n•overlay_nearest('airports', max_distance:= 5000)→ true if there\nis an airport within a distance of 5000 map units from the current feature\n•overlay_nearest('airports', name)→ the name of the closest airport to\nthe current feature, as an array\n•array_to_string(overlay_nearest('airports', name))→ the name\nof the closest airport to the current feature, as a string\n•overlay_nearest(layer:='airports',   expression:=   name,\nmax_distance:= 5000)→ the name of the closest airport within a distance of\n5000 map units from the current feature, as an array\n•overlay_nearest(layer:='airports',     expression:=\"name\",\nfilter:= \"Use\"='Civilian', limit:=3)→ an array of names, for up to\nthe three closest civilian airports ordered by distance\n•overlay_nearest(layer:='airports',     expression:=\"name\",\nlimit:= -1, max_distance:= 5000)→ an array of names, for all the airports\nwithin a distance of 5000 map units from the current feature, ordered by distance\nFurther reading:array manipulation,Join attributes by nearestalgorithm\noverlay_touches\nReturns whether the current feature spatially touches at least one feature from a target layer, or an array of expression-\nbased results for the features in the target layer touched by the current feature.\nRead more on the underlying GEOS “Touches” predicate, as described in PostGISST_Touchesfunction.\n270Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxoverlay_touches(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_touches('regions')→ true if the current feature spatially touches a\nregion\n•overlay_touches('regions', filter:= population > 10000)→\ntrue if the current feature spatially touches a region with a population greater than 10000\n•overlay_touches('regions', name)→ an array of names, for the regions\ntouched by the current feature\n•string_to_array(overlay_touches('regions', name))→ a string as\na comma separated list of names, for the regions touched by the current feature\n•array_sort(overlay_touches(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions touched by the current feature and with a\npopulation greater than 10000\n•overlay_touches(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions touched by the current feature\nFurther reading:touches,array manipulation,Select by locationalgorithm\noverlay_within\nReturns whether the current feature is spatially within at least one feature from a target layer, or an array of expression-\nbased results for the features in the target layer that contain the current feature.\nRead more on the underlying GEOS “Within” predicate, as described in PostGISST_Withinfunction.\n12.2. List of functions271\n\nQGIS Desktop 3.22 User Guide\nSyntaxoverlay_within(layer, [expression], [filter], [limit], [cache=false])\n[] marks optional arguments\nArguments\n•layer- the layer whose overlay is checked\n•expression- an optional expression to evaluate on the features from the target layer. If not\nset, the function will just return a boolean indicating whether there is at least one match.\n•filter- an optional expression to filter the target features to check. If not set, all the features\nwill be checked.\n•limit- an optional integer to limit the number of matching features. If not set, all the\nmatching features will be returned.\n•cache- set this to true to build a local spatial index (most of the time, this is unwanted,\nunless you are working with a particularly slow data provider)\nExamples\n•overlay_within('regions')→ true if the current feature is spatially within a\nregion\n•overlay_within('regions', filter:= population > 10000)→ true\nif the current feature is spatially within a region with a population greater than 10000\n•overlay_within('regions', name)→ an array of names, for the regions con-\ntaining the current feature\n•array_to_string(overlay_within('regions', name))→ a string as a\ncomma separated list of names, for the regions containing the current feature\n•array_sort(overlay_within(layer:='regions',\nexpression:=\"name\",  filter:=  population  >  10000))→ an\nordered array of names, for the regions containing the current feature and with a\npopulation greater than 10000\n•overlay_within(layer:='regions',expression:=\ngeom_to_wkt($geometry),   limit:=2)→ an array of geometries (in\nWKT), for up to two regions containing the current feature\nFurther reading:within,array manipulation,Select by locationalgorithm\n$perimeter\nReturns the perimeter length of the current feature. The perimeter calculated by this function respects both the current\nproject’s ellipsoid setting and distance unit settings. For example, if an ellipsoid has been set for the project then the\ncalculated perimeter will be ellipsoidal, and if no ellipsoid is set then the calculated perimeter will be planimetric.\nSyntax$perimeter\nExamples\n•$perimeter→ 42\nperimeter\nReturns the perimeter of a geometry polygon object. Calculations are always planimetric in the Spatial Reference\nSystem (SRS) of this geometry, and the units of the returned perimeter will match the units for the SRS. This differs\nfrom the calculations performed by the $perimeter function, which will perform ellipsoidal calculations based on the\nproject’s ellipsoid and distance unit settings.\n272Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxperimeter(geometry)\nArguments\n•geometry- polygon geometry object\nExamples\n•perimeter(geom_from_wkt('POLYGON((0 0, 4 0, 4 2, 0 2, 0\n0))'))→ 12.0\npoint_n\nReturns a specific node from a geometry.\nSyntaxpoint_n(geometry, index)\nArguments\n•geometry- geometry object\n•index- index of node to return, where 1 is the first node; if the value is negative, the\nselected vertex index will be its total count minus the absolute value\nExamples\n•geom_to_wkt(point_n(geom_from_wkt('POLYGON((0 0, 4 0, 4 2,\n0 2, 0 0))'),2))→ ‘Point (4 0)’\nFurther reading:Extract specific verticesalgorithm\npoint_on_surface\nReturns a point guaranteed to lie on the surface of a geometry.\nSyntaxpoint_on_surface(geometry)\nArguments\n•geometry- a geometry\nExamples\n•point_on_surface($geometry)→ a point geometry\nFurther reading:Point on Surfacealgorithm\npole_of_inaccessibility\nCalculates the approximate pole of inaccessibility for a surface, which is the most distant internal point from the\nboundary of the surface. This function uses the ‘polylabel’ algorithm (Vladimir Agafonkin, 2016), which is an iterative\napproach guaranteed to find the true pole of inaccessibility within a specified tolerance. More precise tolerances\nrequire more iterations and will take longer to calculate.\nSyntaxpole_of_inaccessibility(geometry, tolerance)\nArguments\n•geometry- a geometry\n•tolerance- maximum distance between the returned point and the true pole location\nExamples\n•geom_to_wkt(pole_of_inaccessibility( geom_from_wkt('POLYGON((0\n1, 0 9, 3 10, 3 3, 10 3, 10 1, 0 1))'), 0.1))'→ ‘Point(1.546875\n2.546875)’\n12.2. List of functions273\n\nQGIS Desktop 3.22 User Guide\nFurther reading:Pole of inaccessibilityalgorithm\nproject\nReturns a point projected from a start point using a distance, a bearing (azimuth) and an elevation in radians.\nSyntaxproject(point, distance, azimuth, [elevation])\n[] marks optional arguments\nArguments\n•point- start point\n•distance- distance to project\n•azimuth- azimuth in radians clockwise, where 0 corresponds to north\n•elevation- angle of inclination in radians\nExamples\n•geom_to_wkt(project(make_point(1, 2), 3, radians(270)))→\n‘Point(-2, 2)’\nFurther reading:Project points (Cartesian)algorithm\nrelate\nTests the Dimensional Extended 9 Intersection Model (DE-9IM) representation of the relationship between two ge-\nometries.\nRelationship variant\nReturns the Dimensional Extended 9 Intersection Model (DE-9IM) representation of the relationship between two\ngeometries.\nSyntaxrelate(geometry, geometry)\nArguments\n•geometry- a geometry\n•geometry- a geometry\nExamples\n•relate(  geom_from_wkt(  'LINESTRING(40  40,120  120)'  ),\ngeom_from_wkt( 'LINESTRING(40 40,60 120)' ) )→ ‘FF1F00102’\nPattern match variant\nTests whether the DE-9IM relationship between two geometries matches a specified pattern.\nSyntaxrelate(geometry, geometry, pattern)\nArguments\n•geometry- a geometry\n•geometry- a geometry\n•pattern- DE-9IM pattern to match\nExamples\n•relate(  geom_from_wkt(  'LINESTRING(40  40,120  120)'  ),\ngeom_from_wkt( 'LINESTRING(40 40,60 120)' ), '**1F001**'\n)→ True\n274Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nreverse\nReverses the direction of a line string by reversing the order of its vertices.\nSyntaxreverse(geometry)\nArguments\n•geometry- a geometry\nExamples\n•geom_to_wkt(reverse(geom_from_wkt('LINESTRING(0 0, 1 1, 2\n2)')))→ ‘LINESTRING(2 2, 1 1, 0 0)’\nFurther reading:Reverse line directionalgorithm\nrotate\nReturns a rotated version of a geometry. Calculations are in the Spatial Reference System of this geometry.\nSyntaxrotate(geometry, rotation, [center])\n[] marks optional arguments\nArguments\n•geometry- a geometry\n•rotation- clockwise rotation in degrees\n•center- rotation center point. If not specified, the center of the geometry’s bounding box\nis used.\nExamples\n•rotate($geometry, 45, make_point(4, 5))→ geometry rotated 45 de-\ngrees clockwise around the (4, 5) point\n•rotate($geometry, 45)→ geometry rotated 45 degrees clockwise around the\ncenter of its bounding box\n12.2. List of functions275\n\nQGIS Desktop 3.22 User Guide\nFig. 12.7: Rotating features\nsegments_to_lines\nReturns a multi line geometry consisting of a line for every segment in the input geometry.\nSyntaxsegments_to_lines(geometry)\nArguments\n•geometry- geometry object\nExamples\n•geom_to_wkt(segments_to_lines(geom_from_wkt('LINESTRING(0\n0, 1 1, 2 2)')))→ ‘MultiLineString ((0 0, 1 1),(1 1, 2 2))’\nFurther reading:Explode linesalgorithm\n276Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nshortest_line\nReturns the shortest line joining geometry1 to geometry2. The resultant line will start at geometry1 and end at\ngeometry2.\nSyntaxshortest_line(geometry1, geometry2)\nArguments\n•geometry1- geometry to find shortest line from\n•geometry2- geometry to find shortest line to\nExamples\n•geom_to_wkt(shortest_line(geom_from_wkt('LINESTRING    (20\n80, 98 190, 110 180, 50 75 )'),geom_from_wkt('POINT(100\n100)')))→ ‘LineString(73.0769 115.384, 100 100)’\nsimplify\nSimplifies a geometry by removing nodes using a distance based threshold (ie, the Douglas Peucker algorithm). The\nalgorithm preserves large deviations in geometries and reduces the number of vertices in nearly straight segments.\nSyntaxsimplify(geometry, tolerance)\nArguments\n•geometry- a geometry\n•tolerance- maximum deviation from straight segments for points to be removed\nExamples\n•geom_to_wkt(simplify(geometry:=geom_from_wkt('LineString(0\n0, 5 0.1, 10 0)'),tolerance:=5))→ ‘LineString(0 0, 10 0)’\nFurther reading:Simplifyalgorithm\nsimplify_vw\nSimplifies a geometry by removing nodes using an area based threshold (ie, the Visvalingam-Whyatt algorithm). The\nalgorithm removes vertices which create small areas in geometries, e.g., narrow spikes or nearly straight segments.\nSyntaxsimplify_vw(geometry, tolerance)\nArguments\n•geometry- a geometry\n•tolerance- a measure of the maximum area created by a node for the node to be removed\nExamples\n•geom_to_wkt(simplify_vw(geometry:=geom_from_wkt('LineString(0\n0, 5 0, 5.01 10, 5.02 0, 10 0)'),tolerance:=5))→ ‘LineString(0\n0, 10 0)’\nFurther reading:Simplifyalgorithm\n12.2. List of functions277\n\nQGIS Desktop 3.22 User Guide\nsingle_sided_buffer\nReturns a geometry formed by buffering out just one side of a linestring geometry. Distances are in the Spatial\nReference System of this geometry.\nSyntaxsingle_sided_buffer(geometry, distance, [segments=8], [join=1], [miter_limit=2.0])\n[] marks optional arguments\nArguments\n•geometry- a (multi)linestring geometry\n•distance- buffer distance. Positive values will be buffered to the left of lines, negative\nvalues to the right\n•segments\n- number of segments to use to represent a quarter circle when a round join\nstyle is used. A larger number results in a smoother buffer with more nodes.\n•join- join style for corners, where 1 = round, 2 = miter and 3 = bevel\n•miter_limit- limit on the miter ratio used for very sharp corners (when using miter joins\nonly)\nExamples\n•single_sided_buffer($geometry, 10.5)→ line buffered to the left by 10.5\nunits\n•single_sided_buffer($geometry, -10.5)→ line buffered to the right by\n10.5 units\n•single_sided_buffer($geometry,     10.5,     segments:=16,\njoin:=1)→ line buffered to the left by 10.5 units, using more segments to re-\nsult in a smoother buffer\n•single_sided_buffer($geometry, 10.5, join:=3)→ line buffered to\nthe left by 10.5 units, using a beveled join\nFurther reading:Single sided bufferalgorithm\nsinuosity\nReturns the sinuosity of a curve, which is the ratio of the curve length to the straight (2D) distance between its\nendpoints.\nSyntaxsinuosity(geometry)\nArguments\n•geometry- Input curve (circularstring, linestring)\nExamples\n•round(sinuosity(geom_from_wkt('LINESTRING(2 0, 2 2, 3 2, 3\n3)')), 3)→ 1.265\n•sinuosity(geom_from_wkt('LINESTRING( 3 1, 5 1)'))→ 1.0\nsmooth\nSmooths a geometry by adding extra nodes which round off corners in the geometry. If input geometries contain Z\nor M values, these will also be smoothed and the output geometry will retain the same dimensionality as the input\ngeometry.\n278Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxsmooth(geometry, [iterations=1], [offset=0.25], [min_length=-1], [max_angle=180])\n[] marks optional arguments\nArguments\n•geometry- a geometry\n•iterations- number of smoothing iterations to apply. Larger numbers result in smoother\nbut more complex geometries.\n•offset- value between 0 and 0.5 which controls how tightly the smoothed geometry follow\nthe original geometry. Smaller values result in a tighter smoothing, larger values result in\nlooser smoothing.\n•min_length- minimum length of segments to apply smoothing to. This parameter can\nbe used to avoid placing excessive additional nodes in shorter segments of the geometry.\n•max_angle- maximum angle at node for smoothing to be applied (0-180). By lowering\nthe maximum angle intentionally sharp corners in the geometry can be preserved. For\ninstance, a value of 80 degrees will retain right angles in the geometry.\nExamples\n•geom_to_wkt(smooth(geometry:=geom_from_wkt('LineString(0\n0, 5 0, 5 5)'),iterations:=1,offset:=0.2,min_length:=-1,\nmax_angle:=180))→ ‘LineString (0 0, 4 0, 5 1, 5 5)’\nFurther reading:Smoothalgorithm\nstart_point\nReturns the first node from a geometry.\nSyntaxstart_point(geometry)\nArguments\n•geometry- geometry object\nExamples\n•geom_to_wkt(start_point(geom_from_wkt('LINESTRING(4  0,  4\n2, 0 2)')))→ ‘Point (4 0)’\nFurther reading:Extract specific verticesalgorithm\nstraight_distance_2d\nReturns the direct/euclidean distance between the first and last vertex of a geometry. The geometry must be a curve\n(circularstring, linestring).\nSyntaxstraight_distance_2d(geometry)\nArguments\n•geometry- The geometry.\nExamples\n•straight_distance_2d(geom_from_wkt('LINESTRING(1   0,   1\n1)'))→ 1\n•round(straight_distance_2d(geom_from_wkt('LINESTRING(1  4,\n3 5, 5 0)')), 3)→ 5.657\nFurther reading:length\n12.2. List of functions279\n\nQGIS Desktop 3.22 User Guide\nsym_difference\nReturns a geometry that represents the portions of two geometries that do not intersect.\nSyntaxsym_difference(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•geom_to_wkt( sym_difference( geom_from_wkt( 'LINESTRING(3\n3, 4 4, 5 5)' ), geom_from_wkt( 'LINESTRING(3 3, 8 8)' ) )\n)\n→ ‘LINESTRING(5 5, 8 8)’\nFurther reading:Symmetrical differencealgorithm\ntapered_buffer\nCreates a buffer along a line geometry where the buffer diameter varies evenly over the length of the line.\nSyntaxtapered_buffer(geometry, start_width, end_width, [segments=8])\n[] marks optional arguments\nArguments\n•geometry- input geometry. Must be a (multi)line geometry.\n•start_width- width of buffer at start of line,\n•end_width- width of buffer at end of line.\n•segments- number of segments to approximate quarter-circle curves in the buffer.\nExamples\n•tapered_buffer(geometry:=geom_from_wkt('LINESTRING(1 2, 4\n2)'),start_width:=1,end_width:=2,segments:=8)→ A tapered buffer\nstarting with a diameter of 1 and ending with a diameter of 2 along the linestring geometry.\n280Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nFig. 12.8: Tapered buffer on line features\nFurther reading:Tapered buffersalgorithm\ntouches\nTests whether a geometry touches another. Returns true if the geometries have at least one point in common, but\ntheir interiors do not intersect.\nSyntaxtouches(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•touches(  geom_from_wkt(  'LINESTRING(5  3,  4  4)'  ),\ngeom_from_wkt( 'LINESTRING(3 3, 4 4, 5 5)' ) )→ true\n•touches(  geom_from_wkt(  'POINT(4  4)'  ),  geom_from_wkt(\n'POINT(5 5)' ) )→ false\nFurther reading:overlay_touches\n12.2. List of functions281\n\nQGIS Desktop 3.22 User Guide\ntransform\nReturns the geometry transformed from a source CRS to a destination CRS.\nSyntaxtransform(geometry, source_auth_id, dest_auth_id)\nArguments\n•geometry- a geometry\n•source_auth_id- the source auth CRS ID\n•dest_auth_id- the destination auth CRS ID\nExamples\n•geom_to_wkt(    transform(    make_point(488995.53240249,\n7104473.38600835), 'EPSG:2154', 'EPSG:4326' ) )→ ‘POINT(0\n51)’\nFurther reading:Reproject layeralgorithm\ntranslate\nReturns a translated version of a geometry. Calculations are in the Spatial Reference System of this geometry.\nSyntaxtranslate(geometry, dx, dy)\nArguments\n•geometry- a geometry\n•dx- delta x\n•dy- delta y\nExamples\n•translate($geometry, 5, 10)→ a geometry of the same type like the original\none\n282Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nFig. 12.9: Translating features\nFurther reading:Translatealgorithm\nunion\nReturns a geometry that represents the point set union of the geometries.\nSyntaxunion(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•geom_to_wkt( union( make_point(4, 4), make_point(5, 5) ) )\n→ ‘MULTIPOINT(4 4, 5 5)’\n12.2. List of functions283\n\nQGIS Desktop 3.22 User Guide\nwedge_buffer\nReturns a wedge shaped buffer originating from a point geometry.\nSyntaxwedge_buffer(center, azimuth, width, outer_radius, [inner_radius=0.0])\n[] marks optional arguments\nArguments\n•center- center point (origin) of buffer. Must be a point geometry.\n•azimuth- angle (in degrees) for the middle of the wedge to point.\n•width- buffer width (in degrees). Note that the wedge will extend to half of the angular\nwidth either side of the azimuth direction.\n•outer_radius\n- outer radius for buffers\n•inner_radius- optional inner radius for buffers\nExamples\n•wedge_buffer(center:=geom_from_wkt('POINT(12)'),\nazimuth:=90,width:=180,outer_radius:=1)→ A wedge shaped buffer\ncentered on the point (1,2), facing to the East, with a width of 180 degrees and outer\nradius of 1.\nFurther reading:Create wedge buffersalgorithm\nwithin\nTests whether a geometry is within another. Returns true if the geometry1 is completely within geometry2.\nSyntaxwithin(geometry1, geometry2)\nArguments\n•geometry1- a geometry\n•geometry2- a geometry\nExamples\n•within( geom_from_wkt( 'POINT( 0.5 0.5)' ), geom_from_wkt(\n'POLYGON((0 0, 0 1, 1 1, 1 0, 0 0))' ) )→ true\n•within( geom_from_wkt( 'POINT( 5 5 )' ), geom_from_wkt(\n'POLYGON((0 0, 0 1, 1 1, 1 0, 0 0 ))' ) )→ false\nFurther reading:overlay_within\n$x\nReturns the x coordinate of the current point feature. If the feature is a multipoint feature, then the x-coordinate of\nthe first point will be returned.\nSyntax$x\nExamples\n•$x→ 42\n284Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nx\nReturns the x coordinate of a point geometry, or the x coordinate of the centroid for a non-point geometry.\nSyntaxx(geometry)\nArguments\n•geometry- a geometry\nExamples\n•x( geom_from_wkt( 'POINT(2 5)' ) )→ 2\n•x( $geometry )→ x coordinate of the current feature’s centroid\n$x_at\nRetrieves a x coordinate of the current feature’s geometry.\nSyntax$x_at(i)\nArguments\n•i- index of point of a line (indices start at 0; negative values apply from the last index,\nstarting at -1)\nExamples\n•$x_at(1)→ 5\nx_max\nReturns the maximum x coordinate of a geometry. Calculations are in the spatial reference system of this geometry.\nSyntaxx_max(geometry)\nArguments\n•geometry- a geometry\nExamples\n•x_max( geom_from_wkt( 'LINESTRING(2 5, 3 6, 4 8)') )→ 4\nx_min\nReturns the minimum x coordinate of a geometry. Calculations are in the spatial reference system of this geometry.\nSyntaxx_min(geometry)\nArguments\n•geometry- a geometry\nExamples\n•x_min( geom_from_wkt( 'LINESTRING(2 5, 3 6, 4 8)') )→ 2\n12.2. List of functions285\n\nQGIS Desktop 3.22 User Guide\n$y\nReturns the y coordinate of the current point feature. If the feature is a multipoint feature, then the y-coordinate of\nthe first point will be returned.\nSyntax$y\nExamples\n•$y→ 42\ny\nReturns the y coordinate of a point geometry, or the y coordinate of the centroid for a non-point geometry.\nSyntaxy(geometry)\nArguments\n•geometry- a geometry\nExamples\n•y( geom_from_wkt( 'POINT(2 5)' ) )→ 5\n•y( $geometry )→ y coordinate of the current feature’s centroid\n$y_at\nRetrieves a y coordinate of the current feature’s geometry.\nSyntax$y_at(i)\nArguments\n•i- index of point of a line (indices start at 0; negative values apply from the last index,\nstarting at -1)\nExamples\n•$y_at(1)→ 2\ny_max\nReturns the maximum y coordinate of a geometry. Calculations are in the spatial reference system of this geometry.\nSyntaxy_max(geometry)\nArguments\n•geometry- a geometry\nExamples\n•y_max( geom_from_wkt( 'LINESTRING(2 5, 3 6, 4 8)') )→ 8\n286Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\ny_min\nReturns the minimum y coordinate of a geometry. Calculations are in the spatial reference system of this geometry.\nSyntaxy_min(geometry)\nArguments\n•geometry- a geometry\nExamples\n•y_min( geom_from_wkt( 'LINESTRING(2 5, 3 6, 4 8)') )→ 5\n$z\nReturns the z value of the current point feature if it is 3D. If the feature is a multipoint feature, then the z value of\nthe first point will be returned.\nSyntax$z\nExamples\n•$z→ 123\nz\nReturns the z coordinate of a point geometry, or NULL if the geometry has no z value.\nSyntaxz(geometry)\nArguments\n•geometry- a point geometry\nExamples\n•z( geom_from_wkt( 'POINTZ(2 5 7)' ) )→ 7\nz_max\nReturns the maximum z coordinate of a geometry, or NULL if the geometry has no z value.\nSyntaxz_max(geometry)\nArguments\n•geometry- a geometry with z coordinate\nExamples\n•z_max( geom_from_wkt( 'POINT ( 0 0 1 )' ) )→ 1\n•z_max( geom_from_wkt( 'MULTIPOINT ( 0 0 1 , 1 1 3 )' ) )→ 3\n•z_max( make_line( make_point( 0,0,0 ), make_point( -1,-1,-2\n) ) )→ 0\n•z_max( geom_from_wkt( 'LINESTRING( 0 0 0, 1 0 2, 1 1 -1 )'\n) )→ 2\n•z_max( geom_from_wkt( 'POINT ( 0 0 )' ) )→ NULL\n12.2. List of functions287\n\nQGIS Desktop 3.22 User Guide\nz_min\nReturns the minimum z coordinate of a geometry, or NULL if the geometry has no z value.\nSyntaxz_min(geometry)\nArguments\n•geometry- a geometry with z coordinate\nExamples\n•z_min( geom_from_wkt( 'POINT ( 0 0 1 )' ) )→ 1\n•z_min( geom_from_wkt( 'MULTIPOINT ( 0 0 1 , 1 1 3 )' ) )→ 1\n•z_min( make_line( make_point( 0,0,0 ), make_point( -1,-1,-2\n) ) )→ -2\n•z_min( geom_from_wkt( 'LINESTRING( 0 0 0, 1 0 2, 1 1 -1 )'\n) )→ -1\n•z_min( geom_from_wkt( 'POINT ( 0 0 )' ) )→ NULL\n12.2.14Layout Functions\nThis group contains functions to manipulate print layout items properties.\nitem_variables\nReturns a map of variables from a layout item inside this print layout.\nSyntaxitem_variables(id)\nArguments\n•id- layout item ID\nExamples\n•map_get( item_variables('Map 0'), 'map_scale')→ scale of the item\n‘Map 0’ in the current print layout\nFurther reading: List of defaultvariables\n288Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nmap_credits\nReturns a list of credit (usage rights) strings for the layers shown in a layout map item.\nSyntaxmap_credits(id, [include_layer_names=false], [layer_name_separator=’: ‘])\n[] marks optional arguments\nArguments\n•id- map item ID\n•include_layer_names- Set to true to include layer names before their credit strings\n•layer_name_separator- String to insert between layer names and their credit strings, if\ninclude_layer_names is true\nExamples\n•array_to_string( map_credits( 'Main Map' ) )→ comma separated\nlist of layer credits for layers shown in the ‘Main Map’ layout item, e.g ‘CC-BY-NC, CC-\nBY-SA’\n•array_to_string(    map_credits(    'Main    Map',    in-\nclude_layer_names  :=  true,  layer_name_separator  :=  ':\n' ) )→ comma separated list of layer names and their credits for layers shown in the\n‘Main Map’ layout item, e.g. ‘Railway lines: CC-BY-NC, Basemap: CC-BY-SA’\nThis function requires theAccess metadata propertiesof the layers to have been filled.\n12.2.15Map Layers\nThis group contains a list of the available layers in the current project. This offers a convenient way to write expressions\nreferring to multiple layers, such as when performing\naggregates,attributeorspatialqueries.\nIt also provides some convenient functions to manipulate layers.\ndecode_uri\nTakes a layer and decodes the uri of the underlying data provider. It depends on the dataprovider, which data is\navailable.\nSyntaxdecode_uri(layer, [part])\n[] marks optional arguments\nArguments\n•layer- The layer for which the uri should be decoded.\n•part- The part of the uri to return. If unspecified, a map with all uri parts will be returned.\nExamples\n•decode_uri(@layer)→  {‘layerId’:‘0’,   ‘layerName’:‘’,   ‘path’:\n‘/home/qgis/shapefile.shp’}\n•decode_uri(@layer)→ {‘layerId’:   NULL, ‘layerName’:   ‘layer’,  ‘path’:\n‘/home/qgis/geopackage.gpkg’}\n•decode_uri(@layer, 'path')→ ‘C:\\my_data\\qgis\\shape.shp’\n12.2. List of functions289\n\nQGIS Desktop 3.22 User Guide\nlayer_property\nReturns a matching layer property or metadata value.\nSyntaxlayer_property(layer, property)\nArguments\n•layer- a string, representing either a layer name or layer ID\n•property- a string corresponding to the property to return. Valid options are:\n–name: layer name\n–id: layer ID\n–title: metadata title string\n–abstract: metadata abstract string\n–keywords: metadata keywords\n–data_url: metadata URL\n–attribution: metadata attribution string\n–attribution_url: metadata attribution URL\n–source: layer source\n–min_scale: minimum display scale for layer\n–max_scale: maximum display scale for layer\n–is_editable: if layer is in edit mode\n–crs: layer CRS\n–crs_definition: layer CRS full definition\n–crs_description: layer CRS description\n–extent: layer extent (as a geometry object)\n–distance_units: layer distance units\n–type: layer type, e.g., Vector or Raster\n–storage_type: storage format (vector layers only)\n–geometry_type: geometry type, e.g., Point (vector layers only)\n–feature_count: approximate feature count for layer (vector layers only)\n–path: File path to the layer data source. Only available for file based layers.\nExamples\n•layer_property('streets','title')→ ‘Basemap Streets’\n•layer_property('airports','feature_count')→ 120\n•layer_property('landsat','crs')→ ‘EPSG:4326’\nFurther reading:vector,rasterandmeshlayer properties\n12.2.16Maps Functions\nThis group contains functions to create or manipulate keys and values of map data structures (also known as dictionary\nobjects, key-value pairs, or associative arrays). Unlike thelist data structurewhere values order matters, the order of\nthe key-value pairs in the map object is not relevant and values are identified by their keys.\nfrom_json\nLoads a JSON formatted string.\nSyntaxfrom_json(string)\nArguments\n•string- JSON string\nExamples\n•from_json('{\"qgis\":\"rocks\"}')→ { ‘qgis’: ‘rocks’ }\n•from_json('[1,2,3]')→ [1,2,3]\n290Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nhstore_to_map\nCreates a map from a hstore-formatted string.\nSyntaxhstore_to_map(string)\nArguments\n•string- the input string\nExamples\n•hstore_to_map('qgis=>rocks')→ { ‘qgis’: ‘rocks’ }\nmap\nReturns a map containing all the keys and values passed as pair of parameters.\nSyntaxmap(key1, value1, key2, value2, ...)\nArguments\n•key- a key (string)\n•value- a value\nExamples\n•map('1','one','2', 'two')→ { ‘1’: ‘one’, ‘2’: ‘two’ }\n•map('1','one','2', 'two')['1']→ ‘one’\nmap_akeys\nReturns all the keys of a map as an array.\nSyntaxmap_akeys(map)\nArguments\n•map- a map\nExamples\n•map_akeys(map('1','one','2','two'))→ [ ‘1’, ‘2’ ]\nmap_avals\nReturns all the values of a map as an array.\nSyntaxmap_avals(map)\nArguments\n•map- a map\nExamples\n•map_avals(map('1','one','2','two'))→ [ ‘one’, ‘two’ ]\n12.2. List of functions291\n\nQGIS Desktop 3.22 User Guide\nmap_concat\nReturns a map containing all the entries of the given maps. If two maps contain the same key, the value of the second\nmap is taken.\nSyntaxmap_concat(map1, map2, ...)\nArguments\n•map- a map\nExamples\n•map_concat(map('1','one', '2','overridden'),map('2','two',\n'3','three'))→ { ‘1’: ‘one’, ‘2’: ‘two’, ‘3’: ‘three’ }\nmap_delete\nReturns a map with the given key and its corresponding value deleted.\nSyntaxmap_delete(map, key)\nArguments\n•map- a map\n•key- the key to delete\nExamples\n•map_delete(map('1','one','2','two'),'2')→ { ‘1’: ‘one’ }\nmap_exist\nReturns true if the given key exists in the map.\nSyntaxmap_exist(map, key)\nArguments\n•map- a map\n•key- the key to lookup\nExamples\n•map_exist(map('1','one','2','two'),'3')→ false\nmap_get\nReturns the value of a map, given its key. Returns NULL if the key does not exist.\nSyntaxmap_get(map, key)\nArguments\n•map- a map\n•key- the key to lookup\nExamples\n•map_get(map('1','one','2','two'),'2')→ ‘two’\n•map_get( item_variables('Map 0'), 'map_scale')→ scale of the item\n‘Map 0’ (if it exists) in the current print layout\nHint:You can also use theindex operator ([])to get a value from a map.\n292Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nmap_insert\nReturns a map with an added key/value. If the key already exists, its value is overridden.\nSyntaxmap_insert(map, key, value)\nArguments\n•map\n- a map\n•key- the key to add\n•value- the value to add\nExamples\n•map_insert(map('1','one'),'3','three')→ { ‘1’: ‘one’, ‘3’: ‘three’ }\n•map_insert(map('1','one','2','overridden'),'2','two')→ {\n‘1’: ‘one’, ‘2’: ‘two’ }\nmap_to_hstore\nMerge map elements into a hstore-formatted string.\nSyntaxmap_to_hstore(map)\nArguments\n•map- the input map\nExamples\n•map_to_hstore(map('qgis','rocks'))→ ‘“qgis”=>”rocks”’\nto_json\nCreate a JSON formatted string from a map, array or other value.\nSyntaxto_json(value)\nArguments\n•value- The input value\nExamples\n•to_json(map('qgis','rocks'))→ {“qgis”:”rocks”}\n•to_json(array(1,2,3))→ [1,2,3]\n12.2.17Mathematical Functions\nThis group contains math functions (e.g., square root, sin and cos).\nabs\nReturns the absolute value of a number.\nSyntaxabs(value)\nArguments\n•value- a number\nExamples\n•abs(-2)→ 2\n12.2. List of functions293\n\nQGIS Desktop 3.22 User Guide\nacos\nReturns the inverse cosine of a value in radians.\nSyntaxacos(value)\nArguments\n•value- cosine of an angle in radians\nExamples\n•acos(0.5)→ 1.0471975511966\nasin\nReturns the inverse sine of a value in radians.\nSyntaxasin(value)\nArguments\n•value- sine of an angle in radians\nExamples\n•asin(1.0)→ 1.5707963267949\natan\nReturns the inverse tangent of a value in radians.\nSyntaxatan(value)\nArguments\n•value- tan of an angle in radians\nExamples\n•atan(0.5)→ 0.463647609000806\natan2\nReturns the inverse tangent of dy/dx by using the signs of the two arguments to determine the quadrant of the result.\nSyntaxatan2(dy, dx)\nArguments\n•dy- y coordinate difference\n•dx- x coordinate difference\nExamples\n•atan2(1.0, 1.732)→ 0.523611477769969\n294Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nceil\nRounds a number upwards.\nSyntaxceil(value)\nArguments\n•value- a number\nExamples\n•ceil(4.9)→ 5\n•ceil(-4.9)→ -4\nclamp\nRestricts an input value to a specified range.\nSyntaxclamp(minimum, input, maximum)\nArguments\n•minimum- the smallest valueinputis allowed to take.\n•input- a value which will be restricted to the range specified byminimumandmaximum\n•maximum- the largest valueinputis allowed to take\nExamples\n•clamp(1,5,10)→ 5\ninputis between 1 and 10 so is returned unchanged\n•clamp(1,0,10)→ 1\ninputis less than minimum value of 1, so function returns 1\n•clamp(1,11,10)→ 10\ninputis greater than maximum value of 10, so function returns 10\ncos\nReturns cosine of an angle.\nSyntaxcos(angle)\nArguments\n•angle- angle in radians\nExamples\n•cos(1.571)→ 0.000796326710733263\ndegrees\nConverts from radians to degrees.\nSyntaxdegrees(radians)\nArguments\n•radians- numeric value\nExamples\n•degrees(3.14159)→ 180\n•degrees(1)→ 57.2958\n12.2. List of functions295\n\nQGIS Desktop 3.22 User Guide\nexp\nReturns exponential of an value.\nSyntaxexp(value)\nArguments\n•value- number to return exponent of\nExamples\n•exp(1.0)→ 2.71828182845905\nfloor\nRounds a number downwards.\nSyntaxfloor(value)\nArguments\n•value- a number\nExamples\n•floor(4.9)→ 4\n•floor(-4.9)→ -5\nln\nReturns the natural logarithm of a value.\nSyntaxln(value)\nArguments\n•value- numeric value\nExamples\n•ln(1)→ 0\n•ln(2.7182818284590452354)→ 1\nlog\nReturns the value of the logarithm of the passed value and base.\nSyntaxlog(base, value)\nArguments\n•base- any positive number\n•value- any positive number\nExamples\n•log(2, 32)→ 5\n•log(0.5, 32)→ -5\n296Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nlog10\nReturns the value of the base 10 logarithm of the passed expression.\nSyntaxlog10(value)\nArguments\n•value- any positive number\nExamples\n•log10(1)→ 0\n•log10(100)→ 2\nmax\nReturns the largest value in a set of values.\nSyntaxmax(value1, value2, ...)\nArguments\n•value- a number\nExamples\n•max(2,10.2,5.5)→ 10.2\n•max(20.5,NULL,6.2)→ 20.5\nmin\nReturns the smallest value in a set of values.\nSyntaxmin(value1, value2, ...)\nArguments\n•value- a number\nExamples\n•min(20.5,10,6.2)→ 6.2\n•min(2,-10.3,NULL)→ -10.3\npi\nReturns value of pi for calculations.\nSyntaxpi()\nExamples\n•pi()→ 3.14159265358979\n12.2. List of functions297\n\nQGIS Desktop 3.22 User Guide\nradians\nConverts from degrees to radians.\nSyntaxradians(degrees)\nArguments\n•degrees- numeric value\nExamples\n•radians(180)→ 3.14159\n•radians(57.2958)→ 1\nrand\nReturns a random integer within the range specified by the minimum and maximum argument (inclusive). If a seed\nis provided, the returned will always be the same, depending on the seed.\nSyntaxrand(min, max, [seed=NULL])\n[] marks optional arguments\nArguments\n•min- an integer representing the smallest possible random number desired\n•max- an integer representing the largest possible random number desired\n•seed- any value to use as seed\nExamples\n•rand(1, 10)→ 8\nrandf\nReturns a random float within the range specified by the minimum and maximum argument (inclusive). If a seed is\nprovided, the returned will always be the same, depending on the seed.\nSyntaxrandf([min=0.0], [max=1.0], [seed=NULL])\n[] marks optional arguments\nArguments\n•min- an float representing the smallest possible random number desired\n•max- an float representing the largest possible random number desired\n•seed- any value to use as seed\nExamples\n•randf(1, 10)→ 4.59258286403147\nround\nRounds a number to number of decimal places.\n298Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxround(value, [places=0])\n[] marks optional arguments\nArguments\n•value- decimal number to be rounded\n•places- Optional integer representing number of places to round decimals to. Can be\nnegative.\nExamples\n•round(1234.567, 2)→ 1234.57\n•round(1234.567)→ 1235\n•round(1234.567, -1)→ 1230\nscale_exp\nTransforms a given value from an input domain to an output range using an exponential curve. This function can be\nused to ease values in or out of the specified output range.\nSyntaxscale_exp(value, domain_min, domain_max, range_min, range_max, exponent)\nArguments\n•value- A value in the input domain. The function will return a corresponding scaled value\nin the output range.\n•domain_min- Specifies the minimum value in the input domain, the smallest value the\ninput value should take.\n•domain_max- Specifies the maximum value in the input domain, the largest value the\ninput value should take.\n•range_min- Specifies the minimum value in the output range, the smallest value which\nshould be output by the function.\n•range_max- Specifies the maximum value in the output range, the largest value which\nshould be output by the function.\n•exponent- A positive value (greater than 0), which dictates the way input values are\nmapped to the output range. Large exponents will cause the output values to ‘ease in’,\nstarting slowly before accelerating as the input values approach the domain maximum.\nSmaller exponents (less than 1) will cause output values to ‘ease out’, where the mapping\nstarts quickly but slows as it approaches the domain maximum.\nExamples\n•scale_exp(5,0,10,0,100,2)→ 25\neasing in, using an exponent of 2\n•scale_exp(3,0,10,0,100,0.5)→ 54.772\neasing out, using an exponent of 0.5\n12.2. List of functions299\n\nQGIS Desktop 3.22 User Guide\nscale_linear\nTransforms a given value from an input domain to an output range using linear interpolation.\nSyntaxscale_linear(value, domain_min, domain_max, range_min, range_max)\nArguments\n•value- A value in the input domain. The function will return a corresponding scaled value\nin the output range.\n•domain_min- Specifies the minimum value in the input domain, the smallest value the\ninput value should take.\n•domain_max- Specifies the maximum value in the input domain, the largest value the\ninput value should take.\n•range_min- Specifies the minimum value in the output range, the smallest value which\nshould be output by the function.\n•range_max- Specifies the maximum value in the output range, the largest value which\nshould be output by the function.\nExamples\n•scale_linear(5,0,10,0,100)→ 50\n•scale_linear(0.2,0,1,0,360)→ 72\nscaling a value between 0 and 1 to an angle between 0 and 360\n•scale_linear(1500,1000,10000,9,20)→ 9.6111111\nscaling a population which varies between 1000 and 10000 to a font size between 9 and\n20\nsin\nReturns the sine of an angle.\nSyntaxsin(angle)\nArguments\n•angle- angle in radians\nExamples\n•sin(1.571)→ 0.999999682931835\nsqrt\nReturns square root of a value.\nSyntaxsqrt(value)\nArguments\n•value- a number\nExamples\n•sqrt(9)→ 3\n300Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\ntan\nReturns the tangent of an angle.\nSyntaxtan(angle)\nArguments\n•angle- angle in radians\nExamples\n•tan(1.0)→ 1.5574077246549\n12.2.18Meshes Functions\nThis group contains functions which calculate or return mesh related values.\n$face_area\nReturns the area of the current mesh face. The area calculated by this function respects both the current project’s\nellipsoid setting and area unit settings. For example, if an ellipsoid has been set for the project then the calculated\narea will be ellipsoidal, and if no ellipsoid is set then the calculated area will be planimetric.\nSyntax$face_area\nExamples\n•$face_area→ 42\n$face_index\nReturns the index of the current mesh face.\nSyntax$face_index\nExamples\n•$face_index→ 4581\n$vertex_as_point\nReturns the current vertex as a point geometry.\nSyntax$vertex_as_point\nExamples\n•geom_to_wkt( $vertex_as_point )→ ‘POINT(800 1500 41)’\n12.2. List of functions301\n\nQGIS Desktop 3.22 User Guide\n$vertex_index\nReturns the index of the current mesh vertex.\nSyntax$vertex_index\nExamples\n•$vertex_index→ 9874\n$vertex_x\nReturns the X coordinate of the current mesh vertex.\nSyntax$vertex_x\nExamples\n•$vertex_x→ 42.12\n$vertex_y\nReturns the Y coordinate of the current mesh vertex.\nSyntax$vertex_y\nExamples\n•$vertex_y→ 12.24\n$vertex_z\nReturns the Z value of the current mesh vertex.\nSyntax$vertex_z\nExamples\n•$vertex_z→ 42\n12.2.19Operators\nThis group contains operators (e.g., +, -, *). Note that for most of the mathematical functions below, if one of the\ninputs is NULL then the result is NULL.\n%\nRemainder of division\nSyntaxa % b\nArguments\n•a- value\n•b- value\nExamples\n•5 % 4→ 1\n•5 % NULL→ NULL\n302Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n*\nMultiplication of two values\nSyntaxa * b\nArguments\n•a- value\n•b- value\nExamples\n•5 * 4→ 20\n•5 * NULL→ NULL\n+\nAddition of two values. If one of the values is NULL the result will be NULL.\nSyntaxa + b\nArguments\n•a- value\n•b- value\nExamples\n•5 + 4→ 9\n•5 + NULL→ NULL\n•'QGIS ' + 'ROCKS'→ ‘QGIS ROCKS’\n•to_datetime('2020-08-01 12:00:00') + '1 day 2 hours'→ 2020-\n08-02T14:00:00\nFurther reading:concat,||\n-\nSubtraction of two values. If one of the values is NULL the result will be NULL.\nSyntaxa - b\nArguments\n•a- value\n•b- value\nExamples\n•5 - 4→ 1\n•5 - NULL→ NULL\n•to_datetime('2012-05-05 12:00:00') - to_interval('1 day 2\nhours')→ 2012-05-04T10:00:00\n12.2. List of functions303\n\nQGIS Desktop 3.22 User Guide\n/\nDivision of two values\nSyntaxa / b\nArguments\n•a- value\n•b- value\nExamples\n•5 / 4→ 1.25\n•5 / NULL→ NULL\n<\nCompares two values and evaluates to 1 if the left value is less than the right value.\nSyntaxa < b\nArguments\n•a- value\n•b- value\nExamples\n•5 < 4→ 0\n•5 < 5→ 0\n•4 < 5→ 1\n<=\nCompares two values and evaluates to 1 if the left value is less or equal than the right value.\nSyntaxa <= b\nArguments\n•a- value\n•b- value\nExamples\n•5 <= 4→ 0\n•5 <= 5→ 1\n•4 <= 5→ 1\n<>\nCompares two values and evaluates to 1 if they are not equal.\n304Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxa <> b\nArguments\n•a- value\n•b- value\nExamples\n•5 <> 4→ 1\n•4 <> 4→ 0\n•5 <> NULL→ NULL\n•NULL <> NULL→ NULL\n=\nCompares two values and evaluates to 1 if they are equal.\nSyntaxa = b\nArguments\n•a- value\n•b- value\nExamples\n•5 = 4→ 0\n•4 = 4→ 1\n•5 = NULL→ NULL\n•NULL = NULL→ NULL\n>\nCompares two values and evaluates to 1 if the left value is greater than the right value.\nSyntaxa > b\nArguments\n•a- value\n•b- value\nExamples\n•5 > 4→ 1\n•5 > 5→ 0\n•4 > 5→ 0\n>=\nCompares two values and evaluates to 1 if the left value is greater or equal than the right value.\nSyntaxa >= b\nArguments\n•a- value\n•b- value\nExamples\n•5 >= 4→ 1\n•5 >= 5→ 1\n•4 >= 5→ 0\n12.2. List of functions305\n\nQGIS Desktop 3.22 User Guide\nAND\nReturns 1 when condition a and b are true.\nSyntaxa AND b\nArguments\n•a- condition\n•b- condition\nExamples\n•TRUE AND TRUE→ 1\n•TRUE AND FALSE→ 0\n•4 = 2+2 AND 1 = 1→ 1\n•4 = 2+2 AND 1 = 2→ 0\nILIKE\nReturns 1 if the first parameter matches case-insensitive the supplied pattern. LIKE can be used instead of ILIKE to\nmake the match case-sensitive. Works with numbers also.\nSyntaxstring/number ILIKE pattern\nArguments\n•string/number- string to search\n•pattern- pattern to find, you can use ‘%’ as a wildcard, ‘_’ as a single char and ‘\\\\’ to escape\nthese special characters.\nExamples\n•'A' ILIKE 'A'→ 1\n•'A' ILIKE 'a'→ 1\n•'A' ILIKE 'B'→ 0\n•'ABC' ILIKE 'b'→ 0\n•'ABC' ILIKE 'B'→ 0\n•'ABC' ILIKE '_b_'→ 1\n•'ABC' ILIKE '_B_'→ 1\n•'ABCD' ILIKE '_b_'→ 0\n•'ABCD' ILIKE '_B_'→ 0\n•'ABCD' ILIKE '_b%'→ 1\n•'ABCD' ILIKE '_B%'→ 1\n•'ABCD' ILIKE '%b%'→ 1\n•'ABCD' ILIKE '%B%'→ 1\n•'ABCD%' ILIKE 'abcd\\\\%'→ 1\n•'ABCD' ILIKE '%B\\\\%'→ 0\nIN\nReturns 1 if value is found within a list of values.\nSyntaxa IN b\nArguments\n•a- value\n•b- list of values\nExamples\n•'A' IN ('A','B')→ 1\n•'A' IN ('C','B')→ 0\n306Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nIS\nReturns 1 if a is the same as b.\nSyntaxa IS b\nArguments\n•a- any value\n•b- any value\nExamples\n•'A' IS 'A'→ 1\n•'A' IS 'a'→ 0\n•4 IS 4→ 1\n•4 IS 2+2→ 1\n•4 IS 2→ 0\n•$geometry IS NULL→ 0, if your geometry is not NULL\nIS NOT\nReturns 1 if a is not the same as b.\nSyntaxa IS NOT b\nArguments\n•a- value\n•b- value\nExamples\n•'a' IS NOT 'b'→ 1\n•'a' IS NOT 'a'→ 0\n•4 IS NOT 2+2→ 0\nLIKE\nReturns 1 if the first parameter matches the supplied pattern. Works with numbers also.\nSyntaxstring/number LIKE pattern\nArguments\n•string/number- value\n•pattern- pattern to compare value with, you can use ‘%’ as a wildcard, ‘_’ as a single char\nand ‘\\\\’ to escape these special characters.\nExamples\n•'A' LIKE 'A'→ 1\n•'A' LIKE 'a'→ 0\n•'A' LIKE 'B'→ 0\n•'ABC' LIKE 'B'→ 0\n•'ABC' LIKE '_B_'→ 1\n•'ABCD' LIKE '_B_'→ 0\n•'ABCD' LIKE '_B%'→ 1\n•'ABCD' LIKE '%B%'→ 1\n•'1%' LIKE '1\\\\%'→ 1\n•'1_' LIKE '1\\\\%'→ 0\n12.2. List of functions307\n\nQGIS Desktop 3.22 User Guide\nNOT\nNegates a condition.\nSyntaxNOT a\nArguments\n•a- condition\nExamples\n•NOT 1→ 0\n•NOT 0→ 1\nOR\nReturns 1 when condition a or b is true.\nSyntaxa OR b\nArguments\n•a- condition\n•b- condition\nExamples\n•4 = 2+2 OR 1 = 1→ 1\n•4 = 2+2 OR 1 = 2→ 1\n•4 = 2 OR 1 = 2→ 0\n[]\nIndex operator. Returns an element from an array or map value.\nSyntax[index]\nArguments\n•index- array index or map key value\nExamples\n•array(1,2,3)[0]→ 1\n•array(1,2,3)[2]→ 3\n•array(1,2,3)[-1]→ 3\n•map('a',1,'b',2)['a']→ 1\n•map('a',1,'b',2)['b']→ 2\nFurther reading:array_get,map_get\n^\nPower of two values.\n308Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxa ^ b\nArguments\n•a- value\n•b- value\nExamples\n•5 ^ 4→ 625\n•5 ^ NULL→ NULL\n||\nJoins two values together into a string.\nIf one of the values is NULL the result will be NULL. See the CONCAT function for a different behavior.\nSyntaxa || b\nArguments\n•a- value\n•b- value\nExamples\n•'Here' || ' and ' || 'there'→ ‘Here and there’\n•'Nothing' || NULL→ NULL\n•'Dia: ' || \"Diameter\"→ ‘Dia: 25’\n•1 || 2→ ‘12’\nFurther reading:concat,+\n~\nPerforms a regular expression match on a string value. Backslash characters must be double escaped (e.g., “\\\\s” to\nmatch a white space character).\nSyntaxstring ~ regex\nArguments\n•string- A string value\n•regex- A regular expression. Slashes must be escaped, eg \\\\d.\nExamples\n•'hello' ~ 'll'→ 1\n•'hello' ~ '^ll'→ 0\n•'hello' ~ 'llo$'→ 1\n•'abc123' ~ '\\\\d+'→ 1\nFurther reading:regexp_match\n12.2. List of functions309\n\nQGIS Desktop 3.22 User Guide\n12.2.20Processing Functions\nThis group contains functions that operate on processing algorithms.\n•parameter\nparameter\nReturns the value of a processing algorithm input parameter.\nSyntaxparameter(name)\nArguments\n•name- name of the corresponding input parameter\nExamples\n•parameter('BUFFER_SIZE')→ 5.6\n12.2.21Rasters Functions\nThis group contains functions to operate on raster layer.\n•raster_statistic\n•raster_value\nraster_statistic\nReturns statistics from a raster layer.\nSyntaxraster_statistic(layer, band, property)\nArguments\n•layer- a string, representing either a raster layer name or layer ID\n•band- integer representing the band number from the raster layer, starting at 1\n•property- a string corresponding to the property to return. Valid options are:\n–min: minimum value\n–max: maximum value\n–avg: average (mean) value\n–stdev: standard deviation of values\n–range: range of values (max - min)\n–sum: sum of all values from raster\nExamples\n•raster_statistic('lc',1,'avg')→ Average value from band 1 from ‘lc’\nraster layer\n•raster_statistic('ac2010',3,'min')→ Minimum value from band3 from\n‘ac2010’ raster layer\n310Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nraster_value\nReturns the raster value found at the provided point.\nSyntaxraster_value(layer, band, point)\nArguments\n•layer- the name or id of a raster layer\n•band- the band number to sample the value from.\n•point- point geometry (for multipart geometries having more than one part, a NULL\nvalue will be returned)\nExamples\n•raster_value('dem', 1, make_point(1,1))→ 25\n12.2.22Record and Attributes Functions\nThis group contains functions that operate on record identifiers.\nattribute\nReturns an attribute from a feature.\nVariant 1\nReturns the value of an attribute from the current feature.\nSyntaxattribute(attribute_name)\nArguments\n•attribute_name- name of attribute to be returned\nExamples\n•attribute( 'name' )→ value stored in ‘name’ attribute for the current feature\nVariant 2\nAllows the target feature and attribute name to be specified.\nSyntaxattribute(feature, attribute_name)\nArguments\n•feature- a feature\n•attribute_name- name of attribute to be returned\nExamples\n•attribute( @atlas_feature, 'name' )→ value stored in ‘name’ attribute\nfor the current atlas feature\n12.2. List of functions311\n\nQGIS Desktop 3.22 User Guide\nattributes\nReturns a map containing all attributes from a feature, with field names as map keys.\nVariant 1\nReturns a map of all attributes from the current feature.\nSyntaxattributes()\nExamples\n•attributes()['name']→ value stored in ‘name’ attribute for the current feature\nVariant 2\nAllows the target feature to be specified.\nSyntaxattributes(feature)\nArguments\n•feature- a feature\nExamples\n•attributes( @atlas_feature )['name']→ value stored in ‘name’ attribute\nfor the current atlas feature\nFurther reading:Maps Functions\n$currentfeature\nReturns the current feature being evaluated. This can be used with the ‘attribute’ function to evaluate attribute values\nfrom the current feature.\nSyntax$currentfeature\nExamples\n•attribute( $currentfeature, 'name' )→ value stored in ‘name’ attribute\nfor the current feature\ndisplay_expression\nReturns the display expression for a given feature in a layer. The expression is evaluated by default. Can be used with\nzero, one or more arguments, see below for details.\nNo parameters\nIf called with no parameters, the function will evaluate the display expression of the current feature in the current\nlayer.\nSyntaxdisplay_expression()\nExamples\n•display_expression()→ The display expression of the current feature in the cur-\nrent layer.\nOne ‘feature’ parameter\nIf called with a ‘feature’ parameter only, the function will evaluate the specified feature from the current layer.\n312Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxdisplay_expression(feature)\nArguments\n•feature- The feature which should be evaluated.\nExamples\n•display_expression(@atlas_feature)→ The display expression of the cur-\nrent atlas feature.\nLayer and feature parameters\nIf the function is called with both a layer and a feature, it will evaluate the specified feature from the specified layer.\nSyntaxdisplay_expression(layer, feature, [evaluate=true])\n[] marks optional arguments\nArguments\n•layer- The layer (or its ID or name)\n•feature- The feature which should be evaluated.\n•evaluate- If the expression must be evaluated. If false, the expression will be returned as\na string literal only (which could potentially be later evaluated using the ‘eval’ function).\nExamples\n•display_expression( 'streets', get_feature_by_id('streets',\n1))→ The display expression of the feature with the ID 1 on the layer ‘streets’.\n•display_expression('a_layer_id', $currentfeature, 'False')\n→ The display expression of the given feature not evaluated.\nget_feature\nReturns the first feature of a layer matching a given attribute value.\nSyntaxget_feature(layer, attribute, value)\nArguments\n•layer- layer name or ID\n•attribute- attribute name\n•value- attribute value to match\nExamples\n•get_feature('streets','name','main  st')→ first feature found in\n“streets” layer with “main st” value in the “name” field\nget_feature_by_id\nReturns the feature with an id on a layer.\nSyntaxget_feature_by_id(layer, feature_id)\nArguments\n•layer- layer, layer name or layer id\n•feature_id- the id of the feature which should be returned\nExamples\n•get_feature_by_id('streets', 1)→ the feature with the id 1 on the layer\n“streets”\nFurther reading:$id\n12.2. List of functions313\n\nQGIS Desktop 3.22 User Guide\n$id\nReturns the feature id of the current row.\nSyntax$id\nExamples\n•$id→ 42\nis_selected\nReturns True if a feature is selected. Can be used with zero, one or two arguments, see below for details.\nNo parameters\nIf called with no parameters, the function will return true if the current feature in the current layer is selected.\nSyntaxis_selected()\nExamples\n•is_selected()→ True if the current feature in the current layer is selected.\nOne ‘feature’ parameter\nIf called with a ‘feature’ parameter only, the function returns true if the specified feature from the current layer is\nselected.\nSyntaxis_selected(feature)\nArguments\n•feature- The feature which should be checked for selection.\nExamples\n•is_selected(@atlas_feature)→ True if the current atlas feature is selected.\n•is_selected(get_feature('streets', 'name', 'Main St.')))→\nTrue if the unique named “Main St.” feature on the active “streets” layer is selected.\n•is_selected(get_feature_by_id('streets', 1))→ True if the feature\nwith the id 1 on the active “streets” layer is selected.\nTwo parameters\nIf the function is called with both a layer and a feature, it will return true if the specified feature from the specified\nlayer is selected.\nSyntaxis_selected(layer, feature)\nArguments\n•layer\n- The layer (its ID or name) on which the selection will be checked.\n•feature- The feature which should be checked for selection.\nExamples\n•is_selected(  'streets',  get_feature('streets',  'name',\n\"street_name\"))→ True if the current building’s street is selected (assuming the\nbuilding layer has a field named ‘street_name’ and the ‘streets’ layer has a field called ‘name’\nwith unique values).\n•is_selected( 'streets', get_feature_by_id('streets', 1))→\nTrue if the feature with the id 1 on the “streets” layer is selected.\n314Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nmaptip\nReturns the maptip for a given feature in a layer. The expression is evaluated by default. Can be used with zero, one\nor more arguments, see below for details.\nNo parameters\nIf called with no parameters, the function will evaluate the maptip of the current feature in the current layer.\nSyntaxmaptip()\nExamples\n•maptip()→ The maptip of the current feature in the current layer.\nOne ‘feature’ parameter\nIf called with a ‘feature’ parameter only, the function will evaluate the specified feature from the current layer.\nSyntaxmaptip(feature)\nArguments\n•feature- The feature which should be evaluated.\nExamples\n•maptip(@atlas_feature)→ The maptip of the current atlas feature.\nLayer and feature parameters\nIf the function is called with both a layer and a feature, it will evaluate the specified feature from the specified layer.\nSyntaxmaptip(layer, feature, [evaluate=true])\n[] marks optional arguments\nArguments\n•layer- The layer (or its ID or name)\n•feature- The feature which should be evaluated.\n•evaluate- If the expression must be evaluated. If false, the expression will be returned\nas a string literal only (which could potentially be later evaluated using the ‘eval_template’\nfunction).\nExamples\n•maptip('streets', get_feature_by_id('streets', 1))→ The map-\ntip of the feature with the ID 1 on the layer ‘streets’.\n•maptip('a_layer_id', $currentfeature, 'False')→ The maptip of\nthe given feature not evaluated.\nnum_selected\nReturns the number of selected features on a given layer. By default works on the layer on which the expression is\nevaluated.\nSyntaxnum_selected([layer=current layer])\n[] marks optional arguments\nArguments\n•layer- The layer (or its id or name) on which the selection will be checked.\nExamples\n•num_selected()→ The number of selected features on the current layer.\n•num_selected('streets')→ The number of selected features on the layer streets\n12.2. List of functions315\n\nQGIS Desktop 3.22 User Guide\nrepresent_value\nReturns the configured representation value for a field value. It depends on the configured widget type. Often, this is\nuseful for ‘Value Map’ widgets.\nSyntaxrepresent_value(value, fieldName)\nArguments\n•value- The value which should be resolved. Most likely a field.\n•fieldName- The field name for which the widget configuration should be loaded. (Op-\ntional)\nExamples\n•represent_value(\"field_with_value_map\")→ Description for value\n•represent_value('static value', 'field_name')→ Description for\nstatic value\nFurther reading:widget types\nsqlite_fetch_and_increment\nManage autoincrementing values in sqlite databases.\nSQlite default values can only be applied on insert and not prefetched.\nThis makes it impossible to acquire an incremented primary key via AUTO_INCREMENT before creating the row\nin the database. Sidenote: with postgres, this works via the optionevaluate default values.\nWhen adding new features with relations, it is really nice to be able to already add children for a parent, while the\nparents form is still open and hence the parent feature uncommitted.\nTo get around this limitation, this function can be used to manage sequence values in a separate table on sqlite based\nformats like gpkg.\nThe sequence table will be filtered for a sequence id (filter_attribute and filter_value) and the current value of the\nid_field will be incremented by 1 and the incremented value returned.\nIf additional columns require values to be specified, the default_values map can be used for this purpose.\nNote\nThis function modifies the target sqlite table. It is intended for usage with default value configurations for attributes.\nWhen the database parameter is a layer and the layer is in transaction mode, the value will only be retrieved once\nduring the lifetime of a transaction and cached and incremented. This makes it unsafe to work on the same database\nfrom several processes in parallel.\n316Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nSyntaxsqlite_fetch_and_increment(database,  table,  id_field,  filter_attribute,  filter_value,  [de-\nfault_values])\n[] marks optional arguments\nArguments\n•database- Path to the sqlite file or geopackage layer\n•table- Name of the table that manages the sequences\n•id_field- Name of the field that contains the current value\n•filter_attribute- Name the field that contains a unique identifier for this sequence. Must\nhave a UNIQUE index.\n•filter_value- Name of the sequence to use.\n•default_values- Map with default values for additional columns on the table. The values\nneed to be fully quoted. Functions are allowed.\nExamples\n•sqlite_fetch_and_increment(@layer,'sequence_table',\n'last_unique_id','sequence_id','global',\nmap('last_change',   'date(''now'')',   'user',   ''''   ||\n@user_account_name || ''''))→ 0\n•sqlite_fetch_and_increment(layer_property(@layer, 'path'),\n'sequence_table',     'last_unique_id',     'sequence_id',\n'global',   map('last_change',   'date(''now'')',   'user',\n'''' || @user_account_name || ''''))→ 0\nFurther reading:Data Sources Properties,Creating one or many to many relations\nuuid\nGenerates a Universally Unique Identifier (UUID) for each row using the QtQUuid::createUuidmethod.\nSyntaxuuid([format=’WithBraces’])\n[] marks optional arguments\nArguments\n•format- The format, as the UUID will be formatted. ‘WithBraces’, ‘WithoutBraces’ or\n‘Id128’.\nExamples\n•uuid()→ ‘{0bd2f60f-f157-4a6d-96af-d4ba4cb366a1}’\n•uuid('WithoutBraces')→ ‘0bd2f60f-f157-4a6d-96af-d4ba4cb366a1’\n•uuid('Id128')→ ‘0bd2f60ff1574a6d96afd4ba4cb366a1’\n12.2. List of functions317\n\nQGIS Desktop 3.22 User Guide\n12.2.23Relations\nThis group contains the list of therelationsavailable in the current project, with their description. It provides a quick\naccess to the relation ID for writing an expression (with e.g. therelation_aggregatefunction) or customizing a form.\n12.2.24String Functions\nThis group contains functions that operate on strings (e.g., that replace, convert to upper case).\nascii\nReturns the unicode code associated with the first character of a string.\nSyntaxascii(string)\nArguments\n•string- the string to convert to unicode code\nExamples\n•ascii('Q')→ 81\nchar\nReturns the character associated with a unicode code.\nSyntaxchar(code)\nArguments\n•code- a unicode code number\nExamples\n•char(81)→ ‘Q’\nconcat\nConcatenates several strings to one. NULL values are converted to empty strings. Other values (like numbers) are\nconverted to strings.\nSyntaxconcat(string1, string2, ...)\nArguments\n•string- a string value\nExamples\n•concat('sun', 'set')→ ‘sunset’\n•concat('a','b','c','d','e')→ ‘abcde’\n•concat('Anno ', 1984)→ ‘Anno 1984’\n•concat('The Wall', NULL)→ ‘The Wall’\nAbout fields concatenation\nYou can also concatenate strings or field values using either||or+operators, with some special characteristics:\n•The+operator also means sum up expression, so if you have an integer (field or numeric value) operand, this\ncan be error prone and you better use the others:\n318Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\n'My feature id is:'+\"gid\"=>triggers an errorasgid returns an integer\n•When any of the arguments is a NULL value, either||or+will return a NULL value. To return the other\narguments regardless the NULL value, you may want to use theconcatfunction:\n'My feature id is:'+NULL==>NULL\n'My feature id is:'||NULL=>NULL\nconcat('My feature id is:', NULL)=>'My feature id is:'\nfurther reading:||,+\nformat\nFormat a string using supplied arguments.\nSyntaxformat(string, arg1, arg2, ...)\nArguments\n•string- A string with placeholders %1, %2, etc., for the arguments. Placeholders can be\nrepeated. The lowest numbered placeholder is replaced by arg1, the next by arg2, etc.\n•arg- any type. Any number of arguments.\nExamples\n•format('This %1 a %2','is', 'test')→ ‘This is a test’\n•format('This is %2','a bit unexpected but 2 is lowest number\nin string','normal')→ ‘This is a bit unexpected but 2 is lowest number in string’\nformat_date\nFormats a date type or string into a custom string format. Uses Qt date/time format strings. SeeQDateTime::toString.\n12.2. List of functions319\n\nQGIS Desktop 3.22 User Guide\nSyntaxformat_date(datetime, format, [language])\n[] marks optional arguments\nArguments\n•datetime- date, time or datetime value\n•format- String template used to format the string.\nExpressionOutput\ndthe day as number without a leading zero (1 to 31)\nddthe day as number with a leading zero (01 to 31)\ndddthe abbreviated localized day name (e.g. ‘Mon’ to ‘Sun’)\nddddthe long localized day name (e.g. ‘Monday’ to ‘Sunday’)\nMthe month as number without a leading zero (1-12)\nMMthe month as number with a leading zero (01-12)\nMMMthe abbreviated localized month name (e.g. ‘Jan’ to ‘Dec’)\nMMMMthe long localized month name (e.g. ‘January’ to ‘December’)\nyythe year as two digit number (00-99)\nyyyythe year as four digit number\nThese expressions may be used for the time part of the format string:\nExpressionOutput\nhthe hour without a leading zero (0 to 23 or 1 to 12 if AM/PM display)\nhhthe hour with a leading zero (00 to 23 or 01 to 12 if AM/PM display)\nHthe hour without a leading zero (0 to 23, even with AM/PM display)\nHHthe hour with a leading zero (00 to 23, even with AM/PM display)\nmthe minute without a leading zero (0 to 59)\nmmthe minute with a leading zero (00 to 59)\nsthe second without a leading zero (0 to 59)\nssthe second with a leading zero (00 to 59)\nzthe milliseconds without trailing zeroes (0 to 999)\nzzzthe milliseconds with trailing zeroes (000 to 999)\nAP or Ainterpret as an AM/PM time.APmust be either ‘AM’ or ‘PM’.\nap or aInterpret as an AM/PM time.apmust be either ‘am’ or ‘pm’.\n•language- language (lowercase, two- or three-letter,ISO 639 language code) used to\nformat the date into a custom string. By default the current QGIS user locale is used.\nExamples\n•format_date('2012-05-15','dd.MM.yyyy')→ ‘15.05.2012’\n•format_date('2012-05-15','d MMMM yyyy','fr')→ ‘15 mai 2012’\n•format_date('2012-05-15','dddd')→ ‘Tuesday’, if the current locale is an\nEnglish variant\n•format_date('2012-05-15 13:54:20','dd.MM.yy')→ ‘15.05.12’\n•format_date('13:54:20','hh:mm AP')→ ‘01:54 PM’\n320Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nformat_number\nReturns a number formatted with the locale separator for thousands. By default the current QGIS user locale is used.\nAlso truncates the decimal places to the number of supplied places.\nSyntaxformat_number(number, [places=0], [language])\n[] marks optional arguments\nArguments\n•number- number to be formatted\n•places- integer representing the number of decimal places to truncate the string to.\n•language- language (lowercase, two- or three-letter,ISO 639 language code) used to\nformat the number into a string. By default the current QGIS user locale is used.\nExamples\n•format_number(10000000.332,2)→ ‘10,000,000.33’ if e.g. the current locale\nis an English variant\n•format_number(10000000.332,2,'fr')→ ‘10 000 000,33’\nleft\nReturns a substring that contains thenleftmost characters of the string.\nSyntaxleft(string, length)\nArguments\n•string- a string\n•length- integer. The number of characters from the left of the string to return.\nExamples\n•left('Hello World',5)→ ‘Hello’\nlength\nReturns the number of characters in a string or the length of a geometry linestring.\nString variant\nReturns the number of characters in a string.\nSyntaxlength(string)\nArguments\n•string- string to count length of\nExamples\n•length('hello')→ 5\nGeometry variant\nCalculate the length of a geometry line object. Calculations are always planimetric in the Spatial Reference System\n(SRS) of this geometry, and the units of the returned length will match the units for the SRS. This differs from the\ncalculations performed by the $length function, which will perform ellipsoidal calculations based on the project’s\nellipsoid and distance unit settings.\n12.2. List of functions321\n\nQGIS Desktop 3.22 User Guide\nSyntaxlength(geometry)\nArguments\n•geometry- line geometry object\nExamples\n•length(geom_from_wkt('LINESTRING(0 0, 4 0)'))→ 4.0\nlower\nConverts a string to lower case letters.\nSyntaxlower(string)\nArguments\n•string- the string to convert to lower case\nExamples\n•lower('HELLO World')→ ‘hello world’\nlpad\nReturns a string padded on the left to the specified width, using a fill character. If the target width is smaller than the\nstring’s length, the string is truncated.\nSyntaxlpad(string, width, fill)\nArguments\n•string- string to pad\n•width- length of new string\n•fill- character to pad the remaining space with\nExamples\n•lpad('Hello', 10, 'x')→ ‘xxxxxHello’\n•lpad('Hello', 3, 'x')→ ‘Hel’\nregexp_match\nReturn the first matching position matching a regular expression within an unicode string, or 0 if the substring is not\nfound.\nSyntaxregexp_match(input_string, regex)\nArguments\n•input_string- the string to test against the regular expression\n•regex- The regular expression to test against. Backslash characters must be double es-\ncaped (e.g., “\\\\s” to match a white space character or “\\\\b” to match a word boundary).\nExamples\n•regexp_match('QGIS ROCKS','\\\\sROCKS')→ 5\n•regexp_match('Budač','udač\\\\b')→ 2\n322Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nregexp_replace\nReturns a string with the supplied regular expression replaced.\nSyntaxregexp_replace(input_string, regex, replacement)\nArguments\n•input_string- the string to replace matches in\n•regex- The regular expression to replace. Backslash characters must be double escaped\n(e.g., “\\\\s” to match a white space character).\n•replacement- The string that will replace any matching occurrences of the supplied reg-\nular expression. Captured groups can be inserted into the replacement string using \\\\1,\n\\\\2, etc.\nExamples\n•regexp_replace('QGIS SHOULD ROCK','\\\\sSHOULD\\\\s',' DOES ')\n→ ‘QGIS DOES ROCK’\n•regexp_replace('ABC123','\\\\d+','')→ ‘ABC’\n•regexp_replace('my name is John','(.*) is (.*)','\\\\2 is \\\\\n1')→ ‘John is my name’\nregexp_substr\nReturns the portion of a string which matches a supplied regular expression.\nSyntaxregexp_substr(input_string, regex)\nArguments\n•input_string- the string to find matches in\n•regex- The regular expression to match against. Backslash characters must be double\nescaped (e.g., “\\\\s” to match a white space character).\nExamples\n•regexp_substr('abc123','(\\\\d+)')→ ‘123’\nreplace\nReturns a string with the supplied string, array, or map of strings replaced.\nString & array variant\nReturns a string with the supplied string or array of strings replaced by a string or an array of strings.\nSyntaxreplace(string, before, after)\nArguments\n•string- the input string\n•before- the string or array of strings to replace\n•after- the string or array of strings to use as a replacement\nExamples\n•replace('QGIS  SHOULD  ROCK','SHOULD','DOES')→ ‘QGIS DOES\nROCK’\n•replace('QGIS  ABC',array('A','B','C'),array('X','Y','Z'))\n→ ‘QGIS XYZ’\n•replace('QGIS',array('Q','S'),'')→ ‘GI’\nMap variant\n12.2. List of functions323\n\nQGIS Desktop 3.22 User Guide\nReturns a string with the supplied map keys replaced by paired values. Longer map keys are evaluated first.\nSyntaxreplace(string, map)\nArguments\n•string- the input string\n•map- the map containing keys and values\nExamples\n•replace('APP    SHOULD    ROCK',map('APP','QGIS','SHOULD',\n'DOES'))→ ‘QGIS DOES ROCK’\n•replace('forty  two',map('for','4','two','2','forty  two',\n'42'))→ ‘42’\nright\nReturns a substring that contains thenrightmost characters of the string.\nSyntaxright(string, length)\nArguments\n•string- a string\n•length- integer. The number of characters from the right of the string to return.\nExamples\n•right('Hello World',5)→ ‘World’\nrpad\nReturns a string padded on the right to the specified width, using a fill character. If the target width is smaller than\nthe string’s length, the string is truncated.\nSyntaxrpad(string, width, fill)\nArguments\n•string- string to pad\n•width- length of new string\n•fill- character to pad the remaining space with\nExamples\n•rpad('Hello', 10, 'x')→ ‘Helloxxxxx’\n•rpad('Hello', 3, 'x')→ ‘Hel’\nstrpos\nReturn the first matching position of a substring within another string, or 0 if the substring is not found.\nSyntaxstrpos(haystack, needle)\nArguments\n•haystack- string that is to be searched\n•needle- string to search for\nExamples\n•strpos('HELLO WORLD','WORLD')→ 7\n•strpos('HELLO WORLD','GOODBYE')→ 0\n324Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nsubstr\nReturns a part of a string.\nSyntaxsubstr(string, start, [length])\n[] marks optional arguments\nArguments\n•string- the full input string\n•start- integer representing start position to extract beginning with 1; if start is negative,\nthe return string will begin at the end of the string minus the start value\n•length- integer representing length of string to extract; if length is negative, the return\nstring will omit the given length of characters from the end of the string\nExamples\n•substr('HELLO WORLD',3,5)→ ‘LLO W’\n•substr('HELLO WORLD',6)→ ‘ WORLD’\n•substr('HELLO WORLD',-5)→ ‘WORLD’\n•substr('HELLO',3,-1)→ ‘LL’\n•substr('HELLO WORLD',-5,2)→ ‘WO’\n•substr('HELLO WORLD',-5,-1)→ ‘WORL’\ntitle\nConverts all words of a string to title case (all words lower case with leading capital letter).\nSyntaxtitle(string)\nArguments\n•string- the string to convert to title case\nExamples\n•title('hello WOrld')→ ‘Hello World’\nto_string\nConverts a number to string.\nSyntaxto_string(number)\nArguments\n•number- Integer or real value. The number to convert to string.\nExamples\n•to_string(123)→ ‘123’\ntrim\nRemoves all leading and trailing whitespace (spaces, tabs, etc) from a string.\nSyntaxtrim(string)\nArguments\n•string- string to trim\nExamples\n•trim(' hello world ')→ ‘hello world’\n12.2. List of functions325\n\nQGIS Desktop 3.22 User Guide\nupper\nConverts a string to upper case letters.\nSyntaxupper(string)\nArguments\n•string- the string to convert to upper case\nExamples\n•upper('hello WOrld')→ ‘HELLO WORLD’\nwordwrap\nReturns a string wrapped to a maximum/minimum number of characters.\nSyntaxwordwrap(string, wrap_length, [delimiter_string])\n[] marks optional arguments\nArguments\n•string- the string to be wrapped\n•wrap_length- an integer. If wrap_length is positive the number represents the ideal\nmaximum number of characters to wrap; if negative, the number represents the minimum\nnumber of characters to wrap.\n•delimiter_string- Optional delimiter string to wrap to a new line.\nExamples\n•wordwrap('UNIVERSITY OF QGIS',13)→ ‘UNIVERSITY OF<br>QGIS’\n•wordwrap('UNIVERSITY OF QGIS',-3)→ ‘UNIVERSITY<br>OF QGIS’\n12.2.25User Expressions\nThis group contains the expressions saved asuser expressions.\n12.2.26Variables\nThis group contains dynamic variables related to the application, the project file and other settings. The availability\nof variables depends on the context:\n•from the\nSelect by expression\ndialog\n•from the\nField calculator\ndialog\n•from the layer properties dialog\n•from the print layout\nTo use these variables in an expression, they should be preceded by the@character (e.g,@row_number).\nVariableDescription\nalgorithm_idThe unique ID of an algorithm\nanimation_end_timeEnd of the animation’s overall temporal time range (as a datetime value)\nanimation_intervalDuration of the animation’s overall temporal time range (as an interval value)\nanimation_start_timeStart of the animation’s overall temporal time range (as a datetime value)\natlas_featureThe current atlas feature (as feature object)\natlas_featureidThe current atlas feature ID\ncontinues on next page\n326Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nTable 12.1 – continued from previous page\nVariableDescription\natlas_featurenumberThe current atlas feature number in the layout\natlas_filenameThe current atlas file name\natlas_geometryThe current atlas feature geometry\natlas_layeridThe current atlas coverage layer ID\natlas_layernameThe current atlas coverage layer name\natlas_pagenameThe current atlas page name\natlas_totalfeaturesThe total number of features in atlas\ncanvas_cursor_pointThe last cursor position on the canvas in the project’s geographical coordinates\ncluster_colorThe color of symbols within a cluster, or NULL if symbols have mixed colors\ncluster_sizeThe number of symbols contained within a cluster\ncurrent_featureThe feature currently being edited in the attribute form or table row\ncurrent_geometryThe geometry of the feature currently being edited in the form or the table row\ncurrent_parent_featurerepresents the feature currently being edited in the parent form. Only usable in an\nembedded form context.\ncurrent_parent_geometryrepresents the geometry of the feature currently being edited in the parent form.\nOnly usable in an embedded form context.\nform_modeWhat the form is used for, like AddFeatureMode, SingleEditMode, MultiEdit-\nMode, SearchMode, AggregateSearchMode or IdentifyMode as string.\nframe_durationTemporal duration of each animation frame (as an interval value)\nframe_numberCurrent frame number during animation playback\nframe_rateNumber of frames per second during animation playback\nfullextent_maxxMaximum x value from full canvas extent (including all layers)\nfullextent_maxyMaximum y value from full canvas extent (including all layers)\nfullextent_minxMinimum x value from full canvas extent (including all layers)\nfullextent_minyMinimum y value from full canvas extent (including all layers)\ngeometry_part_countThe number of parts in rendered feature’s geometry\ngeometry_part_numThe current geometry part number for feature being rendered\ngeometry_point_countThe number of points in the rendered geometry’s part\ngeometry_point_numThe current point number in the rendered geometry’s part\ngeometry_ring_numCurrent geometry ring number for feature being rendered (for polygon features\nonly). The exterior ring has a value of 0.\ngrid_axisThe current grid annotation axis (eg, ‘x’ for longitude, ‘y’ for latitude)\ngrid_numberThe current grid annotation value\nitem_idThe layout item user ID (not necessarily unique)\nitem_uuidThe layout item unique ID\nlayerThe current layer\nlayer_crsNEW in 3.18The Coordinate Reference System Authority ID of the current layer\nlayer_idThe ID of current layer\nlayer_idsThe IDs of all the map layers in the current project as a list\nlayer_nameThe name of current layer\nlayersAll the map layers in the current project as a list\nlayout_dpiThe composition resolution (DPI)\nlayout_nameThe layout name\nlayout_numpagesThe number of pages in the layout\nlayout_pageThe page number of the current item in the layout\nlayout_pageheightThe active page height in the layout (in mm for standard paper sizes, or whatever\nunit was used for custom paper size)\nlayout_pageoffsetsArray of Y coordinate of the top of each page. Allows to dynamically position\nitems on pages in a context where page sizes may change\nlayout_pagewidthThe active page width in the layout (in mm for standard paper sizes, or whatever\nunit was used for custom paper size)\nlegend_column_countThe number of columns in the legend\nlegend_filter_by_mapIndicates if the content of the legend is filtered by the map\nlegend_filter_out_atlasIndicates if the atlas is filtered out of the legend\ncontinues on next page\n12.2. List of functions327\n\nQGIS Desktop 3.22 User Guide\nTable 12.1 – continued from previous page\nVariableDescription\nlegend_split_layersIndicates if layers can be split in the legend\nlegend_titleThe title of the legend\nlegend_wrap_stringThe character(s) used to wrap the legend text\nmap_crsThe Coordinate reference system of the current map\nmap_crs_acronymThe acronym of the Coordinate reference system of the current map\nmap_crs_definitionThe full definition of the Coordinate reference system of the current map\nmap_crs_descriptionThe name of the Coordinate reference system of the current map\nmap_crs_ellipsoidThe acronym of the ellipsoid of the Coordinate reference system of the current map\nmap_crs_proj4The Proj4 definition of the Coordinate reference system of the current map\nmap_crs_projectionNEW\nin 3.20\nThe descriptive name of the projection method used by the Coordinate reference\nsystem of the map (e.g. ‘Albers Equal Area’)\nmap_crs_wktThe WKT definition of the Coordinate reference system of the current map\nmap_end_timeThe end of the map’s temporal time range (as a datetime value)\nmap_extentThe geometry representing the current extent of the map\nmap_extent_centerThe point feature at the center of the map\nmap_extent_heightThe current height of the map\nmap_extent_widthThe current width of the map\nmap_idThe ID of current map destination. This will be ‘canvas’ for canvas renders, and the\nitem ID for layout map renders\nmap_intervalThe duration of the map’s temporal time range (as an interval value)\nmap_layer_idsThe list of map layer IDs visible in the map\nmap_layersThe list of map layers visible in the map\nmap_rotationThe current rotation of the map\nmap_scaleThe current scale of the map\nmap_start_timeThe start of the map’s temporal time range (as a datetime value)\nmap_unitsThe units of map measurements\nmodel_pathFull path (including file name) of current model (or project path if model is em-\nbedded in a project).\nmodel_folderFolder containing current model (or project folder if model is embedded in a\nproject).\nmodel_nameName of current model\nmodel_groupGroup for current model\nnotification_messageContent of the notification message sent by the provider (available only for actions\ntriggered by provider notifications).\nparentRefers to the current feature in the parent layer, providing access to its attributes\nand geometry when filtering anaggregatefunction\nproject_abstractThe project abstract, taken from project metadata\nproject_area_unitsThe area unit for the current project, used when calculating areas of geometries\nproject_authorThe project author, taken from project metadata\nproject_basenameThe basename of current project’s filename (without path and extension)\nproject_creation_dateThe project creation date, taken from project metadata\nproject_crsThe Coordinate reference system of the project\nproject_crs_arconymThe acronym of the Coordinate reference system of the project\nproject_crs_definitionThe full definition of the Coordinate reference system of the project\nproject_crs_descriptionThe description of the Coordinate reference system of the project\nproject_crs_ellipsoidThe ellipsoid of the Coordinate reference system of the project\nproject_crs_proj4The Proj4 representation of the Coordinate reference system of the project\nproject_crs_wktThe WKT (well known text) representation of the coordinate reference system of\nthe project\nproject_distance_unitsThe distance unit for the current project, used when calculating lengths of geome-\ntries and distances\nproject_ellipsoidThe name of the ellipsoid of the current project, used when calculating geodetic\nareas or lengths of geometries\nproject_filenameThe filename of the current project\ncontinues on next page\n328Chapter 12. Level up with Expressions\n\nQGIS Desktop 3.22 User Guide\nTable 12.1 – continued from previous page\nVariableDescription\nproject_folderThe folder of the current project\nproject_homeThe home path of the current project\nproject_identifierThe project identifier, taken from the project’s metadata\nproject_keywordsThe project keywords, taken from the project’s metadata\nproject_last_savedDate/time when project was last saved.\nproject_pathThe full path (including file name) of the current project\nproject_titleThe title of current project\nproject_unitsThe units of the project’s CRS\nqgis_localeThe current language of QGIS\nqgis_os_nameThe current Operating system name, eg ‘windows’, ‘linux’ or ‘osx’\nqgis_platformThe QGIS platform, eg ‘desktop’ or ‘server’\nqgis_release_nameThe current QGIS release name\nqgis_short_versionThe current QGIS version short string\nqgis_versionThe current QGIS version string\nqgis_version_noThe current QGIS version number\nrow_numberStores the number of the current row\nsnapping_resultsGives access to snapping results while digitizing a feature (only available in add\nfeature)\nscale_valueThe current scale bar distance value\nselected_file_pathSelected file path from file widget selector when uploading a file with an external\nstorage system\nsymbol_angleThe angle of the symbol used to render the feature (valid for marker symbols only)\nsymbol_colorThe color of the symbol used to render the feature\nsymbol_countThe number of features represented by the symbol (in the layout legend)\nsymbol_idThe Internal ID of the symbol (in the layout legend)\nsymbol_labelThe label for the symbol (either a user defined label or the default autogenerated\nlabel - in the layout legend)\nsymbol_layer_countTotal number of symbol layers in the symbol\nsymbol_layer_indexCurrent symbol layer index\nsymbol_marker_columnColumn number for marker (valid for point pattern fills only).\nsymbol_marker_rowRow number for marker (valid for point pattern fills only).\nuser_account_nameThe current user’s operating system account name\nuser_full_nameThe current user’s operating system user name\nvalueThe current value\nvector_tile_zoomExact vector tile zoom level of the map that is being rendered (derived from the\ncurrent map scale). Normally in interval [0, 20]. Unlike @zoom_level, this variable\nis a floating point value which can be used to interpolate values between two integer\nzoom levels.\nwith_variableAllows setting a variable for usage within an expression and avoid recalculating the\nsame value repeatedly\nzoom_levelVector tile zoom level of the map that is being rendered (derived from the current\nmap scale). Normally in interval [0, 20].\nSome examples:\n•Return the X coordinate of a map item center in layout:\nx( map_get( item_variables('map1'),'map_extent_center') )\n•Return, for each feature in the current layer, the number of overlapping airport features:\naggregate( layer:='airport', aggregate:='count', expression:=\"code\",\nfilter:=intersects( $geometry, geometry( @parent ) ) )\n•Get the object_id of the first snapped point of a line:\n12.2. List of functions329\n\nQGIS Desktop 3.22 User Guide\nwith_variable(\n'first_snapped_point',\narray_first(@snapping_results),\nattribute(\nget_feature_by_id(\nmap_get(@first_snapped_point,'layer'),\nmap_get(@first_snapped_point,'feature_id')\n),\n'object_id'\n)\n)\n12.2.27Recent Functions\nThis group contains recently used functions. Depending on the context of its usage (feature selection, field calculator,\ngeneric), recently applied expressions are added to the corresponding list (up to ten expressions), sorted from more\nto less recent. This makes it easy to quickly retrieve and reapply previously used expressions.\n330Chapter 12. Level up with Expressions\n\nCHAPTER\nTHIRTEEN\nTHE STYLE LIBRARY\n13.1The Style Manager\n13.1.1The Style Manager dialog\nTheStyle Manageris the place where you can manage and create generic style items. These are symbols, color ramps,\ntext formats or label settings that can be used to symbolize features, layers or print layouts. They are stored in the\nsymbology-style.dbdatabase under the active\nuser profileand shared with all the project files opened with\nthat profile. Style items can also be shared with others thanks to the export/import capabilities of theStyle Manager\ndialog.\nYou can open that modeless dialog either:\n•from theSettings►Style Manager...menu\n•with the\nStyle Manager\nbutton from the Project toolbar\n•or with the\nStyle Manager\nbutton from a vectorLayer Properties► menu (while\nconfiguring a symbolor\nformatting a text).\nFig. 13.1: The Style Manager\n331\n\nQGIS Desktop 3.22 User Guide\nOrganizing style items\nTheStyle Managerdialog displays in its center a frame with previewed items organized into tabs:\n•Allfor a complete collection of point, linear and surface symbols and label settings as well as predefined color\nramps and text formats;\n•Markerfor point symbols only;\n•Linefor linear symbols only;\n•Fillfor surface symbols only;\n•Color ramp;\n•Text formatto managetext formats, which store the font, color, buffers, shadows, and backgrounds of texts\n(i.e. all the formatting parts of the label settings, which for instance can be used in layouts);\n•Label settingsto managelabel settings, which include the text formats and some layer-type specific settings\nsuch as label placement, priority, callouts, rendering...\n•Legend Patch Shapesto manage custom legend patch shapes, which includeMarker,LineandFillgeome-\ntries.\n•3D Symbolsto configure symbols with3D properties(extrusion, shading, altitude, ...) for the features to\nrender in a3D Map view\nYou can arrange the Styles inIcon Viewor inList Viewon the bottom right side. In both views the tooltip\nshows a larger instance of the style.\nFor each family of items, you can organize the elements into different categories, listed in the panel on the left:\n•Favorites: displayed by default when configuring an item, it shows an extensible set of items;\n•All: lists all the available items for the active type;\n•Tags: shows a list of labels you can use to identify the items. An item can be tagged more than once. Select a\ntag in the list and the tabs are updated to show only their items that belong to it. To create a new tag you could\nlater attach to a set of items, use theAdd Tag...button or select theAdd Tag...from any tag contextual\nmenu;\n•Smart Group: a smart group dynamically fetches its symbols according to conditions set (see eg,Fig. 13.2).\nClick theAdd Smart Group...button to create smart groups. The dialog box allows you to enter an expression\nto filter the items to select (has a particular tag, have a string in its name, etc.). Any symbol, color ramp, text\nformat or label setting that satisfies the entered condition(s) is automatically added to the smart group.\nFig. 13.2: Creating a Smart Group\nTags and smart groups are not mutually exclusive: they are simply two different ways to organize your style elements.\nUnlike the smart groups that automatically fetch their belonged items based on the input constraints, tags are filled\n332Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nby the user. To edit any of those categories, you can either:\n•select the items, right-click and chooseAdd to Tag► and then select the tag name or create a new tag;\n•select the tag and pressModify group...►Attach Selected Tag to Symbols. A checkbox appears next to each\nitem to help you select or deselect it. When selection is finished, pressModify group...►Finish Tagging.\n•select the smart group, pressModify group...►Edit smart group...and configure a new set of constraints in\ntheSmart Group Editordialog. This option is also available in the contextual menu of the smart group.\nTo remove a tag or a smart group, right-click on it and select theRemovebutton. Note that this does not delete\nthe items grouped in the category.\nAdding, editing or removing an item\nAs seen earlier, style elements are listed under different tabs whose contents depend on the active category (tag, smart\ngroup, favorites...). When a tab is enabled, you can:\n•Add new items: press the\nAdd item\nbutton and configure the item followingsymbols,color rampsortext\nformat and labelbuilder description.\n•Modify an existing item: select an item and press\nEdit item\nbutton and configure as mentioned above.\n•Delete existing items: to delete an element you no longer need, select it and click\nRemove item\n(also available\nthrough right-click). The item will be deleted from the local database.\nNote that theAlltab provides access to these options for every type of item.\nRight-clicking over a selection of items also allows you to:\n•Add to Favorites;\n•Remove from Favorites;\n•Add to Tag► and select the appropriate tag or create a new one to use; the currently assigned tags are checked;\n•Clear Tags: detaching the symbols from any tag;\n•Remove Item(s);\n•Edit Item: applies to the item you right-click over;\n•Copy Item;\n•Paste Item ...: pasting to one of the categories of the style manager or elsewhere in QGIS (symbol or color\nbuttons)\n•Export Selected Symbol(s) as PNG...(only available with symbols);\n•Export Selected Symbol(s) as SVG...(only available with symbols);\nSharing style items\nTheImport/Exporttool, at the left bottom of the Style Manager dialog, offers options to easily share symbols,\ncolor ramps, text formats and label settings with others. These options are also available through right-click over the\nitems.\n13.1. The Style Manager333\n\nQGIS Desktop 3.22 User Guide\nExporting items\nYou can export a set of items to an.XMLfile:\n1.Expand theImport/Exportdrop-down menu and selectExport Item(s)...\n2.Choose the items you’d like to integrate. Selection can be done with the mouse or using a tag or a group\npreviously set.\n3.PressExportwhen ready. You’ll be prompted to indicate the destination of the saved file. The XML format\ngenerates a single file containing all the selected items. This file can then be imported in another user’s style\nlibrary.\nFig. 13.3: Exporting style items\nWhen symbols are selected, you can also export them to.PNGor.SVG. Exporting to.PNGor.SVG(both not\navailable for other style item types) creates a file for each selected symbol in a given folder. The SVG folder can be\nadded to theSVG pathsinSettings►Options►Systemmenu of another user, allowing him direct access to all these\nsymbols.\nImporting items\nYou can extend your style library by importing new items:\n1.Expand theImport/Exportdrop-down menu and selectImport Item(s)at the left bottom of the dialog.\n2.In the new dialog, indicate the source of the style items (it can be an.xmlfile on the disk or a url).\n3.Set whether toAdd to favoritesthe items to import.\n4.CheckDo not import embedded tagsto avoid the import of tags associated to the items being imported.\n5.Give the name of anyAdditional tag(s)to apply to the new items.\n334Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n6.Select from the preview the symbols you want to add to your library.\n7.And pressImport.\nFig. 13.4: Importing style items\nUsing the Browser panel\nIt’s also possible to import style items into the active user profile style database directly from theBrowserpanel:\n1.Select the style.xmlfile in the browser\n2.Drag-and-drop it over the map canvas or right-click and selectImport Style...\n3.Fill theImport Itemsdialog followingImporting items\n4.PressImportand the selected style items are added to the style database\nDouble-clicking the style file in the browser opens theStyle Managerdialog showing the items in the file. You can\nselect them and pressCopy to Default Style...to import them into the active style database. Tags can be assigned to\nitems. Also available through right-click,Open Style...command.\nFig. 13.5: Opening a style items file\n13.1. The Style Manager335\n\nQGIS Desktop 3.22 User Guide\nThe dialog also allows to export single symbols as.PNGor.SVGfiles.\nUsing the online repository\nThe QGIS project maintains a repository with a collection of styles shared by QGIS users. This is available at\nhttps://plugins.qgis.org/stylesand can be accessed from theStyle Managerdialog, pressing theBrowse Online\nStylesbutton at the bottom.\nFrom that repository, you can:\n1.Browse and search for any style items, based on their type or name\n2.Download the style file and unzip it\n3.Load the.xmlbased file into your style database in QGIS, using any of the aforementioned import methods.\n13.1.2Setting a Color Ramp\nThe Color ramp tab in theStyle Managerdialog helps you preview different color ramps based on the category selected\nin the left panel.\nTo create a custom color ramp, activate the Color ramp tab and click the\nAdd item\nbutton. The button reveals a\ndrop-down list to choose the ramp type:\n•Gradient: given a start and end colors, generate a color ramp which can becontinuousordiscrete. With\ndouble-clicking the ramp preview, you can add as many intermediate color stops as you want.\n336Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nFig. 13.6: Example of custom gradient color ramp with multiple stops\n•Color presets: allows to create a color ramp consisting of a list of colors selected by the user;\n•Random: creates a random set of colors based on range of values forHue,Saturation,ValueandOpacityand\na number of colors (Classes);\n•Catalog: ColorBrewer: a set of predefined discrete color gradients you can customize the number of colors in\nthe ramp;\n•orCatalog: cpt-city: an access to a whole catalog of color gradients to locallysave as standard gradient. The\ncpt-city option opens a new dialog with hundreds of themes included ‘out of the box’.\n13.1. The Style Manager337\n\nQGIS Desktop 3.22 User Guide\nFig. 13.7: cpt-city dialog with hundreds of color ramps\nTip: Easily adjust the color stops of the gradient color ramp\nDouble-clicking the ramp preview or drag-and-drop a color from the color spot onto the ramp preview adds a new\ncolor stop. Each color stop can be tweaked using theColor Selectorwidgets or by plotting each of its parameters. You\ncan also reposition it using the mouse, the arrow keys (combine withShiftkey for a larger move) or theRelative\npositionspinbox. PressingDelete stopas well asDELkey removes the selected color stop.\n13.1.3Creating a Legend Patch Shape\nTo create a new Legend Patch Shape, activate theLegend Patch Shapestab and click the\nAdd item\nbutton. The\nbutton reveals a drop-down list to choose the geometry type:\n•Marker Legend Patch Shape...: to use with point geometries.\n•Line Legend Patch Shape...: to use with line geometries.\n•Fill Legend Patch Shape...: to use with polygon geometries.\nAll three options will show the same dialog.\n338Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nFig. 13.8: Create a new Legend Patch Shape\nOnly the shape type and displayed legend patch shapes will differ regarding to the chosen geometry type. The fol-\nlowing options will be available:\n•Shape: define the shape of the legend patch shape as a WKT string. Single and multipart geometries may be\nused, but no GeometryCollection.\n•Preserve aspect ratio\n•Icon VieworList Viewof available legend patch shapes, filtered by tags.\nWhen the new Shape is defined you canSave Legend Patch Shape...or pressOK, which will both lead to the same\ndialog.\n13.1. The Style Manager339\n\nQGIS Desktop 3.22 User Guide\nFig. 13.9: Save a new Legend Patch Shape\nHere you have to choose a name, tags to describe the shape and if it should be added to favorites.\nIf you pressSave..., the shape is added to the list and you are directed back to theNew Legend Patch Shapedialog to\nkeep creating new shapes.\n13.2The Symbol Selector\nThe Symbol selector is the main dialog to design a symbol. You can create or edit Marker, Line or Fill Symbols.\n340Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nFig. 13.10: Designing a Line symbol\nTwo main components structure the symbol selector dialog:\n•the symbol tree, showing symbol layers that are combined afterwards to shape a new global symbol\n•and settings to configure the selected symbol layer in the tree.\n13.2.1The symbol layer tree\nA symbol can consist of severalSymbol layers. The symbol tree shows the overlay of these symbol layers that are\ncombined afterwards to shape a new global symbol. Besides, a dynamic symbol representation is updated as soon as\nsymbol properties change.\nDepending on the level selected in the symbol tree items, various tools are made available to help you manage the\ntree:\n•add new symbol layer: you can stack as many symbols as you want\n•remove the selected symbol layer\n•lock colors of symbol layer: alocked color stays unchanged when user changes the color at the global (or\nupper) symbol level\n•duplicate a (group of) symbol layer(s)\n13.2. The Symbol Selector341\n\nQGIS Desktop 3.22 User Guide\n•move up or down the symbol layer\n13.2.2Configuring a symbol\nIn QGIS, configuring a symbol is done in two steps: the symbol and then the symbol layer.\nThe symbol\nAt the top level of the tree, it depends on the layer geometry and can be ofMarker,LineorFilltype. Each symbol\ncan embed one or more symbols (including, of any other type) or symbol layers.\nYou can setup some parameters that apply to the global symbol:\n•Unit: it can beMillimeters,Points,Pixels,Meters at Scale,Map unitsorInches(seeUnit Selectorfor\nmore details)\n•Opacity\n•Color: when this parameter is changed by the user, its value is echoed to all unlocked sub-symbols color\n•SizeandRotationfor marker symbols\n•Widthfor line symbols\nTip:Use theSize(for marker symbols) or theWidth(for line symbols) properties at the symbol level to\nproportionally resize all of its embeddedsymbol layersdimensions.\nNote:TheData-defined overridebutton next to the width, size or rotation parameters is inactive when setting\nthe symbol from the Style manager dialog. When the symbol is connected to a map layer, this button helps you\ncreateproportional or multivariate analysisrendering.\n•A preview of thesymbols library: Symbols of the same type are shown and, through the editable drop-down\nlist just above, can be filtered by free-form text or by\ncategories. You can also update the list of symbols using\nthe\nStyle Manager\nbutton and open the eponym dialog. There, you can use any capabilities as exposed in\nThe\nStyle Manager\nsection.\nThe symbols are displayed either:\n–in an icon list (with thumbnail, name and associated tags) using the\nList View\nbutton below the frame;\n–or as icon preview using the\nIcon View\nbutton.\n•Press theSave Symbolbutton to add the symbol being edited to the symbols library.\n•With theAdvancedoption, you can:\n–for line and fill symbols,Clip features to canvas extent.\n–for fill symbols,Force right-hand rule orientation: allows forcing rendered fill symbols to follow the stan-\ndard “right hand rule” for ring orientation (i.e, polygons where the exterior ring is clockwise, and the\ninterior rings are all counter-clockwise).\nThe orientation fix is applied while rendering only, and the original feature geometry is unchanged. This\nallows for creation of fill symbols with consistent appearance, regardless of the dataset being rendered\nand the ring orientation of individual features.\n–Depending on thesymbologyof the layer a symbol is being applied to, additional settings are available in\ntheAdvancedmenu:\n∗Symbol levels...to define the order of symbols rendering\n342Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n∗Data-defined Size Legend\n∗Match to Saved Symbols...andMatch to Symbols from File...to automaticallyassign symbols to\nclasses\nThe symbol layer\nAt a lower level of the tree, you can customize the symbol layers. The available symbol layer types depend on the\nupper symbol type. You can apply on the symbol layer\npaint effectsto enhance its rendering.\nBecause describing all the options of all the symbol layer types would not be possible, only particular and significant\nones are mentioned below.\nCommon parameters\nSome common options and widgets are available to build a symbol layer, regardless it’s of marker, line or fill sub-type:\n•thecolor selectorwidget to ease color manipulation\n•Units: it can beMillimeters,Points,Pixels,Meters at Scale,Map unitsorInches(seeUnit Selectorfor\nmore details)\n•the\nData-defined override\nwidget near almost all options, extending capabilities of customizing each symbol (see\nData defined override setupfor more information)\n•theEnable symbol layeroption controls the symbol layer’s visibility. Disabled symbol layers are not drawn\nwhen rendering the symbol but are saved in the symbol. Being able to hide symbol layers is convenient when\nlooking for the best design of your symbol as you don’t need to remove any for the testing. The data-defined\noverride then makes it possible to hide or display different symbol layers based on expressions (using, for\ninstance, feature attributes).\n•theDraw effectsbutton foreffects rendering.\nNote:While the description below assumes that the symbol layer type is bound to the feature geometry, keep in mind\nthat you can embed symbol layers in each others. In that case, the lower level symbol layer parameter (placement,\noffset...) might be bound to the upper-level symbol, and not to the feature geometry itself.\nMarker Symbols\nAppropriate for point geometry features, marker symbols have severalSymbol layer types:\n•Simple marker(default)\n13.2. The Symbol Selector343\n\nQGIS Desktop 3.22 User Guide\nFig. 13.11: Designing a Simple Marker Symbol\nThe simple marker symbol layer type has the following properties:\n–Sizein various supported units\n–Fill color\n–Stroke color,Stroke stylefrom a predefined list andStroke size\n–Join style: it can beBevel,MiterorRound\n–Cap style: it can beSquare,FlatorRound\n–Rotation\n–OffsetinXandYdirections from the feature\n–Anchor point: defining the quadrant point on the symbol to settle as placement origin. This is the point\ntheOffsetis applied on.\n•Ellipse marker: a simple marker symbol layer, with customizable width and height\n•Filled marker: similar to the simple marker symbol layer, except that it uses afill sub symbolto render the\nmarker. This allows use of all the existing QGIS fill (and stroke) styles for rendering markers, e.g. gradient or\nshapeburst fills.\n344Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n•Fontmarker: similar to the simple marker symbol layer, except that it uses installed fonts to render the marker.\nIts additional properties are:\n–Font family\n–Font style\n–Character(s), representing the text to display as symbol. They can be typed in or selected from the font\ncharacters collection widget and you can livePreviewthem with the selected settings.\n•Geometry generator(seeThe Geometry Generator)\n•Mask: its sub-symbol defines a mask shape whose color property will be ignored and only the opacity will be\nused. This is convenient when the marker symbol overlaps with labels or other symbols whose colors are close,\nmaking it hard to decipher. More details atMasks Properties.\n•Raster image marker: use an image (PNG,JPG,BMP...) as marker symbol. The image can be a file on the\ndisk, a remote URL, embedded in the style database (more details) or it can be encoded as a base64 string.\nWidth and height of the image can be set independently or using the\nLock aspect ratio\n. The size can be set using\nany of thecommon unitsor as a percentage of the image’s original size (scaled by the width).\n•Vector Field marker(seeThe Vector Field Marker)\n•SVG marker: provides you with images from your SVG paths (set inSettings►Options...►Systemmenu) to\nrender as marker symbol. Width and height of the symbol can be set independently or using the\nLock aspect ratio\n.\nEach SVG file colors and stroke can also be adapted. The image can be a file on the disk, a remote URL,\nembedded in the style database (more details) or it can be encoded as a base64 string.\nThe symbol can also be set withDynamic SVG parameters. SeeParametrizable SVGsection to parametrize an\nSVG symbol.\nNote:SVG version requirements\nQGIS renders SVG files that follow the\nSVG Tiny 1.2 profile, intended for implementation on a range of\ndevices, from cellphones and PDAs to laptop and desktop computers, and thus includes a subset of the features\nincluded in SVG 1.1 Full, along with new features to extend the capabilities of SVG.\nSome features not included in these specifications might not be rendered correctly in QGIS.\nLine Symbols\nAppropriate for line geometry features, line symbols have the following symbol layer types:\n•Simple line(default)\n13.2. The Symbol Selector345\n\nQGIS Desktop 3.22 User Guide\nFig. 13.12: Designing a Simple Line Symbol\nThe simple line symbol layer type has many of the same properties as thesimple marker symbol, and in addition:\n–Use custom dash pattern: overrides theStroke stylesetting with a custom dash.\n–Pattern offset: the positioning of the dashes/spaces in the line can be tweaked, so that they can be placed\nat nicer positions to account for corners in the line (also can be used potentially to “align” adjacent dash\npattern borders)\n–Align dash pattern to line length: the dash pattern length will be adjusted so that the line will end with\na complete dash element, instead of a gap.\n–Tweak dash pattern at sharp corners: dynamically adjusts the dash pattern placement so that sharp\ncorners are represented by a full dash element coming into and out of the sharp corner. Dependent on\nAlign dash pattern to line length.\n–Trim linesfromStartand/orEnd: allows for the line rendering to trim off the first x mm and last y mm\nfrom the actual line string when drawing the line. It can be used e.g. when creating complex symbols\nwhere a line layer should not overlap marker symbol layers placed at the start and end of the line. The\nstart/end trim distance supports a range ofunits, including percentage of the overall line length, and can\nbe data defined for extra control.\n•Arrow: draws lines as curved (or not) arrows with a single or a double head with configurable (and data-\ndefined):\n346Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n–Head type\n–Arrow type\n–Arrow width\n–Arrow width at start\n–Head length\n–Head thickness\n–Offset\nIt is possible to createCurved arrows(the line feature must have at least three vertices) andRepeat\narrow on each segment. It also uses afill symbolsuch as gradients or shapeburst to render the arrow body.\nCombined with the geometry generator, this type of layer symbol helps you representing flow maps.\n•Geometry generator(seeThe Geometry Generator)\n•Interpolated line: allows to render a line whoseStroke widthand/orColormay be constant (given aFixed\nwidthandSingle colorparameters) or vary along the geometry. When varying, necessary inputs are:\n–Start valueandEnd value: Values that will be used for interpolation at the extremities of the features\ngeometry. They can be fixed values, feature’s attributes or based on an expression.\n–Min. valueandMax. value: Values between which the interpolation is performed. Press the\nLoad\nbutton to automatically fill them based on the minimum and maximum start/end values applied to the\nlayer.\n–Only available for the stroke option:\n∗Min. widthandMax. width: define the range of the varying width.Min. widthis assigned to the\nMin. valueandMax. widthto theMax. value. Aunitcan be associated.\n∗Use absolute value: only consider absolute value for interpolation (negative values are used as\npositive).\n∗Ignore out of range: by default, when the[start value - end value]range of a feature\nis not included in the[min. value - max. value]range, the out-of-bounds parts of the\nfeature’s geometry are rendered with the min or max width. Check this option to not render them at\nall.\n–For varying color, you can use any of the interpolation methods ofcolor ramp classification\nFig. 13.13: Examples of interpolated lines\n•Marker line: repeats amarker symbolover the length of a line.\n13.2. The Symbol Selector347\n\nQGIS Desktop 3.22 User Guide\n–TheMarker placementcan be at a regular distance or based on the line geometry: first, last or each vertex,\non the central point of the line or of each segment, or on every curve point.\n–Offset along the line: the markers placement can also be given an offset from the start, along the line\n–TheRotate marker to follow line directionoption sets whether each marker symbol should be oriented\nrelative to the line direction or not.\nBecause a line is often a succession of segments of different directions, the rotation of the marker is\ncalculated by averaging over a specified distance along the line. For example, setting theAverage angle\noverproperty to4mmmeans that the two points along the line that are2mmbefore and after the symbol\nplacement are used to calculate the line angle for that marker symbol. This has the effect of smoothing\n(or removing) any tiny local deviations from the overall line direction, resulting in much nicer visual\norientations of the marker line symbols.\n–Line offset: the marker symbols can also be offset from the line feature.\n•Hashed line: repeats a line segment (a hash) over the length of a line symbol, with a line sub-symbol used to\nrender each individual segment. In other words, a hashed line is like a marker line in which marker symbols\nare replaced with segments. As such, the hashed lines have thesame propertiesas marker line symbols, along\nwith:\n–Hash length\n–Hash rotation\nFig. 13.14: Examples of hashed lines\n348Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nFill Symbols\nAppropriate for polygon geometry features, fill symbols have also several symbol layer types:\n•Simple fill(default): fills a polygon with a uniform color\nFig. 13.15: Designing a Simple Fill Symbol\n•Centroid fill: places amarker symbolat the centroid of the visible feature. The position of the marker may\nnot be the real centroid of the feature, because calculation takes into account the polygon(s) clipped to area\nvisible in map canvas for rendering and ignores holes. Use the\ngeometry generator symbolif you want the exact\ncentroid.\nYou can:\n–Force placement of markers inside polygons\n–Draw markers on every part of multi-part featuresor place the point only on its biggest part\n–display the marker symbol(s) in whole or in part, keeping parts overlapping the current feature geometry\n(Clip markers to polygon boundary) or the geometry part the symbol belongs to (Clip markers to current\npart boundary only)\n•Geometry generator(seeThe Geometry Generator)\n•Gradientfill: uses a radial, linear or conical gradient, based on either simple two color gradients or a predefined\ngradient color rampto fill polygons. The gradient can be rotated and applied on a single feature basis or across\n13.2. The Symbol Selector349\n\nQGIS Desktop 3.22 User Guide\nthe whole map extent. Also start and end points can be set via coordinates or using the centroid (of feature or\nmap). A data-defined offset can be defined;\n•Line pattern fill: fills the polygon with a hatching pattern ofline symbol layer. You can set:\n–Rotationof the lines, counter-clockwise\n–Spacing: distance between consecutive lines\n–Offsetdistance of the lines from the feature boundary\n•Point pattern fill: fills the polygon with a grid pattern ofmarker symbol. You can set:\n–Distance:HorizontalandVerticaldistances between consecutive markers\n–Displacement: aHorizontal(resp.Vertical) offset of alignment between consecutive markers in a column\n(resp. in a row)\n–Offset:HorizontalandVerticaldistances from the feature boundary\n•Random marker fill: fills the polygon with amarker symbolplaced at random locations within the polygon\nboundary. You can set:\n–Count method: whether the number of marker symbols to render is considered as an absolute count or\ndensity-based\n–Point count: the number of marker symbols to render,\n–an optional random numberseed, to give consistent placement\n–Density area: in case of density-based count method, ensures the fill density of markers remains the same\non different scale / zoom levels of markers whenever maps are refreshed (also allows random placement\nto play nice with QGIS server and tile-based rendering)\n–Clip markers to polygon boundary: whethermarkersrenderedneartheedgesofpolygonsshouldbe clipped\nto the polygon boundary or not\n•Raster image fill: fills the polygon with tiles from a raster image (PNG JPG,BMP...). The image can be a\nfile on the disk, a remote URL or an embedded file encoded as a string (\nmore details). Options include (data\ndefined) opacity, image width, coordinate mode (object or viewport), rotation and offset. The image width can\nbe set using any of the\ncommon unitsor as a percentage of the original size.\n•SVG fill: fills the polygon usingSVG markersof a given size (Texture width);\n•Shapeburst fill: buffers a gradient fill, where a gradient is drawn from the boundary of a polygon towards the\npolygon’s centre. Configurable parameters include distance from the boundary to shade, use of color ramps or\nsimple two color gradients, optional blurring of the fill and offsets;\n•Outline: Arrow: uses a linearrow symbollayer to represent the polygon boundary. The settings for the outline\narrow are the same as for arrow line symbols.\n•Outline: Hashed line: uses ahash line symbollayer to represent the polygon boundary (Rings) which can be\nthe interior rings only, the exterior ring only or all the rings). The other settings for the outline hashed line are\nthe same as for hashed line symbols.\n•Outline: Marker line: uses amarker line symbollayer to represent the polygon boundary (Rings) which can\nbe the interior rings only, the exterior ring only or all the rings). The other settings for the outline marker line\nare same as for marker line symbols.\n•Outline: simple line: uses asimple line symbollayer to represent the polygon boundary (Rings) which can be\nthe interior rings only, the exterior ring only or all the rings). TheDraw line only inside polygonoption displays\nthe polygon borders inside the polygon and can be useful to clearly represent adjacent polygon boundaries. The\nother settings for the outline simple line are the same as for simple line symbols.\nNote:When geometry type is polygon, you can choose to disable the automatic clipping of lines/polygons to the\ncanvas extent. In some cases this clipping results in unfavourable symbology (e.g. centroid fills where the centroid\nmust always be the actual feature’s centroid).\n350Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nParametrizable SVG\nYou have the possibility to change the colors of aSVG marker. You have to add the placeholdersparam(fill)\nfor fill color,param(outline)for stroke color andparam(outline-width)for stroke width. These place-\nholders can optionally be followed by a default value, e.g.:\n<svgwidth=\"100%\"height=\"100%\">\n<rectfill=\"param(fill) #ff0000\"stroke=\"param(outline) #00ff00\"stroke-width=\n,→\"param(outline-width) 10\"width=\"100\"height=\"100\">\n</rect>\n</svg>\nMore generally, SVG can be freely parametrized usingparam(param_name). This param can either be used as\nan attribute value or a node text:\n<gstroke-width=\".265\"text-anchor=\"middle\"alignment-baseline=\"param(align)\">\n<textx=\"98\"y=\"147.5\"font-size=\"6px\">param(text1)</text>\n<textx=\"98\"y=\"156.3\"font-size=\"4.5px\">param(text2)</text>\n</g>\nThe parameters can then be defined as expressions in theDynamic SVG parameterstable.\nFig. 13.16: Dynamic SVG parameters table\nThe Geometry Generator\nAvailable with all types of symbols, thegeometry generatorsymbol layer allows to useexpression syntaxto generate\na geometry on the fly during the rendering process. The resulting geometry does not have to match with the original\nGeometry typeand you can add several differently modified symbol layers on top of each other.\nAUnitsproperty can be set: when the geometry generator symbol is not applied to a layer (e.g., it is used on a layout\nitem), this allows more control over the generated output.\nSome examples:\n13.2. The Symbol Selector351\n\nQGIS Desktop 3.22 User Guide\n-- render the centroid of a feature\ncentroid( $geometry )\n-- visually overlap features within a 100 map units distance from a point\n-- feature, i.e generate a 100m buffer around the point\nbuffer( $geometry, 100 )\n-- Given polygon layer1( id1, layer2_id, ...) and layer2( id2, fieldn...)\n-- render layer1 with a line joining centroids of both where layer2_id = id2\nmake_line( centroid( $geometry ),\ncentroid( geometry( get_feature( 'layer2', 'id2', attribute(\n$currentfeature, 'layer2_id') ) )\n)\n-- Create a nice radial effect of points surrounding the central feature\n-- point when used as a MultiPoint geometry generator\ncollect_geometries(\narray_foreach(\ngenerate_series( 0, 330, 30 ),\nproject( $geometry, .2, radians( @element ) )\n)\n)\nThe Vector Field Marker\nThe vector field marker is used to display vector field data such as earth deformation, tidal flows, and the like. It\ndisplays the vectors as lines (preferably arrows) that are scaled and oriented according to selected attributes of data\npoints. It can only be used to render point data; line and polygon layers are not drawn by this symbology.\nThe vector field is defined by attributes in the data, which can represent the field either by:\n•cartesiancomponents (xandycomponents of the field)\n•orpolarcoordinates: in this case, attributes defineLengthandAngle. The angle may be measured either\nclockwise from north, or Counterclockwise from east, and may be either in degrees or radians.\n•or asheight onlydata, which displays a vertical arrow scaled using an attribute of the data. This is appropriate\nfor displaying the vertical component of deformation, for example.\nThe magnitude of field can be scaled up or down to an appropriate size for viewing the field.\n13.3Setting a label\nLabels are textual information you can display on vector features or maps. They add details you could not necessarily\nrepresent using symbols. Two types of text-related items are available in QGIS:\n•Text Format: defines the appearance of the text, includingfont, size, colors,shadow,background,buffer, ...\nThey can be used to render texts over the map (layout/map title, decorations, scale bar, ...), usually through\nthefontwidget.\nTo create aText Formatitem:\n1.Open theStyle Managerdialog\n2.Activate theText formattab\n352Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nFig. 13.17: Text formats in Style Manager dialog\n3.Press the\nAdd item\nbutton. TheText Formatdialog opens forconfiguration. As usual, these properties\naredata-definable.\n•Label Settings: extend the text format settings with properties related to the location or the interaction with\nother texts or features (\ncallouts,placement,overlay, scale visibility, mask ...).\nThey are used to configure smart labelling for vector layers through theLabelstab of the vectorLayer\nPropertiesdialog orLayer Stylingpanel or using the\nLayer Labeling Options\nbutton of theLabel toolbar.\nTo create aLabel Settingsitem:\n1.Open theStyle Managerdialog\n2.Activate theLabel Settingstab\n13.3. Setting a label353\n\nQGIS Desktop 3.22 User Guide\nFig. 13.18: Label Settings in Style Manager dialog\n3.Press the\nAdd item\nmenu and select the entry corresponding to the geometry type of the features you\nwant to label.\nTheLabel Settingsdialog opens with the following properties. As usual, these properties aredata-definable.\n13.3.1Formatting the label text\nWhether you are configuring aText FormatorLabel Settingsitem, you will be given the following options:\nProperties tabText formatLabel settings\nText\nFormatting\nBuffer\nMask\nBackground\nShadow\nCallout\nPlacement\nRendering\n354Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nText tab\nFig. 13.19: Labels settings - Text tab\nIn theTexttab, you can set:\n•theFont, from the ones available on your machine\n•theStyle: along with the common styles of the font, you can set whether the text should be underlined or striked\nthrough\n•theSizein anysupported unit\n•theColor\n•theOpacity\n•andAllow HTML Formatting: The HTML formatting option enables the proper rendering of some HTML tags\nto customize the label. The supported tags are the HTML Color tags (applied to text, underline, strikethrough,\nand overline).\nIn order to use the HTML formatting, you need to provide the HTML code in theValuefield. The expression\nis parsed and any supported HTML tag overrides its corresponding setting in the labels properties. They also\ncombine well with other background, shadow, buffer... properties of labels.\nBelow an example of a HTML-based expression and rendering (applies different colors and underline to the\nsame label):\n13.3. Setting a label355\n\nQGIS Desktop 3.22 User Guide\nformat(\n'<spanstyle=\"color:blue\">%1</span> ( <spanstyle=\"color:red\"><u>%2 ft</u></\n,→span> )',\ntitle( lower( \"Name\" ) ),\nround($length)\n)\nFig. 13.20: Labeling with HTML formatting enabled\nAt the bottom of the tab, a widget shows a filterable list of compatible items stored in yourstyle manager database.\nThis allows you to easily configure the current text format or label setting based on an existing one, and also save a\nnew item to the style database: Press theSave format...orSave settings...button and provide a name and tag(s).\nNote:When configuring aLabel Settingsitem, text format items are also available in this widget. Select one to\nquickly overwrite the currenttextual propertiesof the label. Likewise, you can create/overwrite a text format from\nthere.\n356Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nFormatting tab\nFig. 13.21: Label settings - Formatting tab\nIn theFormattingtab, you can:\n•Use theType caseoption to change the capitalization style of the text. You have the possibility to render the\ntext as:\n–No change\n–All uppercase\n–All lowercase\n13.3. Setting a label357\n\nQGIS Desktop 3.22 User Guide\n–Title case: modifies the first letter of each word into capital, and turns the other letters into lower case if\nthe original text is using a single type case. In case of mixed type cases in the text, the other letters are\nleft untouched.\n–Force first letter to capital: modifies the first letter of each word into capital and leaves the other letters in\nthe text untouched.\n•UnderSpacing, change the space between words and between individual letters.\n•Enable kerningof the text font\n•Set theText orientationwhich can beHorizontalorVertical. It can also beRotation-basedwhen setting a label\n(e.g., to properly label line features inparallelplacement mode).\n•Use theBlend modeoption to determine how your labels will mix with the map features below them (more\ndetails atBlending Modes).\n•TheApply label text substitutesoption allows you to specify a list of texts to substitute to texts in feature\nlabels (e.g., abbreviating street types). Replacement texts are used when displaying labels on the map. Users\ncan also export and import lists of substitutes to make reuse and sharing easier.\n•ConfigureMultiple lines:\n–Set a character that will force a line break in the text with theWrap on characteroption\n–Set an ideal line size for auto-wrapping using theWrap lines tooption. The size can represent either the\nMaximum line lengthor theMinimum line length.\n–Decide theLine Height\n–Format theAlignment: typical values available areLeft,Right,JustifyandCenter.\nWhen setting point labels properties, the text alignment can also beFollow label placement. In that case,\nthe alignment will depend on the final placement of the label relative to the point. E.g., if the label is\nplaced to the left of the point, then the label will be right aligned, while if it is placed to the right, it will\nbe left aligned.\nNote:TheMultiple linesformatting is not yet supported by curve basedlabel placement. The options will\nthen be deactivated.\n•For line labels you can includeLine direction symbolto help determine the line directions, with symbols to use\nto indicate theLeftorRight. They work particularly well when used with thecurvedorParallelplacement\noptions from thePlacementtab. There are options to set the symbols position, and toReverse direction.\n•Use theFormatted numbersoption to format numeric texts. You can set the number ofDecimal places. By\ndefault,3decimal places will be used. Use theShow plus signif you want to show the plus sign for positive\nnumbers.\n358Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nBuffer tab\nFig. 13.22: Label settings - Buffer tab\nTo create a buffer around the label, activate theDraw text buffercheckbox in theBuffertab. Then you can:\n•Set the buffer’sSizein anysupported unit\n•Select the buffer’sColor\n•Color buffer’s fill: The buffer expands from the label’s outline, so, if the option is activated, the label’s\ninterior is filled. This may be relevant when using partially transparent labels or with non-normal blending\nmodes, which will allow seeing behind the label’s text. Unchecking the option (while using totally transparent\nlabels) will allow you to create outlined text labels.\n•Define the buffer’sOpacity\n•Apply aPen join style: it can beRound,MiterorBevel\n•Use theBlend modeoption to determine how your label’s buffer will mix with the map components below them\n(more details at\nBlending Modes).\n•CheckDraw effectsto add advancedpaint effectsfor improving text readability, eg through outer glows\nand blurs.\n13.3. Setting a label359\n\nQGIS Desktop 3.22 User Guide\nBackground tab\nTheBackgroundtab allows you to configure a shape that stays below each label. To add a background, activate\ntheDraw Backgroundcheckbox and select theShapetype. It can be:\n•a regular shape such asRectangle,Square,CircleorEllipseusing full properties of afill symbol\n•anSVGsymbol from a file, a URL or embedded in the project or style database (more details)\n•or aMarker Symbolyou can create or select from thesymbol library.\nFig. 13.23: Label settings - Background tab\nDepending on the selected shape, you need to configure some of the following properties:\n•TheSize typeof the frame, which can be:\n–Fixed: using the same size for all the labels, regardless the size of the text\n–or aBufferover the text’s bounding box\n•TheSizeof the frame in X and Y directions, using anysupported units\n•ARotationof the background, betweenSync with label,Offset of labelandFixed. The last two require an angle\nin degrees.\n360Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n•AnOffset X,Yto shift the background item in the X and/or Y directions\n•ARadius X,Yto round the corners of the background shape (applies to rectangle and square shapes only)\n•AnOpacityof the background\n•ABlend modeto mix the background with the other items in the rendering (seeBlending Modes).\n•For SVG symbol, you can use its default properties (Load symbol parameters) or set a customFill color,Stroke\ncolorandStroke width.\n•Draw effectsto add advancedpaint effectsfor improving text readability, eg through outer glows and\nblurs.\nShadow tab\nFig. 13.24: Label settings - Shadow tab\nTo add a shadow to the text, enable theShadowtab and activate theDraw drop shadow. Then you can:\n•Indicate the item used to generate the shadow withDraw under. It can be theLowest label componentor a\nparticular component such as theTextitself, theBufferor theBackground.\n•Set the shadow’sOffsetfrom the item being shadowded, ie:\n–The angle: clockwise, it depends on the underlying item orientation\n–The distance of offset from the item being shadowded\n–The units of the offset\n13.3. Setting a label361\n\nQGIS Desktop 3.22 User Guide\nIf you tick theUse global shadowcheckbox, then the zero point of the angle is always oriented to the north\nand doesn’t depend on the orientation of the label’s item.\n•Influence the appearance of the shadow with theBlur radius. The higher the number, the softer the shadows,\nin the units of your choice.\n•Define the shadow’sOpacity\n•Rescale the shadow’s size using theScalefactor\n•Choose the shadow’sColor\n•Use theBlend modeoption to determine how your label’s shadow will mix with the map components below\nthem (more details atBlending Modes).\n13.3.2Configuring interaction with labels\nOther than the text formatting settings exposed above, you can also set how labels interact with each others or with\nthe features.\nMask tab\nTheMasktab allows you to define a mask area around the labels. This feature is very useful when you have\noverlapping symbols and labels with similar colors, and you want to make the labels visible.\nFig. 13.25: Labels settings - Mask tab\nTo create masking effects on labels:\n1.Activate theEnable maskcheckbox in thetab.\n2.Then you can set:\n•the mask’sSizein thesupported units\n362Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n•theOpacityof the mask area around the label\n•aPen Join Style\n•paint effectsthrough theDraw effectscheckbox.\n3.Select this mask shape as a mask source in the overlapping layer propertiesMasktab (seeMasks Properties).\nCallouts tab\nA common practice when placing labels on a crowded map is to usecallouts- labels which are placed outside (or\ndisplaced from) their associated feature are identified with a dynamic line connecting the label and the feature. If one\nof the two endings (either the label or the feature) is moved, the shape of the connector is recomputed.\nFig. 13.26: Labels with various callouts settings\nTo add a callout to a label, enable theCalloutstab and activate theDraw callouts. Then you can:\n1.Select theStyleof connector, one of:\n•Simple lines: a straight line, the shortest path\n•Manhattan style: a 90° broken line\n•Curved lines: a curved line\n•Balloons: a speech bubble surrounding the label and pointing to the feature. It can have rounded corners.\n2.For a line-based callout:\n1.Select theLine stylewith full capabilities of aline symbolincluding layer effects, and data-defined settings\n2.If curved, you also define:\n•the percentage ofCurvatureof the connection line\n•and itsOrientation: starting from the label to the feature, it can beClockwiseorCounter-clockwise,\norAutomatic(determining an optimal orientation for each label)\n3.Set theMinimum lengthof callout lines\n4.Check whether toDraw lines to all feature partsfrom the feature’s label\n13.3. Setting a label363\n\nQGIS Desktop 3.22 User Guide\n5.Set theLabel anchor point: controls where the connector line should join to the label text. Available\noptions:\n•Closest point\n•Centroid\n•Fixed position at the edge (Top left,Top center,Top right,Left middle,Right middle,Bottom left,\nBottom centerandBottom right).\n6.Set theOffset from label areaoption: controls the distance from the label anchor point (where the callout\nline ends). This avoids drawing lines right up against the text.\n3.For a balloon callout, you’d need to set:\n•theFill stylewith full capabilities of afill symbolincluding layer effects, and data-defined settings\n•theCorner radiusof the speech bubble\n•theWedge width: how large the bubble speech connection with feature’s pointer should be\n•theMarginsaround the label’s text\n4.Set theOffset from featureoption: controls the distance from the feature (or its anchor point if a polygon)\nwhere callout lines end. Eg, this avoids drawing lines right up against the edges of the features.\n5.Set theFeature anchor pointfor the (polygon) feature (the end point of the connector line). Available options:\n•Pole of inaccessibility\n•Point on exterior\n•Point on surface\n•Centroid\n6.Set theBlend mode: controls theblendingof the callout.\nUnder theData defined placementgroup, coordinates of theOrigin(on the label side) and/orDestination(on the\nfeature side) points of the callout can be controlled. Callouts can also be controlled manually by using the\nMove Label, Diagram or Callout\ntool in theLabeling Toolbar. The start and end points of each callout can be moved this way.\nThe nodes should be highlighted when the mouse pointer is nearby. If needed theShiftKey can be held during the\nmovement. This will snap the point in a way that the angle between the two callout points increments by 15 degrees.\nPlacement tab\nChoose thePlacementtab for configuring label placement and labeling priority. Note that the placement options\ndiffer according to the type of vector layer, namely point, line or polygon, and are affected by the globalPAL setting.\nPlacement for point layers\nPoint labels placement modes available are:\n•Cartographic: point labels are generated with a better visual relationship with the point feature, following ideal\ncartographic placement rules. Labels can be placed:\n–at a set\nDistance\ninsupported units, either from the point feature itself or from the bounds of the symbol\nused to represent the feature (set inDistance offset from). The latter option is especially useful when the\nsymbol size isn’t fixed, e.g. if it’s set by a data defined size or when using different symbols in a\ncategorized\nrenderer.\n–following aPosition prioritythat can be customized or set for an individual feature using a data defined list\nof prioritised positions. This also allows only certain placements to be used, so e.g. for coastal features\nyou can prevent labels being placed over the land.\n364Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\nBy default, cartographic mode placements are prioritised in the following order (respecting theguidelines\nfrom Krygier and Wood (2011)and other cartographic textbooks):\n1.top right\n2.top left\n3.bottom right\n4.bottom left\n5.middle right\n6.middle left\n7.top, slightly right\n8.bottom, slightly left.\n•Around Point: labels are placed in a circle around the feature. equal radius (set inDistance) circle around the\nfeature. The placement priority is clockwise from the “top right”. The position can be constrained using the\ndata-definedQuadrantoption.\n•Offset from Point: labels are placed at anOffset X,Ydistance from the point feature, in various units, or prefer-\nably over the feature. You can use a data-definedQuadrantto constrain the placement and can assign aRotation\nto the label.\nPlacement for line layers\nLabel modes for line layers include:\n•Parallel: draws the label parallel to a generalised line representing the feature, with preference for placement\nover straighter portions of the line. You can define:\n–Allowed positions:Above line,On line,Below lineandLine orientation dependent position(placing the\nlabel at the left or the right of the line). It’s possible to select several options at once. In that case, QGIS\nwill look for the optimal label position.\n–Distancebetween the label and the line\n•Curved: draws the label following the curvature of the line feature. In addition to the parameters available with\ntheParallelmode, you can set theMaximum angle between curved characters, either inside or outside.\n•Horizontal: draws labels horizontally along the length of the line feature.\nFig. 13.27: Label placement examples for lines\nNext to placement modes, you can set:\n•Repeating Labels Distanceto display multiple times the label over the length of the feature. The distance can\nbe inMillimeters,Points,Pixels,Meters at scale,Map UnitsandInches.\n13.3. Setting a label365\n\nQGIS Desktop 3.22 User Guide\n•ALabel Overrun Distance(not available for horizontal mode): specifies the maximal allowable distance a label\nmay run past the end (or start) of line features. Increasing this value can allow for labels to be shown for shorter\nline features.\n•Label Anchoring: controls the placement of the labels along the line feature they refer to. Click onSettings ...\nto choose:\n–the position along the line (as a ratio) which labels will be placed close to. It can be data-defined and\npossible values are:\n∗Center of Line\n∗Start of Line\n∗End of Line\n∗orCustom....\n–Clipping: Determines how the label placement on a line is calculated. By default only the visible extent\nof the line is used but the whole extent can be used to have more consistent results.\n–Placement Behavior: usePreferred Placement Hintto treat the label anchor only as a hint for the label\nplacement. By choosingStrict, labels are placed exactly on the label anchor.\nPlacement for polygon layers\nYou can choose one of the following modes for placing labels of polygons:\nFig. 13.28: Label placement examples for polygons\n•Offset from Centroid: labels are placed over the feature centroid or at a fixedOffset X,Ydistance (insupported\nunits\n) from the centroid. The reference centroid can be determined based on the part of the polygon rendered\nin the map canvas (visible polygon) or thewhole polygon, no matter if you can see it. You can also:\n–force the centroid point to lay inside their polygon\n–place the label within a specific quadrant\n–assign a rotation\n366Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n–Allow placing labels outside of polygonswhen it is not possible to place them inside the polygon. Thanks\nto data-defined properties, this makes possible to either allow outside labels, prevent outside labels, or\nforce outside labels on a feature-by-feature basis.\n•Around Centroid: places the label within a preset distance around the centroid, with a preference for the place-\nment directly over the centroid. Again, you can define whether the centroid is the one of thevisible polygonor\nthewhole polygon, and whether to force the centroid point inside the polygon.\n•Horizontal: places at the best position a horizontal label inside the polygon. The preferred placement is further\nfrom the edges of the polygon. It’s possible toAllow placing labels outside of polygons.\n•Free (Angled): places at the best position a rotated label inside the polygon. The rotation respects the polygon’s\norientation and the preferred placement is further from the edges of the polygon. It’s possible toAllow placing\nlabels outside of polygons.\n•Using Perimeter: draws the label parallel to a generalised line representing the polygon boundary, with prefer-\nence for straighter portions of the perimeter. You can define:\n–Allowed positions:Above line,On line,Below lineandLine orientation dependent position(placing the\nlabel at the left or the right of the polygon’s boundary). It’s possible to select several options at once. In\nthat case, QGIS will look for the optimal label position.\n–Distancebetween the label and the polygon’s outline\n–theRepeating Labels Distanceto display multiple times the label over the length of the perimeter.\n•Using Perimeter (Curved): draws the label following the curvature of the polygon’s boundary. In addition to the\nparameters available with the\nUsing Perimeter\nmode, you can set the\nMaximum angle between curved characters\npolygon, either inside or outside.\n•Outside Polygons: always places labels outside the polygons, at a setDistance\nCommon placement settings\nSome label placement settings are available for all layer geometry types:\nGeometry Generator\nTheGeometry Generatorsection allows a user to alter the underlying geometry used to place and render the label, by\nusingexpressions. This can be useful to perform displacement of the geometry dynamically or to convert it to another\ngeometry (type).\nIn order to use the geometry generator:\n1.Check theGeometry generatoroption\n2.Enter the expression generating the geometry to rely on\n3.If relevant, select the geometry type of the expression output: the label geometry-based settings such as place-\nment or rendering are updated to match the new geometry type capabilities.\nSome use cases include:\n•Use a geometry which is saved in another field “label_position”\n•Use thegenerated geometryfrom the symbology also for labeling\n•Use the @map_scale variable to calculate distances / sizes be zoom level independent.\n•Combined with the curved placement mode, creates a circular label around a point feature:\nexterior_ring(make_circle($geometry, 20))\n•Add a label at the start and the end of a line feature:\n13.3. Setting a label367\n\nQGIS Desktop 3.22 User Guide\ncollect_geometries( start_point($geometry), end_point($geometry) )\n•Rely on a smoothed line of a river to get more room for label placement:\nsmooth( $geometry, iterations:=30, offset:=0.25, min_length:=10 )\nData Defined\nTheData Definedgroup provides direct control on labels placement, on a feature-by-feature basis. It relies on their\nattributes or an expression to set:\n•theXandYcoordinate\n•the text alignment over the custom position set above:\n–Horizontal: it can beLeft,CenterorRight\n–the textVertical: it can beBottom,Base,Half,CaporTop\n•the textRotation. Different units can be defined for the labeling rotation (e.g.degrees,minutes of arc,\nturns). Check thePreserve data rotation valuesentry if you want to keep the rotation value in the associated\nfield and apply it to the label, whether the label is pinned or not. If unchecked, unpinning the label rotation is\nreset and its value cleared from the attribute table.\nNote:Data-defined rotation with polygon features is currently supported only with theAround centroidplace-\nment mode.\nNote:Expressions can not be used in combination with the labels map tools (ie theRotate labelandMove label\ntools) todata-definelabels placement. The widget will be reset to the correspondingauxiliary storage field.\nPriority\nIn thePrioritysection you can define the placement priority rank of each label, ie if there are different diagrams or\nlabels candidates for the same location, the item with the higher priority will be displayed and the others could be left\nout.\nThe priority rank is also used to evaluate whether a label could be omitted due to a greater weighted\nobstacle feature.\nObstacles\nIn some contexts (eg, high density labels, overlapping features...), the labels placement can result in labels being\nplaced over unrelated features.\nAn obstacle is a feature over which QGIS avoids placing other features’ labels or diagrams. This can be controlled\nfrom theObstaclessection:\n1.Activate theFeatures act as obstaclesoption to decide that features of the layer should act as obstacles for\nany label and diagram (including items from other features in the same layer).\nInstead of the whole layer, you can select a subset of features to use as obstacles, using the\nData-defined override\ncontrol next to the option.\n2.Use theSettingsbutton to tweak the obstacle’s weighting.\n368Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n•For every potential obstacle feature you can assign anObstacle weight: anylabelordiagramwhose place-\nment priority rank is greater than this value can be placed over. Labels or diagrams with lower rank will\nbe omitted if no other placement is possible.\nThis weighting can also be data-defined, so that within the same layer, certain features are more likely to\nbe covered than others.\n•For polygon layers, you can choose the kind of obstacle the feature is:\n–over the feature’s interior: avoids placing labels over the interior of the polygon (prefers placing\nlabels totally outside or just slightly inside the polygon)\n–orover the feature’s boundary: avoids placing labels over the boundary of the polygon (prefers\nplacing labels outside or completely inside the polygon). This can be useful for layers where the\nfeatures cover the whole area (administrative units, categorical coverages, ...). In this case, it is\nimpossible to avoid placing labels within these features, and it looks much better when placing them\nover the boundaries between features is avoided.\nRendering tab\nIn theRenderingtab, you can tune when the labels can be rendered and their interaction with other labels and\nfeatures.\nLabel options\nUnderLabel options:\n•You find thescale-basedand thePixel size-basedvisibility settings.\n•TheLabel z-indexdetermines the order in which labels are rendered, as well in relation with other feature\nlabels in the layer (using data-defined override expression), as with labels from other layers. Labels with a\nhigher z-index are rendered on top of labels (from any layer) with lower z-index.\nAdditionally, the logic has been tweaked so that if two labels have matching z-indexes, then:\n–if they are from the same layer, the smaller label will be drawn above the larger label\n–if they are from different layers, the labels will be drawn in the same order as their layers themselves (ie\nrespecting the order set in the map legend).\nNote:This setting doesn’t make labels to be drawn below the features from other layers, it just controls the\norder in which labels are drawn on top of all the layers’ features.\n•While rendering labels and in order to display readable labels, QGIS automatically evaluates the position of the\nlabels and can hide some of them in case of collision. You can however choose to\nShow all labels for this\nlayer (including colliding labels)in order to manually fix their placement (see\nThe Label Toolbar).\n•With data-defined expressions inShow labelandAlways Showyou can fine tune which labels should be ren-\ndered.\n•Allow toShow upside-down labels: alternatives areNever,when rotation definedoralways.\n13.3. Setting a label369\n\nQGIS Desktop 3.22 User Guide\nFeature options\nUnderFeature options:\n•You can choose toLabel every part of a multi-part featuresandLimit number of features to be labeled to.\n•Both line and polygon layers offer the option to set a minimum size for the features to be labeled, usingSuppress\nlabeling of features smaller than.\n•For polygon features, you can also filter the labels to show according to whether they completely fit within their\nfeature or not.\n•For line features, you can choose toMerge connected lines to avoid duplicate labels, rendering a quite airy map\nin conjunction with theDistanceorRepeatoptions in thePlacementtab.\n13.4Creating 3D Symbols\nTheStyle Managerhelps you create and store 3D symbols for every geometry type to render in the3D map view.\nAs of the other items, enable the3D Symbolstab and expand thebutton menu to create:\n•3D point symbols\n•3D line symbols\n•3D polygon symbols\n370Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n13.4.1Point Layers\nFig. 13.29: Properties of a 3D point symbol\n•You can define different types of 3DShapeto use for point symbols. They are mainly defined by their dimen-\nsions whose unit refers to the CRS of the project. Available types are:\n–Spheredefined by aRadius\n–Cylinderdefined by aRadiusandLength\n–Cubedefined by aSize\n–Conedefined by aTop radius, aBottom radiusand aLength\n–Planedefined by aSize\n–Torusdefined by aRadiusand aMinor radius\n–3D Model, using a 3D model file (several formats are supported) that can be a file on disk, a remote URL\nor\nembedded in the project.\n–Billboard, defined by theBillboard heightand theBillboard symbol(usually based on amarker symbol).\nThe symbol will have a stable size. Convenient for visualizing 3D point clouds Shapes.\n•TheAltitude clampingcan be set toAbsolute,RelativeorTerrain. TheAbsolutesetting can be used when height\nvalues of the 3d vectors are provided as absolute measures from 0.RelativeandTerrainadd given elevation\nvalues to the underlying terrain elevation.\n•Theshadingcan be defined.\n•Under theTransformationsframe, you can apply affine transformation to the symbol:\n–Translationto move objects in x, y and z axis.\n13.4. Creating 3D Symbols371\n\nQGIS Desktop 3.22 User Guide\n–Scaleto resize the 3D shapes\n–Rotationaround the x-, y- and z-axis.\n13.4.2Line layers\nFig. 13.30: Properties of a 3D line symbol\n•Beneath theWidthandHeightsettings you can define theExtrusionof the vector lines. If the lines do not have\nz-values, you can define the 3d volumes with this setting.\n•With theAltitude clampingyou define the position of the 3D lines relative to the underlying terrain surface, if\nyou have included raster elevation data or other 3D vectors.\n•TheAltitude bindingdefines how the feature is clamped to the terrain. Either everyVertexof the feature will\nbe clamped to the terrain or this will be done by theCentroid.\n•It is possible toRender as simple 3D lines.\n•The shading can be defined in the menusDiffuse,Ambient,SpecularandShininess.\n372Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n13.4.3Polygon Layers\nFig. 13.31: Properties of a 3D polygon symbol\n•As for the other ones,Heightcan be defined in CRS units. You can also use thebutton to overwrite the\nvalue with a custom expression, a variable or an entry of the attribute table\n•Again,Extrusionis possible for missing z-values. Also for the extrusion you can use thebutton in order to\nuse the values of the vector layer and have different results for each polygon:\n13.4. Creating 3D Symbols373\n\nQGIS Desktop 3.22 User Guide\nFig. 13.32: Data Defined Extrusion\n•TheAltitude clamping,Altitude bindingcan be defined as explained above.\n•TheCulling modeto apply to the symbol; it can be:\n–No Culling: this can help to avoid seemingly missing surfaces when polygonZ/multipatch data do not have\nconsistent ordering of vertices (e.g. all clock-wise or counter clock-wise)\n–Front\n–orBack\n•TheRendered facadedetermines the faces to display. Possible values areNo facades,Walls,Roofs, orWalls\nand roofs\n•Add back faces: for each triangle, creates both front and back face with correct normals - at the expense\nof increased number of vertex data. This option can be used to fix shading issues (e.g., due to data with\ninconsistent order of vertices).\n•Invert normals (experimental): can be useful for fixing clockwise/counter-clockwise face vertex orders\n•Theshadingcan be defined.\n•Display of theEdgesof the symbols can be enabled and assigned aWidthandColor.\nHint: Combination for best rendering of 3D data\nCulling mode,Add back facesandInvert normalsare all meant to fix the look of 3D data if it does not look right. Typ-\nically when loading some data, it is best to first tryculling mode=backandadd back faces=disabled\n- it is the most efficient. If the rendering does not look correct, tryadd back faces=enabledand keep\nculling mode=no culling. Other combinations are more advanced and useful only in some scenarios based\non how mixed up is the input dataset.\n374Chapter 13. The Style Library\n\nQGIS Desktop 3.22 User Guide\n13.4.4Shading the texture\nShading helps you reveal 3d details of objects which may otherwise be hidden due to the scene’s lighting. Ultimately,\nit’s an easier material to work with as you don’t need to worry about setting up appropriate scene lighting in order to\nvisualise features.\nVarious techniques of shading are used in QGIS and their availability depends on the geometry type of the symbol:\n•Realistic (Phong): describes the way a surface reflects light as a combination of theDiffusereflection of rough\nsurfaces with theSpecularreflection of shiny surfaces (Shininess). It also includes anAmbientoption to account\nfor the small amount of light that is scattered about the entire scene. Read more athttps://en.wikipedia.org/\nwiki/Phong_reflection_model#Description\n•Realistic Textured (Phong): same as theRealistic (Phong)except that an image is used asDiffuse Texture. The\nimage can be a file on disk, a remote URL orembedded in the project. TheTexture scaleandTexture rotation\nare required.\n•CAD (Gooch): this technique allows shading to occur only in mid-tones so that edge lines and highlights remain\nvisually prominent. Along with theDiffuse,Specular,Shininessoptions, you need to provide aWarmcolor (for\nsurface facing toward the light) and aCoolcolor (for the ones facing away). Also, the relative contributions\nto the cool and warm colors by the diffuse color are controlled byAlphaandBetaproperties respectively. See\nalsohttps://en.wikipedia.org/wiki/Gooch_shading\n•Embedded Textureswith 3D models shape\n13.4.5Application example\nTo go through the settings explained above you can have a look athttps://app.merginmaps.com/projects/saber/\nluxembourg/tree.\n13.4. Creating 3D Symbols375\n\nQGIS Desktop 3.22 User Guide\n376Chapter 13. The Style Library\n\nCHAPTER\nFOURTEEN\nMANAGING DATA SOURCE\n14.1Opening Data\nAs part of an Open Source Software ecosystem, QGIS is built upon different libraries that, combined with its own\nproviders, offer capabilities to read and often write a lot of formats:\n•Vector data formats include GeoPackage, GML, GeoJSON, GPX, KML, Comma Separated Values, ESRI\nformats (Shapefile, Geodatabase...), MapInfo and MicroStation file formats, AutoCAD DWG/DXF, GRASS\nand many more... Read the complete list ofsupported vector formats.\n•Raster data formats include GeoTIFF, JPEG, ASCII Gridded XYZ, MBTiles, R or Idrisi rasters, GDAL Vir-\ntual, SRTM, Sentinel Data, ERDAS IMAGINE, ArcInfo Binary Grid, ArcInfo ASCII Grid, and many more...\nRead the complete list ofsupported raster formats.\n•Database formats include PostgreSQL/PostGIS, SQLite/SpatiaLite, Oracle, MSSQL Spatial, SAP HANA,\nMySQL...\n•Web map and data services (WM(T)S, WFS, WCS, CSW, XYZ tiles, ArcGIS services, ...) are also handled\nby QGIS providers. SeeWorking with OGC / ISO protocolsfor more information about some of these.\n•You can read supported files from archived folders and use QGIS native formats such as QML files (QML -\nThe QGIS Style File Format\n) and virtual and memory layers.\nMore than 80 vector and 140 raster formats are supported byGDALand QGIS native providers.\nNote:Not all of the listed formats may work in QGIS for various reasons. For example, some require external\nproprietary libraries, or the GDAL/OGR installation of your OS may not have been built to support the format you\nwant to use. To see the list of available formats, run the command lineogrinfo --formats(for vector) and\ngdalinfo --formats(for raster), or check theSettings►Options►GDALmenu in QGIS.\nIn QGIS, depending on the data format, there are different tools to open a dataset, mainly available in theLayer►\nAdd Layer► menu or from theManage Layerstoolbar (enabled throughView►Toolbarsmenu). However, all these\ntools point to a unique dialog, theData Source Managerdialog, that you can open with the\nOpen Data Source Manager\nbutton, available on theData Source Manager Toolbar, or by pressingCtrl+L. TheData Source Managerdialog(\nFig.\n14.1) offers a unified interface to open vector or raster file-based data as well as databases or web services supported\nby QGIS. It can be set modal or not with theModeless data source manager dialogin theSettings►Options►\nGeneralmenu.\n377\n\nQGIS Desktop 3.22 User Guide\nFig. 14.1: QGIS Data Source Manager dialog\nBeside this main entry point, you also have theDB Managerplugin that offers advanced capabilities to analyze\nand manipulate connected databases. More information on DB Manager capabilities can be found inDB Manager\nPlugin.\nThere are many other tools, native or third-party plugins, that help you open various data formats.\nThis chapter will describe only the tools provided by default in QGIS for loading data. It will mainly focus on theData\nSource Managerdialog but more than describing each tab, it will also explore the tools based on the data provider or\nformat specificities.\n378Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n14.1.1The Browser Panel\nTheBrowseris one of the main ways to quickly and easily add your data to projects. It’s available as:\n•aData Source Managertab, enabled pressing the\nOpen Data Source Manager\nbutton (Ctrl+L);\n•as a QGIS panel you can open from the menuView►Panels(orSettings►Panels) or by pressingCtrl+2.\nIn both cases, theBrowserhelps you navigate in your file system and manage geodata, regardless the type of layer\n(raster, vector, table), or the datasource format (plain or compressed files, databases, web services).\nExploring the Interface\nAt the top of the Browser panel, you find some buttons that help you to:\n•\nAdd Selected Layers\n: you can also add data to the map canvas by selectingAddselectedlayer(s)from the layer’s\ncontext menu;\n•\nRefresh\nthe browser tree;\n•\nFilter Browser\nto search for specific data. Enter a search word or wildcard and the browser will filter the tree\nto only show paths to matching DB tables, filenames or folders – other data or folders won’t be displayed. See\nthe Browser Panel(2) example inFig. 14.2. The comparison can be case-sensitive or not. It can also be set to:\n–Normal: show items containing the search text\n–Wildcard(s): fine tune the search using the?and/or*characters to specify the position of the search text\n–Regular expression\n•\nCollapse All\nthe whole tree;\n•\nEnable/disable properties widget\n: when toggled on, a new widget is added at the bottom of the panel showing, if\napplicable, metadata for the selected item.\nThe entries in theBrowserpanel are organised hierarchically, and there are several top level entries:\n1.Favoriteswhere you can place shortcuts to often used locations\n2.Spatial Bookmarkswhere you can store often used map extents (seeSpatial Bookmarks)\n3.Project Home: for a quick access to the folder in which (most of) the data related to your project are stored.\nThe default value is the directory where your project file resides.\n4.Homedirectory in the file system and the filesystem root directory.\n5.Connected local or network drives\n6.Then comes a number of container / database types and service protocols, depending on your platform and\nunderlying libraries:\n•GeoPackage\n•SpatiaLite\n•PostGIS\n•MSSQL\n•Oracle\n•SAP HANA\n14.1. Opening Data379\n\nQGIS Desktop 3.22 User Guide\n•WMS/WMTS\n•Vector Tiles\n•XYZ Tiles\n•WCS\n•WFS/OGC API-Features\n•OWS\n•ArcGIS Map Service\n•ArcGIS Feature Service\n•GeoNode\nInteracting with the Browser items\nThe browser supports drag and drop within the browser, from the browser to the canvas andLayerspanel, and from\ntheLayerspanel to layer containers (e.g. GeoPackage) in the browser.\nProject file items inside the browser can be expanded, showing the full layer tree (including groups) contained within\nthat project. Project items are treated the same way as any other item in the browser, so they can be dragged and\ndropped within the browser (for example to copy a layer item to a geopackage file) or added to the current project\nthrough drag and drop or double click.\nThe context menu for an element in theBrowserpanel is opened by right-clicking on it.\nFor file system directory entries, the context menu offers the following:\n•New► to create in the selected entry a:\n–Directory...\n–GeoPackage...\n–ShapeFile...\n•Add as a Favorite: favorite folders can be renamed (Rename favorite...) or removed (Remove favorite) any\ntime.\n•Hide from Browser: hidden folders can be toggled to visible from theSettings►Options►Data Sources►\nHidden browser pathssetting\n•Fast Scan this Directory\n•Open Directory\n•Open in Terminal\n•Properties...\n•Directory Properties...\nFor leaf entries that can act as layers in the project, the context menu will have supporting entries. For example, for\nnon-database, non-service-based vector, raster and mesh data sources:\n•Export Layer►To File...\n•Add Layer to Project\n•Layer Properties\n•Manage►Rename “<name of file>”...orDelete “<name of file>”...\n•Show in Files\n380Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n•File Properties\nIn theLayer propertiesentry, you will find (similar to what you will find in thevectorandrasterlayer properties once\nthe layers have been added to the project):\n•Metadatafor the layer. Metadata groups:Information from provider(if possible,Pathwill be a hyperlink to\nthe source),Identification,Extent,Access,Fields(for vector layers),Bands(for raster layers),Contacts,Links\n(for vector layers),References(for raster layers),History.\n•APreviewpanel\n•The attribute table for vector sources (in theAttributespanel).\nTo add a layer to the project using theBrowser:\n1.Enable theBrowseras described above. A browser tree with your file system, databases and web services is\ndisplayed. You may need to connect databases and web services before they appear (see dedicated sections).\n2.Find the layer in the list.\n3.Use the context menu, double-click its name, or drag-and-drop it into themap canvas. Your layer is now added\nto the\nLayers paneland can be viewed on the map canvas.\nTip: Open a QGIS project directly from the browser\nYou can also open a QGIS project directly from the Browser panel by double-clicking its name or by drag-and-\ndrop into the map canvas.\nOnce a file is loaded, you can zoom around it using the map navigation tools. To change the style of a layer, open\ntheLayer Propertiesdialog by double-clicking on the layer name or by right-clicking on the name in the legend\nand choosingPropertiesfrom the context menu. See sectionSymbology Propertiesfor more information on setting\nsymbology for vector layers.\nRight-clicking an item in the browser tree helps you to:\n•for a file or a table, display its metadata or open it in your project. Tables can even be renamed, deleted or\ntruncated.\n•for a folder, bookmark it into your favourites or hide it from the browser tree. Hidden folders can be managed\nfrom theSettings►Options►Data Sourcestab.\n•manage yourspatial bookmarks: bookmarks can be created, exported and imported asXMLfiles.\n•create a connection to a database or a web service.\n•refresh, rename or delete a schema.\nYou can also import files into databases or copy tables from one schema/database to another with a simple drag-\nand-drop. There is a second browser panel available to avoid long scrolling while dragging. Just select the file and\ndrag-and-drop from one panel to the other.\n14.1. Opening Data381\n\nQGIS Desktop 3.22 User Guide\nFig. 14.2: QGIS Browser panels side-by-side\nTip: Add layers to QGIS by simple drag-and-drop from your OS file browser\nYou can also add file(s) to the project by drag-and-dropping them from your operating system file browser to the\nLayers Panelor the map canvas.\n14.1.2The DB Manager\nTheDB ManagerPlugin is another tool for integrating and managing spatial database formats supported by QGIS\n(PostGIS, SpatiaLite, GeoPackage, Oracle Spatial, MSSQL, Virtual layers). It can be activated from thePlugins►\nManage and Install Plugins...menu.\nThe\nDB Manager\nPlugin provides several features:\n•connect to databases and display their structure and contents\n•preview tables of databases\n•add layers to the map canvas, either by double-clicking or drag-and-drop.\n•add layers to a database from the QGIS Browser or from another database\n•create SQL queries and add their output to the map canvas\n•createvirtual layers\nMore information on DB Manager capabilities is found inDB Manager Plugin.\n382Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFig. 14.3: DB Manager dialog\n14.1.3Provider-based loading tools\nBeside the Browser Panel and the DB Manager, the main tools provided by QGIS to add layers, you’ll also find tools\nthat are specific to data providers.\nNote:Someexternal pluginsalso provide tools to open specific format files in QGIS.\nLoading a layer from a file\nTo load a layer from a file:\n1.Open the layer type tab in theData Source Managerdialog, ie click the\nOpen Data Source Manager\nbutton (or\npressCtrl+L) and enable the target tab or:\n•for vector data (like GML, ESRI Shapefile, Mapinfo and DXF layers): pressCtrl+Shift+V, select\ntheLayer►Add Layer►Add Vector Layermenu option or click on the\nAdd Vector Layer\ntoolbar\nbutton.\n14.1. Opening Data383\n\nQGIS Desktop 3.22 User Guide\nFig. 14.4: Add Vector Layer Dialog\n•for raster data (like GeoTiff, MBTiles, GRIdded Binary and DWG layers): pressCtrl+Shift+R,\nselect theLayer►Add Layer►Add Raster Layermenu option or click on the\nAdd Raster Layer\ntoolbar button.\nFig. 14.5: Add Raster Layer Dialog\n2.CheckFilesource type\n3.Click on the...\nBrowse\nbutton\n4.Navigate the file system and load a supported data source. More than one layer can be loaded at the same time\nby holding down theCtrlkey and clicking on multiple items in the dialog or holding down theShiftkey\nto select a range of items by clicking on the first and last items in the range. Only formats that have been well\ntested appear in the formats filter. Other formats can be loaded by selectingAll files(the top item in the\npull-down menu).\n5.PressOpento load the selected file intoData Source Managerdialog\n384Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFig. 14.6: Loading a Shapefile with open options\n6.PressAddto load the file in QGIS and display them in the map view.Fig. 14.7shows QGIS after loading the\nalaska.shpfile.\n14.1. Opening Data385\n\nQGIS Desktop 3.22 User Guide\nFig. 14.7: QGIS with Shapefile of Alaska loaded\nNote:For loading vector and raster files the GDAL driver offers to define open actions. These will be shown when a\nfile is selected. Options are described in detail onhttps://gdal.org/drivers/vector/,https://gdal.org/drivers/rasterand\nif a file is selected in QGIS, a text with hyperlink will directly lead to the documentation of the selected file type.\nNote:BecausesomeformatslikeMapInfo(e.g.,.tab)orAutocad(.dxf)allowmixingdifferenttypesofgeometry\nin a single file, loading such datasets opens a dialog to select geometries to use in order to have one geometry per\nlayer.\nThe\nAdd Vector Layer\nand\nAdd Raster Layer\ntabs allow loading of layers from source types other thanFile:\n•You can load specific vector formats likeArcInfo Binary Coverage,UK. National Transfer\nFormat, as well as the raw TIGER format of theUS Census BureauorOpenfileGDB. To do that,\nyou select\nDirectoryasSource type. In this case, a directory can be selected in the dialog after pressing...\nBrowse\n.\n•With theDatabasesource type you can select an existing database connection or create one to the selected\ndatabase type. Some possible database types areODBC,Esri Personal Geodatabase,MSSQLas\nwell asPostgreSQLorMySQL.\nPressing theNewbutton opens theCreate a New OGR Database Connectiondialog whose parameters are among\nthe ones you can find in\nCreating a stored Connection. PressingOpenlets you select from the available tables,\nfor example of PostGIS enabled databases.\n•TheProtocol: HTTP(S), cloud, etc.source type opens data stored locally or on the network, either publicly\naccessible, or in private buckets of commercial cloud storage services. Supported protocol types are:\n–HTTP/HTTPS/FTP, with aURIand, if required, anauthentication.\n–Cloud storage such asAWS S3,Google Cloud Storage,Microsoft Azure Blob,Alibaba\nOSS Cloud,Open Stack Swift Storage. You need to fill in theBucket or containerand the\nObject key.\n–service supporting OGCWFS 3(still experimental), usingGeoJSONorGEOJSON - Newline\nDelimitedformat or based onCouchDBdatabase. AURIis required, with optionalauthentication.\n–For all vector source types it is possible to define theEncodingor to use theAutomatic► setting.\n386Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nLoading a mesh layer\nA mesh is an unstructured grid usually with temporal and other components. The spatial component contains a\ncollection of vertices, edges and faces in 2D or 3D space. More information on mesh layers atWorking with Mesh\nData\n.\nTo add a mesh layer to QGIS:\n1.Open theData Source Managerdialog, either by selecting it from theLayer► menu or clicking the\nOpen Data Source Manager\nbutton.\n2.Enable theMeshtab on the left panel\n3.Press the...\nBrowse\nbutton to select the file.Various formatsare supported.\n4.Select the file and pressAdd. The layer will be added using the native mesh rendering.\n5.If the selected file contains many mesh layers, then you’ll be prompted with a dialog to choose the sublayers\nto load. Do your selection and pressOKand the layers are loaded with the native mesh rendering. It’s also\npossible to load them within a group.\nFig. 14.8: Mesh tab in Data Source Manager\nImporting a delimited text file\nDelimited text files (e.g..txt,.csv,.dat,.wkt) can be loaded using the tools described above. This way, they\nwill show up as simple tables. Sometimes, delimited text files can contain coordinates / geometries that you could\nwant to visualize. This is whatAdd Delimited Text Layeris designed for.\n1.Click the\nOpen Data Source Manager\nicon to open the\nData Source Manager\ndialog\n2.Enable theDelimited Texttab\n3.Select the delimited text file to import (e.g.,qgis_sample_data/csv/elevp.csv) by clicking on the\n...\nBrowse\nbutton.\n4.In theLayer namefield, provide the name to use for the layer in the project (e.g.Elevation).\n5.Configure the settings to meet your dataset and needs, as explained below.\n14.1. Opening Data387\n\nQGIS Desktop 3.22 User Guide\nFig. 14.9: Delimited Text Dialog\nFile format\nOnce the file is selected, QGIS attempts to parse the file with the most recently used delimiter, identifying fields\nand rows. To enable QGIS to correctly parse the file, it is important to select the right delimiter. You can specify a\ndelimiter by choosing between:\n•CSV (comma separated values)to use the comma character.\n•Regular expression delimiterand enter text into theExpressionfield. For example, to change the delimiter\nto tab, use\\t(this is used in regular expressions for the tab character).\n•Custom delimiters, choosing among some predefined delimiters likecomma,space,tab,semicolon,\n... .\n388Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nRecords and fields\nSome other convenient options can be used for data recognition:\n•Number of header lines to discard: convenient when you want to avoid the first lines in the file in the import,\neither because those are blank lines or with another formatting.\n•First record has field names: values in the first line are used as field names, otherwise QGIS uses the field\nnamesfield_1,field_2...\n•Detect field types: automatically recognizes the field type. If unchecked then all attributes are treated as text\nfields.\n•Decimal separator is comma: you can force decimal separator to be a comma.\n•Trim fields: allows you to trim leading and trailing spaces from fields.\n•Discard empty fields.\nAs you set the parser properties, a sample data preview updates at the bottom of the dialog.\nGeometry definition\nOnce the file is parsed, setGeometry definitionto\n•Point coordinatesand provide theX field,Y field,Z field(for 3-dimensional data) andM field(for the\nmeasurement dimension) if the layer is of point geometry type and contains such fields. If the coordinates\nare defined as degrees/minutes/seconds, activate theDMS coordinatescheckbox. Provide the appropriate\nGeometry CRSusing the\nSelect CRS\nwidget.\n•Well known text (WKT)option if the spatial information is represented as WKT: select theGeometry field\ncontaining the WKT geometry and choose the approriateGeometry fieldor let QGIS auto-detect it. Provide\nthe appropriateGeometry CRSusing the\nSelect CRS\nwidget.\n•If the file contains non-spatial data, activateNo geometry (attribute only table)and it will be loaded as an\nordinary table.\nLayer settings\nAdditionally, you can enable:\n•Use spatial indexto improve the performance of displaying and spatially selecting features.\n•Use subset indexto improve performance ofsubset filters(when defined in the layer properties).\n•Watch fileto watch for changes to the file by other applications while QGIS is running.\nAt the end, clickAddto add the layer to the map. In our example, a point layer namedElevationis added to\nthe project and behaves like any other map layer in QGIS. This layer is the result of a query on the.csvsource file\n(hence, linked to it) and would requireto be savedin order to get a spatial layer on disk.\n14.1. Opening Data389\n\nQGIS Desktop 3.22 User Guide\nImporting a DXF or DWG file\nDXFandDWGfiles can be added to QGIS by simple drag-and-drop from the Browser Panel. You will be prompted\nto select the sublayers you would like to add to the project. Layers are added with random style properties.\nNote:For DXF files containing several geometry types (point, line and/or polygon), the name of the layers will be\ngenerated as<filename.dxf> entities <geometry type>.\nTo keep the dxf/dwg file structure and its symbology in QGIS, you may want to use the dedicatedProject►Im-\nport/Export►Import Layers from DWG/DXF...tool which allows you to:\n1.import elements from the drawing file into a GeoPackage database.\n2.add imported elements to the project.\nIn theDWG/DXF Importdialog, to import the drawing file contents:\n1.Input the location of theTarget package, i.e. the new GeoPackage file that will store the data. If an existing\nfile is provided, then it will be overwritten.\n2.Specify the coordinate reference system of the data in the drawing file.\n3.CheckExpand block referencesto import the blocks in the drawing file as normal elements.\n4.CheckUse curvesto promote the imported layers to acurvedgeometry type.\n5.Use theImportbutton to select the DWG/DXF file to use (one per geopackage). The GeoPackage database\nwill be automatically populated with the drawing file content. Depending on the size of the file, this can take\nsome time.\nAfter the.dwgor.dxfdata has been imported into the GeoPackage database, the frame in the lower half of the\ndialog is populated with the list of layers from the imported file. There you can select which layers to add to the QGIS\nproject:\n1.At the top, set aGroup nameto group the drawing files in the project.\n2.Check layers to show: Each selected layer is added to an ad hoc group which contains vector layers for the\npoint, line, label and area features of the drawing layer. The style of the layers will resemble the look they\noriginally had in *CAD.\n3.Choose if the layer should be visible at opening.\n4.Checking theMerge layersoption places all layers in a single group.\n5.PressOKto open the layers in QGIS.\n390Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFig. 14.10: Import dialog for DWG/DXF files\nImporting OpenStreetMap Vectors\nThe OpenStreetMap project is popular because in many countries no free geodata such as digital road maps are\navailable. The objective of the OSM project is to create a free editable map of the world from GPS data, aerial\nphotography and local knowledge. To support this objective, QGIS provides support for OSM data.\nUsing theBrowser Panel, you can load an.osmfile to the map canvas, in which case you’ll get a dialog to select\nsublayers based on the geometry type. The loaded layers will contain all the data of that geometry type in the.osm\nfile, and keep theosmfile data structure.\nSpatiaLite Layers\nThe first time you load data from a SpatiaLite database, begin by:\n•clicking on the\nAdd SpatiaLite Layer\ntoolbar button\n•selecting theAdd SpatiaLite Layer...option from theLayer►Add Layermenu\n•or by typingCtrl+Shift+L\nThis will bring up a window that will allow you either to connect to a SpatiaLite database already known to QGIS\n(which you choose from the drop-down menu) or to define a new connection to a new database. To define a new\n14.1. Opening Data391\n\nQGIS Desktop 3.22 User Guide\nconnection, click onNewand use the file browser to point to your SpatiaLite database, which is a file with a.sqlite\nextension.\nQGIS also supports editable views in SpatiaLite.\nGPS\nThere are dozens of different file formats for storing GPS data. The format that QGIS uses is called GPX (GPS\neXchange format), which is a standard interchange format that can contain any number of waypoints, routes and\ntracks in the same file.\nUse the...\nBrowse\nbutton to select the GPX file, then use the checkboxes to select the feature types you want to load\nfrom that GPX file. Each feature type will be loaded in a separate layer.\nFig. 14.11: Loading GPS Data dialog\nGRASS\nWorking with GRASS vector data is described in sectionGRASS GIS Integration.\nDatabase related tools\nCreating a stored Connection\nIn order to read and write tables from a database format QGIS supports you have to create a connection to that\ndatabase. WhileQGIS Browser Panelis the simplest and recommanded way to connect to and use databases, QGIS\nprovides other tools to connect to each of them and load their tables:\n•Add PostGIS Layer...or by typingCtrl+Shift+D\n•Add MSSQL Spatial Layer\n•Add Oracle Spatial Layer...or by typingCtrl+Shift+O\n•Add SAP HANA Spatial Layer...or by typingCtrl+Shift+G\nThese tools are accessible either from theManage Layers Toolbarand theLayer►Add Layer► menu. Connecting\nto SpatiaLite database is described atSpatiaLite Layers.\nTip: Create connection to database from the QGIS Browser Panel\n392Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nSelecting the corresponding database format in the Browser tree, right-clicking and choosing connect will provide\nyou with the database connection dialog.\nMost of the connection dialogs follow a common basis that will be described below using the PostgreSQL database\ntool as an example. For additional settings specific to other providers, you can find corresponding descriptions at:\n•Connecting to MSSQL Spatial;\n•Connecting to Oracle Spatial;\n•Connecting to SAP HANA.\nThe first time you use a PostGIS data source, you must create a connection to a database that contains the data. Begin\nby clicking the appropriate button as exposed above, opening anAdd PostGIS Table(s)dialog (seeFig. 14.14). To\naccess the connection manager, click on theNewbutton to display theCreate a New PostGIS Connectiondialog.\n14.1. Opening Data393\n\nQGIS Desktop 3.22 User Guide\nFig. 14.12: Create a New PostGIS Connection Dialog\n394Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nThe parameters required for a PostGIS connection are explained below. For the other database types, see their\ndifferences atParticular Connection requirements.\n•Name: A name for this connection. It can be the same asDatabase.\n•Service: Service parameter to be used alternatively to hostname/port (and potentially database). This can be\ndefined inpg_service.conf. Check thePostgreSQL Service connection filesection for more details.\n•Host: Name of the database host. This must be a resolvable host name such as would be used to open a TCP/IP\nconnection or ping the host. If the database is on the same computer as QGIS, simply enterlocalhosthere.\n•Port: Port number the PostgreSQL database server listens on. The default port for PostGIS is5432.\n•Database: Name of the database.\n•SSL mode: SSL encryption setup The following options are available:\n–Prefer(the default): I don’t care about encryption, but I wish to pay the overhead of encryption if the\nserver supports it.\n–Require: I want my data to be encrypted, and I accept the overhead. I trust that the network will make\nsure I always connect to the server I want.\n–Verify CA: I want my data encrypted, and I accept the overhead. I want to be sure that I connect to a\nserver that I trust.\n–Verify Full: I want my data encrypted, and I accept the overhead. I want to be sure that I connect to a\nserver I trust, and that it’s the one I specify.\n–Allow: I don’t care about security, but I will pay the overhead of encryption if the server insists on it.\n–Disable: I don’t care about security, and I don’t want to pay the overhead of encryption.\n•Authentication, basic.\n–User name: User name used to log in to the database.\n–Password: Password used withUsernameto connect to the database.\nYou can save any or both of theUser nameandPasswordparameters, in which case they will be used\nby default each time you need to connect to this database. If not saved, you’ll be prompted to supply the\ncredentials to connect to the database in next QGIS sessions. The connection parameters you entered are\nstored in a temporary internal cache and returned whenever a username/password for the same database is\nrequested, until you end the current QGIS session.\nWarning: QGIS User Settings and Security\nIn theAuthenticationtab, savingusernameandpasswordwill keep unprotected credentials in the con-\nnection configuration. Those\ncredentials will be visible\nif, for instance, you share the project file with\nsomeone. Therefore, it is advisable to save your credentials in anAuthentication configurationinstead (Con-\nfigurationstab - SeeAuthentication Systemfor more details) or in a service connection file (seePostgreSQL\nService connection filefor example).\n•Authentication, configurations. Choose an authentication configuration. You can add configurations using the\nbutton. Choices are:\n–Basic authentication\n–PKI PKCS#12 authentication\n–PKI paths authentication\n–PKI stored identity certificate\nOptionally, depending on the type of database, you can activate the following checkboxes:\n•Only show layers in the layer registries\n14.1. Opening Data395\n\nQGIS Desktop 3.22 User Guide\n•Don’t resolve type of unrestricted columns (GEOMETRY)\n•Only look in the ‘public’ schema\n•Also list tables with no geometry\n•Use estimated table metadata\n•Allow saving/loading QGIS projects in the database- more detailshere\nTip: Use estimated table metadata to speed up operations\nWhen initializing layers, various queries may be needed to establish the characteristics of the geometries stored in\nthe database table. When theUse estimated table metadataoption is checked, these queries examine only a sample\nof the rows and use the table statistics, rather than the entire table. This can drastically speed up operations on large\ndatasets, but may result in incorrect characterization of layers (e.g. the feature count of filtered layers will not be\naccurately determined) and may even cause strange behaviour if columns that are supposed to be unique actually are\nnot.\nOnce all parameters and options are set, you can test the connection by clicking theTest Connectionbutton or apply\nit by clicking the\nOK\nbutton. From\nAdd PostGIS Table(s)\n, click now on\nConnect\n, and the dialog is filled with tables\nfrom the selected database (as shown inFig. 14.14).\nParticular Connection requirements\nBecause of database type particularities, provided options are not the same. Database specific options are described\nbelow.\nPostgreSQL Service connection file\nThe service connection file allows PostgreSQL connection parameters to be associated with a single service name.\nThat service name can then be specified by a client and the associated settings will be used.\nIt’s called.pg_service.confunder *nix systems (GNU/Linux, macOS etc.) andpg_service.confon\nWindows.\nThe service file can look like this:\n[water_service]\nhost=192.168.0.45\nport=5433\ndbname=gisdb\nuser=paul\npassword=paulspass\n[wastewater_service]\nhost\n=dbserver.com\ndbname=water\nuser\n=waterpass\nNote:There are two services in the above example:water_serviceandwastewater_service. You can\nuse these to connect from QGIS, pgAdmin, etc. by specifying only the name of the service you want to connect to\n(without the enclosing brackets). If you want to use the service withpsqlyou need to do something likeexport\nPGSERVICE=water_servicebefore doing your psql commands.\nYou can find all the PostgreSQL parameters\nhere\n396Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nNote:If you don’t want to save the passwords in the service file you can use the.pg_passoption.\nOn *nix operating systems (GNU/Linux, macOS etc.) you can save the.pg_service.conffile in the user’s\nhome directory and PostgreSQL clients will automatically be aware of it. For example, if the logged user isweb,\n.pg_service.confshould be saved in the/home/web/directory in order to directly work (without specifying\nany other environment variables).\nYou can specify the location of the service file by creating aPGSERVICEFILEenvironment variable (e.g. run the\nexport PGSERVICEFILE=/home/web/.pg_service.confcommand under your *nix OS to temporar-\nily set thePGSERVICEFILEvariable)\nYou can also make the service file available system-wide (all users) either by placing the.pg_service.conffile\ninpg_config --sysconfdiror by adding thePGSYSCONFDIRenvironment variable to specify the directory\ncontaining the service file. If service definitions with the same name exist in the user and the system file, the user file\ntakes precedence.\nWarning:There are some caveats under Windows:\n•The service file should be saved aspg_service.confand not as.pg_service.conf.\n•The service file should be saved in Unix format in order to work. One way to do it is to open it with\nNotepad++andEdit►EOL Conversion►UNIX Format►File save.\n•You can add environmental variables in various ways; a tested one, known to work reliably, isControl Panel\n►System and Security►System►Advanced system settings►Environment VariablesaddingPGSER-\nVICEFILEwith the path - e.g.C:\\Users\\John\\pg_service.conf\n•After adding an environment variable you may also need to restart the computer.\nConnecting to Oracle Spatial\nThe spatial features in Oracle Spatial aid users in managing geographic and location data in a native type within an\nOracle database. In addition to some of the options in\nCreating a stored Connection, the connection dialog proposes:\n•Database: SID or SERVICE_NAME of the Oracle instance;\n•Port: Port number the Oracle database server listens on. The default port is1521;\n•Options:Oracle  connection  specific  options  (e.g.OCI_ATTR_PREFETCH_ROWS,\nOCI_ATTR_PREFETCH_MEMORY). The format of the options string is a semicolon separated list\nof option names or option=value pairs;\n•Workspace: Workspace to switch to;\n•Schema: Schema in which the data are stored\nOptionally, you can activate the following checkboxes:\n•Only  look  in  metadata  table:   restricts  the  displayed  tables  to  those  that  are  in  the\nall_sdo_geom_metadataview. This can speed up the initial display of spatial tables.\n•Only look for user’s tables: when searching for spatial tables, restricts the search to tables that are owned\nby the user.\n•Also list tables with no geometry: indicates that tables without geometry should also be listed by default.\n•Use estimated table statistics for the layer metadata\n: when the layer is set up, various metadata are required\nfor the Oracle table. This includes information such as the table row count, geometry type and spatial extents\nof the data in the geometry column. If the table contains a large number of rows, determining this meta-\ndata can be time-consuming. By activating this option, the following fast table metadata operations are done:\nRow count is determined fromall_tables.num_rows. Table extents are always determined with the\n14.1. Opening Data397\n\nQGIS Desktop 3.22 User Guide\nSDO_TUNE.EXTENTS_OF function, even if a layer filter is applied. Table geometry is determined from the\nfirst 100 non-null geometry rows in the table.\n•Only existing geometry types: only lists the existing geometry types and don’t offer to add others.\n•Include additional geometry attributes.\nTip: Oracle Spatial Layers\nNormally, an Oracle Spatial layer is defined by an entry in theUSER_SDO_METADATAtable.\nTo ensure that selection tools work correctly, it is recommended that your tables have aprimary key.\nConnecting to MSSQL Spatial\nIn addition to some of the options inCreating a stored Connection, creating a new MSSQL connection dialog proposes\nyou to fill aProvider/DSNname. You can also display available databases.\nConnecting to SAP HANA\nNote:You require the SAP HANA Client to connect to a SAP HANA database. You can download the SAP HANA\nClient for your platform at the\nSAP Development Tools website.\n398Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFig. 14.13: Create a New SAP HANA Connection Dialog\n14.1. Opening Data399\n\nQGIS Desktop 3.22 User Guide\nThe following parameters can be entered:\n•Name: A name for this connection.\n•Driver: The name of the HANA ODBC driver. It isHDBODBCif you are using 64-bit QGIS,HDBODBC32\nif you are using 32-bit QGIS. The appropriate driver name is entered automatically.\n•Driver: Either the name under which the SAP HANA ODBC driver has been registered in/etc/\nodbcinst.inior the full path to the SAP HANA ODBC driver. The SAP HANA Client installer will\ninstall the ODBC driver to/usr/sap/hdbclient/libodbcHDB.soby default.\n•Host: The name of the database host.\n•Identifier: Identifies the instance to connect to on the host. This can be eitherInstance NumberorPort Number.\nInstance numbers consist of two digits, port numbers are in the range from 1 to 65,535.\n•Mode: Specifies the mode in which the SAP HANA instance runs. This setting is only taken into account if\nIdentifier\nis set to\nInstance Number\n. If the database hosts multiple containers, you can either connect to a tenant\nwith the name given atTenant databaseor you can connect to the system database.\n•Schema: This parameter is optional. If a schema name is given, QGIS will only search for data in that schema.\nIf this field is left blank, QGIS will search for data in all schemas.\n•Authentication►Basic.\n–User name: User name used to connect to the database.\n–Password: Password used to connect to the database.\n•SSL Settings\n–Enable TLS/SSL encryption: Enables TLS 1.1 - TLS1.2 encryption. The server will choose the highest\navailable.\n–Provider: Specifies the cryptographic library provider used for SSL communication.sapcryptoshould\nwork on all platforms,opensslshould work on,mscryptoshould work onandcommoncrypto\nrequires CommonCryptoLib to be installed.\n–Validate SSL certificate: If checked, the SSL certificate will be validated using the truststore given in\nTrust store file with public key.\n–Override hostname in certificate: Specifies the host name used to verify server’s identity. The host name\nspecified here verifies the identity of the server instead of the host name with which the connection\nwas established. If you specify*as the host name, then the server’s host name is not validated. Other\nwildcards are not permitted.\n–Keystore file with private key: Currently ignored. This parameter might allow to authenticate via certificate\ninstead via user and password in future.\n–Trust store file with public key: Specifies the path to a trust store file that contains the server’s public\ncertificates if using OpenSSL. Typically, the trust store contains the root certificate or the certificate of\nthe certification authority that signed the server’s public certificates. If you are using the cryptographic\nlibrary CommonCryptoLib or msCrypto, then leave this property empty.\n•Only look for user’s tables: If checked, QGIS searches only for tables and views that are owned by the user\nthat connects to the database.\n•Also list tables with no geometries: If checked, QGIS searches also for tables and views that do not contain\na spatial column.\nTip: Connecting to SAP HANA Cloud\nIf you’d like to connect to an SAP HANA Cloud instance, you usually must setPort Numberto443and checkEnable\nTLS/SSL encryption.\n400Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nLoading a Database Layer\nOnce you have one or more connections defined to a database (see sectionCreating a stored Connection), you can\nload layers from it. Of course, this requires that data are available. See sectionImporting Data into PostgreSQLfor a\ndiscussion on importing data into a PostGIS database.\nTo load a layer from a database, you can perform the following steps:\n1.Open the “Add <database> table(s)” dialog (seeCreating a stored Connection).\n2.Choose the connection from the drop-down list and clickConnect.\n3.Select or unselectAlso list tables with no geometry.\n4.Optionally, use someSearch Optionsto reduce the list of tables to those matching your search. You can\nalso set this option before you hit theConnectbutton, speeding up the database fetching.\n5.Find the layer(s) you wish to add in the list of available layers.\n6.Select it by clicking on it. You can select multiple layers by holding down theShiftorCtrlkey while\nclicking.\n7.If applicable, use theSet Filterbutton (or double-click the layer) to start theQuery Builderdialog (see section\nQuery Builder) and define which features to load from the selected layer. The filter expression appears in the\nsqlcolumn. This restriction can be removed or edited in theLayer Properties►General►Provider Feature\nFilterframe.\n8.The checkbox in theSelect at idcolumn that is activated by default gets the feature ids without the\nattributes and generally speeds up the data loading.\n9.Click on theAddbutton to add the layer to the map.\nFig. 14.14: Add PostGIS Table(s) Dialog\nTip: Use the Browser Panel to speed up loading of database table(s)\nAdding DB tables from theData Source Managermay sometimes be time consuming as QGIS fetches statistics and\nproperties (e.g. geometry type and field, CRS, number of features) for each table beforehand. To avoid this, oncethe\n14.1. Opening Data401\n\nQGIS Desktop 3.22 User Guide\nconnection is set, it is better to use theBrowser Panelor theDB Managerto drag and drop the database tables into\nthe map canvas.\n14.1.4QGIS Custom formats\nQGIS proposes two custom formats:\n•Temporary Scratch Layer: a memory layer that is bound to the project (seeCreating a new Temporary Scratch\nLayerfor more information)\n•Virtual Layers: a layer resulting from a query on other layer(s) (seeCreating virtual layersfor more information)\n14.1.5QLR - QGIS Layer Definition File\nLayer definitions can be saved as aLayer Definition File(QLR -.qlr) usingExport►Save As Layer Definition\nFile...in the layer context menu.\nThe QLR format makes it possible to share “complete” QGIS layers with other QGIS users. QLR files contain links\nto the data sources and all the QGIS style information necessary to style the layer.\nQLR files are shown in the Browser Panel and can be used to add layers (with their saved styles) to the Layers Panel.\nYou can also drag and drop QLR files from the system file manager into the map canvas.\n14.1.6Connecting to web services\nWith QGIS you can get access to different types of OGC web services (WM(T)S, WFS(-T), WCS, CSW, ...). Thanks\nto QGIS Server, you can also publish such services. QGIS-Server-manual contains descriptions of these capabilities.\nUsing Vector Tiles services\nVector Tile services can be added via theVector Tilestab of theData Source Managerdialog or the contextual\nmenu of theVector Tilesentry in theBrowserpanel. Services can be either aNew Generic Connection...or aNew\nArcGIS Vector Tile Service Connection....\nYou set up a service by adding:\n•aName\n•theURL: of the typehttp://example.com/{z}/{x}/{y}.pbffor generic services andhttp:/\n/example.com/arcgis/rest/services/Layer/VectorTileServerfor ArcGIS based ser-\nvices. The service must provide tiles in.pbfformat.\n•theMin. Zoom Leveland theMax. Zoom Level. Vector Tiles have a pyramid structure. By using these\noptions you have the opportunity to individually generate layers from the tile pyramid. These layers will then\nbe used to render the Vector Tile in QGIS.\nFor Mercator projection (used by OpenStreetMap Vector Tiles) Zoom Level 0 represents the whole world at a\nscale of 1:500.000.000. Zoom Level 14 represents the scale 1:35.000.\n•aStyle URL: a URL to a MapBox GL JSON style configuration. If provided, then that style will be applied\nwhenever the layers from the connection are added to QGIS. In the case of Arcgis vector tile service connec-\ntions, the URL overrides the default style configuration specified in the server configuration.\n•theauthenticationconfiguration if necessary\n•aReferer\n402Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFig. 14.15shows the dialog with the MapTiler planet Vector Tiles service configuration.\nFig. 14.15: Vector Tiles - Maptiler Planet configuration\nConfigurations can be saved to.XMLfile (Save Connections) through theVector Tilesentry inData Source Manager\ndialog or its context menu in theBrowserpanel. Likewise, they can be added from a file (Load Connections).\nOnce a connection to a vector tile service is set, it’s possible to:\n•Editthe vector tile connection settings\n•Removethe connection\n•From theBrowserpanel, right-click over the entry and you can also:\n–Add layer to project: a double-click also adds the layer\n–View theLayer Properties...and get access to metadata and a preview of the data provided by the service.\nMore settings are available when the layer has been loaded into the project.\nUsing XYZ Tile services\nXYZ Tile services can be added via theXYZtab of theData Source Managerdialog or the contextual menu of\ntheXYZ Tilesentry in theBrowserpanel. PressNew(respectivelyNew Connection) and provide:\n•aName\n•theURL\n•theauthenticationconfiguration if necessary\n•theMin. Zoom levelandMax. Zoom level\n14.1. Opening Data403\n\nQGIS Desktop 3.22 User Guide\n•aReferer\n•theTile Resolution: possible values areUnknown (not scaled),Standard (256x256 / 96DPI)andHigh (512x512\n/ 192DPI)\nBy default, the OpenStreetMap XYZ Tile service is configured.Fig. 14.16shows the dialog with the OpenStreetMap\nXYZ Tile service configuration.\nFig. 14.16: XYZ Tiles - OpenStreetMap configuration\nConfigurations can be saved to.XMLfile (Save Connections) through theXYZ Tilesentry inData Source Manager\ndialog or its context menu in theBrowserpanel. Likewise, they can be added from a file (Load Connections).\nThe XML file for OpenStreetMap looks like this:\n<!DOCTYPE connections>\n<qgsXYZTilesConnectionsversion=\"1.0\">\n<xyztilesurl=\"https://tile.openstreetmap.org/{z}/{x}/{y}.png\"\nzmin=\"0\"zmax=\"19\"tilePixelRatio=\"0\"password=\"\"name=\"OpenStreetMap\"\nusername=\"\"authcfg=\"\"referer=\"\"/>\n</qgsXYZTilesConnections>\n404Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nOnce a connection to a XYZ tile service is set, it’s possible to:\n•Editthe XYZ connection settings\n•Removethe connection\n•From theBrowserpanel, right-click over the entry and you can also:\n–Export layer...►To File,saving it as a raster\n–Add layer to project: a double-click also adds the layer\n–View theLayer Properties...and get access to metadata and a preview of the data provided by the service.\nMore settings are available when the layer has been loaded into the project.\nExamples of XYZ Tile services:\n•OpenStreetMap Monochrome:URL:http://tiles.wmflabs.org/bw-mapnik/{z}/{x}/{y}.\npng,Min. Zoom Level: 0,Max. Zoom Level: 19.\n•Google Maps:URL:https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z},Min. Zoom\nLevel: 0,Max. Zoom Level: 19.\n•Open Weather Map Temperature:URL:http://tile.openweathermap.org/map/temp_new/\n{z}/{x}/{y}.png?appid={api_key}Min. Zoom Level: 0,Max. Zoom Level: 19.\nUsing ArcGIS REST Servers\nArcGIS REST Servers can be added via theArcGIS REST Servertab of theData Source Managerdialog or the\ncontextual menu of theArcGIS REST Serversentry in theBrowserpanel. PressNew(respectivelyNew Connection)\nand provide:\n•aName\n•theURL\n•aCommunity endpoint URL\n•aContent endpoint URL\n•theauthenticationconfiguration if necessary\n•aReferer\nNote:ArcGIS Feature Service connections which have their corresponding Portal endpoint URLS set can be ex-\nplored by content groups in the browser panel.\nIf a connection has the Portal endpoints set, then expanding out the connection in the browser will show a “Groups”\nand “Services” folder, instead of the full list of services usually shown. Expanding out the groups folder will show\na list of all content groups that the user is a member of, each of which can be expanded to show the service items\nbelonging to that group.\nConfigurations can be saved to.XMLfile (Save Connections) through theArcGIS REST Serverentry inData Source\nManagerdialog. Likewise, they can be added from a file (Load Connections).\nOnce a connection to an ArcGIS REST Server is set, it’s possible to:\n•Editthe ArcGIS REST Server connection settings\n•Removethe connection\n•Refreshthe connection\n•use a filter for the available layers\n•choose from a list of available layers with the option toOnly request features overlapping the current view\nextent\n14.1. Opening Data405\n\nQGIS Desktop 3.22 User Guide\n•From theBrowserpanel, right-click over the connection entry and you can:\n–Refresh\n–Edit connection...\n–Delete connection...\n–View Service Infowhich will open the default web browser and display the Service Info.\n•Right-click over the layer entry and you can also:\n–View Service Infowhich will open the default web browser and display the Service Info.\n–Export layer...►To File\n–Add layer to project: a double-click also adds the layer\n–View theLayer Properties...and get access to metadata and a preview of the data provided by the service.\nMore settings are available when the layer has been loaded into the project.\n14.2Creating Layers\nLayers can be created in many ways, including:\n•empty layers from scratch\n•layers from existing layers\n•layers from the clipboard\n•layers as a result of an SQL-like query based on one or many layers (virtual layers)\nQGIS also provides tools to import/export from/to different formats.\n14.2.1Creating new vector layers\nQGIS allows you to create new layers in different formats. It provides tools for creating GeoPackage, Shapefile,\nSpatiaLite, GPX format and Temporary Scratch layers (aka memory layers). Creation of anew GRASS layeris\nsupported within the GRASS plugin.\nCreating a new GeoPackage layer\nTo create a new GeoPackage layer, press theNew GeoPackage Layer...button in theLayer►Create Layer►\nmenu or from theData Source Managertoolbar. TheNew GeoPackage Layerdialog will be displayed as shown in\nFig. 14.17.\n406Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFig. 14.17: Creating a New GeoPackage layer dialog\n1.The first step is to indicate the database file location. This can be done by pressing the...button to the right\nof theDatabasefield and select an existing GeoPackage file or create a new one. QGIS will automatically add\nthe right extension to the name you provide.\n2.Give the new layer / table a name (Table name)\n3.Define theGeometry type. If not a geometryless layer, you can specify whether it shouldInclude Z dimension\nand/orInclude M values.\n4.Specify the coordinate reference system using thebutton\nTo add fields to the layer you are creating:\n1.Enter theNameof the field\n2.Select the dataType. Supported types areText data,Whole number(both integer and integer64),Decimal\nnumber\n,\nDate\nand\nDate and time\n,\nBinary (BLOB)\nand\nBoolean\n.\n3.Depending on the selected data format, enter theMaximum lengthof values.\n4.Click on theAdd to Fields Listbutton\n5.Reproduce the steps above for each field you need to add\n14.2. Creating Layers407\n\nQGIS Desktop 3.22 User Guide\n6.Once you are happy with the attributes, clickOK. QGIS will add the new layer to the legend, and you can edit\nit as described in sectionDigitizing an existing layer.\nBy default, when creating a GeoPackage layer, QGIS generates aFeature id columncalledfidwhich acts as the\nprimary key of the layer. The name can be changed. The geometry field, if availabe, is namedgeometry, and you\ncan choose toCreate a spatial indexon it. These options can be found under theAdvanced Optionstogether with the\nLayer identifier(short human readable name of the layer) and theLayer description.\nFurther management of GeoPackage layers can be done with theDB Manager.\nCreating a new Shapefile layer\nTo create a new ESRI Shapefile format layer, press theNew Shapefile Layer...button in theLayer►Create Layer\n► menu or from theData Source Managertoolbar. TheNew Shapefile Layerdialog will be displayed as shown in\nFig. 14.18.\n1.Provide a path and file name using the...button next toFile name. QGIS will automatically add the right\nextension to the name you provide.\n2.Next, indicate theFile encodingof the data\n3.Choose theGeometry typeof the layer: No Geometry (resulting in a.DBFformat file), point, multipoint, line\nor polygon\n4.Specify whether the geometry should have additional dimensions:None,Z (+ M values)orM values\n5.Specify the coordinate reference system using thebutton\nFig. 14.18: Creating a new Shapefile layer dialog\nTo add fields to the layer you are creating:\n1.Enter theNameof the field\n408Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n2.Select the dataType. OnlyDecimal number,Whole number,Text dataandDateattributes are supported.\n3.Depending on the selected data format, enter theLengthandPrecision.\n4.Click on theAdd to Fields Listbutton\n5.Reproduce the steps above for each field you need to add\n6.Once you are happy with the attributes, clickOK. QGIS will add the new layer to the legend, and you can edit\nit as described in sectionDigitizing an existing layer.\nBy default, a first integeridcolumn is added but can be removed.\nCreating a new SpatiaLite layer\nTo create a new SpatiaLite layer, press theNew SpatiaLite Layer...button in theLayer►Create Layer► menu\nor from theData Source Managertoolbar. TheNew SpatiaLite Layerdialog will be displayed as shown inFig. 14.19.\nFig. 14.19: Creating a New SpatiaLite layer dialog\n1.The first step is to indicate the database file location. This can be done by pressing the...button to the right of\ntheDatabasefield and select an existing SpatiaLite file or create a new one. QGIS will automatically add the\nright extension to the name you provide.\n2.Provide a name (Layer name) for the new layer\n3.Define theGeometry type. If not a geometryless layer, you can specify whether it shouldInclude Z dimension\nand/orInclude M values.\n14.2. Creating Layers409\n\nQGIS Desktop 3.22 User Guide\n4.Specify the coordinate reference system using thebutton.\nTo add fields to the layer you are creating:\n1.Enter theNameof the field\n2.Select the dataType. Supported types areText data,Whole number,Decimal number,DateandDate time.\n3.Click on theAdd to Fields Listbutton\n4.Reproduce the steps above for each field you need to add\n5.Once you are happy with the attributes, clickOK. QGIS will add the new layer to the legend, and you can edit\nit as described in sectionDigitizing an existing layer.\nIf desired, you can selectCreate an autoincrementing primary keyunder the guilabel:Advanced Optionssection.\nYou can also rename theGeometry column(geometryby default).\nFurther management of SpatiaLite layers can be done withDB Manager.\nCreating a new Mesh layer\nTo create a new Mesh layer, press theNew Mesh Layer...button in theLayer►Create Layer► menu or from\ntheData Source Managertoolbar. TheNew Mesh Layerdialog will be displayed as shown inFig. 14.20.\nFig. 14.20: Creating a New Mesh layer dialog\n410Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n1.The first step is to indicate the mesh file location. This can be done by pressing the...button to the right of the\nFile namefield and select an existing mesh file or create a new one.\n2.Provide a name (Layer name), i.e. the name the layer is displayed with in theLayerspanel\n3.Select theFile format: currently supported mesh file formats are2DM Mesh File (*.2dm),Selafin\nFile (*.slf)andUGRID (*.nc).\n4.Indicate theCoordinate Reference Systemto assign to the dataset\n5.The above steps will generate an empty layer that you can afterwards digitize vertices and add dataset groups\nto. It’s however also possible to initialize the layer with an existing mesh layer, i.e. populate the new layer with\nvertices or faces from the other. To do so:\n1.CheckInitialize Mesh using\n2.and select either aMesh from the current projectorMesh from a file. Informations on the selected mesh\nfile are displayed for checkup.\nNote that only the frame of the mesh layer is transferred to the new layer; their datasets are not copied.\nCreating a new GPX layer\nTo create a new GPX file:\n1.SelectCreate Layer►New GPX Layer...from theLayermenu.\n2.In the dialog, choose where to save the new file, name it and press\nSave\n.\n3.Three new layers are added to theLayers Panel:\n•a point layer to digitize locations (waypoints) with fields storing the name, elevation, comment, de-\nscription, source, url and url name\n•a line layer to digitize sequences of locations that make up a planned route (routes) with fields storing\nthe name, symbol, number, comment, description, source, url, url name\n•and a line layer to track the receiver’s movement over time (tracks) with fields storing the name,\nsymbol, number, comment, description, source, url, url name.\n4.You can now edit any of them as described in sectionDigitizing an existing layer.\nCreating a new Temporary Scratch Layer\nTemporary Scratch Layers are in-memory layers, meaning that they are not saved on disk and will be discarded\nwhen QGIS is closed. They can be handy for storing features you temporarily need or as intermediate layers during\ngeoprocessing operations.\nTo create a new Temporary Scratch layer, choose theNew Temporary Scratch Layer...entry in theLayer►\nCreate Layer► menu or in theData Source Managertoolbar. TheNew Temporary Scratch Layerdialog will be\ndisplayed as shown in\nFig. 14.21. Then:\n1.Provide theLayer name\n2.Select theGeometry type. Here you can create a:\n•No geometrytype layer, served as simple table,\n•PointorMultiPointlayer,\n•LineString/CompoundCurveorMultiLineString/MultiCurvelayer,\n•Polygon/CurvePolygonorMultiPolygon/MultiSurfacelayer.\n3.For geometric types, specify the dimensions of the dataset: check whether it shouldInclude Z dimensionand/or\nInclude M values\n14.2. Creating Layers411\n\nQGIS Desktop 3.22 User Guide\n4.Specify the coordinate reference system using thebutton.\n5.Add fields to the layer. Note that unlike many formats, temporary layers can be created without any fields.\nThis step is thus optional.\n1.Enter theNameof the field\n2.Select the dataType:Text,Whole number,Decimal number,Boolean,Date,Time,Date & Timeand\nBinary (BLOB)are supported.\n3.Depending on the selected data format, enter theLengthandPrecision\n4.Click on theAdd to Fields Listbutton\n5.Repeat the steps above for each field you need to add\n6.Once you are happy with the settings, clickOK. QGIS will add the new layer to theLayerspanel, and you can\nedit it as described in sectionDigitizing an existing layer.\nFig. 14.21: Creating a new Temporary Scratch layer dialog\nYou can also create prepopulated temporary scratch layers using e.g. the clipboard (seeCreating new layers from the\nclipboard) or as a result of aProcessing algorithm.\nTip: Permanently store a memory layer on disk\nTo avoid data loss when closing a project with temporary scratch layers, you can save these layers to any vector format\nsupported by QGIS:\n•clicking theindicator icon next to the layer;\n•selecting theMake permanententry in the layer contextual menu;\n•using theExport► entry from the contextual menu or theLayer►Save As...menu.\n412Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nEach of these commands opens theSave Vector Layer asdialog described in theCreating new layers from an existing\nlayersection and the saved file replaces the temporary one in theLayerspanel.\n14.2.2Creating new layers from an existing layer\nBoth raster and vector layers can be saved in a different format and/or reprojected to a different coordinate reference\nsystem (CRS) using theLayer►Save As...menu or right-clicking on the layer in theLayers paneland selecting:\n•Export►Save As...for raster layers\n•Export►Save Features As...orExport►Save Selected Features As...for vector layers.\n•Drag and drop the layer from the layer tree to the PostGIS entry in theBrowser Panel. Note that you must have\na PostGIS connection in theBrowser Panel.\nCommon parameters\nTheSave Layer as...dialog shows several parameters to change the behavior when saving the layer. Among the\ncommon parameters for raster and vector are:\n•File name: the location of the file on the disk. It can refer to the output layer or to a container that stores the\nlayer (for example database-like formats such as GeoPackage, SpatiaLite or Open Document Spreadsheets).\n•CRS: can be changed to reproject the data\n•Extent: restricts the extent of the input that is to be exported using theextent_selectorwidget\n•Add saved file to map: to add the new layer to the canvas\nHowever, some parameters are specific to raster and vector formats:\nRaster specific parameters\nDepending on the format of export, some of these options may not be available:\n•Output mode(it can beraw dataorrendered image)\n•Format: exports to any raster format GDAL can write to, such as GeoTiff, GeoPackage, MBTiles, Geospatial\nPDF, SAGA GIS Binary Grid, Intergraph Raster, ESRI .hdr Labelled...\n•Resolution\n•Create Options: use advanced options (file compression, block sizes, colorimetry...) when generating files,\neither from the\npredefined create profilesrelated to the output format or by setting each parameter.\n•Pyramidscreation\n•VRT Tilesin case you opted toCreate VRT\n•No data values\n14.2. Creating Layers413\n\nQGIS Desktop 3.22 User Guide\nFig. 14.22: Saving as a new raster layer\nVector specific parameters\nDepending on the format of export, some of these options may be available:\n•Format: exports to any vector format GDAL can write to, such as GeoPackage, GML, ESRI Shapefile, Auto-\nCAD DXF, ESRI FileGDB, Mapinfo TAB or MIF, SpatiaLite, CSV, KML, ODS, ...\n•Layer name: available when theFile namerefers to a container-like format, this entry represents the output\nlayer.\n•Encoding\n•Save only selected features\n•Select fields to export and their export options. In case you set your fields behavior with someEdit widgets, e.g.\nvalue map, you can keep the displayed values in the layer by checkingReplace all selected raw fields\nvalues by displayed values.\n•Persist layer metadata: ensures that any layermetadatapresent in the source layer will be copied and stored:\n–in the newly created layer, if the output is of GeoPackage format\n–as a.qmdfile along with the output layer, for other formats. Note that file-based formats supporting\nmore than one dataset (e.g. SpatiaLite, DXF,...) may have unintended behavior.\n•Symbology export: can be used mainly for DXF export and for all file formats who manage OGR feature styles\n(see note below) as DXF, KML, tab file formats:\n–No symbology: default style of the application that reads the data\n–Feature symbology: save style with OGR Feature Styles (see note below)\n414Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n–SymbolLayersymbology: save with OGR Feature Styles (see note below) but export the same geometry\nmultiple times if there are multiple symbology symbol layers used\n–AScalevalue can be applied to the latest options\nNote:OGR Feature Stylesare a way to store style directly in the data as a hidden attribute. Only some formats can\nhandle this kind of information. KML, DXF and TAB file formats are such formats. For advanced details, you can\nread theOGR Feature Styles specificationdocument.\n•Geometry: you can configure the geometry capabilities of the output layer\n–geometry type: keeps the original geometry of the features when set toAutomatic, otherwise removes or\noverrides it with any type. You can add an empty geometry column to an attribute table and remove the\ngeometry column of a spatial layer.\n–Force multi-type: forces creation of multi-geometry features in the layer.\n–Include z-dimensionto geometries.\nTip:Overriding layer geometry type makes it possible to do things like save a geometryless table (e.g..csvfile)\ninto a shapefile WITH any type of geometry (point, line, polygon), so that geometries can then be manually added to\nrows with the\nAdd Part\ntool.\n•Datasource Options,Layer OptionsorCustom Optionswhich allow you to configure advanced parameters de-\npending on the output format. Some are described inExploring Data Formats and Fieldsbut for full details,\nsee theGDALdriver documentation. Each file format has its own custom parameters, e.g. for theGeoJSON\nformat have a look at theGDAL GeoJSONdocumentation.\n14.2. Creating Layers415\n\nQGIS Desktop 3.22 User Guide\nFig. 14.23: Saving as a new vector layer\nWhen saving a vector layer into an existing file, depending on the capabilities of the output format (Geopackage,\nSpatiaLite, FileGDB...), the user can decide whether to:\n•overwrite the whole file\n•overwrite only the target layer (the layer name is configurable)\n•append features to the existing target layer\n•append features, add new fields if there are any.\nFor formats like ESRI Shapefile, MapInfo .tab, feature append is also available.\n14.2.3Creating new DXF files\nBesides theSave As...dialog which provides options to export a single layer to another format, including*.DXF,\nQGIS provides another tool to export multiple layers as a single DXF layer. It’s accessible in theProject►Im-\nport/Export►Export Project to DXF...menu.\nIn theDXF Exportdialog:\n1.Provide the destination file.\n2.Choose the symbology mode and scale (see theOGR Feature Stylesnote), if applicable.\n3.Select the dataEncoding.\n416Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n4.Select theCRSto apply: the selected layers will be reprojected to the given CRS.\n5.Select the layers to include in the DXF files either by checking them in the table widget or automatically picking\nthem from an existingmap theme. TheSelect AllandDeselect Allbuttons can help to quickly set the data to\nexport.\nFor each layer, you can choose whether to export all the features in a single DXF layer or rely on a field whose\nvalues are used to split the features into layers in the DXF output.\nOptionally, you can also choose to:\n•Use the layer title as name if setinstead of the layer name itself;\n•Export features intersecting the current map extent;\n•Force 2d output (eg. to support polyline width);\n•Export label as MTEXT elementsor TEXT elements.\nFig. 14.24: Exporting a project to DXF dialog\n14.2.4Creating new layers from the clipboard\nFeatures that are on the clipboard can be pasted into a new layer. To do this, Select some features, copy them to the\nclipboard, and then paste them into a new layer usingEdit►Paste Features as► and choosing:\n•New Vector Layer...: theSave vector layer as...dialog appears (seeCreating new layers from an existing layer\nfor parameters)\n•orTemporary Scratch Layer...: you need to provide a name for the layer\nA new layer, filled with selected features and their attributes is created (and added to map canvas).\nNote:Creating layers from the clipboard is possible with features selected and copied within QGIS as well as features\nfrom another application, as long as their geometries are defined using well-known text (WKT).\n14.2. Creating Layers417\n\nQGIS Desktop 3.22 User Guide\n14.2.5Creating virtual layers\nA virtual layer is a special kind of vector layer. It allows you to define a layer as the result of an SQL query involving\nany number of other vector layers that QGIS is able to open. Virtual layers do not carry data by themselves and can\nbe seen as views.\nTo create a virtual layer, open the virtual layer creation dialog by:\n•choosing theAdd/Edit Virtual Layerentry in theLayer►Add Layer► menu;\n•enabling theAdd Virtual Layertab in theData Source Managerdialog;\n•or using theDB Managerdialog tree.\nThe dialog allows you to specify aLayer nameand an SQLQuery. The query can use the name (or id) of loaded\nvector layers as tables, as well as their field names as columns.\nFor example, if you have a layer calledairports, you can create a new virtual layer calledpublic_airports\nwith an SQL query like:\nSELECT*\nFROMairports\nWHEREUSE=\"Civilian/Public\"\nThe SQL query will be executed, regardless of the underlying provider of theairportslayer, even if this provider\ndoes not directly support SQL queries.\nFig. 14.25: Create virtual layers dialog\nJoins and complex queries can also be created, for example, to join airports and country information:\nSELECTairports.*,country.population\nFROMairports\nJOINcountry\nONairports.country=country.name\n418Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nNote:It’s also possible to create virtual layers using the SQL window ofDB Manager Plugin.\nEmbedding layers for use in queries\nBesides the vector layers available in the map canvas, the user can add layers to theEmbedded layerslist, which can\nbe used in queries without the need to have them showing in the map canvas or Layers panel.\nTo embed a layer, clickAddand provide theLocal name,Provider,Encodingand the path to theSource.\nTheImportbutton allows adding layers in the map canvas into the Embedded layers list. Those layers can then be\nremoved from the Layers panel without breaking existent queries.\nSupported query language\nThe underlying engine uses SQLite and SpatiaLite to operate.\nIt means you can use all of the SQL your local installation of SQLite understands.\nFunctions from SQLite and spatial functions from SpatiaLite can also be used in a virtual layer query. For instance,\ncreating a point layer out of an attribute-only layer can be done with a query similar to:\nSELECTid,MakePoint(x,y,4326)asgeometry\nFROMcoordinates\nFunctions of QGIS expressionscan also be used in a virtual layer query.\nTo refer the geometry column of a layer, use the namegeometry.\nContrary to a pure SQL query, all the fields of a virtual layer query must be named. Don’t forget to use theas\nkeyword to name your columns if they are the result of a computation or a function call.\nPerformance issues\nWith default parameters, the virtual layer engine will try its best to detect the type of the different columns of the\nquery, including the type of the geometry column if one is present.\nThis is done by introspecting the query when possible or by fetching the first row of the query (LIMIT 1) as a last\nresort. Fetching the first row of the result just to create the layer may be undesirable for performance reasons.\nThe creation dialog parameters:\n•Unique identifier column: specifies a field of the query that represents unique integer values that QGIS can use\nas row identifiers. By default, an autoincrementing integer value is used. Defining a unique identifier column\nspeeds up the selection of rows by id.\n•No geometry: forces the virtual layer to ignore any geometry field. The resulting layer is an attribute-only layer.\n•GeometryColumn: specifies the name of the geometry column.\n•GeometryType: specifies the type of the geometry.\n•GeometryCRS: specifies the coordinate reference system of the virtual layer.\n14.2. Creating Layers419\n\nQGIS Desktop 3.22 User Guide\nSpecial comments\nThe virtual layer engine tries to determine the type of each column of the query. If it fails, the first row of the query\nis fetched to determine column types.\nThe type of a particular column can be specified directly in the query by using some special comments.\nThe syntax is the following:/*:type*/. It has to be placed just after the name of a column.typecan be either\nintfor integers,realfor floating point numbers ortext.\nFor instance:\nSELECTid+1asnid/*:int*/\nFROMtable\nThe type and coordinate reference system of the geometry column can also be set thanks to special comments with the\nfollowing syntax/*:gtype:srid*/wheregtypeis the geometry type (point,linestring,polygon,\nmultipoint,multilinestringormultipolygon) andsridan integer representing the EPSG code of\na coordinate reference system.\nUse of indexes\nWhen requesting a layer through a virtual layer, the source layer indices will be used in the following ways:\n•if an=predicate is used on the primary key column of the layer, the underlying data provider will be asked for\na particular id (FilterFid)\n•for any other predicates (>,<=,!=, etc.) or on a column without a primary key, a request built from an\nexpression will be used to request the underlying vector data provider. It means indexes may be used on\ndatabase providers if they exist.\nA specific syntax exists to handle spatial predicates in requests and triggers the use of a spatial index: a hidden column\nnamed_search_frame_exists for each virtual layer. This column can be compared for equality to a bounding\nbox. Example:\nSELECT*\nFROMvtab\nWHERE_search_frame_=BuildMbr(-2.10,49.38,-1.3,49.99,4326)\nSpatial binary predicates likeST_Intersectsare sped up significantly when used in conjunction with this spatial\nindex syntax.\n14.3Exploring Data Formats and Fields\n14.3.1Raster data\nGIS raster data are matrices of discrete cells that represent features / phenomena on, above or below the earth’s\nsurface. Each cell in the raster grid has the same size, and cells are usually rectangular (in QGIS they will always be\nrectangular). Typical raster datasets include remote sensing data, such as aerial photography, or satellite imagery and\nmodelled data, such as elevation or temperature.\nUnlike vector data, raster data typically do not have an associated database record for each cell. They are geocoded\nby pixel resolution and the X/Y coordinate of a corner pixel of the raster layer. This allows QGIS to position the data\ncorrectly on the map canvas.\nThe GeoPackage format is convenient for storing raster data when working with QGIS. The popular and powerful\nGeoTiff format is a good alternative.\nQGIS makes use of georeference information inside the raster layer (e.g., GeoTiff) or an associatedworld fileto\nproperly display the data.\n420Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\n14.3.2Vector Data\nMany of the features and tools available in QGIS work the same, regardless the vector data source. However, because\nof the differences in format specifications (GeoPackage, ESRI Shapefile, MapInfo and MicroStation file formats,\nAutoCAD DXF, PostGIS, SpatiaLite, Oracle Spatial, MSSQL Spatial, SAP HANA Spatial databases and many\nmore), QGIS may handle some of their properties differently. Support is provided by theOGR Simple Feature\nLibrary. This section describes how to work with these specificities.\nNote:QGIS supports (multi)point, (multi)line, (multi)polygon, CircularString, CompoundCurve, CurvePolygon,\nMultiCurve, MultiSurface feature types, all optionally with Z and/or M values.\nYou should also note that some drivers don’t support some of these feature types, like CircularString, Compound-\nCurve, CurvePolygon, MultiCurve, MultiSurface feature type. QGIS will convert them.\nGeoPackage\nTheGeoPackage(GPKG) format is platform-independent, and is implemented as a SQLite database container, and\ncan be used to store both vector and raster data. The format was defined by the Open Geospatial Consortium (OGC),\nand was published in 2014.\nGeoPackage can be used to store the following in a SQLite database:\n•vectorfeatures\n•tile matrix sets of imageryandrastermaps\n•attributes (non-spatial data)\n•extensions\nSince QGIS version 3.8, GeoPackage can also store QGIS projects. GeoPackage layers can have JSON fields.\nGeoPackage is the default format for vector data in QGIS.\nESRI Shapefile format\nThe ESRI Shapefile format is still one of the most used vector file formats, even if it has some limitations compared\nto for instance GeoPackage and SpatiaLite.\nAn ESRI Shapefile format dataset consists of several files. The following three are required:\n1..shpfile containing the feature geometries\n2..dbffile containing the attributes in dBase format\n3..shxindex file\nAn ESRI Shapefile format dataset can also include a file with a.prjsuffix, which contains projection information.\nWhile it is very useful to have a projection file, it is not mandatory. A Shapefile format dataset can contain additional\nfiles. For further details, see the the ESRItechnical specification.\nGDAL 3.1 has read-write support for compressed ESRI Shapefile format (shzandshp.zip).\nImproving Performance for ESRI Shapefile format datasets\nTo improve the drawing performance for an ESRI Shapefile format dataset, you can create a spatial index. A spatial\nindex will improve the speed of both zooming and panning. Spatial indexes used by QGIS have a.qixextension.\nUse these steps to create the index:\n1.Load an ESRI Shapefile format dataset (seeThe Browser Panel)\n2.Open theLayer Propertiesdialog by double-clicking on the layer name in the legend or by right-clicking and\nchoosingProperties...from the context menu\n14.3. Exploring Data Formats and Fields421\n\nQGIS Desktop 3.22 User Guide\n3.In theSourcetab, click theCreate Spatial Indexbutton\nProblem loading a .prj file\nIf you load an ESRI Shapefile format dataset with a.prjfile and QGIS is not able to read the coordinate reference\nsystem from that file, you will need to define the proper projection manually in theLayer Properties►Sourcetab of\nthe layer by clicking the\nSelect CRS\nbutton. This is due to the fact that.prjfiles often do not provide the complete\nprojection parameters as used in QGIS and listed in theCRSdialog.\nFor the same reason, if you create a new ESRI Shapefile format dataset with QGIS, two different projection files are\ncreated: a.prjfile with limited projection parameters, compatible with ESRI software, and a.qpjfile, providing\nall the parameters of the CRS. Whenever QGIS finds a.qpjfile, it will be used instead of the.prj.\nDelimited Text Files\nDelimited text files are very common and widely used because of their simplicity and readability – data can be viewed\nand edited in a plain text editor. A delimited text file is tabular data with columns separated by a defined character and\nrows separated by line breaks. The first row usually contains the column names. A common type of delimited text\nfile is a CSV (Comma Separated Values), with columns separated by commas. Delimited text files can also contain\npositional information (seeStoring geometry information in delimited text files).\nQGIS allows you to load a delimited text file as a layer or an ordinary table (seeThe Browser PanelorImporting a\ndelimited text file). First check that the file meets the following requirements:\n1.The file must have a delimited header row of field names. This must be the first line of the data (ideally the\nfirst row in the text file).\n2.If geometry should be enabled, the file must contain field(s) that define the geometry. These field(s) can have\nany name.\n3.The X and Y coordinates fields (if geometry is defined by coordinates) must be specified as numbers. The\ncoordinate system is not important.\n4.If you have a CSV file with non-string columns, you must have an accompanying CSVT file (see sectionUsing\nCSVT file to control field formatting).\nThe elevation point data fileelevp.csvin the QGIS sample dataset (see section\nDownloading sample data) is an\nexample of a valid text file:\nX;Y;ELEV\n-300120;7689960;13\n-654360;7562040;52\n1640;7512840;3\n[...]\nSome things to note about the text file:\n1.The example text file uses;(semicolon) as delimiter (any character can be used to delimit the fields).\n2.The first row is the header row. It contains the fieldsX,YandELEV.\n3.No quotes (\") are used to delimit text fields\n4.The X coordinates are contained in theXfield\n5.The Y coordinates are contained in theYfield\n422Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nStoring geometry information in delimited text files\nDelimited text files can contain geometry information in two main forms:\n•As coordinates in separate columns (eg.Xcol,Ycol... ), for point geometry data;\n•As well-known text (WKT) representation of geometry in a single column, for any geometry type.\nFeatures with curved geometries (CircularString, CurvePolygon and CompoundCurve) are supported. Here are some\nexamples of geometry types in a delimited text file with geometries coded as WKT:\nLabel;WKT_geom\nLineString;LINESTRING(10.020.0,11.021.0,13.025.5)\nCircularString;CIRCULARSTRING(268415,227505,227406)\nCurvePolygon;CURVEPOLYGON(CIRCULARSTRING(13,35,47,73,13))\nCompoundCurve;COMPOUNDCURVE((53,513), CIRCULARSTRING(513,715,\n913), (913,93), CIRCULARSTRING(93,71,53))\nDelimited text files also support Z and M coordinates in geometries:\nLINESTRINGZ(10.020.030.0,11.021.031.0,11.022.030.0)\nUsing CSVT file to control field formatting\nWhen loading CSV files, the OGR driver assumes all fields are strings (i.e. text) unless it is told otherwise. You can\ncreate a CSVT file to tell OGR (and QGIS) the data type of the different columns:\nTypeNameExample\nWhole numberInteger4\nDecimal numberReal3.456\nDateDate (YYYY-MM-DD)2016-07-28\nTimeTime (HH:MM:SS+nn)18:33:12+00\nDate & TimeDateTime (YYYY-MM-DD HH:MM:SS+nn)2016-07-28 18:33:12+00\nThe CSVT file is aONE lineplain text file with the data types in quotes and separated by commas, e.g.:\n\"Integer\",\"Real\",\"String\"\nYou can even specify width and precision of each column, e.g.:\n\"Integer(6)\",\"Real(5.5)\",\"String(22)\"\nThis file is saved in the same folder as the.csvfile, with the same name, but.csvtas the extension.\nYou can find more information atGDAL CSV Driver.\nPostGIS Layers\nPostGIS layers are stored in a PostgreSQL database. The advantages of PostGIS are spatial indexing, filtering and\nquerying capabilities. Using PostGIS, vector functions such as select and identify work more accurately than they do\nwith OGR layers in QGIS.\nTip: PostGIS Layers\nNormally, a PostGIS layer is identified by an entry in the geometry_columns table. QGIS can load layers that do not\nhave an entry in the geometry_columns table. This includes both tables and views. Refer to your PostgreSQL manual\nfor information on creating views.\n14.3. Exploring Data Formats and Fields423\n\nQGIS Desktop 3.22 User Guide\nThis section contains some details on how QGIS accesses PostgreSQL layers. Most of the time, QGIS should simply\nprovide you with a list of database tables that can be loaded, and it will load them on request. However, if you have\ntrouble loading a PostgreSQL table into QGIS, the information below may help you understand QGIS messages and\ngive you directions for modifying the PostgreSQL table or view definition to allow QGIS to load it.\nNote:A PostgreSQL database can also store QGIS projects.\nPrimary key\nQGIS requires that PostgreSQL layers contain a column that can be used as a unique key for the layer. For tables, this\nusually means that the table needs a primary key, or a column with a unique constraint on it. In QGIS, this column\nneeds to be of type int4 (an integer of size 4 bytes). Alternatively, the ctid column can be used as primary key. If a\ntable lacks these items, the oid column will be used instead. Performance will be improved if the column is indexed\n(note that primary keys are automatically indexed in PostgreSQL).\nQGIS offers a checkboxSelect at idthat is activated by default. This option gets the ids without the attributes, which\nis faster in most cases.\nView\nIf the PostgreSQL layer is a view, the same requirement exists, but views do not always have primary keys or columns\nwith unique constraints on them. You have to define a primary key field (has to be integer) in the QGIS dialog before\nyou can load the view. If a suitable column does not exist in the view, QGIS will not load the layer. If this occurs,\nthe solution is to alter the view so that it does include a suitable column (a type of integer and either a primary key or\nwith a unique constraint, preferably indexed).\nAs for table, a checkboxSelect at idis activated by default (see above for the meaning of the checkbox). It can make\nsense to disable this option when you use expensive views.\nNote: PostgreSQL foreign table\nPostgreSQL foreign tables are not explicitely supported by the PostgreSQL provider and will be handled like a view.\nQGIS layer_style table and database backup\nIf you want to make a backup of your PostGIS database using thepg_dumpandpg_restorecommands, and\nthe default layer styles as saved by QGIS fail to restore afterwards, you need to set the XML option toDOCUMENT\nbefore the restore command:\n1.Make a PLAIN backup of thelayer_styletable\n2.Open the file within a text editor\n3.Change the lineSET xmloption = content;intoSET XML OPTION DOCUMENT;\n4.Save the file\n5.Use psql to restore the table in the new database\n424Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFilter database side\nQGIS allows to filter features already on server side. CheckSettings►Options►Data Sources►Execute expres-\nsions on server-side if possibleto do so. Only supported expressions will be sent to the database. Expressions using\nunsupported operators or functions will gracefully fallback to local evaluation.\nSupport of PostgreSQL data types\nData types supported by the PostgreSQL provider include: integer, float, boolean, binary object, varchar, geometry,\ntimestamp, array, hstore and json.\nImporting Data into PostgreSQL\nData can be imported into PostgreSQL/PostGIS using several tools, including the DB Manager plugin and the com-\nmand line tools shp2pgsql and ogr2ogr.\nDB Manager\nQGIS comes with a core plugin named\nDB Manager\n. It can be used to load data, and it includes support for schemas.\nSee sectionDB Manager Pluginfor more information.\nshp2pgsql\nPostGIS includes a utility calledshp2pgsql, that can be used to import Shapefile format datasets into a PostGIS-\nenabled database. For example, to import a Shapefile format dataset namedlakes.shpinto a PostgreSQL database\nnamedgis_data, use the following command:\nshp2pgsql-s2964lakes.shp lakes_new|psql gis_data\nThis creates a new layer namedlakes_newin thegis_datadatabase. The new layer will have a spatial reference\nidentifier (SRID) of 2964. See sectionWorking with Projectionsfor more information about spatial reference systems\nand projections.\nTip: Exporting datasets from PostGIS\nThere is also a tool for exporting PostGIS datasets to Shapefile format:pgsql2shp. It is shipped within your PostGIS\ndistribution.\nogr2ogr\nIn addition toshp2pgsqlandDB Manager, there is another tool for feeding geographical data in PostGIS:ogr2ogr.\nIt is part of your GDAL installation.\nTo import a Shapefile format dataset into PostGIS, do the following:\nogr2ogr-f\"PostgreSQL\"PG:\"dbname=postgis host=myhost.de user=postgres\npassword=topsecret\"alaska.shp\nThis will import the Shapefile format datasetalaska.shpinto the PostGIS databasepostgisusing the userpostgres\nwith the passwordtopsecreton the host servermyhost.de.\nNote that OGR must be built with PostgreSQL to support PostGIS. You can verify this by typing (in):\n14.3. Exploring Data Formats and Fields425\n\nQGIS Desktop 3.22 User Guide\nogrinfo--formats|grep-i post\nIf you prefer to use the PostgreSQL’sCOPYcommand instead of the defaultINSERT INTOmethod, you can\nexport the following environment variable (at least available onand):\nexport PG_USE_COPY=YES\nogr2ogrdoes not create spatial indexes likeshp2pgsldoes. You need to create them manually, using the normal SQL\ncommandCREATE INDEXafterwards, as an extra step (as described in the next sectionImproving Performance).\nImproving Performance\nRetrieving features from a PostgreSQL database can be time-consuming, especially over a network. You can improve\nthe drawing performance of PostgreSQL layers by ensuring that a PostGIS spatial index exists on each layer in the\ndatabase. PostGIS supports creation of a GiST (Generalized Search Tree) index to speed up spatial searching (GiST\nindex information is taken from the PostGIS documentation available athttps://postgis.net).\nTip:You can use the DBManager to create an index for your layer. You should first select the layer and click on\nTable►Edit table, go toIndexestab and click onAdd Spatial Index.\nThe syntax for creating a GiST index is:\nCREATE INDEX [indexname] ON [tablename]\nUSING GIST ( [geometryfield] GIST_GEOMETRY_OPS );\nNote that for large tables, creating the index can take a long time. Once the index is created, you should perform a\nVACUUM ANALYZE. See the PostGIS documentation (POSTGIS-PROJECT inLiterature and Web References) for\nmore information.\nThe following example creates a GiST index:\ngsherman@madison:~/current$ psql gis_data\nWelcome to psql 8.3.0, the PostgreSQL interactive terminal.\nType:  \\copyright for distribution terms\n\\h for help with SQL commands\n\\? for help with psql commands\n\\g or terminate with semicolon to execute query\n\\q to quit\ngis_data=# CREATE INDEX sidx_alaska_lakes ON alaska_lakes\ngis_data-# USING GIST (the_geom GIST_GEOMETRY_OPS);\nCREATE INDEX\ngis_data=# VACUUM ANALYZE alaska_lakes;\nVACUUM\ngis_data=# \\q\ngsherman@madison:~/current$\n426Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nVector layers crossing 180° longitude\nMany GIS packages don’t wrap vector maps with a geographic reference system (lat/lon) crossing the 180 degrees\nlongitude line (https://postgis.net/docs/ST_Shift_Longitude.html). As result, if we open such a map in QGIS, we\ncould see two widely separated locations, that should appear near each other. In\nFig. 14.26, the tiny point on the far\nleft of the map canvas (Chatham Islands) should be within the grid, to the right of the New Zealand main islands.\nFig. 14.26: Map in lat/lon crossing the 180° longitude line\nA work-around is to transform the longitude values using PostGIS and theST_Shift_Longitudefunction. This\nfunction reads every point/vertex in every component of every feature in a geometry, and if the longitude coordinate\nis < 0°, it adds 360° to it. The result is a 0° - 360° version of the data to be plotted in a 180°-centric map.\nFig. 14.27: Crossing 180° longitude applying theST_Shift_Longitudefunction\nUsage\n•Import data into PostGIS (Importing Data into PostgreSQL) using, for example, the DB Manager plugin.\n•Use the PostGIS command line interface to issue the following command (in this example, “TA-\nBLE” is the actual name of your PostGIS table):gis_data=#   update   TABLE   set\nthe_geom=ST_Shift_Longitude(the_geom);\n•If everything went well, you should receive a confirmation about the number of features that were updated.\nThen you’ll be able to load the map and see the difference (Figure_vector_crossing_map).\n14.3. Exploring Data Formats and Fields427\n\nQGIS Desktop 3.22 User Guide\nSpatiaLite Layers\nIf you want to save a vector layer using the SpatiaLite format, you can do this by following instructions atCreating\nnew layers from an existing layer. You selectSpatiaLiteasFormatand enter bothFile nameandLayer name.\nAlso, you can selectSQLiteas format and then addSPATIALITE=YESin theCustom Options►Data source\nfield. This tells GDAL to create a SpatiaLite database. See alsohttps://gdal.org/drivers/vector/sqlite.html.\nQGIS also supports editable views in SpatiaLite. For SpatiaLite data management, you can also use the core plugin\nDB Manager.\nIf you want to create a new SpatiaLite layer, please refer to sectionCreating a new SpatiaLite layer.\nGeoJSON specific parameters\nWhenexporting layersto GeoJSON, there are some specificLayer Optionsavailable. These options come from GDAL\nwhich is responsible for the writing of the file:\n•COORDINATE_PRECISION\nthe maximum number of digits after the decimal separator to write in coordinates.\nDefaults to 15 (note: for Lat Lon coordinates 6 is considered enough). Truncation will occur to remove trailing\nzeros.\n•RFC7946by default GeoJSON 2008 will be used.  If set to YES, the updated RFC 7946 standard\nwill be used.  Default is NO (thus GeoJSON 2008).  Seehttps://gdal.org/drivers/vector/geojson.html#\nrfc-7946-write-support\nfor the main differences, in short: only EPSG:4326 is allowed, other crs’s will be\ntransformed, polygons will be written such as to follow the right-hand rule for orientation, values of a “bbox”\narray are [west, south, east, north], not [minx, miny, maxx, maxy]. Some extension member names are forbid-\nden in FeatureCollection, Feature and Geometry objects, the default coordinate precision is 7 decimal digits\n•WRITE_BBOXset to YES to include the bounding box of the geometries at the feature and feature collection\nlevel\nBesides GeoJSON there is also an option to export to “GeoJSON - Newline Delimited” (seehttps://gdal.org/drivers/\nvector/geojsonseq.html). Instead of a FeatureCollection with Features, you can stream one type (probably only\nFeatures) sequentially separated with newlines.\nGeoJSON - Newline Delimited has some specific Layer options availabe too:\n•COORDINATE_PRECISIONsee above (same as for GeoJSON)\n•RSwhether to start records with the RS=0x1E character. The difference is how the features are separated: only\nby a newline (LF) character (Newline Delimited JSON, geojsonl) or by also prepending a record-separator (RS)\ncharacter (giving GeoJSON Text Sequences, geojsons). Default to NO. Files are given the.jsonextension\nif extension is not provided.\nSAP HANA Spatial Layers\nThis section contains some details on how QGIS accesses SAP HANA layers. Most of the time, QGIS should simply\nprovide you with a list of database tables and views that can be loaded, and it will load them on request. However, if\nyou have trouble loading an SAP HANA table or view into QGIS, the information below may help you understand\nthe root cause and assist in resolving the issue.\n428Chapter 14. Managing Data Source\n\nQGIS Desktop 3.22 User Guide\nFeature Identification\nIf you’d like to use all of QGIS’ feature editing capabilities, QGIS must be able to unambiguously identify each feature\nin a layer. Internally, QGIS uses a 64-bit signed integer to identify features, whereas the negative range is reserved\nfor special purposes.\nTherefore, the SAP HANA provider requires a unique key that can be mapped to a positive 64-bit integer to fully\nsupport QGIS’ feature editing capabilities. If it is not possible to create such a mapping, you might still view the\nfeatures, but editing might not work.\nAdding tables\nWhen adding a table as a layer, the SAP HANA provider uses the table’s primary key to map it to a unique feature\nid. Therefore, to have full feature editing support, you need to have a primary key to your table definition.\nThe SAP HANA provider supports multi-column primary keys, but if you’d like to get the best performance, your\nprimary key should be a single column of typeINTEGER.\nAdding views\nWhen adding a view as a layer, the SAP HANA provider cannot automatically identify columns that unambiguously\nidentify a feature. Furthermore, some views are read-only and cannot be edited.\nTo have full feature editing support, the view must be updatable (check columnIS_READ_ONLYin system view\nSYS.VIEWSfor the view in question) and you must manually provide QGIS with one or more columns that identify\na feature. The columns can be given by usingLayer►Add Layer►Add SAP HANA Spatial Layerand then selecting\nthe columns in theFeature idcolumn. For best performance, theFeature idvalue should be a singleINTEGER\ncolumn.\n14.3. Exploring Data Formats and Fields429\n\nQGIS Desktop 3.22 User Guide\n430Chapter 14. Managing Data Source\n\nCHAPTER\nFIFTEEN\nWORKING WITH VECTOR DATA\n15.1The Vector Properties Dialog\nTheLayer Propertiesdialog for a vector layer provides general settings to manage appearance of layer features in the\nmap (symbology, labeling, diagrams), interaction with the mouse (actions, map tips, form design). It also provides\ninformation about the layer.\nTo access theLayer Propertiesdialog:\n•In theLayerspanel, double-click the layer or right-click and selectProperties...from the pop-up menu;\n•Go toLayer►Layer Properties...menu when the layer is selected.\nThe vectorLayer Propertiesdialog provides the following sections:\nInformationSourceSymbology\n[1]\nLabels\n[1]\nMask\n[1]\n3D View\n[1]\nDiagramsFieldsAttributes Form\nJoinsAuxiliary StorageActions\nDisplayRenderingTemporal\nVariablesMetadataDependencies\nLegendQGIS ServerDigitizing\nExternal plugins\n[2]\ntabs\n[1]\nAlso available in theLayer styling panel\n[2]\nExternal pluginsyou install can optionally add tabs to this dialog. Those are not presented in this document. Refer\nto their documentation.\nTip: Share full or partial properties of the layer styles\nTheStylemenu at the bottom of the dialog allows you to import or export these or part of these properties from/to\nseveral destination (file, clipboard, database). SeeManaging Custom Styles.\nNote:Because properties (symbology, label, actions, default values, forms...) of embedded layers (seeEmbedding\nlayers from external projects) are pulled from the original project file and to avoid changes that may break this behavior,\nthe layer properties dialog is made unavailable for these layers.\n431\n\nQGIS Desktop 3.22 User Guide\n15.1.1Information Properties\nTheInformationtab is read-only and represents an interesting place to quickly grab summarized information and\nmetadata on the current layer. Provided information are:\n•general such as name in the project, source path, list of auxiliary files, last save time and size, the used provider\n•based on the provider of the layer: format of storage, geometry type, data source encoding, extent, feature\ncount...\n•the Coordinate Reference System: name, units, method, accuracy, reference (i.e. whether it’s static or dynamic)\n•picked from thefilled metadata: access, extents, links, contacts, history...\n•and related to its geometry (spatial extent, CRS...) or its attributes (number of fields, characteristics of each...).\n15.1.2Source Properties\nUse this tab to define general settings for the vector layer.\nFig. 15.1: Source tab in vector Layer Properties dialog\nSettings\n•Set aLayer namedifferent from the layer filename that will be used to identify the layer in the project (in the\nLayers Panel, with expressions, in print layout legend, ...)\n•Depending on the data format, select theData source encodingif not correctly detected by QGIS.\n432Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nCoordinate Reference System and Geometry\n•Displays the layer’sAssigned Coordinate Reference System (CRS). You can change the layer’s CRS, selecting a\nrecently used one in the drop-down list or clicking on\nSelect CRS\nbutton (seeCoordinate Reference System\nSelector). Use this process only if the CRS applied to the layer is a wrong one or if none was applied. If you\nwish to reproject your data into another CRS, rather use layer reprojection algorithms from Processing orSave\nit into another layer.\n•Create spatial index(only for OGR-supported formats).\n•Update extentsinformation for a layer.\nQuery Builder\nTheQuery Builderdialog is accessible through the eponym button at the bottom of theSourcetab in the Layer\nProperties dialog, under theProvider feature filtergroup.\nThe Query Builder provides an interface that allows you to define a subset of the features in the layer using a SQL-\nlike WHERE clause and to display the result in the main window. As long as the query is active, only the features\ncorresponding to its result are available in the project.\nYou can use one or more layer attributes to define the filter in theQuery Builder. The use of more than one\nattribute is shown inFig. 15.2. In the example, the filter combines the attributes\n•toa(DateTimefield:cast(\"toa\" as character) > '2017-05-17'andcast(\"toa\" as\ncharacter) < '2019-12-24T18:00:00'),\n•name(Stringfield:\"name\" > 'S') and\n•FID(Integerfield:FID > 10)\nusing the AND, OR and NOT operators and parenthesis. This syntax (including the DateTime format for thetoa\nfield) works for GeoPackage datasets.\nThe filter is made at the data provider (OGR, PostgreSQL, MSSQL...) level. So the syntax depends on the data\nprovider (DateTime is for instance not supported for the ESRI Shapefile format). The complete expression:\ncast(\"toa\"ascharacter)>'2017-05-17'AND\ncast(\"toa\"ascharacter)<'2019-12-24T18:00:00'AND\nNOT (\"name\">'S'OR FID>10)\nYou can also open theQuery Builderdialog using theFilter...option from theLayermenu or the layer contextual\nmenu. TheFields,ValuesandOperatorssections in the dialog help you to construct the SQL-like query exposed in\ntheProvider specific filter expressionbox.\n15.1. The Vector Properties Dialog433\n\nQGIS Desktop 3.22 User Guide\nFig. 15.2: Query Builder\nTheFieldslist contains all the fields of the layer. To add an attribute column to the SQL WHERE clause field,\ndouble-click its name or just type it into the SQL box.\nTheValuesframe lists the values of the currently selected field. To list all unique values of a field, click theAll\nbutton. To instead list the first 25 unique values of the column, click theSamplebutton. To add a value to the SQL\nWHERE clause field, double click its name in the Values list. You can use the search box at the top of the Values\nframe to easily browse and find attribute values in the list.\nTheOperatorssection contains all usable operators. To add an operator to the SQL WHERE clause field, click\nthe appropriate button. Relational operators (=,>, ...), string comparison operator (LIKE), and logical operators\n(AND,OR, ...) are available.\nTheTestbutton helps you check your query and displays a message box with the number of features satisfying the\ncurrent query. Use theClearbutton to wipe the SQL query and revert the layer to its original state (ie, fully load all\nthe features).\nWhen a filter is applied, QGIS treats the resulting subset acts as if it were the entire layer. For example if you applied\nthe filter above for ‘Borough’ (\"TYPE_2\" = 'Borough'), you can not display, query, save or editAnchorage,\nbecause that is a ‘Municipality’ and therefore not part of the subset.\nTip: Filtered layers are indicated in the Layers Panel\nIn theLayerspanel, filtered layer is listed with a\nFilter\nicon next to it indicating the query used when the mouse\nhovers over the button. Double-click the icon opens theQuery Builderdialog for edit.\n434Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n15.1.3Symbology Properties\nThe Symbology tab provides you with a comprehensive tool for rendering and symbolizing your vector data.\nYou can use tools that are common to all vector data, as well as special symbolizing tools that were designed for the\ndifferent kinds of vector data. However all types share the following dialog structure: in the upper part, you have\na widget that helps you prepare the classification and the symbol to use for features and at the bottom theLayer\nrenderingwidget.\nTip: Switch quickly between different layer representations\nUsing theStyles►Addmenu at the bottom of theLayer Propertiesdialog, you can save as many styles as needed. A\nstyle is the combination of all properties of a layer (such as symbology, labeling, diagram, fields form, actions...) as\nyou want. Then, simply switch between styles from the context menu of the layer inLayers Panelto automatically\nget different representations of your data.\nTip: Export vector symbology\nYou have the option to export vector symbology from QGIS into Google *.kml, *.dxf and MapInfo *.tab files. Just\nopen the right mouse menu of the layer and click onSave As...to specify the name of the output file and its format.\nIn the dialog, use theSymbology exportmenu to save the symbology either asFeature symbology► or asSymbol layer\nsymbology►. If you have used symbol layers, it is recommended to use the second setting.\nFeatures rendering\nThe renderer is responsible for drawing a feature together with the correct symbol. Regardless layer geometry type,\nthere are four common types of renderers: single symbol, categorized, graduated and rule-based. For point layers,\nthere are a point displacement and a heatmap renderers available while polygon layers can also be rendered with the\ninverted polygons and 2.5 D renderers.\nThere is no continuous color renderer, because it is in fact only a special case of the graduated renderer. The cate-\ngorized and graduated renderers can be created by specifying a symbol and a color ramp - they will set the colors\nfor symbols appropriately. For each data type (points, lines and polygons), vector symbol layer types are available.\nDepending on the chosen renderer, the dialog provides different additional sections.\nNote:If you change the renderer type when setting the style of a vector layer the settings you made for the symbol\nwill be maintained. Be aware that this procedure only works for one change. If you repeat changing the renderer type\nthe settings for the symbol will get lost.\nSingle Symbol Renderer\nTheSingle Symbolrenderer is used to render all features of the layer using a single user-defined symbol. SeeThe\nSymbol Selectorfor further information about symbol representation.\n15.1. The Vector Properties Dialog435\n\nQGIS Desktop 3.22 User Guide\nFig. 15.3: Single symbol line properties\nNo Symbols Renderer\nTheNo Symbolsrenderer is a special use case of the Single Symbol renderer as it applies the same rendering to\nall features. Using this renderer, no symbol will be drawn for features, but labeling, diagrams and other non-symbol\nparts will still be shown.\nSelections can still be made on the layer in the canvas and selected features will be rendered with a default symbol.\nFeatures being edited will also be shown.\nThis is intended as a handy shortcut for layers which you only want to show labels or diagrams for, and avoids the\nneed to render symbols with totally transparent fill/border to achieve this.\n436Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nCategorized Renderer\nTheCategorizedrenderer is used to render the features of a layer, using a user-defined symbol whose aspect\nreflects the discrete values of a field or an expression.\nFig. 15.4: Categorized Symbolizing options\nTo use categorized symbology for a layer:\n1.Select theValueof classification: it can be an existing field or anexpressionyou can type in the box or build\nusing the associated\nbutton. Using expressions for categorizing avoids the need to create an ad hoc field\nfor symbology purposes (eg, if your classification criteria are derived from one or more attributes).\nThe expression used to classify features can be of any type; eg, it can:\n•be a comparison. In this case, QGIS returns values1(True) and0(False). Some examples:\nmyfield >= 100\n$id = @atlas_featureid\nmyfield % 2 = 0\nwithin( $geometry, @atlas_geometry )\n•combine different fields:\nconcat( field_1,'', field_2 )\n•be a calculation on fields:\nmyfield%2\nyear( myfield )\nfield_1+field_2\nsubstr( field_1,\n-3)\n•be used to transform linear values to discrete classes, e.g.:\nCASE WHEN x>1000THEN'Big'ELSE'Small'END\n•combine several discrete values into a single category, e.g.:\n15.1. The Vector Properties Dialog437\n\nQGIS Desktop 3.22 User Guide\nCASE\nWHEN building IN ('residence','mobile home') THEN'residential'\nWHEN building IN ('commercial','industrial') THEN'Commercial and␣\n,→Industrial'\nEND\nTip:While you can use any kind of expression to categorize features, for some complex expressions it might\nbe simpler to userule-based rendering.\n2.Configure theSymbol, which will be used as base symbol for all the classes;\n3.Indicate theColor ramp, ie the range of colors from which the color applied to each symbol is selected.\nBesides the common options of thecolor ramp widget, you can apply aRandom Color Rampto the cate-\ngories. You can click theShuffle Random Colorsentry to regenerate a new set of random colors if you are not\nsatisfied.\n4.Then click on theClassifybutton to create classes from the distinct values of the provided field or expression.\n5.Applythe changes if thelive updateis not in use and each feature on the map canvas will be rendered with the\nsymbol of its class.\nBy default, QGIS appends anall other valuesclass to the list. While empty at the beginning, this class is used\nas a default class for any feature not falling into the other classes (eg, when you create features with new values\nfor the classification field / expression).\nFurther tweaks can be done to the default classification:\n•You can\nAdd\nnew categories,\nRemove\nselected categories orDelete Allof them.\n•A class can be disabled by unchecking the checkbox to the left of the class name; the corresponding features\nare hidden on the map.\n•Drag-and-drop the rows to reorder the classes\n•To change the symbol, the value or the legend of a class, double click the item.\nRight-clicking over selected item(s) shows a contextual menu to:\n•Copy SymbolandPaste Symbol, a convenient way to apply the item’s representation to others\n•Change Color...of the selected symbol(s)\n•Change Opacity...of the selected symbol(s)\n•Change Output Unit...\nof the selected symbol(s)\n•Change Width...of the selected line symbol(s)\n•Change Size...of the selected point symbol(s)\n•Change Angle...of the selected point symbol(s)\n•Merge Categories\n: Groups multiple selected categories into a single one. This allows simpler styling of layers\nwith a large number of categories, where it may be possible to group numerous distinct categories into a smaller\nand more manageable set of categories which apply to multiple values.\nTip:Since the symbol kept for the merged categories is the one of the topmost selected category in the list,\nyou may want to move the category whose symbol you wish to reuse to the top before merging.\n•Unmerge Categoriesthat were previously merged\nTheAdvancedmenu gives access to options to speed classification or fine-tune the symbols rendering:\n438Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•Match to saved symbols: Using thesymbols library, assigns to each category a symbol whose name represents\nthe classification value of the category\n•Match to symbols from file...: Provided a file with symbols, assigns to each category a symbol whose name\nrepresents the classification value of the category\n•Symbol levels...to define the order of symbols rendering.\nTip: Edit categories directly from theLayerspanel\nWhen a layer symbology is based on acategorized,graduatedorrule-basedsymbology mode, you can edit each of\nthe categories from theLayersPanel. Right-click on a sub-item of the layer and you will:\n•Toggle itemsvisibility\n•Show all items\n•Hide all items\n•Modify the symbol color thanks to thecolor selectorwheel\n•Edit symbol...from thesymbol selectordialog\n•Copy symbol\n•Paste symbol\nGraduated Renderer\nTheGraduatedrenderer is used to render all the features from a layer, using an user-defined symbol whose color\nor size reflects the assignment of a selected feature’s attribute to a class.\nLike the Categorized Renderer, the Graduated Renderer allows you to define rotation and size scale from specified\ncolumns.\nAlso, analogous to the Categorized Renderer, it allows you to select:\n•The value (using the fields listbox or the\nSet value expression\nfunction)\n•The symbol (using the Symbol selector dialog)\n•The legend format and the precision\n•The method to use to change the symbol: color or size\n•The colors (using the color Ramp list) if the color method is selected\n•The size (using the size domain and its unit)\nThen you can use the Histogram tab which shows an interactive histogram of the values from the assigned field or\nexpression. Class breaks can be moved or added using the histogram widget.\nNote:You can use Statistical Summary panel to get more information on your vector layer. SeeStatistical Summary\nPanel\n.\nBack to the Classes tab, you can specify the number of classes and also the mode for classifying features within the\nclasses (using the Mode list). The available modes are:\n•Equal Count (Quantile): each class will have the same number of elements (the idea of a boxplot).\n•Equal Interval: each class will have the same size (e.g. with the values from 1 to 16 and four classes, each class\nwill have a size of four).\n15.1. The Vector Properties Dialog439\n\nQGIS Desktop 3.22 User Guide\n•Logarithmic scale: suitable for data with a wide range of values. Narrow classes for low values and wide classes\nfor large values (e.g. for decimal numbers with range [0..100] and two classes, the first class will be from 0 to\n10 and the second class from 10 to 100).\n•Natural Breaks (Jenks): the variance within each class is minimized while the variance between classes is\nmaximized.\n•Pretty Breaks: computes a sequence of about n+1 equally spaced nice values which cover the range of the\nvalues in x. The values are chosen so that they are 1, 2 or 5 times a power of 10. (based on pretty from the R\nstatistical environmenthttps://www.rdocumentation.org/packages/base/topics/pretty).\n•Standard Deviation: classes are built depending on the standard deviation of the values.\nThe listbox in the center part of theSymbologytab lists the classes together with their ranges, labels and symbols that\nwill be rendered.\nClick onClassifybutton to create classes using the chosen mode. Each classes can be disabled unchecking the\ncheckbox at the left of the class name.\nTo change symbol, value and/or label of the class, just double click on the item you want to change.\nRight-clicking over selected item(s) shows a contextual menu to:\n•Copy SymbolandPaste Symbol, a convenient way to apply the item’s representation to others\n•Change Color...of the selected symbol(s)\n•Change Opacity...of the selected symbol(s)\n•Change Output Unit...of the selected symbol(s)\n•Change Width...of the selected line symbol(s)\n•Change Size...of the selected point symbol(s)\n•Change Angle...of the selected point symbol(s)\nThe example inFig. 15.5shows the graduated rendering dialog for the major_rivers layer of the QGIS sample dataset.\n440Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.5: Graduated Symbolizing options\nTip: Thematic maps using an expression\nCategorized and graduated thematic maps can be created using the result of an expression. In the properties dialog\nfor vector layers, the attribute chooser is extended with a\nSet column expression\nfunction. So you don’t need to write the\nclassification attribute to a new column in your attribute table if you want the classification attribute to be a composite\nof multiple fields, or a formula of some sort.\nProportional Symbol and Multivariate Analysis\nProportional Symbol and Multivariate Analysis are not rendering types available from the Symbology rendering drop-\ndown list. However with thedata-defined overrideoptions applied over any of the previous rendering options, QGIS\nallows you to display your point and line data with such representation.\nCreating proportional symbol\nTo apply a proportional rendering:\n1.First apply to the layer thesingle symbol renderer.\n2.Then set the symbol to apply to the features.\n3.Select the item at the upper level of the symbol tree, and use the\nData-defined override\nbuttonnext to theSize\n(for point layer) orWidth(for line layer) option.\n4.Select a field or enter an expression, and for each feature, QGIS will apply the output value to the property and\nproportionally resize the symbol in the map canvas.\n15.1. The Vector Properties Dialog441\n\nQGIS Desktop 3.22 User Guide\nIf need be, use theSize assistant...option of themenu to apply some transformation (exponential, flan-\nnery...) to the symbol size rescaling (seeUsing the data-defined assistant interfacefor more details).\nYou can choose to display the proportional symbols in theLayers paneland theprint layout legend item: unfold\ntheAdvanceddrop-down list at the bottom of the main dialog of theSymbologytab and selectData-defined size\nlegend...to configure the legend items (seeData-defined size legendfor details).\nCreating multivariate analysis\nA multivariate analysis rendering helps you evaluate the relationship between two or more variables e.g., one can be\nrepresented by a color ramp while the other is represented by a size.\nThe simplest way to create multivariate analysis in QGIS is to:\n1.First apply a categorized or graduated rendering on a layer, using the same type of symbol for all the classes.\n2.Then, apply a proportional symbology on the classes:\n1.Click on theChangebutton above the classification frame: you get theThe Symbol Selectordialog.\n2.Rescale the size or width of the symbol layer using thedata defined overridewidget as seen above.\nLike the proportional symbol, the scaled symbology can be added to the layer tree, on top of the categorized or\ngraduated classes symbols using the\ndata defined size legendfeature. And both representation are also available in the\nprint layout legend item.\nFig. 15.6: Multivariate example with scaled size legend\nRule-based Renderer\nRules are QGISexpressionsused to discriminate features according to their attributes or properties in order to apply\nspecific rendering settings to them. Rules can be nested, and features belong to a class if they belong to all the upper\nnesting level(s).\nThe\nRule-basedrenderer is thus designed to render all the features from a layer, using symbols whose aspect\nreflects the assignment of a selected feature to a fine-grained class.\nTo create a rule:\n442Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n1.Activate an existing row by double-clicking it (by default, QGIS adds a symbol without a rule when the rendering\nmode is enabled) or click the\nEdit rule\nor\nAdd rule\nbutton.\n2.In theEdit Ruledialog that opens, you can define a label to help you identify each rule. This is the label that\nwill be displayed in theLayers Paneland also in the print composer legend.\n3.Manually enter an expression in the text box next to theFilteroption or press thebutton next to it to\nopen the expression string builder dialog.\n4.Use the provided functions and the layer attributes to build anexpressionto filter the features you’d like to\nretrieve. Press theTestbutton to check the result of the query.\n5.You can enter a longer label to complete the rule description.\n6.You can use theScale Rangeoption to set scales at which the rule should be applied.\n7.Finally, configure thesymbol to usefor these features.\n8.And pressOK.\nA new row summarizing the rule is added to the Layer Properties dialog. You can create as many rules as necessary\nfollowing the steps above or copy pasting an existing rule. Drag-and-drop the rules on top of each other to nest them\nand refine the upper rule features in subclasses.\nThe rule-based renderer can be combined with categorized or graduated renderers. Selecting a rule, you can organize\nits features in subclasses using theRefine selected rulesdrop-down menu. Refined classes appear like sub-items of the\nrule, in a tree hierarchy and like their parent, you can set the symbology and the rule of each class. Automated rule\nrefinement can be based on:\n•scales: given a list of scales, this option creates a set of classes to which the different user-defined scale ranges\napply. Each new scale-based class can have its own symbology and expression of definition. This can e.g. be\na convenient way to display the same features with various symbols at different scales, or display only a set of\nfeatures depending on the scale (e.g. local airports at large scale vs international airports at small scale).\n•categories: applies acategorized rendererto the features falling in the selected rule.\n•orranges: applies agraduated rendererto the features falling in the selected rule.\nRefined classes appear like sub-items of the rule, in a tree hierarchy and like above, you can set symbology of each\nclass. Symbols of the nested rules are stacked on top of each other so be careful in choosing them. It is also possible\nto uncheckSymbolsin theEdit ruledialog to avoid rendering a particular symbol in the stack.\nIn theEdit ruledialog, you can avoid writing all the rules and make use of theElseoption to catch all the features\nthat do not match any of the other rules, at the same level. This can also be achieved by writingElsein theRule\ncolumn of theLayer Properties►Symbology►Rule-baseddialog.\nRight-clicking over selected item(s) shows a contextual menu to:\n•CopyandPaste, a convenient way to create new item(s) based on existing item(s)\n•Copy SymbolandPaste Symbol, a convenient way to apply the item’s representation to others\n•Change Color...of the selected symbol(s)\n•Change Opacity...of the selected symbol(s)\n•Change Output Unit...of the selected symbol(s)\n•Change Width...of the selected line symbol(s)\n•Change Size...of the selected point symbol(s)\n•Change Angle...of the selected point symbol(s)\n•Refine Current Rule: open a submenu that allows to refine the current rule withscales,categoriesorRanges.\nSame as selecting the\ncorresponding menuat the bottom of the dialog.\n15.1. The Vector Properties Dialog443\n\nQGIS Desktop 3.22 User Guide\nUnchecking a row in the rule-based renderer dialog hides in the map canvas the features of the specific rule and the\nnested ones.\nThe created rules also appear in a tree hierarchy in the map legend. Double-click an entry in the map legend to edit\nthe assigned symbol.\nThe example inFig. 15.7shows the rule-based rendering dialog for the rivers layer of the QGIS sample dataset.\nFig. 15.7: Rule-based Symbolizing options\nPoint displacement Renderer\nThePoint Displacementrenderer works to visualize all features of a point layer, even if they have the same\nlocation. To do this, the renderer takes the points falling in a givenDistancetolerance from each other and places\nthem around their barycenter following differentPlacement methods:\n•Ring: places all the features on a circle whose radius depends on the number of features to display.\n•Concentric rings: uses a set of concentric circles to show the features.\n•Grid: generates a regular grid with a point symbol at each intersection.\nTheCenter symbolwidget helps you customize the symbol and color of the middle point. For the distributed points\nsymbols, you can apply any of theNo symbols,Single symbol,Categorized,GraduatedorRule-basedrenderer using\ntheRendererdrop-down list and customize them using theRenderer Settings...button.\nWhile the minimal spacing of theDisplacement linesdepends on the point symbol renderer’s, you can still customize\nsome of its settings such as theStroke width,Stroke colorandSize adjustment(eg, to add more spacing between the\nrendered points).\nUse theLabelsgroup options to perform points labeling: the labels are placed near the displaced position of the\nsymbol, and not at the feature real position. Other than theLabel attribute,Label fontandLabel color, you can set\ntheMinimum map scaleto display the labels.\n444Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.8: Point displacement dialog\nNote:Point Displacement renderer does not alter feature geometry, meaning that points are not moved from their\nposition. They are still located at their initial place. Changes are only visual, for rendering purpose. Use instead the\nProcessingPoints displacementalgorithm if you want to create displaced features.\nPoint Cluster Renderer\nUnlike thePoint Displacementrenderer which blows up nearest or overlaid point features placement, the\nPoint Clusterrenderer groups nearby points into a single rendered marker symbol. Based on a specifiedDistance,\npoints that fall within from each others are merged into a single symbol. Points aggregation is made based on the\nclosest group being formed, rather than just assigning them the first group within the search distance.\nFrom the main dialog, you can:\n•set the symbol to represent the point cluster in theCluster symbol; the default rendering displays the number of\naggregated features thanks to the@cluster_sizevariableon Font marker symbol layer.\n•use theRendererdrop-down list to apply any of the other feature rendering types to the layer (single, cate-\ngorized, rule-based...). Then, push theRenderer Settings...button to configure features’ symbology as usual.\nNote that this renderer is only visible on features that are not clustered. Also, when the symbol color is the\nsame for all the point features inside a cluster, that color sets the@cluster_colorvariable of the cluster.\n15.1. The Vector Properties Dialog445\n\nQGIS Desktop 3.22 User Guide\nFig. 15.9: Point Cluster dialog\nNote:Point Cluster renderer does not alter feature geometry, meaning that points are not moved from their position.\nThey are still located at their initial place. Changes are only visual, for rendering purpose. Use instead the Processing\nK-means clusteringorDBSCAN clusteringalgorithm if you want to create cluster-based features.\nMerged Features Renderer\nTheMerged Featuresrenderer allows area and line features to be “dissolved” into a single object prior to rendering\nto ensure that complex symbols or overlapping features are represented by a uniform and contiguous cartographic\nsymbol.\nInverted Polygon Renderer\nTheInverted Polygonrenderer allows user to define a symbol to fill in outside of the layer’s polygons. As above\nyou can select subrenderers, namely Single symbol, Graduated, Categorized, Rule-Based or 2.5D renderer.\n446Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.10: Inverted Polygon dialog\nHeatmap Renderer\nWith theHeatmaprenderer you can create live dynamic heatmaps for (multi)point layers. You can specify the\nheatmap radius in millimeters, points, pixels, map units or inches, choose and edit a color ramp for the heatmap style\nand use a slider for selecting a trade-off between render speed and quality. You can also define a maximum value\nlimit and give a weight to points using a field or an expression. When adding or removing a feature the heatmap\nrenderer updates the heatmap style automatically.\nFig. 15.11: Heatmap dialog\n15.1. The Vector Properties Dialog447\n\nQGIS Desktop 3.22 User Guide\n2.5D Renderer\nUsing the2.5Drenderer it’s possible to create a 2.5D effect on your layer’s features. You start by choosing a\nHeightvalue (in map units). For that you can use a fixed value, one of your layer’s fields, or an expression. You also\nneed to choose anAngle(in degrees) to recreate the viewer position (0° means west, growing in counter clock wise).\nUse advanced configuration options to set theRoof ColorandWall Color. If you would like to simulate solar radiation\non the features walls, make sure to check theShade walls based on aspectoption. You can also simulate a shadow\nby setting aColorandSize(in map units).\nFig. 15.12: 2.5D dialog\nTip: Using 2.5D effect with other renderers\nOnce you have finished setting the basic style on the 2.5D renderer, you can convert this to another renderer (single,\ncategorized, graduated). The 2.5D effects will be kept and all other renderer specific options will be available for\nyou to fine tune them (this way you can have for example categorized symbols with a nice 2.5D representation or add\nsome extra styling to your 2.5D symbols). To make sure that the shadow and the “building” itself do not interfere with\nother nearby features, you may need to enable Symbols Levels (Advanced►Symbol levels...). The 2.5D height and\nangle values are saved in the layer’s variables, so you can edit it afterwards in the variables tab of the layer’s properties\ndialog.\n448Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nEmbedded Renderer\nTheEmbedded Symbolsrenderer allows to display the ‘native’ symbology of a provided datasource. This is mostly\nthe case withKMLandTABdatasets that have predefined symbology.\nLayer rendering\nFrom the Symbology tab, you can also set some options that invariably act on all features of the layer:\n•Opacity: You can make the underlying layer in the map canvas visible with this tool. Use\nthe slider to adapt the visibility of your vector layer to your needs. You can also make a precise definition of\nthe percentage of visibility in the menu beside the slider.\n•Blending modeat theLayerandFeaturelevels: You can achieve special rendering effects with these tools that\nyou may previously only know from graphics programs. The pixels of your overlaying and underlaying layers\nare mixed through the settings described inBlending Modes.\n•Applypaint effectson all the layer features with theDraw Effectsbutton.\n•Control feature rendering orderallows you, using features attributes, to define the z-order in which they shall\nbe rendered. Activate the checkbox and click on thebutton beside. You then get theDefine Orderdialog\nin which you:\n1.Choose a field or build an expression to apply to the layer features.\n2.Set in which order the fetched features should be sorted, i.e. if you chooseAscendingorder, the features\nwith lower value are rendered under those with higher value.\n3.Define when features returning NULL value should be rendered:first(bottom) orlast(top).\n4.Repeat the above steps as many times as rules you wish to use.\nThe first rule is applied to all the features in the layer, z-ordering them according to their returned value. Then,\nwithin each group of features with the same value (including those with NULL value) and thus the same z-level,\nthe next rule is applied to sort them. And so on...\nFig. 15.13: Layer rendering options\nOther Settings\nSymbol levels\nFor renderers that allow stacked symbol layers (only heatmap doesn’t) there is an option to control the rendering order\nof each symbol’s levels.\nFor most of the renderers, you can access the Symbols levels option by clicking theAdvancedbutton below the saved\nsymbols list and choosingSymbol levels. For theRule-based Rendererthe option is directly available throughSymbols\nLevels...button, while for\nPoint displacement Rendererrenderer the same button is inside theRendering settingsdialog.\nTo activate symbols levels, select the\nEnable symbol levels. Each row will show up a small sample of the combined\nsymbol, its label and the individual symbols layer divided into columns with a number next to it. The numbers\nrepresent the rendering order level in which the symbol layer will be drawn. Lower values levels are drawn first,\nstaying at the bottom, while higher values are drawn last, on top of the others.\n15.1. The Vector Properties Dialog449\n\nQGIS Desktop 3.22 User Guide\nFig. 15.14: Symbol levels dialog\nNote:If symbols levels are deactivated, the complete symbols will be drawn according to their respective features\norder. Overlapping symbols will simply obfuscate to other below. Besides, similar symbols won’t “merge” with each\nother.\nFig. 15.15: Symbol levels activated (A) and deactivated (B) difference\nData-defined size legend\nWhen a layer is rendered with theproportional symbol or the multivariate renderingor when ascaled size diagram\nis applied to the layer, you can allow the display of the scaled symbols in both theLayers paneland theprint layout\nlegend\n.\nTo enable theData-defined Size Legenddialog to render symbology, select the eponym option in theAdvancedbutton\nbelow the saved symbols list. For diagrams, the option is available under theLegendtab. The dialog provides the\nfollowing options to:\n•select the type of legend:Legend not enabled,Separated legend itemsandCollapsed legend. For\nthe latter option, you can select whether the legend items are aligned at theBottomor at theCenter;\n450Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•preview thesymbol to usefor legend representation;\n•insert the title in the legend;\n•resize the classes to use: by default, QGIS provides you with a legend of five classes (based on natural pretty\nbreaks) but you can apply your own classification using theManual size classesoption. Use theand\nbuttons to set your custom classes values and labels.\n•For collapsed legend, it’s possible to:\n–Align symbolsin the center or the bottom\n–configure the horizontal leaderLine symbolfrom the symbol to the corresponding legend text.\nA preview of the legend is displayed in the right panel of the dialog and updated as you set the parameters.\nFig. 15.16: Setting size scaled legend\nNote:Currently, data-defined size legend for layer symbology can only be applied to point layer using single,\ncategorized or graduated symbology.\nDraw effects\nIn order to improve layer rendering and avoid (or at least reduce) the resort to other software for final rendering\nof maps, QGIS provides another powerful functionality: the\nDraw Effectsoptions, which adds paint effects for\ncustomizing the visualization of vector layers.\nThe option is available in theLayer Properties►Symbologydialog, under the\nLayer renderinggroup (applying to the\nwhole layer) or insymbol layer properties(applying to corresponding features). You can combine both usage.\nPaint effects can be activated by checking theDraw effectsoption and clicking the\nCustomize effects\nbutton. That\nwill open theEffect PropertiesDialog (see\nFig. 15.17). The following effect types, with custom options are available:\n15.1. The Vector Properties Dialog451\n\nQGIS Desktop 3.22 User Guide\n•Source: Draws the feature’s original style according to the configuration of the layer’s properties. TheOpacity\nof its style can be adjusted as well as theBlend modeandDraw mode. These are common properties for all\ntypes of effects.\nFig. 15.17: Draw Effects: Source dialog\n•Blur: Adds a blur effect on the vector layer. The custom options that you can change are theBlur type(Stack\nblur (fast)orGaussian blur (quality)) and theBlur strength.\nFig. 15.18: Draw Effects: Blur dialog\n•Colorise: This effect can be used to make a version of the style using one single hue. The base will always be\na grayscale version of the symbol and you can:\n–Use theGrayscaleto select how to create it: options are ‘By lightness’, ‘By luminosity’, ‘By average’\nand ‘Off’.\n–IfColoriseis selected, it will be possible to mix another color and choose how strong it should be.\n452Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n–Control theBrightness,ContrastandSaturationlevels of the resulting symbol.\nFig. 15.19: Draw Effects: Colorize dialog\n•Drop Shadow: Using this effect adds a shadow on the feature, which looks like adding an extra dimension.\nThis effect can be customized by changing theOffsetangle and distance, determining where the shadow shifts\ntowards to and the proximity to the source object.Drop Shadowalso has the option to change theBlur radius\nand theColorof the effect.\nFig. 15.20: Draw Effects: Drop Shadow dialog\n15.1. The Vector Properties Dialog453\n\nQGIS Desktop 3.22 User Guide\n•Inner Shadow: This effect is similar to theDrop Shadoweffect, but it adds the shadow effect on the inside of\nthe edges of the feature. The available options for customization are the same as theDrop Shadoweffect.\nFig. 15.21: Draw Effects: Inner Shadow dialog\n•Inner Glow: Adds a glow effect inside the feature. This effect can be customized by adjusting theSpread\n(width) of the glow, or theBlur radius. The latter specifies the proximity from the edge of the feature where\nyou want any blurring to happen. Additionally, there are options to customize the color of the glow using a\nSingle coloror aColor ramp.\nFig. 15.22: Draw Effects: Inner Glow dialog\n454Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•Outer Glow: This effect is similar to theInner Gloweffect, but it adds the glow effect on the outside of the\nedges of the feature. The available options for customization are the same as theInner Gloweffect.\nFig. 15.23: Draw Effects: Outer Glow dialog\n•Transform: Adds the possibility of transforming the shape of the symbol. The first options available for\ncustomization are theReflect horizontalandReflect vertical, which actually create a reflection on the horizontal\nand/or vertical axes. The other options are:\n–Shear X,Y: Slants the feature along the X and/or Y axis.\n–Scale X,Y: Enlarges or minimizes the feature along the X and/or Y axis by the given percentage.\n–Rotation: Turns the feature around its center point.\n–andTranslate X,Ychanges the position of the item based on a distance given on the X and/or Y axis.\n15.1. The Vector Properties Dialog455\n\nQGIS Desktop 3.22 User Guide\nFig. 15.24: Draw Effects: Transform dialog\nOne or more effect types can be used at the same time. You (de)activate an effect using its checkbox in the effects list.\nYou can change the selected effect type by using theEffect typeoption. You can reorder the effects using\nMove up\nand\nMove down\nbuttons, and also add/remove effects using the\nAdd new effect\nand\nRemove effect\nbuttons.\nThere are some common options available for all draw effect types.OpacityandBlend modeoptions work similar to\nthe ones described inLayer renderingand can be used in all draw effects except for the transform one.\nThere is also aDraw modeoption available for every effect, and you can choose whether to render and/or\nmodify the symbol, following some rules:\n•Effects render from top to bottom.\n•Render onlymode means that the effect will be visible.\n•Modifier onlymode means that the effect will not be visible but the changes that it applies will be passed to the\nnext effect (the one immediately below).\n•TheRender and Modifymode will make the effect visible and pass any changes to the next effect. If the effect\nis at the top of the effects list or if the immediately above effect is not in modify mode, then it will use the\noriginal source symbol from the layers properties (similar to source).\n15.1.4Labels Properties\nTheLabelsproperties provides you with all the needed and appropriate capabilities to configure smart labeling\non vector layers. This dialog can also be accessed from theLayer Stylingpanel, or using the\nLayer Labeling Options\nbutton of theLabels toolbar.\nThe first step is to choose the labeling method from the drop-down list. Available methods are:\n•No labels: the default value, showing no labels from the layer\n•Single labels: Show labels on the map using a single attribute or an expression\n•Rule-based labeling\n456Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•andBlocking: allows to set a layer as just an obstacle for other layer’s labels without rendering any labels\nof its own.\nThe next steps assume you select theSingle labelsoption, opening the following dialog.\nFig. 15.25: Layer labeling settings - Single labels\nAt the top of the dialog, aValuedrop-down list is enabled. You can select an attribute column to use for labeling.\nBy default, thedisplay fieldis used. Clickif you want to define labels based on expressions - SeeDefine labels\nbased on expressions.\nNote:\nLabels with their formatting can be displayed as entries in the legends, if enabled in the\nLegendtab.\nBelow are displayed options to customize the labels, under various tabs:\n•Text\n•Formatting\n•Buffer\n•Mask\n•Background\n•Shadow\n•Callouts\n15.1. The Vector Properties Dialog457\n\nQGIS Desktop 3.22 User Guide\n•Placement\n•Rendering\nDescription of how to set each property is exposed atSetting a label.\nSetting the automated placement engine\nYou can use the automated placement settings to configure a project-level automated behavior of the labels. In the\ntop right corner of theLabelstab, click the\nAutomated placement settings (applies to all layers)\nbutton, opening a dialog with\nthe following options:\nFig. 15.26: The labels automated placement engine\n•Number of candidates: calculates and assigns to line and polygon features the number of possible labels place-\nment based on their size. The longer or wider a feature is, the more candidates it has, and its labels can be\nbetter placed with less risk of collision.\n•Text rendering: sets the default value for label rendering widgets whenexporting a map canvasora layoutto\nPDF or SVG. IfAlways render labels as textis selected then labels can be edited in external applications (e.g.\nInkscape) as normal text. BUT the side effect is that the rendering quality is decreased, and there are issues\nwith rendering when certain text settings like buffers are in place. That’s whyAlways render labels as paths\n(recommended)which exports labels as outlines, is recommended.\n•Allow truncated labels on edges of map: controls whether labels which fall partially outside of the map\nextent should be rendered. If checked, these labels will be shown (when there’s no way to place them fully\nwithin the visible area). If unchecked then partially visible labels will be skipped. Note that this setting has no\neffects on labels’ display in the\nlayout map item.\n•Show all labels for all layers (i.e. including colliding objects). Note that this option can be also set per layer\n(seeRendering tab)\n•Show unplaced labels: allows to determine whether any important labels are missing from the maps (e.g.\ndue to overlaps or other constraints). They are displayed using a customizable color.\n•Show candidates (for debugging): controls whether boxes should be drawn on the map showing all the\ncandidates generated for label placement. Like the label says, it’s useful only for debugging and testing the\neffect different labeling settings have. This could be handy for a better manual placement with tools from the\nlabel toolbar.\n458Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•Project labeling version: QGIS supports two different versions of label automatic placement:\n–Version 1: the old system (used by QGIS versions 3.10 and earlier, and when opening projects created\nin these versions in QGIS 3.12 or later). Version 1 treats label and obstacle priorities as “rough guides”\nonly, and it’s possible that a low-priority label will be placed over a high-priority obstacle in this version.\nAccordingly, it can be difficult to obtain the desired labeling results when using this version and it is thus\nrecommended only for compatibility with older projects.\n–Version 2 (recommended): this is the default system in new projects created in QGIS 3.12 or later. In\nversion 2, the logic dictating when labels are allowed to overlapobstacleshas been reworked. The newer\nlogic forbids any labels from overlapping any obstacles with a greater obstacle weight compared to the\nlabel’s priority. As a result, this version results in much more predictable and easier to understand labeling\nresults.\nRule-based labeling\nWith rule-based labeling multiple label configurations can be defined and applied selectively on the base of expression\nfilters and scale range, as inRule-based rendering.\nTo create a rule:\n1.Select theRule-based labelingoption in the main drop-down list from theLabelstab\n2.Click the\nAdd rule\nbutton at the bottom of the dialog.\n3.Fill the new dialog with:\n•Description: a text used to identify the rule in theLabelstab and as alabel legend entryin the print layout\nlegend\n•Filter: an expression to select the features to apply the label settings to\n•If there are rules already set, theElseoption can be used to select all the features not matching any filter\nof the rules in the same group.\n4.You can set ascale rangein which the label rule should be applied.\n5.The options available under theLabelsgroup box are the usuallabel settings. Configure them and pressOK.\n15.1. The Vector Properties Dialog459\n\nQGIS Desktop 3.22 User Guide\nFig. 15.27: Rule settings\n460Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nA summary of existing rules is shown in the main dialog (seeFig. 15.28). You can add multiple rules, reorder or\nimbricate them with a drag-and-drop. You can as well remove them with thebutton or edit them withbutton\nor a double-click.\nFig. 15.28: Rule based labeling panel\nDefine labels based on expressions\nWhether you choose single or rule-based labeling type, QGIS allows using expressions to label features.\nAssuming you are using theSingle labelsmethod, click thebutton near theValuedrop-down list in theLabels\ntab of the properties dialog.\nIn\nFig. 15.29, you see a sample expression to label the alaska trees layer with tree type and area, based on the field\n‘VEGDESC’, some descriptive text, and the function$areain combination withformat_number()to make it\nlook nicer.\nFig. 15.29: Using expressions for labeling\nExpression based labeling is easy to work with. All you have to take care of is that:\n•You may need to combine all elements (strings, fields, and functions) with a string concatenation function such\nasconcat,+or||. Be aware that in some situations (when null or numeric value are involved) not all of\nthese tools will fit your need.\n15.1. The Vector Properties Dialog461\n\nQGIS Desktop 3.22 User Guide\n•Strings are written in ‘single quotes’.\n•Fields are written in “double quotes” or without any quote.\nLet’s have a look at some examples:\n1.Label based on two fields ‘name’ and ‘place’ with a comma as separator:\n\"name\"||','||\"place\"\nReturns:\nJohn Smith, Paris\n2.Label based on two fields ‘name’ and ‘place’ with other texts:\n'My name is ' + \"name\" + 'and I live in ' + \"place\"\n'My name is ' || \"name\" || 'and I live in ' || \"place\"\nconcat('My name is ', name, ' and I live in ', \"place\")\nReturns:\nMy nameisJohn SmithandI liveinParis\n3.Label based on two fields ‘name’ and ‘place’ with other texts combining different concatenation functions:\nconcat('My name is ', name, ' and I live in ' || place)\nReturns:\nMy nameisJohn SmithandI liveinParis\nOr, if the field ‘place’ is NULL, returns:\nMy nameisJohn Smith\n4.Multi-line label based on two fields ‘name’ and ‘place’ with a descriptive text:\nconcat('My name is ', \"name\", '\\n' , 'I live in ' , \"place\")\nReturns:\nMy nameisJohn Smith\nI liveinParis\n5.Label based on a field and the $area function to show the place’s name and its rounded area size in a converted\nunit:\n'The area of ' || \"place\" || ' has a size of '\n|| round($area/10000) || ' ha'\nReturns:\nThe area of Paris has a size of10500ha\n6.Create a CASE ELSE condition. If the population value in fieldpopulationis <= 50000 it is a town, otherwise\nit is a city:\nconcat('This place is a ',\nCASE WHEN \"population\" <= 50000 THEN 'town' ELSE 'city' END)\nReturns:\n462Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nThis placeisa town\n7.Display name for the cities and no label for the other features (for the “city” context, see example above):\nCASE WHEN \"population\" > 50000 THEN \"NAME\" END\nReturns:\nParis\nAs you can see in the expression builder, you have hundreds of functions available to create simple and very complex\nexpressions to label your data in QGIS. SeeExpressionschapter for more information and examples on expressions.\nUsing data-defined override for labeling\nWith the\nData defined override\nfunction, the settings for the labeling are overridden by entries in the attribute table or\nexpressions based on them. This feature can be used to set values for most of the labeling options described above.\nFor example, using the Alaska QGIS sample dataset, let’s label theairportslayer with their name, based on their\nmilitarianUSE, i.e. whether the airport is accessible to :\n•military people, then display it in gray color, size 8;\n•others, then show in blue color, size 10.\nTo do this, after you enabled the labeling on theNAMEfield of the layer (seeSetting a label):\n1.Activate theTexttab.\n2.Click on theicon next to theSizeproperty.\n3.SelectEdit...and type:\nCASE\nWHEN\"USE\"like'%Military%'THEN8--because compatible values are\n,→'Military'\n--and'Joint Military/Civilian'\nELSE10\nEND\n4.PressOKto validate. The dialog closes and thebutton becomesmeaning that an rule is being run.\n5.Then click the button next to the color property, type the expression below and validate:\nCASE\nWHEN\"USE\"like'%Military%'THEN'150, 150, 150'\nELSE'0, 0, 255'\nEND\nLikewise, you can customize any other property of the label, the way you want. See more details on the\nData-define override\nwidget’s description and manipulation inData defined override setupsection.\n15.1. The Vector Properties Dialog463\n\nQGIS Desktop 3.22 User Guide\nFig. 15.30: Airports labels are formatted based on their attributes\nTip: Use the data-defined override to label every part of multi-part features\nThere is an option to set the labeling for multi-part features independently from your label properties. Choose the\nRendering,Feature options, go to the\nData-define override\nbutton next to the checkboxLabel every\npart of multipart-featuresand define the labels as described in\nData defined override setup.\nThe Label Toolbar\nTheLabel Toolbarprovides some tools to manipulatelabel(including theircallout) ordiagramproperties:\nFig. 15.31: The Label toolbar\n•\nHighlight Pinned Labels, Diagrams and Callouts\n. If the vector layer of the item is editable, then the highlighting is green,\notherwise it’s blue.\n•\nToggle Display of Unplaced Labels\n: Allows to determine whether any important labels are missing from the maps\n(e.g. due to overlaps or other constraints). They are displayed with a customizable color (see\nSetting the\nautomated placement engine).\n•\nPin/Unpin Labels and Diagrams\n. By clicking or draging an area, you pin overlaid items. If you click or drag an area\nholdingShift, the items are unpinned. Finally, you can also click or drag an area holdingCtrlto toggle\n464Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\ntheir pin status.\n•\nShow/Hide Labels and Diagrams\n. If you click on the items, or click and drag an area holdingShift, they are\nhidden. When an item is hidden, you just have to click on the feature to restore its visibility. If you drag an\narea, all the items in the area will be restored.\n•\nMove a Label, Diagram or Callout\n: click to select the item and click to move it to the desired place. The new\ncoordinates are stored inauxiliary fields. Selecting the item with this tool and hitting theDeletekey will\ndelete the stored position value.\n•\nRotate a Label\n. Click to select the label and click again to apply the desired rotation. Likewise, the new angle\nis stored in an auxiliary field. Selecting a label with this tool and hitting theDeletekey will delete the rotation\nvalue of this label.\n•\nChange Label Properties\n. It opens a dialog to change the clicked label properties; it can be the label itself, its\ncoordinates, angle, font, size, multiline alignment ... as long as this property has been mapped to a field. Here\nyou can set the option toLabel every part of a feature.\nWarning: Label tools overwrite current field values\nUsing theLabel toolbarto customize the labeling actually writes the new value of the property in the mapped\nfield. Hence, be careful to not inadvertently replace data you may need later!\nNote:TheAuxiliary Storage Propertiesmechanism may be used to customize labeling (position, and so on) without\nmodifying the underlying data source.\nCustomize the labels from the map canvas\nCombined with theLabel Toolbar, the data defined override setting helps you manipulate labels in the map\ncanvas (move, edit, rotate).  We now describe an example using the data-defined override function for the\nMove Label, Diagram or Callout\nfunction (seeFig. 15.32).\n1.Importlakes.shpfrom the QGIS sample dataset.\n2.Double-click the layer to open the Layer Properties. Click onLabelsandPlacement. SelectOffset from\ncentroid.\n3.Look for theData definedentries. Click theicon to define the field type for theCoordinate. Choose\nxlabelfor X andylabelfor Y. The icons are now highlighted in yellow.\nFig. 15.32: Labeling of vector polygon layers with data-defined override\n4.Zoom into a lake.\n5.Set editable the layer using the\nToggle Editing\nbutton.\n15.1. The Vector Properties Dialog465\n\nQGIS Desktop 3.22 User Guide\n6.Go to the Label toolbar and click theicon. Now you can shift the label manually to another position (see\nFig. 15.33). The new position of the label is saved in thexlabelandylabelcolumns of the attribute table.\n7.It’s also possible to add a line connecting each lake to its moved label using:\n•the label’scallout property\n•or thegeometry generator symbol layerwith the expression below:\nmake_line( centroid( $geometry ), make_point( \"xlabel\", \"ylabel\" ) )\nFig. 15.33: Moved labels\nNote:TheAuxiliary Storage Propertiesmechanism may be used with data-defined properties without having an\neditable data source.\n466Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n15.1.5Diagrams Properties\nTheDiagramstab allows you to add a graphic overlay to a vector layer (seeFig. 15.34).\nThe current core implementation of diagrams provides support for:\n•No diagrams: the default value with no diagram displayed over the features;\n•Pie chart, a circular statistical graphic divided into slices to illustrate numerical proportion. The arc length\nof each slice is proportional to the quantity it represents;\n•Text diagram, a horizontaly divided circle showing statistics values inside;\n•Histogram, bars of varying colors for each attribute aligned next to each other\n•Stacked bars, Stacks bars of varying colors for each attribute on top of each other vertically or horizontally\nIn the top right corner of theDiagramstab, the\nAutomated placement settings (applies to all layers)\nbutton provides means to\ncontrol diagram\nlabels placementon the map canvas.\nTip: Switch quickly between types of diagrams\nGiven that the settings are almost common to the different types of diagram, when designing your diagram, you can\neasily change the diagram type and check which one is more appropriate to your data without any loss.\nFor each type of diagram, the properties are divided into several tabs:\n•Attributes\n•Rendering\n•Size\n•Placement\n•Options\n•Legend\nAttributes\nAttributesdefines which variables to display in the diagram. Use\nadd item\nbutton to select the desired fields into the\n‘Assigned Attributes’ panel. Generated attributes withExpressionscan also be used.\nYou can move up and down any row with click and drag, sorting how attributes are displayed. You can also change\nthe label in the ‘Legend’ column or the attribute color by double-clicking the item.\nThis label is the default text displayed in the legend of the print layout or of the layer tree.\n15.1. The Vector Properties Dialog467\n\nQGIS Desktop 3.22 User Guide\nFig. 15.34: Diagram properties - Attributes tab\nRendering\nRenderingdefines how the diagram looks like. It provides general settings that do not interfere with the statistic values\nsuch as:\n•the graphic’s opacity, its outline width and color;\n•depending on the type of diagram:\n–for histogram and stacked bars, the width of the bar and the spacing between the bars. You may want\nto set the spacing to0for stacked bars. Moreover, theAxis line symbolcan be made visible on the map\ncanvas and customized using\nline symbol properties.\n–for text diagram, the circle background color and thefontused for texts;\n–for pie charts, theStart angleof the first slice and theirDirection(clockwise or not).\n•the use ofpaint effectson the graphics.\nIn this tab, you can also manage and fine tune the diagram visibility with different options:\n•Diagram z-index: controls how diagrams are drawn on top of each other and on top of labels. A diagram with\na high index is drawn over diagrams and labels;\n•Show all diagrams: shows all the diagrams even if they overlap each other;\n•Show diagram: allows only specific diagrams to be rendered;\n•Always Show: selects specific diagrams to always render, even when they overlap other diagrams or map labels;\n•setting theScale dependent visibility;\n468Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.35: Diagram properties - Rendering tab\nSize\nSizeis the main tab to set how the selected statistics are represented. The diagram sizeunitscan be ‘Millimeters’,\n‘Points’, ‘Pixels’, ‘Map Units’ or ‘Inches’. You can use:\n•Fixed size, a unique size to represent the graphic of all the features (not available for histograms)\n•orScaled size, based on an expression using layer attributes:\n1.InAttribute, select a field or build an expression\n2.PressFindto return theMaximum valueof the attribute or enter a custom value in the widget.\n3.For histogram and stacked bars, enter aBar lengthvalue, used to represent theMaximum valueof the\nattributes. For each feature, the bar lenght will then be scaled linearly to keep this matching.\n4.For pie chart and text diagram, enter aSizevalue, used to represent theMaximum valueof the attributes.\nFor each feature, the circle area or diameter will then be scaled linearly to keep this matching (from0).\nAMinimum sizecan however be set for small diagrams.\n15.1. The Vector Properties Dialog469\n\nQGIS Desktop 3.22 User Guide\nFig. 15.36: Diagram properties - Size tab\nPlacement\nPlacementdefines the diagram position. Depending on the layer geometry type, it offers different options for the\nplacement (more details atPlacement):\n•Around pointorOver pointfor point geometry. The former variable requires a radius to follow.\n•Around lineorOver linefor line geometry. Like point feature, the first variable requires a distance to respect\nand you can specify the diagram placement relative to the feature (‘above’, ‘on’ and/or ‘below’ the line) It’s\npossible to select several options at once. In that case, QGIS will look for the optimal position of the diagram.\nRemember that you can also use the line orientation for the position of the diagram.\n•Around centroid(at a setDistance),Over centroid,Using perimeterandInside polygonare the options for polygon\nfeatures.\nTheCoordinategroup provides direct control on diagram placement, on a feature-by-feature basis, using their at-\ntributes or an expression to set theXandYcoordinate. The information can also be filled using the\nMove labels and\ndiagrams\ntool.\nIn thePrioritysection, you can define the placement priority rank of each diagram, ie if there are different diagrams\nor labels candidates for the same location, the item with the higher priority will be displayed and the others could be\nleft out.\nDiscourage diagrams and labels from covering featuresdefines features to use asobstacles, ie QGIS will try to not\nplace diagrams nor labels over these features. The priority rank is then used to evaluate whether a diagram could be\nomitted due to a greater weighted obstacle feature.\n470Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.37: Vector properties dialog with diagram properties, Placement tab\nOptions\nTheOptionstab has settings for histograms and stacked bars. You can choose whether theBar orientationshould be\nUp,Down,RightorLeft, for horizontal and vertical diagrams.\nLegend\nFrom theLegendtab, you can choose to display items of the diagram in theLayers panel, and in theprint layout\nlegend, next to the layer symbology:\n•checkShow legend entries for diagram attributesto display in the legends theColorandLegendproperties,\nas previously assigned in theAttributestab;\n•and, when ascaled sizeis being used for the diagrams, push theLegend Entries for Diagram Size...button to\nconfigure the diagram symbol aspect in the legends. This opens theData-defined Size Legenddialog whose\noptions are described inData-defined size legend.\nWhen set, the diagram legend items (attributes with color and diagram size) are also displayed in the print layout\nlegend, next to the layer symbology.\n15.1.6Masks Properties\nTheMaskstab helps you configure the current layer symbols overlay with other symbol layers or labels, from\nany layer. This is meant to improve the readability of symbols and labels whose colors are close and can be hard to\ndecipher when overlapping; it adds a custom and transparent mask around the items to “hide” parts of the symbol\nlayers of the current layer.\nTo apply masks on the active layer, you first need to enable in the project either\nmask symbol layersormask labels.\nThen, from theMaskstab, check:\n•theMasked symbol layers: lists in a tree structure all the symbol layers of the current layer. There you can select\nthe symbol layer item you would like to transparently “cut out” when they overlap the selected mask sources\n•theMask sourcestab: list all the mask labels and mask symbol layers defined in the project. Select the items\nthat would generate the mask over the selected masked symbol layers\n15.1. The Vector Properties Dialog471\n\nQGIS Desktop 3.22 User Guide\nFig. 15.38: Layer properties - Masks tab\n15.1.73D View Properties\nThe3D Viewtab provides settings for vector layers that should be depicted in the3D Map viewtool.\nFor better performance, data from vector layers are loaded in the background, using multithreading, and rendered in\ntiles whose size can be controlled from theLayer renderingsection of the tab:\n•Zoom levels count: determines how deep the quadtree will be. For example, one zoom level means there will\nbe a single tile for the whole layer. Three zoom levels means there will be 16 tiles at the leaf level (every extra\nzoom level multiplies that by 4). The default is3and the maximum is8.\n•Show bounding boxes of tiles: especially useful if there are issues with tiles not showing up when they should\nTo display a layer in 3D, select from the combobox at the top of the tab, either:\n•Single symbol: features are rendered using a common 3D symbol whose properties can bedata-definedor not.\nRead details onsetting a 3D symbolfor each layer geometry type.\n•Rule-based: multiple symbol configurations can be defined and applied selectively based on expression filters\nand scale range. More details on how-to atRule-based rendering.\n472Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.39: 3D properties of a point layer\n15.1.8Fields Properties\nTheFieldstab provides information on fields related to the layer and helps you organize them.\nThe layer can be madeeditableusing the\nToggle editing mode\n. At this moment, you can modify its structure using the\nNew field\nand\nDelete field\nbuttons.\nYou can also rename fields by double-clicking its name. This is only supported for data providers like PostgreSQL,\nOracle, Memory layer and some OGR layer depending on the OGR data format and version.\nIf set in the underlying data source or in theforms properties, the field’s alias is also displayed. An alias is a human\nreadable field name you can use in the feature form or the attribute table. Aliases are saved in the project file.\nOther than the fields contained in the dataset,virtual fieldsandAuxiliary Storageincluded, theFieldstab also lists\nfields from any\njoined layers. Depending on the origin of the field, a different background color is applied to it.\nFor each listed field, the dialog also lists read-only characteristics such as itsType,Type name,LengthandPrecision`.\nDependingon the data provider, you can associate a comment with a field, for example at its creation. Thisinformation\nis retrieved and shown in theCommentcolumn and is later displayed when hovering over the field label in a feature\nform.\n15.1. The Vector Properties Dialog473\n\nQGIS Desktop 3.22 User Guide\nUnder theConfigurationcolumn, you can set how the field should behave in certain circumstances:\n•Not searchable: check this option if you do not want this field to be queried by thesearch locator bar\n•Do not expose via WMS: check this option if you do not want to display this field if the layer is served\nas WMS from QGIS server\n•Do not expose via WFS: check this option if you do not want to display this field if the layer is served\nas WFS from QGIS server\nFig. 15.40: Fields properties tab\n15.1.9Attributes Form Properties\nTheAttributes Formtab helps you set up the form to display when creating new features or querying existing one.\nYou can define:\n•the look and the behavior of each field in the feature form or the attribute table (label, widget, constraints...);\n•the form’s structure (custom or autogenerated):\n•extra logic in Python to handle interaction with the form or field widgets.\nAt the top right of the dialog, you can set whether the form is opened by default when creating new features. This can\nbe configured per layer or globally with theSuppress attribute form pop-up after feature creationoption in theSettings\n►Options►Digitizingmenu.\nCustomizing a form for your data\nBy default, when you click on a feature with the\nIdentify Features\ntool or switch the attribute table to theform\nviewmode, QGIS displays a basic form with predefined widgets (generally spinboxes and textboxes — each field\nis represented on a dedicated row by its label next to the widget). Ifrelationsare set on the layer, fields from the\nreferencing layers are shown in an embedded frame at the bottom of the form, following the same basic structure.\nThis rendering is the result of the defaultAutogeneratevalue of theAttribute editor layoutsetting in theLayer\nproperties►Attributes Formtab. This property holds three different values:\n•Autogenerate: keeps the basic structure of “one row - one field” for the form but allows to customize each\ncorresponding widget.\n•Drag-and-drop designer: other than widget customization, the form structure can be made more\ncomplex eg, with widgets embedded in groups and tabs.\n•Provide ui file: allows to use a Qt designer file, hence a potentially more complex and fully featured\ntemplate, as feature form.\n474Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nThe autogenerated form\nWhen theAutogenerateoption is on, theAvailable widgetspanel shows lists of fields (from the layer and its\nrelations) that would be shown in the form. Select a field and you can configure its appearance and behavior in the\nright panel:\n•addingcustom label and automated checksto the field;\n•setting aparticular widgetto use.\nThe drag and drop designer\nThe drag and drop designer allows you to create a form with several containers (tabs or groups) to present the attribute\nfields or other widgets that are not directly linked to a particular field (like the HTML/QML widgets or theactions\ndefined for the layer), as shown for example inFig. 15.41.\nFig. 15.41: Resulting built-in form with tabs and named groups\n1.ChooseDrag and drop designerfrom theSelect attribute layout editorcombobox. This enables the\nForm Layoutpanel next to theAvailable widgetspanel, filled with existing fields. The selected field displays its\npropertiesin a third panel.\n2.Select fields you do not want to use in yourForm Layoutpanel and hit thebutton to remove them. You\ncan also toggle the selection with the\nInvert selection\nbutton\n3.Drag and drop fields from the first panel to the :guilabel`Form Layout` one to re-add them. The same field can\nbe added multiple times.\n4.Drag and drop fields within theForm Layoutpanel to reorder their position.\n5.Add containers (tab or group frames) to associate fields that belong to the same category and better structure\nthe form.\n1.The first step is to use theicon to create a tab in which fields and groups will be displayed\n15.1. The Vector Properties Dialog475\n\nQGIS Desktop 3.22 User Guide\n2.Then set the properties of the container, ie:\n•the name\n•the type, ie atabor agroup in container(a group inside a tab or another group)\n•and thenumber of columnsthe embedded fields should be distributed over\nFig. 15.42: Dialog to create containers with theAttribute editor layout\nThese, and other properties can later be updated by selecting the item and, from the third panel:\n•hide or show the container’s label\n•display the container as a group box (only available for tabs).\n•rename the container\n•set the number of columns\n•enter an expression to control the container’s visibility. The expression will be re-evaluated every\ntime values in the form change, and the tab or group box shown/hidden accordingly\n•add a background color\n3.You can create as many containers as you want; press theicon again to create another tab or a group\nframe under an existing tab.\n6.The next step is to assign the relevant fields to each container, by simple drag and drop. Groups and tabs can\nalso be moved in the same way.\n7.Customize the widgetof the fields in use\n8.In case the layer is involved in aone or many to many relation, drag-and-drop the relation name from the\nAvailable Widgetspanel to theForm Layoutpanel. The associated layer attribute form will be embedded at\n476Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nthe chosen place in the current layer’s form. As for the other items, select the relation label to configure some\nproperties:\n•hide or show the relation label\n•show the link button\n•show the unlink button\n9.In case the layer has one or moreactionsenabled forLayerorFeaturescope, the actions will be listed\nunderActionsand you can drag and drop them as with the other fields. The associated action will be embedded\nat the chosen place in the current layer’s form.\n10.Apply the layer’s properties dialog\n11.Open a feature attribute form (eg, using the\nIdentify features\ntool) and it should display the new form.\nUsing custom ui-file\nTheProvide ui-fileoption allows you to use complex dialogs made with Qt-Designer. Using a UI-file allows\na great deal of freedom in creating a dialog. Note that, in order to link the graphical objects (textbox, combobox...)\nto the layer’s fields, you need to give them the same name.\nUse theEdit UIto define the path to the file to use.\nUI-files can also be hosted on a remote server. In this case, you provide the URL of the form instead of the file path\ninEdit UI.\nYou’ll  find  some  example  in  the  Creating  a  new  form  lesson  of  the  QGIS-training-manual-\nindex-reference.For  more  advanced  information,  see\nhttps://woostuff.wordpress.com/2011/09/05/\nqgis-tips-custom-feature-forms-with-python-logic/.\nEnhance your form with custom functions\nQGIS forms can have a Python function that is called when the dialog is opened. Use this function to add extra logic\nto your dialogs. The form code can be specified in three different ways:\n•load from the environment: use a function, for example instartup.pyor from an installed\nplugin\n•load from an external file: a file chooser will let you select a Python file from your filesystem or\nenter a URL for a remote file.\n•provide code in this dialog: a Python editor will appear where you can directly type the function\nto use.\nIn all cases you must enter the name of the function that will be called (openin the example below).\nAn example is (in module MyForms.py):\ndefopen(dialog,layer,feature):\ngeom\n=feature.geometry()\ncontrol=dialog.findChild(QWidget,\"My line edit\")\nReference in Python Init Function like so:open\n15.1. The Vector Properties Dialog477\n\nQGIS Desktop 3.22 User Guide\nConfigure the field behavior\nThe main part of theAttributes Formtab helps you set the type of widget used to fill or display values of the field, in\nthe attribute table or the feature form: you can define how user interacts with each field and the values or range of\nvalues that are allowed to be added to each.\nFig. 15.43: Dialog to select an edit widget for an attribute column\nCommon settings\nRegardless the type of widget applied to the field, there are some common properties you can set to control whether\nand how a field can be edited.\n478Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nWidget display\nShow label: indicates whether the field name should be displayed in the form (only in theDrag and dropdesigner\nmode).\nGeneral options\n•Alias: a human readable name to use for fields. The alias will be displayed in the feature form, the attribute\ntable, or in theIdentify resultspanel. It can also be used as field name replacement in theexpression builder,\neasing expressions understanding and reviews. Aliases are saved in project file.\n•Comment: displays the field’s comment as shown in theFieldstab, in a read-only state. This information is\nshown as tooltip when hovering over the field label in a feature form.\n•Editable: uncheck this option to set the field read-only (not manually modifiable) even when the layer is in\nedit mode. Note that checking this setting doesn’t override any edit limitation from the provider.\n•Reuse last entered value: remembers the last value entered in this field and uses it as default for the next\nfeature being edited in the layer.\n•Label on top: places the field name above or beside the widget in the feature form.\nDefault values\n•Default value: for new features, automatically populates by default the field with a predefined value or an\nexpression-based one. For example, you can:\n–use$x,$length,$areato automatically populate a field with the feature’s X coordinate, length, area\nor any geometric information at its creation;\n–increment a field by 1 for each new feature usingmaximum(\"field\")+1;\n–save the feature creation datetime usingnow();\n–usevariablesin expressions, making it easier to e.g. insert the operator name (@user_full_name),\nthe project file path (@project_path), ...\nA preview of the resulting default value is displayed at the bottom of the widget.\nNote:TheDefault valueoption is not aware of the values in any other field of the feature being\ncreated so it won’t be possible to use an expression combining any of those values i.e using an expression like\nconcat(field1, field2)may not work.\n•Apply default value on update: whenever the feature attribute or geometry is changed, the default value is\nrecalculated. This could be handy to save values like last user that modifies data, last time it was changed...\nConstraints\nYou can constrain the value to insert in the field. This constraint can be:\n•Not null: requires the user to provide a value;\n•Unique: guarantee the inserted value to be unique throughout the field;\n•based on a customexpression: e.g.not regexp_match(col0,'[^A-Za-z]')will ensure that the\nvalue of the fieldcol0has only alphabet letters. A short description can be added to help you remember the\nconstraint.\n15.1. The Vector Properties Dialog479\n\nQGIS Desktop 3.22 User Guide\nWhenever a value is added or edited in a field, it’s submitted to the existing constraints and:\n•if it meets all the requirements, a green check is shown beside the field in the form;\n•if it does not meet all the requirements, then the field is colored in yellow or orange and a corresponding cross\nis displayed next to the widget. You can hover over the cross to remind which constraints are applied to the\nfield and fix the value:\n–A yellow cross appears when the unmet constraint is an unenforced one and it does not prevent you to\nsave the changes with the “wrong” values;\n–An orange cross can not be ignored and does not allow you to save your modifications until they meet the\nconstraints. It appears when theEnforce constraintoption is checked.\nEdit widgets\nBased on the field type, QGIS automatically determines and assigns a default widget type to it. You can then replace\nthe widget with any other compatible with the field type. The available widgets are:\n•Checkbox: Displays a checkbox whose state defines the value to insert.\n•Classification: Only available when acategorized symbologyis applied to the layer, displays a combo box with\nthe values of the classes.\n•Color: Displays acolor widgetallowing to select a color; the color value is stored as a html notation in the\nattribute table.\n•Date/Time: Displays a line field which can open a calendar widget to enter a date, a time or both. Column\ntype must be text. You can select a custom format, pop-up a calendar, etc.\n•Enumeration: Opens a combo box with predefined values fetched from the database. This is currently only\nsupported by the PostgreSQL provider, for fields ofenumtype.\n•Attachment: Uses a “Open file” dialog to store file path in a relative or absolute mode. It can be used to display\na hyperlink (to document path), a picture or a web page. User can also configure anexternal storage systemto\nfetch/store resources.\n•Hidden: A hidden attribute column is invisible. The user is not able to see its contents.\n•Key/Value: Displays a two-columns table to store sets of key/value pairs within a single field. This is currently\nsupported by the PostgreSQL provider, for fields ofhstoretype.\n•JSON View: Displays JSON data in a syntax highlighted text edit or in tree view. This widget is currently read\nonly. Several options are available to change how the data is displayed. ‘Default view’ specify if the widget\nshould appear in Text or Tree mode. ‘Format JSON’ has three options which are related to the tree view only:\n–Indented: Display data in a human readable form with newlines and four space characters for indentation.\n–Compact: Display data in a one-line size optimized string without newlines or spaces.\n–Disabled: Display data as it comes from the provider.\n•List: Displays a single column table to add different values within a single field. This is currently supported by\nthe PostgreSQL provider, for fields ofarraytype.\n•Range: Allows you to set numeric values from a specific range. The edit widget can be either a slider or a spin\nbox.\n•Relation Reference: This is the default widget assigned to the referencing field (i.e., the foreign key in the\nchild layer) when arelationis set. It provides direct access to the parent feature’s form which in turn embeds\nthe list and form of its children.\n•Text Edit(default): This opens a text edit field that allows simple text or multiple lines to be used. If you\nchoose multiple lines you can also choose html content.\n•Unique Values: You can select one of the values already used in the attribute table. If ‘Editable’ is activated,\na line edit is shown with autocompletion support, otherwise a combo box is used.\n480Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•Uuid Generator: Generates a read-only UUID (Universally Unique Identifiers) field, if empty.\n•Value Map: A combo box with predefined items. The value is stored in the attribute, the description is shown\nin the combo box. You can define values manually or load them from a layer or a CSV file.\n•Value Relation: Offers values from a related table in a combobox. You can select layer, key column and value\ncolumn. Several options are available to change the standard behaviors: allow null value, order by value, allow\nmultiple selections and use of auto-completer. The forms will display either a drop-down list or a line edit field\nwhen completer checkbox is enabled.\nIf a layer that is stored in PostgreSQL, GeoPackage or SpatiaLite is configured to use a value relation widget,\nbut the required layer is not already loaded into the project, QGIS will automatically search for the layer in the\nsame database/connection.\nTip: Relative Path in Attachment widget\nIf the path which is selected with the file browser is located in the same directory as the.qgsproject file or below,\npaths are converted to relative paths. This increases portability of a.qgsproject with multimedia information\nattached.\n15.1.10Joins Properties\nTheJoinstab allows you to associate features of the current layer (calledTarget layer) to features from\nanother loaded vector layer (or table). The join is based on an attribute that is shared by the layers. The layers can\nbe geometryless (tables) or not but their join attribute should be of the same type.\nTo create a join:\n1.Click the\nAdd new join\nbutton. TheAdd vector joindialog appears.\n2.Select theJoin layeryou want to connect with the target vector layer\n3.Specify theJoin fieldand theTarget fieldthat are common to both the join layer and the target layer\n4.PressOKand a summary of selected parameters is added to theJoinpanel.\n15.1. The Vector Properties Dialog481\n\nQGIS Desktop 3.22 User Guide\nFig. 15.44: Join an attribute table to an existing vector layer\nThe steps above will create a join, whereALLthe attributes of the first matching feature in the join layer is added\nto the target layer’s feature. QGIS provides more options to tweak the join:\n•Cache join layer in virtual memory: allows you to cache values in memory (without geometries) from the\njoined layer in order to speed up lookups.\n•Create attribute index on the join field\n•Dynamic form: helps to synchronize join fields on the fly, according to theTarget field. This way, constraints\nfor join fields are also correctly updated. Note that it’s deactivated by default because it may be very time\nconsuming if you have a lot of features or a myriad of joins.\n482Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•If the target layer is editable, then some icons will be displayed in the attribute table next to fields, in order to\ninform about their status:\n–: the join layer is not configured to be editable. If you want to be able to edit join features from the\ntarget attribute table, then you have to check the optionEditable join layer.\n–: the join layer is well configured to be editable, but its current status is read only.\n–: the join layer is editable, but synchronization mechanisms are not activated. If you want to auto-\nmatically add a feature in the join layer when a feature is created in the target layer, then you have to\ncheck the optionUpsert on edit. Symmetrically, the optionDelete cascademay be activated if\nyou want to automatically delete join features.\n•Joined fields: instead of adding all the fields from the joined layer, you can specify a subset.\n•Custom field name prefixfor joined fields, in order to avoid name collision\nQGIS currently has support for joining non-spatial table formats supported by OGR (e.g., CSV, DBF and Excel),\ndelimited text and the PostgreSQL provider.\n15.1.11Auxiliary Storage Properties\nThe regular way to customize styling and labeling is to use data-defined properties as described inData defined\noverride setup\n. However, it may not be possible if the underlying data is read only. Moreover, configuring these\ndata-defined properties may be very time consuming or not desirable! For example, if you want to fully use map tools\ncoming withThe Label Toolbar, then you need to add and configure more than 20 fields in your original data source\n(X and Y positions, rotation angle, font style, color and so on).\nThe Auxiliary Storage mechanism provides the solution to these limitations and awkward configurations. Auxiliary\nfields are a roundabout way to automatically manage and store these data-defined properties (labels, diagram, sym-\nbology...) in a SQLite database thanks to editable joins. This allows you to store properties for layers that aren’t\neditable.\nA tab is available in vector layer properties dialog to manage auxiliary storage:\n15.1. The Vector Properties Dialog483\n\nQGIS Desktop 3.22 User Guide\nFig. 15.45: Auxiliary Storage tab\nLabeling\nConsidering that the data source may be customized thanks to data-defined properties without being editable, labeling\nmap tools described inThe Label Toolbarare always available as soon as labeling is activated.\nActually, the auxiliary storage system needs an auxiliary layer to store these properties in a SQLite database (see\nAuxiliary storage database). Its creation process is run the first time you click on the map while a labeling map tool is\ncurrently activated. Then, a window is displayed, allowing you to select the primary key to use for joining (to ensure\nthat features are uniquely identified):\nFig. 15.46: Auxiliary Layer creation dialog\nAs soon as an auxiliary layer is configured for the current data source, you can retrieve its information in the tab:\n484Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.47: Auxiliary Layer key\nThe auxiliary layer now has these characteristics:\n•the primary key isID,\n•there are0features using an auxiliary field,\n•there are0auxiliary fields.\nNow that the auxiliary layer is created, you can edit the layer labels. Click on a label while the\nChange Label\nmap\ntool is activated, then you can update styling properties like sizes, colors, and so on. The corresponding data-defined\nproperties are created and can be retrieved:\n15.1. The Vector Properties Dialog485\n\nQGIS Desktop 3.22 User Guide\nFig. 15.48: Auxiliary Fields\nAs you can see in the figure above,21fields are automatically created and configured for labeling. For example, the\nFontStyleauxiliary field type is aStringand is namedlabeling_fontstylein the underlying SQLite\ndatabase. There is also1feature which is currently using these auxiliary fields.\nNotice that the icon\nis displayed in theLabelsproperties tab indicating that the data-defined override options are\nset correctly:\n486Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.49: Data-defined properties automatically created\nOtherwise, there’s another way to create an auxiliary field for a specific property thanks to the\nData-defined override\nbutton. By clicking onStore data in the project, an auxiliary field is automatically created for theOpacityfield. If you\nclick on this button and the auxiliary layer is not created yet, a window (Fig. 15.46) is first displayed to select the\nprimary key to use for joining.\nSymbology\nLike the method described above for customizing labels, auxiliary fields can also be used to stylize symbols and\ndiagrams. To do this, click on\nData-defined override\nand selectStore data in the projectfor a specific property. For\nexample, theFill colorfield:\n15.1. The Vector Properties Dialog487\n\nQGIS Desktop 3.22 User Guide\nFig. 15.50: Data-defined property menu for symbol\nThere are different attributes for each symbol (e.g. fill style, fill color, stroke color, etc...), so each auxiliary field\nrepresenting an attribute requires a unique name to avoid conflicts. After selectingStore data in the project, a window\nopens and displays theTypeof the field and prompts you to enter a unique name for the auxiliary field. For example,\nwhen creating aFill colorauxiliary field the following window opens:\nFig. 15.51: Name of the auxiliary field for a symbol\nOnce created, the auxiliary field can be retrieved in the auxiliary storage tab:\n488Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.52: Auxiliary field symbol\nAttribute table and widgets\nAuxiliary fields can be edited using theattribute table. However, not all auxiliary fields are initially visible in the\nattribute table.\nAuxiliary fields representing attributes of a layer’s symbology, labeling, appearance, or diagrams will appear auto-\nmatically in the attribute table. The exception are attributes that can be modified using the\nLabel Toolbarwhich are\nhidden by default. Auxiliary fields representing aColorhave a widgetColorset by default, otherwise auxiliary\nfields default to theText Editwidget.\nAuxiliary fields that represent attributes that can be modified using theLabel toolbarareHiddenin the attribute table\nby default. To make a field visible, open theAttribute Form properties taband change the value of an auxiliary field\nWidget TypefromHiddento another relevant value. For example, change theauxiliary_storage_labeling_sizeto\nText Editor changeauxiliary_storage_labeling_colorto theColorwidget. Those fields will now be visible in the\nattribute table.\nAuxiliary fields in the attribute table will appear like the following image:\n15.1. The Vector Properties Dialog489\n\nQGIS Desktop 3.22 User Guide\nFig. 15.53: Form with auxiliary fields\nManagement\nTheAuxiliary Layermenu allows you to manage the auxiliary fields:\n490Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.54: Auxiliary layer management\nThe first itemCreateis disabled in this case because the auxiliary layer is already created. But in case of a fresh work,\nyou can use this action to create an auxiliary layer. As explained inLabeling, a primary key will be needed then.\nTheClearaction allows to keep all auxiliary fields, but remove their contents. This way, the number of features using\nthese fields will fall to0.\nTheDeleteaction completely removes the auxiliary layer. In other words, the corresponding table is deleted from the\nunderlying SQLite database and properties customization are lost.\nFinally, theExportaction allows to save the auxiliary layer as anew vector layer. Note that geometries are not stored\nin auxiliary storage. However, in this case, geometries are exported from the original data source too.\n15.1. The Vector Properties Dialog491\n\nQGIS Desktop 3.22 User Guide\nAuxiliary storage database\nWhen you save your project with the.qgsformat, the SQLite database used for auxiliary storage is saved at the\nsame place but with the extension.qgd.\nFor convenience, an archive may be used instead thanks to the.qgzformat. In this case,.qgdand.qgsfiles are\nboth embedded in the archive.\n15.1.12Actions Properties\nQGIS provides the ability to perform an action based on the attributes of a feature. This can be used to perform\nany number of actions, for example, running a program with arguments built from the attributes of a feature or passing\nparameters to a web reporting tool.\nFig. 15.55: Overview action dialog with some sample actions\nActions are useful when you frequently want to run an external application or view a web page based on one or more\nvalues in your vector layer. They are divided into six types and can be used like this:\n•Generic, Mac, Windows and Unix actions start an external process.\n•Python actions execute a Python expression.\n•Generic and Python actions are visible everywhere.\n•Mac, Windows and Unix actions are visible only on the respective platform (i.e., you can define three ‘Edit’\nactions to open an editor and the users can only see and execute the one ‘Edit’ action for their platform to run\nthe editor).\nThere are several examples included in the dialog. You can load them by clicking onCreate Default Actions. To edit\nany of the examples, double-click its row. One example is performing a search based on an attribute value. This\nconcept is used in the following discussion.\nThe\nShow in Attribute Tableallows you to display in the attribute table dialog the checked feature-scoped actions,\neither asCombo Boxor asSeparate Buttons(seeConfiguring the columns).\n492Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nDefining Actions\nTo define an attribute action, open the vectorLayer Propertiesdialog and click on theActionstab. In theActionstab,\nclick the\nAdd a new action\nto open theEdit Actiondialog.\nSelect the actionTypeand provide a descriptive name for the action. The action itself must contain the name of\nthe application that will be executed when the action is invoked. You can add one or more attribute field values as\narguments to the application. When the action is invoked, any set of characters that start with a%followed by the\nname of a field will be replaced by the value of that field. The special characters%%will be replaced by the value of\nthe field that was selected from the identify results or attribute table (seeusing_actionsbelow). Double quote marks\ncan be used to group text into a single argument to the program, script or command. Double quotes will be ignored\nif preceded by a backslash.\nTheAction Scopesallows you to definewherethe action should be available. You have 4 different choices:\n1.Feature Scope: action is available when right click in the cell within the attribute table.\n2.Field Scope: action is available when right click in the cell within the attribute table, in the feature form and in\nthe default action button of the main toolbar.\n3.Layer Scope: action is available in the action button in the attribute table toolbar. Be aware that this type of\naction involves the entire layer and not the single features.\n4.Canvas: action is available in the main action button in the toolbar.\nIf you have field names that are substrings of other field names (e.g.,col1andcol10), you should indicate that\nby surrounding the field name (and the % character) with square brackets (e.g.,[%col10]). This will prevent\nthe%col10field name from being mistaken for the%col1field name with a0on the end. The brackets will be\nremoved by QGIS when it substitutes in the value of the field. If you want the substituted field to be surrounded by\nsquare brackets, use a second set like this:[[%col10]].\nUsing theIdentify Featurestool, you can open theIdentify Resultsdialog. It includes a(Derived)item that contains\ninformation relevant to the layer type. The values in this item can be accessed in a similar way to the other fields\nby proceeding the derived field name with(Derived).. For example, a point layer has anXandYfield, and the\nvalues of these fields can be used in the action with%(Derived).Xand%(Derived).Y. The derived attributes\nare only available from theIdentify Resultsdialog box, not theAttribute Tabledialog box.\nTwo example actions are shown below:\n•konqueror https://www.google.com/search?q=%nam\n•konqueror https://www.google.com/search?q=%%\nIn the first example, the web browser konqueror is invoked and passed a URL to open. The URL performs a Google\nsearch on the value of thenamfield from our vector layer. Note that the application or script called by the action must\nbe in the path, or you must provide the full path. To be certain, we could rewrite the first example as:/opt/kde3/\nbin/konqueror https://www.google.com/search?q=%nam. This will ensure that the konqueror\napplication will be executed when the action is invoked.\nThe second example uses the %% notation, which does not rely on a particular field for its value. When the action is\ninvoked, the %% will be replaced by the value of the selected field in the identify results or attribute table.\nUsing Actions\nQGIS offers many ways to execute actions you enabled on a layer. Depending on their settings, they can be available:\n•in the drop-down menu of\nRun Feature Action\nbutton from theAttributes toolbarorAttribute tabledialog;\n•when right-clicking a feature with the\nIdentify Features\ntool (see\nIdentifying Featuresfor more information);\n•from theIdentify Resultspanel, under theActionssection;\n•as items of anActionscolumn in theAttribute Tabledialog.\n15.1. The Vector Properties Dialog493\n\nQGIS Desktop 3.22 User Guide\nIf you are invoking an action that uses the%%notation, right-click on the field value in theIdentify Resultsdialog or\ntheAttribute Tabledialog that you wish to pass to the application or script.\nHere is another example that pulls data out of a vector layer and inserts it into a file using bash and theechocommand\n(so it will only work onor perhaps). The layer in question has fields for a species nametaxon_name, latitude\nlatand longitudelong. We would like to be able to make a spatial selection of localities and export these field\nvalues to a text file for the selected record (shown in yellow in the QGIS map area). Here is the action to achieve this:\nbash-c\"echo\\\"%taxon_name%lat%long\\\">> /tmp/species_localities.txt\"\nAfter selecting a few localities and running the action on each one, opening the output file will show something like\nthis:\nAcacia mearnsii-34.0800000000150.0800000000\nAcacia mearnsii-34.9000000000150.1200000000\nAcacia mearnsii-35.2200000000149.9300000000\nAcacia mearnsii-32.2700000000150.4100000000\nAs an exercise, we can create an action that does a Google search on thelakeslayer. First, we need to determine\nthe URL required to perform a search on a keyword. This is easily done by just going to Google and doing a simple\nsearch, then grabbing the URL from the address bar in your browser. From this little effort, we see that the format\nis\nhttps://www.google.com/search?q=QGIS, whereQGISis the search term. Armed with this information, we can\nproceed:\n1.Make sure thelakeslayer is loaded.\n2.Open theLayer Propertiesdialog by double-clicking on the layer in the legend, or right-click and chooseProp-\nertiesfrom the pop-up menu.\n3.Click on theActionstab.\n4.Click\nAdd a new action\n.\n5.Choose theOpenaction type,\n6.Enter a name for the action, for exampleGoogle Search.\n7.Additionally you can add aShort Nameor even anIcon.\n8.Choose the actionScope. SeeDefining Actionsfor further information. Leave the default settings for this\nexample.\n9.For the action, we need to provide the name of the external program to run. In this case, we can use Firefox.\nIf the program is not in your path, you need to provide the full path.\n10.Following the name of the external application, add the URL used for doing a Google search, up to but not\nincluding the search term:https://www.google.com/search?q=\n11.The text in theActionfield should now look like this:https://www.google.com/search?q=\n12.Click on the drop-down box containing the field names for thelakeslayer. It’s located just to the left of the\nInsertbutton.\n13.From the drop-down box, select ‘NAMES’ and clickInsert.\n14.Your action text now looks like this:\nhttps://www.google.com/search?q=[%NAMES%]\n15.To finalize and add the action, click theOKbutton.\n494Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.56: Edit action dialog configured with the example\nThis completes the action, and it is ready to use. The final text of the action should look like this:\nhttps://www.google.com/search?q=[%NAMES%]\nWe can now use the action. Close theLayer Propertiesdialog and zoom in to an area of interest. Make sure the\nlakeslayer is active and identify a lake. In the result box you’ll now see that our action is visible:\n15.1. The Vector Properties Dialog495\n\nQGIS Desktop 3.22 User Guide\nFig. 15.57: Select feature and choose action\nWhen we click on the action, it brings up Firefox and navigates to the URLhttps://www.google.com/search?q=\nTustumena\n. It is also possible to add further attribute fields to the action. Therefore, you can add a+to the end of\nthe action text, select another field and click onInsert Field. In this example, there is just no other field available that\nwould make sense to search for.\nYou can define multiple actions for a layer, and each will show up in theIdentify Resultsdialog.\nYou can also invoke actions from the attribute table by selecting a row and right-clicking, then choosing the action\nfrom the pop-up menu.\nThere are all kinds of uses for actions. For example, if you have a point layer containing locations of images or photos\nalong with a file name, you could create an action to launch a viewer to display the image. You could also use actions\nto launch web-based reports for an attribute field or combination of fields, specifying them in the same way we did\nin our Google search example.\nWe can also make more complex examples, for instance, usingPythonactions.\nUsually, when we create an action to open a file with an external application, we can use absolute paths, or eventually\nrelative paths. In the second case, the path is relative to the location of the external program executable file. But what\nabout if we need to use relative paths, relative to the selected layer (a file-based one, like Shapefile or SpatiaLite)?\nThe following code will do the trick:\ncommand=\"firefox\"\nimagerelpath=\"images_test/test_image.jpg\"\nlayer=qgis.utils.iface.activeLayer()\nimportos.path\nlayerpath=layer.source()iflayer.providerType()=='ogr'\nelse(qgis.core.QgsDataSourceURI(layer.source()).database()\niflayer.providerType()=='spatialite'elseNone)\npath=os.path.dirname(str(layerpath))\nimage\n=os.path.join(path,imagerelpath)\nimportsubprocess\nsubprocess.Popen( [command, image ] )\nWe just have to remember that the action is one of typePythonand thecommandandimagerelpathvariables must\nbe changed to fit our needs.\n496Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nBut what about if the relative path needs to be relative to the (saved) project file? The code of the Python action\nwould be:\ncommand=\"firefox\"\nimagerelpath=\"images_test/test_image.jpg\"\nprojectpath=qgis.core.QgsProject.instance().fileName()\nimportos.path\npath=os.path.dirname(str(projectpath))ifprojectpath!=''elseNone\nimage=os.path.join(path, imagerelpath)\nimportsubprocess\nsubprocess.Popen( [command, image ] )\nAnother Python action example is the one that allows us to add new layers to the project. For instance, the following\nexamples will add to the project respectively a vector and a raster. The names of the files to be added to the project\nand the names to be given to the layers are data driven (filenameandlayernameare column names of the table of\nattributes of the vector where the action was created):\nqgis.utils.iface.addVectorLayer('/yourpath/[%\"filename\"%].shp',\n'[%\"layername\"%]','ogr')\nTo add a raster (a TIF image in this example), it becomes:\nqgis.utils.iface.addRasterLayer('/yourpath/[%\"filename\"%].tif',\n'[%\"layername\"%]')\n15.1.13Display Properties\nTheDisplaytab helps you configure fields to use for feature identification:\n•TheDisplay name: based on a field or anexpression. This is:\n–the label shown on top of the feature information in theIdentify toolresults\n–the field used in thelocator barwhen looking for features in all layers\n–the feature identifier in the attribute tableform view\n–the feature identifier when the map or layout is exported to a layered output format such as GeoPDF\n–the map tip information, i.e. the message displayed in the map canvas when hovering over a feature of\nthe active layer with the\nShow Map Tips\nicon pressed. Applicable when noHTML Map Tipis set.\n•TheHTML Map Tipis specifically created for the map tips: it’s a more complex and full HTML text mixing\nfields, expressions and html tags (multiline, fonts, images, hyperlink...).\n15.1. The Vector Properties Dialog497\n\nQGIS Desktop 3.22 User Guide\nFig. 15.58: HTML code for map tip\nTo activate map tips, select the menu optionView►Show Map Tipsor click on the\nShow Map Tips\nicon of the\nAttributes Toolbar. Map tip is a cross-session feature meaning that once activated, it stays on and apply to any layer\nin any project, even in future QGIS sessions until it’s toggled off.\nFig. 15.59: Map tip made with HTML code\n498Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n15.1.14Rendering Properties\nScale dependent visibility\nYou can set theMaximum (inclusive)andMinimum (exclusive)scale, defining a range of scale in which features will\nbe visible. Out of this range, they are hidden. The\nSet to current canvas scale\nbutton helps you use the current map\ncanvas scale as boundary of the range visibility. SeeScale Dependent Renderingfor more information.\nSimplify geometry\nQGIS offers support for on-the-fly feature generalisation. This can improve rendering times when drawing many\ncomplex features at small scales. This feature can be enabled or disabled in the layer settings using theSimplify\ngeometryoption. There is also a global setting that enables generalisation by default for newly added layers (seeglobal\nsimplificationfor more information).\nFig. 15.60: Layer Geometry Simplification dialog\nNote:Feature generalisation may introduce artefacts into your rendered output in some cases. These may include\nslivers between polygons and inaccurate rendering when using offset-based symbol layers.\nWhile rendering extremely detailed layers (e.g. polygon layers with a huge number of nodes), this can cause layout\nexports in PDF/SVG format to be huge as all nodes are included in the exported file. This can also make the resultant\nfile very slow to work with/open in other programs.\nChecking\nForce layer to render as rasterforces these layers to be rasterised so that the exported files won’t have\nto include all the nodes contained in these layers and the rendering is therefore sped up.\nYou can also do this by forcing the layout to export as a raster, but that is an all-or-nothing solution, given that the\nrasterisation is applied to all layers.\n15.1. The Vector Properties Dialog499\n\nQGIS Desktop 3.22 User Guide\nRefresh layer at interval (seconds): set a timer to automatically refresh individual layers at a matching interval. Canvas\nupdates are deferred in order to avoid refreshing multiple times if more than one layer has an auto update interval set.\nDepending on the data provider (e.g. PostgreSQL), notifications can be sent to QGIS when changes are applied to\nthe data source, out of QGIS. Use theRefresh layer on notificationoption to trigger an update. You can also limit\nthe layer refresh to a specific message set in theOnly if message istext box.\nUse Scale Reference\nIf set, the reference scale indicates the map scale at which symbology and labeling sizes which uses paper-based units\n(such as millimeters or points) relate to. The sizes will be scaled accordingly whenever the map is viewed at a different\nscale.\nFor instance, a line layer using a 2mm wide line with a 1:2000 reference scale set will be rendered using 4mm wide\nlines when the map is viewed at 1:1000.\n15.1.15Temporal Properties\nTheTemporaltab provides options to control the rendering of the layer over time. Such dynamic rendering\nrequires thetemporal navigationto be enabled over the map canvas.\nFig. 15.61: Vector layer temporal properties dialog\nCheck theDynamic Temporal Controloption to configure the vector layer temporal rendering. Depending on the\nstructure of your dataset, you may want to use one of the providedConfigurationoptions:\n•Fixed time range: all the features are rendered if the map canvas temporal frame overlaps the givenStart date\nandEnd daterange.\n•Single field with date/time: features are rendered if theirField’s value falls within the map canvas temporal\nframe. AnEvent durationcan be set. With checking theAccumulate features over timeoption, all features\n500Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nwhich occur before or within the map’s temporal range will continue to be rendered. The event duration is thus\nignored.\n•Separate fields for start and end date/time: features are rendered if the range specified by theirStart fieldand\nEnd fieldvalues overlaps the map canvas temporal.\n•Separate fields for start and event duration: features are rendered if the range defined by theirStart fieldand\nEvent duration fieldvalues overlaps the map canvas temporal.\n•Start and end date/time from expressions: features are rendered if the time range specified by the fieldsStart\nexpressionandEnd expressionoverlaps the map canvas temporal.\n•Redraw layer only: the layer is redrawn at each new animation frame but no time-based filtering is applied to\nthe features. It’s useful when the layer uses time-based expression values for renderer settings (e.g. data-defined\nsymbology).\nIt is also possible to set theLimitsof the features time range as:\n•Include start, exclude end\n•Include start, include end\n15.1.16Variables Properties\nTheVariablestab lists all the variables available at the layer’s level (which includes all global and project’s\nvariables).\nIt also allows the user to manage layer-level variables. Click thebutton to add a new custom layer-level variable.\nLikewise, select a custom layer-level variable from the list and click thebutton to remove it.\nMore information on variables usage in the General Tools\nStoring values in Variablessection.\n15.1.17Metadata Properties\nTheMetadatatab provides you with options to create and edit a metadata report on your layer. SeeMetadatafor\nmore information.\n15.1.18Dependencies Properties\nTheDependenciestab allows to declare data dependencies between layers. A data dependency occurs when a\ndata modification in a layer, not by direct user manipulation, may modify data of other layers. This is the case for\ninstance when geometry of a layer is updated by a database trigger or custom PyQGIS scripting after modification of\nanother layer’s geometry.\nIn theDependenciestab, you can select any layers which may externally alter the data in the current layer. Correctly\nspecifying dependent layers allows QGIS to invalidate caches for this layer when the dependent layers are altered.\n15.1. The Vector Properties Dialog501\n\nQGIS Desktop 3.22 User Guide\n15.1.19Legend Properties\nTheLegendproperties tab provides you with advanced settings for theLayers paneland/or theprint layout legend.\nThese options include:\n•Depending on the symbology applied to the layer, you may end up with several entries in the legend, not\nnecessarily readable/useful to display. TheLegend placeholder imagehelps youselect an imagefor replacement,\ndisplayed both in theLayerspanel and the print layout legend.\n•Show label legend: Displays overviews of the different label settings as entries in the legends. Thelabel\nstyleis previewed along with the description.\n•Text on symbols: In some cases it can be useful to add extra information to the symbols in the legend. With\nthis frame, you can affect to any of the symbols used in the layer symbology a text that is displayed over the\nsymbol, in bothLayerspanel and print layout legend. This mapping is done by typing each text next to the\nsymbol in the table widget or filling the table using theSet Labels from Expressionbutton. Text appearance is\nhandled through the font and color selector widgets of theText Formatbutton.\nFig. 15.62: Setting text on symbols (left) and its rendering in theLayerspanel (right)\n•a list of widgets you can embed within the layer tree in the Layers panel. The idea is to have a way to quickly\naccess some actions that are often used with the layer (setup transparency, filtering, selection, style or other\nstuff...).\nBy default, QGIS provides transparency widget but this can be extended by plugins registering their own widgets\nand assign custom actions to layers they manage.\n15.1.20QGIS Server Properties\nTheQGIS Servertab consists ofDescription,Attribution,Metadata URL, andLegend URLsections.\nFrom theDescriptionsection, you can change theShort nameused to reference the layer in requests (to learn more\nabout short names, read services_basics_short_name). You can also add or edit aTitleandAbstractfor the layer, or\ndefine aKeyword listhere. These keyword lists can be used in a metadata catalog. If you want to use a title from an\nXML metadata file, you have to fill in a link in theData URLfield.\nUseAttributionto get attribute data from an XML metadata catalog.\nInMetadata URL, you can add the general paths to the XML metadata catalog. This information will be saved in the\nQGIS project file for subsequent sessions and will be used for QGIS Server.\nIn theLegend URLsection, you can provide the url of a legend image in the url field. You can use the Format drop-\ndown option to apply the appropriate format of the image. Currently png, jpg and jpeg image formats are supported.\n502Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.63: QGIS Server tab in vector layers properties dialog\nTo learn more about QGIS Server, read the QGIS-Server-manual.\n15.1.21Digitizing Properties\nTheDigitizingtab gives access to options that help to ensure the quality of digitized geometries.\n15.1. The Vector Properties Dialog503\n\nQGIS Desktop 3.22 User Guide\nFig. 15.64: The QGIS Digitizing tab in the vector layers properties dialog\nAutomatic Fixes\nOptions in theAutomatic Fixessection will directly affect the vertices of any geometry which is added or modified.\nIf theRemove duplicate nodesoption is checked, any two subsequent vertices with exactly the same coordinates\nwill be removed. If theGeometry precisionis set, all vertices will be rounded to the closest multiple of the configured\ngeometry precision. The rounding will happen in the layer coordinate reference system. Z and M values are not\nrounded. With many map tools, a grid is shown on the canvas while digitizing.\nFig. 15.65: Moving the top vertex snaps all the vertices to the grid\n504Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nGeometry Checks\nIn theGeometry checkssection, additional validations on a per geometry basis can be activated. Immediately after\nany geometry modification, failures in these checks are reported to the user in theGeometry validationpanel. As long\nas a check is failing, it is not possible to save the layer. TheIs validcheck will run basic validity checks like self\nintersection on geometries.\nTopology Checks\nIn theTopology checkssection, additional topology validation checks can be activated. Topology checks will be\nexecuted when the user saves the layer. Check errors will be reported in theGeometry validationpanel. As long as\nvalidation errors are present, the layer can not be saved. Topology checks are executed in the area of the bounding\nbox of the modified features. Since other features may be present in the same area, topological errors concerning\nthese features are reported as well as errors introduced in the current edit session.\nTopology check optionIllustration\nTheGapcheck will check for gaps between neighbouring\npolygons.\nTheOverlapcheck will check for overlaps between neigh-\nbouring polygons.\nTheMissing vertexcheck will check for shared boundaries\nof neighbouring polygons where one border misses a vertex\nwhich is present on the other one.\nGap check exceptions\nSometimes it is desirable to keep gaps inside an area in a polygon layer that otherwise is fully covered by polygons.\nFor example, a land use layer may have acceptable holes for lakes. It is possible to define areas that are ignored in\nthe gap check. Since gaps inside these areas are allowed, we will refer to them asAllowed Gapsareas.\nIn the options for the gap checks underAllowed Gaps, anAllowed Gaps layercan be configured.\nWhenever the gap check is executed, gaps which are covered by one or more polygons in theAllowed Gaps Layerare\nnot reported as topology errors.\n15.1. The Vector Properties Dialog505\n\nQGIS Desktop 3.22 User Guide\nIt is also possible to configure an additionalBuffer. This buffer is applied to each polygon on theAllowed Gaps Layer.\nThis makes it possible to make the tests less susceptible to small changes in the outlines at the borders of gaps.\nWhenAllowed Gapsare enabled, an additional button (Add Allowed Gap) for detected gap errors is available in the\ngeometry validation dock, where gaps are reported during digitizing. If theAdd Allowed Gapbutton is pushed, a\nnew polygon with the geometry of the detected gap is inserted into theAllowed Gaps Layer. This makes it possible\nto quickly flag gaps as allowed.\nGeometry validation panel\nTheGeometry Validationpanel is triggered when any of the abovementioned digitizing checks finds an error. The\ndialog provides you with the list of errors and their description, and you can to browse the list using the keyboard\narrows or dedicated arrows.\nYou’ll need to address all the issues before you can save edits to the layer. To do so:\n1.Select an error, and it’s possible to:\n•Zoom to Feature(s)\n•Zoom to problem\n2.Pick the usualdigitizing toolsto fix the issue.\n15.2Working with the Attribute Table\nThe attribute table displays information on features of a selected layer. Each row in the table represents a feature\n(with or without geometry), and each column contains a particular piece of information about the feature. Features\nin the table can be searched, selected, moved or even edited.\n15.2.1Foreword: Spatial and non-spatial tables\nQGIS allows you to load spatial and non-spatial layers. This currently includes tables supported by OGR and delimited\ntext, as well as the PostgreSQL, MSSQL, SpatiaLite and Oracle provider. All loaded layers are listed in theLayers\npanel. Whether a layer is spatially enabled or not determines whether you can interact with it on the map.\nNon-spatial tables can be browsed and edited using the attribute table view. Furthermore, they can be used for field\nlookups. For example, you can use columns of a non-spatial table to define attribute values, or a range of values that\nare allowed, to be added to a specific vector layer during digitizing. Have a closer look at the edit widget in section\nAttributes Form Propertiesto find out more.\n15.2.2Introducing the attribute table interface\nTo open the attribute table for a vector layer, activate the layer by clicking on it in theLayers Panel. Then, from the\nmainLayermenu, chooseOpen Attribute Table. It is also possible to right-click on the layer and choose\nOpen Attribute Tablefrom the drop-down menu, or to click on theOpen Attribute Tablebutton in the Attributes\ntoolbar. If you prefer shortcuts,F6will open the attribute table.Shift+F6will open the attribute table filtered to\nselected features andCtrl+F6will open the attribute table filtered to visible features.\nThis will open a new window that displays the feature attributes for the layer (\nfigure_attributes_table). According to\nthe setting inSettings►Options►Data sourcesmenu, the attribute table will open in a docked window or a regular\nwindow. The total number of features in the layer and the number of currently selected/filtered features are shown in\nthe attribute table title, as well as if the layer is spatially limited.\n506Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.66: Attribute Table for regions layer\nThe buttons at the top of the attribute table window provide the following functionality:\nTable 15.1: Available Tools\nIconLabelPurposeDefault Shortcut\nToggle editing modeEnable editing functionalitiesCtrl+E\nToggle multi edit modeUpdate multiple fields of many features\nSave EditsSave current modifications\nReload the table\nAdd featureAdd new geometryless feature\nDelete selected featuresRemove selected features from the layer\nCut selected features to clipboardCtrl+X\nCopy selected features to clipboardCtrl+C\nPaste features from clipboardInsert new features from copied onesCtrl+V\nSelect features using an Expression\nSelect AllSelect all features in the layerCtrl+A\nInvert selectionInvert the current selection in the layerCtrl+R\nDeselect allDeselect all features in the current layerCtrl+Shift+A\nFilter/Select features using formCtrl+F\nMove selected to topMove selected rows to the top of the table\nPan map to the selected rowsCtrl+P\ncontinues on next page\n15.2. Working with the Attribute Table507\n\nQGIS Desktop 3.22 User Guide\nTable 15.1 – continued from previous page\nIconLabelPurposeDefault Shortcut\nZoom map to the selected rowsCtrl+J\nNew fieldAdd a new field to the data sourceCtrl+W\nDelete fieldRemove a field from the data source\nOrganize columnsShow/hide fields from the attribute table\nOpen field calculatorUpdate field for many features in a rowCtrl+I\nConditional formattingEnable table formatting\nDock attribute tableAllows to dock/undock the attribute table\nActionsLists the actions related to the layer\nNote:Depending on the format of the data and the OGR library built with your QGIS version, some tools may not\nbe available.\nBelow these buttons is the Quick Field Calculation bar (enabled only inedit mode), which allows to quickly apply\ncalculations to all or part of the features in the layer. This bar uses the sameexpressionsas the\nField Calculator\n(see\nEditing attribute values).\nTable view vs Form view\nQGIS provides two view modes to easily manipulate data in the attribute table:\n•The\nTable view\n, displays values of multiple features in a tabular mode, each row representing a feature and\neach column a field. A right-click on the column header allows you toconfigure the table displaywhile a\nright-click on a cell providesinteraction with the feature.\n•The\nForm view\nshowsfeature identifiersin a first panel and displays only the attributes of the clicked identifier\nin the second one. There is a pull-down menu at the top of the first panel where the “identifier” can be specified\nusing an attribute (Column preview) or anExpression. The pull-down also includes the last 10 expressions for\nre-use. Form view uses the layer fields configuration (see\nAttributes Form Properties).\nYou can browse through the feature identifiers with the arrows on the bottom of the first panel. The features\nattributes update in the second panel as you go. It’s also possible to identify or move to the active feature in\nthe map canvas with pushing down any of the button at the bottom:\n–\nHighlight current feature\nif visible in the map canvas\n–\nAutomatically pan to current feature\n–\nZoom to current feature\nYou can switch from one mode to the other by clicking the corresponding icon at the bottom right of the dialog.\nYou can also specify theDefault viewmode at the opening of the attribute table inSettings►Options►Data Sources\nmenu. It can be ‘Remember last view’, ‘Table view’ or ‘Form view’.\n508Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.67: Attribute table in table view (top) vs form view (bottom)\nConfiguring the columns\nRight-click in a column header when in table view to have access to tools that help you control:\n•thecolumn(s) size\n•thecolumn(s) visibility and order\n•thesort order of the data\n15.2. Working with the Attribute Table509\n\nQGIS Desktop 3.22 User Guide\nResizing columns widths\nColumns width can be set through a right-click on the column header and select either:\n•Set width...to enter the desired value. By default, the current value is displayed in the widget\n•Set all column widths...to the same value\n•Autosizeto resize at the best fit the column.\n•Autosize all columns\nA column size can also be changed by dragging the boundary on the right of its heading. The new size of the column\nis maintained for the layer, and restored at the next opening of the attribute table.\nHiding and organizing columns and enabling actions\nBy right-clicking in a column header, you can choose toHide columnfrom the attribute table (in “table view”\nmode). For more advanced controls, press the\nOrganize columns...\nbutton from the dialog toolbar or chooseOrganize\ncolumns...in a column header contextual menu. In the new dialog, you can:\n•check/uncheck columns you want to show or hide: a hidden column will disappear from every instances of the\nattribute table dialog until it is actively restored.\n•drag-and-drop items to reorder the columns in the attribute table. Note that this change is for the table rendering\nand does not alter the fields order in the layer datasource\n•add a new virtualActionscolumn that displays in each row a drop-down box or a button list of enabled actions.\nSeeActions Propertiesfor more information about actions.\nSorting columns\nThe table can be sorted by any column, by clicking on the column header. A small arrow indicates the sort order\n(downward pointing means descending values from the top row down, upward pointing means ascending values from\nthe top row down). You can also choose to sort the rows with theSort...option of the column header context menu\nand write an expression. E.g. to sort the rows using multiple columns you can writeconcat(col0, col1).\nIn form view, features identifier can be sorted using theSort by preview expressionoption.\nTip: Sorting based on columns of different types\nTrying to sort an attribute table based on columns of string and numeric types may lead to unexpected result because\nof theconcat(\"USE\", \"ID\")expression returning string values (ie,'Borough105' < 'Borough6').\nYou can workaround this by using egconcat(\"USE\", lpad(\"ID\", 3, 0))which returns'Borough105'\n> 'Borough006'.\nFormatting of table cells using conditions\nConditional formatting settings can be used to highlight in the attribute table features you may want to put a particular\nfocus on, using custom conditions on feature’s:\n•geometry (e.g., identifying multi-parts features, small area ones or in a defined map extent...);\n•or field value (e.g., comparing values to a threshold, identifying empty cells...).\nYou can enable the conditional formatting panel clicking onat the top right of the attributes window in table view\n(not available in form view).\n510Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nThe new panel allows user to add new rules to format rendering ofFieldorFull row. Adding new rule opens\na form to define:\n•the name of the rule;\n•a condition using any of theexpression builderfunctions;\n•the formatting: it can be choosen from a list of predefined formats or created based on properties like:\n–background and text colors;\n–use of icon;\n–bold, italic, underline, or strikeout;\n–font.\nFig. 15.68: Conditional Formatting of an attribute table\n15.2.3Interacting with features in an attribute table\nSelecting features\nIn table view, each row in the attribute table displays the attributes of a unique feature in the layer. Selecting a row\nselects the feature and likewise, selecting a feature in the map canvas (in case of geometry enabled layer) selects the\nrow in the attribute table. If the set of features selected in the map canvas (or attribute table) is changed, then the\nselection is also updated in the attribute table (or map canvas) accordingly.\nRows can be selected by clicking on the row number on the left side of the row.Multiple rowscan be marked by\nholding theCtrlkey. Acontinuous selectioncan be made by holding theShiftkey and clicking on several row\nheaders on the left side of the rows. All rows between the current cursor position and the clicked row are selected.\nMoving the cursor position in the attribute table, by clicking a cell in the table, does not change the row selection.\nChanging the selection in the main canvas does not move the cursor position in the attribute table.\n15.2. Working with the Attribute Table511\n\nQGIS Desktop 3.22 User Guide\nIn form view of the attribute table, features are by default identified in the left panel by the value of their displayed\nfield (seeDisplay Properties). This identifier can be replaced using the drop-down list at the top of the panel, either\nby selecting an existing field or using a custom expression. You can also choose to sort the list of features from the\ndrop-down menu.\nClick a value in the left panel to display the feature’s attributes in the right one. To select a feature, you need to click\ninside the square symbol at the left of the identifier. By default, the symbol turns into yellow. Like in the table view,\nyou can perform multiple feature selection using the keyboard combinations previously exposed.\nBeyond selecting features with the mouse, you can perform automatic selection based on feature’s attribute using tools\navailable in the attribute table toolbar, such as (see sectionAutomatic selectionand following one for more information\nand use case):\n•Select By Expression...\n•Select Features By Value...\n•Deselect All Features from the Layer\n•Select All Features\n•Invert Feature Selection.\nIt is also possible to select features using theFiltering and selecting features using forms.\nFiltering features\nOnce you have selected features in the attribute table, you may want to display only these records in the table. This\ncan be easily done using theShow Selected Featuresitem from the drop-down list at the bottom left of the attribute\ntable dialog. This list offers the following filters:\n•Show All Features\n•Show Selected Features- same as usingOpen Attribute Table (Selected Features)from theLayermenu or\ntheAttributes Toolbaror pressingShift+F6\n•Show Features visible on map- same as usingOpen Attribute Table (Visible Features)from theLayermenu\nor theAttributes Toolbaror pressingCtrl+F6\n•Show Edited and New Features- same as usingOpen Attribute Table (Edited and New Features)from the\nLayermenu or theAttributes Toolbar\n•Field Filter- allows the user to filter based on value of a field: choose a column from a list, type or select a value\nand pressEnterto filter. Then, only the features matchingnum_field = valueorstring_field\nilike '%value%'expression are shown in the attribute table. You can check\nCase sensitiveto be less\npermissive with strings.\n•Advanced filter (Expression)-Openstheexpressionbuilderdialog. Withinit, youcancreatecomplex expressions\nto match table rows. For example, you can filter the table using more than one field. When applied, the filter\nexpression will show up at the bottom of the form.\n•Stored filter expressions►: a shortcut tosaved expressionsfrequently used for filtering your attribute table.\nIt is also possible tofilter features using forms.\nNote:Filtering records out of the attribute table does not filter features out of the layer; they are simply momenta-\nneously hidden from the table and can be accessed from the map canvas or by removing the filter. For filters that do\nhide features from the layer, use theQuery Builder.\n512Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nTip: Update datasource filtering withShow Features Visible on Map\nWhen for performance reasons, features shown in attribute table are spatially limited to the canvas extent at its opening\n(seeData Source Optionsfor a how-to), selectingShow Features Visible on Mapon a new canvas extent updates the\nspatial restriction.\nStoring filter expressions\nExpressions you use for attribute table filtering can be saved for further calls. When usingField FilterorAdvanced\nFilter (expression)entries, the expression used is displayed in a text widget in the bottom of the attribute table dialog.\nPress the\nSave expression with text as name\nnext to the box to save the expression in the project. Pressing the drop-down\nmenu next to the button allows to save the expression with a custom name (Save expression as...). Once a saved\nexpression is displayed, the\nbutton is triggered and its drop-down menu allows you toEdit the expressionand\nname if any, orDelete stored expression.\nSaved filter expressions are saved in the project and available through theStored filter expressionsmenu of the attribute\ntable. They are different from the\nuser expressions, shared by all projects of the active user profile.\nFiltering and selecting features using forms\nClicking the\nFilter/Select features using form\nor pressingCtrl+Fwill make the attribute table dialog switch to form view\nand replace each widget with its search variant.\nFrom this point onwards, this tool functionality is similar to the one described inSelect Features By Value, where you\ncan find descriptions of all operators and selecting modes.\nFig. 15.69: Attribute table filtered by the filter form\nWhen selecting / filtering features from the attribute table, there is aFilter featuresbutton that allows defining and\nrefining filters. Its use triggers theAdvanced filter (Expression)option and displays the corresponding filter expression\nin an editable text widget at the bottom of the form.\nIf there are already filtered features, you can refine the filter using the drop-down list next to theFilter featuresbutton.\nThe options are:\n•Filter within (“AND”)\n•Extend filter (“OR”)\n15.2. Working with the Attribute Table513\n\nQGIS Desktop 3.22 User Guide\nTo clear the filter, either select theShow all featuresoption from the bottom left pull-down menu, or clear the ex-\npression and clickApplyor pressEnter.\n15.2.4Using action on features\nUsers have several possibilities to manipulate feature with the contextual menu like:\n•Select all(Ctrl+A) the features;\n•Copy the content of a cell in the clipboard withCopy cell content;\n•Zoom to featurewithout having to select it beforehand;\n•Pan to featurewithout having to select it beforehand;\n•Flash feature, to highlight it in the map canvas;\n•Open form\n: it toggles attribute table into form view with a focus on the clicked feature.\nFig. 15.70: Copy cell content button\nIf you want to use attribute data in external programs (such as Excel, LibreOffice, QGIS or a custom web application),\nselect one or more row(s) and use the\nCopy selected rows to clipboard\nbutton or pressCtrl+C.\nInSettings►Options►Data Sourcesmenu you can define the format to paste to withCopy features asdropdown list:\n•Plain text, no geometry,\n•Plain text, WKT geometry,\n•GeoJSON\nYou can also display a list of actions in this contextual menu. This is enabled in theLayer properties►Actionstab.\nSeeActions Propertiesfor more information on actions.\n514Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nSaving selected features as new layer\nThe selected features can be saved as any OGR-supported vector format and also transformed into another coordinate\nreference system (CRS). In the contextual menu of the layer, from theLayerspanel, click onExport►Save selected\nfeatures as...\nto define the name of the output dataset, its format and CRS (see section\nCreating new layers from an\nexisting layer). You’ll notice thatSave only selected featuresis checked. It is also possible to specify OGR creation\noptions within the dialog.\n15.2.5Editing attribute values\nEditing attribute values can be done by:\n•typing the new value directly in the cell, whether the attribute table is in table or form view. Changes are hence\ndone cell by cell, feature by feature;\n•using thefield calculator: update in a row a field that may already exist or to be created but for multiple features.\nIt can be used to create virtual fields;\n•using the quick fieldcalculation bar: same as above but for only existing field;\n•or using themulti editmode: update in a row multiple fields for multiple features.\nUsing the Field Calculator\nThe\nField Calculator\nbutton in the attribute table allows you to perform calculations on the basis of existing attribute\nvalues or defined functions, for instance, to calculate length or area of geometry features. The results can be used to\nupdate an existing field, or written to a new field (that can be avirtualone).\nThe field calculator is available on any layer that supports edit. When you click on the field calculator icon the dialog\nopens (see\nFig. 15.71). If the layer is not in edit mode, a warning is displayed and using the field calculator will cause\nthe layer to be put in edit mode before the calculation is made.\nBased on the\nExpression Builderdialog, the field calculator dialog offers a complete interface to define an expression\nand apply it to an existing or a newly created field. To use the field calculator dialog, you must select whether you\nwant to:\n1.apply calculation on the whole layer or on selected features only\n2.create a new field for the calculation or update an existing one.\n15.2. Working with the Attribute Table515\n\nQGIS Desktop 3.22 User Guide\nFig. 15.71: Field Calculator\nIf you choose to add a new field, you need to enter a field name, a field type (integer, real, date or string) and if needed,\nthe total field length and the field precision. For example, if you choose a field length of 10 and a field precision of 3,\nit means you have 7 digits before the dot, and 3 digits for the decimal part.\nA short example illustrates how field calculator works when using theExpressiontab. We want to calculate the length\nin km of therailroadslayer from the QGIS sample dataset:\n1.Load the shapefilerailroads.shpin QGIS and press\nOpen Attribute Table\n.\n2.Click on\nToggle editing mode\nand open the\nField Calculator\ndialog.\n3.Select theCreate a new fieldcheckbox to save the calculations into a new field.\n4.SetOutput field nametolength_km\n5.SelectDecimal number (real)asOutput field type\n6.Set theOutput field lengthto10and thePrecisionto3\n7.Double click on$lengthin theGeometrygroup to add the length of the geometry into the Field calculator\nexpression box.\n8.Complete the expression by typing/ 1000in the Field calculator expression box and clickOK.\n9.You can now find a newlength_kmfield in the attribute table.\n516Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nCreating a Virtual Field\nA virtual field is a field based on an expression calculated on the fly, meaning that its value is automatically updated\nas soon as an underlying parameter changes. The expression is set once; you no longer need to recalculate the field\neach time underlying values change. For example, you may want to use a virtual field if you need area to be evaluated\nas you digitize features or to automatically calculate a duration between dates that may change (e.g., usingnow()\nfunction).\nNote: Use of Virtual Fields\n•Virtual fields are not permanent in the layer attributes, meaning that they’re only saved and available in the\nproject file they’ve been created.\n•A field can be set virtual only at its creation. Virtual fields are marked with a purple background in the fields\ntab of the layer properties dialog to distinguish them from regular physical or joined fields. Their expression\ncan be edited later by pressing the expression button in the Comment column. An expression editor window\nwill be opened to adjust the expression of the virtual field.\nUsing the Quick Field Calculation Bar\nWhile Field calculator is always available, the quick field calculation bar on top of the attribute table is only visible if\nthe layer is in edit mode. Thanks to the expression engine, it offers a quicker access to edit an already existing field:\n1.Select the field to update in the drop-down list.\n2.Fill the textbox with a value, an expression you directly write or build using theexpression button.\n3.Click onUpdate All,Update SelectedorUpdate Filteredbutton according to your need.\nFig. 15.72: Quick Field Calculation Bar\nEditing multiple fields\nUnlike the previous tools, multi edit mode allows multiple attributes of different features to be edited simultaneously.\nWhen the layer is toggled to edit, multi edit capabilities are accessible:\n•using the\nToggle multi edit mode\nbutton from the toolbar inside the attribute table dialog;\n•or selectingEdit►Modify attributes of selected featuresmenu.\n15.2. Working with the Attribute Table517\n\nQGIS Desktop 3.22 User Guide\nNote:Unlike the tool from the attribute table, hitting theEdit►Modify Attributes of Selected Featuresoption\nprovides you with a modal dialog to fill attributes changes. Hence, features selection is required before execution.\nIn order to edit multiple fields in a row:\n1.Select the features you want to edit.\n2.From the attribute table toolbar, click thebutton. This will toggle the dialog to its form view. Feature\nselection could also be made at this step.\n3.At the right side of the attribute table, fields (and values) of selected features are shown. New widgets appear\nnext to each field allowing for display of the current multi edit state:\n•The field contains different values for selected features. It’s shown empty and each feature will keep\nits original value. You can reset the value of the field from the drop-down list of the widget.\n•All selected features have the same value for this field and the value displayed in the form will be\nkept.\n•The field has been edited and the entered value will be applied to all the selected features. A message\nappears at the top of the dialog, inviting you to either apply or reset your modification.\nClicking any of these widgets allows you to either set the current value for the field or reset to original value,\nmeaning that you can roll back changes on a field-by-field basis.\nFig. 15.73: Editing fields of multiple features\n4.Make the changes to the fields you want.\n5.Click onApply changesin the upper message text or any other feature in the left panel.\nChanges will apply toall selected features. If no feature is selected, the whole table is updated with your changes.\nModifications are made as a single edit command. So pressing\nUndo\nwill rollback the attribute changes for all\n518Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nselected features at once.\nNote:Multi edit mode is only available for auto generated and drag and drop forms (seeCustomizing a form for\nyour data); it is not supported by custom ui forms.\n15.2.6Creating one or many to many relations\nRelations are a technique often used in databases. The concept is that features (rows) of different layers (tables) can\nbelong to each other.\nIntroducing 1-N relations\nAs an example you have a layer with all regions of alaska (polygon) which provides some attributes about its name\nand region type and a unique id (which acts as primary key).\nThen you get another point layer or table with information about airports that are located in the regions and you also\nwant to keep track of these. If you want to add them to the regions layer, you need to create a one to many relation\nusing foreign keys, because there are several airports in most regions.\nFig. 15.74: Alaska region with airports\nLayers in 1-N relations\nQGIS makes no difference between a table and a vector layer. Basically, a vector layer is a table with a geometry.\nSo you can add your table as a vector layer. To demonstrate the 1-n relation, you can load theregionsshapefile\nand theairportsshapefile which has a foreign key field (fk_region) to the layer regions. This means, that\neach airport belongs to exactly one region while each region can have any number of airports (a typical one to many\nrelation).\n15.2. Working with the Attribute Table519\n\nQGIS Desktop 3.22 User Guide\nForeign keys in 1-N relations\nIn addition to the already existing attributes in the airports attribute table, you’ll need another fieldfk_region\nwhich acts as a foreign key (if you have a database, you will probably want to define a constraint on it).\nThis field fk_region will always contain an id of a region. It can be seen like a pointer to the region it belongs to. And\nyou can design a custom edit form for editing and QGIS takes care of the setup. It works with different providers (so\nyou can also use it with shape and csv files) and all you have to do is to tell QGIS the relations between your tables.\nDefining 1-N relations\nThe first thing we are going to do is to let QGIS know about the relations between the layers. This is done inProject\n►Properties.... Open theRelationstab and click onAdd Relation.\n•Nameis going to be used as a title. It should be a human readable string, describing, what the relation is used\nfor. We will just call sayairport_relationin this case.\n•Referenced Layer (Parent)also considered as parent layer, is the one with the primary key, pointed to, so\nhere it is theregionslayer. You need to define the primary key of the referenced layer, so it isID.\n•Referencing Layer (Child)also considered as child layer, is the one with the foreign key field on it. In our\ncase, this is theairportslayer. For this layer you need to add a referencing field which points to the other\nlayer, so this isfk_region.\nNote:Sometimes, you need more than a single field to uniquely identify features in a layer. Creating a\nrelation with such a layer requires acomposite key, ie more than a single pair of matching fields. Use the\nAdd new field pair as part of a composite foreign key\nbutton to add as many pairs as necessary.\n•Idwill be used for internal purposes and has to be unique. You may need it to buildcustom forms. If you leave\nit empty, one will be generated for you but you can assign one yourself to get one that is easier to handle\n•Relationship strengthsets the strength of the relation between the parent and the child layer. The default\nAssociationtype means that the parent layer issimplylinked to the child one while theCompositiontype allows\nyou to duplicate also the child features when duplicating the parent ones and on deleting a feature the children\nare deleted as well, resulting in cascade over all levels (means children of children of... are deleted as well).\n520Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.75: Adding a relation between regions and airports layers\nFrom theRelationstab, you can also press theDiscover Relationbutton to fetch the relations available from the\nproviders of the loaded layers. This is possible for layers stored in data providers like PostgreSQL or SpatiaLite.\nForms for 1-N relations\nNow that QGIS knows about the relation, it will be used to improve the forms it generates. As we did not change the\ndefault form method (autogenerated) it will just add a new widget in our form. So let’s select the layer region in the\nlegend and use the identify tool. Depending on your settings, the form might open directly or you will have to choose\nto open it in the identification dialog under actions.\n15.2. Working with the Attribute Table521\n\nQGIS Desktop 3.22 User Guide\nFig. 15.76: Identification dialog regions with relation to airports\nAs you can see, the airports assigned to this particular region are all shown in a table. And there are also some buttons\navailable. Let’s review them shortly:\n•Thebutton is for toggling the edit mode. Be aware that it toggles the edit mode of the airport layer,\nalthough we are in the feature form of a feature from the region layer. But the table is representing features of\nthe airport layer.\n•Thebutton is for saving all the edits in the child layer (airport).\n•Thebutton lets you digitize the airport geometry in the map canvas and assigns the new feature to the\ncurrent region by default. Note that the icon will change according to the geometry type.\n•Thebutton adds a new record to the airport layer attribute table and assigns the new feature to the current\nregion by default. The geometry can be drawn later with theAdd partdigitizing tool.\n•Thebutton allows you to copy and paste one or more child features within the child layer. They can later\nbe assigned to a different parent feature or have their attributes modified.\n•Thebutton deletes the selected airport(s) permanently.\n•Thesymbol opens a new dialog where you can select any existing airport which will then be assigned to\nthe current region. This may be handy if you created the airport on the wrong region by accident.\n•Thesymbol unlinks the selected airport(s) from the current region, leaving them unassigned (the foreign\nkey is set to NULL) effectively.\n•With thebutton you can zoom the map to the selected child features.\n522Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•The two buttonsandto the right switch between thetable view and form viewof the related child\nfeatures.\nIf you use theDrag and Drop Designerfor the regions feature, you can select which tools are available. You can even\ndecide whether to open a new form when a new feature is added usingForce hide form on add featureoption. Be\naware that this option implies that not null attributes must take a valid default value to work correctly.\nFig. 15.77: Drag and Drop Designer for configure regions-airports relation tools\nIn the above example the referencing layer has geometries (so it isn’t just an alphanumeric table) so the above steps\nwill create an entry in the layer attribute table that has no corresponding geometric feature. To add the geometry:\n1.ChooseOpen Attribute Tablefor the referencing layer.\n2.Select the record that has been added previously within the feature form of the referenced layer.\n3.Use the\nAdd Part\ndigitizing tool to attach a geometry to the selected attributes table record.\nIf you work on the airport table, the widget Relation Reference is automatically set up for thefk_regionfield (the\none used to create the relation), seeRelation Reference widget.\nIn the airport form you will see thebutton at the right side of thefk_regionfield: if you click on the button\nthe form of the region layer will be opened. This widget allows you to easily and quickly open the forms of the linked\nparent features.\n15.2. Working with the Attribute Table523\n\nQGIS Desktop 3.22 User Guide\nFig. 15.78: Identification dialog airport with relation to regions\nThe Relation Reference widget has also an option to embed the form of the parent layer within the child one. It is\navailable in theProperties►Attributes Formmenu of the airport layer: select thefk_regionfield and check the\nShow embedded formoption.\nIf you look at the feature dialog now, you will see, that the form of the region is embedded inside the airports form\nand will even have a combobox, which allows you to assign the current airport to another region.\nMoreover if you toggle the editing mode of the airport layer, thefk_regionfield has also an autocompleter\nfunction: while typing you will see all the values of theidfield of the region layer. Here it is possible to digitize a\npolygon for the region layer using thebutton if you chose the optionAllow adding new featuresin\ntheProperties►Attributes Formmenu of the airport layer.\nThe child layer can also be used in the\nSelect Features By Valuetool in order to select features of the parent layer\nbased on attributes of their children.\nInFig. 15.79, all the regions where the mean altitude of the airports is greater than 500 meters above sea level are\nselected.\nYou will find that many different aggregation functions are available in the form.\n524Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.79: Select parent features with child values\nIntroducing many-to-many (N-M) relations\nN-M relations are many-to-many relations between two tables. For instance, theairportsandairlineslayers:\nan airport receives several airline companies and an airline company flies to several airports.\nThis SQL code creates the three tables we need for an N-M relationship in a PostgreSQL/PostGIS schema named\nlocations. You can run the code using theDatabase►DB Manager...for PostGIS or external tools such as\npgAdmin.\nThe airports table stores theairportslayer and the airlines table stores theairlineslayer. In both tables few\nfields are used for clarity. Thetrickypart is theairports_airlinestable. We need it to list all airlines for all\nairports (or vice versa). This kind of table is known as apivot table. Theconstraintsin this table force that an airport\ncan be associated with an airline only if both already exist in their layers.\nCREATESCHEMAlocations;\nCREATETABLElocations.airports\n(\nidserialNOTNULL,\ngeomgeometry(Point,4326)NOTNULL,\nairport_nametextNOTNULL,\nCONSTRAINTairports_pkeyPRIMARYKEY(id)\n);\nCREATEINDEXairports_geom_idxONlocations.airportsUSINGgist(geom);\nCREATETABLElocations.airlines\n(\nidserialNOTNULL,\ngeomgeometry(Point,4326)NOTNULL,\nairline_nametextNOTNULL,\nCONSTRAINTairlines_pkeyPRIMARYKEY(id)\n);\nCREATEINDEXairlines_geom_idxONlocations.airlinesUSINGgist(geom);\n(continues on next page)\n15.2. Working with the Attribute Table525\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\nCREATETABLElocations.airports_airlines\n(\nidserialNOTNULL,\nairport_fkintegerNOTNULL,\nairline_fkintegerNOTNULL,\nCONSTRAINTairports_airlines_pkeyPRIMARYKEY(id),\nCONSTRAINTairports_airlines_airport_fk_fkeyFOREIGNKEY(airport_fk)\nREFERENCESlocations.airports(id)\nONDELETECASCADE\nONUPDATECASCADE\nDEFERRABLEINITIALLYDEFERRED,\nCONSTRAINTairports_airlines_airline_fk_fkeyFOREIGNKEY(airline_fk)\nREFERENCESlocations.airlines(id)\nONDELETECASCADE\nONUPDATECASCADE\nDEFERRABLEINITIALLYDEFERRED\n);\nInstead of PostgreSQL you can also use GeoPackage. In this case, the three tables can be created manually using the\nDatabase►DB Manager.... In GeoPackage there are no schemas so thelocationsprefix is not needed.\nForeign key constraints inairports_airlinestable can ́t be created usingTable►Create Table...orTable\n►Edit Table...so they should be created usingDatabase►SQL Window.... GeoPackage doesn’t supportADD\nCONSTRAINTstatements so theairports_airlinestable should be created in two steps:\n1.Set up the table only with theidfield usingTable►Create Table...\n2.UsingDatabase►SQL Window..., type and execute this SQL code:\nALTERTABLEairports_airlines\nADDCOLUMNairport_fkINTEGER\nREFERENCESairports(id)\nONDELETECASCADE\nONUPDATECASCADE\nDEFERRABLEINITIALLYDEFERRED;\nALTERTABLEairports_airlines\nADDCOLUMNairline_fkINTEGER\nREFERENCESairlines(id)\nONDELETECASCADE\nONUPDATECASCADE\nDEFERRABLEINITIALLYDEFERRED;\nThen in QGIS, you should set up twoone-to-many relationsas explained above:\n•a relation betweenairlinestable and the pivot table;\n•and a second one betweenairportstable and the pivot table.\nAn easier way to do it (only for PostgreSQL) is using theDiscover RelationsinProject►Properties►Relations.\nQGIS will automatically read all relations in your database and you only have to select the two you need. Remember\nto load the three tables in the QGIS project first.\n526Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.80: Relations and autodiscover\nIn case you want to remove anairportor anairline, QGIS won’t remove the associated record(s) inair-\nports_airlines\ntable. This task will be made by the database if we specify the right\nconstraints\nin the pivot\ntable creation as in the current example.\nNote: Combining N-M relation with automatic transaction group\nYou should enable the transaction mode inProject Properties►Data Sources► when working on such context. QGIS\nshould be able to add or update row(s) in all tables (airlines, airports and the pivot tables).\nFinally we have to select the right cardinality in theLayer Properties►Attributes Formfor theairportsand\nairlineslayers. For the first one we should choose theairlines (id)option and for the second one theairports\n(id)option.\nFig. 15.81: Set relationship cardinality\nNow you can associate an airport with an airline (or an airline with an airport) usingAdd child featureorLink existing\nchild featurein the subforms. A record will automatically be inserted in theairports_airlinestable.\n15.2. Working with the Attribute Table527\n\nQGIS Desktop 3.22 User Guide\nFig. 15.82: N-M relationship between airports and airlines\nNote:UsingMany to one relationcardinality\nSometimes hiding the pivot table in an N-M relationship is not desirable. Mainly because there are attributes in the\nrelationshipthatcanonlyhavevalueswhenarelationshipisestablished. Ifyourtablesarelayers(haveageometryfield)\nit could be interesting to activate theOn map identificationoption (Layer Properties►Attributes Form►Available\nwidgets►Fields) for the foreign key fields in the pivot table.\nNote: Pivot table primary key\nAvoid using multiple fields in the primary key in a pivot table. QGIS assumes a single primary key so a constraint\nlikeconstraint airports_airlines_pkey primary key (airport_fk, airline_fk)will\nnot work.\n528Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nIntroducing polymorphic relations\nPolymorphic relations are special case of 1-N relations, where a single referencing (document) layer contains the\nfeatures for multiple referenced layers. This differs from normal relations which require different referencing layer\nfor each referenced layer. A single referencing (document) layer is achieved by adding an adiditonal\nlayer_field\ncolumn in the referencing (document) layer that stores information to identify the referenced layer. In its most simple\nform, the referencing (document) layer will just insert the layer name of the referenced layer into this field.\nTo be more precise, a polymorphic relation is a set of normal relations having the same referencing layer but having\nthe referenced layer dynamically defined. The polymorphic setting of the layer is solved by using an expression which\nhas to match some properties of the referenced layer like the table name, layer id, layer name.\nImagine we are going to the park and want to take pictures of different species ofplantsandanimalswe see\nthere. Each plant or animal has multiple pictures associated with it, so if we use the normal 1:N relations to store\npictures, we would need two separate tables,animal_imagesandplant_images. This might not be a problem\nfor 2 tables, but imagine if we want to take separate pictures for mushrooms, birds etc.\nPolymorphic relations solve this problem as all the referencing features are stored in the same tabledocuments.\nFor each feature the referenced layer is stored in thereferenced_layerfield and the referenced feature id in\nthereferenced_fkfield.\nDefining polymorphic relations\nFirst, let QGIS know about the polymorphic relations between the layers. This is done inProject►Properties....\nOpen theRelationstab and click on the little down arrow next to the\nAdd Relationbutton, so you can select the\nAdd Polymorphic Relationoption from the newly appeared dropdown.\n15.2. Working with the Attribute Table529\n\nQGIS Desktop 3.22 User Guide\nFig. 15.83: Adding a polymorphic relation usingdocumentslayer as referencing andanimalsandplantsas\nreferenced layers.\n•Idwill be used for internal purposes and has to be unique. You may need it to buildcustom forms. If you leave\nit empty, one will be generated for you but you can assign one yourself to get one that is easier to handle\n•Referencing Layer (Child)also considered as child layer, is the one with the foreign key field on it. In our\ncase, this is thedocumentslayer. For this layer you need to add a referencing field which points to the other\nlayer, so this isreferenced_fk.\nNote:Sometimes, you need more than a single field to uniquely identify features in a layer. Creating a\nrelation with such a layer requires acomposite key, ie more than a single pair of matching fields. Use the\nAdd new field pair as part of a composite foreign key\nbutton to add as many pairs as necessary.\n•Layer Fieldis the field in the referencing table that stores the result of the evaluated layer expression which is\nthe referencing table that this feature belongs to. In our example, this would be thereferenced_layer\nfield.\n•Layer expressionevaluates to a unique identifier of the layer. This can be the layer name@layer_name,\nthe layer id@layer_id, the layer’s table namedecode_uri(@layer, 'table')or anything that\ncan uniquely identifies a layer.\n530Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•Relationship strengthsets the strength of the generated relations between the parent and the child layer. The\ndefaultAssociationtype means that the parent layer issimplylinked to the child one while theCompositiontype\nallows you to duplicate also the child features when duplicating the parent ones and on deleting a feature the\nchildren are deleted as well, resulting in cascade over all levels (means children of children of... are deleted as\nwell).\n•Referenced Layersalso considered as parent layers, are those with the primary key, pointed to, so here they\nwould beplantsandanimalslayers. You need to define the primary key of the referenced layers from\nthe dropdown, so it isfid. Note that the definition of a valid primary key requires all the referenced layers to\nhave a field with that name. If there is no such field you cannot save a polymorphic relation.\nOnce added, the polymorphic relation can be edited via theEdit Polymorphic Relationmenu entry.\nFig. 15.84: Preview of the newly created polymorphic relation and it’s child relations for animals and plants.\nThe example above uses the following database schema:\nCREATESCHEMApark;\nCREATETABLEpark.animals\n(\nfidserialNOTNULL,\ngeomgeometry(Point,4326)NOTNULL,\nanimal_speciestextNOTNULL,\nCONSTRAINTanimals_pkeyPRIMARYKEY(fid)\n);\nCREATEINDEXanimals_geom_idxONpark.animalsUSINGgist(geom);\nCREATETABLEpark.plants\n(\nfidserialNOTNULL,\ngeomgeometry(Point,4326)NOTNULL,\nplant_speciestextNOTNULL,\nCONSTRAINTplants_pkeyPRIMARYKEY(fid)\n);\nCREATEINDEXplants_geom_idxONpark.plantsUSINGgist(geom);\nCREATETABLEpark.documents\n(continues on next page)\n15.2. Working with the Attribute Table531\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n(\nfidserialNOTNULL,\nreferenced_layertextNOTNULL,\nreferenced_fkintegerNOTNULL,\nimage_filenametextNOTNULL,\nCONSTRAINTdocuments_pkeyPRIMARYKEY(fid)\n);\n15.2.7Storing and fetching an external resource\nA field may target a resource stored on an external storage system. Attribute forms can be configured so they act as\na client to an external storage system in order to store and fetch those resources, on users demand, directly from the\nforms.\nConfiguring an external storage\nIn order to setup an external storage, you have to first configure it from the vectorattribute form propertiesand select\ntheAttachmentwidget.\nFig. 15.85: Editing a WebDAV external storage for a given field\nFrom theAttachmentwidget, you have to first select theStorage type:\n•Select Existing File: The target URL already exists. When you select a resource, no store operation is achieved,\nthe attribute is simply updated with the URL.\n•Simple Copy: Stores a copy of the resource on a file disk destination (which could be a local or network shared\nfile system) and the attribute is updated with the path to the copy.\n•WebDAV Storage: The resource is pushed to a HTTP server supporting theWebDAVprotocol and the attribute\nis updated with its URL.Nextcloud,Pydioor other file hosting software support this protocol.\nThen, you have to set up theStore URLparameter, which provides the URL to be used when a new resource needs to\nbe stored. It’s possible to set up an expression using thedata defined override widgetin order to have specific values\naccording to feature attributes.\nThe variable@selected_file_pathcould be used in that expression and represent the absolute file path of the user\nselected file (using the file selector or drag’n drop).\n532Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nNote:Using theWebDAVexternal storage, if the URL ends with a “/”, it is considered as a folder and the selected\nfile name will be appended to get the final URL.\nIf the external storage system needs to, it’s possible to configure anauthentication.\nUsing an external storage\nOnce configured, you can select a local file using the button...when editing a feature’s attribute. Depending on the\nconfiguredstorage type, the file will be stored on the external storage system (except ifSelect existing filehas been\nselected) and the field will be updated with the new resource URL.\nFig. 15.86: Storing a file to a WebDAV external storage\nNote:User can also achieve the same result if he drags and drops a file on the whole attachment widget.\nUse the\nCancel\nbutton to abort the storing process. It’s possible to configure a viewer using theIntegrated document\nviewerso the resource will be automatically fetched from the external storage system and displayed directly below\nthe URL. The above\nicon indicates that the resource cannot be fetched from the external storage system. In that\ncase, more details might appear in the\nLog Messages Panel.\n15.3Editing\nQGIS has various capabilities for editing OGR, SpatiaLite, PostGIS, MSSQL Spatial and Oracle Spatial vector layers\nand tables.\nNote:The procedure for editing GRASS layers is different - see sectionDigitizing and editing a GRASS vector layer\nfor details.\n15.3. Editing533\n\nQGIS Desktop 3.22 User Guide\nAttention: Concurrent Edits\nThis version of QGIS does not track if somebody else is editing the same feature at the same time as you are.\nThe last person to save the edits wins.\nTip: Validating Edits\nContinuous validation can be activated on a layer basis in theLayer Properties►Digitizingtab. More atDigitizing\nProperties.\n15.3.1Setting the snapping tolerance and search radius\nUnder theSettings►Options...►Digitizingmenu, QGIS provides a number of parameters to configure default\nbehaviour of editing tools. More information atDigitizing Settings.\nFor optimal and accurate editing of vector layer geometries, we need to set an appropriate value of snapping tolerance\nand search radius for features vertices. TheSnappinggroup provides related options, namely handling of the snapping\ntolerance and the search radius.\n•Snapping tolerance: When you add a new vertex or move an existing one, the snapping tolerance is the distance\nQGIS uses to search for the closest vertex or segment you are trying to connect to. If you are not within the\nsnapping tolerance, QGIS will leave the vertex where you release the mouse button, instead of snapping it to\nan existing vertex or segment.\nThe tolerance setting affects all tools that work with snapping and applies by default to new layers and projets.\nIt can however be overridden at layer level (see\nSnapping and Digitizing Options).\n•Search radius:Search radius for vertex editsis the distance QGIS uses tosearchfor the vertex to select\nwhen you click on the map. If you are not within the search radius, QGIS will not find and select any vertex\nfor editing.\nSnap tolerance and search radius are set inmap unitsorpixels. You may need to experiment to get them\nright. If you specify a too big tolerance, QGIS may snap to the wrong vertex, especially if you are dealing with a\nlarge number of vertices in close proximity. The smaller the search radius, the more difficult it will be to hit what\nyou want to move.\n15.3.2Snapping and Digitizing Options\nGlobalsnapping and digitizing settings(snapping mode, tolerance value, and units...) can be overridden in the project\nfrom theProject►Snapping Options...menu. In theSnapping and Digitizing Options, you can also configure some\nother properties (snapping layers, scale limit, topology...) The guilabel:Snapping Toolbargives access to most of\nthese features.\nBy default, snapping is disabled in a project until you press the\nEnable snapping\nbutton or pressS. The snapping mode,\ntolerance value, and units can also be configured in this toolbar.\n534Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nSnapping properties\nThere are three options to select the layer(s) to snap to:\n•All layers: quick setting for all visible layers in the project so that the pointer snaps to all vertices and/or\nsegments. In most cases, it is sufficient to use this snapping mode, but beware when using it for projects with\nmany vector layers, as it may affect performance.\n•Current layer: only the active layer is used, a convenient way to ensure topological consistency within the layer\nbeing edited.\n•Advanced Configuration: allows you to enable and adjust snapping mode, tolerance and units, overlaps and\nscales of snapping on a layer basis (seeFig. 15.87). If you need to edit a layer and snap its vertices to another,\nmake sure that the target layer is checked and increase the snapping tolerance to a higher value. Snapping will\nnot occur to a layer that is not checked in the snapping options dialog.\nAs for snapping mode, you can choose betweenVertex,Segment,Area,Centroid,Middle of Seg-\nmentsandLine Endpoints.\nQGIS will show differentsnapicons depending on the kind ofsnap:\nSnapping to a vertex: box iconSnapping to a segment: hourglass\nicon\nSnapping to an intersection: cross\nicon\nNote that it is possible to change the color of these icons in theDigitizingpart of the global settings.\nThe tolerance values can be set either in the project’smap unitsor inpixels. The advantage of choosing\npixelsis that it keeps the snapping constant at different map scales. 10 to 12 pixels is normally a good value, but it\ndepends on the DPI of your screen. Using map units allows the tolerance to be related to real ground distances. For\nexample, if you have a minimum distance between elements, this option can be useful to ensure that you don’t add\nvertices too close to each other.\nFig. 15.87: Snapping options (Advanced Configuration mode)\nNote:By default, only visible features (the features whose style is displayed, except for layers where the symbology\nis “No symbols”) can be snapped. You can enable the snapping on invisible features by checking\nEnable snapping\non invisible featuresunder theSettings►Options►Digitizingtab.\n15.3. Editing535\n\nQGIS Desktop 3.22 User Guide\nTip: Enable snapping by default\nYou can set snapping to be enabled by default on all new projects in theSettings►Options►Digitizingtab. You can\nalso set the default snapping mode, tolerance value, and units, which will populate theSnapping Optionsdialog.\nEnable snapping on intersections\nAnother available option is to usesnapping on intersection, which allows you to snap to geometry intersections\nof snapping enabled layers, even if there are no vertices at the intersections.\nLimit snapping to a scale range\nIn some cases snapping can become very slow. This is often caused by the amount of features in some layers that\nrequire a heavy index to compute and maintain. Some parameters exist to enable snapping only when the map view is\ninside a relevant scale range. This allows to only do the costly index computation related to snapping at a scale where\ndrawing is relevant.\nScale limit to snapping is configured inProject►Snapping Options.... Limiting snapping to scale is only available in\nAdvanced Configurationmode.\nTo limit snapping to a scale range you have three modes available:\n•Disabled: Snapping is enabled whatever the current map scale is. This is the default mode.\n•Global: Snapping is limited and only enabled when the current scale of the map is between a global minimum\nand a global maximum value. When selecting this mode two widgets become available to configure the range\nof scales in which snapping is enabled.\n•Per layer: The snapping scale range limit is defined for each layer. When selecting this mode two columns\nbecome available to configure the minimum and maximum scales for each layer.\nPlease note that the minimum and maximum scales follow the QGIS convention: minimum scale is the most “zoomed\nout” scale while maximum scale is the most “zoomed in”. A minimum or maximum scale that is set to “0” or “not\nset” is considered not limiting.\nSelf-snapping\nThe\nSelf-snapping\noption allows you to snap to the geometry that is being edited. Combined with the\nadvanced\ndigitizing panel, this provides a handy way to digitize new edges relative to the previous edges or vertices. Self-\nsnapping can cause invalid geometries, use with caution.\nSnapping on custom grid\nA snapping distance can also be customized on a layer basis in theDigitizingtab of the layer properties dialog. With\nsetting theGeometry precisiondistance, you enable a dotted grid visible when the map canvas is at a coherent scale\nfor display. Snapping can then be performed on the dots of the grid: an added or modified geometry will have all of\nits vertices snapped automatically to the closest node of the grid. More information at\nDigitizing Properties.\n536Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n15.3.3Topological editing\nIn addition to these snapping options, theSnapping options...dialog (Project►Snapping options) and theSnapping\ntoolbar allow you to enable / disable some other topological functionalities.\nEnable topological editing\nThe\nTopological editing\nbutton helps when editing and maintaining features with common boundaries. With this option\nenabled, QGIS ‘detects’ shared boundaries. When you move common vertices/segments, QGIS will also move them\nin the geometries of the neighboring features.\nTopological editing works with features from different layers, as long as the layers are visible and in editing mode.\nIn layer with Z values, topological editing will interpolate the Z value of the vertex based on the value of the edge\nused for the connection.\nOverlapping control\nOverlapping prevents you from drawing new features that overlap existing ones in the selected layer, speeding up\ndigitizing of adjacent polygons. It can be controlled by the overlap tool. Three modes are available:\n1.Allow Overlap(default)\n2.Avoid Overlap on Active Layer: prevents any overlap with other features from the layer being edited.\nDigitize the new geometries so that they overlap their neighbours and QGIS will cut the overlapping part(s) of\nthe new geometries and snap them to the boundary of the existing features. The advantage is that you don’t\nhave to digitize the common vertices on boundary.\n3.Follow Advanced Configuration: allows the overlapping setting to be set on a layer basis in theAdvanced\nconfigurationview mode.\nNote:\nIf the new geometry is totally covered by existing ones, it gets cleared, and QGIS will show an error message.\nWarning: Use cautiously theAvoid overlapoption\nSince this option will cut new overlapping geometries of any polygon layer, you can get unexpected geometries if\nyou forget to uncheck it when no longer needed.\nAutomatic Tracing\nUsually, when using capturing map tools (add feature, add part, add ring, reshape and split), you need to click each\nvertex of the feature. With the automatic tracing mode, you can speed up the digitization process as you no longer\nneed to manually place all the vertices during digitization:\n1.Enable the\nTracing\ntool (in theSnappingtoolbar) by pushing the icon or pressingTkey.\n2.Snap toa vertex or segment of a feature you want to trace along.\n3.Move the mouse over another vertex or segment you’d like to snap and, instead of the usual straight line, the\ndigitizing rubber band represents a path from the last point you snapped to the current position. The tool also\nworks with curved geometries.\nQGIS actually uses the underlying features topology to build the shortest path between the two points. Tracing\nrequires snapping to be activated in traceable layers to build the path. You should also snap to an existing\n15.3. Editing537\n\nQGIS Desktop 3.22 User Guide\nvertex or segment while digitizing and ensure that the two nodes are topologically connectable through existing\nfeatures edges, otherwise QGIS is unable to connect them and thus traces a single straight line.\n4.Click and QGIS places the intermediate vertices following the displayed path.\nUnfold the\nEnable Tracing\nicon and set theOffsetoption to digitize a path parallel to the features instead of tracing\nalong them. A positive value shifts the new drawing to the left side of the tracing direction and a negative value does\nthe opposite.\nNote: Adjust map scale or snapping settings for an optimal tracing\nIf there are too many features in map display, tracing is disabled to avoid potentially long tracing structure preparation\nand large memory overhead. After zooming in or disabling some layers the tracing is enabled again.\nNote: Does not add topological points\nThis tool does not add points to existing polygon geometries even ifTopological editingis enabled. If geometry\nprecision is activated on the edited layer, the resulting geometry might not exactly follow an existing geometry.\nTip: Quickly enable or disable automatic tracing by pressing theTkey\nBy pressing theTkey, tracing can be enabled/disabled anytime (even while digitizing a feature), so it is possible to\ndigitize parts of the feature with tracing enabled and other parts with tracing disabled. Tools behave as usual when\ntracing is disabled.\nTip: Convert tracing to curved geometries\nBy usingSettings►Options►Digitizing►Tracingyou can create curved geometries while digitizing. Seedigitizing\noptions.\n15.3.4Digitizing an existing layer\nBy default, QGIS loads layers read-only. This is a safeguard to avoid accidentally editing a layer if there is a slip of\nthe mouse. However, you can choose to edit any layer as long as the data provider supports it (see\nExploring Data\nFormats and Fields), and the underlying data source is writable (i.e., its files are not read-only).\nTip: Restrict edit permission on layers within a project\nFrom theProject►Properties...►Data Sources►Layers Capabilitiestable, you can choose to set any layer read-only\nregardless the provider permission. This can be a handy way, in a multi-users environment to avoid unauthorized users\nto mistakenly edit layers (e.g., Shapefile), hence potentially corrupt data. Note that this setting only applies inside the\ncurrent project.\nIn general, tools for editing vector layers are divided into a digitizing and an advanced digitizing toolbar, described\nin sectionAdvanced digitizing. You can select and unselect both underView►Toolbars►.\nUsing the basic digitizing tools, you can perform the following functions:\n538Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nIconPurposeIconPurpose\nAccess to save, rollback or cancel changes in all\nor selected layers simultaneously\nTurn on or off edit status of selected layer(s)\nbased on the active layer status\nSave edits to the active layer\nAdd new recordAdd Feature: Capture Point\nAdd Feature: Capture LineAdd Feature: Capture Polygon\nVertex Tool (All Layers)Vertex Tool (Current Layer)\nModify the attributes of all selected features si-\nmultaneously\nDelete Selected features from the active layerCut Features from the active layer\nCopy selected Features from the active layerPaste Features into the active layer\nUndo changes in the active layerRedo changes in active layer\nTable Editing: Vector layer basic editing toolbar\nNote that while using any of the digitizing tools, you can stillzoom or panin the map canvas without losing the focus\non the tool.\nAll editing sessions start by choosing the\nToggle editing\noption found in the context menu of a given layer, from the\nattribute table dialog, the digitizing toolbar or theLayermenu.\nOnce the layer is in edit mode, additional tool buttons on the editing toolbar will become available and markers will\nappear at the vertices of all features unlessShow markers only for selected featuresoption underSettings►Options...\n►Digitizingmenu is checked.\nTip: Save Regularly\nRemember to\nSave Layer Edits\nregularly. This will also check that your data source can accept all the changes.\nAdding Features\nDepending on the layer type, you can use the\nAdd Record\n,\nAdd Point Feature\n,\nAdd Line Feature\nor\nAdd Polygon Feature\nicons on the toolbar to add new features into the current layer.\nTo add a geometryless feature, click on the\nAdd Record\nbutton and you can enter attributes in the feature form that\nopens.\nTo create features with the spatially enabled tools, you first digitize the geometry then enter its attributes. To digitize\nthe geometry:\n1.Left-click on the map area to create the first point of your new feature. For point features, this should be enough\nand trigger, if required, the feature form to fill in their attributes.\n2.For line or polygon geometries, keep on left-clicking for each additional point you wish to capture. You can\nrely on thesnapping to featuresoptions, thesnap-to-gridor theadvanced digitizingpanel to accurately position\neach vertex.\nAlong with placing nodes clik by click, lines and polygons can be:\n•traced automatically, accelerating the digitization. This will create consecutive straight lines between the\nvertices you place.\n•free-hand digitized, pressingRor activating\nStream digitizing\nin theAdvanced Digitizing Toolbar.\n15.3. Editing539\n\nQGIS Desktop 3.22 User Guide\nNote:PressingDeleteorBackspacekey reverts the last node you add.\n3.When you have finished adding points, right-click anywhere on the map area to confirm you have finished\nentering the geometry of that feature.\nNote:While digitizing line or polygon geometries, you can switch back and forth between the linearAdd\nfeaturetools andcircular string toolsto create compound curved geometries.\nTip: Customize the digitizing rubber band\nWhile capturing polygon, the by-default red rubber band can hide underlying features or places you’d like to\ncapture a point. This can be fixed by setting a lower opacity (or alpha channel) to the rubber band’sFill Color\ninSettings►Options►Digitizingmenu. You can also avoid the use of the rubber band by checkingDon’t\nupdate rubber band during node editing.\n4.For line feature pressingShift+ right-click will close the line automatically.\n5.The attribute window will appear, allowing you to enter the information for the new feature.Fig. 15.88shows\nsetting attributes for a fictitious new river. However, in theDigitizingmenu under theSettings►Optionsmenu,\nyou can also:\n•Suppress attributes pop-up windows after each created featureto avoid the form opening;\n•orReuse last entered attribute valuesto have fields automatically filled at the opening of the form and\njust have to type changing values.\nFig. 15.88: Enter Attribute Values Dialog after digitizing a new vector feature\nVertex tool\nQGIS provides two tools to interact with vector features vertices:\n•\nVertex Tool (Current Layer)\n: only overlaid features in the active layer (in theLayerspanel) are affected\n•\nVertex Tool (All Layers)\n: any overlaid features in all editable layers are affected. This allows you to edit features\nwithout switching the active layer or edit multiple layers at once (e.g., country and their regions boundaries)\nFor any editable vector layer, the vertex tools provide manipulation capabilities of feature vertices similar to CAD\nprograms. It is possible to select multiple vertices at once and to move, add or delete them altogether. The vertex tools\nalso support the topological editing feature. They are selection persistent, so when some operation is done, selection\nstays active for this feature and tool.\nIt is important to set the propertySettings►\nOptions►Digitizing►Search Radius:to a number greater\nthan zero. Otherwise, QGIS will not be able to tell which vertex is being edited and will display a warning.\n540Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nTip: Vertex Markers\nQGIS supports different kinds of vertex markers: ‘Semi-transparent circle’, ‘Cross’ and ‘None’. To change the marker\nstyle, chooseOptionsfrom theSettingsmenu, click on theDigitizingtab and select the appropriate entry.\nBasic operations\nGiven a layer in edit mode, start by activating the vertex tool. Red circles will appear when hovering vertices.\n•Selecting vertices: You can select vertices by:\n–Clicking on them one at a time holdingShiftkey pressed\n–Click-and-dragging a rectangle surrounding the target vertices\n–Drawing a polygon surrounding the target vertices: HoldAltand click using the vertex tool to start\ndigitizing a polygon. Each subsequent click adds a new vertex to the rubberband polygon.Backspace\norDeleteremoves last added rubberband vertex.Esccancels the polygon selection mode, as also\ndoes backspacing/deleting all of the rubberband’s vertices. Right click finalizes the polygon digitizing\nand selects all vertices within the rubberband polygon.\nWhen a vertex is selected, its color changes to blue. To add more vertices to the current selection, hold down\ntheShiftkey while proceeding as above. To remove vertices from the selection, hold downCtrl.\nTip: Feature selection bounds vertex tool\nVertices can be selected accross different features (or layers). If you are looking for vertices of a specific feature\nin a crowded place, first select that feature. Then draw the rectangle or polygon selector with the vertex tool\naround the vertices: only the selected feature’s vertices are selected.\nThis is also the case if you display the feature in thevertex editorpanel.\n•Batch vertex selection mode: The batch selection mode can be activated by pressingShift+R. Select a first\nnode with one single click, and then hoverwithout clickinganother vertex. This will dynamically select all\nthe nodes in between using the shortest path (for polygons).\n15.3. Editing541\n\nQGIS Desktop 3.22 User Guide\nFig. 15.89: Batch vertex selection usingShift+R\nPressCtrlwill invert the selection, selecting the longest path along the feature boundary. Ending your node\nselection with a second click, or pressingEscwill escape the batch mode.\n•Adding vertices: To add a vertex to a line or polygon geometry, holdShiftand double-click the place on\nthe segment.\nWhen hovering a segment, a virtual new node appears on the center. Click on it, move the cursor to a new\nlocation and click again to add a new vertex. For lines, a virtual node is also proposed at both extremities: click\non it, do subsequent clicks and finish with a right-click; this allows to easily extend an existing line.\nFig. 15.90: Virtual nodes for adding vertices\n•Deletingvertices: SelecttheverticesandclicktheDeletekey. Deletingalltheverticesofafeaturegenerates,\nif compatible with the datasource, a geometryless feature. Note that this doesn’t delete the complete feature,\njust the geometry part. To delete a complete feature use the\nDelete Selected\ntool.\n•Moving vertices: Select all the vertices you want to move, click on a selected vertex or edge, and click on\n542Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nthe desired new location. You can use thesnapping to feature capabilitiesand theAdvanced Digitizing Panel\nconstraints for distance, angles, exact X and Y location before the second click. All the selected vertices will\nbe translated.\nHowever, if thesnap-to-gridoption is enabled, selected vertices are snapped to the closest grid intersection\nto their translated position. Unselected vertices are also moved to their closest grid intersection. There is no\nsimple translation.\nFig. 15.91: Moving the top vertex snaps all the vertices to the grid\nEach change made with the vertex tool is stored as a separate entry in theUndodialog. Remember that all operations\nsupport topological editing when this is turned on. On-the-fly projection is also supported.\nThe Vertex Editor Panel\nWith enabling a vertex tool, you also open theVertex Editorpanel. Right-clicking over a feature fills the panel with\nthe list of all the vertices of the feature with theirx,y(z,mif applicable) coordinates andr(for the radius, in case\nof circular geometry). The feature is also made exclusive for editing, meaning that the edit of any other features is\ndisabled: new vertices can only be added to the bound feature, selecting and moving of vertices and segments by\nclicking or dragging the map canvas is only possible for that feature. Also, select a row in the table does select the\ncorresponding vertex in the map canvas, and vice versa. Change a coordinate in the table and the vertex position is\nupdated. You can also select multiple rows and delete them altogether.\n15.3. Editing543\n\nQGIS Desktop 3.22 User Guide\nFig. 15.92: Vertex editor panel showing selected nodes\nCutting, Copying and Pasting Features\nSelected features can be cut, copied and pasted between layers in the same QGIS project, as long as destination layers\nare set to\nToggle editing\nbeforehand.\nTip: Transform polygon into line and vice-versa using copy/paste\nCopy a line feature and paste it in a polygon layer: QGIS pastes in the target layer a polygon whose boundary corre-\nsponds to the closed geometry of the line feature. This is a quick way to generate different geometries of the same\ndata.\nFeatures can also be pasted to external applications as text. That is, the features are represented in CSV format,\nwith the geometry data appearing in the OGC Well-Known Text (WKT) format. WKT and GeoJSON features from\noutside QGIS can also be pasted to a layer within QGIS.\nWhen would the copy and paste function come in handy? Well, it turns out that you can edit more than one layer at\na time and copy/paste features between layers. Why would we want to do this? Say we need to do some work on a\nnew layer but only need one or two lakes, not the 5,000 on ourbig_lakeslayer. We can create a new layer and\nuse copy/paste to plop the needed lakes into it.\nAs an example, we will copy some lakes to a new layer:\n1.Load the layer you want to copy from (source layer)\n2.Load or create the layer you want to copy to (target layer)\n3.Start editing for target layer\n4.Make the source layer active by clicking on it in the legend\n5.Use the\nSelect Features by area or single click\ntool to select the feature(s) on the source layer\n6.Click on the\nCopy Features\ntool\n7.Make the destination layer active by clicking on it in the legend\n8.Click on the\nPaste Features\ntool\n9.Stop editing and save the changes\n544Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nWhat happens if the source and target layers have different schemas (field names and types are not the same)? QGIS\npopulates what matches and ignores the rest. If you don’t care about the attributes being copied to the target layer,\nit doesn’t matter how you design the fields and data types. If you want to make sure everything - the feature and its\nattributes - gets copied, make sure the schemas match.\nNote: Congruency of Pasted Features\nIf your source and destination layers use the same projection, then the pasted features will have geometry identical to\nthe source layer. However, if the destination layer is a different projection, then QGIS cannot guarantee the geometry\nis identical. This is simply because there are small rounding-off errors involved when converting between projections.\nTip: Copy string attribute into another\nIf you have created a new column in your attribute table with type ‘string’ and want to paste values from another\nattribute column that has a greater length the length of the column size will be extended to the same amount. This is\nbecause the GDAL Shapefile driver starting with GDAL/OGR 1.10 knows to auto-extend string and integer fields to\ndynamically accommodate for the length of the data to be inserted.\nDeleting Selected Features\nIf we want to delete an entire feature (attribute and geometry), we can do that by first selecting the geometry using\nthe regular\nSelect Features by area or single click\ntool. Selection can also be done from the attribute table. Once you have\nthe selection set, pressDeleteorBackspacekey or use the\nDelete Selected\ntool to delete the features. Multiple\nselected features can be deleted at once.\nThe\nCut Features\ntool on the digitizing toolbar can also be used to delete features. This effectively deletes the feature\nbut also places it on a “spatial clipboard”. So, we cut the feature to delete. We could then use the\nPaste Features\ntool\nto put it back, giving us a one-level undo capability. Cut, copy, and paste work on the currently selected features,\nmeaning we can operate on more than one at a time.\nUndo and Redo\nThe\nUndo\nand\nRedo\ntools allows you to undo or redo vector editing operations. There is also a dockable widget,\nwhich shows all operations in the undo/redo history (see\nFig. 15.93). This widget is not displayed by default; it can be\ndisplayed by right-clicking on the toolbar and activating theUndo/Redo Panelcheckbox. The Undo/Redo capability\nis however active, even if the widget is not displayed.\nFig. 15.93: Redo and Undo digitizing steps\nWhen Undo is hit orCtrl+Z(orCmd+Z) pressed, the state of all features and attributes are reverted to the state\nbefore the reverted operation happened. Changes other than normal vector editing operations (for example, changes\n15.3. Editing545\n\nQGIS Desktop 3.22 User Guide\ndone by a plugin) may or may not be reverted, depending on how the changes were performed.\nTo use the undo/redo history widget, simply click to select an operation in the history list. All features will be reverted\nto the state they were in after the selected operation.\nSaving Edited Layers\nWhen a layer is in editing mode, any changes remain in the memory of QGIS. Therefore, they are not committed/saved\nimmediately to the data source or disk. If you want to save edits to the current layer but want to continue editing\nwithout leaving the editing mode, you can click the\nSave Layer Edits\nbutton. When you turn editing mode off with\nToggle editing\n(or quit QGIS for that matter), you are also asked if you want to save your changes or discard them.\nIf the changes cannot be saved (e.g., disk full, or the attributes have values that are out of range), the QGIS in-memory\nstate is preserved. This allows you to adjust your edits and try again.\nTip: Data Integrity\nIt is always a good idea to back up your data source before you start editing. While the authors of QGIS have made\nevery effort to preserve the integrity of your data, we offer no warranty in this regard.\nSaving multiple layers at once\nThis feature allows the digitization of multiple layers. ChooseSave for Selected Layersto save all changes you\nmade in multiple layers. You also have the opportunity toRollback for Selected Layers, so that the digitization\nmay be withdrawn for all selected layers. If you want to stop editing the selected layers,\nCancel for Selected\nLayer(s)is an easy way.\nThe same functions are available for editing all layers of the project.\nTip: Use transaction group to edit, save or rollback multiple layers changes at once\nWhen working with layers from the same PostGreSQL database, activate theAutomatically create transaction groups\nwhere possibleoption inProject►Properties...►Data Sourcesto sync their behavior (enter or exit the edit mode,\nsave or rollback changes at the same time).\n15.3.5Advanced digitizing\n546Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nIconPurposeIconPurpose\nEnable Advanced Digitizing Tools\nDigitize with CurveEnable Stream Digitizing\nMove Feature(s)Copy and Move Feature(s)\nRotate Feature(s)Simplify Feature\nScale Feature\nAdd RingAdd Part\nFill RingSwap direction\nDelete RingDelete Part\nOffset CurveReshape Features\nSplit PartsSplit Features\nMerge Attributes of Selected FeaturesMerge Selected Features\nRotate Point SymbolsOffset Point Symbols\nTrim or Extend Feature\nTable Advanced Editing: Vector layer advanced editing toolbar\nStraight, curve and stream digitizing\nThe\nDigitize with Curve\ntool allows you to draw curves in layers with geometries that support curves. Digitizing a\ncurve requires to provide three points along the curve (start, point along the arc, end) which define it.\nThe\nStream Digitizing\ntool allows you to activate and deactivate stream digitizing which allows to create features in\nfreehand mode.\nThe streaming tolerance affects the spacing between consecutive vertices. Currently, the only supported unit is pixels\n(px).\nMove Feature(s)\nThe\nMove Feature(s)\ntool allows you to move existing features:\n1.Select the feature(s) to move.\n2.Click on the map canvas to indicate the origin point of the displacement; you can rely on snapping capabilities\nto select an accurate point.\nYou can also take advantages of theadvanced digitizing constraintsto accurately set the origin point coordinates.\nIn that case:\n1.First click on thebutton to enable the panel.\n2.Typexand enter the corresponding value for the origin point you’d like to use. Then press thebutton\nnext to the option to lock the value.\n3.Do the same for theycoordinate.\n4.Click on the map canvas and your origin point is placed at the indicated coordinates.\n15.3. Editing547\n\nQGIS Desktop 3.22 User Guide\n3.Move over the map canvas to indicate the destination point of the displacement, still using snapping mode\nor, as above, use the advanced digitizing panel which would provide complementarydistanceandangle\nplacement constraints to place the end point of the translation.\n4.Click on the map canvas: the whole features are moved to new location.\nLikewise, you can create a translated copy of the feature(s) using the\nCopy and Move Feature(s)\ntool.\nNote:If no feature is selected when you first click on the map canvas with any of theMove Feature(s)orCopy and\nMove Feature(s)tools, then only the feature under the mouse is affected by the action. So, if you want to move several\nfeatures, they should be selected first.\nRotate Feature(s)\nUse the\nRotate Feature(s)\ntool to rotate one or multiple features in the map canvas:\n1.Press the\nRotate Feature(s)\nicon\n2.Then click on the feature to rotate. The feature’s centroid is referenced as rotation center, a preview of the\nrotated feature is displayed and a widget opens showing the currentRotationangle.\n3.Click on the map canvas when you are satisfied with the new placement or manually enter the rotation angle in\nthe text box. You can also use theSnap to °box to constrain the rotation values.\n4.If you want to rotate several features at once, they shall be selected first, and the rotation is by default around\nthe centroid of their combined geometries.\nYou can also use an anchor point different from the default feature centroid: press theCtrlbutton, click on the map\ncanvas and that point will be used as the new rotation center.\nIf you holdShiftbefore clicking on the map, the rotation will be done in 45 degree steps, which can be modified\nafterwards in the user input widget.\nTo abort feature rotation, press theESCbutton or click on the\nRotate Feature(s)\nicon.\nScale Feature\nThe\nScale Feature\ntool is similar to the Rotate feature. Though instead of performing a rotation of selected features,\nit rescales their geometry. The change is performed in relation to the anchor point and the scale ratio can be manually\nspecified in the widget that appears in the upper corner of the canvas.\nSimplify Feature\nThe\nSimplify Feature\ntool allows you to interactively reshape a line or polygon geometry by reducing or densifying\nthe number of vertices, as long as the geometry remains valid:\n1.Select the\nSimplify Feature\ntool.\n2.Click on the feature or drag a rectangle over the features.\n3.A dialog pops up allowing you to define theMethodto apply, ie whether you would like to:\n•simplify the geometry, meaning less vertices than the original. Available methods areSimplify by\ndistance,Simplify by snapping to gridorsimplify by area (Visvalingam).\nYou’d then need to indicate the value ofToleranceinLayer units,Pixelsormap unitsto use\nfor simplification. The higher the tolerance is the more vertices can be deleted.\n548Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n•ordensify the geometrieswith new vertices thanks to theSmoothoption: for each existing vertex, two\nvertices are placed on each of the segments originated from it, at anOffsetdistance representing the\npercentage of the segment length. You can also set the number ofIterationsthe placement would be\nprocessed: the more iterations, the more vertices and smoother is the feature.\nSettings that you used will be saved when leaving a project or an edit session. So you can go back to the same\nparameters the next time you simplify a feature.\n4.A summary of the modifications that would apply is shown at the bottom of the dialog, listing number of\nfeatures and number of vertices (before and after the operation and the ratio the change represents). Also, in\nthe map canvas, the expected geometry is displayed over the existing one, using the rubberband color.\n5.When the expected geometry fits your needs, clickOKto apply the modification. Otherwise, to abort the\noperation, you can either pressCancelor right-click in the map canvas.\nNote:Unlike the feature simplification option inSettings►Options►Renderingmenu which simplifies the geometry\njust for rendering, the\nSimplify Feature\ntool permanently modifies feature’s geometry in data source.\nAdd Part\nYou can\nAdd Part\nto a selected feature generating a multipoint, multiline or multipolygon feature. The new part\nmust be digitized outside the existing one which should be selected beforehand.\nThe\nAdd Part\ncan also be used to add a geometry to a geometryless feature. First, select the feature in the attribute\ntable and digitize the new geometry with the\nAdd Part\ntool.\nDelete Part\nThe\nDelete Part\ntool allows you to delete parts from multifeatures (e.g., to delete polygons from a multi-polygon\nfeature). This tool works with all multi-part geometries: point, line and polygon. Furthermore, it can be used to\ntotally remove the geometric component of a feature. To delete a part, simply click within the target part.\nAdd Ring\nYou can create ring polygons using the\nAdd Ring\nicon in the toolbar. This means that inside an existing area, it is\npossible to digitize further polygons that will occur as a ‘hole’, so only the area between the boundaries of the outer\nand inner polygons remains as a ring polygon.\nFill Ring\nThe\nFill Ring\ntool helps you create polygon feature that totally falls within another one without any overlapping\narea; that is the new feature covers a hole within the existing one. To create such a feature:\n1.Select the\nFill Ring\ntool.\n2.Draw a new polygon over the existing feature: QGIS adds a ring to its geometry (like if you used the\nAdd Ring\ntool) and creates a new feature whose geometry matches the ring (like if youtracedover the interior\nboundaries with the\nAdd polygon feature\ntool).\n15.3. Editing549\n\nQGIS Desktop 3.22 User Guide\n3.Or alternatively, if the ring already exists on the feature, place the mouse over the ring and left-click while\npressingShift: a new feature filling the hole is drawn at that place.\nTheFeature Attributesform of the new feature opens, pre-filled with values of the “parent” feature and/orfields\nconstraints.\nDelete Ring\nThe\nDelete Ring\ntool allows you to delete rings within an existing polygon, by clicking inside the hole. This tool\nonly works with polygon and multi-polygon features. It doesn’t change anything when it is used on the outer ring of\nthe polygon.\nReshape Features\nYou can reshape line and polygon features using the\nReshape Features\ntool on the toolbar. For lines, it replaces the\nline part from the first to the last intersection with the original line.\nFig. 15.94: Reshape line\nTip: Extend linestring geometries with reshape tool\nUse the\nReshape Features\ntool to extend existing linestring geometries: snap to the first or last vertex of the line and\ndraw a new one. Validate and the feature’s geometry becomes the combination of the two lines.\nFor polygons, it will reshape the polygon’s boundary. For it to work, the reshape tool’s line must cross the polygon’s\nboundary at least twice. To draw the line, click on the map canvas to add vertexes. To finish it, just right-click. Like\nwith the lines, only the segment between the first and the last intersections is considered. The reshape line’s segments\nthat are inside the polygon will result in cropping it, where the ones outside the polygon will extend it.\n550Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.95: Reshape polygon\nWith polygons, reshaping can sometimes lead to unintended results. It is mainly useful to replace smaller parts of\na polygon, not for major overhauls, and the reshape line is not allowed to cross several polygon rings, as this would\ngenerate an invalid polygon.\nNote:The reshape tool may alter the starting position of a polygon ring or a closed line. So, the point that is\nrepresented ‘twice’ will not be the same any more. This may not be a problem for most applications, but it is something\nto consider.\nOffset Curves\nThe\nOffset Curve\ntool creates parallel shifts of line layers. The tool can be applied to the edited layer (the geometries\nare modified) or also to background layers (in which case it creates copies of the lines / rings and adds them to the\nedited layer). It is thus ideally suited for the creation of distance line layers. TheUser Inputdialog pops-up, showing\nthe displacement distance.\nTo create a shift of a line layer, you must first go into editing mode and activate the\nOffset Curve\ntool. Then click\non a feature to shift it. Move the mouse and click where wanted or enter the desired distance in the user input\nwidget. HoldingCtrlduring the 2nd click will make an offset copy. Your changes may then be saved with the\nSave Layer Edits\ntool.\nQGIS options dialog (Digitizing tab thenCurve offset toolssection) allows you to configure some parameters like\nJoin style,Quadrant segments,Miter limit.\nReverse Line\nChanging the direction of a line geometry can be useful for cartographical purposes or when preparing for network\nanalysis.\nTo change a line direction:\n1.Activate the reverse line tool by clicking\nReverse line\n.\n2.Click on the line. The direction of the line is reversed.\n15.3. Editing551\n\nQGIS Desktop 3.22 User Guide\nSplit Features\nUse the\nSplit Features\ntool to split a feature into two or more new and independent features, ie. each geometry\ncorresponding to a new row in the attribute table.\nTo split line or polygon features:\n1.Select the\nSplit Features\ntool.\n2.Draw a line across the feature(s) you want to split. If a selection is active, only selected features are split. When\nset,default values or clausesare applied to corresponding fields and other attributes of the parent feature are\nby default copied to the new features.\n3.You can then as usually modify any of the attributes of any resulting feature.\nTip: Split a polyline into new features in one-click\nUsing the\nSplit Features\ntool, snap and click on an existing vertex of a polyline feature to split that feature into two\nnew features.\nSplit parts\nIn QGIS it is possible to split the parts of a multi part feature so that the number of parts is increased. Just draw a\nline across the part you want to split using the\nSplit Parts\nicon.\nTip: Split a polyline into new parts in one-click\nUsing the\nSplit Parts\ntool, snap and click on an existing vertex of a polyline feature to split the feature into two new\npolylines belonging to the same feature.\nMerge selected features\nThe\nMerge Selected Features\ntool allows you to create a new feature by merging existing ones: their geometries are\nmerged to generate a new one. If features don’t have common boundaries, a multipolygon/multipolyline/multipoint\nfeature is created.\n1.First, select the features you’d like to combine.\n2.Then press the\nMerge Selected Features\nbutton.\n3.In the new dialog, theMergeline at the bottom of the table shows the attributes of the resulting feature. You\ncan alter any of these values either by:\n•manually replacing the value in the corresponding cell;\n•selecting a row in the table and pressingTake attributes from selected featureto use the values of this\ninitial feature;\n•pressing theTake attributes from the largest geometryto use the attributes from the longest line feature,\nthe largest polygon, or the multipoints with the most parts;\n•pressingSkip all fieldsto use empty attributes;\n•expanding the drop down menu at the top of the table, select any of the above options to apply to the\ncorresponding field only. There, you can also choose to aggregate the initial features attributes (Minimum,\n552Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nMaximum, Median, Sum, Count, Concatenation... depending on the type of the field. seeStatistical\nSummary Panelfor the full list of functions).\nNote:If the layer has default values or clauses present on fields, these are used as the initial value for the\nmerged feature.\n4.PressOKto apply the modifications. A single (multi)feature is created in the layer, replacing the previously\nselected ones.\nMerge attributes of selected features\nThe\nMerge Attributes of Selected Features\ntool allows you to apply same attributes to features without merging their bound-\naries. The dialog is the same as theMerge Selected Featurestool’s except that unlike that tool, selected\nobjects are kept with their geometry while some of their attributes are made identical.\nRotate Point Symbols\nThe\nRotate Point Symbols\nallows you to individually change the rotation of point symbols in the map canvas.\n1.First, you need to indicate the field to store the rotation value in. This is made by assigning a field to the symbol\ndata-definedrotation property:\n1.In theLayer Properties►Symbologydialog, browse to the symbol editor dialog.\n2.Click theData-defined overridewidget near theRotationoption of the topMarkerlevel (preferably)\nof the symbol layers.\n3.Choose a field in theField Typecombobox. Values of this field are hence used to rotate each feature’s\nsymbol accordingly.\nYou can also check the\nStore data in project\nentry to generate an\nauxiliary data storagefield to control the\nrotation value.\nNote: Make sure that the same field is assigned to all the symbol layers\nSetting the data-defined rotation field at the topmost level of the symbol tree automatically propagates it to\nall the symbol layers, a prerequisite to perform graphical symbol rotation with theRotate Point Symbolstool.\nIndeed, if a symbol layer does not have the same field attached to its rotation property, the tool will not work.\nFig. 15.96: Rotating a point symbol\n2.Then click on a point symbol in the map canvas with the\nRotate Point Symbols\ntool\n15.3. Editing553\n\nQGIS Desktop 3.22 User Guide\n3.Move the mouse around. A red arrow with the rotation value will be visualized (seeFig. 15.96). If you hold\ntheCtrlkey while moving, the rotation will be done in 15 degree steps.\n4.When you get the expected angle value, click again. The symbol is rendered with this new rotation and the\nassociated field is updated accordingly.\nYou can right-click to abort symbol rotation.\nOffset Point Symbols\nThe\nOffset Point Symbols\nallows you to interactively change the rendered position of point symbols in the map canvas.\nThis tool behaves like the\nRotate Point Symbols\ntool except that it requires you to connect a field to the data-defined\nOffset (X,Y)property of each layer of the symbol. The field will then be populated with the offset coordinates for the\nfeatures whose symbol is moved in the map canvas.\n1.Associate a field to the data-defined widget of theOffset (X,Y)property of the symbol. If the symbol is made\nwith many layers, you may want to assign the field to each of them\n2.Select the\nOffset Point Symbols\ntool\n3.Click a point symbol\n4.Move to a new location\n5.Click again. The symbol is moved to the new place. Offset values from the original position are stored in the\nlinked field.\nYou can right-click to abort symbol offset.\nNote:The\nOffset Point Symbols\ntool doesn’t move the point feature itself; you should use the\nVertex Tool (Current Layer)\nor\nMove Feature\ntool for this purpose.\nTrim/Extend Feature\nThe\nTrim/Extend\ntool allows you to shorten or lengthen segments of a (multi)line or (multi)polygon geometry to\nconverge with a selected segment (the cutting line). This results in a modified geometry with a vertex snapped to the\ntarget segment or in its prolongation. Depending on how the selected geometries are placed in relation to each other,\nthe tool will either:\n•Trim: removes parts of the line segment or polygon boundary, beyond the cutting line\n•Extend: extends polygon boundaries or line segments so that they can snap to the cutting line.\nIn order to trim or extend existing geometries:\n1.Enable appropriatesnapping settingson segment for the involved layer(s)\n2.Select the\nTrim/Extend\ntool\n3.Click the target limit segment, i.e. the segment with respect to which you want to extend or trim another\nsegment. It appears highlighted.\n4.Move to the segment you want to trim or extend. It does not need to be the last segment of the geometry, but\nhas to be on the active layer.\n5.Hover over the segment, and QGIS displays a preview of what the feature’s geometry would be. If OK, click\nthe segment. In the case of a trim, you must select the part that should be shortened.\n6.When both segments are in 3D, the tool performs an interpolation on the limit segment to get the Z value.\n554Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nAttention:Pay attention to the modified geometry while using the\nTrim/Extend\ntool. Depending on the inputs,\nit can create invalid geometries, potentially resulting in failure at layer saving.\n15.3.6Shape digitizing\nTheShape Digitizingtoolbar offers a set of tools to draw regular shapes and curved geometries.\nAdd Circular string\nThe\nAdd circular string\nor\nAdd circular string by radius\nbuttons allow users to add line or polygon features with a circular\ngeometry.\nCreating features with these tools follow the same rule as of other digitizing tools: left-click to place vertices and\nright-click to finish the geometry. While drawing the geometry, you can switch from one tool to the other as well as\nto thelinear geometry tools, creating some coumpound geometries.\nNote: Curved geometries are stored as such only in compatible data provider\nAlthough QGIS allows to digitize curved geometries within any editable data format, you need to be using a data\nprovider (e.g. PostGIS, memory layer, GML or WFS) that supports curves to have features stored as curved, otherwise\nQGIS segmentizes the circular arcs.\nDraw Circles\nThere is a set of tools for drawing circles. The tools are described below.\nCircles are converted into circular strings. Therefore, as explained inAdd Circular string, if allowed by the data\nprovider, it will be saved as a curved geometry, if not, QGIS will segmentize the circular arcs.\n•\nAdd circle from 2 points\n: The two points define the diameter and the orientation of the circle. (Left-click, right-\nclick)\n•\nAdd circle from 3 points\n: Draws a circle from three known points on the circle. (Left-click, left-click, right-click)\n•\nAdd circle from center and a point\n: Draws a circle with a given center and a point on the circle (Left-click, right-\nclick). When used with theThe Advanced Digitizing panelthis tool can become a “Add circle from center and\nradius” tool by setting and locking the distance value after first click.\n•\nAdd circle from 3 tangents\n: Draws a circle that is tangential to three segments.Note that you must activate\nsnapping to segments(SeeSetting the snapping tolerance and search radius). Click on a segment to add\na tangent. If two tangents are parallel, the coordinates of the click on the first parallel tangent are used to\ndetermine the positioning of the circle. If three tangents are parallel, an error message appears and the input\nis cleared. (Left-click, left-click, right-click)\n•\nAdd circle from 2 tangents and a point\n: Similar to circle from 3 tangents, except that you have to select two tangents,\nenter a radius and select the desired center.\n15.3. Editing555\n\nQGIS Desktop 3.22 User Guide\nDraw Ellipses\nThere is a set of tools for drawing ellipses. The tools are described below.\nEllipses cannot be converted as circular strings, so they will always be segmented.\n•\nAdd Ellipse from center and two points\n: Draws an ellipse with a given center, major axis and minor axis. (Left-click,\nleft-click, right-click)\n•\nAdd Ellipse from center and a point\n: Draws an ellipse into a bounding box with the center and a corner. (Left-click,\nright-click)\n•\nAdd Ellipse from extent\n: Draws an ellipse into a bounding box with two opposite corners. (Left-click, right-click)\n•\nAdd Ellipse from foci\n: Draws an ellipse by 2 points for foci and a point on the ellipse. (Left-click, left-click,\nright-click)\nDraw Rectangles\nThere is a set of tools for drawing rectangles. The tools are described below.\n•\nRectangle from center and a point\n: Draws a rectangle from the center and a corner. (Left-click, right-click)\n•\nRectangle from extent\n: Draws a rectangle from two opposite corners. (Left-click, right-click)\n•\nRectangle from 3 points (distance)\n: Draws an oriented rectangle from three points. The first and second points\ndetermine the length and angle of the first edge. The third point determines the length of the other edge. One\ncan useThe Advanced Digitizing panelto set the length of the edges. (Left-click, left-click, right-click)\n•\nRectangle from 3 points (projected)\n: Same as the preceding tool, but the length of the second edge is computed from\nthe projection of the third point on the first edge. (Left-click, left-click, right-click)\nFig. 15.97: Draw rectangle from 3 points using distance (right) and projected (left)\n556Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nDraw Regular Polygons\nThere is a set of tools for drawing regular polygons. The tools are described below. Left-click to place the first point.\nA dialog appears, where you can set the number of polygon edges. Right-click to finish the regular polygon.\n•\nRegular polygon from two points\n: Draws a regular polygon where the two points determine the length and angle of\nthe first edge.\n•\nRegular polygon from center and a point\n: Draws a regular polygon from the provided center point. The second point\ndetermines the angle and distance to the middle of an edge.\n•\nRegular polygon from center and a corner\n: Same as the preceding tool, but the second point determines the angle and\ndistante to a vertex.\n15.3.7The Advanced Digitizing panel\nWhen capturing, reshaping, splitting new or existing geometries you also have the possibility to use the Advanced\nDigitizing panel. You can digitize lines exactly parallel or perpendicular to a particular angle or lock lines to spe-\ncific angles. Furthermore, you can enter coordinates directly so that you can make a precise definition of your new\ngeometry.\nFig. 15.98: The Advanced Digitizing panel\nTheAdvanced Digitizingpanel can be open either with a right-click on the toolbar, fromView►Panels► menu or\npressingCtrl+4. Once the panel is visible, click the\nEnable advanced digitizing tools\nbutton to activate the set of tools.\nNote:The tools are not enabled if the map view is in geographic coordinates.\nThe aim of the Advanced Digitizing tool is to lock coordinates, lengths, and angles when moving the mouse during\nthe digitalizing in the map canvas.\nYou can also create constraints with relative or absolute reference. Relative reference means that the next vertex\nconstraints’ values will be relative to the previous vertex or segment.\n15.3. Editing557\n\nQGIS Desktop 3.22 User Guide\nThe toolbar\nAt the top of theDigitizing panel, you find the following buttons:\n•\nEnable advanced digitizing tools\n•\nConstruction mode\n: allows to capture the clicks’ positions to reuse as reference points to lock distance, angle,\nX, Y, Z or M relative values. More details atConstruction mode.\n•\nParallel\nto draw a line parallel to an existing one (more atParallel and perpendicular lines)\n•\nPerpendicular\nto draw a line perpendicular to an existing one (more atParallel and perpendicular lines)\n•\nSnap to common angles\n: when moving the cursor, displays a virtual line that you can snap to to add the next\nvertex. The snapping line is defined by the last added vertex and an (absolute or relative to previous segment)\nangle from a preset list (following steps of 5°, 10°, 15°, 18°, 22.5°, 30°, 45° or 90°). ChooseDo not snap to\ncommon anglesto disable this feature.\n•\nFloater\n: displays a live preview of the coordinates right next to the cursor. The values can be accessed and\nedited using thepanel’s shortcuts.\nKeyboard shortcuts\nTo speed up the use of Advanced Digitizing Panel, there are a couple of keyboard shortcuts available:\nKeySimpleCtrl+orAlt+Shift+\nDSet distanceLock distance\nASet angleLock angleToggle relative angle to last segment\nXSet X coordinateLock X coordinateToggle relative X to last vertex\nYSet Y coordinateLock Y coordinateToggle relative Y to last vertex\nZSet Z coordinateLock Z coordinateToggle relative Z to last vertex\nMSet M valueLock M valueToggle relative M to last vertex\nCToggle construction mode\nPToggle perpendicular and parallel modes\nNote:Z coordinate and M value options are available only if compatible with the layer geometry dimension.\nAbsolute reference digitizing\nWhen drawing a new geometry from scratch, it is very useful to have the possibility to start digitizing vertexes at\ngiven coordinates.\nFor example, to add a new feature to a polygonal layer, click the\nbutton. You can enter the exact coordinates\nwhere you want to start editing the feature, i.e.:\n1.Click thextext box (or use theXkeyboard shortcut).\n2.Type the X coordinate value you want and pressEnteror click thebutton to their right to lock the mouse\nto the X axis on the map canvas.\n3.Click theytext box (or use theYkeyboard shortcut).\n4.Type the Y coordinate value you want and pressEnteror click thebutton to their right to lock the mouse\nto the Y axis on the map canvas.\n558Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n5.If available and relevant, proceed as above to add the Z coordinate and M value (respectivelyzormtext box).\nTwo blue dotted lines and a green cross identify the exact coordinates you entered.\n6.Start digitizing by clicking on the map canvas; a vertex is added at the green cross position.\nFig. 15.99: Start drawing at given coordinates\n7.You can continue digitizing by free hand, adding a new set of coordinates, or you can type the segment’slength\n(distance) andangle.\n8.If you want to draw a segment of a given length:\n1.Click thed (distance)text box (keyboard shortcutD)\n2.Type the distance value (in map units)\n3.PressEnteror click thebutton on the right to lock the mouse in the map canvas to the length of the\nsegment. In the map canvas, the latest vertex is surrounded by a circle whose radius is the value entered\nin the distance text box. A cross on the circle shows the position of the next vertex if you click.\nFig. 15.100: Fixed length segment\n9.You can also constrain the vertex position, setting the angle of the segment. As described before:\n1.Click thea (angle)text box (keyboard shortcutA)\n2.Type the angle value (in degrees)\n15.3. Editing559\n\nQGIS Desktop 3.22 User Guide\n3.PressEnteror click thebutton on the right to lock it. A line going through the latest vertex and\nrotated based on the set angle appears in the map canvas and a cross on it shows the next vertex position\nif you click.\nFig. 15.101: Fixed angle segment\nHint:PressingCtrl+<key>orAlt+<key>automatically locks the target property and puts its value into edit.\nModify, pressEnterand you are done. Combined with the\nToggle floater\n, this can be a real time saver, with\nkeyboard digitizing.\nRelative reference digitizing\nInstead of using absolute values of angles or coordinates, you can also use values relative to the last digitized vertex\nor segment.\nFor angles, you can click the\nbutton on the left of theatext box (or pressShift+A) to toggle relative angles to\nthe previous segment. With that option on, angles are measured between the last segment and the mouse pointer.\nFor coordinates, click the\nbuttons to the left of thex,y,zormtext boxes (or pressShift+<key>) to toggle\nrelative coordinates to the previous vertex. With these options on, coordinates measurement will consider the last\nvertex to be the origin of the set coordinates.\nContinuous lock\nBoth in absolute or relative reference digitizing, angle, distance, X, Y, Z and M constraints can be locked continuously\nby clicking theContinuous lockbuttons. Using continuous lock allows you to digitize several points or vertexes\nusing the same constraints.\n560Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nParallel and perpendicular lines\nAll the tools described above can be combined with the\nPerpendicular\nand\nParallel\ntools. These two tools allow\ndrawing segments perfectly perpendicular or parallel to another segment. The target segment can be on another layer,\nanother feature within the layer or the feature being digitized (requiresself-snapping option).\nTo draw aperpendicularsegment:\n1.First add one of the segment vertices.\n2.Click the\nPerpendicular\nicon (keyboard shortcutP) to activate it.\n3.Click on the segment that you want to be perpendicular to.\n4.A virtual dotted line perpendicular to the segment through the previous vertex appears. The angle property is\nlocked, constraining the next vertex on that line and, a cross indicates the projected position of the cursor on\nthe line. Click to place the new vertex.\nFig. 15.102: Perpendicular digitizing\nTo draw aparallelsegment, the steps are the same except that you need to click on the\nParallel\nicon (keyboard\nshortcutPtwice).\nFig. 15.103: Parallel digitizing\n15.3. Editing561\n\nQGIS Desktop 3.22 User Guide\nThese two tools just find the right angle of the perpendicular and parallel angle and lock this parameter during your\nediting. Unlock the angle parameter to cancel their use in the middle of the process.\nConstruction mode\nYou can enable and disableconstruction modeby clicking on the\nConstruction mode\nicon or with theCkeyboard\nshortcut. While in construction mode, clicking the map canvas won’t add new vertexes, but will capture the clicks’\npositions so that you can use them as reference points to then lock distance, angle or X, Y, Z, M relative values.\nAs an example, the construction mode can be used to draw some point at an exact distance from an existing point.\nWith an existing point in the map canvas and the snapping mode correctly activated, you can easily draw other points\nat given distances and angles from it. In addition to thebutton, you have to activate also theconstruction mode\nby clicking the\nConstruction mode\nicon or with theCkeyboard shortcut.\nClick next to the point from which you want to calculate the distance and click on thedbox (Dshortcut) type the\ndesired distance and pressEnterto lock the mouse position in the map canvas:\nFig. 15.104: Distance from point\nBefore adding the new point, pressCto exit the construction mode. Now, you can click on the map canvas, and the\npoint will be placed at the distance entered.\nYou can also use the angle constraint to, for example, create another point at the same distance of the original one,\nbut at a particular angle from the newly added point. Click the\nConstruction mode\nicon or with theCkeyboard shortcut\nto enter construction mode. Click the recently added point, and then the other one to set a direction segment. Then,\nclick on thedtext box (Dshortcut) type the desired distance and pressEnter. Click theatext box (Ashortcut) type\nthe angle you want and pressEnter. The mouse position will be locked both in distance and angle.\n562Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\nFig. 15.105: Distance and angle from points\nBefore adding the new point, pressCto exit the construction mode. Now, you can click on the map canvas, and the\npoint will be placed at the distance and angle entered. Repeating the process, several points can be added.\nFig. 15.106: Points at given distance and angle\n15.3.8The Processing in-place layer modifier\nTheProcessing menuprovides access to a large set of tools to analyze and create new features based on the properties\nof the input features or their relations with other features (within the same layer or not). While the common behavior\nis to create new layers as outputs, some algorithms also allow modifications to the input layer. This is a handy way to\nautomate multiple features modification using advanced and complex operations.\nTo edit features in-place:\n1.Select the layer to edit in theLayerspanel.\n2.Select the concerned features. You can skip this step, in which case the modification will apply to the whole\nlayer.\n15.3. Editing563\n\nQGIS Desktop 3.22 User Guide\n3.Press the\nEdit Features In-Place\nbutton at the top of theProcessing toolbox. The list of algorithms is filtered,\nshowing only those compatible with in-place modifications, i.e.:\n•They work at the feature source and not at the layer level.\n•They do not change the layer structure, e.g. adding or removing fields.\n•They do not change the geometry type, e.g. from line to point layer.\nFig. 15.107: Processing algorithms: all (left) vs polygon in-place editors (right)\n4.Find the algorithm you’d like to run and double-click it.\nNote:If the algorithm does not need any additional user-set parameters (excluding the usual input and output\nlayer parameters), then the algorithm is run immediately without any dialog popup.\n1.If parameters other than the usual input or output layers are needed, the algorithm dialog pops up. Fill\nin the required information.\n2.ClickModify Selected FeaturesorModify All Featuresdepending on whether there’s an active selection.\nChanges are applied to the layer and placed in the edit buffer: the layer is indeed toggled to editing mode with\nunsaved modification as indicated by the\nicon next to the layer name.\n564Chapter 15. Working with Vector Data\n\nQGIS Desktop 3.22 User Guide\n5.As usual, press\nSave layer edits\nto commit the changes in the layer. You can also press\nUndo\nto rollback the\nwhole modification.\n15.3. Editing565\n\nQGIS Desktop 3.22 User Guide\n566Chapter 15. Working with Vector Data\n\nCHAPTER\nSIXTEEN\nWORKING WITH RASTER DATA\n16.1Raster Properties Dialog\nTo view and set the properties for a raster layer, double click on the layer name in the map legend, or right click on\nthe layer name and choosePropertiesfrom the context menu. This will open theRaster Layer Propertiesdialog.\nThere are several tabs in the dialog:\nInformationSourceSymbology\n[1]\nTransparency\n[1]\nHistogram\n[1]\nRendering\nTemporalPyramidsMetadata\nLegendQGIS ServerExternal plugins\n[2]\ntabs\n[1]\nAlso available in the\nLayer styling panel\n[2]\nExternal pluginsyou install can optionally add tabs to this dialog. Those are not presented in this document. Refer\nto their documentation.\nTip: Live update rendering\nTheLayer Styling Panelprovides you with some of the common features of the Layer properties dialog and is a good\nmodeless widget that you can use to speed up the configuration of the layer styles and view your changes on the map\ncanvas.\nNote:Because properties (symbology, label, actions, default values, forms...) of embedded layers (seeEmbedding\nlayers from external projects) are pulled from the original project file, and to avoid changes that may break this\nbehavior, the layer properties dialog is made unavailable for these layers.\n16.1.1Information Properties\nTheInformationtab is read-only and represents an interesting place to quickly grab summarized information and\nmetadata for the current layer. Provided information are:\n•general such as name in the project, source path, list of auxiliary files, last save time and size, the used provider\n•based on the provider of the layer: extent, width and height, data type, GDAL driver, bands statistics\n•the Coordinate Reference System: name, units, method, accuracy, reference (i.e. whether it’s static or dynamic)\n•read from layer properties: data type, extent, width/height, compression, pixel size, statistics on bands, number\nof columns, rows and no-data values of the raster...\n567\n\nQGIS Desktop 3.22 User Guide\n•picked from thefilled metadata: access, extents, links, contacts, history...\n16.1.2Source Properties\nTheSourcetab displays basic information about the selected raster, including:\n•theLayer nameto display in theLayers Panel;\n•theCoordinate Reference System: Displays the layer’sCoordinate Reference System (CRS). You can change the\nlayer’s CRS, by selecting a recently used one in the drop-down list or clicking on the\nSelect CRS\nbutton (see\nCoordinate Reference System Selector). Use this process only if the layer CRS is a wrong or not specified. If\nyou wish to reproject your data, use a reprojection algorithm from Processing orSave it as new dataset.\nFig. 16.1: Raster Layer Properties - Source Dialog\n16.1.3Symbology Properties\nThe raster layer symbology tab is made of three different sections:\n•TheBand renderingwhere you can control the renderer type to use\n•The\nLayer rendering\nto apply effects on rendered data\n•TheResamplingmethods to optimize rendering on map\n568Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nBand rendering\nQGIS offers many differentRender types. The choice of renderer depends on the data type and the information you’d\nlike to highlight.\n1.Multiband color- if the file comes with several bands (e.g. a satellite image with several bands).\n2.Paletted/Unique values- for single band files that come with an indexed palette (e.g. a digital topographic map)\nor for general use of palettes for rendering raster layers.\n3.Singleband gray- (one band of) the image will be rendered as gray. QGIS will choose this renderer if the file\nis neither multiband nor paletted (e.g. a shaded relief map).\n4.Singleband pseudocolor- this renderer can be used for files with a continuous palette or color map (e.g. an\nelevation map).\n5.Hillshade- Creates hillshade from a band.\n6.Contours- Generates contours on the fly for a source raster band.\nMultiband color\nWith the multiband color renderer, three selected bands from the image will be used as the red, green or blue com-\nponent of the color image. QGIS automatically fetchesMinandMaxvalues for each band of the raster and scales\nthe coloring accordingly. You can control the value ranges in the\nMin/Max Value Settingssection.\nAContrast enhancementmethod can be applied to the values: ‘No enhancement’, ‘Stretch to MinMax’, ‘Stretch and\nclip to MinMax’ and ‘Clip to min max’.\nNote: Contrast enhancement\nWhen adding GRASS rasters, the optionContrast enhancementwill always be set automatically tostretch to min max,\neven if this is set to another value in the QGIS general options.\nFig. 16.2: Raster Symbology - Multiband color rendering\nTip: Viewing a Single Band of a Multiband Raster\nIf you want to view a single band of a multiband image (for example, Red), you might think you would set the Green\nand Blue bands toNot Set. But the preferred way of doing this is to set the image type toSingleband gray, and then\nselect Red as theGray bandto use.\n16.1. Raster Properties Dialog569\n\nQGIS Desktop 3.22 User Guide\nPaletted/Unique values\nThis is the standard render option for singleband files that include a color table, where a certain color is assigned to\neach pixel value. In that case, the palette is rendered automatically.\nIt can be used for all kinds of raster bands, assigning a color to each unique raster value.\nIf you want to change a color, just double-click on the color and theSelect colordialog appears.\nIt is also possible to assign labels to the colors. The label will then appear in the legend of the raster layer.\nRight-clicking over selected rows in the color table shows a contextual menu to:\n•Change Color...for the selection\n•Change Opacity...for the selection\n•Change Label...for the selection\nFig. 16.3: Raster Symbology - Paletted unique value rendering\nThe pulldown menu, that opens when clicking the...(\nAdvanced options\n) button below the color map to the right, offers\ncolor map loading (Load Color Map from File...) and exporting (Export Color Map to File...), and loading of classes\n(Load Classes from Layer).\n570Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nSingleband gray\nThis renderer allows you to render a layer using only one band with aColor gradient: ‘Black to white’ or ‘White to\nblack’. You can change the range of values to color (MinandMax) in theMin/Max Value Settings.\nAContrast enhancementmethod can be applied to the values: ‘No enhancement’, ‘Stretch to MinMax’, ‘Stretch and\nclip to MinMax’ and ‘Clip to min max’.\nFig. 16.4: Raster Symbology - Singleband gray rendering\nPixels are assigned a color based on the selected color gradient and the layer’s legend (in theLayerspanel and the\nlayoutlegend item) is displayed using a continuous color ramp. PressLegend settings...if you wish to tweak the\nsettings. More details at\nCustomize raster legend.\nSingleband pseudocolor\nThis is a render option for single-band files that include a continuous palette. You can also create color maps for a\nband of a multiband raster.\n16.1. Raster Properties Dialog571\n\nQGIS Desktop 3.22 User Guide\nFig. 16.5: Raster Symbology - Singleband pseudocolor rendering\nUsing aBandof the layer and avalues range, you can now interpolate and assign representation color to pixels within\nclasses. More atColor ramp shader classification.\nPixels are assigned a color based on the selected color ramp and the layer’s legend (in theLayerspanel and the layout\nlegend item) is displayed using a continuous color ramp. PressLegend settings...if you wish to tweak the settings or\ninstead use a legend with separated classes (and colors). More details atCustomize raster legend.\nHillshade\nRender a band of the raster layer using hillshading.\n572Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nFig. 16.6: Raster Symbology - Hillshade rendering\nOptions:\n•Band: The raster band to use.\n•Altitude: The elevation angle of the light source (default is45°).\n•Azimuth: The azimuth of the light source (default is315°).\n•Z Factor: Scaling factor for the values of the raster band (default is1).\n•Multidirectional: Specify if multidirectional hillshading is to be used (default isoff).\nContours\nThis renderer draws contour lines that are calculated on the fly from the source raster band.\n16.1. Raster Properties Dialog573\n\nQGIS Desktop 3.22 User Guide\nFig. 16.7: Raster Symbology - Contours rendering\nOptions:\n•Input band: the raster band to use.\n•Contour interval: the distance between two consecutive contour lines\n•Contour symbol: thesymbolto apply to the common contour lines.\n•Index contour interval: the distance between two consecutiveindex contours, that is the lines shown in a\ndistinctive manner for ease of identification, being commonly printed more heavily than other contour lines\nand generally labeled with a value along its course.\n•Index contour symbol: the symbol to apply to the index contour lines\n•Input downscaling: Indicates by how much the renderer will scale down the request to the data provider (default\nis4.0).\nFor example, if you generate contour lines on input raster block with the same size as the output raster block, the\ngenerated lines would contain too much detail. This detail can be reduced by the “downscale” factor, requesting\nlower resolution of the source raster. For a raster block 1000x500 with downscale 10, the renderer will request\nraster 100x50 from provider. Higher downscale makes contour lines more simplified (at the expense of losing\nsome detail).\n574Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nSetting the min and max values\nBy default, QGIS reports theMinandMaxvalues of the band(s) of the raster. A few very low and/or high values\ncan have a negative impact on the rendering of the raster. TheMin/Max Value Settingsframe helps you control the\nrendering.\nFig. 16.8: Raster Symbology - Min and Max Value Settings\nAvailable options are:\n•User defined: The defaultMinandMaxvalues of the band(s) can be overridden\n•Cumulative count cut: Removes outliers. The standard range of values is2%to98%, but it can be adapted\nmanually.\n•Min / max: Uses the whole range of values in the image band.\n•Mean +/- standard deviation x: Creates a color table that only considers values within the standard deviation\nor within multiple standard deviations. This is useful when you have one or two cells with abnormally high\nvalues in a raster layer that impact the rendering of the raster negatively.\nCalculations of the min and max values of the bands are made based on the:\n•Statistics extent: it can beWhole raster,Current canvasorUpdated canvas.Updated canvasmeans that min/max\nvalues used for the rendering will change with the canvas extent (dynamic stretching).\n•Accuracy, which can be eitherEstimate (faster)orActual (slower).\nNote:For some settings, you may need to press theApplybutton of the layer properties dialog in order to display\nthe actual min and max values in the widgets.\nColor ramp shader classification\nThis method can be used to classify and represent scalar dataset (raster or mesh contour) based on their values.\nGiven acolor rampand a number of classes, it generates intermediate color map entries for class limits. Each color\nis mapped with a value interpolated from a range of values and according to a classification mode. The scalar dataset\nelements are then assigned their color based on their class.\n16.1. Raster Properties Dialog575\n\nQGIS Desktop 3.22 User Guide\nFig. 16.9: Classifying a dataset with a color ramp shader\n1.AMinandMaxvalues must be defined and used to interpolate classes bounds. By default QGIS detects them\nfrom the dataset but they can be modified.\n2.TheInterpolationentry defines how scalar elements are assigned their color :\n•Discrete(a<=symbol appears in the header of theValuecolumn): The color is taken from the closest\ncolor map entry with equal or higher value\n•Linear: The color is linearly interpolated from the color map entries above and below the pixel value,\nmeaning that to each dataset value corresponds a unique color\n•Exact\n(a\n=\nsymbol appears in the header of the\nValue\ncolumn): Only pixels with value equal to a color\nmap entry are applied a color; others are not rendered.\n3.TheColor rampwidget helps you select the color ramp to assign to the dataset. As usual withthis widget, you\ncan create a new one and edit or save the currently selected one. The name of the color ramp will be saved in\nthe configuration.\n4.TheLabel unit suffixadds a label after the value in the legend, and theLabel precisioncontrols the number of\ndecimals to display.\n5.The classificationModehelps you define how values are distributed across the classes:\n•Equal interval: Provided theNumber of classes, limits values are defined so that the classes all have the\nsame magnitude.\n•Continuous: Classes number and color are fetched from the color ramp stops; limits values are set fol-\nlowing stops distribution in the color ramp.\n•Quantile: Provided theNumber of classes, limits values are defined so that the classes have the same\nnumber of elements. Not available withmesh layers.\n6.You can thenClassifyor tweak the classes:\n•The button\nAdd values manually\nadds a value to the table.\n576Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\n•The button\nRemove selected row\ndeletes selected values from the table.\n•Double clicking in theValuecolumn lets you modify the class value.\n•Double clicking in theColorcolumn opens the dialogChange color, where you can select a color to apply\nfor that value.\n•Double clicking in theLabelcolumn to modify the label of the class, but this value won’t be displayed\nwhen you use the identify feature tool.\n•Right-clicking over selected rows in the color table shows a contextual menu toChange Color...and\nChange Opacity...for the selection.\nYou can use the buttons\nLoad color map from file\nor\nExport color map to file\nto load an existing color table or to\nsave the color table for later use.\n7.With linearInterpolation, you can also configure:\n•Clip out of range values: By default, the linear method assigns the first class (respectively the last\nclass) color to values in the dataset that are lower than the setMin(respectively greater than the setMax)\nvalue. Check this setting if you do not want to render those values.\n•Legend settings, for display in theLayerspanel and the layoutlegend item. More details atCustomize raster\nlegend.\nCustomize raster legend\nWhen applying a color ramp to a raster or a mesh layer, you may want to display a legend showing the classification.\nBy default, QGIS displays a continuous color ramp with min and max values in theLayerspanel and the layout\nlegend\nitem\n. This can be customized using theLegend settingsbutton in the classification widget.\nFig. 16.10: Modifying a raster legend\nIn this dialog, you can set whether toUse continuous legend: if unchecked, the legend displays separated colors\ncorresponding to the different classes applied. This option is not available for rastersingleband graysymbology.\nChecking theUse continuous legendallows you to configure both the labels and layout properties of the legend.\n16.1. Raster Properties Dialog577\n\nQGIS Desktop 3.22 User Guide\nLabels\n•Add aPrefixand aSuffixto the labels\n•Modify theMinimumand aMaximumvalues to show in the legend\n•CustomizetheNumber format\n•CustomizetheText formatto use in the print layout legend.\nLayout\n•Control theOrientationof the legend color ramp; it can beVerticalorHorizontal\n•Control theDirectionof the values depending on the orientation:\n–If vertical, you can display theMaximum on topor theMinimum on top\n–If horizontal, you can display theMaximum on rightor theMinimum on right\nLayer rendering\nOver the symbology type applied to the layer band(s), you can achieve special rendering effects for the whole raster\nfile(s):\n•Use one of the blending modes (seeBlending Modes)\n•Set customBrightness,Saturation,GammaandContrastto colors.\n•With theInvert colors, the layer is rendered with opposite colors. Handy, for example, to switch out-of-the\nbox OpenStreetMap tiles to dark mode.\n•Turn the layer toGrayscaleoption either ‘By lightness’, ‘By luminosity’ or ‘By average’.\n•Colorizeand adjust theStrengthofHuein the color table\nPressResetto remove any custom changes to the layer rendering.\nFig. 16.11: Raster Symbology - Layer rendering and Resampling settings\n578Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nResampling\nTheResamplingoption has effect when you zoom in and out of an image. Resampling modes can optimize the\nappearance of the map. They calculate a new gray value matrix through a geometric transformation.\nWhen applying the ‘Nearest neighbour’ method, the map can get a pixelated structure when zooming in. This appear-\nance can be improved by using the ‘Bilinear’ or ‘Cubic’ method, which cause sharp edges to be blurred. The effect is\na smoother image. This method can be applied to for instance digital topographic raster maps.\n16.1.4Transparency Properties\nQGIS provides capabilities to set the transparency level of a raster layer.\nUse theGlobal opacityslider to set to what extent the underlying layers (if any) should be visible through the current\nraster layer. This is very useful if you overlay raster layers (e.g., a shaded relief map overlayed by a classified raster\nmap). This will make the look of the map more three dimensional. The opacity of the raster can be data-defined,\nand vary e.g. depending on the visibility of another layer, by temporal variables, on different pages of an atlas, ...\nFig. 16.12: Raster Transparency\nWithNo data valueQGIS reports the original source no data value (if defined) which you can consider as is in\nthe rendering. Additionally, you can enter a raster value that should be treated as anAdditional no data value. The\nDisplay no data ascolor selector allows you to apply a custom color to no data pixels, instead of the default transparent\nrendering.\nAn even more flexible way to customize the transparency is available in theCustom transparency optionssection:\n•UseTransparency bandto apply transparency for an entire band.\n16.1. Raster Properties Dialog579\n\nQGIS Desktop 3.22 User Guide\n•Provide a list of pixels to make transparent with corresponding levels of transparency:\n1.Click the\nAdd values manually\nbutton. A new row will appear in the pixel list.\n2.Enter theRed,GreenandBluevalues of the pixel and adjust thePercent Transparentto apply.\n3.Alternatively, youcanfetchthepixelvaluesdirectlyfromtherasterusingthe\nAdd values from display\nbutton.\nThen enter the transparency value.\n4.Repeat the steps to adjust more values with custom transparency.\n5.Press theApplybutton and have a look at the map.\nAs you can see, it is quite easy to set custom transparency, but it can be quite a lot of work. Therefore, you\ncan use the button\nExport to file\nto save your transparency list to a file. The button\nImport from file\nloads your\ntransparency settings and applies them to the current raster layer.\n16.1.5Histogram Properties\nTheHistogramtab allows you to view the distribution of the values in your raster. The histogram is generated\nwhen you press theCompute Histogrambutton. All existing bands will be displayed together. You can save the\nhistogram as an image with the\nbutton.\nAt the bottom of the histogram, you can select a raster band in the drop-down menu andSet min/max style forit. The\nPrefs/Actionsdrop-down menu gives you advanced options to customize the histogram:\n•With theVisibilityoption, you can display histograms for individual bands. You will need to select the option\nShow selected band.\n•TheMin/max optionsallow you to ‘Always show min/max markers’, to ‘Zoom to min/max’ and to ‘Update style\nto min/max’.\n•TheActionsoption allows you to ‘Reset’ or ‘Recompute histogram’ after you have changed the min or max\nvalues of the band(s).\n580Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nFig. 16.13: Raster Histogram\n16.1.6Rendering Properties\nIn theRenderingtab, it’s possible to:\n•setScale dependent visibilityfor the layer: You can set theMaximum (inclusive)andMinimum (exclusive)scale,\ndefining a range of scales in which the layer will be visible. It will be hidden outside this range. The\nSet to current canvas scale\nbutton helps you use the current map canvas scale as a boundary. SeeScale Dependent\nRenderingfor more information.\n•Refresh layer at interval (seconds): set a timer to automatically refresh individual layers. Canvas updates are\ndeferred in order to avoid refreshing multiple times if more than one layer has an auto update interval set.\n16.1. Raster Properties Dialog581\n\nQGIS Desktop 3.22 User Guide\nFig. 16.14: Raster Rendering Properties\n16.1.7Temporal Properties\nTheTemporaltab provides options to control the rendering of the layer over time. Such dynamic rendering\nrequires the\ntemporal navigationto be enabled over the map canvas.\n582Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nFig. 16.15: Raster Temporal Properties\nCheck theDynamic Temporal Controloption and set whether the layer redraw should be:\n•Automatic: the rendering is controlled by the underlying data provider if it suppports temporal data handling.\nE.g. this can be used with WMS-T layers or PostGIS rasters.\n•Fixed time range: only show the raster layer if the animation time is within aStart dateandEnd daterange\n•Redraw layer only: the layer is redrawn at each new animation frame. It’s useful when the layer uses time-based\nexpression values for renderer settings (e.g. data-defined renderer opacity, to fade in/out a raster layer).\n16.1.8Pyramids Properties\nHigh resolution raster layers can slow navigation in QGIS. By creating lower resolution copies of the data (pyramids),\nperformance can be considerably improved, as QGIS selects the most suitable resolution to use depending on the\nzoom level.\nYou must have write access in the directory where the original data is stored to build pyramids.\nFrom theResolutionslist, select resolutions at which you want to create pyramid levels by clicking on them.\nIf you chooseInternal (if possible)from theOverview formatdrop-down menu, QGIS tries to build pyramids\ninternally.\nNote:Please note that building pyramids may alter the original data file, and once created they cannot be removed.\nIf you wish to preserve a ‘non-pyramided’ version of your raster, make a backup copy prior to pyramid building.\nIf you chooseExternalandExternal (Erdas Imagine)the pyramids will be created in a file next to the original\nraster with the same name and a.ovrextension.\nSeveralResampling methodscan be used for pyramid calculation:\n•Nearest Neighbour\n16.1. Raster Properties Dialog583\n\nQGIS Desktop 3.22 User Guide\n•Average\n•Gauss\n•Cubic\n•Cubic Spline\n•Laczos\n•Mode\n•None\nFinally, clickBuild Pyramidsto start the process.\nFig. 16.16: Raster Pyramids\n584Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\n16.1.9Metadata Properties\nTheMetadatatab provides you with options to create and edit a metadata report on your layer. SeeMetadatafor\nmore information.\nFig. 16.17: Raster Metadata\n16.1.10Legend Properties\nTheLegendtab provides you with advanced settings for theLayers paneland/or theprint layout legend. These\noptions include:\n•Depending on the symbology applied to the layer, you may end up with several entries in the legend, not\nnecessarily readable/useful to display. TheLegend placeholder imagehelps youselect an imagefor replacement,\ndisplayed both in theLayerspanel and the print layout legend.\n•TheEmbedded widgets in Legendprovides you with a list of widgets you can embed within the layer tree\nin the Layers panel. The idea is to have a way to quickly access some actions that are often used with the layer\n(setup transparency, filtering, selection, style or other stuff...).\nBy default, QGIS provides a transparency widget but this can be extended by plugins that register their own\nwidgets and assign custom actions to layers they manage.\n16.1. Raster Properties Dialog585\n\nQGIS Desktop 3.22 User Guide\nFig. 16.18: Raster Legend\n16.1.11QGIS Server Properties\nFrom theQGIS Servertab, information can be provided forDescription,Attribution,Metadata URLandLegend\nURL.\n586Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nFig. 16.19: QGIS Server in Raster Properties\n16.2Raster Analysis\n16.2.1Raster Calculator\nTheRaster Calculatorin theRastermenu allows you to perform calculations on the basis of existing raster pixel values\n(seeFig. 16.20). The results are written to a new raster layer in a GDAL-supported format.\n16.2. Raster Analysis587\n\nQGIS Desktop 3.22 User Guide\nFig. 16.20: Raster Calculator\nTheRaster bandslist contains all loaded raster layers that can be used. To add a raster to the raster calculator\nexpression field, double click its name in the Fields list. You can then use the operators to construct calculation\nexpressions, or you can just type them into the box.\nIn theResult layersection, you will need to define an output layer. You can:\n•Create on-the-fly raster instead of writing layer to disk:\n–If unchecked, the output is stored on the disk as a new plain file. AnOutput layerpath and anOutput\nformatare required.\n–If checked, a virtual raster layer, i.e. a raster layer defined by its URI and whose pixels are calculated\n588Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\non-the-fly, is created. It’s not a new file on disk; the virtual layer is still connected to the rasters used in the\ncalculation meaning that deleting or moving these rasters would break it. ALayer namecan be provided,\notherwise the calculation expression is used as such. Removing the virtual layer from the project deletes\nit, and it can be made persistent in file using the layerExport►Save as...contextual menu.\n•Define theSpatial extentof the calculation based on an input raster layer extent, or on custom X,Y coordinates\n•Set theResolutionof the layer using columns and rows number. If the input layer has a different resolution, the\nvalues will be resampled with the nearest neighbor algorithm.\n•With theAdd result to projectcheckbox, the result layer will automatically be added to the legend area and\ncan be visualized. Checked by default for virtual rasters.\nTheOperatorssection contains all available operators. To add an operator to the raster calculator expression box,\nclick the appropriate button. Mathematical calculations (+,-,*, ... ) and trigonometric functions (sin,cos,tan,\n... ) are available. Conditional expressions (=,!=,<,>=, ... ) return either 0 for false or 1 for true, and therefore\ncan be used with other operators and functions.\nHint:See also theRaster calculatoralgorithm.\nExamples\nConvert elevation values from meters to feet\nCreating an elevation raster in feet from a raster in meters, you need to use the conversion factor for meters to feet:\n3.28. The expression is:\n\"elevation@1\"*3.28\nUsing a mask\nIf you want to mask out parts of a raster – say, for instance, because you are only interested in elevations above 0\nmeters – you can use the following expression to create a mask and apply the result to a raster in one step.\n(\"elevation@1\">=0)*\"elevation@1\"\nIn other words, for every cell greater than or equal to 0 the conditional expression evaluates to 1, which keeps the\noriginal value by multiplying it by 1. Otherwise the conditional expression evaluates to 0, which sets the raster value\nto 0. This creates the mask on the fly.\nClassify a Raster\nIf you want to classify a raster – say, for instance into two elevation classes, you can use the following expression to\ncreate a raster with two values 1 and 2 in one step.\n(\"elevation@1\"<50)*1+(\"elevation@1\">=50)*2\nIn other words, for every cell less than 50 set its value to 1. For every cell greater than or equal 50 set its value to 2.\nOr you can use theIFoperator.\nif( elevation@1<50,1,2)\n16.2. Raster Analysis589\n\nQGIS Desktop 3.22 User Guide\n16.2.2Raster Alignment\nThis tool is able to take several rasters as input and to align them perfectly, that means:\n•reproject to the same CRS,\n•resample to the same cell size and offset in the grid,\n•clip to a region of interest,\n•rescale values when required.\nAll rasters will be saved in another files.\nFirst, open the tools fromRaster►Align Raster...and click on the\nAdd new raster\nbutton to choose one existing\nraster in QGIS. Select an output file to save the raster after the alignment, the resampling method and if the tools\nneed toRescale values according to the cell size. The resampling method can be (seeFig. 16.21):\n•Nearest Neighbor\n•Bilinear (2x2 kernel)\n•Cubic (4x4 kernel): Cubic Convolution Approximation\n•Cubic B-Spline (4x4 kernel): Cubic B-Spline Approximation\n•Lanczos (6x6 kernel): Lanczos windowed sinc interpolation\n•Average: computes the average of all non-NODATA contributing pixels\n•Mode: selects the value which appears most often of all the sampled points\n•Maximum,Minimum,Mediane,First Quartile (Q1)orThird Quartile (Q3)of all non-NODATA con-\ntributing pixels\nFig. 16.21: Select Raster Resampling Options\nIn the mainAlign rasterdialog, you can still\nEdit file settings\nor\nRemove an existing file\nfrom the list of raster layers.\nYou can also choose one or more other options (see\nFig. 16.22):\n•Select theReference Layer,\n•Transform into a newCRS,\n•Setup a differentCell size,\n•Setup a differentGrid Offset,\n•Clip to Extent: it can be user-defined, bound to a layer or to the map canvas\n590Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\n•Output Size,\n•Add aligned raster to the map canvas.\nFig. 16.22: Raster Alignment\n16.3Georeferencer\nTheGeoreferencer is a tool for generating world files for rasters. It allows you to reference rasters to geographic\nor projected coordinate systems by creating a new GeoTiff or by adding a world file to the existing image. The\nbasic approach to georeferencing a raster is to locate points on the raster for which you can accurately determine\ncoordinates.\nFeatures\n16.3. Georeferencer591\n\nQGIS Desktop 3.22 User Guide\nIconPurposeIconPurpose\nOpen rasterStart georeferencing\nGenerate GDAL ScriptLoad GCP Points\nSave GCP Points AsTransformation settings\nAdd PointDelete Point\nMove GCP PointPan\nZoom InZoom Out\nZoom To LayerZoom Last\nZoom NextLink Georeferencer to QGIS\nLink QGIS to GeoreferencerFull histogram stretch\nLocal histogram stretch\nTable Georeferencer: Georeferencer Tools\n16.3.1Usual procedure\nAs X and Y coordinates (DMS (dd mm ss.ss), DD (dd.dd) or projected coordinates (mmmm.mm)), which correspond\nwith the selected point on the image, two alternative procedures can be used:\n•The raster itself sometimes provides crosses with coordinates “written” on the image. In this case, you can\nenter the coordinates manually.\n•Using already georeferenced layers.  This can be either vector or raster data that contain the same ob-\njects/features that you have on the image that you want to georeference and with the projection that you want\nfor your image. In this case, you can enter the coordinates by clicking on the reference dataset loaded in the\nQGIS map canvas.\nThe usual procedure for georeferencing an image involves selecting multiple points on the raster, specifying their\ncoordinates, and choosing a relevant transformation type. Based on the input parameters and data, the Georeferencer\nwill compute the world file parameters. The more coordinates you provide, the better the result will be.\nThe first step is to start QGIS and click on\nRaster\n►\nGeoreferencer, which appears in the QGIS menu bar. The\nGeoreferencer dialog appears as shown inFig. 16.23.\nFor this example, we are using a topo sheet of South Dakota from SDGS. It can later be visualized together with\nthe data from the GRASSspearfish60location. You can download the topo sheet here:https://grass.osgeo.org/\nsampledata/spearfish_toposheet.tar.gz.\n592Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nFig. 16.23: Georeferencer Dialog\nEntering ground control points (GCPs)\n1.To start georeferencing an unreferenced raster, we must load it using thebutton. The raster will show up\nin the main working area of the dialog. Once the raster is loaded, we can start to enter reference points.\n2.Using the\nAdd Point\nbutton, add points to the main working area and enter their coordinates (see FigureFig.\n16.24). For this procedure you have the following options:\n•Click on a point in the raster image and enter the X and Y coordinates manually, along with the CRS of\nthe point.\n•Click on a point in the raster image and choose the\nFrom map canvas\nbutton to add the X and Y coordinates\nwith the help of a georeferenced map already loaded in the QGIS map canvas. The CRS will be set\nautomatically.\n3.Continue entering points. You should have at least four points, and the more coordinates you can provide, the\nbetter the result will be. There are additional tools for zooming and panning the working area in order to locate\na relevant set of GCP points.\n4.With thetool, you can move the GCPs in both the canvas and the georeferencing window, if you need to\ncorrect them.\n16.3. Georeferencer593\n\nQGIS Desktop 3.22 User Guide\nFig. 16.24: Add points to the raster image\nThe points that are added to the map will be stored in a separate text file ([filename].points) usually together\nwith the raster image. This allows us to reopen the Georeferencer at a later date and add new points or delete existing\nones to optimize the result. The points file contains values of the form:mapX, mapY, pixelX, pixelY. You\ncan use the\nLoad GCP points\nand\nSave GCP points as\nbuttons to manage the files.\nDefining the transformation settings\nAfter you have added your GCPs to the raster image, you need to define the transformation settings for the georef-\nerencing process.\nFig. 16.25: Defining the georeferencer transformation settings\n594Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nAvailable Transformation algorithms\nA number of transformation algorithms are available, dependent on the type and quality of input data, the nature and\namount of geometric distortion that you are willing to introduce to the final result, and the number of ground control\npoints (GCPs).\nCurrently, the followingTransformation typesare available:\n•TheLinearalgorithm is used to create a world file and is different from the other algorithms, as it does not\nactually transform the raster pixels. It allows positioning (translating) the image and uniform scaling, but no\nrotation or other transformations. It is the most suitable if your image is a good quality raster map, in a known\nCRS, but is just missing georeferencing information. At least 2 GCPs are needed.\n•TheHelmerttransformation also allows rotation. It is particularly useful if your raster is a good quality local\nmap or orthorectified aerial image, but not aligned with the grid bearing in your CRS. At least 2 GCPs are\nneeded.\n•ThePolynomial 1algorithm allows a more general affine transformation, in particular also a uniform shear.\nStraight lines remain straight (i.e., collinear points stay collinear) and parallel lines remain parallel. This is\nparticularly useful for georeferencing data cartograms, which may have been plotted (or data collected) with\ndifferent ground pixel sizes in different directions. At least 3 GCP’s are required.\n•ThePolynomialalgorithms 2-3 use more general 2nd or 3rd degree polynomials instead of just affine trans-\nformation. This allows them to account for curvature or other systematic warping of the image, for instance\nphotographed maps with curving edges. At least 6 (respectively 10) GCP’s are required. Angles and local scale\nare not preserved or treated uniformly across the image. In particular, straight lines may become curved, and\nthere may be significant distortion introduced at the edges or far from any GCPs arising from extrapolating\nthe data-fitted polynomials too far.\n•TheProjectivealgorithm generalizes Polynomial 1 in a different way, allowing transformations representing\na central projection between 2 non-parallel planes, the image and the map canvas. Straight lines stay straight,\nbut parallelism is not preserved and scale across the image varies consistently with the change in perspective.\nThis transformation type is most useful for georeferencing angled photographs (rather than flat scans) of good\nquality maps, or oblique aerial images. A minimum of 4 GCPs is required.\n•Finally, theThin Plate Spline(TPS) algorithm “rubber sheets” the raster using multiple local polynomi-\nals to match the GCPs specified, with overall surface curvature minimized. Areas away from GCPs will be\nmoved around in the output to accommodate the GCP matching, but will otherwise be minimally locally de-\nformed. TPS is most useful for georeferencing damaged, deformed, or otherwise slightly inaccurate maps,\nor poorly orthorectified aerials. It is also useful for approximately georeferencing and implicitly reprojecting\nmaps with unknown projection type or parameters, but where a regular grid or dense set of ad-hoc GCPs can\nbe matched with a reference map layer. It technically requires a minimum of 10 GCPs, but usually more to\nbe successful.\nIn all of the algorithms except TPS, if more than the minimum GCPs are specified, parameters will be fitted so\nthat the overall residual error is minimized. This is helpful to minimize the impact of registration errors, i.e. slight\nimprecisions in pointer clicks or typed coordinates, or other small local image deformations. Absent other GCPs to\ncompensate, such errors or deformations could translate into significant distortions, especially near the edges of the\ngeoreferenced image. However, if more than the minimum GCPs are specified, they will match only approximately\nin the output. In contrast, TPS will precisely match all specified GCPs, but may introduce significant deformations\nbetween nearby GCPs with registration errors.\n16.3. Georeferencer595\n\nQGIS Desktop 3.22 User Guide\nDefine the Resampling method\nThe type of resampling you choose will likely depend on your input data and the ultimate objective of the exercise.\nIf you don’t want to change statistics of the raster (other than as implied by nonuniform geometric scaling if using\nother than the Linear, Helmert, or Polynomial 1 transformations), you might want to choose ‘Nearest neighbour’. In\ncontrast, ‘cubic resampling’, for instance, will usually generate a visually smoother result.\nIt is possible to choose between five different resampling methods:\n1.Nearest neighbour\n2.Linear\n3.Cubic\n4.Cubic Spline\n5.Lanczos\nDefine the transformation settings\nThere are several options that need to be defined for the georeferenced output raster.\n•TheCreate world filecheckbox is only available if you decide to use the linear transformation type, because\nthis means that the raster image actually won’t be transformed. In this case, theOutput rasterfield is not\nactivated, because only a new world file will be created.\n•For all other transformation types, you have to define anOutput raster.  As default, a new file ([file-\nname]_modified) will be created in the same folder together with the original raster image.\n•As a next step, you have to define theTarget SRS(Spatial Reference System) for the georeferenced raster (see\nWorking with Projections).\n•If you like, you cangenerate a pdf mapand alsoa pdf report. The report includes information about the\nused transformation parameters, an image of the residuals and a list with all GCPs and their RMS errors.\n•Furthermore, you can activate theSet Target Resolutioncheckbox and define the pixel resolution of the\noutput raster. Default horizontal and vertical resolution is 1.\n•TheUse 0 for transparency when neededcan be activated, if pixels with the value 0 shall be visualized\ntransparent. In our example toposheet, all white areas would be transparent.\n•Finally,Load in QGIS when done\nloads the output raster automatically into the QGIS map canvas when the\ntransformation is done.\nShow and adapt raster properties\nClicking on theRaster propertiesoption in theSettingsmenu opens theLayer propertiesdialog of the raster file that\nyou want to georeference.\n596Chapter 16. Working with Raster Data\n\nQGIS Desktop 3.22 User Guide\nConfigure the georeferencer\n•You can define whether you want to show GCP coordinates and/or IDs.\n•As residual units, pixels and map units can be chosen.\n•For the PDF report, a left and right margin can be defined and you can also set the paper size for the PDF map.\n•Finally, you can activate toShow Georeferencer window docked.\nRunning the transformation\nAfter all GCPs have been collected and all transformation settings are defined, just press the\nStart georeferencing\nbutton to create the new georeferenced raster.\n16.3. Georeferencer597\n\nQGIS Desktop 3.22 User Guide\n598Chapter 16. Working with Raster Data\n\nCHAPTER\nSEVENTEEN\nWORKING WITH MESH DATA\n17.1What’s a mesh?\nA mesh is an unstructured grid usually with temporal and other components. The spatial component contains a\ncollection of vertices, edges and/or faces, in 2D or 3D space:\n•vertices- XY(Z) points (in the layer’s coordinate reference system)\n•edges- connect pairs of vertices\n•faces- a face is a set of edges forming a closed shape - typically a triangle or a quadrilateral (quad), rarely\npolygons with more vertices\nRelying on the above, mesh layers can thus have different types of structure:\n•1D Meshes: consist of vertices and edges. An edge connects two vertices and can have assigned data (scalars\nor vectors) on it. The 1D mesh network can be for example used for modelling of an urban drainage system.\n•2D meshes: consist of faces with triangles, regular or unstructured quads.\n•3D layered meshes: consist of multiple stacked 2D unstructured meshes each extruded in the vertical direction\n(levels) by means of a vertical coordinate. The vertices and faces have the same topology in each vertical level.\nThe mesh definition (vertical level extrusion) could in general change in time. The data is usually defined in\nvolume centres or by some parametric function.\nFig. 17.1: Different mesh types\nMesh provides information about the spatial structure. In addition, the mesh can have datasets (groups) that assign a\nvalue to every vertex. For example, having a triangular mesh with numbered vertices as shown in the image below:\n599\n\nQGIS Desktop 3.22 User Guide\nFig. 17.2: Triangular grid with numbered vertices\nEach vertex can store different datasets (typically multiple quantities), and those datasets can also have a temporal\ndimension. Thus, a single file may contain multiple datasets.\nThe following table gives an idea about the information that can be stored in mesh datasets. Table columns represent\nindices of mesh vertices, each row represents one dataset. Datasets can have different datatypes. In this case, it stores\nwind velocity at 10m at a particular moments in time (t1, t2, t3).\nIn a similar way, the mesh dataset can also store vector values for each vertex. For example, wind direction vector at\nthe given time stamps:\n10 metre wind123...\n10 metre speed at time=t1172512491832858...\n10 metre speed at time=t2191682300136418...\n10 metre speed at time=t3210853066817251...\n...............\n10m wind direction time=t1[20,2][20,3][20,4.5]...\n10m wind direction time=t2[21,3][21,4][21,5.5]...\n10m wind direction time=t3[22,4][22,5][22,6.5]...\n...............\nWe can visualize the data by assigning colors to values (similarly to how it is done withSingleband pseudocolorraster\nrendering) and interpolating data between vertices according to the mesh topology. It is common that some quantities\nare 2D vectors rather than being simple scalar values (e.g. wind direction). For such quantities it is desirable to display\narrows indicating the directions.\n600Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\nFig. 17.3: Possible visualisation of mesh data\n17.2Supported formats\nQGIS accesses mesh data using theMDAL drivers, and natively supports avariety of formats. Whether QGIS can\nedit a mesh layer depends on the format and the mesh structure type.\nTo load a mesh dataset into QGIS, use theMeshtab in theData Source Managerdialog. ReadLoading a mesh\nlayer\nfor more details.\n17.3Mesh Dataset Properties\nTheLayer Propertiesdialog for a mesh layer provides general settings to manage dataset groups of the layer and their\nrendering (active dataset groups, symbology, 2D and 3D rendering). It also provides information about the layer.\nTo access theLayer Propertiesdialog:\n•In theLayerspanel, double-click the layer or right-click and selectProperties...from the pop-up menu;\n•Go toLayer►Layer Properties...menu when the layer is selected.\nThe meshLayer Propertiesdialog provides the following sections:\nInformationSourceSymbology\n[1]\n3D View\n[1]\nTemporalRendering\nMetadata\n[1]\nAlso available in theLayer styling panel\nNote:Most of the properties of a mesh layer can be saved to or loaded from a.qmlusing theStylemenu at the\nbottom of the dialog. More details atManaging Custom Styles.\n17.2. Supported formats601\n\nQGIS Desktop 3.22 User Guide\n17.3.1Information Properties\nFig. 17.4: Mesh Layer Information Properties\nTheInformationtab is read-only and represents an interesting place to quickly grab summarized information and\nmetadata on the current layer. Provided information are:\n•general such as name in the project, source path, list of auxiliary files, last save time and size, the used provider\n•based on the provider of the layer: extent, vertex, face, edges and/or dataset groups count\n•the Coordinate Reference System: name, units, method, accuracy, reference (i.e. whether it’s static or dynamic)\n•extracted from filledmetadata: access, extents, links, contacts, history...\n602Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\n17.3.2Source Properties\nTheSourcetab displays basic information about the selected mesh, including:\nFig. 17.5: Mesh Layer Source Properties\n•the layer name to display in theLayerspanel\n•setting the Coordinate Reference System: Displays the layer’sAssigned Coordinate Reference System (CRS).\nYou can change the layer’s CRS by selecting a recently used one in the drop-down list or clicking onSelect\nCRSbutton (see\nCoordinate Reference System Selector). Use this process only if the CRS applied to the layer\nis wrong or if none was applied.\n•TheAvailable datasetsframe lists all the dataset groups (and subgroups) in the mesh layer, with their type and\ndescription in a tree view. Both regular datasets (i.e. their data is stored in the file) and virtual datasets (which\narecalculated on the fly) are listed.\n–Use theAssign extra dataset to meshbutton to add more groups to the current mesh layer.\n–Collapse allandExpand allthe dataset tree, in case of embedded groups\n–If you are interested in few datasets, you can uncheck the others and make them unavailable in the project\n–Double-click over a name and you can rename the dataset.\n–Reset to defaults: checks all the groups and renames them back to their original name in the provider.\n–Right-click over a virtual dataset group and you can:\n∗Remove dataset groupfrom the project\n∗Save dataset group as...a file on disk, to any supported format. The new file is kept assigned to the\ncurrent mesh layer in the project.\n17.3. Mesh Dataset Properties603\n\nQGIS Desktop 3.22 User Guide\n•Checking theTreat as static datasetgroup allows to ignore the map temporal navigation properties while\nrendering the mesh layer. For each active dataset group (as selected inSymbology►Datasetstab),\nyou can:\n–set toNone: the dataset group is not displayed at all\n–Display dataset: eg, for the “bed elevation” dataset which is not time aware\n–extract a particular date time: the dataset matching the provided time is rendered and stay fixed during\nmap navigation.\n17.3.3Symbology Properties\nClick theSymbologybutton to activate the dialog. Symbology properties are divided into several tabs:\n•Datasets\n•Contours\n•Vectors\n•Rendering\n•Stacked mesh averaging method\nDatasets\nThe tab\nDatasets\nis the main place to control and set which datasets will be used for the layer. It presents the\nfollowing items:\n•Groupsavailable in the mesh dataset, with whether they provide:\n–scalar dataset\n–orvector dataset: by default, each vector dataset has a scalar dataset representing its magnitude\nautomatically generated.\nClick on the icon next to the dataset name to select the group and type of data to represent.\n•Selected dataset group(s) metadata, with details on:\n–the mesh type: edges or faces\n–the data type: vertices, edges, faces or volume\n–whether it’s of vector type or not\n–the original name in the mesh layer\n–the unit, if applicable\n•blending modeavailable for the selected datasets.\n604Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\nFig. 17.6: Mesh Layer Datasets\nYou can apply symbology to the selected vector and/or scalar group using the next tabs.\nContours Symbology\nNote:The\nContours\ntab can be activated only if a scalar dataset has been selected in theDatasetstab.\nIn the\nContours\ntab you can see and change the current visualization options of contours for the selected group, as\nshown in\nFig. 17.7below:\n17.3. Mesh Dataset Properties605\n\nQGIS Desktop 3.22 User Guide\nFig. 17.7: Styling Contours in a Mesh Layer\n•For 1D mesh, set theStroke widthof the edges. This can be a fixed size for the whole dataset, or vary along\nthe geometry (more details with theinterpolated line renderer)\n•Use the slider or the spinbox to set theOpacityof the current group, if of a 2D mesh type.\n•Enter the range of values you want to represent on the current group: use\nLoad\nto fetch the min and max\nvalues of the current group or enter custom values if you want to exclude some.\n•For 2D/3D meshes, select theResampling methodto interpolate the values on the surrounding vertices to the\nfaces (or from the surrounding faces to the vertices) using theNeighbour averagemethod. Depending on\nwhether the dataset is defined on the vertices (respectively on the faces), QGIS defaults this setting toNone\n(respectivelyNeighbour average) method in order to use values on vertices and keep the default rendering\nsmooth.\n•Classify the dataset using thecolor ramp shaderclassification.\n606Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\nVectors Symbology\nNote:The\nVectors\ntab can be activated only if a vector dataset has been selected in theDatasetstab.\nIn the\nVectors\ntab you can see and change the current visualization options of vectors for the selected group, as\nshown inFig. 17.8:\nFig. 17.8: Styling Vectors in a Mesh Layer with arrows\nMesh vector dataset can be styled using various types ofSymbology:\n•Arrows: vectors are represented with arrows at the same place as they are defined in the raw dataset (i.e. on the\nnodes or center of elements) or on a user-defined grid (hence, they are evenly distributed). The arrow length\nis proportional to the magnitude of the arrow as defined in the raw data but can be scaled by various methods.\n•Streamlines: vectors are represented with streamlines seeded from start points. The seeding points can start\nfrom the vertices of the mesh, from a user grid or randomly.\n•Traces: a nicer animation of the streamlines, the kind of effect you get when you randomly throws sand in the\nwater and see where the sand items flows.\nAvailable properties depend on the selected symbology as shown in the following table.\n17.3. Mesh Dataset Properties607\n\nQGIS Desktop 3.22 User Guide\nLabelDescription  and\nProperties\nArrowStreamlinesTraces\nLine widthWidth of the vector\nrepresentation\nColoring method\n•aSingle color\nassigned  to\nall vectors\n•or a variable\ncolor  based\non   vectors\nmagnitude,\nusing aColor\nramp shader\nFilter by magnitudeOnly vectors whose\nlength for the se-\nlected dataset falls\nbetween aMinand\nMaxrange are dis-\nplayed\nDisplay on user gridPlaces the vector\non  a  grid  with\ncustomX  spacing\nandY spacingand\ninterpolates   their\nlength  based  on\nneighbours\nHead optionsLengthandWidthof\nthe arrow head, as\na percentage of its\nshaft length\nArrow length\n•Defined  by\nMin   and\nMax:   You\nspecify  the\nminimum\nand   maxi-\nmum  length\nfor  the  ar-\nrows,  QGIS\nwill interpo-\nlate their size\nbased on the\nunderlying\nvector’s mag-\nnitude\n•Scale    to\nmagnitude:\narrow length\nis   propor-\ntionalto\ntheir vector’s\nmagnitude\n•Fixed: all the\nvectors  are\nshown  with\nthe    same\nlength\nStreamlines seeding\nmethod\n•On\nmesh/grid:\nrelies on the\nuser grid to\ndisplay  the\nvectors\n•Randomly:\nvector place-\nmentis\nrandomly\ndone   with\nrespect   to\na    certain\ndensity\nParticles countThe  amount  of\n“sand” you want to\nthrow into visuali-\nsation\nMax tail lengthThe time until the\nparticle fades out\n608Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\nRendering\nIn the tab\nRendering\ntab, QGIS offers possibilities to display and customize the mesh structure.Line widthandLine\ncolorcan be set to represent:\n•the edges for 1D meshes\n•For 2D meshes:\n–Native mesh rendering: shows original faces and edges from the layer\n–Triangular mesh rendering: adds more edges and displays the faces as triangles\nFig. 17.9: 2D Mesh Rendering\nStacked mesh averaging method\n3D layered meshes consist of multiple stacked 2D unstructured meshes each extruded in the vertical direction\n(levels) by means of a vertical coordinate. The vertices and faces have the same topology in each vertical level.\nValues are usually stored on the volumes that are regularly stacked over base 2d mesh. In order to visualise them on\n2D canvas, you need to convert values on volumes (3d) to values on faces (2d) that can be shown in mesh layer. The\nStacked mesh averaging method\nprovides different averaging/interpolation methods to handle this.\nYou can select the method to derive the 2D datasets and corresponding parameters (level index, depth or height\nvalues). For each method, an example of application is shown in the dialog but you can read more on the methods at\nhttps://fvwiki.tuflow.com/index.php?title=Depth_Averaging_Results.\n17.3.43D View Properties\nMesh layers can be used asterrain in a 3D map viewbased on their vertices Z values. From the3D Viewproperties\ntab, it’s also possible to render the mesh layer’s dataset in the same 3D view. Therefore, the vertical component of\nthe vertices can be set equal to dataset values (for example, level of water surface) and the texture of the mesh can be\nset to render other dataset values with color shading (for example velocity).\n17.3. Mesh Dataset Properties609\n\nQGIS Desktop 3.22 User Guide\nFig. 17.10: Mesh dataset 3D properties\nCheckEnable 3D Rendererand you can edit following properties:\n•UnderTriangle settings\n–Smooth triangles: Angles between consecutive triangles are smoothed for a better 3D rendering\n–Show wireframewhose you can set theLine widthandColor\n–Level of detail: Controls howsimplifiedthe mesh layer to render should be. On the far right, it is the base\nmesh, and the more you go left, the more the layer is simplified and is rendered with less details. This\noption is only available if theSimplify meshoption under theRenderingtab is activated.\n•Vertical settingsto control behavior of the vertical componentof vertices of rendered triangles\n–Dataset group for vertical value: the dataset group that will be used for the vertical component of the\nmesh\n–Dataset value relative to vertices Z value: whether to consider the dataset values as absolute Z coordi-\nnate or relative to the vertices native Z value\n–Vertical scale: the scale factor to apply to the dataset Z values\n•Rendering color settingswith aRendering stylethat can be based on the color ramp shader set inContours\nSymbology(2D contour color ramp shader) or as aSingle colorwith an associatedMesh color\n•Show arrows: displays arrows on mesh layer dataset 3D entity, based on the same vector dataset group used in\nthevector 2D rendering. They are displayed using the 2D color setting. It’s also possible to define theArrow\nspacingand, if it’s of aFixed sizeor scaled on magnitude. This spacing setting defines also the max size of\narrows because arrows can’t overlap.\n610Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\n17.3.5Rendering Properties\nAs mesh layers can have millions of faces, their rendering can sometimes be very slow, especially when all the faces\nare displayed in the view whereas they are too small to be viewed. To speed up the rendering, you can simplify the\nmesh layer, resulting in one or more meshes representing differentlevels of detailand select at which level of detail\nyou would like QGIS to render the mesh layer. Note that the simplify mesh contains only triangular faces.\nFrom theRenderingtab, checkSimplify meshand set:\n•aReduction factor: Controls generation of successive levels of simplified meshes. For example, if the base\nmesh has 5M faces, and the reduction factor is 10, the first simplified mesh will have approximately 500 000\nfaces, the second 50 000 faces, the third 5000,... If a higher reduction factor leads quickly to simpler meshes\n(i.e. with triangles of bigger size), it produces also fewer levels of detail.\n•Minimum triangle size: the average size (in pixels) of the triangles that is permitted to display. If the average\nsize of the mesh is lesser than this value, the rendering of a lower level of details mesh is triggered.\n17.3.6Temporal Properties\nTheTemporaltab provides options to control the rendering of the layer over time. It allows to dynamically\ndisplay temporal values of the enabled dataset groups. Such a dynamic rendering requires thetemporal navigationto\nbe enabled over the map canvas.\nFig. 17.11: Mesh Temporal properties\nLayer temporal settings\n•Reference timeof the dataset group, as an absolute date time. By default, QGIS parses the source layer and\nreturns the first valid reference time in the layer’s dataset group. If unavailable, the value will be set by the\nproject time range or fall back to the current date. TheStart timeandEnd timeto consider are then calculated\nbased on the internal timestamp step of the dataset.\nIt is possible to set a customReference time(and then the time range), and revert the changes using the\nReload from provider\nbutton.\n•Dataset matching method: determines the dataset to display at the given time. Options areFind closest dataset\nbefore requested timeorFind closest dataset from requested time (after or before).\nProvider time settings\n17.3. Mesh Dataset Properties611\n\nQGIS Desktop 3.22 User Guide\n•Time unitextracted from the raw data, or user defined. This can be used to align the speed of the mesh layer\nwith other layers in the project during map time navigation. Supported units areSeconds,Minutes,Hoursand\nDays.\n17.3.7Metadata Properties\nTheMetadatatab provides you with options to create and edit a metadata report on your layer. SeeMetadatafor\nmore information.\n17.4Editing a mesh layer\nQGIS allows tocreate a mesh layerfrom scratch or based on an existing one. You can create/modify the geometries\nof the new layer whom you can assign datasets afterwards. It’s also possible to edit an existing mesh layer. Because\nthe editing operation requires a frames-only layer, you will be asked to either remove any associated datasets first\n(make sure you have them available if they still are necessary) or create a copy (only geometries) of the layer.\nNote:QGIS does not allow to digitize edges on mesh layers. Only vertices and faces are mesh elements that can be\ncreated. Also not all supported mesh formats can be edited in QGIS (seepermissions).\n17.4.1Overview of the mesh digitizing tools\nTo interact with or edit a base mesh layer element, following tools are available.\nTable 17.1: Tools for mesh digitizing\nLabelPurposeLocation\nCurrent Edits\nAccess to save, rollback or cancel changes in all or selected\nlayers simultaneously\nDigitizingtoolbar\nToggle to Edit\nTurn on/off the layer in edit modeDigitizingtoolbar\nSave Edits\nSave changes done to the layerDigitizingtoolbar\nUndo\nUndo the last change(s) -Ctrl+ZDigitizingtoolbar\nRedo\nRedo the last undone action(s) -Ctrl+Shift+ZDigitizingtoolbar\nEnable Advanced Digitizing tools\nTurn on/off theAdvanced Digitizing PanelAdvanced  Digitizing\ntoolbar\nReindex Faces and Vertices\nRecreate index and renumber the mesh elements for optimiza-\ntion\nMeshmenu\nDigitize Mesh Elements\nSelect/Create vertices and facesMesh Digitizingtool-\nbar\nSelect Mesh Elements by Polygon\nSelect vertices and faces overlapped by a drawn polygonMesh Digitizingtool-\nbar\nSelect Mesh Elements by Expression\nSelect vertices and faces using an expressionMesh Digitizingtool-\nbar\nTransform Vertices Coordinates\nModify coordinates of a selection of verticesMesh Digitizingtool-\nbar\nForce by Selected Geometries\nSplit faces and constrain Z value using a linear geometryMesh Digitizingtool-\nbar\n612Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\n17.4.2Exploring the Z value assignment logic\nWhen a mesh layer is turned into edit mode, aVertex Z valuewidget opens at the top right of the map canvas. By\ndefault, its value corresponds to theDefault Z valueset inSettings►Options►Digitizingtab. When there are selected\nvertices, the widget displays the average Z value of the selected vertices.\nDuring editing, theVertex Z valueis assigned to new vertices. It is also possible to set a custom value: edit the widget,\npressEnterand you will override the default value and make use of this new value in the digitizing process. Click\ntheicon in the widget to reset its value to the Options default value.\nRules of assignment\nWhencreatinga new vertex, its Z value definition may vary depending on the active selection in the mesh layer and\nits location. The following table displays the various combinations.\nTable 17.2: Matrix of Z value assignment to new vertex\nVertex creationAre there selected ver-\ntices in mesh layer?\nSource of assigned valueAssigned Z Value\n“Free”  vertex,  not\nconnected to any\nface or edge of a face\nNoVertex Z valueDefault or user de-\nfined\nAdvanced Digitizing Panel(ifz\nwidget is in\nLocked\nstate)\nzwidget if in\nLocked\nstate\nYesVertex Z valueAverage of the se-\nlected vertices\nVertex on an edge—Mesh layerInterpolated from the\nedge’s vertices\nVertex on a face—Mesh layerInterpolated from the\nface’s vertices\nVertex snapped to a\n2D vector feature\n—Vertex Z valueDefault or user de-\nfined\nVertex snapped to a\n3D vector vertex\n—Vector layerVertex\nVertex snapped to a\n3D vector segment\n—Vector layerInterpolated   along\nthe vector segment\nNote:TheVertex Z valuewidget is deactivated if theAdvanced Digitizing Panelis enabled and no mesh element is\nselected. The latter’szwidget then rules the Z value assignment.\nModifying Z value of existing vertices\nTo modify the Z value of vertices, the most straightforward way is:\n1.Select one or many vertices. TheVertex Z valuewidget will display the average height of the selection.\n2.Change the value in the widget.\n3.PressEnter. The entered value is assigned to the vertices and becomes the default value of next vertices.\nAnother way to change the Z value of a vertex is to move and snap it on a vector layer feature with the Z value\ncapability. If more than one vertex are selected, the Z value can’t be changed in this way.\nThe\nTransform mesh verticesdialog also provides means to modify the Z value of a selection of vertices (along with\ntheir X or Y coordinates).\n17.4. Editing a mesh layer613\n\nQGIS Desktop 3.22 User Guide\n17.4.3Selecting mesh elements\nUsingDigitize Mesh Elements\nActivate the\nDigitize Mesh Elements\ntool. Hover over an element and it gets highlighted, allowing you to select it.\n•Click on a vertex, and it is selected.\n•Click on the small square at the center of a face or an edge, and it gets selected. Connected vertices are also\nselected. Conversely, selecting all the vertices of an edge or a face also selects that element.\n•Drag a rectangle to select overlapping elements (a selected face comes with all their vertices). PressAltkey\nif you want to select only completely contained elements.\n•To add elements to a selection, pressShiftwhile selecting them.\n•To remove an element from the selection, pressCtrland reselect it. A deselected face will also deselect all\ntheir vertices.\nUsingSelect Mesh Elements by Polygon\nActivate the\nSelect Mesh Elements by Polygon\ntool and:\n•Draw a polygon (left-click to add vertex,Backspaceto undo last vertex,Escto abort the polygon and right-\nclick to validate it) over the mesh geometries. Any partially overlapping vertices and faces will get selected.\nPressAltkey while drawing if you want to select only completely contained elements.\n•Right-click over the geometry of a vector layer’s feature, select it in the list that pops up and any partially\noverlapping vertices and faces of the mesh layer will get selected. UseAltwhile drawing to select only\ncompletely contained elements.\n•To add elements to a selection, pressShiftwhile selecting them.\n•To remove an element from the selection, pressCtrlwhile drawing over the selection polygon.\nUsingSelect Mesh Elements by Expression\nAnother tool for mesh elements selection is\nSelect Mesh Elements by Expression\n. When pressed, the tool opens the mesh\nexpression selector dialogfrom which you can:\n1.Select the method of selection:\n•Select by vertices: applies the entered expression to vertices, and returns matching ones and their eventually\nassociated edges/faces\n•Select by faces: applies the entered expression to faces, and returns matching ones and their associated\nedges/vertices\n2.Write the expression of selection. Depending on the selected method, available functions in theMeshes group\nwill be filtered accordingly.\n3.Run the query by setting how the selection should behave and pressing:\n•Select: replaces any existing selection in the layer\n•Add to current selection\n•Remove from current selection\n614Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\n17.4.4Modifying mesh elements\nAdding vertices\nTo add vertices to a mesh layer:\n1.Press the\nDigitize mesh elements\nbutton\n2.AVertex Z valuewidget appears on the top right corner of the map canvas. Set this value to the Z coordinate\nyou would like to assign to the subsequent vertices\n3.Then double-click:\n•outside a face: adds a “free vertex”, that is a vertex not linked to any face. This vertex is represented by\na red dot when the layer is in editing mode.\n•on the edge of existing face(s): adds a vertex on the edge, splits the face(s) into triangles connected to\nthe new vertex\n•inside a face: splits the face into triangles whose edges connect the surrounding vertices to the new vertex.\nAdding faces\nTo add faces to a mesh layer:\n1.Press the\nDigitize mesh elements\nbutton\n2.AVertex Z valuewidget appears on the top right corner of the map canvas. Set this value to the Z coordinate\nyou would like to assign to the subsequent vertices.\n3.Double-click to add a first vertex or move the cursor next to a vertex.\n4.Click the small triangle that appears next to the vertex and move the cursor to the next vertex position; you can\nsnap to existing vertex or double-click to add a new one.\n5.Proceed as above to add as many vertices you wish for the face. PressBackspacebutton to undo the last\nvertex.\n6.While moving the mouse, a rubberband showing the shape of the face is displayed. If it is shown in green,\nthen the expected face is valid and you can right-click to add it to the mesh. If in red, the face is not valid (e.g.\nbecause it self-intersects, overlaps an existing face or vertex, ...) and can’t be added. You’d need to fix the\ngeometry.\n7.PressEscto abort the face digitizing.\n8.Right-click to validate the face.\nRemoving mesh elements\n1.Select the target elements\n2.Enable the\nDigitize mesh elements\ntool\n3.Right-click and select:\n•Remove Selected Vertices and Fill Hole(s)or pressCtrl+Del: removes vertices and linked faces and\nfills the hole(s) by triangulating from the neighbor vertices\n•Remove Selected Vertices Without Filling Hole(s)or pressCtrl+Shift+Del: removes vertices and\nlinked faces and do not fill hole(s)\n•Remove Selected Face(s)or pressShift+Del: removes faces but keeps the vertices\nThese options are also accessible from the contextual menu when hovering over a single item without selecting.\n17.4. Editing a mesh layer615\n\nQGIS Desktop 3.22 User Guide\nMoving mesh elements\nTo move vertices and faces of a mesh layer:\n1.Select the target elements\n2.Enable the\nDigitize mesh elements\ntool\n3.To start moving the element, click on a vertex or the centroid of a face/edge\n4.Move the cursor to the target location (snapping to vector features is supported).\n5.If the new location does not generate an invalid mesh, the moved elements appear in green. Click again to\nrelease them at this location. Faces whose vertices are all selected are translated, their neighbors are reshaped\naccordingly.\nTransforming mesh vertices\nThe\nTransform Vertices Coordinates\ntool gives a more advanced way to move vertices, by editing their X, Y and/or Z\ncoordinates thanks to expressions.\n1.Select the vertices you want to edit the coordinates\n2.Press\nTransform Vertices Coordinates\n. A dialog opens with a mention of the number of selected vertices. You can\nstill add or remove vertices from the selection.\n3.Depending on the properties you want to modify, you need to check theX coordinate,Y coordinateand/orZ\nvalue.\n4.Then enter the target position in the box, either as a numeric value or an expression (using the\nExpression dialog\n)\n5.With the\nImport Coordinates of the Selected Vertex\npressed, the X, Y and Z boxes are automatically filled with its\ncoordinates whenever a single vertex is selected. A convenient and quick way to adjust vertices individually.\n6.PressPreview Transformto simulate the vertices new location and preview the mesh with transformation.\n•If the preview is green, transformed mesh is valid and you can apply the transformation.\n•If the preview is red, the transformed mesh is invalid and you can not apply the transformation until it is\ncorrected.\n7.PressApply Transformto modify the selected coordinates for the set of vertices.\nReshaping mesh geometry\nThe contextual menu\n1.Enable the\nDigitize mesh elements\n2.Select mesh item(s), or not\n3.Hover over a mesh element, it gets highlighted.\n4.Right-click and you can:\n•remove the item(s)\n•Split Selected Face(s)(Split Current Face): splits the face you are hovering over or each selected quad mesh\nfaces into two triangles\n•Delaunay Triangulation with Selected vertices: builds triangular faces using selected free vertices.\n616Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\n•Refine Selected Face(s)(Refine Current Face): splits the face into four faces, based on vertices added at\nthe middle of each edge (a triangle results into triangles, a quad into quads). Also triangulates adjacent\nfaces connected to the new vertices.\nThe edge markers\nWhen the\nDigitize mesh elements\nis active and you hover over an edge, the edge is highlighted and it is possible to\ninteract with it. Depending on the context, following markers may be available:\n•asquare, at the center of the edge: click on it to select extremity vertices.\n•acrossif the two faces on either side can be merged: click on it to delete the edge and merge the faces.\n•acircleif the edge is between two triangles: Click on it to flip the edge, i.e. connect it instead to the two other\n“free” vertices of the faces\nTheForce by Selected Geometriestool\nThe\nForce by Selected Geometries\ntool provides advanced ways to apply break lines using lines geometry. A break line\nwill force the mesh to have edges along the line. Note that the break line will not be considered persistent once\nthe operation is done; resulting edges will not act as constraints anymore and can be modified like any other edge.\nThis can be used for example to locally modify a mesh layer with accurate lines, as river banks or border of road\nembankments.\n1.Enable the\nForce by Selected Geometries\ntool\n2.Indicate the geometry to use as “forcing line”; it can be:\n•picked from a line or polygon feature in the map canvas: right-click over the vector feature and select it\nfrom the list in the contextual menu.\n•a virtual line drawn over the mesh frame: left-click to add vertices, right-click for validation. Vertices Z\nvalue is set through theVertex Z valuewidget or thezwidget if theAdvanced Digitizing Panelis on. If\nthe line is snapped to a mesh vertex or a 3D vector feature’s vertex or segment, the new vertex takes the\nsnapped element Z value.\nMesh faces that overlap the line geometry or the polygon’s boundary will be affected in a way that depends on options\nyou can set from the\nForce by Selected Geometries\ntool drop-down menu:\n•Add new vertex on intersecting edges: with this option, a new vertex is added each time the forcing line\nintersect an edge. This option leads to split along the line each encountered faces.\nWithout this option, encountered faces are removed and replaced by faces coming from a triangulation with\nonly the existing vertices plus the vertices of the forcing lines (new vertices are also added on the boundary\nedge intersecting the forcing lines).\nFig. 17.12: Force Mesh using a line geometry - Results without (middle) and with (right) new vertex on edges\nintersection\n17.4. Editing a mesh layer617\n\nQGIS Desktop 3.22 User Guide\n•Interpolate Z value from: set how the new vertices Z value is calculated. It can be from:\n–theMeshitself: the new vertices Z value is interpolated from vertices of the face they fall within\n–or theForcing line: if the line is defined by a 3D vector feature or a drawn line then the new vertices Z\nvalue is derived from its geometry. In case of 2D line feature, the new vertices Z value is theVertex Z\nvalue.\n•Tolerance: when an existing mesh vertex is closer to the line than the tolerance value, do not create new vertex\non the line but use the existing vertex instead. The value can be set inMeters at Scaleor inMap Units(more\ndetails atUnit Selector).\n17.4.5Reindexing meshes\nDuring edit, and in order to allow quick undo/redo operations, QGIS keeps empty places for deleted elements, which\nmay lead to growing memory use and inefficient mesh structuring. TheMesh►Reindex Faces and Vertices\ntool is designed to remove these holes and renumber the indices of faces and vertices so that they are continuous\nand somewhat reasonably ordered. This optimizes relation between faces and vertices and increases the efficiency of\ncalculation.\nNote:TheReindex Faces and Verticestool saves the layer and clear the undo/redo stacks, disabling any rollback.\n17.5Mesh Calculator\nTheMesh Calculatortool from the topMeshmenu allows you to perform arithmetic and logical calculations on\nexisting dataset groups to generate a new dataset group (see\nFig. 17.13).\n618Chapter 17. Working with Mesh Data\n\nQGIS Desktop 3.22 User Guide\nFig. 17.13: Mesh Calculator\nTheDatasetslist contains all dataset groups in the active mesh layer. To use a dataset group in an expression, double\nclick its name in the list and it will be added to theMesh calculator expressionfield. You can then use the operators\nto construct calculation expressions, or you can just type them into the box.\nTheResult Layerhelps you configure properties of the output layer:\n•Create on-the-fly dataset group instead of writing layer to disk:\n–If unchecked, the output is stored on disk as a new plain file. AnOutput Filepath and anOutput Format\nare required.\n–If checked, a new dataset group will be added to the mesh layer. Values of the dataset group are not stored\nin memory but each dataset is calculated when needed with the formula entered in the mesh calculator.\nThat virtual dataset group is saved with the project, and if needed, it can be removed or made persistent\nin file from the layerSourceproperties tab.\nIn either case, you should provide aGroup Namefor the output dataset group.\n•TheSpatial extentto consider for calculation can be:\n–aCustom extent, manually filled with theX min,X max,Y minandY maxcoordinate, or extracted from\nan existing dataset group (select it in the list and pressUse selected layer extentto fill the abovementioned\n17.5. Mesh Calculator619\n\nQGIS Desktop 3.22 User Guide\ncoordinate fields)\n–defined by a polygon layer (Mask layer) of the project: the polygon features geometry are used to clip the\nmesh layer datasets\n•TheTemporal extentto take into account for datasets can be set with theStart timeandEnd timeoptions,\nselected from the existing dataset groups timesteps. They can also be filled using theUse all selected dataset\ntimesbutton to take the whole range.\nTheOperatorssection contains all available operators. To add an operator to the mesh calculator expression box, click\nthe appropriate button. Mathematical calculations (+,-,*, ... ) and statistical functions (min,max,sum (aggr),\naverage (aggr), ... ) are available. Conditional expressions (=,!=,<,>=,IF,AND,NOT, ... ) return either 0\nfor false and 1 for true, and therefore can be used with other operators and functions. TheNODATAvalue can also\nbe used in the expressions.\nTheMesh Calculator Expressionwidget shows and lets you edit the expression to execute.\n620Chapter 17. Working with Mesh Data\n\nCHAPTER\nEIGHTEEN\nWORKING WITH VECTOR TILES\n18.1What are Vector Tiles?\nVector tiles are packets of geographic data, packaged into pre-defined roughly-square shaped “tiles” for transfer over\nthe web. They combine pre-rendered raster map tiles and vector map tiles. The vector tile server returns vector\nmap data, which has been clipped to the boundaries of each tile, instead of a pre-rendered map image. The clipped\ntiles represent the zoom-levels of the vector tile service, derived from a pyramid approach. Using this structure, the\ndata-transfer is reduced in comparison to un-tiled vector maps. Only data within the current map view, and at the\ncurrent zoom level need to be transferred. Also, compared to a tiled raster map, data transfer is also greatly reduced,\nas vector data is typically much smaller than a rendered bitmap. Vector tiles do not have any styling information\nassigned so QGIS needs to apply a cartographic style in order to display the data.\n621\n\nQGIS Desktop 3.22 User Guide\nFig. 18.1: Pyramid structure of vector tiles with zoom-levels\n18.2Supported Formats\nThere is support for vector tiles through:\n•remotesources(HTTP/S)-withXYZtemplate-type=xyz&url=http://example.com/{z}/{x}/\n{y}.pbf\n•local files - with XYZ template - e.g.type=xyz&url=file:///path/to/tiles/{z}/{x}/{y}.\npbf\n•local MBTiles database - e.g.type=mbtiles&url=file:///path/to/file.mbtiles\nTo load a vector tiles dataset into QGIS, use theVector Tiletab in theData Source Managerdialog. ReadUsing\nVector Tiles services\nfor more details.\n622Chapter 18. Working with Vector Tiles\n\nQGIS Desktop 3.22 User Guide\n18.3Vector Tiles Dataset Properties\n18.3.1Information Properties\nTheInformationtab is read-only and represents an interesting place to quickly grab summarized information and\nmetadata on the current layer. Provided information are:\n•based on the provider of the layer: name, URI, source type and path, number of zoom levels\n•the Coordinate Reference System: name, units, method, accuracy, reference (i.e. whether it’s static or dynamic)\n•picked from thefilled metadata: access, extents, links, contacts, history...\n18.3.2Symbology and Label Properties\nFig. 18.2: Vector Tile Layer Symbology\nAs vector tiles consist of point, line and polygon geometries, the respective symbols are available. To apply a carto-\ngraphic style you need to use aStyle URLwhen creating theVector Tiles Connection. The symbology will be shown\nimmediately in theSymbologytab after clicking theOKbutton.\nTo create your own cartographic style you can define a set ofrulesfor features and apply style and label. InFig. 18.2\nwe set up style and labeling for the OpenStreetMaplanduselayer. The settings are made for the classsuburb\nhere. For better visibility most of the rules are deselected.\nAt the bottom theCurrent Zoomis shown. Check theVisible rules onlyoption to filter the list of rules to only those that\nare visible at the given zoom level. This makes it easier to work with complex vector styling and to locate troublesome\nrules. Style and labelling can be dependent on the zoom level.\nThere is also the option to import styles. Those styles can be supplied as:\n•QMLfiles (QML - The QGIS Style File Format)\n•MapBox GL Jsonstyle configuration files\n18.3. Vector Tiles Dataset Properties623\n\nQGIS Desktop 3.22 User Guide\n18.3.3Metadata Properties\nTheMetadatatab provides you with options to create and edit a metadata report on your layer. SeeMetadatafor\nmore information.\n624Chapter 18. Working with Vector Tiles\n\nCHAPTER\nNINETEEN\nLAYING OUT THE MAPS\nWith Print Layouts and Reports you can create maps and atlases, and print them or save them as image, PDF or SVG\nfiles.\n19.1Overview of the Print Layout\nThe print layout provides growing layout and printing capabilities. It allows you to add elements such as the QGIS\nmap canvas, text labels, images, legends, scale bars, basic shapes, arrows, attribute tables and HTML frames. You\ncan size, group, align, position and rotate each element and adjust their properties to create your layout. The layout\ncan be printed or exported to image formats, PostScript, PDF or to SVG. You can save the layout as a template and\nload it again in another session. Finally, generating several maps based on a template can be done through the atlas\ngenerator.\n19.1.1Sample Session for beginners\nBefore you start to work with the print layout, you need to load some raster or vector layers in the QGIS map canvas\nand adapt their properties to suit your own convenience. After everything is rendered and symbolized to your liking,\nclick the\nNew Print Layout\nicon in the toolbar or chooseFile►New Print Layout. You will be prompted to choose a\ntitle for the new layout.\nTo demonstrate how to create a map please follow the next instructions.\n1.On the left side, select the\nAdd map\ntoolbar button and draw a rectangle on the canvas holding down the left\nmouse button. Inside the drawn rectangle the QGIS map view to the canvas.\n2.Select the\nAdd scalebar\ntoolbar button and click with the left mouse button on the print layout canvas. A\nscalebar will be added to the canvas.\n3.Select the\nAdd legend\ntoolbar button and draw a rectangle on the canvas holding down the left mouse button.\nInside the drawn rectangle the legend will be drawn.\n4.Select the\nSelect/Move item\nicon to select the map on the canvas and move it a bit.\n5.While the map item is still selected you can also change the size of the map item. Click while holding down\nthe left mouse button, in a white little rectangle in one of the corners of the map item and drag it to a new\nlocation to change its size.\n6.Click theItem Propertiespanel on the left down side and find the setting for the orientation. Change the value\nof the settingMap orientationto ‘15.00° ‘. You should see the orientation of the map item change.\n7.Now, you can print or export your print layout to image formats, PDF or to SVG with the export tools inLayout\nmenu.\n8.Finally, you can save your print layout within the project file with the\nSave Project\nbutton.\n625\n\nQGIS Desktop 3.22 User Guide\nYou can add multiple elements to the print layout. It is also possible to have more than one map view or legend or\nscale bar in the print layout canvas, on one or several pages. Each element has its own properties and, in the case of\nthe map, its own extent. If you want to remove any elements from the layout canvas you can do that with theDelete\nor theBackspacekey.\n19.1.2The Layout Manager\nTheLayout Manageris the main window to manage print layouts in the project. It gives you an overview of existing\nprint layouts and reports in the project and offers tools to:\n•search for a layout;\n•add new print layout or new report from scratch, template or duplicating an existing one;\n•rename or delete any of them;\n•open them in the project.\nTo open the layout manager dialog:\n•from the main QGIS dialog, selectProject►Layout Manager...menu or click on the\nLayout Manager\nbutton\nin theProject Toolbar;\n•from a print layout or report dialog, selectLayout►Layout Manager...menu or click on the\nLayout Manager\nbutton in theLayout Toolbar.\nFig. 19.1: The Print Layout Manager\nThe layout manager lists in its upper part all the available print layouts or reports in the project with tools to:\n•show the selection: you can select multiple reports and/or print layout(s) and open them in one-click. Double-\nclick a name also opens it;\n•duplicate the selected print layout or report (available only if one item is selected): it creates a new dialog using\nthe selected one as template. You’ll be prompted to choose a new title for the new layout;\n•rename the report or layout (available only if one item is selected): you’ll be prompted to choose a new title\nfor the layout;\n•remove the layout: the selected print layout(s) will be deleted from the project.\nIn the lower part, it’s possible to create new print layouts or reports from scratch or a template. By default, QGIS will\nlook for templates in the user profile and the application template directories (accessible with the two buttons at the\nbottom of the frame) but also in any folder declared asPath(s) to search for extra print templatesinSettings►Options\n626Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n►Layouts. Found templates are listed in the combobox. Select an item and press theCreatebutton to generate a new\nreport or print layout.\nYou can also use layout templates from a custom folder; in that case, selectspecificin the templates drop-down list,\nbrowse to the template and pressCreate.\nTip: Creating template-based print layouts from Browser panel\nDrag-and-drop a print layout template.qptfile from any file browser onto the map canvas or double-click it in the\nBrowser panelgenerates a new print layout from the template.\n19.1.3Menus, tools and panels of the print layout\nOpening the print layout provides you with a blank canvas that represents the paper surface when using the print\noption. Initially you find buttons on the left beside the canvas to add print layout items: the current QGIS map\ncanvas, text labels, images, legends, scale bars, basic shapes, arrows, attribute tables and HTML frames. In this\ntoolbar you also find buttons to navigate, zoom in on an area and pan the view on the layout a well as buttons to select\nany layout item and to move the contents of the map item.\nFig. 19.2shows the initial view of the print layout before any elements are added.\nFig. 19.2: Print Layout\nOn the right beside the canvas you find two set of panels. The upper one holds the panelsItemsandUndo Historyand\nthe lower holds the panelsLayout,Item propertiesandAtlas generation.\n•TheItemspanel provides a list of all the print layout items added to the canvas and ways to globally interact\nwith them (seeThe Items Panelfor more information).\n•TheUndo Historypanel displays a history of all changes applied to the layout. With a mouse click, it is possible\nto undo and redo layout steps back and forth to a certain status.\n•TheLayoutpanel allows you to set general parameters to apply to the layout when exporting or working within\n(see\nThe Layout Panelfor more details);\n19.1. Overview of the Print Layout627\n\nQGIS Desktop 3.22 User Guide\n•TheItem Propertiespanel displays the properties for the selected item. Click the\nSelect/Move item\nicon to select\nan item (e.g., legend, scale bar or label) on the canvas. Then click theItem Propertiespanel and customize the\nsettings for the selected item (seeLayout Itemsfor detailed information on each item settings).\n•TheAtlaspanel allows you to enable the generation of an atlas for the current layout and gives access to its\nparameters (seeGenerate an Atlasfor detailed information on atlas generation usage).\nIn the bottom part of the print layout window, you can find a status bar with mouse position, current page number, a\ncombo box to set the zoom level, the number of selected items if applicable and, in the case of atlas generation, the\nnumber of features.\nIn the upper part of the print layout window, you can find menus and other toolbars. All print layout tools are available\nin menus and as icons in a toolbar.\nThe toolbars and the panels can be switched off and on using the right mouse button over any toolbar or throughView\n►Toolbars► orView►Panels►.\nMenus and Tools\nLayout menu\nTheLayoutprovides action to manage the layout:\n•Save the project file directly from the print layout window.\n•Create a new and blank print layout withNew Layout....\n•Duplicate Layout...: Create a new print layout by duplicating the current one.\n•Remove the current layout withDelete Layout....\n•Open theLayout Manager....\n•Layouts► : Open an existing print layout.\nOnce the layout is designed, with\nSave as TemplateandAdd Items from Templateicons, you can save the\ncurrent state of a print layout session as a.qpttemplate file and load its items again in another session/print layout.\nIn theLayoutmenu, there are also powerful ways to share geographical information produced with QGIS that can be\nincluded in reports or published. These tools areExport as Image...,Export as PDF...,Export as SVG...\nandPrint....\nBelow is a list of all the available tools in this menu with some convenient information.\n628Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nToolShortcutToolbarReference\nSave ProjectCtrl+SLayoutIntroducing QGIS projects\nNew LayoutCtrl+NLayoutThe Layout Manager\nDuplicate LayoutLayoutThe Layout Manager\nDelete Layout\nLayout Manager...LayoutThe Layout Manager\nLayouts►\nLayout Properties...The Layout Panel\nRename Layout...\nAdd Pages...LayoutWorking with the page properties\nAdd Items from TemplateLayoutCreating a layout item\nSave as Template...LayoutThe Layout Manager\nExport as Image...LayoutExport as Image\nExport as SVG...LayoutExport as SVG\nExport as PDF...LayoutExport as PDF\nPage Setup...Ctrl+Shift+P\nPrint...Ctrl+PLayoutCreating an Output\nCloseCtrl+Q\nEdit menu\nTheEditmenu offers tools to manipulate print layout items.  It includes common actions like selection tools,\nCopy/Cut/Paste and undo/redo (seeThe Undo History Panel: Revert and Restore actions) functionality for the items\nin the layout.\nWhen using the Paste action, the elements will be pasted according to the current mouse position. Using theEdit►\nPaste in Placeaction or pressingCtrl+Shift+Vwill paste the items into the current page, at the same position\nthey were in their initial page. It ensures to copy/paste items at the same place, from page to page.\nBelow is a list of all the available tools in this menu with some convenient information.\n19.1. Overview of the Print Layout629\n\nQGIS Desktop 3.22 User Guide\nTable 19.1: Available Tools\nToolShortcutToolbarReference\nUndo (last change)Ctrl+ZLayoutThe Undo History Panel: Revert and Re-\nstore actions\nRedo (last reverted change)Ctrl+YLayoutThe Undo History Panel: Revert and Re-\nstore actions\nDeleteDel\nCutCtrl+X\nCopyCtrl+C\nPasteCtrl+V\nPaste in placeCtrl+Shift+V\nSelect AllCtrl+A\nDeselect allCtrl+Shift+A\nInvert Selection\nSelect Next Item BelowCtrl+Alt+[\nSelect Next Item aboveCtrl+Alt+]\nPan LayoutPToolbox\nZoomZToolbox\nSelect/Move ItemVToolboxInteracting with layout items\nMove ContentCToolboxThe Map Item\nEdit Nodes ItemToolboxThe Node-Based Shape Items\nView menu\nTheViewmenu gives access to navigation tools and helps to configure general behavior of the print layout. Beside\nthe common zoom tools, you have means to:\n•\nRefresh view\n(if you find the view in an inconsistent state);\n•enable agridyou could snap items to when moving or creating them. Grids setting is done inSettings►Layout\nOptions...or in the\nLayout Panel;\n•enableguidesyou could snap items to when moving or creating them. Guides are red lines that you can create\nby clicking in the ruler (above or at the left side of the layout) and drag and drop to the desired location;\n•Smart Guides: uses other layout items as guides to dynamically snap to as you move or reshape an item;\n•Clear Guidesto remove all current guides;\n•Show Bounding boxaround the items to better identify your selection;\n•Show Rulesaround the layout;\n•Show Pagesor set up pages to transparent. Often layout is used to create non-print layouts, e.g. for inclusion\nin presentations or other documents, and it’s desirable to export the composition using a totally transparent\nbackground. It’s sometimes referred to as “infinite canvas” in other editing packages.\nIn the print layout, you can change the zoom level using the mouse wheel or the slider and combo box in the status\nbar. If you need to switch to pan mode while working in the layout area, you can hold theSpacebaror the mouse\nwheel. WithCtrl+Spacebar, you can temporarily switch to Zoom In mode, and withCtrl+Alt+Spacebar,\nto Zoom Out mode.\n630Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nPanels and toolbars can be enabled from theView► menu. To maximise the space available to interact with a\ncomposition you can check theView►Toggle Panel Visibilityoption or pressCtrl+Tab; all panels are hidden\nand only previously visible panels are restored when unchecked.\nIt’s also possible to switch to a full screen mode to have more space to interact with by pressingF11or usingView\n►Toggle Full Screen.\nToolShortcutToolbarReference\nRefreshF5Navigation\nPreview►\nZoom InCtrl++Navigation\nZoom OutCtrl+-Navigation\nZoom to 100%Ctrl+1Navigation\nZoom FullCtrl+0Navigation\nZoom to Width\nShow GridCtrl+'Guides and Grid\nSnap to GridCtrl+Shift+'Guides and Grid\nShow GuidesCtrl+;Guides and Grid\nSnap to GuidesCtrl+Shift+;Guides and Grid\nSmart GuidesCtrl+Alt+;\nManage Guides...The Guides Panel\nClear GuidesThe Guides Panel\nShow RulersCtrl+R\nShow Bounding BoxesCtrl+Shift+B\nShow Pages\nToolbars►Panels and Toolbars\nPanels►Panels and Toolbars\nToggle Full ScreenF11View\nToggle Panel VisibilityCtrl+TabView\n19.1. Overview of the Print Layout631\n\nQGIS Desktop 3.22 User Guide\nItems menu\nTheItemshelps you configure items’ position in the layout and the relations between them (seeInteracting with layout\nitems).\nToolShortcutToolbarReference\nGroupCtrl+GActionsGrouping items\nUngroupCtrl+Shift+GActionsGrouping items\nRaiseCtrl+]ActionsAlignment\nLowerCtrl+[ActionsAlignment\nBring to FrontCtrl+Shift+]ActionsAlignment\nSend to BackCtrl+Shift+[ActionsAlignment\nLock Selected ItemsCtrl+LActionsLocking items\nUnlock AllCtrl+Shift+LActionsLocking items\nAlign Items►ActionsAlignment\nDistribute Items►ActionsMoving and resizing items\nResize►ActionsMoving and resizing items\nAdd Item menu\nThese are tools to create layout items. Each of them is deeply described inLayout Itemschapter.\n632Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nToolToolbarReference\nAdd MapToolboxThe Map Item\nAdd 3D MapToolboxThe 3D Map Item\nAdd PictureToolboxThe Picture Item\nAdd LabelToolboxThe Label Item\nAdd Dynamic Text►The Label Item\nAdd LegendToolboxThe Legend Item\nAdd Scale BarToolboxThe Scale Bar Item\nAdd North ArrowToolboxThe North Arrow Item\nAdd Shape►ToolboxThe Regular Shape Item\n►Add RectangleToolboxThe Regular Shape Item\n►Add EllipseToolboxThe Regular Shape Item\n►Add TriangleToolboxThe Regular Shape Item\nAdd MarkerToolbox\nAdd ArrowToolboxThe Arrow Item\nAdd Node Item►ToolboxThe Node-Based Shape Items\n►Add PolygonToolboxThe Node-Based Shape Items\n►Add PolylineToolboxThe Node-Based Shape Items\nAdd HTMLToolboxThe HTML Frame Item\nAdd Attribute TableToolboxThe attribute table item\nAdd Fixed TableToolboxThe fixed table item\nAtlas menu\nToolShortcutToolbarReference\nPreview AtlasCtrl+ALt+/AtlasPreview and generate an atlas\nFirst FeatureCtrl+<AtlasPreview and generate an atlas\nPrevious FeatureCtrl+,AtlasPreview and generate an atlas\nNext FeatureCtrl+.AtlasPreview and generate an atlas\nLast featureCtrl+>AtlasPreview and generate an atlas\nPrint Atlas...AtlasPreview and generate an atlas\nExport Atlas as Images...AtlasPreview and generate an atlas\nExport Atlas as SVG...AtlasPreview and generate an atlas\nExport Atlas as PDF...AtlasPreview and generate an atlas\nAtlas SettingsAtlasGenerate an Atlas\n19.1. Overview of the Print Layout633\n\nQGIS Desktop 3.22 User Guide\nSettings Menu\nTheSettings►Layout Options...menu is a shortcut toSettings►Options►Layoutsmenu of QGIS main canvas.\nHere, you can set some options that will be used as default on any new print layout:\n•Layout defaultslet you specify the default font to use;\n•WithGrid appearance, you can set the grid style and its color. There are three types of grid:Dots,Solidlines\nandCrosses;\n•Grid and guide defaultsdefines spacing, offset and tolerance of the grid (seeGuides and Gridfor more details);\n•Layout Paths: to manage list of custom paths to search print templates.\nContextual menus\nDepending on where you right-click in the print layout dialog, you open a contextual menu with various features:\n•Right-click on the menu bar or any toolbar and you get the list of layout panels and toolbars you can enable or\ndisable in one-click.\n•Right-click over a ruler and you canShow Guides,Snap to Guides,Manage Guides...opening theGuides\npanelorClear Guides. It’s also possible to hide the rulers.\n•Right-click in the print layout canvas and:\n–You’ll be able toUndoandRedorecent changes, orPasteany copied item (only available if no item is\nselected).\n–If you click over a page, you can additionally access the currentPage Propertiespanel orRemove Page.\n–If you click on a selected item then you can cut or copy it as well as open theItem Propertiespanel.\n–If more than one item are selected, then you can either group them and/or ungroup if at least one group\nis already in the selection.\n•Right-click inside a text box or spinbox widget of any layout panel provides edit options to manipulate its\ncontent.\n634Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nThe Layout Panel\nIn theLayoutpanel, you can define the global settings of your print layout.\nFig. 19.3: Layout Settings in the Print Layout\nGeneral settings\nIn a print layout, you can use more than one map item. TheReference maprepresents the map item to use as the\nlayout’s master map. It’s assigned as long as there’s a map item in the layout. The layout will use this map in any\nof their properties and variables calculating units or scale. This includes exporting the print layout to georeferenced\nformats.\nMoreover, new layout items such as scale bar, legend or north arrow have by default their settings (orientation,\ndisplayed layers, scale, ...) bound to the map item they are drawn over, and fall back to the reference map if no\noverlapping map.\n19.1. Overview of the Print Layout635\n\nQGIS Desktop 3.22 User Guide\nGuides and Grid\nYou can put some reference marks on your paper sheet to help you accurately place some items. These marks can\nbe:\n•simple horizontal or vertical lines (calledGuides) put at the position you want (seeThe Guides Panelfor guides\ncreation).\n•or regularGrid: a network of horizontal and vertical lines superimposed over the layout.\nSettings likeGrid spacingorGrid offsetcan be adjusted in this group as well as theSnap toleranceto use for items.\nThe tolerance is the maximum distance below which the mouse cursor is snapped to a grid or a guide, while moving,\nresizing or creating an item.\nWhether grid or guides should be shown is set inViewmenu. There, you can also decide if they might be used to\nsnap layout items. When both a grid line and a guide line are within tolerance of a point, guides will always take\nprecedence - since they have been manually set (hence, assumption that they have been explicitly placed at highly\ndesirable snapping locations, and should be selected over the general grid).\nNote:In theSettings►Layout Optionsmenu, you can also set the grid and guides parameters exposed above.\nHowever, these options will only apply as defaults to new print layouts.\nExport settings\nYou can define a resolution to use for all exported maps inExport resolution. This setting can then be overridden each\ntime you export a map.\nBecause of some advanced rendering options (\nblending mode,effects...), a layout item may need rasterization in order\nto be exported correctly. QGIS will individually rasterize it without forcing every other item to also be rasterized.\nThis allows printing or saving as PostScript or PDF to keep items as much as possible as vectors, e.g. a map item\nwith layer opacity won’t force labels, scale bars, etc to be rasterized too. You can however:\n•force all the items to be rasterized checking thePrint as rasterbox;\n•or use the opposite option, i.e.Always export as vectors, to force the export to keep items as vectors when\nexported to a compatible format. Note that in some cases, this could cause the output to look different to\nlayout.\nWhere the format makes it possible (e.g.,.TIF,.PDF) exporting a print layout results by default in a georeferenced\nfile (based on theReference mapitem in theGeneral settingsgroup). For other formats, georeferenced output requires\nyou to generate a world file by checking\nSave world file. The world file is created beside the exported map(s), has\nthe name of the page output with the reference map item and contains information to georeference it easily.\nResize layout to content\nUsing theResize pagetool in this group, you create a unique page composition whose extent covers the current contents\nof the print layout (with some optionalmarginsaround the cropped bounds).\nNote that this behavior is different from the\ncrop to contentoption in that all the items are placed on a real and unique\npage in replacement of all the existing pages.\n636Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nVariables\nTheVariableslists all the variables available at the layout’s level (which includes all global and project’s variables).\nIt also allows the user to manage layout-level variables. Click thebutton to add a new custom layout-level variable.\nLikewise, select a custom layout-level variable from the list and click thebutton to remove it.\nMore information on variables usage in theGeneral Toolssection.\nFig. 19.4: Variables Editor in the Print Layout\nWorking with the page properties\nA layout can be composed of several pages. For instance, a first page can show a map canvas, and a second page can\nshow the attribute table associated with a layer, while a third one shows an HTML frame linking to your organization\nwebsite. Or you can add many types of items on each page.\nAdding a new page\nFuthermore, a layout can be made using different size and/or orientation of pages. To add a page, select theAdd\nPages...tool from theLayoutmenu orLayout Toolbar. TheInsert Pagesdialog opens and you are asked to fill:\n•the number of pages to insert;\n•the position of the page(s): before or after a given page or at the end of the print layout;\n•ThePage size: it could be of a preset format page (A4,B0,Legal,Letter,ANSI A,Arch Aand\ntheir derivatives as well as a resolution type, such as1920x1080or1024x768) with associatedOrientation\n(Portrait or Landscape).\nThe page size can also be of acustomformat; In that case, you’d need to enter itsWidthandHeight(with\nlocked size ratio if needed) and select the unit to use amongmm,cm,px,pt,in,ft... Conversion of entered\nvalues is automatically applied when switching from one unit to another.\n19.1. Overview of the Print Layout637\n\nQGIS Desktop 3.22 User Guide\nFig. 19.5: Creating a new page in the Print Layout\nUpdating page properties\nAny page can be later customized through the PageItem Propertiespanel. To access a page’s properties, left-click on\nan empty section of the page or right-click on a page and selectPage Properties.... TheItem Propertiespanel opens\nwith settings such as:\n•thePage sizeframe described above. You can modify each property using the data defined override options\n(see\nExplore Data-defined override buttons with atlasfor a use case);\n•theExclude page from exportsto control whether the current page with its content should be included in\nthelayout output;\n•theBackgroundof the current page using thecolororsymbolyou want.\nFig. 19.6: Page properties dialog\n638Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nThe Guides Panel\nGuides are vertical or horizontal line references you can place on a layout page to assist you on items placement, when\ncreating, moving or resizing them. To be active, guides require theView►Show GuidesandView►Snap to Guides\noptions to be checked. To create a guide, there are two different methods:\n•if theView►Show Rulersoption is set, drag out a ruler and release the mouse button within the page area, at\nthe desired position.\n•for more precision, use theGuidespanel from theView►Toolbox► or by selectingManage guides for page...\nfrom the page’s contextual menu.\nFig. 19.7: The Guides panel\nTheGuidespanel allows creation of snap lines at specific locations:\n1.Select thePageyou’d like to add the guides to\n2.Click the\nAdd new guide\nbutton and enter the coordinates of the horizontal or vertical line. The origin is at the\ntop left corner. Different units are available for this.\nThe panel also allows adjusting the position of existing guides to exact coordinates: double-click and replace\nthe value.\n3.TheGuidespanel lists only the items for the current page. It allows creation or removal of guides only in the\ncurrent page. However, you can use theApply to All Pagesbutton to replicate the guide configuration of the\ncurrent page to the other pages in the layout.\n4.To delete a guide, select it and press the\nRemove selected guide\nbutton. UseClear All Guidesto remove all the\nguides in the current page.\nTip: Snapping to existing layout items\n19.1. Overview of the Print Layout639\n\nQGIS Desktop 3.22 User Guide\nOther than guides and grids, you can use existing items as snapping references when moving, resizing or creating new\nitems; these are calledsmart guidesand requireView►Smart Guidesoption to be checked. Anytime the mouse\npointer is close to an item’s bound, a snapping cross appears.\nThe Items Panel\nTheItemspanel offers some options to manage selection and visibility of items. All the items added to the print layout\ncanvas (includingitems group) are shown in a list and selecting an item makes the corresponding row selected in the\nlist as well as selecting a row does select the corresponding item in the print layout canvas. This is thus a handy way\nto select an item placed behind another one. Note that a selected row is shown as bold.\nFor any selected item, you can :\n•set it visible or not;\n•lock or unlock its position;\n•sort its Z position. You can move up and down each item in the list with a click and drag. The upper item in\nthe list will be brought to the foreground in the print layout canvas. By default, a newly created item is placed\nin the foreground.\n•change the item ID by double-clicking the text;\n•right-click an item and copy or delete it or open itsproperties panel.\nOnce you have found the correct position for an item, you can lock it by ticking the box incolumn. Locked\nitems arenotselectable on the canvas. Locked items can be unlocked by selecting the item in theItemspanel and\nunchecking the tickbox or you can use the icons on the toolbar.\nThe Undo History Panel: Revert and Restore actions\nDuring the layout process, it is possible to revert and restore changes. This can be done with the revert and restore\ntools available in theEditmenu, theLayouttoolbar or the contextual menu any time you right-click in the print layout\narea:\n•\nRevert last change\n•\nRestore last change\nThis can also be done by mouse click within theUndo historypanel (seeFig. 19.8). The History panel lists the last\nactions done within the print layout. Just select the point you want to revert to and once you do new action all the\nactions done after the selected one will be removed.\nFig. 19.8: Undo History in the Print Layout\n640Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n19.2Layout Items\n19.2.1Layout Items Common Options\nQGIS provides a large set of items to layout a map. They can be of map, legend, scale bar, picture, table, north arrow,\nimage type... They however share some common options and behavior that are exposed below.\nCreating a layout item\nItems can be created using different tools, either from scratch or based on existing items.\nTo create a layout item from scratch:\n1.Select the corresponding tool either from theAdd Itemmenu or theToolboxbar.\n2.Then:\n•Click on the page and fill the size and placement information requested in theNew Item Propertiesdialog\nthat pops up (for details, seePosition and Size);\nFig. 19.9: New Item properties dialog\n•Or click-and-drag to define the initial size and placement of the item. You can rely ongrids and guides\nsnapping for a better position.\nNote:Because they can have particular shapes, drawing node or arrow items does not work with one-click nor\nclick-and-drag methods; you need to click and place each node of the item. See\nThe Node-Based Shape Itemsfor\nmore details.\nYou can also:\n1.Select an existing item with the\nSelect/Move item\nbutton from theToolboxtoolbar\n2.Use the contextual menu or theEditmenu tools to copy/cut the item and paste it at the mouse position as a\nnew item.\nYou can also use thePaste in Place(Ctrl+Shift+V) command to duplicate an item from one page to another\nand place it in the new page at the same coordinates as the original.\nMoreover, you can create items using a print layout template (for details, see\nThe Layout Manager) through theLayout\n►Add Items from Template...command.\nTip: Add layout items using the file browser\n19.2. Layout Items641\n\nQGIS Desktop 3.22 User Guide\nFrom your file browser or using theBrowserpanel, drag-and-drop a print layout template (.qptfile) onto a print\nlayout dialog and QGIS automatically adds all items from that template to the layout.\nInteracting with layout items\nEach item inside the print layout can be moved and resized to create a perfect layout. For both operations the first\nstep is to activate the\nSelect/Move item\ntool and click on the item.\nYou can select multiple items with the\nSelect/Move item\nbutton: click and drag over the items or hold theShift\nbutton and click on each of the items you want. To deselect an item, click on it holding theShiftbutton.\nEach time there’s a selection, count of selected items is displayed on the status bar. Inside theEditmenu, you can\nfind actions to select all the items, clear all selections, invert the current selection and more...\nMoving and resizing items\nUnlessView►Show Bounding Boxesoption is unchecked, a selected item will show squares on its boundaries ;\nmoving one of them with the mouse will resize the item in the corresponding direction. While resizing, holding\nShiftwill maintain the aspect ratio. HoldingAltwill resize from the item center.\nTo move a layout item, select it with the mouse and move while holding the left button. If you need to constrain the\nmovements to the horizontal or vertical axis, just hold theShiftbutton on the keyboard while moving the mouse.\nYou can also move a selected item using theArrow keyson the keyboard; if the movement is too slow, you\ncan speed it up by holdingShift. If you need better precision, use thePosition and sizeproperties, or grid/guides\nsnapping as explained above for item’s creation.\nResizing or moving several items at once is made the same way as for a single item. QGIS however provides some\nadvanced tools to automatically resize a selection of items following different rules:\n•each item height matches thetallest or theshortest selected item;\n•each item width matches thewidest or thenarrowest selected item;\n•resizes items tosquares: each item is enlarged to form a square.\nLikewise, automated tools are available to organize multiple items position by distributing equidistantly:\n•edges (left, right, top or bottom) of items;\n•centers of items either horizontally or vertically.\nGrouping items\nGrouping items allows you to manipulate a set of items like a single one: you can easily resize, move, delete, copy\nthe items as a whole.\nTo create a group of items, select more than one and press the\nGroupbutton on theViewmenu or theActions\ntoolbar or from the right-click menu. A row namedGroupis added to theItemspanel and can be locked or hidden\nlike any otherItems panel’s object. Grouped items arenot individuallyselectable on the canvas; use the Items panel\nfor direct selection and access the item’s properties panel.\n642Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nLocking items\nOnce you have found the correct position for an item, you can lock it by using theLock selected itemsbutton in\ntheItemsmenu or theActionstoolbar or ticking the box next to the item in theItemspanel. Locked items arenot\nselectable on the canvas.\nLocked items can be unlocked by selecting the item in theItemspanel and unchecking the tickbox or you can use the\nicons on the toolbar.\nAlignment\nRaising or lowering the visual hierarchy for elements are inside the\nRaise selected items\npull-down menu. Choose\nan element on the print layout canvas and select the matching functionality to raise or lower the selected element\ncompared to the other elements. This order is shown in theItemspanel. You can also raise or lower objects in the\nItemspanel by clicking and dragging an object’s label in this list.\nFig. 19.10: Alignment helper lines in the print layout\nThere are several alignment options available within the\nAlign selected items\npull-down menu (seeFig. 19.10). To use\nan alignment function, you first select the elements and then click on one of the alignment icons:\n•Align LeftorAlign Right;\n•Align ToporAlign Bottom;\n•Align Centerhorizontally orAlign Center Vertical.\nAll selected elements will then be aligned to their common bounding box. When moving items on the layout canvas,\nalignment helper lines appear when borders, centers or corners are aligned.\n19.2. Layout Items643\n\nQGIS Desktop 3.22 User Guide\nItems Common Properties\nLayout items have a set of common properties you will find at the bottom of theItem Propertiespanel: Position and\nsize, Rotation, Frame, Background, Item ID, Variables and Rendering (SeeFig. 19.11).\nFig. 19.11: Common Item Properties groups\nNote:The\nData defined override\nicon next to most of the options means that you can associate that property with a\nlayer, features attributes, geometry or with any other layout item’s property, using\nexpressionsorvariables. For more\ninformation seeData defined override setup.\n•ThePosition and sizegroup lets you define the size and position of the frame which contains the item (see\nPosition and Sizefor more information).\n•TheRotationsets the rotation of the element (in degrees).\n•TheFrame\nshows or hides the frame around the item. Use the\nColor\n,\nThickness\nand\nJoin style\nwidgets to\nadjust those properties.\n•Use theBackground colormenu for setting a background color. Click on the [Color...] button to display a\ndialog where you can pick a color or choose from a custom setting. Transparency can be adjusted through\naltering the alpha field settings.\n644Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n•Use theItem IDto create a relationship to other print layout items. This is used with QGIS server and other\npotential web clients. You can set an ID on an item (for example, a map or a label), and then the web client\ncan send data to set a property (e.g., label text) for that specific item. The GetProjectSettings command will\nlist the items and IDs which are available in a layout.\n•Renderingmode helps you set whether and how the item can be displayed: you can, for instance, applyblending\nmode, adjust the opacity of the item orExclude item from exports.\nPosition and Size\nExtending the features of theNew Item Propertiesdialog with data-defined capabilities, this group allows you to place\nthe items accurately.\nFig. 19.12: Position and size\n•the actual number of the page to place the item on;\n•the reference point of the item;\n•theXandYcoordinates of theReference pointof the item on the chosen page. The ratio between these values\ncan be locked by clicking on thebutton. Changes made to a value using the widget or the\nSelect/Move item\ntool will be reflected in both of them;\n•theWidthandHeightof the item bounding box. As for coordinates, the ratio between width and height can be\nlocked.\nRendering mode\nQGIS allows advanced rendering for layout items just like vector and raster layers.\nFig. 19.13: Rendering mode\n•Blending mode: With this tool you can achieve effects which would otherwise only be achieved using graphic\nrendering software. The pixels of your overlaying and underlaying items can be mixed according to the mode\nset (see\nBlending Modesfor description of each effect).\n19.2. Layout Items645\n\nQGIS Desktop 3.22 User Guide\n•Transparency: You can make the underlying item in the layout visible with this tool. Use\nthe slider to adapt the visibility of your item to your needs. You can also make a precise definition of the\npercentage of visibility in the menu beside the slider.\n•Exclude item from exports: You can decide to make an item invisible in all exports. After activating this\ncheckbox, the item will not be included in export to PDF, print etc..\nVariables\nTheVariableslists all the variables available at the layout item’s level (which includes all global, project and compo-\nsition’s variables). Map items also include Map settings variables that provide easy access to values like the map’s\nscale, extent, and so on.\nInVariables, it’s also possible to manage item-level variables. Click thebutton to add a new custom variable.\nLikewise, select any custom item-level variable from the list and click thebutton to remove it.\nMore information on variables usage in theStoring values in Variablessection.\n19.2.2The Map Item\nThe map item is the main frame that displays the map you’ve designed in the map canvas. Use theAdd Maptool\nfollowing\nitems creation instructionsto add a new map item that you can later manipulate the same way as exposed in\nInteracting with layout items.\nBy default, a new map item shows the current status of the\nmap canvaswith its extent and visible layers. You can\ncustomize it thanks to theItem Propertiespanel. Other than theitems common properties, this feature has the following\nfunctionalities:\n646Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.14: Map Item Properties Panel\nThe Toolbar\nThe MapItem Propertiespanel embeds a toolbar with the following functionalities:\n•\nUpdate map preview\n•\nSet map canvas to match main canvas extent\n•\nView current map extent in main canvas\n•\nSet map scale to match main canvas scale\n•\nSet main canvas to match current map scale\n•\nBookmarks\n: set the map item extent to match an existing spatial bookmark\n•\nInteractively edit map extent\n: pan and zoom interactively within the map item\n•\nLabeling settings\n: control feature label behaviour (placement, visibility...) in the layout map item extent:\n–set aMargin from map edges, a data definable distance from the map item’s limits inside which no label\nshould be displayed\n–Allow truncated labels on edges of map: controls whether labels which fall partially outside of the\nmap item allowed extent should be rendered. If checked, these labels will be shown (when there’s no way\nto place them fully within the visible area). If unchecked then partially visible labels will be skipped.\n19.2. Layout Items647\n\nQGIS Desktop 3.22 User Guide\n–Label blocking items: allows other layout items (such as scalebars, north arrows, inset maps, etc) to be\nmarked as a blockers for the map labels in theactivemap item. This prevents any map labels from being\nplaced under those items - causing the labeling engine to either try alternative placement for these labels\nor discard them altogether.\nIf aMargin from map edgesis set, the map labels are not placed closer than the specified distance from\nthe checked layout items.\n–Show unplaced labels: can be used to determine whether labels are missing from the layout map (e.g. due\nto conflicts with other map labels or due to insufficient space to place the label) by highlighting them in\napredefined color.\n•\nClipping settings\n: allows to clip the map item to the atlas feature and to shape and polygon items:\n–Clip to atlas feature: you can determine that the layout map item will be clipped automatically to the\ncurrentatlas feature.\nThere are different clipping modes available:\n∗Clip During Render Only: applies a painter based clip, so that portions of vector features which sit\noutside the atlas feature become invisible\n∗Clip Feature Before Render: applies the clip before rendering features, so borders of features which\nfall partially outside the atlas feature will still be visible on the boundary of the atlas feature\n∗Render Intersecting Features Unchanged: renders all features which intersect the current atlas feature,\nbut without clipping their their geometry.\nYou canForce labels inside atlas feature. If you don’t want toClip all layersto the atlas feature\nyou can use theClip selected layersoption.\n–Clip to item: it is possible to change the shape of the map item by using ashapeorpolygonitem from\nthe print layout. When you enable this option the map will be automatically clipped to the selected shape\nin the combobox. Again, the above mentioned clipping modes are available and labels can be forced to\ndisplay only inside the clipping shape.\nFig. 19.15: Clipping a layout map item to shapes\n648Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nMain properties\nIn theMain propertiesgroup (seeFig. 19.14) of the mapItem Propertiespanel, available options are:\n•TheUpdate Previewbutton to refresh the map item rendering if the view in map canvas has been modified.\nNote that most of the time, the map item refresh is automatically triggered by the changes;\n•TheScaleto manually set the map item scale;\n•TheMap rotationallows you to rotate the map item content clockwise in degrees. The rotation of the map\ncanvas can be imitated here;\n•TheCRSallows you to display the map item content in anyCRS. It defaults toUse project CRS;\n•Draw map canvas itemslets you show in the print layoutannotationsthat are placed on the main map\ncanvas.\nLayers\nBy default, map item appearance is synced with the map canvas rendering meaning that toggling visibility of the layers\nor modifying their style in theLayers Panelis automatically applied to the map item. Because, like any other item,\nyou may want to add multiple map items to a print layout, there’s a need to break this synchronization in order to\nallow showing different areas, layer combinations, at different scales... TheLayersproperties group (seeFig. 19.16)\nhelps you do that.\nFig. 19.16: Map Layers group\nIf you want to keep the map item consistent with an existingmap theme, checkFollow map themeand select the\ndesired theme in the drop-down list. Any changes applied to the theme in QGIS’ main window (using the replace\ntheme function) will automatically affect the map item. If a map theme is selected, theLock styles for layersoption\nis disabled becauseFollow map themealso updates the style (symbology, labels, diagrams) of the layers.\nTo lock the layers shown in a map item to the current map canvas visibility, check\nLock layers. When this\noption is enabled, any changes on the layers’ visibility in QGIS’ main window will not affect the layout’s map item.\nNevertheless, style and labels of locked layers are still refreshed according to QGIS’ main window. You can prevent\nthis by usingLock styles for layers.\nInstead of using the current map canvas, you can also lock the layers of the map item to those of an existing map\ntheme: select a map theme from the\nSet layer list from a map theme\ndrop-down button, and theLock layersis activated.\nThe set of visible layers in the map theme is from now on used for the map item until you select another map theme\nor uncheck theLock layersoption. You then may need to refresh the view using the\nRefresh view\nbutton of the\nNavigationtoolbar or theUpdate Previewbutton seen above.\nNote that, unlike theFollow map themeoption, if theLock layersoption is enabled and set to a map theme, the layers\nin the map item will not be refreshed even if the map theme is updated (using the replace theme function) in QGIS’\nmain window.\nLocked layers in the map item can also be\ndata-defined, using theicon beside the option. When used, this\noverrides the selection set in the drop-down list. You need to pass a list of layers separated by|character. The\nfollowing example locks the map item to use only layerslayer 1andlayer 2:\n19.2. Layout Items649\n\nQGIS Desktop 3.22 User Guide\nconcat ('layer 1','|','layer 2')\nExtents\nTheExtentsgroup of the map item properties panel provides the following functionalities (seeFig. 19.17):\nFig. 19.17: Map Extents group\nTheExtentsarea displaysXandYcoordinates of the area shown in the map item. Each of these values can be\nmanually replaced, modifying the map canvas area displayed and/or map item size. The extent can also be modified\nusing tools at the top of the map item panel such as:\n•\nSet map canvas to match main canvas extent\n•\nSet map scale to match main canvas scale\nYou can also alter a map item extent using the\nMove item content\ntool: click-and-drag within the map item to modify\nits current view, keeping the same scale. With thetool enabled, use the mouse wheel to zoom in or out, modifying\nthe scale of the shown map. Combine the movement withCtrlkey pressed to have a smaller zoom.\nTemporal range\nTheTemporal rangegroup of the map item properties panel provides the options to control layers rendering in the\nmap item based on a temporal range. Only layers whose temporal properties overlap with the time range set by the\nStartandEnddates are displayed in the map item.\nThe associated data-defined widgets help make the time range dynamic, and allow outputting temporal\natlases, i.e.\nautomated maps with fixed spatial extent and whose contents vary based on time. For example, using as coverage\nlayer a csv file with a start and end pair of fields and a number of rows representing date ranges, enable both the\ntemporal range and control by atlas in the map item properties and hit atlas export.\nControlled by atlas\nTheControlled by atlasgroup properties is available only if anatlasis active in the print layout. Check this option\nif you want the map item being ruled by the atlas; when iterating over the coverage layer, the map item extent is\npanned/zoomed to the atlas feature following:\n•Margin around features: zooms to the feature at the best scale, keeping around each a margin representing\na percentage of the map item width or height. The margin can be the same for all features orset variable, e.g.,\ndepending on map scale;\n•Predefined scale (best fit): zooms to the feature at the projectpredefined scalewhere the atlas feature best\nfits;\n650Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n•Fixed scale: atlas features are panned from one to another, keeping the same scale of the map item. Ideal\nwhen working with features of same size (e.g., a grid) or willing to highlight size differences among atlas\nfeatures.\nGrids\nWith grids, you can add, over your map, information relative to its extent or coordinates, either in the map item\nprojection or a different one. TheGridsgroup provides the possibility to add several grids to a map item.\n•With theandbuttons you can add or remove a selected grid;\n•With theandbuttons you can move up and down a grid in the list, hence move it on top or bottom of\nanother one, over the map item.\nDouble-click the added grid to rename it.\nFig. 19.18: Map Grids Dialog\nTo modify a grid, select it and press theModify Grid...button to open theMap Grid Propertiespanel and access its\nconfiguration options.\nGrid Appearance\nIn theMap Grid Propertiespanel, checkGrid enabledto show the grid on the map item.\nAs grid type, you can specify to use a:\n•Solid: shows a line across the grid frame. TheLine stylecan be customized usingcolorandsymbolselector\nwidget;\n•Cross: displays segment at the grid lines intersection for which you can set theLine styleand theCross width;\n•Markers: only displays customizable markers symbol at grid lines intersection;\n•orFrame and annotations only.\nOther than the grid type, you can define:\n•theCRSof the grid. If not changed, it will follow the Map CRS. TheChangebutton lets you set it to a different\nCRS. Once set, it can be changed back to default by selecting any group heading (e.gGeographic Coordinate\nSystem) underPredefined Coordinate Reference Systemsin the CRS selection dialog.\n•theIntervaltype to use for the grid references. Available options areMap Unit,Fit Segment Width,\nMillimeterorCentimeter:\n–choosingFit Segment Widthwill dynamically select the grid interval based on the map extent to\na “pretty” interval. When selected, theMinimumandMaximumintervals can be set.\n–the other options allow you to set the distance between two consecutive grid references in theXandY\ndirections.\n19.2. Layout Items651\n\nQGIS Desktop 3.22 User Guide\n•theOffsetfrom the map item edges, in theXand/or theYdirection\n•and theBlend modeof the grid (seeBlending Modes) when compatible.\nFig. 19.19: Grid Appearance Dialog\nGrid Frame\nThere are different options to style the frame that holds the map. The following options are available:No Frame,\nZebra,Zebra (nautical),Interior ticks,Exterior ticks,Interior and Exterior\nticks,Line borderandLine border (nautical).\nWhen compatible, it’s possible to set theFrame size, aFrame margin, theFrame line thicknesswith associated color\nand theFrame fill colors.\nUsingLatitude/Y onlyandLongitude/X onlyvalues in the divisions section you can prevent a mix of\nlatitude/Y and longitude/X coordinates showing on each side when working with rotated maps or reprojected grids.\nAlso you can choose to set visible or not each side of the grid frame.\n652Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.20: Grid Frame Dialog\nCoordinates\nTheDraw coordinatescheckbox allows you to add coordinates to the map frame. You can choose the annotation\nnumeric format, the options range from decimal to degrees, minute and seconds, with or without suffix, aligned or\nnot and a custom format using the expression dialog.\nYou can choose which annotation to show. The options are: show all, latitude only, longitude only, or disable(none).\nThis is useful when the map is rotated. The annotation can be drawn inside or outside the map frame. The annotation\ndirection can be defined as horizontal, vertical ascending or vertical descending.\nFinally, you can define the annotation font, font color, distance from the map frame and the precision of the drawn\ncoordinates.\n19.2. Layout Items653\n\nQGIS Desktop 3.22 User Guide\nFig. 19.21: Grid Draw Coordinates dialog\nOverviews\nSometimes you may have more than one map in the print layout and would like to locate the study area of one map\nitem on another one. This could be for example to help map readers identify the area in relation with its larger\ngeographic context shown in the second map.\nTheOverviewsgroup of the map panel helps you create the link between two different maps extent and provides the\nfollowing functionalities:\n654Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.22: Map Overviews group\nTo create an overview, select the map item on which you want to show the other map item’s extent and expand the\nOverviewsoption in theItem Propertiespanel. Then press thebutton to add an overview.\nInitially this overview is named ‘Overview 1’ (seeFig. 19.22). You can:\n•Rename it with a double-click\n•With theandbuttons, add or remove overviews\n•With theandbuttons, move an overview up and down in the list, placing it above or below other\noverviews in the map item (when they are at the same\nstack position).\nThen select the overview item in the list and check the\nDraw “<name_overview>” overviewto enable the drawing\nof the overview on the selected map frame. You can customize it with:\n•TheMap frameselects the map item whose extents will be shown on the present map item.\n•TheFrame Styleuses thesymbol propertiesto render the overview frame.\n•TheBlending modeallows you to set different transparency blend modes.\n•TheInvert overviewcreates a mask around the extents when activated: the referenced map extents are\nshown clearly, whereas the rest of the map item is blended with the frame fill color (if a fill color is used).\n•TheCenter on overviewpans the map item content so that the overview frame is displayed at the center of\nthe map. You can only use one overview item to center, when you have several overviews.\n•ThePositioncontrols exactly where in the map item’s layer stack the overview will be placed, e.g. allowing an\noverview extent to be drawn below some feature layers such as roads whilst drawing it above other background\nlayers. Available options are:\n–Below map\n–Below map layerandAbove map layer: place the overview frame below and above the geometries of a\nlayer, respectively. The layer is selected in theStacking layeroption.\n–Below map labels: given that labels are always rendered above all the feature geometries in a map item,\nplaces the overview frame above all the geometries and below any label.\n–Above map labels: places the overview frame above all the geometries and labels in the map item.\n19.2. Layout Items655\n\nQGIS Desktop 3.22 User Guide\n19.2.3The 3D Map Item\nThe 3D Map item is used to display a3D map view. Use theAdd 3D Mapbutton, and followitems creation\ninstructionsto add a new 3D Map item that you can later manipulate the same way as demonstrated inInteracting\nwith layout items.\nBy default, a new 3D Map item is empty. You can set the properties of the 3D view and customize it in theItem\nPropertiespanel. In addition to thecommon properties, this feature has the following functionalities (Fig. 19.23):\nFig. 19.23: 3D Map Item Properties\nScene settings\nPressCopy Settings from a 3D View...to choose the 3D map view to display.\nThe 3D map view is rendered with its current configuration (layers, terrain, lights, camera position and angle...).\nCamera pose\n•Center Xsets the X coordinate of the point the camera is pointing at\n•Center Ysets the Y coordinate of the point the camera is pointing at\n•Center Zsets the Z coordinate of the point the camera is pointing at\n•Distancesets the distance from the camera center to the point the camera is pointing at\n•Pitchsets the rotation of the camera around the X-axis (vertical rotation). Values from 0 to 360 (degrees). 0°:\nterrain seen straight from above; 90°: horizontal (from the side); 180°: straight from below; 270°: horizontal,\nupside down; 360°: straight from above.\n656Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n•Headingsets the rotation of the camera around the Y-axis (horizontal rotation - 0 to 360 degrees). 0°/360°:\nnorth; 90°: west; 180°: south; 270°: east.\nTheSet from a 3D View...pull-down menu lets you populate the items with the parameters of a 3D View.\n19.2.4The Label Item\nTheLabelitem is a tool that helps decorate your map with texts that would help to understand it; it can be the title,\nauthor, data sources or any other information... You can add a label with theAdd Labeltool followingitems\ncreation instructionsand manipulate it the same way as exposed inInteracting with layout items.\nBy default, the label item provides a default text that you can customize using itsItem Propertiespanel. Other than\ntheitems common properties, this feature has the following functionalities (seeFig. 19.24):\nFig. 19.24: Label Item Properties Panel\nMain properties\nTheMain propertiesgroup is the place to provide the text of the label. The text can be static, dynamic withexpression\nfunctions and variables, and/or formatted with HTML. Dynamic parts of a label need to be surrounded by[%and\n%]in order to be interpreted and evaluated as such.\n•To use expressions in labels, you can click onInsert/Edit Expression...button, write your formula as usual and\nwhen the dialog is applied, QGIS automatically adds the surrounding characters.\nHint:Clicking theInsert/Edit Expression...button when no selection is made in the textbox will append the\nnew expression to the existing text. If you want to modify an existing expression, you need to first select the\n19.2. Layout Items657\n\nQGIS Desktop 3.22 User Guide\npart of interest.\nBecause maps are usually filled with some common textual information (date, author, title, page number, ...),\nQGIS provides a direct access to the corresponding expressions or variables: press theDynamic textbutton to\nselect and insert them into your label.\nTip:The top menuAdd Item►Add Dynamic Text► can be used to create a new label item filled with the\nselected predefined expression.\nIt’s possible to turn a dynamic label into static: press the drop-down arrow next to theInsert/Edit Expression...\nbutton and selectConvert to Static. Any dynamic parts of the label’s contents will be evaluated and replaced\nwith their current values. You can then manually tweak the resulting text when needed.\n•Labels can be interpreted as HTML code: checkRender as HTML. You can now insert HTML tags or\nstyles, URL, a clickable image that links to a web page, or something more complex...\nThe following code combines HTML rendering with expressions, for an advanced labeling and will outputFig. 19.25:\n<html>\n<head>\n<style>\n/* Define some custom styles, with attribute-based size */\nname{color:red;font-size:[%ID%]px;font-family:Verdana;text-shadow:␣\n,→grey1px010px;}\nuse{color:blue;}\n</style>\n</head>\n<body>\n<!--Informationtodisplay-->\n<u>FeatureInformation</u>\n<ulstyle=\"list-style-type:disc\">\n<li>FeatureId:[%ID%]</li>\n<li>Airport:<name>[%NAME%]</name></li>\n<li>Mainuse:<use>[%USE%]</use></li>\n</ul>\nLastcheck:[%concat(format_date(\"control_date\",'yyyy-MM-dd'),' by <b><i>',\n,→@user_full_name,'</i></b>')%]\n<!--Insertanimage-->\n<palign=center><imgsrc=\"path/to/logos/qgis-logo-made-with-color.svg\"alt=\n,→\"QGIS icon\"style=\"width:80px;height:50px;\"</p>\n</body>\n</html>\nFig. 19.25: Leveraging a label with HTML styling\n658Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nAppearance\n•DefineFontby clicking on theFont...button or aFont colorby pushing thecolor widget.\n•You can specify different horizontal and vertical margins inmm. This is the margin from the edge of the layout\nitem. The label can be positioned outside the bounds of the label e.g. to align label items with other items. In\nthis case you have to use negative values for the margin.\n•Using the text alignment is another way to position your label. It can be:\n–Left,Center,RightorJustifyforHorizontal alignment\n–andTop,Middle,BottomforVertical alignment.\nExploring expressions in a label item\nBelow some examples of expressions you can use to populate the label item with interesting information - remember\nthat the code, or at least the calculated part, should be surrounded by[%and%]in theMain propertiesframe:\n•Display a title with the current atlas feature value in “field1”:\n'This is the map for'||\"field1\"\nor, written in theMain propertiessection:\nThisisthemapfor[%\"field1\"%]\n•Add a pagination for processed atlas features (eg,Page 1/10):\nconcat('Page',@atlas_featurenumber,'/',@atlas_totalfeatures)\n•Return the name of the airports of the current atlas region feature, based on their common attributes:\naggregate( layer:='airports',\naggregate:='concatenate',\nexpression:=\"NAME\",\nfilter:=fk_regionId=attribute(@atlas_feature,'ID'),\nconcatenator:=','\n)\nOr, if anattributes relationis set:\nrelation_aggregate( relation:='airports_in_region_relation',\naggregate:='concatenate',\nexpression:=\"NAME\",\nconcatenator:=','\n)\n•Return the name of the airports contained in the current atlas region feature, based on their spatial relationship:\naggregate( layer := 'airports',\naggregate := 'concatenate',\nexpression := \"NAME\",\nfilter := contains( geometry( @parent ), $geometry ),\nconcatenator := ', '\n)\nOR:\narray_to_string( array:=overlay_contains( layer:='airports',\nexpression\n:=\"NAME\"),\ndelimiter:=','\n)\n19.2. Layout Items659\n\nQGIS Desktop 3.22 User Guide\n•Return the lower X coordinate of theMap 1item’s extent:\nx_min( map_get( item_variables('Map 1'),'map_extent') )\n•Retrieve the name of the layers in the current layoutMap 1item, and formats in one name by line:\narray_to_string(\narray_foreach(\nmap_get( item_variables('Map 1'),'map_layers'),--retrieve the layers␣\n,→list\nlayer_property(@element,'name')--retrieve each layer name\n),\n'\\n'--converts thelistto string separated by breaklines\n)\n•Display the list of layers with their license strings (usage rights) in a layoutMap 1item. You need to fill the\nlayers’Access metadataproperties first.\narray_to_string( map_credits('Map 1', true ) )\n19.2.5The Legend Item\nTheLegenditem is a box or a table that explains the meanings of the symbols used on the map. A legend is then\nbound to a map item. You can add a legend item with theAdd Legendtool followingitems creation instructions\nand manipulate it the same way as exposed inInteracting with layout items.\nBy default, the legend item displays all available layers and can be refined using itsItem Propertiespanel. Other than\ntheitems common properties, this feature has the following functionalities (seeFig. 19.26):\nFig. 19.26: Legend Item Properties Panel\n660Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nMain properties\nTheMain propertiesgroup of the legendItem Propertiespanel provides the following functionalities (seeFig. 19.27):\nFig. 19.27: Legend Main properties group\nIn Main properties you can:\n•Change theTitleof the legend. It can be made dynamic using thedata-defined overridesetting, useful for\nexample when generating an atlas;\n•Choose whichMapitem the current legend will refer to. By default, the map over which the legend item is\ndrawn is picked. If none, then it falls back to thereference map.\nNote:Variablesof the linked map item (@map_id, @map_scale, @map_extent...) are also accessible from\ndata-defined properties of the legend.\n•Wrap the text of the legend on a given character: each time the character appears, it’s replaced with a line\nbreak;\n•Set the symbols and text placement in the legend: theArrangementcan beSymbols on leftorSymbols on right.\nThe default value depends on the locale in use (right-to-left based or not).\n•UseResize to fit contentsto control whether or not a legend should be automatically resized to fit its contents.\nIf unchecked, then the legend will never resize and instead just stick to whatever size the user has set. Any\ncontent which doesn’t fit the size is cropped out.\n19.2. Layout Items661\n\nQGIS Desktop 3.22 User Guide\nLegend items\nTheLegend itemsgroup of the legendItem Propertiespanel provides the following functionalities (seeFig. 19.28):\nFig. 19.28: Legend Items group\n•The legend will be updated automatically ifAuto updateis checked. WhenAuto updateis unchecked this\nwill give you more control over the legend items. All the icons below the legend items list will be activated.\n•The legend items window lists all legend items and allows you to change item order, group layers, remove and\nrestore items in the list, edit layer names and symbology and add a filter.\n–The item order can be changed using theandbuttons or with ‘drag-and-drop’ functionality. The\norder can not be changed for WMS legend graphics.\n–Use thebutton to add a legend group.\n–Use thebutton to add layers andbutton to remove groups, layers or symbol classes.\n–Thebutton is used to edit the layer, group name or title. First you need to select the legend item.\nDouble-clicking the item also opens the text box to rename it.\n–Thebutton uses expressions to customize each symbol label of the selected layer (seeData-define\nthe legend labels)\n–Thebutton adds a feature count for each class of vector layer.\n–The\nFilter legend by expression\nhelps you filter which of the legend items of a layer will be displayed, i.e.\nusing a layer that has different legend items (e.g., from a rule-based or categorized symbology), you\ncan specify a boolean expression to remove from the legend tree, styles that have no feature satisfying a\ncondition. Note that the features are nevertheless kept and shown in the layout map item.\nWhile the default behavior of the legend item is to mimic theLayerspanel tree, displaying the same groups,\nlayers and classes of symbology, right-click any item offers you options to hide layer’s name or raise it as a\ngroup or subgroup. In case you have made some changes to a layer, you can revert them by choosingReset to\ndefaultsfrom the contextual menu of the legend entry.\nAfter changing the symbology in the QGIS main window, you can click onUpdate Allto adapt the changes in\nthe legend element of the print layout.\n662Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n•With theOnly show items inside linked map, only the legend items visible in the linked map will be listed\nin the legend. This tool remains available whenAuto-updateis active\n•While generating an atlas with polygon features, you can filter out legend items that lie outside the current atlas\nfeature. To do that, check theOnly show items inside current atlas featureoption.\nData-define the legend labels\nallows you to addexpressionsto each symbol label of a given layer. New variables (@symbol_label,@sym-\nbol_idand@symbol_count) help you interact with the legend entry.\nFor example, given aregionslayer categorized by itstypefield, you can append to each class in the legend their\nnumber of features and total area, e.g.Borough (3) - 850ha:\n1.Select the layer entry in the legend tree\n2.Press thebutton, opening theExpression String Builderdialog\n3.Enter the following expression (assuming symbol labels have not been edited):\nformat( '%1 (%2) - %3ha',\n@symbol_label,\n@symbol_count,\nround( aggregate(@layer, 'sum', $area, filter:= \"type\"=@symbol_label)/\n,→10000 )\n)\n4.PressOK\n19.2. Layout Items663\n\nQGIS Desktop 3.22 User Guide\nCustomizing legend items\nLegend items can also be customized individually in theLegend Items Properties. But these customization can only\nbe done withAuto updatedisabled.\nDouble-clicking on an item or pressing\nEdit selected item properties\nallows for futher customization.\nLabel\nFor all item types it allows to modify the label text by typing in or by inserting expressions using theInsert or\nEdit an Expression. Expressions can also be added directly anywhere in the item’s label by using the [% expression\n%] notation.\nColumns\nThe Legend Item Property also allows you to control the column splitting behaviour by forcing the column split to\noccur after a specific item or all symbols of a layer. Automatic splitting of a layer and its child can also be allowed or\nblocked on a layer-basis in this widget.\nPatch\n664Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFor items with a symbol, the Legend Item Property allows you to specify the maximum height and width that a symbol\ncan occupy.\nFor vector symbols, you can specify a custom shape for the symbol. The shapes are usually defined by an expression\nto represent the geometry in a simple plane, but those symbols can also be saved in the style manager and imported\nlater. The default symbol for each geometry type can also be controlled via the style manager.\nCustom Symbol\nA custom symbol can also be specified for vector symbols. This can be useful to tweak the render of a specific\nsymbol, to enhance it in the legend or have a symbol independent from its true symbol preview. This custom symbol\nwill override the legend symbol, but will take into account the symbolPatchspecified.\nFonts\nTheFontsgroup of the legendItem Propertiespanel provides the following functionalities:\nFig. 19.29: Legend Fonts properties\n•You can change the font of the legend title, group, subgroup and item (feature) in the legend item using the\nfont selectorwidget\n•For each of these levels you can set the textAlignment: it can beLeft(default for left-to-right based locales),\nCenterorRight(default for right-to-left based locales).\n19.2. Layout Items665\n\nQGIS Desktop 3.22 User Guide\n•You set theColorof the labels using thecolor selectorwidget. The selected color will apply to all the font items\nin the legend.\nColumns\nUnder theColumnsgroup of the legendItem Propertiespanel, legend items can be arranged over several columns:\n•Set the number of columns in theCountfield. This value can be made dynamic e.g., following atlas\nfeatures, legend contents, the frame size...\n•Equal column widthssets how legend columns should be adjusted.\n•TheSplit layersoption allows a categorized or a graduated layer legend to be divided between columns.\nFig. 19.30: Legend Columns settings\nSymbol\nTheSymbolgroup of the legendItem Propertiespanel configures the size of symbols displayed next to the legend\nlabels. You can:\n•Set theSymbol widthandSymbol height\n•Set the markers’Min symbol sizeandMax symbol size:0.00mmmeans there is no value set.\n•Draw stroke for raster symbols: this adds an outline to the symbol representing the band color of the raster\nlayer; you can set both theStroke colorandTickness.\n666Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.31: Legend Symbol configuration\nWMS LegendGraphic\nTheWMS LegendGraphicsection of the legendItem Propertiespanel provide the following functionalities (seeFig.\n19.32):\nFig. 19.32: WMS LegendGraphic\nWhen you have added a WMS layer and you insert a legend item, a request will be sent to the WMS server to provide\na WMS legend. This Legend will only be shown if the WMS server provides the GetLegendGraphic capability. The\nWMS legend content will be provided as a raster image.\nWMS LegendGraphicis used to be able to adjust theLegend widthand theLegend heightof the WMS legend raster\nimage.\n19.2. Layout Items667\n\nQGIS Desktop 3.22 User Guide\nSpacing\nTheSpacingsection allows you to customize the spacing within the legend. Spacing can greatly help denote the\ngroupement of items in the legend and their relation.\nSpacingaround and before title, groups, subgroups, symbols, labels, boxes, columns and lines can be customized\nthrough this dialog.\n19.2.6The Scale Bar Item\nScale bars provide a visual indication of the size of features, and distance between features, on the map item. A scale\nbar item requires a map item. Use the\nAdd Scale Bartool followingitems creation instructionsto add a new scale\nbar item that you can later manipulate the same way as exposed in\nInteracting with layout items.\nBy default, a new scale bar item shows the scale of the map item over which it is drawn. If there is no map item\nbelow, thereference mapis used. You can customize it in theItem Propertiespanel. Other than theitems common\nproperties, this feature has the following functionalities (seeFig. 19.33):\n668Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.33: Scale Bar Item Properties Panel\nMain properties\nTheMain propertiesgroup of the scale barItem Propertiespanel provides the following functionalities (seeFig. 19.34):\nFig. 19.34: Scale Bar Main properties group\n1.First, choose the map the scale bar will be attached to\n2.Then, choose the style of the scale bar. Available styles are:\n•Single boxandDouble boxstyles, which contain one or two lines of boxes alternating colors;\n•Middle,UporDownline ticks;\n•Stepped linestyle that draws a stepped line representation of a scalebar\n•Hollowstyle that draws a single box with alternating color for the segments, with horizontal lines through\nalternating segments\n•Numeric, where the scale ratio is printed (e.g.,1:50000).\n3.Set properties as appropriate\n19.2. Layout Items669\n\nQGIS Desktop 3.22 User Guide\nUnits\nTheUnitsgroup of the scale barItem Propertiespanel provides the functionalities to set the units of display and some\ntext formatting (seeFig. 19.35):\nFig. 19.35: Scale Bar Units group\n•Select the units you want to use withScalebar units. There are many possible choices:Map Units(the default\none),Meters,Feet,MilesorNautical Miles... and some derivatives. Units conversion is handled automati-\ncally.\n•TheLabel unit multiplierspecifies how many scale bar units per labeled unit. Eg, if your scale bar units are set\nto “meters”, a multiplier of 1000 will result in the scale bar labels in “kilometers”.\n•TheLabel for unitsfield defines the text used to describe the units of the scale bar, egmorkm. This should be\nmatched to reflect the multiplier above.\n•PressCustomizenext toNumber formatto have control over all the formatting properties for the numbers in\nthe scale bar, including thousand separators, decimal places, scientific notation, etc. (seeNumber Formatting\nfor more details). Very useful in the case of making maps for audiences outside of the current QGIS locale,\nor when you would like to vary the style from the locale defaults (e.g. adding thousands separators when the\nlocale default is to hide them).\nSegments\nTheSegmentsgroup of the scale barItem Propertiespanel provides the functionalities to configure the number and\nsize of segments and subdivisions (seeFig. 19.36):\nFig. 19.36: Scale Bar Segments group\n•You can define the number ofSegmentsthat will be drawn at the left and right sides of the0of the scale bar:\n–number of subdivisions of a unique segment on theLeftside\n–number of segments on theRightside\n670Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n•You can set how long a segment will be (Fixed width), or limit the scale bar size inmmwithFit segment width\noption. In the latter case, each time the map scale changes, the scale bar is resized (and its label updated) to fit\nthe range set.\n•Heightis used to define the height of the bar.\n•Right segment subdivisionsis used to define the number of sections the right-side segments of the scale bar can\nhave (forLine Ticks Down,Line Ticks MiddleandLine Ticks Upscale bar styles) .\n•Subdivision heightis used to define the height of the subdivision segment.\nDisplay\nTheDisplaygroup of the scale barItem Propertiespanel provides the following functionalities:\nFig. 19.37: Scale Bar Display group\nYou can define how the scale bar will be displayed in its frame.\n•Box margin: space between text and frame borders\n•Label margin: space between text and scale bar drawing\n•Vertical label placement: it can be above or below the scale bar segment\n•Horizontal label placement: which would be centered at the scale bar segment’s edge or center\n•Primary fillandSecondary fillof the scale bar drawing usingfill symbols properties(color, opacity, patterns,\neffects...) — forSingle Box,Double BoxandHollowstyles\n•Line styleof the scale bar drawing usingline symbols properties(color, stroke, join, cap style, patterns, effects...)\n— for all butNumericstyle\n•Division styleandSubdivision stylerespectively for division and subdivision segments inLine Ticks Up,Line\nTicks MiddleandLine Ticks Downscale bar styles usingline symbols properties(color, stroke, join, cap style,\npatterns, effects...)\n•Alignmentputs text on the left, center or right side of the frame (only forNumericscale bar style)\n•Fontto set theproperties(size, font, color, letter spacing, shadow, background...) of the scale bar label.\nSince most of the display properties of the scale bar rely on symbols whose properties can be data-defined, it’s possible\nto render data-defined scale bars.\n19.2. Layout Items671\n\nQGIS Desktop 3.22 User Guide\nExample: The following code applied to the bold property of the scale labels will display numbers in bold when they\nare a multiple of 500:\n--returnsTrue(or1)ifthe value displayed on the bar\n--isa multiple of500\n@scale_value%500=0\n19.2.7The Table Items\nYou can use table items to decorate and explain your map:\n•Attribute table: shows a subset of the attributes of a layer, based on predefined rules\n•Fixed table: inserts a manual text table where information can be independent from the layers.\nThe attribute table item\nAny layer in the project can have its attributes shown in the print layout. Use theAdd Attribute Tabletool\nfollowing\nitems creation instructionsto add a new table item that you can later manipulate the same way as exposed\ninInteracting with layout items.\nBy default, a new attribute table item loads first rows of the first (alphabetically sorted) layer, with all the fields. You\ncan however customize the table thanks to itsItem Propertiespanel. Other than the\nitems common properties, this\nfeature has the following functionalities (see\nFig. 19.38):\nFig. 19.38: Attribute table Item Properties Panel\n672Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nMain properties\nTheMain propertiesgroup of the attribute table provides the following functionalities (seeFig. 19.39):\nFig. 19.39: Attribute table Main properties Group\n•ForSourceyou can by default only selectLayer featuresallowing you to select aLayerfrom the vector layers\nloaded in the project.\nThe\nData-defined override\nbutton near the layer list allows you to dynamically change the layer which is used\nto populate the table, e.g. you could fill the attribute table with different layer attributes per atlas page. Note\nthat the table structure used (Fig. 19.42) is the one of the layer shown in theLayerdrop-down list and it is left\nintact, meaning that setting a data defined table to a layer with different field(s) will result in empty column(s)\nin the table.\nIn case you activate theGenerate an atlasoption in theAtlaspanel (seeGenerate an Atlas), there are two\nadditionalSourcepossible:\n–Current atlas feature(seeFig. 19.40): you won’t see any option to choose the layer, and the table item\nwill only show a row with the attributes from the current feature of the atlas coverage layer.\n–andRelation children(seeFig. 19.41): an option with the relation names will show up. This feature can\nonly be used if you have defined arelationusing your atlas coverage layer as parent, and the table will\nshow the children rows of the atlas coverage layer’s current feature.\n•The buttonRefresh Table Datacan be used to refresh the table when the actual contents of the table has\nchanged.\nFig. 19.40: Attribute table Main properties for ‘Current atlas feature’\nFig. 19.41: Attribute table Main properties for ‘Relation children’\n•The buttonAttributes...starts theSelect Attributesdialog, (seeFig. 19.42) that can be used to change the visible\ncontents of the table. The upper part of the window shows the list of the attributes to display and the lower\npart helps you sort the data.\n19.2. Layout Items673\n\nQGIS Desktop 3.22 User Guide\nFig. 19.42: Attribute table Select attributes Dialog\nIn theColumnssection you can:\n–Move attributes up or down the list by selecting the rows and then using theandbuttons to shift\nthe rows. Multiple rows can be selected and moved at any one time.\n–Add an attribute with thebutton. This will add an empty row at the bottom of the table where you\ncan select a field to be the attribute value or create an attribute via a regular expression.\n–Remove an attribute with thebutton. Multiple rows can be selected and removed at any one time.\n–Reset the attribute table back to its default state with theResetbutton.\n–Clear the table using theClearbutton. This is useful when you have a large table but only want to show a\nsmall number of attributes. Instead of manually removing each row, it may be quicker to clear the table\nand add the rows needed.\n–Cell headings can be altered by adding the custom text in theHeadingcolumn.\n–Cell alignment can be managed with theAlignmentcolumn which will dictate the texts position within\nthe table cell.\n–Cell width can be manually managed by adding custom values to thewidthcolumn.\nIn theSortingsection you can:\n–Add an attribute to sort the table with: press thebutton and a new empty row is added. Insert a field\nor an expression in theAttributecolumn and set theSort ordertoAscendingorDescending.\n–Select a row in the list and use theandbuttons to change the sort priority on attribute level.\nSelecting a cell in theSort Ordercolumn helps you change the sorting order of the attribute field.\n–Use thebutton to remove an attribute from the sorting list.\n674Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFeature filtering\nTheFeature filteringgroup of the attribute table provides the following functionalities (seeFig. 19.43):\nFig. 19.43: Attribute table Feature filtering Group\nYou can:\n•Define theMaximum rowsto be displayed.\n•ActivateRemove duplicate rows from tableto show unique records only.\n•ActivateShow only visible features within a mapand select the correspondingLinked mapwhose visible\nfeatures attributes will be displayed.\n•ActivateShow only features intersecting Atlas featureis only available whenGenerate an atlasis acti-\nvated. When activated it will show a table with only the features which intersect the current atlas feature.\n•ActivateFilter withand provide a filter by typing in the input line or insert a regular expression using the\ngivenexpression button. A few examples of filtering statements you can use when you have loaded the\nairports layer from the Sample dataset:\n–ELEV > 500\n–NAME = 'ANIAK'\n–NAME NOT LIKE 'AN%'\n–regexp_match( attribute( $currentfeature, 'USE' ) , '[i]')\nThe last regular expression will include only the airports that have a letter ‘i’ in the attribute field ‘USE’.\n19.2. Layout Items675\n\nQGIS Desktop 3.22 User Guide\nAppearance\nTheAppearancegroup of the attribute table provides the following functionalities (seeFig. 19.44):\nFig. 19.44: Attribute table appearance Group\n•ClickShow empty rowsto fill the attribute table with empty cells. This option can also be used to provide\nadditional empty cells when you have a result to show!\n•WithCell marginsyou can define the margin around text in each cell of the table.\n•WithDisplay headeryou can select from a list one of ‘On first frame’, ‘On all frames’ default option, or ‘No\nheader’.\n•The optionEmpty tablecontrols what will be displayed when the result selection is empty.\n–Draw headers only\n, will only draw the header except if you have chosen ‘No header’ for\nDisplay header\n.\n–Hide entire table, will only draw the background of the table. You can activateDon’t draw back-\nground if frame is emptyinFramesto completely hide the table.\n–Show set message, will draw the header and adds a cell spanning all columns and display a message like\n‘No result’ that can be provided in the optionMessage to display\n•The optionMessage to displayis only activated when you have selectedShow set messageforEmpty table.\nThe message provided will be shown in the table in the first row, when the result is an empty table.\n•WithBackground coloryou can set the background color of the table using thecolor selectorwidget. The\nAdvanced customizationoption helps you define different background colors for each cell (seeFig. 19.45)\n676Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.45: Attribute table Advanced Background Dialog\n•Apply layer conditional styling colors: theconditional table formattingpresent in the layer is applied in-\nside the layout attribute table (only background and foreground colors are currently supported). Conditional\nformatting rules take precedence over other layout table formatting settings, e.g. they will override other cell\nbackground color settings such as alternating row colors.\n•With theWrap text onoption, you can define a character on which the cell content will be wraped each time it\nis met\n•WithOversized textyou define the behavior when the width set for a column is smaller than its content’s length.\nIt can beWrap textorTruncate text.\nNote:More properties of the attribute table item are described in theTables common functionalitiessection.\nThe fixed table item\nAdditional information about the map can be inserted manually into a table by choosingAdd Fixed Tableand by\nfollowingitems creation instructionsto add a new table item that you can later manipulate the same way as exposed\ninInteracting with layout items.\nBy default, an empty table with two minimized columns and rows appears in the map layout. You have to cus-\ntomize the table in theItem Propertiespanel. Other than theitems common properties, this feature has the following\nfunctionalities:\n19.2. Layout Items677\n\nQGIS Desktop 3.22 User Guide\nMain properties\nFig. 19.46: Fixed table Item Properties Panel with Table designer\nInMain propertiesyou can work with theTable designerwhen clicking theEdit table ...:\n•You can click into the table and insert texts manually.\n•Through the menus on top it is possible to:\n–Import Content From Clipboard\nby going to\nFile\n(it overrides given inputs).\n–work with selection functionalities for rows and columns by going toEdit.\n–Insert rows,Insert columns,Delete Rows,Delete Columnsas well as using the option toInclude Header\nRow.\n•You can work with theCell Contentssection on the right and:\n–Define the text format of selected cells inFormatting\n∗by clicking on the givenexpression button and using a regular expression for the input of the\ncell\n∗by choosing theText format\n∗byFormat as number\n(several formats are available)\n∗by defining theHorizontal alignmentand theVertical alignment\n∗by choosing aBackground color\n678Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n–Define theCell SizewithRow heightandColumn width.\nAppearance\nTheAppearancegroup of the fixed table provides the following functionalities:\n•ClickShow empty rows\nto fill the attribute table with empty cells.\n•WithCell marginsyou can define the margin around text in each cell of the table.\n•WithDisplay headeryou can select from a list one of ‘On first frame’, ‘On all frames’ default option, or ‘No\nheader’.\n•WithBackground coloryou can set the background color of the table using thecolor selectorwidget. The\nAdvanced customizationoption helps you define different background colors for each cell.\n•WithOversized textyou define the behavior when the width set for a column is smaller than its content’s length.\nIt can beWrap textorTruncate text.\nNote:More properties of the fixed table item are described in theTables common functionalitiessection.\nTables common functionalities\nShow grid\nTheShow gridgroup of the table items provides the following functionalities (seeFig. 19.47):\nFig. 19.47: Attribute table Show grid Group\n•ActivateShow gridwhen you want to display the grid, the outlines of the table cells. You can also select to\neitherDraw horizontal linesorDraw vertical linesor both.\n•WithLine widthyou can set the thickness of the lines used in the grid.\n•TheColorof the grid can be set using the color selection widget.\nFonts and text styling\nTheFonts and text stylinggroup of the table items provides the following functionalities (seeFig. 19.48):\n19.2. Layout Items679\n\nQGIS Desktop 3.22 User Guide\nFig. 19.48: Attribute table Fonts and text styling Group\n•You can defineFontproperties forTable headingandTable contents, using the advancedtext settingswidget\n(with buffer, shadow, paint effects, transparence, background, coloring, ...). Note that these changes do not\naffect the cells that have custom font assigned, either from theAppearancesection or theTable Designerdialog.\nOnly cells with the default rendering are overwritten.\n•ForTable headingyou can additionally set theAlignmenttoFollow column alignmentor override this\nsetting by choosingLeft,CenterorRight. The column alignment is set using theSelect Attributesdialog\n(seeFig. 19.42).\nFrames\nTheFramesgroup of the table item properties provides the following functionalities (seeFig. 19.49):\nFig. 19.49: Attribute table Frames Group\n•WithResize modeyou can select how to render the attribute table contents:\n–Use existing framesdisplays the result in the first frame and added frames only.\n–Extend to next pagewill create as many frames (and corresponding pages) as necessary to display\nthe full selection of attribute table. Each frame can be moved around on the layout. If you resize a frame,\nthe resulting table will be divided up between the other frames. The last frame will be trimmed to fit the\ntable.\n–Repeat until finishedwill also create as many frames as theExtend to next pageoption, except\nall frames will have the same size.\n•Use theAdd Framebutton to add another frame with the same size as selected frame. The result of the table that\nwill not fit in the first frame will continue in the next frame when you use the Resize modeUse existing\nframes.\n•ActivateDon’t export page if frame is emptyprevents the page to be exported when the table frame has no\ncontents. This means all other layout items, maps, scalebars, legends etc. will not be visible in the result.\n•ActivateDon’t draw background if frame is emptyprevents the background to be drawn when the table\nframe has no contents.\n680Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n19.2.8The Marker, Picture and North Arrow Items\n•The Picture Item\n–Main properties\n–Size and placement\n–Image rotation\n•The North Arrow Item\n•The Marker Item\nAlong with the map or legend items in the print layout, you may want to decorate your realization with images or\nannotations. QGIS provides different tools to achieve this:\n•thepicture item: decorates the layout with an image raster or SVG file (e.g. logos, pictures, north arrows, ...)\n•thenorth arrow item: a picture item predefined with a north arrow image\n•themarker item: decorates the layout with QGIS vectorsymbols. It can be used to place markers over a map\nitem or for creation of advanced custom legends.\nThe Picture Item\nYou can add a picture by dragging it from your file manager onto the canvas, pasting it directly into the layout by\nusingCtrl+VorEdit►Pasteand by using the\nAdd Picture\n, following\nitems creation instructions. Then you can\nmanipulate it, as explained inInteracting with layout items.\nWhen using\nAdd Picture\n, the picture item will be a blank frame that you can customize using itsItem Properties\npanel. Other than the\nitems common properties, this feature has the following functionalities:\n19.2. Layout Items681\n\nQGIS Desktop 3.22 User Guide\nMain properties\nFig. 19.50: Picture Item Properties panel\nThe picture item supports two types of images:\n•Raster Image: a file selector widget can be used to fetch the data. Use the...\nBrowse\nbutton to select a file on\nyour computer or enter the path directly in the text field. You can even provide a remote URL that points to a\npicture. The associated image can also beembeddedin the layout.\nUse the\ndata defined override\nbutton to set the image source from a feature attribute or using a regular expression.\n•SVG Image: using by default the SVG libraries provided inSettings►Options►System►SVG Paths. You\ncan however use any other file, and the file selection follows the same rules as for the raster image. The SVG\nparameters can as well be set dynamic.\nThe QGIS provided (default).SVGfiles are customizable, meaning that you can easily apply otherFill color,\nStroke color(including opacity) andStroke widththan the original, using their corresponding feature in theSVG\nParametersgroup. These properties can also be\ndata-defined.\nIf you add an.SVGfile that does not enable these properties, you may need to add the following tags to the\nfile in order to add support e.g. for transparency:\n–fill-opacity=”param(fill-opacity)”\n–stroke-opacity=”param(outline-opacity)”\nMore details atParametrizable SVG.\nNote:Drag-and-drop an image file (raster or SVG) into the layout page will create a layout picture item with\ncorresponding settings.\n682Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nSize and placement\nFig. 19.51: Layout pictures size and placement properties\nWith theResize modeoption, you can set how the image is displayed when the frame is resized:\n•Zoom: enlarges/reduces the image to the frame while maintaining the aspect ratio of picture\n•Stretch: stretches the image to fit inside the frame\n•Clip: use this mode for raster images only, it sets the size of the image to the original image size without\nscaling, and the frame is used to clip the image. So only the part of the image that is inside the frame will be\nvisible.\n•Zoom and resize frame: enlarges the image to fit the frame, and then resizes frame to fit the resulting\nimage dimensions\n•Resize frame to image size: sets the size of the frame to match the original size of the image (no\nscaling)\nDepending on the selectedResize mode, thePlacementandImage rotationoptions may be disabled.Placementlets\nyou select the position of the image inside its frame (top/middle/bottom and left/center/right).\nImage rotation\nImages can be rotated with theImage rotationfield. Activating theSync with mapcheckbox synchronizes the\nrotation of the image with the rotation applied to the selected map item. This is a convenient feature to make any\npicture behave as a north arrow. TheNorth alignmentcan be:\n•Grid north: the direction of a grid line which is parallel to the central meridian of the national/local grid\n•True north: direction of a meridian of longitude.\nYou can also apply a declinationOffsetto the picture rotation.\nFig. 19.52: Layout pictures image rotation properties\n19.2. Layout Items683\n\nQGIS Desktop 3.22 User Guide\nThe North Arrow Item\nYou can add a north arrow with the\nAdd North Arrow\nbutton, followingitems creation instructionsand manipulate it\nthe same way as exposed inInteracting with layout items.\nSince north arrows are images, theNorth Arrowitem has the same properties as thepicture item. The main differences\nare:\n•A default north arrow is used when adding the item, instead of a blank frame\n•The north arrow item is synced with a map item by default: theSync with mapproperty is the map over which\nthe north arrow item is drawn. If none, it falls back to thereference map.\nNote:Many of the north arrows do not have an ‘N’ added in the north arrow. This is done on purpose, since there\nare languages that do not use an ‘N’ for North.\nFig. 19.53: North arrows available for selection in provided SVG library\nThe Marker Item\nTo add a marker item, select the\nAdd Marker\nbutton, and click on the page. A default point marker symbol is added.\nThen you can manipulate it, as explained inInteracting with layout items. But note that unlike most of the other items,\nyou resize the item given that its size is controlled by the embedded symbols properties.\nThe marker item can be customized from theItem Propertiespanel. Other than the\nitems common properties, you can\nalso:\n•modify theSymbol, relying on all the symbolwidget capabilities\n•sync the marker item rotation with the map’s (seeImage rotation), acting as a north arrow. The map rotation\nis added to any existing marker symbol level rotation (so .e.g if you have to rotate the triangle marker 90° to\nget it pointing straight up, it will still work nicely in north arrow mode!)\n684Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nFig. 19.54: The marker item custom properties\n19.2.9The HTML Frame Item\nIt is possible to add a frame that displays the contents of a website or even create and style your own HTML page and\ndisplay it! You can add a picture with theAdd HTMLfollowingitems creation instructionsand manipulate it the\nsame way as exposed inInteracting with layout items. Note that the HTML scale is controlled by the layout export\nresolution at the time the HTML frame is created.\nThe HTML item can be customized using itsItem Propertiespanel. Other than theitems common properties, this\nfeature has the following functionalities (seeFig. 19.55):\nFig. 19.55: HTML Frame, the Item Properties Panel\n19.2. Layout Items685\n\nQGIS Desktop 3.22 User Guide\nHTML Source\nTheHTML Sourcegroup of the HTML frameItem Propertiespanel provides the following functionalities (seeFig.\n19.56):\nFig. 19.56: HTML frame, the HTML Source properties\n•InURLyou can enter the URL of a webpage you copied from your Internet browser or select an HTML file\nusing the...\nBrowse\nbutton. There is also the option to use the\nData-defined override\nbutton, to provide a URL\nfrom the contents of an attribute field of a table or using a regular expression.\n•InSourceyou can enter text in the textbox with some HTML tags or provide a full HTML page.\n•TheInsert or Edit an Expression...button can be used to add an expression like[%Year($now)%]in the\nSource textbox to display the current year. This button is only activated when radiobuttonSourceis selected.\nAfter inserting the expression click somewhere in the textbox before refreshing the HTML frame, otherwise\nyou will lose the expression.\n•ActivateEvaluate QGIS expressions in HTML codeto see the result of the expression you have included,\notherwise you will see the expression instead.\n•Use theRefresh HTMLbutton to refresh the HTML frame(s) and see the result of changes.\nFrames\nTheFramesgroup of the HTML frameItem Propertiespanel provides the following functionalities (seeFig. 19.57):\nFig. 19.57: HTML frame, the Frames properties\n•WithResize modeyou can select how to render the HTML contents:\n–Use existing framesdisplays the result in the first frame and added frames only.\n–Extend to next pagewill create as many frames (and corresponding pages) as necessary to render\nthe height of the web page. Each frame can be moved around on the layout. If you resize a frame, the\nwebpage will be divided up between the other frames. The last frame will be trimmed to fit the web page.\n–Repeat on every pagewill repeat the upper left of the web page on every page in frames of the\nsame size.\n686Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n–Repeat until finishedwill also create as many frames as theExtend to next page\noption, except all frames will have the same size.\n•Use theAdd Framebutton to add another frame with the same size as selected frame. If the HTML page does\nnot fit in the first frame it will continue in the next frame when you useResize modeorUse existing frames.\n•ActivateDon’t export page if frame is emptyprevents the page from being exported when the frame has\nno HTML contents. This means all other layout items, maps, scale bars, legends etc. will not be visible in the\nresult.\n•ActivateDon’t draw background if frame is emptyprevents the HTML frame being drawn if the frame is\nempty.\nUse smart page breaks and User style sheet\nTheUse smart page breaksdialog andUser style sheetdialog of the HTML frameItem Propertiespanel provides the\nfollowing functionalities (seeFig. 19.58):\nFig. 19.58: HTML frame, Use smart page breaks and User style sheet properties\n•ActivateUse smart page breaksto prevent the html frame contents from breaking mid-way a line of text\nso it continues nice and smooth in the next frame.\n•Set theMaximum distanceallowed when calculating where to place page breaks in the html. This distance is\nthe maximum amount of empty space allowed at the bottom of a frame after calculating the optimum break\nlocation. Setting a larger value will result in better choice of page break location, but more wasted space at the\nbottom of frames. This is only used whenUse smart page breaksis activated.\n•ActivateUser style sheetto apply HTML styles that often is provided in cascading style sheets. An example\nof style code is provided below to set the color of<h1>header tag to green and set the font and font size of\ntext included in paragraph tags<p>.\nh1{color:#00ff00;\n}\np{font-family:\"Times New Roman\",Times,serif;\nfont-size:20px;\n}\n•Use theUpdate HTMLbutton to see the result of the style sheet settings.\n19.2. Layout Items687\n\nQGIS Desktop 3.22 User Guide\n19.2.10The Shape Items\nQGIS provides a couple of tools to draw regular or more complex shapes over the print layout.\nNote:Unlike other print layout items, you can not style the frame nor the background color of the shapes bounding\nframe (set to transparent by default).\nThe Regular Shape Item\nTheShapeitem is a tool that helps to decorate your map with regular shapes like triangle, rectangle, ellipse... You can\nadd a regular shape using the\nAdd Shape\ntool which gives access to particular tools like\nAdd Rectangle\n,\nAdd Ellipse\nand\nAdd Triangle\n. Once you have selected the appropriate tool, you can draw the item followingitems creation\ninstructions. Like other layout items, a regular shape can be manipulated the same way as exposed inInteracting with\nlayout items.\nNote:Holding down theShiftkey while drawing the basic shape with the click and drag method helps you create\na perfect square, circle or triangle.\nThe default shape item can be customized using itsItem Propertiespanel. Other than theitems common properties,\nthis feature has the following functionalities (seeFig. 19.59):\nFig. 19.59: Shape Item Properties Panel\nTheMain propertiesgroup shows and allows you to switch the type of the shape item (Ellipse,RectangleorTriangle)\ninside the given frame.\nYou can set the style of the shape using the advanced\nsymbolandcolorselector widget...\nFor the rectangle shape, you can set in different units the value of theCorner radiusto round of the corners.\n688Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nThe Node-Based Shape Items\nWhile theAdd Shapetool provides way to create simple and predefined geometric item, theAdd Node Item\ntool helps you create a custom and more advanced geometric item. For polylines or polygons, you can draw as many\nlines or sides as you want and vertices of the items can be independently and directly manipulated using theEdit\nNodes Item. The item itself can be manipulated as exposed inInteracting with layout items.\nTo add a node-based shape:\n1.Click the\nAdd Node Item\nicon\n2.Select either\nAdd Polygon\nor\nAdd Polyline\ntool\n3.Perform consecutive left clicks to add nodes of your item. If you hold down theShiftkey while drawing a\nsegment, it is constrained to follow an orientation multiple of 45°.\n4.When you’re done, right-click to terminate the shape.\nYou can customize the appearance of the shape in theItem Propertiespanel.\nFig. 19.60: Polygon Node Shape Item Properties Panel\nIn theMain properties, you can set the style of the shape using the advancedsymbolandcolorselector widget...\nFor polyline node items, you can also parameterize theLine markersi.e. add:\n•start and/or end markers with options:\n–None: draws a simple polyline.\n–Arrow: adds a regular triangular arrow head that you can customize.\n–SVGmarker: uses anSVGfile as arrow head of the item.\n•customize the arrow head:\n–Arrow stroke color: sets the stroke color of the arrow head.\n–Arrow fill color: sets the fill color of the arrow head.\n–Arrow stroke width: sets the stroke width of the arrow head.\n–Arrow head width: sets the size of the arrow head.\nSVG images are automatically rotated with the line. Stroke and fill colors of QGIS predefined SVG images can be\nchanged using the corresponding options. Custom SVG may require some tags following thisinstruction.\n19.2. Layout Items689\n\nQGIS Desktop 3.22 User Guide\nFig. 19.61: Polyline Node Shape Item Properties Panel\nThe Arrow Item\nThe\nAdd Arrow\ntool is a shortcut to create an arrow-enabled polyline by default and thus has the same properties\nand behavior as apolyline node item.\nActually, the arrow item can be used to add a simple arrow, for example, to show the relation between two different\nprint layout items. However, to create a north arrow, the\nimage itemshould be considered first as it gives access to a\nset of north arrows in.SVGformat that you can sync with a map item so that it rotates automatically with it.\nEditing a node item geometry\nA specific tool is provided to edit node-based shapes through\nEdit Nodes Item\n. Within this mode, you can select a\nnode by clicking on it (a marker is displayed on the selected node). A selected node can be moved either by dragging\nit or by using the arrow keys. Moreover, in this mode, you are able to add nodes to an existing shape: double-click on\na segment and a node is added at the place you click. Finally, you can remove the currently selected node by hitting\nthe\nDel\nkey.\n690Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n19.3Creating an Output\nFig. 19.62shows an example print layout including all the types of layout items described in the previous section.\nFig. 19.62: Print Layout with map view, legend, image, scale bar, coordinates, text and HTML frame added\nFrom theLayoutmenu or toolbar, you can output the print layout to different file formats, and it is possible to modify\nthe resolution (print quality) and paper size:\n•The\nPrint\nicon allows you to print the layout to a connected printer or a PostScript file, depending on the\ninstalled printer drivers.\n•The\nExport as image\nicon exports the print layout image formats such asPNG,BMP,TIF,JPG, and many\nothers...\n•The\nExport as SVG\nicon saves the print layout as anSVG(Scalable Vector Graphic).\n•The\nExport as PDF\nicon saves the defined print layout directly as aPDF(Portable Document Format) file.\n19.3.1Export settings\nWhenever you export a print layout, there are a selection of export settings QGIS needs to check in order to produce\nthe most appropriate output. These configurations are:\n•TheExport settingsof theLayoutpanel, such asExport resolution,Print as raster Always export as vectorsor\nSave world file\n•Exclude page from exportsin thepage item propertiespanel\n•Exclude item from exportsin theitem propertiespanel\n19.3. Creating an Output691\n\nQGIS Desktop 3.22 User Guide\n19.3.2Export as Image\nTo export a layout as an image:\n1.Click the\nExport as image\nicon\n2.Select the image format, the folder and filename (e.g.myill.png) to use. If the layout contains more than\none page, each page will be exported to a file with the given filename with the page number appended (e.g.\nmyill_2.png).\n3.In the next (\nImage Export Options\n) dialog:\n•You can override the print layoutExport resolutionand the exported page dimensions (as set inLayout\npanel).\n•Image rendering can also be improved with theEnable antialiasingoption.\n•If you want to export your layout as ageoreferenced image(e.g., to share with other projects), check the\nGenerate world fileoption, and anESRI World Filewith the same name as the exported image, but a\ndifferent extension (.tfwfor TIFF,.pnwfor PNG,jgwfor JPEG, ...) will be created when exporting.\nThis option can also be checked by default in thelayout panel.\nNote:For multi-page output, only the page that contains thereference mapwill get a world file (assuming\nthat theGenerate world fileoption is checked).\n•By checkingCrop to contentoption, the image output by the layout will include the minimal area\nenclosing all the items (map, legend, scale bar, shapes, label, image...) of each page of the composition:\n–If the composition includes a single page, then the output is resized to include EVERYTHING on\nthe composition. The page can then be reduced or extended to all items depending on their position\n(on, above, below, left or right of the page).\n–In case of a multi-page layout, each page will be resized to include items in its area (left and right\nsides for all pages, plus top for the first page and bottom for the last page). Each resized page is\nexported to a separate file.\nTheCrop to contentdialog also lets you add margins around the cropped bounds.\nFig. 19.63: Image Export Options, output is resized to items extent\n692Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nTip: Use image formats that support transparency when items extend beyond the paper extent\nLayout items may be placed outside the paper extent. When exporting with theCrop to contentoption, the resulting\nimage may therefore extend beyond the paper extent. Since the background outside of the paper extent will be\ntransparent, for image formats that do not support transparency (e.g.BMPandJPG) the transparent background will\nbe rendered as full black, “corrupting” the image. Use transparency-compatible formats (e.g.TIFFandPNG) in\nsuch cases.\nNote:When supported by the format (e.g.PNG) and the underlying Qt library, the exported image may include\nproject metadata(author, title, date, description...)\n19.3.3Export as SVG\nTo export a layout as SVG:\n1.Click the\nExport as SVG\nicon\n2.Fill in the path and filename (used as a base name for all the files in case of multi-page composition, as for\nimage export)\n3.In the nextSVG Export Optionsdialog, you can override the layout defaultexport settingsor configure new ones:\n•Export map layers as SVG groups: exported items are grouped within layers whose name matches the\nlayer names from QGIS, making it much easier to understand the contents of the document.\n•Always export as vectors: some rendering options require items to be rasterized for a better rendering.\nCheck this option to keep the objects as vectors with the risk that the appearance of the output file may\nnot match the print layout preview (for more details, seeExport settings).\n•Export RDF metadataof the document such as the title, author, date, description...\n•Simplify geometries to reduce output file size: this avoids exporting ALL geometry vertices, which\ncan result in a ridiculously complex and large export file size that could fail to load in other applications.\nGeometries will be simplified while exporting the layout in order to remove any redundant vertices which\nare not discernably different at the export resolution (e.g. if the export resolution is300 dpi, vertices\nthat are less than1/600 inchapart will be removed).\n•Set theText export: controls whether text labels are exported as proper text objects (Always export texts\nas text objects) or as paths only (Always export texts as paths). If they are exported as text objects, they\ncan be edited in external applications (e.g. Inkscape) as normal text. BUT the side effect is that the\nrendering quality is reduced, AND there are issues with rendering when certain text settings like buffers\nare in place. That’s why exporting as paths is recommended.\n•ApplyCrop to contentoption\n•Disable tiled raster layer exports: When exporting files, QGIS uses a built-in raster layer tiled rendering\nthat saves memory. Sometimes, this can cause visible “seams” in the rasters for generated files. Checking\nthis option would fix that, at the cost of a higher memory usage during exports.\n19.3. Creating an Output693\n\nQGIS Desktop 3.22 User Guide\nFig. 19.64: SVG Export Options\nNote:Currently, the SVG output is very basic. This is not a QGIS problem, but a problem with the underlying Qt\nlibrary. This will hopefully be sorted out in future versions.\n19.3.4Export as PDF\nTo export a layout as PDF:\n1.Click the\nExport as PDF\nicon\n2.Fill in the path and filename: unlike for image and SVG export, all the pages in the layout are exported to a\nsingle PDF file.\n3.In the nextPDF Export Optionsdialog, you can override the layout defaultexport settingsor configure new ones:\n•Always export as vectors: some rendering options require items to be rasterized for a better rendering.\nCheck this option to keep the objects as vectors with the risk that the appearance of the output file may\nnot match the print layout preview (for more details, see\nExport settings).\n•Append georeference information: available only if thereference map, from which the information is\ntaken, is on the first page.\n•Export RDF metadataof the document such as the title, author, date, description...\n•Set theText export: controls whether text labels are exported as proper text objects (Always export texts\nas text objects) or as paths only (Always export texts as paths). If they are exported as text objects then\nthey can be edited in external applications (e.g. Inkscape) as normal text. BUT the side effect is that\nthe rendering quality is decreased, AND there are issues with rendering when certain text settings like\nbuffers are in place. That’s why exporting as paths is recommended.\n•Control the PDFImage compressionusing:\n–Lossy (JPEG), which is the default compression mode\n–or\nLossless\n, which creates bigger files in most cases, but is much more suitable for printing outputs\nor for post-production in external applications (requires Qt 5.13 or later).\n•Create Geospatial PDF (GeoPDF): Generate a georeferenced PDF file (requires GDAL version 3 or\nlater).\n694Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n•Disable tiled raster layer exports: When exporting files, QGIS uses tiled based rendering that saves\nmemory. Sometimes, this can cause visible “seams” in the rasters for generated files. Checking this\noption would fix that, at the cost of a higher memory usage during exports.\n•Simplify geometries to reduce output file size: Geometries will be simplified while exporting the layout\nby removing vertices that are not discernably different at the export resolution (e.g. if the export resolution\nis300 dpi, vertices that are less than1/600 inchapart will be removed). This can reduce the size\nand complexity of the export file (very large files can fail to load in other applications).\nFig. 19.65: PDF Export Options\nNote:Since QGIS 3.10, with GDAL 3, GeoPDF export is supported, and a number of GeoPDF specific options\nare available:\n•Format(GeoPDF format - there are some GeoPDF variations),\n•Include multiple map themes(specify map themes to include),\n•Include vector feature information(choose the layers and group them into logical PDF groups).\nNote:Exporting a print layout to formats that supports georeferencing (e.g.PDFandTIFF) creates a georeferenced\noutput by default.\n19.3.5Generate an Atlas\nAtlas functions allow you to create map books in an automated way. Atlas uses the features of a table or vector layer\n(Coverage layer) to create an output for each feature (atlas feature) in the table / layer. The most common usage is\nto zoom a map item to the current atlas feature. Further use cases include:\n•a map item showing, for another layer, only features that share the same attribute as the atlas feature or are\nwithin its geometry.\n•a label or HTML item whose text is replaced as features are iterated over\n•a table item showing attributes of associatedparent or childrenfeatures of the current atlas feature...\n19.3. Creating an Output695\n\nQGIS Desktop 3.22 User Guide\nFor each feature, the output is processed for all pages and items according to their exports settings.\nTip: Use variables for more flexibility\nQGIS provides a large panel of functions andvariables, including atlas related ones, that you can use to manipulate\nthe layout items, but also the symbology of the layers, according to atlas status. Combining these features gives you\na lot of flexibility and helps you easily produce advanced maps.\nTo enable the generation of an atlas and access atlas parameters, refer to theAtlaspanel. This panel contains the\nfollowing (seeFig. 19.66):\nFig. 19.66: Atlas Panel\n•Generate an atlasenables or disables atlas generation.\n•Configuration\n–ACoverage layercombo box that allows you to choose the table or vector layer containing the\nfeatures to iterate over.\n–An optionalHidden coverage layerthat, if checked, will hide the coverage layer (but not the other\nlayers) during the generation.\n–An optionalPage namecombo box to specify the name for the feature page(s). You can select a field of\nthe coverage layer or set anexpression. If this option is empty, QGIS will use an internal ID, according\nto the filter and/or the sort order applied to the layer.\n–An optionalFilter withtext area that allows you to specify an expression for filtering features from\nthe coverage layer. If the expression is not empty, only features that evaluate toTruewill be processed.\n–An optionalSort bythat allows you to sort features of the coverage layer (and the output), using a\nfield of the coverage layer or an expression. The sort order (either ascending or descending) is set by the\ntwo-stateSort directionbutton that displays an up or a down arrow.\n•Output- this is where the output of the atlas can be configured:\n–AnOutput filename expressiontextbox that is used to generate a filename for each atlas feature. It is based\non expressions. is meaningful only for rendering to multiple files.\n–ASingle file export when possiblethat allows you to force the generation of a single file if this is\npossible with the chosen output format (PDF, for instance). If this field is checked, the value of the\nOutput filename expressionfield is meaningless.\n696Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n–AnImage export formatdrop-down list to select the output format when using the\nExport atlas as Images...\nbutton.\nControl map by atlas\nThe most common usage of atlas is with the map item, zooming to the current atlas feature, as iteration goes over the\ncoverage layer. This behavior is set in theControlled by atlasgroup properties of the map item. SeeControlled by\natlasfor different settings you can apply on the map item.\nCustomize labels with expression\nIn order to adapt labels to the feature the atlas iterates over, you can include expressions. Make sure that you place the\nexpression part (including functions, fields or variables) between[%and%](seeThe Label Itemfor more details).\nFor example, for a city layer with fieldsCITY_NAMEandZIPCODE, you could insert this:\nThe area of [% concat( upper(CITY_NAME), ',', ZIPCODE, ' is ',\nformat_number($area/1000000, 2) ) %] km2\nor, another combination:\nThe area of [% upper(CITY_NAME)%],[%ZIPCODE%] is\n[%format_number($area/1000000,2) %] km2\nThe information[%   concat(   upper(CITY_NAME),   ',',   ZIPCODE,   '   is   ',\nformat_number($area/1000000, 2) ) %]is an expression used inside the label. Both expressions\nwould result in the following type of label in the generated atlas:\nThe area of PARIS,75001is1.94km2\nExplore Data-defined override buttons with atlas\nThere are several places where you can use a\nData defined override\nbutton to override the selected setting. This is\nparticularly useful with atlas generation. See\nData defined override setupfor more details on this widget.\nFor the following examples theRegionslayer of the QGIS sample dataset is used and selected asCoverage layer\nfor the atlas generation. We assume that it is a single page layout containing a map item and a label item.\nWhen the height (north-south) of a region extent is greater than its width (east-west), you should usePortraitinstead\nofLandscapeorientation to optimize the use of paper. With a\nData Defined Override\nbutton you can dynamically set\nthe paper orientation.\nRight-click on the page and selectPage Propertiesto open the panel. We want to set the orientation dynamically,\nusing an expression depending on the region geometry, so press the\nbutton of fieldOrientation, selectEdit...to\nopen theExpression string builderdialog and enter the following expression:\nCASE WHEN bounds_width(@atlas_geometry)>bounds_height(@atlas_geometry)\nTHEN'Landscape'ELSE'Portrait'END\nNow if youpreview the atlas, the paper orients itself automatically, but item placements may not be ideal. For each\nRegion you need to reposition the location of the layout items as well. For the map item you can use the\nbutton\nof itsWidthproperty to set it dynamic using the following expression:\n@layout_pagewidth-20\nLikewise, use thebutton of theHeightproperty to provide the following expression to constrain map item size:\n19.3. Creating an Output697\n\nQGIS Desktop 3.22 User Guide\n@layout_pageheight-20\nTo ensure the map item is centered in the page, set itsReference pointto the upper left radio button and enter10for\nitsXandYpositions.\nLet’s add a title above the map in the center of the page. Select the label item and set the horizontal alignment to\nCenter. Next move the label to the right position, choose the middle button for theReference point, and provide the\nfollowing expression for fieldX:\n@layout_pagewidth/2\nFor all other layout items you can set the position in a similar way so they are correctly positioned both for portrait\nand landscape. You can also do more tweaks such as customizing the title with feature attributes (see\nCustomize\nlabels with expressionexample), changing images, resizing the number of legend columns number according to page\norientation, ...\nThe information provided here is an update of the excellent blog (in English and Portuguese) on the Data Defined\nOverride optionsMultiple_format_map_series_using_QGIS_2.6.\nAnother example for using data-defined override buttons is the usage of a dynamic picture. For the following examples\nwe use a geopackage layer containing a BLOB field calledlogowith the field type binary (seeCreating a new\nGeoPackage layer). For every feature there is defined a different picture so that the atlas can iterate over as described\ninPreview and generate an atlas. All you need to do is add a picture in the print layout and go to itsItem propertiesin\nthe atlas context. There you can find a data-defined override button in theImage sourcesection of theMain Properties.\nIn the following window chooseEditso that theExpression String Builderopens. From theFields and valuessection\nyou can find the BLOB field that was defined in the geopackage layer. Double-click the field namelogoand click\nOK.\n698Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nThe atlas iterates over the entries in the BLOB field provided that you choose the geopackage layer asCoverage layer\n(further instructions you can find inPreview and generate an atlas).\nThese are just two examples of how you can use some advanced settings with atlas.\nPreview and generate an atlas\nFig. 19.67: Atlas Preview toolbar\nOnce the atlas settings have been configured, and layout items (map, table, image...) linked to it, you can create a\npreview of all the pages by choosingAtlas►Preview Atlasor clicking the\nPreview Atlas\nicon. You can then use the\narrows to navigate through all the features:\n•\nFirst feature\n•\nPrevious feature\n•\nNext feature\n•\nLast feature\nYou can also use the combo box to select and preview a specific feature. The combo box shows atlas feature names\naccording to the expression set in the atlasPage nameoption.\nAs for simple compositions, an atlas can be generated in different ways (seeCreating an Outputfor more information\n- just use tools from theAtlasmenu or toolbar instead of theLayoutmenu.\n19.3. Creating an Output699\n\nQGIS Desktop 3.22 User Guide\nThis means that you can directly print your compositions withAtlas►Print Atlas. You can also create a PDF using\nAtlas►Export Atlas as PDF...: You will be asked for a directory to save all the generated PDF files, except if the\nSingle file export when possiblehas been selected. In that case, you’ll be prompted to give a filename.\nWithAtlas►Export Atlas as Images...orAtlas►Export Atlas as SVG...tool, you’re also prompted to select a folder.\nEach page of each atlas feature composition is exported to the image file format set inAtlaspanel or to SVG.\nNote:With multi-page output, an atlas behaves like a layout in that only the page that contains theGeneral settings\nwill get a world file (for each feature output).\nTip: Print a specific atlas feature\nIf you want to print or export the composition of only one feature of the atlas, simply start the preview, select the\ndesired feature in the drop-down list and click onLayout►Print(orExport...to any supported file format).\nUse project defined relations for atlas creation\nFor users with HTML and Javascript knowledge it is possible to operate on GeoJSON objects and use project defined\nrelations from the QGIS project. The difference between this approach and using expressions directly inserted into\nthe HTML is that it gives you a full, unstructured GeoJSON feature to work with. This means that you can use\nexisting Javascript libraries and functions that operate on GeoJSON feature representations.\nThe following code includes all related child features from the defined relation. Using the JavaScriptsetFeature\nfunction it allows you to make flexible HTML which represents relations in whatever format you like (lists, tables,\netc). In the code sample, we create a dynamic bullet list of the related child features.\n// Declare the two HTML div elements we will use for the parent feature id\n// and information about the children\n<divid=\"parent\"></div>\n<divid=\"my_children\"></div>\n<\nscripttype=\"text/javascript\">\nfunctionsetFeature(feature)\n{\n// Show the parent feature's identifier (using its \"ID\" field)\ndocument.getElementById('parent').innerHTML=feature.properties.ID;\n//clear the existing relation contents\ndocument.getElementById('my_children').innerHTML='';\nfeature.properties.my_relation.forEach(function(child_feature){\n// for each related child feature, create a list element\n// with the feature's name (using its \"NAME\" field)\nvarnode=document.createElement(\"li\");\nnode.appendChild(document.createTextNode(child_feature.NAME));\ndocument.getElementById('my_children').appendChild(node);\n});\n}\n</\nscript>\nDuring atlas creation there will be an iteration over the coverage layer containing the parent features. On each page,\nyou will see a bullet list of the related child features following the parent’s identifier.\n700Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n19.4Creating a Report\nThis section will help you set up a report in QGIS.\n19.4.1What is it?\nBy definition, a GIS report is a document containing information organized in a narrative way, containing maps, text,\ngraphics, tables, etc. A report can be prepared ad hoc, periodic, recurring, regular, or as required. Reports may refer\nto specific periods, events, occurrences, subjects or locations.\nIn QGIS, aReportis an extension of aLayouts.\nReports allow users to output their GIS projects in a simple, quick and structured way.\nA report can be created withProject►New Reportor inside theProject►Layout Manager.\nNote:The maps in QGIS reports behave in the same way as maps in print layouts and atlases. We will concentrate\non the specifics of QGIS reports. For details on map handling, see the sections onprint layoutsandatlases.\n19.4.2Get started\nIn theLayout Managerdialog a report can be created throughNew from templateby selecting the dropdown option\nEmpty Reportand hitting theCreate...button.\nFor this example, we use some administrative boundaries, populated places, ports and airports from the\nNatural Earth\ndataset(1:10M).\nUsing theProject►New Reportcommand, we create a blank report. Initially, there is not much to look at – the\ndialog which is displayed looks much like the print layout designer, except for theReport Organizerpanel to the left:\n19.4. Creating a Report701\n\nQGIS Desktop 3.22 User Guide\n19.4.3Layout Report Workspace\nQGIS reports can consist of multiple, nested sections. In our new blank report we initially only have the main report\nsection. The only options for this report section isInclude report headerandInclude report footer. If we enable these\noptions, a header will be included as the first page(s) (individual parts of reports can be multi-page if desired) in the\nreport, and a footer will constitute the last page(s). Enable the header (Include report header), and hit theEditbutton\nnext to it:\n702Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nA few things happen as a result. Firstly, an edit pencil is shown next toReportin theReport Organizer, indicating\nthat the report section is currently being edited in the designer. We also see a new page with a smallReport Header\ntitle. The page haslandscapeorientation by default, but this (and other properties of the page) can be changed by\nright-clicking on the page and choosingPage properties. This will bring up theItem propertiestab for the page, and\npageSize,Width,Height, and more can be specified.\nIn QGIS reports, every component of the report is made up of individual layouts. They can be created and modified\nusing the same tools as for standard print layouts – so you can use any desired combination of labels, pictures, maps,\ntables, etc. Let us add some items to our report header to demonstrate:\nWe will also create a simple footer for the report by checking theInclude report footeroption and hittingEdit.\n19.4. Creating a Report703\n\nQGIS Desktop 3.22 User Guide\nBefore proceeding further, let us export this report and see what we get. Exporting is done from theReportmenu – in\nthis case we selectExport Report as PDF...to render the whole report to a PDF file. Here is the not-very-impressive\nresult – a two page PDF consisting of our header and footer:\n704Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nLet us make things more interesting. By hitting the\nAdd Section\nbutton in theReport Organizer, we are given a\nchoice of new sections to add to our report.\n19.4. Creating a Report705\n\nQGIS Desktop 3.22 User Guide\nThere are two options:Static Layout SectionandField Group Section.\nTheAdd Static Layout Sectionis a single, static body layout. This can be used to embed static layouts mid-way through\na report.\nTheField Group Sectionrepeats its body layout for every feature of a layer. The features are sorted by the selected\ngrouping feature (with an option for ascending/descending sort). If a field group section has child sections (e.g.\nanother field group section with a different field), then only features with unique values for the group feature are\niterated over. This allows nested reports.\nFor now we will add aField Group Sectionto our report. At its most basic level, you can think of aField Group\nSectionas the equivalent of aprint atlas: you select a layer to iterate over, and the report will insert a section for each\nfeature found. Selecting the newField Group Sectionreveals a number of new related settings:\n706Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nIn this case we’ve setup our Field Group so that we iterate over all the states from theAdmin Level 1layer, using the\n19.4. Creating a Report707\n\nQGIS Desktop 3.22 User Guide\nvalues from theadm1namefield. The same options to include header and footer are present, together with a new\noption to include abodyfor this section. We’ll do that, and edit the body:\nOur body now consists of a map and a label showing the name of the state. To include the name of the state, we\nselectedAdd Item►Add Labeland data defined the text underMain Propertieswith the help ofInsert or Edit an\nExpression....\nThe result was the following expression (nameis the name of the attribute in theAdmin Level 1layer that contains\nthe name of the state):\n[%\"name\"%]\nThe map is set to follow the current report feature (enabled by checkingControlled by Report– just like a map item\nin an atlas will follow the current atlas feature whenControlled by Atlasis checked):\n708Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nIf we went ahead and exported our report now, we’d get something like this:\n19.4. Creating a Report709\n\nQGIS Desktop 3.22 User Guide\nFig. 19.68: The report header, a page for each state, and the report footer.\nSo more or less an atlas, but with a header and footer page.\nLet us make things more interesting by adding a subsection to our state group. We do this by first selecting theAdmin\nLevel 1field group in the organizer, then hitting the\nAdd Field\nbutton and adding a newField Group Section:\n710Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nWhen iterating over the features of aField Group Section, the features will be filtered to match the defining field\n19.4. Creating a Report711\n\nQGIS Desktop 3.22 User Guide\nof its parent group (adm1namein this case). Here, the subsection we added will iterate over aPopulated Places\nlayer, including a body section for each place encountered. The magic here is that thePopulated Placeslayer has an\nattribute with the same name as the defining field in the parent layer,adm1name, tagging each place with the state\nit is contained within (if you’re lucky your data will already be structured like this – if not, run theJoin Attributes by\nLocationProcessing algorithm and create your own field). When we export this report, QGIS will grab the first state\nfrom theAdmin Level 1layer, and then iterate over all thePopulated Placeswith a matchingadm1namevalue. Here’s\nwhat we get:\nHere we created a basic body for the Populated Places group, including a map of the place and a table of some place\nattributes. So our report is now a report header, a page for the first state, followed by a page for every populated place\nwithin that state, then the rest of the states with their populated places, and finally the report footer. If we were to\nadd a header for the Populated Places group, it would be included just before listing the populated places for each\nstate, as shown in the illustration below.\nSimilarly, a footer for the Populated Places group would be inserted after the final place for each state is included.\nIn addition to nested subsections, subsections in a report can also be included consecutively. If we add a second\nsubsection to theAdmin Level 1 groupforAirports, then (if theAirportslayer has an attributeadm1namethat can link\nit to the parent group) our report will first list ALL the populated places for each state, followed by all the airports\nwithin that state, before proceeding to the next state.\n712Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nThe key point here is that ourAirports groupis a subsection of theAdmin Level 1 group– not thePopulated Places\ngroup.\nIn this case our report would be structured like this (note that state flags have also been included - the procedure for\nadding feature specific pictures in this way is described below):\n19.4. Creating a Report713\n\nQGIS Desktop 3.22 User Guide\n714Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\nIncluding pictures in a report\nPictures can be quite useful in reports, and QGIS allows pictures in both the static and dynamic parts of a report.\nPictures are added in the same way as for standard print layouts, and for the static report parts (and static pictures in\ndynamic parts) there is not more to it.\nBut if you want illustrations that are tailored to the report features, your layer must have an attribute that can be used\nto define the picture to include.\nQGIS depends on absolute file names for images in reports.\nFor dynamic pictures, you first add a picture to the body part of the group, as usual. In theItem propertiesof the\npicture, you set theImage Sourceusing the\nData defined override\nbutton, and either select an attribute that contains the\nabsolute path of the images orEdit...(to enter an expression that generates the absolute image path).\nBelow is an example expression that uses string concatenation to specify the absolute path to the pictures, using the\ndirectory where the project file is located@project_path) and an attribute (adm1name) from which the file\nname is generated (in this case by transforming the string in theadm1nameattribute to uppercase, and appending\n‘_flag.png’):\nconcat(@project_folder,'/naturalearth/pictures/',\nupper(\"adm1name\"),'_flag.png')\nThis means that the pictures are located in thenaturalearth/picturessubdirectory of the project file direc-\ntory.\nHighlighting the current report feature in a map\nIn the above report, the report features are emphasized in the maps using highlighting (state) and circles (populated\nplaces). To emphasize the report features in the maps (apart from placing them at the centre of the maps), you must\ndata define the style using a comparison between its@idand the@atlas_featureid, as for atlases.\nFor instance, if you would like to use a thicker line / border for the report feature than the other features you can data\ndefine the line width:\nif($id=@atlas_featureid, 2.0, 0.1)\nThe report feature will get a 2 units wide polygon outline, while all other features will get a 0.1 units wide line. It\nis also possible to data define the colour (non-transparent dark magenta for the report feature and semi-transparent\nlight gray for the other features):\nif($id=@atlas_featureid, '#FF880088', '#88CCCCCC')\n19.4. Creating a Report715\n\nQGIS Desktop 3.22 User Guide\nMore level 1 groups\nCombining nested and consecutive sections, together with section headers and footers allows for tons of flexibility.\nFor instance, in the below report we add another field group as a child of the main report for the :guilabel`Ports` layer.\nNow, after listing the states together with their populated places and airports, we’ll get a summary list of all the ports\nin the region:\nThis results in the last part of our report exporting as:\n716Chapter 19. Laying out the maps\n\nQGIS Desktop 3.22 User Guide\n19.4.4Export settings\nWhen you export a report (Report►Export Report as Images... / SVG... / PDF...), you will be asked for a file name,\nand then you get the opportunity to tune the export settings to get the most appropriate output.\nAs you see, reports in QGIS are extremely powerful and flexible!\nNote:The current information was adapted from a North Road blog,Exploring Reports in QGIS 3.0 - the Ultimate\nGuide!\n19.4. Creating a Report717\n\nQGIS Desktop 3.22 User Guide\n718Chapter 19. Laying out the maps\n\nCHAPTER\nTWENTY\nWORKING WITH OGC / ISO PROTOCOLS\nThe Open Geospatial Consortium (OGC) is an international organization with membership of more than 300 com-\nmercial, governmental, nonprofit and research organizations worldwide. Its members develop and implement stan-\ndards for geospatial content and services, GIS data processing and exchange.\nDescribing a basic data model for geographic features, an increasing number of specifications are developed by OGC\nto serve specific needs for interoperable location and geospatial technology, including GIS. Further information can\nbe found athttps://www.ogc.org/.\nImportant OGC specifications supported by QGIS are:\n•WMS— Web Map Service (WMS/WMTS Client)\n•WMTS— Web Map Tile Service (WMS/WMTS Client)\n•WFS— Web Feature Service (WFS and WFS-T Client)\n•WFS-T— Web Feature Service - Transactional (WFS and WFS-T Client)\n•WCS\n— Web Coverage Service (\nWCS Client)\n•WPS— Web Processing Service\n•CSW— Catalog Service for the Web\n•SFS— Simple Features for SQL (PostGIS Layers)\n•GML— Geography Markup Language\nOGC services are increasingly being used to exchange geospatial data between different GIS implementations and\ndata stores. QGIS can deal with the above specifications as a client, beingSFS(through support of the PostgreSQL\n/ PostGIS data provider, see sectionPostGIS Layers).\nYou can also share your maps and data through the WMS, WMTS, WFS, WFS-T and WCS protocols using a web-\nserver with QGIS Server, UMN MapServer or GeoServer installed.\n20.1WMS/WMTS Client\n20.1.1Overview of WMS Support\nQGIS currently can act as a WMS client that understands WMS 1.1, 1.1.1 and 1.3 servers. In particular, it has been\ntested against publicly accessible servers such as DEMIS.\nA WMS server acts upon requests by the client (e.g., QGIS) for a raster map with a given extent, set of layers,\nsymbolization style, and transparency. The WMS server then consults its local data sources, rasterizes the map, and\nsends it back to the client in a raster format. For QGIS, this format would typically be JPEG or PNG.\nWMS is generically a REST (Representational State Transfer) service rather than a full-blown Web service. As such,\nyou can actually take the URLs generated by QGIS and use them in a web browser to retrieve the same images that\nQGIS uses internally. This can be useful for troubleshooting, as there are several brands of WMS server on the market\nand they all have their own interpretation of the WMS standard.\n719\n\nQGIS Desktop 3.22 User Guide\nWMSlayerscanbeaddedquitesimply, aslongasyouknowtheURLtoaccesstheWMSserver, youhaveaserviceable\nconnection to that server, and the server understands HTTP as the data transport mechanism.\nAdditionally, QGIS will cache your WMS responses (i.e. images) for 24h as long as the GetCapabilities request is not\ntriggered. The GetCapabilities request is triggered everytime theConnectbutton in theAdd Layer(s) from WMS(T)\nServerdialog is used to retrieve the WMS server capabilities. This is an automatic feature meant to optimize project\nloading time. If a project is saved with a WMS layer, the corresponding WMS tiles will be loaded from the cache\nthe next time the project is opened as long as they are no older than 24H.\n20.1.2Overview of WMTS Support\nQGIS can also act as a WMTS client. WMTS is an OGC standard for distributing tile sets of geospatial data. This is\na faster and more efficient way of distributing data than WMS because with WMTS, the tile sets are pre-generated,\nand the client only requests the transmission of the tiles, not their production. A WMS request typically involves\nboth the generation and transmission of the data. A well-known example of a non-OGC standard for viewing tiled\ngeospatial data is Google Maps.\nIn order to display the data at a variety of scales close to what the user might want, the WMTS tile sets are produced\nat several different scale levels and are made available for the GIS client to request them.\nThis diagram illustrates the concept of tile sets:\nFig. 20.1: Concept of WMTS tile sets\nThe two types of WMTS interfaces that QGIS supports are via Key-Value-Pairs (KVP) and RESTful. These two\ninterfaces are different, and you need to specify them to QGIS differently.\n1.In order to access aWMTS KVPservice, a QGIS user must open the WMS/WMTS interface and add the\nfollowing string to the URL of the WMTS tile service:\n\"?SERVICE=WMTS&REQUEST=GetCapabilities\"\nAn example of this type of address is\nhttps://opencache.statkart.no/gatekeeper/gk/gk.open_wmts?\\\nservice=WMTS&request=GetCapabilities\nFor testing the topo2 layer in this WMTS works nicely. Adding this string indicates that a WMTS web service\nis to be used instead of a WMS service.\n2.TheRESTful WMTSservice takes a different form, a straightforward URL. The format recommended by\nthe OGC is:\n{WMTSBaseURL}/1.0.0/WMTSCapabilities.xml\n720Chapter 20. Working with OGC / ISO protocols\n\nQGIS Desktop 3.22 User Guide\nThis format helps you to recognize that it is a RESTful address. A RESTful WMTS is accessed in QGIS by\nsimply adding its address in the WMS setup in the URL field of the form. An example of this type of address\nfor the case of an Austrian basemap ishttps://maps.wien.gv.at/basemap/1.0.0/WMTSCapabilities.xml.\nNote:You can still find some old services called WMS-C. These services are quite similar to WMTS (i.e., same\npurpose but working a little bit differently). You can manage them the same as you do WMTS services. Just add\n?tiled=trueat the end of the url. Seehttps://wiki.osgeo.org/wiki/Tile_Map_Service_Specificationfor more\ninformation about this specification.\nWhen you read WMTS, you can often think WMS-C also.\n20.1.3Selecting WMS/WMTS Servers\nThe first time you use the WMS feature in QGIS, there are no servers defined.\nYou then need to create connections to the server you are targeting:\n1.Go to theWMS/WMTStab of theData Source Managerdialog, either by:\n•clicking the\nOpen Data Source Manager\nbutton (or pressingCtrl+L) and enabling the tab\n•clicking the\nAdd WMS layer\nbutton on theManage Layerstoolbar\n•or selectingLayer►Add Layer►Add WMS/WMTS Layer...menu\n2.PressNewfrom theLayerstab. TheCreate a New WMS/WMTS Connection...dialog appears.\nTip:Right-click theWMS/WMTSentry from within theBrowser paneland selectNew Connection...also\nopens theCreate a New WMS/WMTS Connection...dialog.\n3.Then enter the parameters to connect to your desired WMS server, as listed below:\n20.1. WMS/WMTS Client721\n\nQGIS Desktop 3.22 User Guide\nFig. 20.2: Creating a connection to a WMS server\n•Name: A name for the connection. This name will be used in the Server Connections drop-down box so\nthat you can distinguish it from other WMS servers.\n•URL: URL of the server providing the data. This must be a resolvable host name – the same format as you\nwould use to open a telnet connection or ping a host, i.e. the base URL only. For example, you shouldn’t\nhave fragments such asrequest=GetCapabilitiesorversion=1.0.0in your URL.\n•Authentication(optional): using astored configurationor a basic authentication withUsernameandPass-\nword.\nWarning:Enteringusernameandpasswordin theAuthenticationtab will keep unprotected cre-\ndentials in the connection configuration. Thosecredentials will be visibleif, for instance, you shared\nthe project file with someone. Therefore, it’s advisable to save your credentials in aAuthentication\nconfigurationinstead (configurationstab). See\nAuthentication Systemfor more details.\n•HTTPReferer\n•DPI-Mode: Available options areall,off,QGIS,UMNandGeoServer\n•Ignore GetMap/GetTile URI reported in capabilities: if checked, use given URI from theURLfield\nabove.\n722Chapter 20. Working with OGC / ISO protocols\n\nQGIS Desktop 3.22 User Guide\n•Ignore GetFeatureInfo URI reported in capabilities: if checked, use given URI from theURLfield\nabove.\n•Ignore axis orientation (WMS 1.3/WMTS)\n•Ignore reported layer extents: because the extent reported by raster layers may be smaller than the\nactual area which can be rendered (notably for WMS servers with symbology which takes more space\nthan the data extent), check this option to avoid cropping raster layers to their reported extents, resulting\nin truncated symbols on the borders of these layers.\n•Invert axis orientation\n•Smooth pixmap transformation\n4.PressOK\nOnce the new WMS server connection has been created, it will be preserved for future QGIS sessions.\nIf you need to set up a proxy server to be able to receive WMS services from the internet, you can add your proxy\nserver in the options. ChooseSettings►Optionsand click on theNetworktab. There, you can add your proxy settings\nand enable them by settingUse proxy for web access. Make sure that you select the correct proxy type from the\nProxy typedrop-down menu.\n20.1.4Loading WMS/WMTS Layers\nOnce you have successfully filled in your parameters, you can use theConnectbutton to retrieve the capabilities of\nthe selected server. This includes the image encoding, layers, layer styles and projections. Since this is a network\noperation, the speed of the response depends on the quality of your network connection to the WMS server. While\ndownloading data from the WMS server, the download progress is visualized in the lower left corner of the main\nQGIS dialog.\nYour screen should now look a bit likeFig. 20.3, which shows the response provided by a WMS server.\n20.1. WMS/WMTS Client723\n\nQGIS Desktop 3.22 User Guide\nFig. 20.3: Dialog for adding a WMS server, with filter on available layers\nThe upper part of theLayerstab of the dialog shows a tree structure that can include layer groups embedding layers\nwith their associated image style(s) served by the server. Each item can be identified by:\n•anID\n•aName\n•aTitle\n•and anAbstract.\nThe list can be filtered using thewidget in the top right corner.\nImage Encoding\nTheImage encodingsection lists the formats that are supported by both the client and server. Choose one depending\non your image accuracy requirements.\nTip: Image Encoding\nYou will typically find that a WMS server offers you the choice of JPEG or PNG image encoding. JPEG is a lossy\ncompression format, whereas PNG faithfully reproduces the raw raster data.\nUse JPEG if you expect the WMS data to be photographic in nature and/or you don’t mind some loss in picture\nquality. This trade-off typically reduces by five times the data transfer requirement compared with PNG.\n724Chapter 20. Working with OGC / ISO protocols\n\nQGIS Desktop 3.22 User Guide\nUse PNG if you want precise representations of the original data and you don’t mind the increased data transfer\nrequirements.\nOptions\nThe Options area of the dialog provides means to configure the WMS requests. You can define:\n•Tile sizeif you want to set tile sizes (e.g., 256x256) to split up the WMS request into multiple requests.\n•Request step size: if you want to reduce the effect of cut labels at tile borders, increasing the step size creates\nlarger requests, fewer tiles and fewer borders. The default value is 2000.\n•TheMaximum number of GetFeatureInfo resultsfrom the server\n•Each WMS layer can be presented in multiple CRSs, depending on the capability of the WMS server. If you\nselect a WMS from the list, a field with the default projection provided by the web server appears. Press the :\nSelect CRS\nwidget to replace the default projection of the WMS with another CRS supported by the WMS\nserver.\nA dialog similar to the one shown inFig. 10.3will appear. The main difference with the WMS version of the\ndialog is that only those CRSs supported by the WMS server will be shown.\n•Finally you can activateUse contextual WMS Legendif the WMS Server supports this feature. Then only\nthe relevant legend for your current map view extent will be shown and thus will not include legend items for\nitems you can’t see in the current map.\nAt the bottom of the dialog, aLayer nametext field displays the selected item’sTitle. You can change the name at\nyour will. This name will appear in theLayerspanel after you pressed theAddbutton and loaded the layer(s) in\nQGIS.\nYou can select several layers at once, but only one image style per layer. When several layers are selected, they will\nbe combined at the WMS server and transmitted to QGIS in one go, as a single layer. The default name is a slash (\n/\n)\nseparated list of their original title.\nLayer Order\nTheLayer Ordertab lists the selected layers available from the current connected WMS server.\nWMS layers rendered by a server are overlaid in the order listed in theLayerstab, from top to bottom of the list. If\nyou want to change the overlay order, you can use theUpandDownbuttons of theLayer Ordertab.\nTransparency\nTheGlobal transparencysetting from theLayer Propertiesis hard coded to be always on, where available.\n20.1.5Tilesets\nWhen using WMTS (Cached WMS) services like\nhttps://opencache.statkart.no/gatekeeper/gk/gk.open_wmts?\\\nservice=WMTS&request=GetCapabilities\nyou are able to browse through theTilesetstab given by the server. Additional information like tile size, formats and\nsupported CRS are listed in this table. In combination with this feature, you can use the tile scale slider by selecting\nView►Panels( or\nSettings►Panels), then choosingTile Scale Panel. This gives you the available scales from\nthe tile server with a nice slider docked in.\n20.1. WMS/WMTS Client725\n\nQGIS Desktop 3.22 User Guide\n20.1.6Using the Identify Tool\nOnce you have added a WMS server, and if any layer from a WMS server is queryable, you can then use the\nIdentify\ntool to select a pixel on the map canvas. A query is made to the WMS server for each selection made. The\nresults of the query are returned in plain text. The formatting of this text is dependent on the particular WMS server\nused.\nFormat selection\nIf multiple output formats are supported by the server, a combo box with supported formats is automatically added\nto the identify results dialog and the selected format may be stored in the project for the layer.\nGML format support\nThe\nIdentify\ntool supports WMS server response (GetFeatureInfo) in GML format (it is called Feature in the QGIS\nGUI in this context). If “Feature” format is supported by the server and selected, results of the Identify tool are vector\nfeatures, as from a regular vector layer. When a single feature is selected in the tree, it is highlighted in the map and\nit can be copied to the clipboard and pasted to another vector layer. See the example setup of the UMN Mapserver\nbelow to support GetFeatureInfo in GML format.\n# in layer METADATA add which fields should be included and define geometry␣\n,→(example):\n\"gml_include_items\"\"all\"\n\"ows_geometries\"\"mygeom\"\n\"ows_mygeom_type\"\"polygon\"\n# Then there are two possibilities/formats available, see a) and b):\n# a) basic (output is generated by Mapserver and does not contain XSD)\n# in WEB METADATA define formats (example):\n\"wms_getfeatureinfo_formatlist\"\"application/vnd.ogc.gml,text/html\"\n# b) using OGR (output is generated by OGR, it is send as multipart and contains␣\n,→XSD)\n# in MAP define OUTPUTFORMAT (example):\nOUTPUTFORMAT\nNAME\"OGRGML\"\nMIMETYPE\"ogr/gml\"\nDRIVER\"OGR/GML\"\nFORMATOPTION\"FORM=multipart\"\nEND\n# in WEB METADATA define formats (example):\n\"wms_getfeatureinfo_formatlist\"\"OGRGML,text/html\"\nViewing Properties\nOnce you have added a WMS server, you can view its properties by right-clicking on it in the legend and selecting\nProperties.\nMetadata Tab\nThe tabMetadatadisplays a wealth of information about the WMS server, generally collected from the capabilities\nstatement returned from that server. Many definitions can be gleaned by reading the WMS standards (see OPEN-\nGEOSPATIAL-CONSORTIUM in\nLiterature and Web References), but here are a few handy definitions:\n•Server Properties\n–WMS Version— The WMS version supported by the server.\n–Image Formats— The list of MIME-types the server can respond with when drawing the map. QGIS\nsupports whatever formats the underlying Qt libraries were built with, which is typically at leastimage/\npngandimage/jpeg.\n726Chapter 20. Working with OGC / ISO protocols\n\nQGIS Desktop 3.22 User Guide\n–Identity Formats— The list of MIME-types the server can respond with when you use the Identify tool.\nCurrently, QGIS supports thetext-plaintype.\n•Layer Properties\n–Selected— Whether or not this layer was selected when its server was added to this project.\n–Visible— Whether or not this layer is selected as visible in the legend (not yet used in this version of\nQGIS).\n–Can Identify— Whether or not this layer will return any results when the Identify tool is used on it.\n–Can be Transparent— Whether or not this layer can be rendered with transparency. This version of\nQGIS will always use transparency if this isYesand the image encoding supports transparency.\n–Can Zoom In— Whether or not this layer can be zoomed in by the server. This version of QGIS\nassumes all WMS layers have this set toYes. Deficient layers may be rendered strangely.\n–Cascade Count— WMS servers can act as a proxy to other WMS servers to get the raster data for a\nlayer. This entry shows how many times the request for this layer is forwarded to peer WMS servers for\na result.\n–Fixed Width, Fixed Height— Whether or not this layer has fixed source pixel dimensions. This version\nof QGIS assumes all WMS layers have this set to nothing. Deficient layers may be rendered strangely.\n–WGS 84 Bounding Box— The bounding box of the layer, in WGS 84 coordinates. Some WMS servers\ndo not set this correctly (e.g., UTM coordinates are used instead). If this is the case, then the initial view\nof this layer may be rendered with a very ‘zoomed-out’ appearance by QGIS. The WMS webmaster should\nbe informed of this error, which they may know as the WMS XML elementsLatLonBoundingBox,\nEX_GeographicBoundingBoxor the CRS:84BoundingBox.\n–Available in CRS— The projections that this layer can be rendered in by the WMS server. These are\nlisted in the WMS-native format.\n–Available in style— The image styles that this layer can be rendered in by the WMS server.\n20.1.7Show WMS legend graphic in table of contents and layout\nThe QGIS WMS data provider is able to display a legend graphic in the table of contents’ layer list and in the print\nlayout. The WMS legend will be shown only if the WMS server has GetLegendGraphic capability and the layer has\ngetCapability url specified, so you additionally have to select a styling for the layer.\nIf a legendGraphic is available, it is shown below the layer. It is little and you have to click on it to open it in real\ndimension (due to QgsLegendInterface architectural limitation). Clicking on the layer’s legend will open a frame with\nthe legend at full resolution.\nIn the print layout, the legend will be integrated at it’s original (downloaded) dimension. Resolution of the legend\ngraphic can be set in the item properties underLegend►WMS LegendGraphicto match your printing requirements.\nThe legend will display contextual information based on your current scale. The WMS legend will be shown only if\nthe WMS server has GetLegendGraphic capability and the layer has getCapability url specified, so you have to select\na styling.\n20.1. WMS/WMTS Client727\n\nQGIS Desktop 3.22 User Guide\n20.1.8WMS Client Limitations\nNot all possible WMS client functionality had been included in this version of QGIS. Some of the more noteworthy\nexceptions follow.\nEditing WMS Layer Settings\nOnce you’ve completed the\nAdd WMS layer\nprocedure, there is no way to change the settings. A work-around is to\ndelete the layer completely and start again.\nWMS Servers Requiring Authentication\nCurrently, publicly accessible and secured WMS services are supported. The secured WMS servers can be accessed\nby public authentication. You can add the (optional) credentials when you add a WMS server. See sectionSelecting\nWMS/WMTS Serversfor details.\nTip: Accessing secured OGC-layers\nIf you need to access secured layers with secured methods other than basic authentication, you can use InteProxy\nas a transparent proxy, which does support several authentication methods. More information can be found in the\nInteProxy manual at\nhttps://inteproxy.wald.intevation.org.\nTip: QGIS WMS Mapserver\nSince Version 1.7.0, QGIS has its own implementation of a WMS 1.3.0 Mapserver. Read more about this in QGIS-\nServer-manual.\n20.2WCS Client\nA Web Coverage Service (WCS) provides access to raster data in forms that are useful for client-side rendering,\nas input into scientific models, and for other clients. The WCS may be compared to the WFS and the WMS. As\nWMS and WFS service instances, a WCS allows clients to choose portions of a server’s information holdings based\non spatial constraints and other query criteria.\nQGIS has a native WCS provider and supports both version 1.0 and 1.1 (which are significantly different), but cur-\nrently it prefers 1.0, because 1.1 has many issues (i.e., each server implements it in a different way with various\nparticularities).\nThe native WCS provider handles all network requests and uses all standard QGIS network settings (especially proxy).\nIt is also possible to select cache mode (‘always cache’, ‘prefer cache’, ‘prefer network’, ‘always network’), and the\nprovider also supports selection of time position, if temporal domain is offered by the server.\nWarning:Enteringusernameandpasswordin theAuthenticationtab will keep unprotected credentials in\nthe connection configuration. Thosecredentials will be visibleif, for instance, you shared the project file with\nsomeone. Therefore, it’s advisable to save your credentials in aAuthentication configurationinstead (configurations\ntab). See\nAuthentication Systemfor more details.\n728Chapter 20. Working with OGC / ISO protocols\n\nQGIS Desktop 3.22 User Guide\n20.3WFS and WFS-T Client\nIn QGIS, a WFS layer behaves pretty much like any other vector layer. You can identify and select features, and\nview the attribute table. QGIS supports WFS 1.0.0, 1.1.0, 2.0 and OGC API - Features (OAPIF), including editing\n(through WFS-T).\nIn general, adding a WFS layer is very similar to the procedure used with WMS. There are no default servers defined,\nso you have to add your own. You can find WFS servers by using theMetaSearch pluginor your favourite web search\nengine. There are a number of lists with public URLs, some of them maintained and some not.\nLoading a WFS Layer\nAs an example, we use the Gateway Geomatics WFS server and display a layer.https://demo.gatewaygeomatics.\ncom/cgi-bin/wfs_gateway?REQUEST=GetCapabilities&VERSION=1.0.0&SERVICE=WFS\nTo be able to load a WFS Layer, first create a connection to the WFS server:\n1.Open theData Source Managerdialog by pressing the\nOpen Data Source Manager\nbutton\n2.Enable theWFS/OGC API-Featurestab\n3.Click onNew...to open theCreate a New WFS Connectiondialog\n4.EnterGateway Geomaticsas name\n5.Enter the URL (see above)\nFig. 20.4: Creating a connection to a WFS server\nNote:In case of an OGC API - Features (OAPIF), the URL to provide should be the landing page, ie the\n20.3. WFS and WFS-T Client729\n\nQGIS Desktop 3.22 User Guide\nmain page from which it is possible to navigate to all the available service endpoints.\n6.In the WFS settings dialog, you can:\n•Indicate the WFS version of the server. If unknown, press theDetectbutton to automatically retrieve it.\n•Define themaximum number of featuresretrieved in a single GetFetFeature request. If empty, no limit\nis set.\n•Invert axis orientation.\n•And depending on the WFS version:\n–Force toIgnore axis orientation (WFS 1.1/WFS 2.0)\n–Enable feature pagingand specify the maximum number of features to retrieve withPage size. If no\nlimit is defined, then the server default is applied.\nWarning:Enteringusernameandpasswordin theAuthenticationtab will keep unprotected credentials\nin the connection configuration. Thosecredentialswillbevisibleif, for instance, you shared the project file\nwith someone. Therefore, it’s advisable to save your credentials in anAuthentication configurationinstead\n(Configurationstab). See\nAuthentication Systemfor more details.\n7.PressOKto create the connection.\nNote that any proxy settings you may have set in your preferences are also recognized.\nNow we are ready to load WFS layers from the above connection.\n1.Choose ‘Gateway Geomatics’ from theServer Connectionsdrop-down list.\n2.ClickConnect\n3.Select theParkslayer in the list\n4.You can also choose whether to:\n•Use title for layer name, showing the layer’s title as defined on the server in theLayerspanel instead\nof itsName\n•Only request features overlapping the view extent\n•Changethe layer’s CRS\n•orBuild queryto specify particular features to retrieve, by either using the corresponding button or double-\nclicking the target layer.\n5.ClickAddto add the layer to the map.\n730Chapter 20. Working with OGC / ISO protocols\n\nQGIS Desktop 3.22 User Guide\nFig. 20.5: Adding a WFS layer\nYou’ll notice the download progress is visualized in the lower left of the QGIS main window. Once the layer is loaded,\nyou can identify and select a couple of features and view the attribute table.\nNote:QGIS supports different versions of the WFS protocol, with background download and progressive rendering,\non-disk caching of downloaded features and version autodetection.\n20.3. WFS and WFS-T Client731\n\nQGIS Desktop 3.22 User Guide\n732Chapter 20. Working with OGC / ISO protocols\n\nCHAPTER\nTWENTYONE\nWORKING WITH GPS DATA\n21.1GPS Plugin\n21.1.1What is GPS?\nGPS, the Global Positioning System, is a satellite-based system that allows anyone with a GPS receiver to find their\nexact position anywhere in the world. GPS is used as an aid in navigation, for example in airplanes, in boats and\nby hikers. The GPS receiver uses the signals from the satellites to calculate its latitude, longitude and (sometimes)\nelevation. Most receivers also have the capability to store locations (known aswaypoints), sequences of locations\nthat make up a plannedrouteand a tracklog ortrackof the receiver’s movement over time. Waypoints, routes and\ntracks are the three basic feature types in GPS data. QGIS displays waypoints in point layers, while routes and tracks\nare displayed in linestring layers.\nNote:QGIS supports also GNSS receivers. But we keep using the term GPS in this documentation.\n21.1.2Loading GPS data from a file\nThere are dozens of different file formats for storing GPS data. The format that QGIS uses is called GPX (GPS\neXchange format), which is a standard interchange format that can contain any number of waypoints, routes and\ntracks in the same file.\nTo load a GPX file, you first need to load the plugin.Plugins►\nPlugin Manager...opens the Plugin Manager\nDialog. Activate theGPS Toolscheckbox. When this plugin is loaded, a button with a small handheld GPS device\nwill show up in the toolbar and inLayer►Create Layer► :\n•\nGPS Tools\n•Create new GPX Layer\nFor working with GPS data, we provide an example GPX file available in the QGIS sample dataset:\nqgis_sample_data/gps/national_monuments.gpx. See sectionDownloading sample datafor more\ninformation about the sample data.\n1.SelectVector►GPS Toolsor click the\nGPS Tools\nicon in the toolbar and open theLoad GPX filetab (see\nFig. 21.1).\n2.Browse to the folderqgis_sample_data/gps/, select the GPX filenational_monuments.gpx\nand clickOpen.\n733\n\nQGIS Desktop 3.22 User Guide\nFig. 21.1: TheGPS Toolsdialog window\nUse theBrowse...button to select the GPX file, then use the checkboxes to select the feature types you want\nto load from that GPX file. Each feature type will be loaded in a separate layer when you clickOK. The file\nnational_monuments.gpxonly includes waypoints.\nNote:GPS units allow you to store data in different coordinate systems. When downloading a GPX file (from\nyour GPS unit or a web site) and then loading it in QGIS, be sure that the data stored in the GPX file uses WGS 84\n(latitude/longitude). QGIS expects this, and it is the official GPX specification. Seehttps://www.topografix.com/\nGPX/1/1/.\n21.1.3GPSBabel\nSince QGIS uses GPX files, you need a way to convert other GPS file formats to GPX. This can be done for many\nformats using the free program GPSBabel, which is available athttps://www.gpsbabel.org. This program can also\ntransfer GPS data between your computer and a GPS device. QGIS uses GPSBabel to do these things, so it is\nrecommended that you install it. However, if you just want to load GPS data from GPX files you will not need it.\nVersion 1.2.3 of GPSBabel is known to work with QGIS, but you should be able to use later versions without any\nproblems.\n21.1.4Importing GPS data\nTo import GPS data from a file that is not a GPX file, you use the toolImport other filein the GPS Tools dialog.\nHere, you select the file that you want to import (and the file type), which feature type you want to import from it,\nwhere you want to store the converted GPX file and what the name of the new layer should be. Note that not all GPS\ndata formats will support all three feature types, so for many formats you will only be able to choose between one or\ntwo types.\n21.1.5Downloading GPS data from a device\nQGIS can use GPSBabel to download data from a GPS device directly as new vector layers. For this we use the\nDownload from GPStab of the GPS Tools dialog (seeFig. 21.2). Here, we select the type of GPS device, the port\nthat it is connected to (or USB if your GPS supports this), the feature type that you want to download, the GPX file\nwhere the data should be stored, and the name of the new layer.\n734Chapter 21. Working with GPS Data\n\nQGIS Desktop 3.22 User Guide\nFig. 21.2: The download tool\nThe device type you select in the GPS device menu determines how GPSBabel tries to communicate with your GPS\ndevice. If none of the available types work with your GPS device, you can create a new type (see sectionDefining\nnew device types\n).\nThe port may be a file name or some other name that your operating system uses as a reference to the physical port\nin your computer that the GPS device is connected to. It may also be simply USB, for USB-enabled GPS units.\n•On Linux, this is something like\n/dev/ttyS0\nor\n/dev/ttyS1\n.\n•On Windows, it isCOM1orCOM2.\nWhen you clickOK, the data will be downloaded from the device and appear as a layer in QGIS.\n21.1.6Uploading GPS data to a device\nYou can also upload data directly from a vector layer in QGIS to a GPS device using theUpload to GPStab of the\nGPS Tools dialog. To do this, you simply select the layer that you want to upload (which must be a GPX layer), your\nGPS device type, and the port (or USB) that it is connected to. Just as with the download tool, you can specify new\ndevice types if your device isn’t in the list.\nThis tool is very useful in combination with the vector-editing capabilities of QGIS. It allows you to load a map,\ncreate waypoints and routes, and then upload them and use them on your GPS device.\n21.1.7Defining new device types\nThere are lots of different types of GPS devices. The QGIS developers can’t test all of them, so if you have one that\ndoes not work with any of the device types listed in theDownload from GPSandUpload to GPStools, you can define\nyour own device type for it. You do this by using the GPS device editor, which you start by clicking theEdit Devices\nbutton in the download or the upload tab.\nTo define a new device, you simply click theNew Devicebutton, enter a name, enter download and upload commands\nfor your device, and click theUpdate Devicebutton. The name will be listed in the device menus in the upload and\ndownload windows – it can be any string. The download command is the command that is used to download data\nfrom the device to a GPX file. This will probably be a GPSBabel command, but you can use any other command\nline program that can create a GPX file. QGIS will replace the keywords%type,%in, and%outwhen it runs the\ncommand.\n%typewill be replaced by-wif you are downloading waypoints,-rif you are downloading routes and-tif you\nare downloading tracks. These are command-line options that tell GPSBabel which feature type to download.\n%inwill be replaced by the port name that you choose in the download window and%outwill be replaced by the\nname you choose for the GPX file that the downloaded data should be stored in. So, if you create a device type\nwith the download commandgpsbabel %type -i garmin -o gpx %in %out(this is actually the\n21.1. GPS Plugin735\n\nQGIS Desktop 3.22 User Guide\ndownload command for the predefined device type ‘Garmin serial’) and then use it to download waypoints from port\n/dev/ttyS0to the fileoutput.gpx, QGIS will replace the keywords and run the commandgpsbabel -w\n-i garmin -o gpx /dev/ttyS0 output.gpx.\nThe upload command is the command that is used to upload data to the device. The same keywords are used, but\n%inis now replaced by the name of the GPX file for the layer that is being uploaded, and%outis replaced by the\nport name.\nYou can learn more about GPSBabel and its available command line options athttps://www.gpsbabel.org.\nOnce you have created a new device type, it will appear in the device lists for the download and upload tools.\n21.1.8Download of points/tracks from GPS units\nAs described in previous sections QGIS uses GPSBabel to download points/tracks directly in the project. QGIS comes\nout of the box with a pre-defined profile to download from Garmin devices. Unfortunately there is a\nbug #6318that\ndoes not allow create other profiles, so downloading directly in QGIS using the GPS Tools is at the moment limited\nto Garmin USB units.\nGarmin GPSMAP 60cs\nMS Windows\nInstall the Garmin USB drivers fromhttps://www8.garmin.com/support/download_details.jsp?id=591\nConnect the unit. Open GPS Tools and usetype=garmin serialandport=usb:Fill the fieldsLayer name\nandOutput file. Sometimes it seems to have problems saving in a certain folder, using something likec:\\temp\nusually works.\nUbuntu/Mint GNU/Linux\nIt is first needed an issue about the permissions of the device, as described athttps://wiki.openstreetmap.org/wiki/\nUSB_Garmin_on_GNU/Linux\n. You can try to create a file/etc/udev/rules.d/51-garmin.rulescon-\ntaining this rule\nATTRS{idVendor}==\"091e\", ATTRS{idProduct}==\"0003\", MODE=\"666\"\nAfter that is necessary to be sure that thegarmin_gpskernel module is not loaded\nrmmod garmin_gps\nand then you can use the GPS Tools. Unfortunately there seems to be abug #7182and usually QGIS freezes several\ntimes before the operation work fine.\nBTGP-38KM datalogger (only Bluetooth)\nMS Windows\nThe already referred bug does not allow to download the data from within QGIS, so it is needed to use GPSBabel\nfrom the command line or using its interface. The working command is\ngpsbabel-t-i skytraq,baud=9600,initbaud=9600-f COM9-o gpx-F C:/GPX/aaa.gpx\nUbuntu/Mint GNU/Linux\nUse same command (or settings if you use GPSBabel GUI) as in Windows. On Linux it maybe somehow common\nto get a message like\nskytraq: Too many read errors on serial port\nit is just a matter to turn off and on the datalogger and try again.\n736Chapter 21. Working with GPS Data\n\nQGIS Desktop 3.22 User Guide\nBlueMax GPS-4044 datalogger (both BT and USB)\nMS Windows\nNote:It needs to install its drivers before using it on Windows 7. See in the manufacturer site for the proper\ndownload.\nDownloading with GPSBabel, both with USB and BT returns always an error like\ngpsbabel-t-i mtk-f COM12-o gpx-F C:/temp/test.gpx\nmtk_logger: Can't create temporary file data.bin\nError running gpsbabel: Process exited unsuccessfullywithcode1\nUbuntu/Mint GNU/Linux\nWith USB\nAfter having connected the cable use thedmesgcommand to understand what port is being used, for example\n/dev/ttyACM3. Then as usual use GPSBabel from the CLI or GUI\ngpsbabel-t-i mtk-f/dev/ttyACM3-o gpx-F/home/user/bluemax.gpx\nWith Bluetooth\nUse Blueman Device Manager to pair the device and make it available through a system port, then run GPSBabel\ngpsbabel-t-i mtk-f/dev/rfcomm0-o gpx-F/home/user/bluemax_bt.gpx\n21.2Live GPS tracking\nTo activate live GPS tracking in QGIS, you need to selectView►PanelsGPS Information Panelor pressCtrl+0.\nYou will get a new docked window on the left side of the canvas.\nThere are three possible screens in this GPS tracking window:\n•\nPosition\n: GPS position coordinates and an interface for manually entering vertices and features\n•\nSignal\n: signal strength of satellite connections\n•\nOptions\n:GPS options screen (seeFig. 21.5)\nWith a plugged-in GPS receiver (has to be supported by your operating system), a simple click onConnectconnects\nthe GPS to QGIS. A second click (now onDisconnect) disconnects the GPS receiver from your computer. For\nGNU/Linux, gpsd support is integrated to support connection to most GPS receivers. Therefore, you first have to\nconfigure gpsd properly to connect QGIS to it.\nWith theRecenterbutton the map will jump to the current GPS position.\nWarning:If you want to record your position to the canvas, you have to create a new vector layer first and switch\nit to editable status to be able to record your track.\nWhen a GPS device is connected and the user moves the cursor over the map canvas, a live status bar message displays\nthe distance and bearing from the cursor to the GPS position. Project distance and bearing settings are respected in\nthis display.\nTip: Touch Screen Devices\n21.2. Live GPS tracking737\n\nQGIS Desktop 3.22 User Guide\nOn a touch screen device use a tap-and-hold event to trigger the live status bar message.\n21.2.1Position and additional attributes\nIf the GPS is receiving signals from satellites, you will see your position in latitude, longitude and altitude together\nwith additional attributes.\nFig. 21.3: GPS tracking position and additional attributes\n21.2.2GPS signal strength\nHere, you can see the signal strength of the satellites you are receiving signals from.\nFig. 21.4: GPS tracking signal strength\n738Chapter 21. Working with GPS Data\n\nQGIS Desktop 3.22 User Guide\n21.2. Live GPS tracking739\n\nQGIS Desktop 3.22 User Guide\n21.2.3GPS options\nFig. 21.5: GPS tracking options window\n740Chapter 21. Working with GPS Data\n\nQGIS Desktop 3.22 User Guide\nHere you can specify:\n•Connection\n–In case of connection problems, you can switch between:\n∗Autodetect\n∗Serial device(reload required if a new GPS Device is connected)\n∗gpsd(selecting the Host, Port and Device your GPS is connected to)\n–A click onConnectagain initiates the connection to the GPS receiver.\n•Digitizing\n–You can activateAutomatically save added featureswhen you are in editing mode. Or you can activate\nAutomatically add pointsto the map canvas with a certain width and color.\n–TheCalculate bearing from travel directioncan be used if the device reports faulty bearing measurements\nand it will calculate the GPS bearing based on the previous two recorded locations.\n•Cursor: you can use a sliderto shrink and grow the position cursor on the canvas.\n•Filtering: You can also set anAcquisition interval (seconds)and aDistance threshold (meters)parameters to\nkeep the cursor still active when the receiver is in static conditions.\n•Map Centering and Rotation\n–ActivatingMap centeringallows you to decide in which way the canvas will be updated. This includes\n‘always’, ‘when leaving’, if your recorded coordinates start to move out of the canvas, or ‘never’, to keep\nmap extent.\n–ActivatingRotate map to match GPS directionwill automatically rotate the map canvas so that it is oriented\nin the same direction as the GPS bearing.\n•ActivatingShow Bearing Linewill show a line from the GPS location pointing in current path direction of the\nGPS.\n•Finally, you can activateLog fileand define a path and a file where log messages about the GPS tracking\nare logged.\nIf you want to set a feature manually, you have to go back to\nPosition\nand click onAdd PointorAdd Track Point.\n21.2.4Connect to a Bluetooth GPS for live tracking\nWith QGIS you can connect a Bluetooth GPS for field data collection. To perform this task you need a GPS Bluetooth\ndevice and a Bluetooth receiver on your computer.\nAt first you must let your GPS device be recognized and paired to the computer. Turn on the GPS, go to the Bluetooth\nicon on your notification area and search for a New Device.\nOn the right side of the Device selection mask make sure that all devices are selected so your GPS unit will probably\nappear among those available. In the next step a serial connection service should be available, select it and click on\nConfigurebutton.\nRemember the number of the COM port assigned to the GPS connection as resulting by the Bluetooth properties.\nAfter the GPS has been recognized, make the pairing for the connection. Usually the authorization code is0000.\nNow openGPS informationpanel and switch toGPS options screen. Select the COM port assigned to the GPS\nconnection and click theConnect. After a while a cursor indicating your position should appear.\n21.2. Live GPS tracking741\n\nQGIS Desktop 3.22 User Guide\nIf QGIS can’t receive GPS data, then you should restart your GPS device, wait 5-10 seconds then try to connect again.\nUsuallythissolutionwork. Ifyoureceiveagainaconnectionerrormakesureyoudon’thaveanotherBluetoothreceiver\nnear you, paired with the same GPS unit.\n21.2.5Using GPSMAP 60cs\nMS Windows\nEasiest way to make it work is to use a middleware (freeware, not open) calledGPSGate.\nLaunch the program, make it scan for GPS devices (works for both USB and BT ones) and then in QGIS just click\nConnectin the Live tracking panel using theAutodetectmode.\nUbuntu/Mint GNU/Linux\nAs for Windows the easiest way is to use a server in the middle, in this case GPSD, so\nsudo apt install gpsd\nThen load thegarmin_gpskernel module\nsudo modprobe garmin_gps\nAnd then connect the unit. Then check withdmesgthe actual device being used bu the unit, for example/dev/\nttyUSB0. Now you can launch gpsd\ngpsd/dev/ttyUSB0\nAnd finally connect with the QGIS live tracking tool.\n21.2.6Using BTGP-38KM datalogger (only Bluetooth)\nUsing GPSD (under Linux) or GPSGate (under Windows) is effortless.\n21.2.7Using BlueMax GPS-4044 datalogger (both BT and USB)\nMS Windows\nThe live tracking works for both USB and BT modes, by using GPSGate or even without it, just use theAutodetect\nmode, or point the tool the right port.\nUbuntu/Mint GNU/Linux\nFor USB\nThe live tracking works both with GPSD\ngpsd/dev/ttyACM3\nor without it, by connecting the QGIS live tracking tool directly to the device (for example/dev/ttyACM3).\nFor Bluetooth\nThe live tracking works both with GPSD\n742Chapter 21. Working with GPS Data\n\nQGIS Desktop 3.22 User Guide\ngpsd/dev/rfcomm0\nor without it, by connecting the QGIS live tracking tool directly to the device (for example/dev/rfcomm0).\n21.2. Live GPS tracking743\n\nQGIS Desktop 3.22 User Guide\n744Chapter 21. Working with GPS Data\n\nCHAPTER\nTWENTYTWO\nAUTHENTICATION SYSTEM\n22.1Authentication System Overview\nFig. 22.1: Anatomy of authentication system\n22.1.1Authentication database\nThe new authentication system stores authentication configurations in an SQLite database file located, by default, at\n<profile directory>/qgis-auth.db.\nThis authentication database can be moved between QGIS installations without affecting other current QGIS user\npreferences, as it is completely separate from normal QGIS settings. A configuration ID (a random 7-character\nalphanumeric string) is generated when initially storing a configuration to the database. This represents the configu-\nration, thereby allowing the ID to be stored in plain text application components, (such as project, plugin, or settings\nfiles) without disclosure of its associated credentials.\nNote:The parent directory of theqgis-auth.dbcan be set using the following environment variable,\nQGIS_AUTH_DB_DIR_PATH, or set on the command line during launch with the--authdbdirectoryop-\ntion.\n745\n\nQGIS Desktop 3.22 User Guide\n22.1.2Master password\nTo store or access sensitive information within the database, a user must define amaster password. A new master\npassword is requested and verified when initially storing any encrypted data to the database. When sensitive infor-\nmation is accessed, the user is prompted for the master password. The password is then cached for the remainder\nof the session (until application is quit), unless the user manually chooses an action to clear its cached value. Some\ninstances of using the authentication system do not require input of the master password, such as when selecting an\nexisting authentication configuration, or applying a configuration to a server configuration (such as when adding a\nWMS layer).\nYou can choose to save the password in theWallet/Keyringof your computer.\nFig. 22.2: Input new master password\nNote:A path to a file containing the master password can be set using the following environment variable,\nQGIS_AUTH_PASSWORD_FILE.\nManaging the master password\nOnce set, the master password can be reset; the current master password will be needed prior to resetting. During\nthis process, there is an option to generate a complete backup of the current database.\nFig. 22.3: Resetting master password\nIf the user forgets the master password, there is no way to retrieve or override it. There is also no means of retrieving\nencrypted information without knowing the master password.\nIf a user inputs their existing password incorrectly three times, the dialog will offer to erase the database.\n746Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.4: Password prompt after three invalid attempts\n22.1.3Authentication Configurations\nYou can manage authentication configurations fromConfigurationsin theAuthenticationtab of the QGIS Options\ndialog (Settings►Options).\nFig. 22.5: Configurations editor\nUse thebutton to add a new configuration, thebutton to remove configurations, and thebutton to modify\nexisting ones.\n22.1. Authentication System Overview747\n\nQGIS Desktop 3.22 User Guide\nFig. 22.6: Adding config from within Configuration editor\nThe same type of operations for authentication configuration management (Add, Edit and Remove) can be done when\nconfiguring a given service connection, such as configuring an OWS service connection. For that, there are action\nbuttons within the configuration selector for fully managing configurations found within the authentication database.\nIn this case, there is no need to go to theconfigurationsinAuthenticationtab of QGIS options unless you need to do\nmore comprehensive configuration management.\nFig. 22.7: WMS connection dialog showingAdd,Edit, andRemoveauthentication configuration buttons\nWhen creating or editing an authentication configuration, the info required is a name, an authentication method\n748Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nand any other info that the authentication method requires (see more about the available authentication types in\nAuthentication Methods).\n22.1.4Authentication Methods\nAvailable authentications are provided by C++ plugins much in the same way data provider plugins are supported by\nQGIS. The method of authentication that can be selected is relative to the access needed for the resource/provider, e.g.\nHTTP(S) or database, and whether there is support in both QGIS code and a plugin. As such, some authentication\nmethod plugins may not be applicable everywhere an authentication configuration selector is shown. A list of available\nauthentication method plugins and their compatible resource/providers can be accessed going toSettings►Options\nand, in theAuthenticationtab, click theInstalled Pluginsbutton.\nFig. 22.8: Available method plugins list\nPlugins can be created for new authentication methods that do not require QGIS to be recompiled. Since the support\nfor plugins is currently C++-only, QGIS will need to be restarted for the new dropped-in plugin to become available\nto the user. Ensure your plugin is compiled against the same target version of QGIS if you intend to add it to an\nexisting target install.\nFig. 22.9: Basic HTTP authentication configs\n22.1. Authentication System Overview749\n\nQGIS Desktop 3.22 User Guide\nFig. 22.10: ESRI Token authentication configs\n750Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.11: OAuth2 authentication configs\n22.1. Authentication System Overview751\n\nQGIS Desktop 3.22 User Guide\nFig. 22.12: PKI paths authentication configs\nFig. 22.13: PKI PKCS#12 file paths authentication configs\nFig. 22.14: Stored Identity authentication configs\nNote:The Resource URL is currently anunimplementedfeature that will eventually allow a particular configuration\nto be auto-chosen when connecting to resources at a given URL.\n752Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\n22.1.5Master Password and Auth Config Utilities\nUnder the Options menu (Settings►Options) in theAuthenticationtab, there are several utility actions to manage the\nauthentication database and configurations:\nFig. 22.15: Utilities menu\n•Input master password: opens the master password input dialog, independent of performing any authenti-\ncation database command\n•Clear cached master password: unsets the master password if it has been set\n•Reset master password: opens a dialog to change the master password (the current password must be known)\nand optionally back up the current database\n•Clear network authentication access cache: clears the authentication cache of all connections\n•Automatically clear network authentication access cache on SSL errors: the connection cache stores all\nauthentication data for connections, also when the connection fails. If you change authentication configurations\nor certification authorities, you should clear the authentication cache or restart QGIS. When this option is\nchecked, the authentication cache will be automatically cleared every time an SSL error occurs and you choose\nto abort the connection\n•Integrate master password with your Wallet/Keyring: adds the master password to your personal Wal-\nlet/Keyring\n•Store/update the master password in your Wallet/Keyring: updates the changed master password in your\nWallet/Keyring\n•Clear the master password from your Wallet/Keyring: deletes the master password from your Wal-\nlet/Keyring\n•Enable password helper debug log: enables a debug tool that will contain all the log information of the\nauthentication methods\n•Clear cached authentication configurations: clears the internal lookup cache for configurations, used to\nspeed up network connections. This does not clear QGIS’s core network access manager’s cache, which requires\na relaunch of QGIS.\n•Remove allauthenticationconfigurations: clears the database of all configuration records, without removing\nother stored records.\n22.1. Authentication System Overview753\n\nQGIS Desktop 3.22 User Guide\n•Erase authentication database: schedules a backup of the current database and complete rebuild of the\ndatabase table structure. The actions are scheduled for a later time, to ensure that other operations, like project\nloading, do not interrupt the operation or cause errors due to a temporarily missing database.\nFig. 22.16: DB erase verification menu\n22.1.6Using authentication configurations\nTypically, an authentication configuration is selected in a configuration dialog for a network services (such as WMS).\nHowever, the selector widget can be embedded anywhere authentication is needed or in non-core functionality, like\nin third-party PyQGIS or C++ plugins.\nWhen using the selector,No authenticationis displayed in the pop-up menu control when nothing is selected, when\nthere are no configurations to choose from, or when a previously assigned configuration can no longer be found in\nthe database. TheTypeandIdfields are read-only and provide a description of the authentication method and the\nconfig’s ID respectively.\nFig. 22.17: Authentication configuration selector with no authentication\nFig. 22.18: Authentication configuration selector with selected config\n22.1.7Python bindings\nAll classes and public functions have sip bindings, exceptQgsAuthCrypto, since management of the master\npassword hashing and auth database encryption should be handled by the main app, and not via Python. SeeSecurity\nConsiderations\nconcerning Python access.\n754Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\n22.2User Authentication Workflows\nFig. 22.19: Generic user workflow\n22.2.1HTTP(S) authentication\nOne of the most common resource connections is via HTTP(S), e.g. web mapping servers, and authentication method\nplugins often work for these types of connections. Method plugins have access to the HTTP request object and can\nmanipulate both the request as well as its headers. This allows for many forms of internet-based authentication. When\nconnecting via HTTP(S) using the standard username/password authentication method will attempt HTTP BASIC\nauthentication upon connection.\n22.2. User Authentication Workflows755\n\nQGIS Desktop 3.22 User Guide\nFig. 22.20: Configuring a WMS connection for HTTP BASIC\n22.2.2Database authentication\nConnections to database resources are generally stored askey=valuepairs, which will expose usernames and\n(optionally) passwords, ifnotusing an authentication configuration. When configuring with the auth system, the\nkey=valuewill be an abstracted representation of the credentials, e.g.authfg=81t21b9.\n756Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.21: Configuring a Postgres SSL-with-PKI connection\n22.2.3PKI authentication\nWhen configuring PKI components within the authentication system, you have the option of importing components\nintothedatabaseorreferencingcomponentfilesstoredonyourfilesystem. Thelattermaybeusefulifsuchcomponents\nchange frequently, or where the components will be replaced by a system administrator. In either instance you will\nneed to store any passphrase needed to access private keys within the database.\n22.2. User Authentication Workflows757\n\nQGIS Desktop 3.22 User Guide\nFig. 22.22: PKI configuration workflow\nAll PKI components can be managed in separate editors within theCertificate Manager, which can be accessed in\ntheAuthenticationtab in QGISOptionsdialog (Settings►Options) by clicking theManage Certificatesbutton.\n758Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.23: Opening the Certificate Manager\nIn theCertificate Manager, there are editors forIdentities,ServersandAuthorities. Each of these are contained in\ntheir own tabs, and are described below in the order they are encountered in the workflow chart above. The tab order\nis relative to frequently accessed editors once you are accustomed to the workflow.\nNote:Because all authentication system edits write immediately to the authentication database, there is no need to\nclick theOptionsdialogOKbutton for any changes to be saved. This is unlike other settings in the Options dialog.\nAuthorities\nYou can manage available Certificate Authorities (CAs) from theAuthoritiestab in theCertificate managerfrom\ntheAuthenticationtab of the QGISOptionsdialog.\nAs referenced in the workflow chart above, the first step is to import or reference a file of CAs. This step is op-\ntional, and may be unnecessary if your PKI trust chain originates from root CAs already installed in your operating\nsystem (OS), such as a certificate from a commercial certificate vendor. If your authenticating root CA is not in\nthe OS’s trusted root CAs, it will need to be imported or have its file system path referenced. (Contact your system\nadministrator if unsure.)\n22.2. User Authentication Workflows759\n\nQGIS Desktop 3.22 User Guide\nFig. 22.24: Authorities editor\nBy default, the root CAs from your OS are available; however, their trust settings are not inherited. You should review\nthe certificate trust policy settings, especially if your OS root CAs have had their policies adjusted. Any certificate\nthat is expired will be set to untrusted and will not be used in secure server connections, unless you specifically\noverride its trust policy. To see the QGIS-discoverable trust chain for any certificate, select it and click the\nShow information for certificate\n.\n760Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.25: Certificate info dialog\nYou can edit theTrust policyfor any selected certificate within the chain. Any change in trust policy to a\nselected certificate will not be saved to the database unless the\nSave certificate trust policy change to database\nbutton is clicked\nperselected certification. Closing the dialog willnotapply the policy changes.\nFig. 22.26: Saving the trust policy changes\nYou can review the filtered CAs, both intermediate and root certificates, that will be trusted for secure connections\nor change the default trust policy by clicking theOptionsbutton.\nWarning:Changing the default trust policy may result in problems with secure connections.\n22.2. User Authentication Workflows761\n\nQGIS Desktop 3.22 User Guide\nFig. 22.27: Authorities options menu\nYou can import CAs or save a file system path from a file that contains multiple CAs, or import individual CAs. The\nstandard PEM format for files that contain multiple CA chain certifications has the root cert at the bottom of the file\nand all subsequently signed child certificates above, towards the beginning of the file.\nThe CA certificate import dialog will find all CA certificates within the file, regardless of order, and also offers the\noption to import certificates that are considered invalid (in case you want to override their trust policy). You can\noverride the trust policy upon import, or do so later within theAuthoritieseditor.\nFig. 22.28: Import certificates dialog\nNote:If you are pasting certificate information into thePEM textfield, note that encrypted certificates are not\nsupported.\nIdentities\nYou can manage available client identity bundles from theIdentitiestab in theCertificate managerfrom theAuthen-\nticationtab of the QGISOptionsdialog. An identity is what authenticates you against a PKI-enabled service and\nusually consists of a client certificate and private key, either as separate files or combined into a single “bundled” file.\nThe bundle or private key is often passphrase-protected.\nOnce you have any Certificate Authorities (CAs) imported you can optionally import any identity bundles into the\nauthentication database. If you do not wish to store the identities, you can reference their component file system paths\nwithin an individual authentication configuration.\n762Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.29: Identities editor\nWhen importing an identity bundle, it can be passphrase-protected or unprotected, and can contain CA certificates\nforming a trust chain. Trust chain certifications will not be imported here; they can be added separately under the\nAuthorities\ntab.\nUpon import the bundle’s certificate and private key will be stored in the database, with the key’s storage encrypted\nusing the QGIS master password. Subsequent usage of the stored bundle from the database will only require input\nof the master password.\nPersonal identity bundles consisting of PEM/DER (.pem/.der) and PKCS#12 (.p12/.pfx) components are supported.\nIf a key or bundle is passphrase-protected, the password will be required to validate the component prior to import.\nLikewise, if the client certificate in the bundle is invalid (for example, its effective date has not yet started or has\nelapsed) the bundle can not be imported.\nFig. 22.30: PEM/DER identity import\n22.2. User Authentication Workflows763\n\nQGIS Desktop 3.22 User Guide\nFig. 22.31: PKCS#12 identity import\n22.2.4Handling bad layers\nOccasionally, the authentication configuration ID that is saved with a project file is no longer valid, possibly because\nthe current authentication database is different than when the project was last saved, or due to a credentials mismatch.\nIn such cases theHandle bad layersdialog will be presented upon QGIS launch.\nFig. 22.32: Handle bad layers with authentication\nIf a data source is found to have an authentication configuration ID associated with it, you will be able to edit it. Doing\nso will automatically edit the data source string, much in the same way as opening the project file in a text editor and\nediting the string.\n764Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.33: Edit bad layer’s authentication config ID\n22.2.5Changing authentication config ID\nOccasionally, you will need to change the authentication configuration ID that is associated with accessing a resource.\nThere are instances where this is useful:\n•Resource auth config ID is no longer valid: This can occur when you have switched auth databases add need\ntoaligna new configuration to the ID already associated with a resource.\n•Shared project files: If you intended to share projects between users, e.g. via a shared file server, you can\npredefinea 7-character (containinga-zand/or0-9) that is associated with the resource. Then, individual users\nchange the ID of an authentication configuration that is specific to their credentials of the resource. When the\nproject is opened, the ID is found in the authentication database, but the credentials are different per user.\nFig. 22.34: Changing a layer’s authentication config ID (unlocked yellow text field)\nWarning:Changing the auth config ID is considered an advanced operation and should only be done with full\nknowledge as to why it is necessary. This is why there is a lock button that needs clicked, to unlock the ID’s text\nfield prior to editing the ID.\n22.2. User Authentication Workflows765\n\nQGIS Desktop 3.22 User Guide\n22.2.6QGIS Server support\nWhen using a project file, with layers that have authentication configurations, as a basis for a map in QGIS Server,\nthere are a couple of additional setup steps necessary for QGIS to load the resources:\n•Authentication database needs to be available\n•Authentication database’s master password needs to be available\nWhen instantiating the authentication system, Server will create or useqgis-auth.dbfile in the activeuser profile,\nor the directory defined by theQGIS_AUTH_DB_DIR_PATHenvironment variable. It may be that the Server’s user\nhas no HOME directory, in which case, use the environment variable to define a directory that the Server’s user has\nread/write permissions and is not located within the web-accessible directories.\nTo pass the master password to Server, write it to the first line of file at a path on the file system readable by the Server\nprocesses user and defined using theQGIS_AUTH_PASSWORD_FILEenvironment variable. Ensure to limit the\nfile as only readable by the Server’s process user and to not store the file within web-accessible directories.\nNote:QGIS_AUTH_PASSWORD_FILEvariable will be removed from the Server environment immediately after\naccessing.\n22.2.7SSL server exceptions\nFig. 22.35: SSL server exception\nYou can manage SSL server configurations and exceptions from theServerstab in theAuthenticationsection of the\nQGISOptionsdialog.\nSometimes, when connecting to an SSL server, there are errors with the SSL “handshake” or the server’s certificate.\nYou can ignore those errors or create an SSL server configuration as an exception. This is similar to how web browsers\nallow you to override SSL errors, but with more granular control.\nWarning:You should not create an SSL server configuration unless you have complete knowledge of the entire\nSSL setup between the server and client. Instead, report the issue to the server administrator.\nNote:Some PKI setups use a completely different CA trust chain to validate client identities than the chain used\nto validate the SSL server certificate. In such circumstances, any configuration created for the connecting server will\nnot necessarily fix an issue with the validation of your client identity, and only your client identity’s issuer or server\nadministrator can fix the issue.\nYou can pre-configure an SSL server configuration by clicking thebutton. Alternatively, you can add a config-\nuration when an SSL error occurs during a connection and you are presented with anSSL Errordialog (where the\nerror can be ignored temporarily or saved to the database and ignored):\n766Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.36: Manually adding configuration\n22.2. User Authentication Workflows767\n\nQGIS Desktop 3.22 User Guide\nFig. 22.37: Adding configuration during SSL error\nOnce an SSL configuration is saved to the database, it can be edited or deleted.\nFig. 22.38: Existing SSL configuration\n768Chapter 22. Authentication System\n\nQGIS Desktop 3.22 User Guide\nFig. 22.39: Editing an existing SSL configuration\nIf you want to pre-configure an SSL configuration and the import dialog is not working for your server’s connection,\nyou can manually trigger a connection via thePython Consoleby running the following code (replacehttps://\nbugreports.qt-project.orgwith the URL of your server):\nfromqgis.PyQt.QtNetworkimportQNetworkRequest\nfromqgis.PyQt.QtCoreimportQUrl\nfromqgis.coreimportQgsNetworkAccessManager\nreq\n=QNetworkRequest(QUrl('https://bugreports.qt-project.org'))\nreply=QgsNetworkAccessManager.instance().get(req)\nThis will open an SSL error dialog if any errors occur, where you can choose to save the configuration to the database.\n22.3Security Considerations\nOnce the master password is entered, the API is open to access authentication configs in the authentication database,\nsimilar to how Firefox works. However, in the initial implementation, no wall against PyQGIS access has been\ndefined. This may lead to issues where a user downloads/installs a malicious PyQGIS plugin or standalone app that\ngains access to authentication credentials.\nThe quick solution for initial release of feature is to just not include most PyQGIS bindings for the authentication\nsystem.\nAnother simple, though not robust, fix is to add a combobox inSettings►Options►Authentication(defaults to\n“never”):\n\"Allow Python access to authentication system\"\nChoices: [ confirm once per session|always confirm|always allow|never]\nSuch an option’s setting would need to be saved in a location non-accessible to Python, e.g. the authentication\ndatabase, and encrypted with the master password.\n•Another option may be to track which plugins the user has specifically\n•allowed to access the authentication system, though it may be tricky to deduce which plugin is actually making\nthe call.\n22.3. Security Considerations769\n\nQGIS Desktop 3.22 User Guide\n•Sandboxing plugins, possibly in their own virtual environments, would reduce ‘cross-plugin’ hacking of authen-\ntication configs from another plugin that is authorized. This might mean limiting cross-plugin communication\nas well, but maybe only between third-party plugins.\n•Another good solution is to issue code-signing certificates to vetted plugin authors. Then validate the plugin’s\ncertificate upon loading. If need be the user can also directly set an untrusted policy for the certificate associated\nwith the plugin using existing certificate management dialogs.\n•Alternatively, access to sensitive authentication system data from Python\n•could never be allowed, and only the use of QGIS core widgets, or duplicating authentication system integra-\ntions, would allow the plugin to work with resources that have an authentication configuration, while keeping\nmaster password and authentication config loading in the realm of the main app.\nThe same security concerns apply to C++ plugins, though it will be harder to restrict access, since there is no function\nbinding to simply be removed as with Python.\n22.3.1Restrictions\nThe confusinglicensing and exportingissues associated with OpenSSL apply. In order for Qt to work with SSL certifi-\ncates, it needs access to the OpenSSL libraries. Depending upon how Qt was compiled, the default is to dynamically\nlink to the OpenSSL libs at run-time (to avoid the export limitations).\nQCA follows a similar tactic, whereby linking to QCA incurs no restrictions, because the qca-ossl (OpenSSL) plugin\nis loaded at run-time. The qca-ossl plugin is directly linked to the OpenSSL libs. Packagers would be the ones needing\nto ensure any OpenSSL-linking restrictions are met, if they ship the plugin. Maybe. I don’t really know. I’m not a\nlawyer.\nThe authentication system safely disables itself whenqca-osslis not found at run-time.\n770Chapter 22. Authentication System\n\nCHAPTER\nTWENTYTHREE\nGRASS GIS INTEGRATION\nGRASSintegrationprovidesaccesstoGRASSGISdatabasesandfunctionalities(seeGRASS-PROJECTinLiterature\nand Web References). The integration consists of two parts: provider and plugin. The provider allows to browse,\nmanage and visualize GRASS raster and vector layers. The plugin can be used to create new GRASS locations and\nmapsets, change GRASS region, create and edit vector layers and analyze GRASS 2-D and 3-D data with more than\n400 GRASS modules. In this section, we’ll introduce the provider and plugin functionalities and give some examples\nof managing and working with GRASS data.\nThe provider supports GRASS version 6 and 7, the plugin supports GRASS 6 and 7 (starting from QGIS 2.12).\nQGIS distribution may contain provider/plugin for either GRASS 6 or GRASS 7 or for both versions at the same\ntime (binaries have different file names). Only one version of the provider/plugin may be loaded on runtime however.\n23.1Demo dataset\nAs an example, we will use the QGIS Alaska dataset (see sectionDownloading sample data). It includes a small sam-\nple GRASSLOCATIONwith three vector layers and one raster elevation map. Create a new folder calledgrass-\ndata, download the QGIS ‘Alaska’ datasetqgis_sample_data.zipfromhttps://qgis.org/downloads/data/\nand unzip the file intograssdata.\nMore sample GRASSLOCATIONsare available at the GRASS website athttps://grass.osgeo.org/download/data/.\n23.2Loading GRASS raster and vector layers\nIf the provider is loaded in QGIS, the location item with GRASSicon is added in the browser tree under each\nfolder item which contains GRASS location. Go to the foldergrassdataand expand locationalaskaand mapset\ndemo.\nYou can load GRASS raster and vector layers like any other layer from the browser either by double click on layer\nitem or by dragging and dropping to map canvas or legend.\nTip: GRASS Data Loading\nIf you don’t see GRASS location item, verify inHelp►About►Providersif GRASS vector provider is loaded.\n771\n\nQGIS Desktop 3.22 User Guide\n23.3Importing data into a GRASS LOCATION via drag and drop\nThis section gives an example of how to import raster and vector data into a GRASS mapset.\n1.In QGIS browser navigate to the mapset you want to import data into.\n2.In QGIS browser find a layer you want to import to GRASS, note that you can open another instance of the\nbrowser (Browser Panel (2)) if source data are too far from the mapset in the tree.\n3.Drag a layer and drop it on the target mapset. The import may take some time for larger layers, you will see\nanimated iconin front of new layer item until the import finishes.\nWhen raster data are in different CRS, they can be reprojected using anApproximate(fast) orExact(precise) trans-\nformation. If a link to the source raster is created (usingr.external), the source data are in the same CRS and\nthe format is known to GDAL, the source data CRS will be used. You can set these options in theBrowsertab in\nGRASS Options.\nIf a source raster has more bands, a new GRASS map is created for each layer with.<band number>suffix and\ngroup of all maps withicon is created. External rasters have a different icon.\n23.4Managing GRASS data in QGIS Browser\n•Copying maps: GRASS maps may be copied between mapsets within the same location using drag and drop.\n•Deleting maps: Right click on a GRASS map and selectDeletefrom context menu.\n•Renaming maps: Right click on a GRASS map and selectRenamefrom context menu.\n23.5GRASS Options\nGRASS options may be set inGRASS Optionsdialog, which can be opened by right clicking on the location or mapset\nitem in the browser and then choosingGRASS Options.\n23.6Starting the GRASS plugin\nTo use GRASS functionalities in QGIS, you must select and load the GRASS plugin using the Plugin Manager. To\ndo this, go to the menuPlugins►Manage and Install Plugins..., selectGRASSand clickOK.\nThe following main features are provided with the GRASS menu (Plugins►GRASS) when you start the GRASS\nplugin:\n•\nOpen Mapset\n•\nNew Mapset\n•\nClose Mapset\n•\nOpen GRASS Tools\n•\nDisplay Current GRASS Region\n•\nGRASS Options\n772Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\n23.7Opening GRASS mapset\nA GRASS mapset must be opened to get access to GRASS Tools in the plugin (the tools are disabled if no mapset\nis open). You can open a mapset from the browser: right click on mapset item and then chooseOpen mapsetfrom\ncontext menu.\n23.8GRASS LOCATION and MAPSET\nGRASS data are stored in a directory referred to as GISDBASE. This directory, often calledgrassdata, must be\ncreated before you start working with the GRASS plugin in QGIS. Within this directory, the GRASS GIS data are\norganized by projects stored in subdirectories calledLOCATIONs. EachLOCATIONis defined by its coordinate\nsystem, map projection and geographical boundaries. EachLOCATIONcan have severalMAPSETs(subdirectories\nof theLOCATION) that are used to subdivide the project into different topics or subregions, or as workspaces for\nindividual team members (see Neteler & Mitasova 2008 in\nLiterature and Web References). In order to analyse vector\nand raster layers with GRASS modules, you generally have to import them into a GRASSLOCATION. (This is\nnot strictly true – with the GRASS modulesr.externalandv.externalyou can create read-only links to\nexternal GDAL/OGR-supported datasets without importing them. This is not the usual way for beginners to work\nwith GRASS, therefore this functionality will not be described here.)\nFig. 23.1: GRASS data in the alaska LOCATION\n23.9Importing data into a GRASS LOCATION\nSee sectionImporting data into a GRASS LOCATION via drag and dropto find how data can be easily imported by\ndragging and dropping in the browser.\nThissectiongivesanexampleofhowtoimportrasterandvectordataintothe‘alaska’GRASSLOCATIONprovidedby\nthe QGIS ‘Alaska’ dataset in traditional way, using standard GRASS modules. Therefore, we use the landcover raster\nmaplandcover.imgand the vector GML filelakes.gmlfrom the QGIS ‘Alaska’ dataset (see\nDownloading\nsample data).\n1.Start QGIS and make sure the GRASS plugin is loaded.\n2.In the GRASS toolbar, click the\nOpen MAPSET\nicon to bring up theMAPSETwizard.\n3.Select as GRASS database the foldergrassdatain the QGIS Alaska dataset, asLOCATION‘alaska’, as\nMAPSET‘demo’ and clickOK.\n4.Now click the\nOpen GRASS tools\nicon. The GRASS Toolbox (see sectionThe GRASS Toolbox) dialog appears.\n23.7. Opening GRASS mapset773\n\nQGIS Desktop 3.22 User Guide\n5.To import the raster maplandcover.img, click the moduler.in.gdalin theModules Treetab. This\nGRASS module allows you to import GDAL-supported raster files into a GRASSLOCATION. The module\ndialog forr.in.gdalappears.\n6.Browse to the folderrasterin the QGIS ‘Alaska’ dataset and select the filelandcover.img.\n7.As raster output name, definelandcover_grassand clickRun. In theOutputtab, you see the cur-\nrently running GRASS commandr.in.gdal  -o  input=/path/to/landcover.img  out-\nput=landcover_grass.\n8.When it saysSuccessfully finished, clickView Output. Thelandcover_grassraster layer is now im-\nported into GRASS and will be visualized in the QGIS canvas.\n9.To import the vector GML filelakes.gml, click the modulev.in.ogrin theModules Treetab. This\nGRASS module allows you to import OGR-supported vector files into a GRASSLOCATION. The module\ndialog forv.in.ograppears.\n10.Browse to the foldergmlin the QGIS ‘Alaska’ dataset and select the filelakes.gmlas OGR file.\n11.As vector output name, definelakes_grassand clickRun. You don’t have to care about the other options\nin this example. In the\nOutput\ntab you see the currently running GRASS command\nv.in.ogr -o dsn=/\npath/to/lakes.gml output=lakes\\_grass.\n12.When it saysSuccesfully finished, clickView Output. Thelakes_grassvector layer is now imported into\nGRASS and will be visualized in the QGIS canvas.\n23.9.1Creating a new GRASS LOCATION\nAs an example, here is the sample GRASSLOCATION alaska, which is projected in the Albers Equal Area\nprojection using feet as units. This sample GRASSLOCATION alaskawill be used for all examples and exercises\nin the following GRASS-related sections. It is useful to download and install the dataset on your computer (see\nDownloading sample data).\n1.Start QGIS and make sure the GRASS plugin is loaded.\n2.Visualize thealaska.shpshapefile (see sectionLoading a layer from a file) from the QGIS Alaska dataset\n(seeDownloading sample data).\n3.In the GRASS toolbar, click on the\nNew mapset\nicon to bring up theMAPSETwizard.\n4.Select an existing GRASS database (GISDBASE) foldergrassdata, or create one for the newLOCATION\nusing a file manager on your computer. Then clickNext.\n5.We can use this wizard to create a newMAPSETwithin an existingLOCATION(see sectionAdding a new\nMAPSET) or to create a newLOCATIONaltogether. SelectCreate new location(seeFig. 23.2).\n6.Enter a name for theLOCATION– we used ‘alaska’ – and clickNext.\n7.Define the projection by clicking on the radio buttonProjectionto enable the projection list.\n8.We are using Albers Equal Area Alaska (feet) projection. Since we happen to know that it is represented by the\nEPSG ID 2964, we enter it in the search box. (Note: If you want to repeat this process for anotherLOCATION\nand projection and haven’t memorized the EPSG ID, click on the\nCRS Status\nicon in the lower right-hand\ncorner of the status bar (see sectionWorking with Projections)).\n9.InFilter, insert 2964 to select the projection.\n10.ClickNext.\n11.To define the default region, we have to enter theLOCATIONbounds in the north, south, east, and west\ndirections. Here, we simply click on the buttonSet Current QGIS Extent, to apply the extent of the loaded layer\nalaska.shpas the GRASS default region extent.\n12.ClickNext.\n774Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\n13.We also need to define aMAPSETwithin our newLOCATION(this is necessary when creating a newLOCA-\nTION). You can name it whatever you like - we used ‘demo’. GRASS automatically creates a specialMAPSET\ncalledPERMANENT, designed to store the core data for the project, its default spatial extent and coordinate\nsystem definitions (see Neteler & Mitasova 2008 inLiterature and Web References).\n14.Check out the summary to make sure it’s correct and clickFinish.\n15.The newLOCATION, ‘alaska’, and twoMAPSETs, ‘demo’ and ‘PERMANENT’, are created. The currently\nopened working set is ‘demo’, as you defined.\n16.Notice that some of the tools in the GRASS toolbar that were disabled are now enabled.\nFig. 23.2: Creating a new GRASS LOCATION or a new MAPSET in QGIS\nIf that seemed like a lot of steps, it’s really not all that bad and a very quick way to create aLOCATION. The\nLOCATION‘alaska’ is now ready for data import (see sectionImporting data into a GRASS LOCATION). You can\nalso use the already-existing vector and raster data in the sample GRASSLOCATION‘alaska’, included in the QGIS\n‘Alaska’ datasetDownloading sample data, and move on to sectionThe GRASS vector data model.\n23.9.2Adding a new MAPSET\nA user has write access only to a GRASSMAPSETwhich he or she created. This means that besides access to your\nownMAPSET, you can read maps in other users’MAPSETs(and they can read yours), but you can modify or remove\nonly the maps in your ownMAPSET.\nAllMAPSETsinclude aWINDfile that stores the current boundary coordinate values and the currently selected raster\nresolution (see Neteler & Mitasova 2008 in\nLiterature and Web References, and sectionThe GRASS region tool).\n1.Start QGIS and make sure the GRASS plugin is loaded.\n2.In the GRASS toolbar, click on the\nNew mapset\nicon to bring up theMAPSETwizard.\n3.Select the GRASS database (GISDBASE) foldergrassdatawith theLOCATION‘alaska’, where we want\nto add a furtherMAPSETcalled ‘test’.\n4.ClickNext.\n5.We can use this wizard to create a newMAPSETwithin an existingLOCATIONor to create a newLOCATION\naltogether. Click on the radio buttonSelect location(seeFig. 23.2) and clickNext.\n6.Enter the nametestfor the newMAPSET. Below in the wizard, you see a list of existingMAPSETsand\ncorresponding owners.\n7.ClickNext, check out the summary to make sure it’s all correct and clickFinish.\n23.9. Importing data into a GRASS LOCATION775\n\nQGIS Desktop 3.22 User Guide\n23.10The GRASS vector data model\nIt is important to understand the GRASS vector data model prior to digitizing. In general, GRASS uses a topological\nvector model. This means that areas are not represented as closed polygons, but by one or more boundaries. A\nboundary between two adjacent areas is digitized only once, and it is shared by both areas. Boundaries must be\nconnected and closed without gaps. An area is identified (and labelled) by thecentroidof the area.\nBesides boundaries and centroids, a vector map can also contain points and lines. All these geometry elements can\nbe mixed in one vector and will be represented in different so-called ‘layers’ inside one GRASS vector map. So in\nGRASS, a layer is not a vector or raster map but a level inside a vector layer. This is important to distinguish carefully.\n(Although it is possible to mix geometry elements, it is unusual and, even in GRASS, only used in special cases such\nas vector network analysis. Normally, you should prefer to store different geometry elements in different layers.)\nIt is possible to store several ‘layers’ in one vector dataset. For example, fields, forests and lakes can be stored in one\nvector. An adjacent forest and lake can share the same boundary, but they have separate attribute tables. It is also\npossible to attach attributes to boundaries. An example might be the case where the boundary between a lake and a\nforest is a road, so it can have a different attribute table.\nThe ‘layer’ of the feature is defined by the ‘layer’ inside GRASS. ‘Layer’ is the number which defines if there is more\nthan one layer inside the dataset (e.g., if the geometry is forest or lake). For now, it can be only a number. In the\nfuture, GRASS will also support names as fields in the user interface.\nAttributes can be stored inside the GRASSLOCATIONas dBase, SQLite3 or in external database tables, for example,\nPostgreSQL, MySQL, Oracle, etc.\nAttributes in database tables are linked to geometry elements using a ‘category’ value.\n‘Category’ (key, ID) is an integer attached to geometry primitives, and it is used as the link to one key column in the\ndatabase table.\nTip: Learning the GRASS Vector Model\nThe best way to learn the GRASS vector model and its capabilities is to download one of the many GRASS tutorials\nwhere the vector model is described more deeply. Seehttps://grass.osgeo.org/learn/manuals/for more information,\nbooks and tutorials in several languages.\n23.11Creating a new GRASS vector layer\nTo create a new GRASS vector layer, select one of following items from mapset context menu in the browser:\n•New Point Layer\n•New Line Layer\n•New Polygon Layer\nand enter a name in the dialog. A new vector map will be created and layer will be added to canvas and editing started.\nSelecting type of the layer does not restrict geometry types which can be digitized in the vector map. In GRASS, it\nis possible to organize all sorts of geometry types (point, line and polygon) in one vector map. The type is only used\nto add the layer to the canvas, because QGIS requires a layer to have a specific type.\nIt is also possible to add layers to existing vector maps selecting one of the items described above from context menu\nof existing vector map.\nIn GRASS, it is possible to organize all sorts of geometry types (point, line and area) in one layer, because GRASS\nuses a topological vector model, so you don’t need to select the geometry type when creating a new GRASS vector.\nThis is different from shapefile creation with QGIS, because shapefiles use the Simple Feature vector model (see\nsection\nCreating new vector layers).\n776Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\n23.12Digitizing and editing a GRASS vector layer\nGRASS vector layers can be digitized using the standard QGIS digitizing tools. There are however some particular-\nities, which you should know about, due to\n•GRASS topological model versus QGIS simple feature\n•complexity of GRASS model\n–multiple layers in single maps\n–multiple geometry types in single map\n–geometry sharing by multiple features from multiple layers\nThe particularities are discussed in the following sections.\nSave, discard changes, undo, redo\nWarning:All the changes done during editing are immediately written to vector map and related attribute tables.\nChanges are written after each operation, it is however, possible to do undo/redo or discard all changes when closing\nediting. If undo or discard changes is used, original state is rewritten in vector map and attribute tables.\nThere are two main reasons for this behaviour:\n•It is the nature of GRASS vectors coming from conviction that user wants to do what he is doing and it is better\nto have data saved when the work is suddenly interrupted (for example, blackout)\n•Necessity for effective editing of topological data is visualized information about topological correctness, such\ninformation can only be acquired from GRASS vector map if changes are written to the map.\nToolbar\nThe ‘Digitizing Toolbar’ has some specific tools when a GRASS layer is edited:\nIconToolPurpose\nNew PointDigitize new point\nNew LineDigitize new line\nNew BoundaryDigitize new boundary\nNew CentroidDigitize new centroid (label existing area)\nNew Closed BoundaryDigitize new closed boundary\nTable GRASS Digitizing: GRASS Digitizing Tools\nTip: Digitizing polygons in GRASS\nIf you want to create a polygon in GRASS, you first digitize the boundary of the polygon. Then you add a centroid\n(label point) into the closed boundary. The reason for this is that a topological vector model links the attribute\ninformation of a polygon always to the centroid and not to the boundary.\nCategory\nCategory, often called cat, is sort of ID. The name comes from times when GRASS vectors had only singly attribute\n“category”. Category is used as a link between geometry and attributes. A single geometry may have multiple\ncategories and thus represent multiple features in different layers. Currently it is possible to assign only one category\nper layer using QGIS editing tools. New features have automatically assigned new unique category, except boundaries.\nBoundaries usually only form areas and do not represent linear features, it is however possible to define attributes for\na boundary later, for example in different layer.\n23.12. Digitizing and editing a GRASS vector layer777\n\nQGIS Desktop 3.22 User Guide\nNew categories are always created only in currently being edited layer.\nIt is not possible to assign more categories to geometry using QGIS editing, such data are properly represented as\nmultiple features, and individual features, even from different layers, may be deleted.\nAttributes\nAttributes of currently edited layer can only be modified. If the vector map contains more layers, features of other\nlayers will have all attributes set to ‘<not editable (layer #)>’ to warn you that such attribute is not editable. The reason\nis, that other layers may have and usually have different set of fields while QGIS only supports one fixed set of fields\nper layer.\nIf a geometry primitive does not have a category assigned, a new unique category is automatically assigned and new\nrecord in attribute table is created when an attribute of that geometry is changed.\nTip:If you want to do bulk update of attributes in table, for example using ‘Field Calculator’ (Using the Field\nCalculator), and there are features without category which you don’t want to update (typically boundaries), you can\nfilter them out by setting ‘Advanced Filter’ tocat is not null.\nEditing style\nThe topological symbology is essential for effective editing of topological data. When editing starts, a specialized\n‘GRASS Edit’ renderer is set on the layer automatically and original renderer is restored when editing is closed. The\nstyle may be customized in layer properties ‘Style’ tab. The style can also be stored in project file or in separate file as\nany other style. If you customize the style, do not change its name, because it is used to reset the style when editing\nis started again.\nTip:Do not save project file when the layer is edited, the layer would be stored with ‘Edit Style’ which has no\nmeaning if layer is not edited.\nThe style is based on topological information which is temporarily added to attribute table as field ‘topo_symbol’. The\nfield is automatically removed when editing is closed.\nTip:Do not remove ‘topo_symbol’ field from attribute table, that would make features invisible because the renderer\nis based on that column.\nSnapping\nTo form an area, vertices of connected boundaries must haveexactlythe same coordinates. This can be achieved using\nsnapping tool only if canvas and vector map have the same CRS. Otherwise, due conversion from map coordinates to\ncanvas and back, the coordinate may become slightly different due to representation error and CRS transformations.\nTip:Use layer’s CRS also for canvas when editing.\nLimitations\nSimultaneous editing of multiple layers within the same vector at the same time is not supported. This is mainly due\nto the impossibility of handling multiple undo stacks for a single data source.\nOn Linux and macOS only one GRASS layer can be edited at time. This is due to a bug in GRASS which does\nnot allow to close database drivers in random order. This is being solved with GRASS developers.\nTip: GRASS Edit Permissions\nYou must be the owner of the GRASSMAPSETyou want to edit. It is impossible to edit data layers in aMAPSET\nthat is not yours, even if you have write permission.\n778Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\n23.13The GRASS region tool\nThe region definition (setting a spatial working window) in GRASS is important for working with raster layers. Vector\nanalysis is by default not limited to any defined region definitions. But all newly created rasters will have the spatial\nextension and resolution of the currently defined GRASS region, regardless of their original extension and resolution.\nThe current GRASS region is stored in the$LOCATION/$MAPSET/WINDfile, and it defines north, south, east and\nwest bounds, number of columns and rows, horizontal and vertical spatial resolution.\nIt is possible to switch on and off the visualization of the GRASS region in the QGIS canvas using the\nDisplay current GRASS region\nbutton.\nThe region can be modified in ‘Region’ tab in ‘GRASS Tolls’ dock widget. Type in the new region bounds and\nresolution, and clickApply. If you click onSelect the extent by dragging on canvasyou can select a new region\ninteractively with your mouse on the QGIS canvas dragging a rectangle.\nThe GRASS moduleg.regionprovides a lot more parameters to define an appropriate region extent and resolution\nfor your raster analysis. You can use these parameters with the GRASS Toolbox, described in sectionThe GRASS\nToolbox.\n23.14The GRASS Toolbox\nThe\nOpen GRASS Tools\nbox provides GRASS module functionalities to work with data inside a selected GRASS\nLOCATIONandMAPSET. To use the GRASS Toolbox you need to open aLOCATIONandMAPSETthat you have\nwrite permission for (usually granted, if you created theMAPSET). This is necessary, because new raster or vector\nlayers created during analysis need to be written to the currently selectedLOCATIONandMAPSET.\nFig. 23.3: GRASS Toolbox and Module Tree\n23.13. The GRASS region tool779\n\nQGIS Desktop 3.22 User Guide\n23.14.1Working with GRASS modules\nThe GRASS shell inside the GRASS Toolbox provides access to almost all (more than 300) GRASS modules in a\ncommand line interface. To offer a more user-friendly working environment, about 200 of the available GRASS\nmodules and functionalities are also provided by graphical dialogs within the GRASS plugin Toolbox.\nA complete list of GRASS modules available in the graphical Toolbox in QGIS version 3.22 is available in the GRASS\nwiki athttps://grasswiki.osgeo.org/wiki/GRASS-QGIS_relevant_module_list.\nIt is also possible to customize the GRASS Toolbox content. This procedure is described in sectionCustomizing the\nGRASS Toolbox.\nAs shown inFig. 23.3, you can look for the appropriate GRASS module using the thematically groupedModules Tree\nor the searchableModules Listtab.\nBy clicking on a graphical module icon, a new tab will be added to the Toolbox dialog, providing three new sub-tabs:\nOptions,OutputandManual.\nOptions\nTheOptionstab provides a simplified module dialog where you can usually select a raster or vector layer visualized\nin the QGIS canvas and enter further module-specific parameters to run the module.\nFig. 23.4: GRASS Toolbox Module Options\nThe provided module parameters are often not complete to keep the dialog simple. If you want to use further module\nparameters and flags, you need to start the GRASS shell and run the module in the command line.\nA new feature since QGIS 1.8 is the support for aShow Advanced Optionsbutton below the simplified module dialog\nin theOptionstab. At the moment, it is only added to the modulev.in.asciias an example of use, but it will\nprobably be part of more or all modules in the GRASS Toolbox in future versions of QGIS. This allows you to use\nthe complete GRASS module options without the need to switch to the GRASS shell.\nOutput\n780Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\nFig. 23.5: GRASS Toolbox Module Output\nTheOutputtab provides information about the output status of the module. When you click theRunbutton, the\nmodule switches to theOutputtab and you see information about the analysis process. If all works well, you will\nfinally see aSuccessfully finishedmessage.\nManual\n23.14. The GRASS Toolbox781\n\nQGIS Desktop 3.22 User Guide\nFig. 23.6: GRASS Toolbox Module Manual\nTheManualtab shows the HTML help page of the GRASS module. You can use it to check further module param-\neters and flags or to get a deeper knowledge about the purpose of the module. At the end of each module manual\npage, you see further links to theMain Help index, theThematic indexand theFull index. These\nlinks provide the same information as the moduleg.manual.\nTip: Display results immediately\nIf you want to display your calculation results immediately in your map canvas, you can use the ‘View Output’ button\nat the bottom of the module tab.\n782Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\n23.14.2GRASS module examples\nThe following examples will demonstrate the power of some of the GRASS modules.\nCreating contour lines\nThe first example creates a vector contour map from an elevation raster (DEM). Here, it is assumed that you have the\nAlaskaLOCATIONset up as explained in sectionImporting data into a GRASS LOCATION.\n•First, open the location by clicking the\nOpen mapset\nbutton and choosing the Alaska location.\n•Now open the Toolbox with the\nOpen GRASS tools\nbutton.\n•In the list of tool categories, double-clickRaster►Surface Management►Generate vector contour lines.\n•Now a single click on the toolr.contourwill open the tool dialog as explained above (seeWorking with GRASS\nmodules).\n•In theName of input raster mapentergtopo30.\n•Type into theIncrement between Contour levelsthe value 100. (This will create contour lines at intervals\nof 100 meters.)\n•Type into theName for output vector mapthe namectour_100.\n•ClickRunto start the process. Wait for several moments until the messageSuccessfully finished\nappears in the output window. Then clickView OutputandClose.\nSince this is a large region, it will take a while to display. After it finishes rendering, you can open the layer properties\nwindow to change the line color so that the contours appear clearly over the elevation raster, as in\nThe Vector Properties\nDialog.\nNext, zoom in to a small, mountainous area in the center of Alaska. Zooming in close, you will notice that the contours\nhave sharp corners. GRASS offers thev.generalizetool to slightly alter vector maps while keeping their overall shape.\nThe tool uses several different algorithms with different purposes. Some of the algorithms (i.e., Douglas Peuker and\nVertex Reduction) simplify the line by removing some of the vertices. The resulting vector will load faster. This\nprocess is useful when you have a highly detailed vector, but you are creating a very small-scale map, so the detail is\nunnecessary.\nTip: The simplify tool\nNote that QGIS has aVector►Geometry Tools►Simplify geometriestool that works just like the GRASS\nv.generalizeDouglas-Peuker algorithm.\nHowever, the purpose of this example is different. The contour lines created byr.contourhave sharp angles\nthat should be smoothed. Among thev.generalizealgorithms, there is Chaiken’s, which does just that (also Hermite\nsplines). Be aware that these algorithms canaddadditional vertices to the vector, causing it to load even more slowly.\n•Open the GRASS Toolbox and double-click the categoriesVector►Develop map►Generalization, then click\non thev.generalizemodule to open its options window.\n•Check that the ‘ctour_100’ vector appears as theName of input vector.\n•From the list of algorithms, choose Chaiken’s. Leave all other options at their default, and scroll down to the\nlast row to enter in the fieldName for output vector map‘ctour_100_smooth’, and clickRun.\n•The process takes several moments. OnceSuccessfully finishedappears in the output windows,\nclickView Outputand thenClose.\n•You may change the color of the vector to display it clearly on the raster background and to contrast with the\noriginal contour lines. You will notice that the new contour lines have smoother corners than the original while\nstaying faithful to the original overall shape.\n23.14. The GRASS Toolbox783\n\nQGIS Desktop 3.22 User Guide\nFig. 23.7: GRASS module v.generalize to smooth a vector map\nTip: Other uses for r.contour\nThe procedure described above can be used in other equivalent situations. If you have a raster map of precipitation\ndata, for example, then the same method will be used to create a vector map of isohyetal (constant rainfall) lines.\nCreating a Hillshade 3-D effect\nSeveral methods are used to display elevation layers and give a 3-D effect to maps. The use of contour lines, as shown\nabove, is one popular method often chosen to produce topographic maps. Another way to display a 3-D effect is by\nhillshading. The hillshade effect is created from a DEM (elevation) raster by first calculating the slope and aspect\nof each cell, then simulating the sun’s position in the sky and giving a reflectance value to each cell. Thus, you get\nsun-facing slopes lighted; the slopes facing away from the sun (in shadow) are darkened.\n•Begin this example by loading thegtopo30elevation raster. Start the GRASS Toolbox, and under the Raster\ncategory, double-click to openSpatial analysis►Terrain analysis.\n•Then clickr.shaded.reliefto open the module.\n•Change theazimuth angle270 to 315.\n•Entergtopo30_shadefor the new hillshade raster, and clickRun.\n•When the process completes, add the hillshade raster to the map. You should see it displayed in grayscale.\n•To view both the hillshading and the colors of thegtopo30together, move the hillshade map below the\ngtopo30map in the table of contents, then open thePropertieswindow ofgtopo30, switch to theTrans-\nparencytab and set its transparency level to about 25%.\nYou should now have thegtopo30elevation with its colormap and transparency setting displayedabovethe\ngrayscale hillshade map. In order to see the visual effects of the hillshading, turn off thegtopo30_shademap,\nthen turn it back on.\nUsing the GRASS shell\nThe GRASS plugin in QGIS is designed for users who are new to GRASS and not familiar with all the modules and\noptions. As such, some modules in the Toolbox do not show all the options available, and some modules do not appear\nat all. The GRASS shell (or console) gives the user access to those additional GRASS modules that do not appear in\nthe Toolbox tree, and also to some additional options to the modules that are in the Toolbox with the simplest default\nparameters. This example demonstrates the use of an additional option in ther.shaded.reliefmodule that was shown\nabove.\n784Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\nFig. 23.8: The GRASS shell, r.shaded.relief module\nThe moduler.shaded.reliefcan take a parameterzmult, which multiplies the elevation values relative to the X-Y\ncoordinate units so that the hillshade effect is even more pronounced.\n•Load thegtopo30elevation raster as above, then start the GRASS Toolbox and click on the GRASS shell. In\nthe shell window, type the commandr.shaded.relief map=gtopo30 shade=gtopo30_shade2\nazimuth=315 zmult=3and pressEnter.\n•After the process finishes, shift to theBrowsetab and double-click on the newgtopo30_shade2raster to\ndisplay it in QGIS.\n•As explained above, move the shaded relief raster below thegtopo30raster in the table of contents, then\ncheck the transparency of the coloredgtopo30layer. You should see that the 3-D effect stands out more\nstrongly compared with the first shaded relief map.\n23.14. The GRASS Toolbox785\n\nQGIS Desktop 3.22 User Guide\nFig. 23.9: Displaying shaded relief created with the GRASS module r.shaded.relief\nRaster statistics in a vector map\nThe next example shows how a GRASS module can aggregate raster data and add columns of statistics for each\npolygon in a vector map.\n•Again using the Alaska data, refer toImporting data into a GRASS LOCATIONto import theshapefiles/\ntrees.shpfile into GRASS.\n•Now an intermediate step is required: centroids must be added to the imported trees map to make it a complete\nGRASS area vector (including both boundaries and centroids).\n•From the Toolbox, chooseVector►Manage features, and open the modulev.centroids.\n•Enter as theoutput vector map‘forest_areas’ and run the module.\n•Now load theforest_areasvector and display the types of forests - deciduous, evergreen, mixed - in\ndifferent colors: In the layerPropertieswindow,Symbologytab, choose fromLegend type‘Unique value’\nand set theClassification fieldto ‘VEGDESC’. (Refer to the explanation of the symbology tab inSymbology\nProperties\nof the vector section.)\n•Next, reopen the GRASS Toolbox and openVector►Vector updateby other maps.\n•Click on thev.rast.statsmodule. Entergtopo30andforest_areas.\n•Only one additional parameter is needed: Entercolumn prefixelev, and clickRun. This is a computationally\nheavy operation, which will run for a long time (probably up to two hours).\n•Finally, open theforest_areasattribute table, and verify that several new columns have been added,\nincludingelev_min,elev_max,elev_mean, etc., for each forest polygon.\n23.14.3Customizing the GRASS Toolbox\nNearly all GRASS modules can be added to the GRASS Toolbox. An XML interface is provided to parse the pretty\nsimple XML files that configure the modules’ appearance and parameters inside the Toolbox.\nA sample XML file for generating the modulev.buffer(v.buffer.qgm) looks like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE qgisgrassmodule SYSTEM \"http://mrcc.com/qgisgrassmodule.dtd\">\n<qgisgrassmodulelabel=\"Vector buffer\"module=\"v.buffer\">\n<optionkey=\"input\"typeoption=\"type\"layeroption=\"layer\"/>\n(continues on next page)\n786Chapter 23. GRASS GIS Integration\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n<optionkey=\"buffer\"/>\n<optionkey=\"output\"/>\n</qgisgrassmodule>\nThe parser reads this definition and creates a new tab inside the Toolbox when you select the module. A more\ndetailed description for adding new modules, changing a module’s group, etc., can be found athttps://qgis.org/en/\nsite/getinvolved/development/addinggrasstools.html.\n23.14. The GRASS Toolbox787\n\nQGIS Desktop 3.22 User Guide\n788Chapter 23. GRASS GIS Integration\n\nCHAPTER\nTWENTYFOUR\nQGIS PROCESSING FRAMEWORK\n24.1Introduction\nThis chapter introduces the QGIS processing framework, a geoprocessing environment that can be used to call native\nand third-party algorithms from QGIS, making your spatial analysis tasks more productive and easy to accomplish.\nAs aCore plugin, Processing is installed by default but you need to activate it:\n1.Go toPlugins►Manage and install plugins...\n2.Click on theInstalledtab at the left\n3.Check the box next to theProcessingentry\n4.Close the dialog.\nAProcessingmenu is now available in the top menu bar. From there you can reach the main components of\nthis framework.\nIn the following sections, we will review how to use the graphical elements of this framework and make the most out\nof each one of them.\nThere are four basic elements in the framework GUI, which are used to run algorithms for different purposes. Choos-\ning one tool or another will depend on the kind of analysis that is to be performed and the particular characteristics\nof each user and project. All of them (except for the batch processing interface, which is called from the toolbox or\nthe algorithm execution dialog, as we will see) can be accessed from theProcessingmenu item (you will see more\nentries; the remaining ones are not used to execute algorithms and will be explained later in this chapter).\n•TheToolbox: The main element of the GUI, it is used to execute a single algorithm or run a batch process\nbased on that algorithm.\n789\n\nQGIS Desktop 3.22 User Guide\nFig. 24.1: Processing Toolbox\n•TheGraphical Modeler: Several algorithms can be combined graphically using the modeler to define a work-\nflow, creating a single process that involves several subprocesses.\nFig. 24.2: Processing Modeler\n790Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n•TheHistorymanager: All actions performed using any of the aforementioned elements are stored in a history\nfile and can be later easily reproduced using the history manager.\nFig. 24.3: Processing History\n•TheBatch Processinginterface: This interface allows you to execute batch processes and automate the execution\nof a single algorithm on multiple datasets.\nFig. 24.4: Batch Processing interface\nIn the following sections, we will review each one of these elements in detail.\n24.2Configuring the Processing Framework\nThe Processing Options menu (Settings►Options►Processingtab) allows you to configure how algorithms work.\nConfiguration parameters are structured in separate blocks that you can select on the left-hand side of the dialog.\nTheGeneralblock contains a number of interesting parameters.\n•Default output raster layer extensionis by defaulttif\n•Default output vector layer extensionis by defaultgpkg\n•Invalid features filteringwhen executing algorithm:\n–Do not filter (better performance): all the features (with valid and invalid geometries) are processed, but\nthe result may be erroneous depending on how the geometry invalidity affects the operations\n24.2. Configuring the Processing Framework791\n\nQGIS Desktop 3.22 User Guide\n–Skip (ignore) features with invalid geometries, meaning that only a subset of your dataset (the valid geom-\netry features) will be processed\n–Stop algorithm execution when a geometry is invalid: you’ll need to track and fix the invalid geometries if\nyou want the algorithm to process the whole layer. Algorithms likeCheck validityorFix geometriescan\nhelp you achieve this.\nTheInvalid features filteringsetting can be overridden on a per-input basis, at algorithm runtime.\n•Keep dialog open after running algorithm. Once an algorithm has finished execution and its output layers are\nloaded into the QGIS project, the algorithm dialog is closed. If you want to keep it open (to run the algorithm\nagain with different parameters, or to better check the output that is written to the log tab), check this option.\n•Max Threads\n•Output folderfor non temporary outputs: If no folder path is provided for the Processing execution outputs,\nthis is the folder in which they will be saved. Default isprocessing/outputsunder the activeuser profile\ndirectory.\n•Override temporary output folder path: Temporary outputs are saved by default in thetmpfolder on the ma-\nchine. This option helps you set a different place for storage.\n•Pre-execution scriptandPost-execution script. These parameters point to files that contain scripts written using\nthe processing scripting functionality, explained in the section covering scripting and the console.\n•Prefer output filename for layer names. The name of each resulting layer created by an algorithm is defined\nby the algorithm itself. In some cases, a fixed name might be used, meaning that the same output name will\nbe used, no matter which input layer is used. In other cases, the name might depend on the name of the input\nlayer or some of the parameters used to run the algorithm. If this checkbox is checked, the name will be taken\nfrom the output filename instead. Notice that, if the output is saved to a temporary file, the filename of this\ntemporary file is usually a long and meaningless one intended to avoid collision with other already existing\nfilenames.\n•Results group name. If you want to obtain all processing result layers in a group in theLayerspanel, set a\ngroup name for this parameter. The group may exist already or not. QGIS will add all output layers to such\na group. By default, this parameter is empty, so all output layers are added to different places in theLayers\npanel, depending on the item that is active when running an algorithm. Note that output layers will be loaded\nto theLayerspanel only ifOpen output file after running algorithmis checked in the algorithm dialog.\n•Show algorithms with known issues: By default, QGIS avoids display of broken algorithms (generally from\nthird-party providers). If checked, they will be available in the Processing toolbox, with a warning icon and a\ntooltip explaining they have issues. Use at your own risks.\n•Show layer CRS definition in selection boxes\n•Show tooltip when there are disabled providers\n•Style for line layers,Style for point layers,Style for polygons layersandStyle for raster layersare used for setting\nthe default rendering style for output layers (that is, layers generated by processing algorithms). Just create the\nstyle you want using QGIS, save it to a file, and then enter the path to that file in the settings so the algorithms\ncan use it. Whenever a layer is loaded by Processing and added to the QGIS canvas, it will be rendered with\nthat style.\nRendering styles can be configured individually for each algorithm and each one of its outputs. Just right-click\non the name of the algorithm in the toolbox and selectEdit rendering styles for outputs. You will see a dialog\nlike the one shown next.\n792Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nFig. 24.5: Rendering Styles\nSelect the style file (.qml) that you want for each output and pressOK.\n•Warn before executing if parameter CRS’s do not match\nTheMenusblock controls whether an algorithm, script or model (built-in or provided by plugins) should be made\navailable through a dedicated menu or toolbar (along with the Processing Toolbox). For each item of each provider,\nyou can:\n•Add button in toolbar, making it available in theProcessing Algorithmstoolbar\n•assign anIconto the algorithm\n•set aMenu path: the algorithm will then be available through an existing or a custom menu, e.g.Vect&or/\nMyTopAlgorithms\nRestart QGIS to apply the settings. At any time, your changes can beReset to defaults.\nIn theModelsandScriptsblocks, you can set a default folder to store, and look for models and scripts respectively.\nYou will also find a block for algorithmProviders. This is the place installed providers expose their settings. For\nexample, built-in providers contain anActivateitem that you can use to make their algorithms appear or not in\nthe toolbox. Some algorithm providers have their own configuration items, which will be explained when covering\nparticular algorithm providers.\n24.3The Toolbox\nThe\nProcessing Toolbox\nis the main element of the processing GUI, and the one that you are more likely to use in\nyour daily work. It shows the list of all availablealgorithmsgrouped in different blocks calledProviders, and custom\nmodelsandscriptsyou can add to extend the set of tools. Hence the toolbox is the access point to run them, whether\nas a single process or as a batch process involving several executions of the same algorithm on different sets of inputs.\n24.3. The Toolbox793\n\nQGIS Desktop 3.22 User Guide\nFig. 24.6: Processing Toolbox\nProviders can be (de)activated in theProcessing settings dialog. By default, only providers that do not rely on third-\nparty applications (that is, those that only require QGIS elements to be run) are active. Algorithms requiring external\napplications might need additional configuration. Configuring providers is explained in a\nlater chapterin this manual.\nIn the upper part of the toolbox dialog, you will find a set of tools to:\n•work with\nModels\n:Create New Model...,Open Existing Model...andAdd Model to Toolbox...;\n•work with\nScripts\n:Create New Script...,Create New Script from Template...,Open Existing Script...andAdd\nScript to Toolbox...;\n•open the\nHistory\npanel;\n•open the\nResults Viewer\npanel;\n•toggle the toolbox to thein-place modification modeusing the\nEdit Features In-Place\nbutton: only the algorithms\nthat are suitable to be executed on the active layer without outputting a new layer are displayed;\n•open the\nOptions\ndialog.\nBelow this toolbar is aSearch...box to help you easily find the tools you need. You can enter any word or phrase\non the text box. Notice that, as you type, the number of algorithms, models or scripts in the toolbox is reduced to\njust those that contain the text you have entered in their names or keywords.\nNote:At the top of the list of algorithms are displayed the most recent used tools; handy if you want to reexecute\nany.\n794Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nFig. 24.7: Processing Toolbox showing search results\nTo execute a tool, just double-click on its name in the toolbox.\n24.3.1The algorithm dialog\nOnce you double-click on the name of the algorithm that you want to execute, a dialog similar to that in theFig. 24.8\nbelow is shown (in this case, the dialog corresponds to theCentroidsalgorithm).\nFig. 24.8: Algorithm Dialog - Parameters\nThe dialog shows two tabs (ParametersandLog) on the left part, the algorithm description on the right, and a set of\nbuttons at the bottom.\n24.3. The Toolbox795\n\nQGIS Desktop 3.22 User Guide\nTheParameterstab is used to set the input values that the algorithm needs to be executed. It shows a list of input\nvalues and configuration parameters to be set. It of course has a different content, depending on the requirements of\nthe algorithm to be executed, and is created automatically based on those requirements.\nAlthough the number and type of parameters depend on the characteristics of the algorithm, the structure is similar\nfor all of them. The parameters found in the table can be of one of the following types.\n•Arasterlayer, to select from a list of all such layers available (currently opened) in QGIS. The selector contains\nas well a button on its right-hand side, to let you select filenames that represent layers currently not loaded in\nQGIS.\n•Avector layer, to select from a list of all vector layers available in QGIS. Layers not loaded in QGIS can be\nselected as well, as in the case of raster layers, but only if the algorithm does not require a table field selected\nfrom the attributes table of the layer. In that case, only opened layers can be selected, since they need to be\nopen so as to retrieve the list of field names available.\nYou will see an iterator button by each vector layer selector, as shown in the figure below.\nFig. 24.9: Vector iterator button\nIf thealgorithm containsseveral ofthem, youwill be able to toggle justone ofthem. If the buttoncorresponding\nto a vector input is toggled, the algorithm will be executed iteratively on each one of its features, instead of\njust once for the whole layer, producing as many outputs as times the algorithm is executed. This allows for\nautomating the process when all features in a layer have to be processed separately.\nNote:By default, the parameters dialog will show a description of the CRS of each layer along with its name. If\nyou do not want to see this additional information, you can disable this functionality in the Processing Settings dialog,\nunchecking theGeneral►Show layer CRS definition in selection boxesoption.\n•Atable, to select from a list of all available in QGIS. Non-spatial tables are loaded into QGIS like vector layers,\nand in fact they are treated as such by the program. Currently, the list of available tables that you will see when\nexecuting an algorithm that needs one of them is restricted to tables coming from files in dBase (.dbf) or\nComma-Separated Values (.csv) formats.\n•Anoption, to choose from a selection list of possible options.\n•Anumerical value, to be introduced in a spin box. In some contexts (when the parameter applies at the feature\nlevel and not at the layer’s), you will find a\nData-defined override\nbutton by its side, allowing you to open the\nexpression builderand enter a mathematical expression to generate variable values for the parameter. Some\nuseful variables related to data loaded into QGIS can be added to your expression, so you can select a value\nderived from any of these variables, such as the cell size of a layer or the northernmost coordinate of another\none.\n796Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nFig. 24.10: Expression based input\n•Arange, with min and max values to be introduced in two text boxes.\n•Atext string, to be introduced in a text box.\n•Afield, to choose from the attributes table of a vector layer or a single table selected in another parameter.\n•Acoordinate reference system. You can select it among the recently used ones from the drop-down list or\nfrom the\nCRS selectiondialog that appears when you click on the button on the right-hand side.\n•Anextent, a text box defining a rectangle through its corners coordinate in the formatxmin, xmax, ymin,\nymax. Clicking on the button on the right-hand side of the value selector, a pop-up menu will appear, giving\nyou options to:\n–Calculate from layer: fills the text box with the coordinates of the bounding box of a layer to select among\nthe loaded ones\n–Use map canvas extent\n–Draw on canvas: the parameters window will hide itself, so you can click and drag onto the canvas. Once\nyou have defined the extent rectangle, the dialog will reappear, containing the values in the extent text\nbox.\nFig. 24.11: Extent selector\n•Alist of elements(whether raster or vector layers, tables, fields) to select from. Click on the...button at the\nleft of the option to see a dialog like the following one. Multiple selection is allowed and when the dialog is\nclosed, number of selected items is displayed in the parameter text box widget.\n24.3. The Toolbox797\n\nQGIS Desktop 3.22 User Guide\nFig. 24.12: Multiple Selection\n•Asmall tableto be edited by the user. These are used to define parameters like lookup tables or convolution\nkernels, among others.\nClick on the button on the right side to see the table and edit its values.\nFig. 24.13: Fixed Table\nDepending on the algorithm, the number of rows can be modified or not by using the buttons on the right side\nof the window.\nNote:Some algorithms require many parameters to run, e.g. in theRaster calculatoryou have to specify manually\nthe cell size, the extent and the CRS. You can avoid to choose all the parameters manually when the algorithm has\ntheReference layersparameter. With this parameter you can choose the reference layer and all its properties\n(cell size, extent, CRS) will be used.\nAlong with theParameterstab, there is another tab namedLog(seeFig. 24.14below). Information provided by the\nalgorithm during its execution is written in this tab, and allow you to track the execution and be aware and have more\ndetails about the algorithm as it runs. Information on algorithm execution is also output in theView►Panels►Log\nMessages Panel.\nNotice that not all algorithms write information to theLogtab, and many of them might run silently without producing\nany output other than the final files. Check theLog Messages Panelin that case.\n798Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nFig. 24.14: Algorithm Dialog - Log\nAt the bottom of theLogtab you will find buttons toSave Log to File,Copy Log to ClipboardandClear\nLog. These are particularly handy when you have checked theKeep dialog open after running algorithmin theGeneral\npart of the Processing options.\nOn the right hand side of the dialog you will find a short description of the algorithm, which will help you understand\nits purpose and its basic ideas. If such a description is not available, the description panel will not be shown.\nFor a more detailed help file, which might include description of every parameter it uses, or examples, you will find\naHelpbutton at the bottom of the dialog bringing you to the\nProcessing algorithms documentationor to the provider\ndocumentation (for some third-party providers).\nTheRun as batch processbutton triggers thebatch processing modeallowing to configure and run multiple instances\nof the algorithm with a variety of parameters.\n24.3. The Toolbox799\n\nQGIS Desktop 3.22 User Guide\nA note on projections\nProcessing algorithm execution are always performed in the input layer coordinate reference system (CRS). Due to\nQGIS’s on-the-fly reprojecting capabilities, although two layers might seem to overlap and match, that might not be\ntrue if their original coordinates are used without reprojecting them onto a common coordinate system. Whenever you\nuse more than one layer as input to aQGIS native algorithm, whether vector or raster, the layers will all be reprojected\nto match the coordinate reference system of the first input layer.\nThis is however less true for most of the external applications whose algorithms are exposed through the processing\nframework as they assume that all of the layers are already in a common coordinate system and ready to be analyzed.\nBy default, the parameters dialog will show a description of the CRS of each layer along with its name, making it\neasy to select layers that share the same CRS to be used as input layers. If you do not want to see this additional\ninformation, you can disable this functionality in the Processing settings dialog, unchecking theShow layer CRS\ndefinition in selection boxesoption.\nIf you try to execute an algorithm using as input two or more layers with unmatching CRSs, a warning dialog will be\nshown. This occurs thanks to theWarn before executing if layer CRS’s do not matchoption.\nYou still can execute the algorithm, but be aware that in most cases that will produce wrong results, such as empty\nlayers due to input layers not overlapping.\nTip: Use Processing algorithms to do intermediate reprojection\nWhen an algorithm can not successfully perform on multiple input layers due to unmatching CRSs, use QGIS internal\nalgorithm such asReproject layerto perform layers’ reprojection to the same CRS before executing the algorithm using\nthese outputs.\n24.3.2Data objects generated by algorithms\nData objects generated by an algorithm can be of any of the following types:\n•A raster layer\n•A vector layer\n•A table\n•An HTML file (used for text and graphical outputs)\nThese are all saved to disk, and the parameters table will contain a text box corresponding to each one of these outputs,\nwhere you can type the output channel to use for saving it. An output channel contains the information needed to\nsave the resulting object somewhere. In the most usual case, you will save it to a file, but in the case of vector layers,\nand when they are generated by native algorithms (algorithms not using external applications) you can also save to a\nPostGIS, GeoPackage or SpatiaLite database, or a memory layer.\nTo select an output channel, just click on the button on the right side of the text box, and you will see a small context\nmenu with the available options.\nIn the most usual case, you will select saving to a file. If you select that option, you will be prompted with a save file\ndialog, where you can select the desired file path. Supported file extensions are shown in the file format selector of\nthe dialog, depending on the kind of output and the algorithm.\nThe format of the output is defined by the filename extension. The supported formats depend on what is supported\nby the algorithm itself. To select a format, just select the corresponding file extension (or add it, if you are directly\ntyping the file path instead). If the extension of the file path you entered does not match any of the supported formats,\na default extension will be appended to the file path, and the file format corresponding to that extension will be used to\nsave the layer or table. Default extensions are.dbffor tables,.tiffor raster layers and.gpkgfor vector layers.\nThese can be modified in the setting dialog, selecting any other of the formats supported by QGIS.\nIf you do not enter any filename in the output text box (or select the corresponding option in the context menu), the\nresult will be saved as a\ntemporary filein the corresponding default file format, and it will be deleted once you exit\nQGIS (take care with that, in case you save your project and it contains temporary layers).\n800Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nYou can set a default folder for output data objects. Go to the settings dialog (you can open it from theSettings►\nOptions►Processingmenu), and in theGeneralgroup, you will find a parameter namedOutput folder. This output\nfolder is used as the default path in case you type just a filename with no path (i.e.,myfile.shp) when executing\nan algorithm.\nWhen running an algorithm that uses a vector layer in iterative mode, the entered file path is used as the base path\nfor all generated files, which are named using the base name and appending a number representing the index of the\niteration. The file extension (and format) is used for all such generated files.\nApart from raster layers and tables, algorithms also generate graphics and text as HTML files. These results are shown\nat the end of the algorithm execution in a new dialog. This dialog will keep the results produced by any algorithm\nduring the current session, and can be shown at any time by selectingProcessing►Results Viewerfrom the QGIS\nmain menu.\nSome external applications might have files (with no particular extension restrictions) as output, but they do not belong\nto any of the categories above. Those output files will not be processed by QGIS (opened or included into the current\nQGIS project), since most of the time they correspond to file formats or elements not supported by QGIS. This is,\nfor instance, the case with LAS files used for LiDAR data. The files get created, but you won’t see anything new in\nyour QGIS working session.\nFor all the other types of output, you will find a checkbox that you can use to tell the algorithm whether to load the\nfile once it is generated by the algorithm or not. By default, all files are opened.\nOptional outputs are not supported. That is, all outputs are created. However, you can uncheck the corresponding\ncheckbox if you are not interested in a given output, which essentially makes it behave like an optional output (in\nother words, the layer is created anyway, but if you leave the text box empty, it will be saved to a temporary file and\ndeleted once you exit QGIS).\n24.4The history manager\n24.4.1The processing history\nEvery time you execute an algorithm, information about the process is stored in the history manager. The date and\ntime of the execution are saved, along with the parameters used, making it is easy to track and control all the work\nthat has been developed using the Processing framework, and to reproduce it.\nFig. 24.15: History\nProcess information is kept as a command-line expression, even if the algorithm was launched from the toolbox. This\nmakes it useful for those learning how to use the command-line interface, since they can call an algorithm using the\ntoolbox and then check the history manager to see how it could be called from the command line.\n24.4. The history manager801\n\nQGIS Desktop 3.22 User Guide\nApart from browsing the entries in the registry, you can also re-execute processes by simply double-clicking on the\nentry. The algorithm dialog then opens with parameters already set, and you can change any of them to fit your needs\nand re-run the algorithm.\nTheHistorydialog also provides a convenient way to contribute to the consolidation of the testing infrastructure\nof QGIS Processing algorithms and scripts. When you right-click on an entry, you canCreate Test...using the con-\ncerned algorithm and parameters, following instructions athttps://github.com/qgis/QGIS/blob/release-3_22/python/\nplugins/processing/tests/README.md\n.\n24.4.2The processing log\nThe history dialog only contains the execution calls, but not the information produced by the algorithm when executed.\nThat information is written to the QGIS log (View►Panels►Log Messages Panel).\nThird-party algorithms are usually executed by using their command-line interfaces, which communicate with the\nuser via the console. Although that console is not shown, usually a full dump of it is written to the log each time you\nrun one of those algorithms. To avoid cluttering the log with that information, you can disable it for each provider in\nthe settings dialog.\nSome algorithms, even if they can produce a result with the given input data, output comments or additional infor-\nmation to log when they detect potential problems with the data, in order to warn you. Make sure you check those\nmessages in the log if you get unexpected results.\n24.5The graphical modeler\nThegraphical modelerallows you to create complex models using a simple and easy-to-use interface. When working\nwith a GIS, most analysis operations are not isolated, rather part of a chain of operations. Using the graphical modeler,\nthat chain of operations can be wrapped into a single process, making it convenient to execute later with a different set\nof inputs. No matter how many steps and different algorithms it involves, a model is executed as a single algorithm,\nsaving time and effort.\nThe graphical modeler can be opened from the Processing menu (Processing►Graphical Modeler).\n802Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n24.5.1The graphical modeler interface\nFig. 24.16: Modeler\nIn its main part, the modeler has a working canvas where the structure of the model and the workflow it represents\ncan be constructed.\nAt the top of the dialog, different menus and theNavigationtoolbar give access to a variety of tools.\n24.5. The graphical modeler803\n\nQGIS Desktop 3.22 User Guide\nModel menu\nLabelShortcutNavi-\ngation\nToolbar\nDescription\nValidate ModelChecks whether the algorithms and inputs used in the\nmodel exist. Convenient before releasing a model.\nRun Model...F5Executes the model\nReorder Model Inputs...Sets the order in which inputs are presented to the user\nin the algorithm dialog.\nOpen Model...Ctrl+OOpens a.model3file for edit or execution\nSave ModelCtrl+SSaves the model to disk as a.model3file\nSave Model as...Ctrl+Shift+SSaves the model to disk as a new.model3file\nSave Model in projectEmbeds the model file in the project file, making it avail-\nable when sharing the project file.\nEdit Model Help...An interface to document the model, the algorithms, the\nparameters and outputs, as well as the author and ver-\nsioning\nExport►\n►Export as Image...Saves the model’s graphical design to an image file for-\nmat (for illustration purpose)\n►Export as PDF...Saves the model’s graphical design to aPDFfile format\n(for illustration purpose)\n►Export as SVG...Saves the model’s graphical design to anSVGfile format\n(for illustration purpose)\n►Export as Script Al-\ngorithm...\nGenerates a python script file including the model’s in-\nstructions\n804Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nEdit menu\nLabelShortcutNavi-\ngation\nToolbar\nDescription\nSelect AllCtrl+ASelects all the model components in the designer\nSnap selected components\nto Grid\nsnaps and aligns the elements into a grid\nRedoCtrl+YRollback the latest canceled action.  See also the\nUndo/Redopanel.\nUndoCtrl+ZCancel the previous change. See also theUndo/Redo\npanel.\nCutCtrl+XCuts a selection of components from the model.\nCopyCtrl+CCopies a selection of components from the model.\nPasteCtrl+VPastes a cut or copied selection of components from a\nmodel to another or within the same model. The se-\nlected components keep their original properties and\ncomments.\nDelete selected com-\nponents\nDelRemoves a component from the model.\nAdd Group BoxAdds a box at the background of related components in\norder to visually group them. Particularly useful in big\nmodels to keep the workflow clean.\nView menu\nLabelShortcutNavi-\ngation\nToolbar\nDescription\nZoom To►Zooms to the selected group box extent\nZoom InCtrl++\nZoom OutCtrl+-\nZoom to 100%Ctrl+1\nZoom FullCtrl+0Displays all the components in the designer current can-\nvas\nShow CommentsDisplays comments associated to every algorithm or in-\nput in the graphical designer\nEnable Snapping\nToggle Panel VisibilityCtrl+TabSwitches ON or OFF thepanelsin the designer\n24.5. The graphical modeler805\n\nQGIS Desktop 3.22 User Guide\nPanels\nThe left part of the window is a section with five panels that can be used to add new elements to the model:\n1.Model Properties: specify the name (required) of the model and the group in which it will be displayed in the\nProcessing Toolbox\n2.Inputs: all theinput parametersthat could shape your model\n3.Algorithms: the availableProcessing algorithms\n4.Variables: Models can contain dedicatedvariablesthat are unique and only available to them. These variables\ncan be accessed by any expression used within the model. They are useful to control algorithms within a model\nand control multiple aspects of the model by changing a single variable. The variables can be viewed and\nmodified in theVariablespanel.\n5.Undo History: this panel will register everything that happens in the modeler, making it easy to cancel things\nyou did wrong.\nAbout available algorithms\nSome algorithms that can be executed from the toolbox do not appear in the list of available algorithms when you are\ndesigning a model. To be included in a model, an algorithm must have the correct semantic. If an algorithm does not\nhave such a well-defined semantic (for instance, if the number of output layers cannot be known in advance), then it\nis not possible to use it within a model, and it will not appear in the list of algorithms that you can find in the modeler\ndialog. On the other hand some algorithms are specific to the modeler. Those algorithms are located within the group\n‘Modeler Tools’.\n24.5.2Creating a model\nCreating a model involves two basic steps:\n1.Definition of necessary inputs. These inputs will be added to the parameters window, so the user can set their\nvalues when executing the model. The model itself is an algorithm, so the parameters window is generated\nautomatically as for all algorithms available in the Processing framework.\n2.Definition of the workflow. Using the input data of the model, the workflow is defined by adding algorithms\nand selecting how they use the defined inputs or the outputs generated by other algorithms in the model.\nDefinition of inputs\nThe first step is to define the inputs for the model. The following elements are found in theInputspanel on the left\nside of the modeler window:\nTable 24.1: List of parameter types for model building\nAnnotation LayerAuthentication ConfigurationBooleanColorConnection Name\nCoordinate OperationCRSDatabase SchemaDatabase TableDatetime\nDistanceDurationDXF LayersEnumExpression\nExtentField AggregatesFields MapperFile/FolderGeometry\nMap LayerMap ThemeMatrixMesh Dataset GroupsMesh Dataset Time\nMesh LayerMultiple InputNumberPointPoint Cloud Layer\nPrint LayoutPrint Layout ItemRangeRaster BandRaster Layer\nScaleStringTIN Creation LayersVector FeaturesVector Field\nVector LayerVector Tile Writer Layers\nNote:Hovering with the mouse over the inputs will show a tooltip with additional information.\n806Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nWhen double-clicking on an element, a dialog is shown that lets you define its characteristics. Depending on the\nparameter, the dialog will contain at least one element (the description, which is what the user will see when executing\nthe model). For example, when adding a numerical value, as can be seen in the next figure, in addition to the\ndescription of the parameter, you have to set a default value and the range of valid values.\nFig. 24.17: Model Parameters Definition\nYou can define your input as mandatory for your model by checking theMandatoryoption and by checking\nthe\nAdvancedcheckbox you can set the input to be within theAdvancedsection. This is particularly useful\nwhen the model has many parameters and some of them are not trivial, but you still want to choose them.\nFor each added input, a new element is added to the modeler canvas.\n24.5. The graphical modeler807\n\nQGIS Desktop 3.22 User Guide\nFig. 24.18: Model Parameters\nYou can also add inputs by dragging the input type from the list and dropping it at the position where you want it\nin the modeler canvas. If you want to change a parameter of an existing input, just double click on it, and the same\ndialog will pop up.\nWhen using a model within another model, the inputs and outputs necessary will be displayed in the canvas.\nDefinition of the workflow\nIn the following example we will add two inputs and two algorithms. The aim of the model is to copy the elevation\nvalues from a DEM raster layer to a line layer using theDrapealgorithm, and then calculate the total ascent of the\nline layer using theClimb Along Linealgorithm.\nIn theInputstab, choose the two inputs asVector Layerfor the line andRaster Layerfor the DEM. We\nare now ready to add the algorithms to the workflow.\nAlgorithms can be found in theAlgorithmspanel, grouped much in the same way as they are in the Processing toolbox.\nFig. 24.19: Model Inputs\nTo add an algorithm to a model, double-click on its name or drag and drop it, just like for inputs. As for the inputs\nyou can change the description of the algorithm and add a comment. When adding an algorithm, an execution dialog\nwill appear, with a content similar to the one found in the execution panel that is shown when executing the algorithm\n808Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nfrom the toolbox. The following picture shows both theDrape (set Z value from raster)and the\nClimb along linealgorithm dialogs.\nFig. 24.20: Model Algorithm parameters\nAs you can see, there are however some differences. Each parameter has a drop-down menu next to it allowing to\ncontrol how it will be served during the workflow:\n•Value: allows you to set the parameter from a loaded layer in the QGIS project or to browse a layer from\na folder\n•Pre-calculated Value: with this option you can open the Expression Builder and define your\nown expression to fill the parameter. Model inputs together with some other layer statistics are available as\nvariablesand are listed at the top of the Search dialog of the Expression Builder\n•Model Input: choose this option if the parameter comes from an input of the model you have defined.\nOnce clicked, this option will list all the suitable inputs for the parameter\n•Algorithm Output: is useful when the input parameter of an algorithm is an output of another\nalgorithm\n•outputs parametershave the addditionalModel Outputoption that makes the output of the algorithm\navailable in the model. If a layer generated by the algorithm is only to be used as input to another algorithm,\ndon’t edit that text box.\nIn the following picture you can see the two input parameters defined asModel Inputand the temporary\noutput layer:\n24.5. The graphical modeler809\n\nQGIS Desktop 3.22 User Guide\nFig. 24.21: Algorithm Input and Output parameters\nYou will also find an additional parameter namedDependenciesthat is not available when calling the algorithm from\nthe toolbox. This parameter allows you to define the order in which algorithms are executed, by explicitly defining\none algorithm as aparentof the current one. This will force theparentalgorithm to be executed before the current\none.\nWhen you use the output of a previous algorithm as the input of your algorithm, that implicitly sets the previous\nalgorithm as parent of the current one (and places the corresponding arrow in the modeler canvas). However, in some\ncases an algorithm might depend on another one even if it does not use any output object from it (for instance, an\nalgorithm that executes a SQL sentence on a PostGIS database and another one that imports a layer into that same\ndatabase). In that case, just select the previous algorithm in theDependenciesparameter and they will be executed in\nthe correct order.\nOnce all the parameters have been assigned valid values, click onOKand the algorithm will be added to the canvas.\nIt will be linked to the elements in the canvas (algorithms or inputs) that provide objects that are used as inputs for\n810Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nthe algorithm.\nElements can be dragged to a different position on the canvas using the\nSelect/Move Item\ntool. This is useful to make\nthe structure of the model clearer and more intuitive. You can also resize the elements, grasping their border. This is\nparticularly useful if the description of the input or algorithm is long. WithView►Enable snappingoption checked,\nitems resizing or displacement can be bound to a virtual grid, for a more visually structured algorithm design.\nLinks between elements are updated automatically and you can see a+button at the top and at the bottom of each\nalgorithm. Clicking the button will list all the inputs and outputs of the algorithm so you can have a quick overview.\nFig. 24.22: A complete model\nWith theEdit►Add Group Boxtool, you can add a draggableboxto the canvas. This feature is very useful in big\nmodels to group related elements in the modeler canvas and to keep the workflow clean. For example we might group\ntogether all the inputs of the example:\n24.5. The graphical modeler811\n\nQGIS Desktop 3.22 User Guide\nFig. 24.23: Model Group Box\nYou can change the name and the color of the boxes. Group boxes are very useful when used together withView►\nZoom To► tool, allowing you to zoom to a specific part of the model. You can also zoom in and out by using the\nmouse wheel.\nYou might want to change the order of the inputs and how they are listed in the main model dialog. At the bottom of\ntheInputpanel you will find theReorder Model Inputs...button and by clicking on it a new dialog pops\nup allowing you to change the order of the inputs:\n812Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nFig. 24.24: Reorder Model Inputs\nComments can also be added to inputs or algorithms present in the modeler. This can be done by going in the\nCommenttab of the item or with a right-click. In the same tab a color can be set manual for individual model\ncomments. Comments are visible only in the modeler canvas and not in the final algorithm dialog; they can be hidden\nby deactivatingView►Show Comments.\nYou can run your algorithm any time by clicking on the\nRun model\nbutton. When using the editor to execute a\nmodel, any non-default values will be saved in the inputs. This means that executing the model at a later time from\nthe editor will have the dialog prefilled with those values on any subsequent run.\nIn order to use the algorithm from the toolbox, it has to be saved and the modeler dialog closed, to allow the toolbox\nto refresh its contents.\n24.5. The graphical modeler813\n\nQGIS Desktop 3.22 User Guide\nDocumenting your model\nYou need to document your model, and this can be done from the modeler itself. Click on the\nEdit model help\nbutton,\nand a dialog like the one shown next will appear.\nFig. 24.25: Editing Help\nOn the right-hand side, you will see a simple HTML page, created using the description of the input parameters and\noutputs of the algorithm, along with some additional items like a general description of the model or its author. The\nfirst time you open the help editor, all these descriptions are empty, but you can edit them using the elements on the\nleft-hand side of the dialog. Select an element on the upper part and then write its description in the text box below.\nModel help is saved as part of the model itself.\n814Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n24.5.3Saving and loading models\nSaving models\nUse the\nSave model\nbutton to save the current model and the\nOpen Model\nbutton to open a previously saved model.\nModels are saved with the.model3extension. If the model has already been saved from the modeler window, you\nwill not be prompted for a filename. Since there is already a file associated with the model, that file will be used for\nsubsequent saves.\nBefore saving a model, you have to enter a name and a group for it in the text boxes in the upper part of the window.\nModels saved in themodelsfolder (the default folder when you are prompted for a filename to save the model) will\nappear in the toolbox in the corresponding branch. When the toolbox is invoked, it searches themodelsfolder for\nfiles with the.model3extension and loads the models they contain. Since a model is itself an algorithm, it can be\nadded to the toolbox just like any other algorithm.\nModels can also be saved within the project file using the\nSave model in project\nbutton. Models saved using this method\nwon’t be written as.model3files on the disk but will be embedded in the project file.\nProject models are available in theProject modelsmenu of the toolbox.\nThe models folder can be set from the Processing configuration dialog, under theModelergroup.\nModels loaded from themodelsfolder appear not only in the toolbox, but also in the algorithms tree in theAlgorithms\ntab of the modeler window. That means that you can incorporate a model as a part of a bigger model, just like other\nalgorithms.\nModels will show up in theBrowserpanel and can be run from there.\nExporting a model as a Python script\nAs we will see in a later chapter, Processing algorithms can be called from the QGIS Python console, and new\nProcessing algorithms can be created using Python. A quick way to create such a Python script is to create a model\nand then export it as a Python file.\nTo do so, click on the\nExport as Script Algorithm...\nin the modeler canvas or right click on the name of the model in the\nProcessing Toolbox and choose\nExport Model as Python Algorithm...\n.\nExporting a model as an image, PDF or SVG\nA model can also be exported as an image, SVG or PDF (for illustration purposes) by clicking\nExport as image\n,\nExport as PDF\nor\nExport as SVG\n.\n24.5.4Editing a model\nYou can edit the model you are currently creating, redefining the workflow and the relationships between the algo-\nrithms and inputs that define the model.\nIf you right-click on an algorithm in the canvas, you will see a context menu like the one shown next:\n24.5. The graphical modeler815\n\nQGIS Desktop 3.22 User Guide\nFig. 24.26: Modeler Right Click\nSelecting theRemoveoption will cause the selected algorithm to be removed. An algorithm can be removed only if\nthere are no other algorithms depending on it. That is, if no output from the algorithm is used in a different one as\ninput. If you try to remove an algorithm that has others depending on it, a warning message like the one you can see\nbelow will be shown:\nFig. 24.27: Cannot Delete Algorithm\nSelecting theEdit...option will show the parameter dialog of the algorithm, so you can change the inputs and param-\neter values. Not all input elements available in the model will appear as available inputs. Layers or values generated at\na more advanced step in the workflow defined by the model will not be available if they cause circular dependencies.\nSelect the new values and click on theOKbutton as usual. The connections between the model elements will change\nin the modeler canvas accordingly.\nTheAdd comment...allows you to add a comment to the algorithm to better describe the behavior.\nA model can be run partially by deactivating some of its algorithms. To do it, select theDeactivateoption in the\ncontext menu that appears when right-clicking on an algorithm element. The selected algorithm, and all the ones in\nthe model that depend on it will be displayed in grey and will not be executed as part of the model.\n816Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nFig. 24.28: Model With Deactivated Algorithms\nWhen right-clicking on an algorithm that is not active, you will see aActivatemenu option that you can use to reactivate\nit.\n24.6The batch processing interface\n24.6.1Introduction\nAll algorithms (including models) can be executed as a batch process. That is, they can be executed using not just\na single set of inputs, but several of them, executing the algorithm as many times as needed. This is useful when\nprocessing large amounts of data, since it is not necessary to launch the algorithm many times from the toolbox.\nTo execute an algorithm as a batch process, right-click on its name in the toolbox and select theExecute as batch\nprocessoption in the pop-up menu that will appear.\nFig. 24.29: Batch Processing from right-click\nIf you have the execution dialog of the algorithm open, you can also start the batch processing interface from there,\nclicking on theRun as batch process...button.\n24.6. The batch processing interface817\n\nQGIS Desktop 3.22 User Guide\nFig. 24.30: Batch Processing From Algorithm Dialog\n24.6.2The parameters table\nExecuting a batch process is similar to performing a single execution of an algorithm. Parameter values have to be\ndefined, but in this case we need not just a single value for each parameter, but a set of them instead, one for each\ntime the algorithm has to be executed. Values are introduced using a table like the one shown next, where each row\nis an iteration and columns are the parameters of the algorithm.\nFig. 24.31: Batch Processing\nFrom the top toolbar, you can:\n•\nAdd row\n: adds a new processing entry for configuration\n•\nRemove row(s)\n: remove selected rows from the table. Row selection is done by clicking the number at the left\nand allows\nkeyboard combinationfor multi selection.\n•\nOpen\na batch processing configuration file\n•\nSave\nthe batch processing configuration to a.JSONfile that can be run afterwards\nBy default, the table contains just two rows:\n818Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n•The first row displays in each cell anAutofill...► drop-down menu withoptionsto quickly fill the cells below.\nAvailable options depend on the parameter type.\n•The second row (as well as each subsequent one) represents a single execution of the algorithm, and each cell\ncontains the value of one of the parameters. It is similar to the parameters dialog that you see when executing\nan algorithm from the toolbox, but with a different arrangement.\nAt the bottom of the table, you can set whether toLoad layers on completion.\nOnce the size of the table has been set, it has to be filled with the desired values.\n24.6.3Filling the parameters table\nFor most parameters, setting the value is trivial. The appropriate widget, same as in thesingle process dialog, is\nprovided, allowing to just type the value, or select it from a list of possible values, depending on the parameter type.\nThis also includes data-define widget, when compatible.\nTo automate the batch process definition and avoid filling the table cell by cell, you may want to press down the\nAutofill...menu of a parameter and select any of the following options to replace values in the column:\n•Fill Downwill take the input for the first process and enter it for all other processes.\n•Calculate by Expression...will allow you to create a new QGIS expression to use to update all existing\nvalues within that column. Existing parameter values (including those from other columns) are available for\nuse inside the expression via\nvariables. E.g. setting the number of segments based on the buffer distance of\neach layer:\nCASE WHEN@DISTANCE>20THEN12ELSE8END\n•Add Values by Expression...will add new rows using the values from an expression which returns an array (as\nopposed toCalculate by Expression..., which works only on existing rows). The intended use case is to allow\npopulating the batch dialog using complex numeric series. For example adding rows for a batch buffer using\nthe expressiongenerate_series(100, 1000, 50)for distance parameter results in new rows with\nvalues 100, 150, 200, .... 1000.\n•When setting a file or layer parameter, more options are provided:\n–Add Files by Pattern...adds new rows to the table for matching files found using a file pattern and folder,\nwith the option toSearch recursively. E.g. *.shp.\n–Select files\n–Add all files from a directory\n–Select from open layers\nOutput data parameter exposes the same capabilities as when executing the algorithm as a single process. Depending\non the algorithm, the output can be:\n•skipped, if the cell is left empty\n•saved as a temporary layer: fill the cell withTEMPORARY_OUTPUTand remember to tick theLoad layers\non completioncheckbox.\n•saved as a plain file (.SHP,.GPKG,.XML,.PDF,.JPG,...) whose path could be set with theAutofilloptions\nexposed beforehand. E.g. useCalculate by Expression...to set output file names to complex expressions like:\n'/home/me/stuff/buffer_'||left(@INPUT,30)||'_'||@DISTANCE||'.shp'\nYou can also type the file path directly or use the file chooser dialog that appears when clicking on the accom-\npanying...button. Once you select the file, a new dialog is shown to allow for auto-completion of other cells\nin the same column (same parameter).\n24.6. The batch processing interface819\n\nQGIS Desktop 3.22 User Guide\nFig. 24.32: Batch Processing Save\nIf the default value (\nDo not autofill\n) is selected, it will just put the selected filename in the selected cell from the\nparameters table. If any of the other options is selected, all the cellsbelowthe selected one will be automatically\nfilled based on a defined criteria:\n–Fill with numbers: incrementally appends a number to the file name\n–Fill with parameter values: you can select a parameter whose value in the same row is appended to the\nfile name. This is particularly useful for naming output data objects according to input ones.\n•saved as a layer within a database container:\n# Indicate a layer within a GeoPackage file\nogr:dbname='C:/Path/To/Geopackage.gpkg'table=\"New_Table\"(geom)\n# Use the \"Calculate By Expression\" to output to different layers in a␣\n,→GeoPackage\n'ogr:dbname=\\''||@project_folder||'/Buffers.gpkg\\'table=\"'||@INPUT||'_\n,→'||@DISTANCE||'\"(geom)'\n24.6.4Executing the batch process\nTo execute the batch process once you have introduced all the necessary values, just click onRun. TheLogpanel is\nactivated and displays details and steps of the execution process. Progress of the global batch task will be shown in\nthe progress bar in the lower part of the dialog.\n24.7Using processing algorithms from the console\nThe console allows advanced users to increase their productivity and perform complex operations that cannot be\nperformed using any of the other GUI elements of the processing framework. Models involving several algorithms\ncan be defined using the command-line interface, and additional operations such as loops and conditional sentences\ncan be added to create more flexible and powerful workflows.\nThere is not a processing console in QGIS, but all processing commands are available instead from the QGIS built-in\nPython console. That means that you can incorporate those commands into your console work and connect processing\nalgorithms to all the other features (including methods from the QGIS API) available from there.\nThe code that you can execute from the Python console, even if it does not call any specific processing method,\ncan be converted into a new algorithm that you can later call from the toolbox, the graphical modeler or any other\ncomponent, just like you do with any other algorithm. In fact, some algorithms that you can find in the toolbox are\nsimple scripts.\nIn this section, we will see how to use processing algorithms from the QGIS Python console, and also how to write\nalgorithms using Python.\n820Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n24.7.1Calling algorithms from the Python console\nThe first thing you have to do is to import the processing functions with the following line:\n>>>fromqgisimportprocessing\nNow, there is basically just one (interesting) thing you can do with that from the console: execute an algorithm. That\nis done using therun()method, which takes the name of the algorithm to execute as its first parameter, and then\na variable number of additional parameters depending on the requirements of the algorithm. So the first thing you\nneed to know is the name of the algorithm to execute. That is not the name you see in the toolbox, but rather a unique\ncommand–line name. To find the right name for your algorithm, you can use theprocessingRegistry. Type\nthe following line in your console:\n>>>foralginQgsApplication.processingRegistry().algorithms():\nprint(alg.id(), \"->\", alg.displayName())\nYou will see something like this (with some extra dashes added to improve readability).\n3d:tessellate-------------->Tessellate\ngdal:aspect---------------->Aspect\ngdal:assignprojection------>Assign projection\ngdal:buffervectors--------->Buffer vectors\ngdal:buildvirtualraster---->Build Virtual Raster\ngdal:cliprasterbyextent---->Clip raster by extent\ngdal:cliprasterbymasklayer->Clip raster by mask layer\ngdal:clipvectorbyextent---->Clip vector by extent\ngdal:clipvectorbypolygon\n--->Clip vector by mask layer\ngdal:colorrelief----------->Color relief\ngdal:contour--------------->Contour\ngdal:convertformat--------->Convertformat\ngdal:dissolve-------------->Dissolve\n...\nThat’s a list of all the available algorithm IDs, sorted by provider name and algorithm name, along with their corre-\nsponding names.\nOnce you know the command-line name of the algorithm, the next thing to do is to determine the right syntax to\nexecute it. That means knowing which parameters are needed when calling therun()method.\nThere is a method to describe an algorithm in detail, which can be used to get a list of the parameters that\nan algorithm requires and the outputs that it will generate.  To get this information, you can use the\nalgo-\nrithmHelp(id_of_the_algorithm)method. Use the ID of the algorithm, not the full descriptive name.\nCalling the method withnative:bufferas parameter (qgis:bufferis an alias fornative:bufferand\nwill also work), you get the following description:\n>>>processing.algorithmHelp(\"native:buffer\")\nBuffer (native:buffer)\nThis algorithm computes a buffer area for all the features in an\ninput layer, using a fixed or dynamic distance.\nThe segments parameter controls the number of line segments to\nuse to approximate a quarter circle when creating rounded\noffsets.\nThe end cap style parameter controls how line endings are handled\nin the buffer.\nThe join style parameter specifies whether round, miter or\nbeveled joins should be used when offsetting corners in a line.\n(continues on next page)\n24.7. Using processing algorithms from the console821\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\nThe miter limit parameter is only applicable for miter join\nstyles, and controls the maximum distance from the offset curve\nto use when creating a mitered join.\n----------------\nInput parameters\n----------------\nINPUT: Input layer\nParameter type: QgsProcessingParameterFeatureSource\nAccepted data types:\n- str: layer ID\n- str: layer name\n- str: layer source\n- QgsProcessingFeatureSourceDefinition\n- QgsProperty\n- QgsVectorLayer\nDISTANCE: Distance\nParameter type: QgsProcessingParameterDistance\nAccepted data types:\n- int\n- float\n- QgsProperty\nSEGMENTS: Segments\nParameter type: QgsProcessingParameterNumber\nAccepted data types:\n- int\n- float\n- QgsProperty\nEND_CAP_STYLE: End cap style\nParameter type: QgsProcessingParameterEnum\nAvailable values:\n- 0: Round\n- 1: Flat\n- 2: Square\nAccepted data types:\n- int\n- str: as string representation of int, e.g. '1'\n- QgsProperty\nJOIN_STYLE: Join style\nParameter type: QgsProcessingParameterEnum\nAvailable values:\n- 0: Round\n- 1: Miter\n- 2: Bevel\n(continues on next page)\n822Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\nAccepted data types:\n- int\n- str: as string representation of int, e.g. '1'\n- QgsProperty\nMITER_LIMIT: Miter limit\nParameter type: QgsProcessingParameterNumber\nAccepted data types:\n- int\n- float\n- QgsProperty\nDISSOLVE: Dissolve result\nParameter type: QgsProcessingParameterBoolean\nAccepted data types:\n- bool\n- int\n- str\n- QgsProperty\nOUTPUT: Buffered\nParameter type: QgsProcessingParameterFeatureSink\nAccepted data types:\n- str: destination vector file, e.g. 'd:/test.shp'\n- str: 'memory:' to store result in temporary memory layer\n- str: using vector provider ID prefix and destination URI,\ne.g. 'postgres:...' to store result in PostGIS table\n- QgsProcessingOutputLayerDefinition\n- QgsProperty\n----------------\nOutputs\n----------------\nOUTPUT:  <QgsProcessingOutputVectorLayer>\nBuffered\nNow you have everything you need to run any algorithm. As we have already mentioned, algorithms can be run using:\nrun(). Its syntax is as follows:\n>>>processing.run(name_of_the_algorithm, parameters)\nWhere parameters is a dictionary of parameters that depend on the algorithm you want to run, and is exactly the list\nthat thealgorithmHelp()method gives you.\n1>>>processing.run(\"native:buffer\", {'INPUT':'/data/lines.shp',\n2'DISTANCE':100.0,\n3\n'SEGMENTS':10,\n4'DISSOLVE':True,\n5'END_CAP_STYLE':0,\n6\n'JOIN_STYLE':0,\n7'MITER_LIMIT':10,\n8\n'OUTPUT':'/data/buffers.shp'})\nIf a parameter is optional and you do not want to use it, then don’t include it in the dictionary.\n24.7. Using processing algorithms from the console823\n\nQGIS Desktop 3.22 User Guide\nIf a parameter is not specified, the default value will be used.\nDepending on the type of parameter, values are introduced differently. The next list gives a quick review of how to\nintroduce values for each type of input parameter:\n•Raster Layer, Vector Layer or Table. Simply use a string with the name that identifies the data object to use\n(the name it has in the QGIS Table of Contents) or a filename (if the corresponding layer is not opened, it will\nbe opened but not added to the map canvas). If you have an instance of a QGIS object representing the layer,\nyou can also pass it as parameter.\n•Enumeration. If an algorithm has an enumeration parameter, the value of that parameter should be entered\nusing an integer value. To know the available options, you can use thealgorithmHelp()command, as\nabove. For instance, thenative:bufferalgorithm has an enumeration called JOIN_STYLE:\nJOIN_STYLE: Join style\nParametertype: QgsProcessingParameterEnum\nAvailable values:\n-0: Round\n-1: Miter\n-2: Bevel\nAccepted data types:\n-int\n-str:asstring representation ofint, e.g.'1'\n-QgsProperty\nIn this case, the parameter has three options. Notice that ordering is zero-based.\n•Boolean. UseTrueorFalse.\n•Multiple input. The value is a string with input descriptors separated by semicolons (;). As in the case of\nsingle layers or tables, each input descriptor can be the data object name, or its file path.\n•Table Field from XXX. Use a string with the name of the field to use. This parameter is case-sensitive.\n•Fixed Table. Type the list of all table values separated by commas (,) and enclosed between quotes (\"). Values\nstart on the upper row and go from left to right. You can also use a 2-D array of values representing the table.\n•CRS. Enter the EPSG code number of the desired CRS.\n•Extent. You must use a string withxmin,xmax,yminandymaxvalues separated by commas (,).\nBoolean, file, string and numerical parameters do not need any additional explanations.\nInput parameters such as strings, booleans, or numerical values have default values. The default value is used if the\ncorresponding parameter entry is missing.\nFor output data objects, type the file path to be used to save it, just as it is done from the toolbox. If the output object\nis not specified, the result is saved to a temporary file (or skipped if it is an optional output). The extension of the\nfile determines the file format. If you enter a file extension not supported by the algorithm, the default file format for\nthat output type will be used, and its corresponding extension appended to the given file path.\nUnlike when an algorithm is executed from the toolbox, outputs are not added to the map canvas if you execute that\nsame algorithm from the Python console using\nrun(), butrunAndLoadResults()will do that.\nTherun()method returns a dictionary with one or more output names (the ones shown in the algorithm description)\nas keys and the file paths of those outputs as values:\n1>>>myresult=processing.run(\"native:buffer\", {'INPUT':'/data/lines.shp',\n2\n'DISTANCE':100.0,\n3'SEGMENTS':10,\n4'DISSOLVE':True,\n5\n'END_CAP_STYLE':0,\n6'JOIN_STYLE':0,\n(continues on next page)\n824Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n7'MITER_LIMIT':10,\n8'OUTPUT':'/data/buffers.shp'})\n9>>>myresult['OUTPUT']\n10/data/buffers.shp\nYou can load feature output by passing the corresponding file paths to theload()method. Or you could use\nrunAndLoadResults()\ninstead of\nrun()to load them immediately.\nIf you want to open an algorithm dialog from the console you can use thecreateAlgorithmDialogmethod.\nThe only mandatory parameter is the algorithm name, but you can also define the dictionary of parameters so that\nthe dialog will be filled automatically:\n1>>>my_dialog=processing.createAlgorithmDialog(\"native:buffer\", {\n2'INPUT':'/data/lines.shp',\n3'DISTANCE':100.0,\n4'SEGMENTS':10,\n5'DISSOLVE':True,\n6'END_CAP_STYLE':0,\n7'JOIN_STYLE':0,\n8'MITER_LIMIT':10,\n9\n'OUTPUT':'/data/buffers.shp'})\n10>>>my_dialog.show()\nTheexecAlgorithmDialogmethod opens the dialog immediately:\n1>>>processing.execAlgorithmDialog(\"native:buffer\", {\n2'INPUT':'/data/lines.shp',\n3'DISTANCE':100.0,\n4'SEGMENTS':10,\n5'DISSOLVE':True,\n6'END_CAP_STYLE':0,\n7'JOIN_STYLE':0,\n8'MITER_LIMIT':10,\n9\n'OUTPUT':'/data/buffers.shp'})\n24.7.2Creating scripts and running them from the toolbox\nYou can create your own algorithms by writing Python code. Processing scripts extendQgsProcessingAl-\ngorithm, so you need to add some extra lines of code to implement mandatory functions. You can findCreate\nnew script(clean sheet) andCreate New Script from Template(template that includes code for mandatory functions\nof\nQgsProcessingAlgorithm) under theScriptsdropdown menu on the top of the Processing toolbox. The\nProcessing Script Editor will open, and that’s where you should type your code. Saving the script from there in\nthescriptsfolder (the default folder when you open the save file dialog) with a.pyextension should create the\ncorresponding algorithm.\nThe name of the algorithm (the one you will see in the toolbox) is defined within the code.\nLet’s have a look at the following code, which defines a Processing algorithm that performs a buffer operation with a\nuser defined buffer distance on a vector layer that is specified by the user, after first smoothing the layer.\n1fromqgis.coreimport(QgsProcessingAlgorithm,\n2QgsProcessingParameterNumber,\n3QgsProcessingParameterFeatureSource,\n4QgsProcessingParameterFeatureSink)\n5\n6\nfromqgisimportprocessing\n7\n8classalgTest(QgsProcessingAlgorithm):\n9INPUT_BUFFERDIST\n='BUFFERDIST'\n(continues on next page)\n24.7. Using processing algorithms from the console825\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n10OUTPUT_BUFFER='OUTPUT_BUFFER'\n11INPUT_VECTOR='INPUT_VECTOR'\n12\n13def__init__(self):\n14super().__init__()\n15\n16defname(self):\n17return\"algTest\"\n18\n19defdisplayName(self):\n20return\"algTest script\"\n21\n22defcreateInstance(self):\n23returntype(self)()\n24\n25definitAlgorithm(self, config=None):\n26self.addParameter(QgsProcessingParameterFeatureSource(\n27self.INPUT_VECTOR,\"Input vector\"))\n28self.addParameter(QgsProcessingParameterNumber(\n29self.INPUT_BUFFERDIST,\"Buffer distance\",\n30QgsProcessingParameterNumber.Double,\n31100.0))\n32self.addParameter(QgsProcessingParameterFeatureSink(\n33self.OUTPUT_BUFFER,\"Output buffer\"))\n34\n35\ndefprocessAlgorithm(self, parameters, context, feedback):\n36#DO SOMETHING\n37algresult=processing.run(\"native:smoothgeometry\",\n38{'INPUT': parameters[self.INPUT_VECTOR],\n39'ITERATIONS':2,\n40'OFFSET':0.25,\n41'MAX_ANGLE':180,\n42'OUTPUT':'memory:'},\n43context=context, feedback=feedback, is_child_algorithm=True)\n44smoothed=algresult['OUTPUT']\n45algresult=processing.run('native:buffer',\n46{\n'INPUT': smoothed,\n47'DISTANCE': parameters[self.INPUT_BUFFERDIST],\n48'SEGMENTS':5,\n49'END_CAP_STYLE':0,\n50'JOIN_STYLE':0,\n51'MITER_LIMIT':10,\n52'DISSOLVE':True,\n53'OUTPUT': parameters[self.OUTPUT_BUFFER]},\n54context=context, feedback=feedback, is_child_algorithm=True)\n55buffered=algresult['OUTPUT']\n56\nreturn{self.OUTPUT_BUFFER: buffered}\nAfter doing the necessary imports, the followingQgsProcessingAlgorithmfunctions are specified:\n•name(): The id of the algorithm (lowercase).\n•displayName(): A human readable name for the algorithm.\n•createInstance(): Create a new instance of the algorithm class.\n•initAlgorithm(): Configure the parameterDefinitions and outputDefinitions.\nHere you describe the parameters and output of the algorithm. In this case, a feature source for the input, a\nfeature sink for the result and a number for the buffer distance.\n•processAlgorithm(): Do the work.\nHere we first run thesmoothgeometryalgorithm to smooth the geometry, and then we run thebuffer\n826Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nalgorithm on the smoothed output. To be able to run algorithms from within another algorithm we have to set\ntheis_child_algorithmargument toTrue. You can see how input and output parameters are used as\nparameters to thesmoothgeometryandbufferalgorithms.\nThere are a number of different parameter types available for input and output. Below is an alphabetically sorted list:\nTable 24.2: List of input and output algorithm parameter types\nQgsProcessingParameterAggregateQgsProcessingParameterAnnotationLayerQgsProcessingParameterAuthConfigQgsProcessingParameterBand\nQgsProcessingParameterBooleanQgsProcessingParameterColorQgsProcessingParameterCoordinateOperationQgsProcessingParameterCrs\nQgsProcessingParameterDatabaseSchemaQgsProcessingParameterDatabaseTableQgsProcessingParameterDateTimeQgsProcessingParameterDistance\nQgsProcessingParameterEnumQgsProcessingParameterExpressionQgsProcessingParameterExtentQgsProcessingParameterFeatureSink\nQgsProcessingParameterFeatureSourceQgsProcessingParameterFieldQgsProcessingParameterFieldMappingQgsProcessingParameterFile\nQgsProcessingParameterFileDestinationQgsProcessingParameterFolderDestinationQgsProcessingParameterGeometryQgsProcessingParameterLayout\nQgsProcessingParameterLayoutItemQgsProcessingParameterMapLayerQgsProcessingParameterMapThemeQgsProcessingParameterMatrix\nQgsProcessingParameterMeshLayerQgsProcessingParameterMultipleLayersQgsProcessingParameterNumberQgsProcessingParameterPoint\nQgsProcessingParameterPointCloudLayerQgsProcessingParameterProviderConnectionQgsProcessingParameterRangeQgsProcessingParameterRasterDestination\nQgsProcessingParameterRasterLayerQgsProcessingParameterScaleQgsProcessingParameterStringQgsProcessingParameterVectorDestination\nQgsProcessingParameterVectorLayerQgsProcessingParameterVectorTileWriterLayers\nThe first parameter to the constructors is the name of the parameter, and the second is the description of the parameter\n(for the user interface). The rest of the constructor parameters are parameter type specific.\nThe input can be turned into QGIS classes using theparameterAsfunctions of\nQgsProcessingAlgorithm.\nFor instance to get the number provided for the buffer distance as a double:\nself.parameterAsDouble(parameters,self.INPUT_BUFFERDIST, context)).\nTheprocessAlgorithmfunction should return a dictionary containing values for every output defined by the\nalgorithm. This allows access to these outputs from other algorithms, including other algorithms contained within the\nsame model.\nWell behaved algorithms should define and return as many outputs as makes sense. Non-feature outputs, such as\nnumbers and strings, are very useful when running your algorithm as part of a larger model, as these values can be\nused as input parameters for subsequent algorithms within the model. Consider adding numeric outputs for things\nlike the number of features processed, the number of invalid features encountered, the number of features output,\netc. The more outputs you return, the more useful your algorithm becomes!\nFeedback\nThefeedbackobject passed toprocessAlgorithm()should be used for user feedback / interaction. You\ncan use thesetProgress()function of thefeedbackobject to update the progress bar (0 to 100) to inform\nthe user about the progress of the algorithm. This is very useful if your algorithm takes a long time to complete.\nThefeedbackobject provides anisCanceled()method that should be monitored to enable cancelation of the\nalgorithm by the user. The\npushInfo()method offeedbackcan be used to send information to the user, and\nreportError()is handy for pushing non-fatal errors to users.\nAlgorithms should avoid using other forms of providing feedback to users, such as print statements or logging to\nQgsMessageLog, and should always use the feedback object instead. This allows verbose logging for the algorithm,\nand is also thread-safe (which is important, given that algorithms are typically run in a background thread).\n24.7. Using processing algorithms from the console827\n\nQGIS Desktop 3.22 User Guide\nHandling errors\nIf your algorithm encounters an error which prevents it from executing, such as invalid input values or some other\ncondition from which it cannot or should not recover, then you should raise aQgsProcessingException. E.g.:\niffeature['value']<20:\nraiseQgsProcessingException('Invalid input value{}, must be >= 20'.\n,→format(feature['value']))\nTry to avoid raisingQgsProcessingExceptionfor non-fatal errors (e.g. when a feature has a null geometry),\nand instead just report these errors viafeedback.reportError()and skip the feature. This helps make\nyour algorithm “model-friendly”, as it avoids halting the execution of an entire algorithm when a non-fatal error is\nencountered.\nDocumenting your scripts\nAs in the case of models, you can create additional documentation for your scripts, to explain what they do and how\nto use them.\nQgsProcessingAlgorithmprovides thehelpString(),shortHelpString()andhelpUrl()\nfunctions for that purpose. Specify / override these to provide more help to the user.\nshortDescription()is used in the tooltip when hovering over the algorithm in the toolbox.\n24.7.3Pre- and post-execution script hooks\nScripts can also be used as pre- and post-execution hooks that are run before and after an algorithm is run, respectively.\nThis can be used to automate tasks that should be performed whenever an algorithm is executed.\nThe syntax is identical to the syntax explained above, but an additional global variable namedalgis available,\nrepresenting the algorithm that has just been (or is about to be) executed.\nIn theGeneralgroup of the processing options dialog, you will find two entries namedPre-execution scriptandPost-\nexecution scriptwhere the filenames of the scripts to be run in each case can be entered.\n24.8Using processing from the command line\nQGIS comes with a tool calledQGIS Processing Executorwhich allows you to run Processing algorithms\nand models (built-in or provided by plugins) directly from the command line without starting QGIS Desktop itself.\nFrom a command line tool, runqgis_processand you should get:\nQGISProcessingExecutor-3.21.0-Master'Master'(3.21.0-Master)\nUsage:C:\\OSGeo4W\\apps\\qgis-dev\\bin\\qgis_process.exe[--json][--verbose]␣\n,→[command][algorithmidorpathtomodelfile][parameters]\nOptions:\n--jsonOutputresultsasJSONobjects\n--verboseOutputverboselogs\nAvailablecommands:\npluginslistavailableandactiveplugins\npluginsenableenablesaninstalledplugin.Thepluginnamemustbespecified,␣\n,→e.g.\"plugins enable cartography_tools\"\npluginsdisabledisablesaninstalledplugin.Thepluginnamemustbespecified,\n,→e.g.\"plugins disable cartography_tools\"\n(continues on next page)\n828Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\nlistlistallavailableprocessingalgorithms\nhelpshowhelpforanalgorithm.Thealgorithmidorapathtoa␣\n,→modelfilemustbespecified.\nrunrunsanalgorithm.Thealgorithmidorapathtoamodelfile␣\n,→andparametervaluesmustbespecified.\nParametervaluesarespecifiedafter--withPARAMETER=VALUE␣\n,→syntax.\nOrderedlistvaluesforaparametercanbecreatedby␣\n,→specifyingtheparametermultipletimes,\ne.g.--LAYERS=layer1.shp--LAYERS=layer2.shp\nIfrequired,theellipsoidtousefordistanceandarea␣\n,→calculationscanbespecifiedviathe\"--ELLIPSOID=name\"argument.\nIfrequired,anexistingQGISprojecttouseduringthe␣\n,→algorithmexecutioncanbespecifiedviathe\"--PROJECT_PATH=path\"argument.\nNote:Only installed plugins that advertizehasProcessingProvider=yesin theirmetadata.txtfile are\nrecognized and can be activated or loaded by qgis_process tool.\nThe commandlistcan be used to get a list of all available providers and algorithms.\nqgis_processlist\nThe commandhelpcan be used to get further information about commands or algorithms.\nqgis_processhelpqgis:regularpoints\nThe commandruncan be used to run an algorithm or model. Specify the name of the algorithm or a path to a model\nas first parameter.\nqgis_processrunqgis:buffer--INPUT=source.shpDISTANCE=2OUTPUT=buffered.shp\nWhere a parameter accepts a list of values, set the same variable multiple times.\nqgis_processrunnative:mergevectorlayers--LAYERS=input1.shpLAYERS=input2.shp␣\n,→OUTPUT=merged.shp\nWhile running an algorithm a text-based feedback bar is shown, and the operation can be cancelled viaCTRL+C.\nTheruncommand also supports further parameters.\n•--jsonwill format stdout output in a JSON structured way.\n•--ellipsoidwill set the ellipsoid to the specified one.\n•--distance_unitswill use the specified distance units.\n•--area_unitswill use the specified area units.\n•--project_pathwill load the specified project for running the algorithm.\n24.8. Using processing from the command line829\n\nQGIS Desktop 3.22 User Guide\n24.9Writing new Processing algorithms as Python scripts\nThere are two options for writing Processing algorithms using Python.\n•ExtendingQgsProcessingAlgorithm\n•Using the @alg decorator\nWithin QGIS, you can useCreate new scriptin theScriptsmenu at the top of theProcessing Toolboxto open the\nProcessing Script Editorwhere you can write your code. To simplify the task, you can start with a script template by\nusingCreate new script from templatefrom the same menu. This opens a template that extendsQgsProcessin-\ngAlgorithm.\nIf you save the script in thescriptsfolder (the default location) with a.pyextension, the algorithm will become\navailable in theProcessing Toolbox.\n24.9.1Extending QgsProcessingAlgorithm\nThe following code\n1.takes a vector layer as input\n2.counts the number of features\n3.does a buffer operation\n4.creates a raster layer from the result of the buffer operation\n5.returns the buffer layer, raster layer and number of features\n1fromqgis.PyQt.QtCoreimportQCoreApplication\n2fromqgis.coreimport(QgsProcessing,\n3QgsProcessingAlgorithm,\n4QgsProcessingException,\n5QgsProcessingOutputNumber,\n6QgsProcessingParameterDistance,\n7QgsProcessingParameterFeatureSource,\n8QgsProcessingParameterVectorDestination,\n9QgsProcessingParameterRasterDestination)\n10\nfromqgisimportprocessing\n11\n12\n13classExampleProcessingAlgorithm(QgsProcessingAlgorithm):\n14\"\"\"\n15This is an example algorithm that takes a vector layer,\n16creates some new layers and returns some results.\n17\"\"\"\n18\n19\ndeftr(self, string):\n20\"\"\"\n21Returns a translatable string with the self.tr() function.\n22\"\"\"\n23returnQCoreApplication.translate('Processing', string)\n24\n25\ndefcreateInstance(self):\n26\n# Must return a new copy of your algorithm.\n27returnExampleProcessingAlgorithm()\n28\n29\ndefname(self):\n30\n\"\"\"\n31Returns the unique algorithm name.\n32\"\"\"\n33return'bufferrasterextend'\n(continues on next page)\n830Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n34\n35defdisplayName(self):\n36\"\"\"\n37Returns the translated algorithm name.\n38\"\"\"\n39returnself.tr('Buffer and export to raster (extend)')\n40\n41defgroup(self):\n42\n\"\"\"\n43Returns the name of the group this algorithm belongs to.\n44\"\"\"\n45returnself.tr('Example scripts')\n46\n47defgroupId(self):\n48\n\"\"\"\n49Returns the unique ID of the group this algorithm belongs\n50to.\n51\"\"\"\n52return'examplescripts'\n53\n54defshortHelpString(self):\n55\"\"\"\n56Returns a localised short help string for the algorithm.\n57\"\"\"\n58returnself.tr('Example algorithm short description')\n59\n60\ndefinitAlgorithm(self, config=None):\n61\"\"\"\n62Here we define the inputs and outputs of the algorithm.\n63\"\"\"\n64# 'INPUT' is the recommended name for the main input\n65# parameter.\n66self.addParameter(\n67QgsProcessingParameterFeatureSource(\n68'INPUT',\n69self.tr('Input vector layer'),\n70types\n=[QgsProcessing.TypeVectorAnyGeometry]\n71)\n72)\n73self.addParameter(\n74QgsProcessingParameterVectorDestination(\n75'BUFFER_OUTPUT',\n76self.tr('Buffer output'),\n77)\n78)\n79# 'OUTPUT' is the recommended name for the main output\n80# parameter.\n81self.addParameter(\n82QgsProcessingParameterRasterDestination(\n83\n'OUTPUT',\n84\nself.tr('Raster output')\n85)\n86)\n87\nself.addParameter(\n88QgsProcessingParameterDistance(\n89\n'BUFFERDIST',\n90self.tr('BUFFERDIST'),\n91defaultValue\n=1.0,\n92# Make distance units match the INPUT layer units:\n93parentParameterName='INPUT'\n94)\n(continues on next page)\n24.9. Writing new Processing algorithms as Python scripts831\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n95)\n96self.addParameter(\n97QgsProcessingParameterDistance(\n98'CELLSIZE',\n99self.tr('CELLSIZE'),\n100defaultValue=10.0,\n101parentParameterName='INPUT'\n102)\n103)\n104self.addOutput(\n105QgsProcessingOutputNumber(\n106'NUMBEROFFEATURES',\n107self.tr('Number of features processed')\n108)\n109)\n110\n111defprocessAlgorithm(self, parameters, context, feedback):\n112\"\"\"\n113Here is where the processing itself takes place.\n114\"\"\"\n115# First, we get the count of features from the INPUT layer.\n116# This layer is defined as a QgsProcessingParameterFeatureSource\n117# parameter, so it is retrieved by calling\n118# self.parameterAsSource.\n119input_featuresource=self.parameterAsSource(parameters,\n120\n'INPUT',\n121context)\n122numfeatures=input_featuresource.featureCount()\n123\n124# Retrieve the buffer distance and raster cell size numeric\n125# values. Since these are numeric values, they are retrieved\n126# using self.parameterAsDouble.\n127bufferdist=self.parameterAsDouble(parameters,'BUFFERDIST',\n128context)\n129rastercellsize=self.parameterAsDouble(parameters,'CELLSIZE',\n130context)\n131\niffeedback.isCanceled():\n132return{}\n133buffer_result=processing.run(\n134'native:buffer',\n135{\n136# Here we pass on the original parameter values of INPUT\n137# and BUFFER_OUTPUT to the buffer algorithm.\n138'INPUT': parameters['INPUT'],\n139'OUTPUT': parameters['BUFFER_OUTPUT'],\n140'DISTANCE': bufferdist,\n141\n'SEGMENTS':10,\n142'DISSOLVE':True,\n143\n'END_CAP_STYLE':0,\n144'JOIN_STYLE':0,\n145\n'MITER_LIMIT':10\n146},\n147# Because the buffer algorithm is being run as a step in\n148# another larger algorithm, the is_child_algorithm option\n149# should be set to True\n150is_child_algorithm=True,\n151#\n152# It's important to pass on the context and feedback objects to\n153# child algorithms, so that they can properly give feedback to\n154# users and handle cancelation requests.\n155context=context,\n(continues on next page)\n832Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n156feedback=feedback)\n157\n158# Check for cancelation\n159iffeedback.isCanceled():\n160return{}\n161\n162# Run the separate rasterization algorithm using the buffer result\n163# as an input.\n164rasterized_result=processing.run(\n165'qgis:rasterize',\n166{\n167# Here we pass the 'OUTPUT' value from the buffer's result\n168# dictionary off to the rasterize child algorithm.\n169'LAYER': buffer_result['OUTPUT'],\n170\n'EXTENT': buffer_result['OUTPUT'],\n171\n'MAP_UNITS_PER_PIXEL': rastercellsize,\n172# Use the original parameter value.\n173'OUTPUT': parameters['OUTPUT']\n174},\n175is_child_algorithm=True,\n176context=context,\n177feedback=feedback)\n178\n179iffeedback.isCanceled():\n180return{}\n181\n182\n# Return the results\n183return{'OUTPUT': rasterized_result['OUTPUT'],\n184'BUFFER_OUTPUT': buffer_result['OUTPUT'],\n185'NUMBEROFFEATURES': numfeatures}\nProcessing algorithm standard functions:\n•createInstance (mandatory)Must return a new copy of your algorithm. If you change the name of the class,\nmake sure you also update the value returned here to match!\n•name (mandatory)Returns the unique algorithm name, used for identifying the algorithm.\n•displayName (mandatory)Returns the translated algorithm name.\n•groupReturns the name of the group this algorithm belongs to.\n•groupIdReturns the unique ID of the group this algorithm belongs to.\n•shortHelpStringReturns a localised short help string for the algorithm.\n•initAlgorithm (mandatory)Here we define the inputs and outputs of the algorithm.\nINPUTandOUTPUTare recommended names for the main input and main output parameters, respec-\ntively.\nIf a parameter depends on another parameter,parentParameterNameis used to specify this rela-\ntionship (could be the field / band of a layer or the distance units of a layer).\n•processAlgorithm (mandatory)This is where the processing takes place.\nParameters are retrieved using special purpose functions, for instanceparameterAsSourceandpa-\nrameterAsDouble.\nprocessing.runcan be used to run other processing algorithms from a processing algorithm. The\nfirst parameter is the name of the algorithm, the second is a dictionary of the parameters to the algorithm.\nis_child_algorithmis normally set toTruewhen running an algorithm from within another\nalgorithm.contextandfeedbackinform the algorithm about the environment to run in and the\nchannel for communicating with the user (catching cancel request, reporting progress, providing textual\n24.9. Writing new Processing algorithms as Python scripts833\n\nQGIS Desktop 3.22 User Guide\nfeedback). When using the (parent) algorithm’s parameters as parameters to “child” algorithms, the\noriginal parameter values should be used (e.g.parameters['OUTPUT']).\nIt is good practice to check the feedback object for cancelation as much as is sensibly possible! Doing so\nallows for responsive cancelation, instead of forcing users to wait for unwanted processing to occur.\nThe algorithm should return values for all the output parameters it has defined as a dictionary. In this\ncase, that’s the buffer and rasterized output layers, and the count of features processed. The dictionary\nkeys must match the original parameter/output names.\n24.9.2The @alg decorator\nUsing the @alg decorator, you can create your own algorithms by writing the Python code and adding a few extra\nlines to supply additional information needed to make it a proper Processing algorithm. This simplifies the creation\nof algorithms and the specification of inputs and outputs.\nOne important limitation with the decorator approach is that algorithms created in this way will always be added to\na user’s Processing Scripts provider – it is not possible to add these algorithms to a custom provider, e.g. for use in\nplugins.\nThe following code uses the @alg decorator to\n1.use a vector layer as input\n2.count the number of features\n3.do a buffer operation\n4.create a raster layer from the result of the buffer operation\n5.returns the buffer layer, raster layer and number of features\n1fromqgisimportprocessing\n2\nfromqgis.processingimportalg\n3fromqgis.coreimportQgsProject\n4\n5@alg(name='bufferrasteralg', label='Buffer and export to raster (alg)',\n6group='examplescripts', group_label='Example scripts')\n7# 'INPUT' is the recommended name for the main input parameter\n8@alg.input(type=alg.SOURCE, name='INPUT', label='Input vector layer')\n9# 'OUTPUT' is the recommended name for the main output parameter\n10@alg.input(type=alg.RASTER_LAYER_DEST, name='OUTPUT',\n11label='Raster output')\n12\n@alg.input(type=alg.VECTOR_LAYER_DEST, name='BUFFER_OUTPUT',\n13label='Buffer output')\n14@alg.input(type=alg.DISTANCE, name='BUFFERDIST', label='BUFFER DISTANCE',\n15default=1.0)\n16@alg.input(type=alg.DISTANCE, name='CELLSIZE', label='RASTER CELL SIZE',\n17default=10.0)\n18\n@alg.output(type=alg.NUMBER, name='NUMBEROFFEATURES',\n19label='Number of features processed')\n20\n21\ndefbufferrasteralg(instance, parameters, context, feedback, inputs):\n22\"\"\"\n23Description of the algorithm.\n24(If there is no comment here, you will get an error)\n25\"\"\"\n26input_featuresource=instance.parameterAsSource(parameters,\n27\n'INPUT', context)\n28numfeatures=input_featuresource.featureCount()\n29bufferdist=instance.parameterAsDouble(parameters,'BUFFERDIST',\n30context)\n31rastercellsize\n=instance.parameterAsDouble(parameters,'CELLSIZE',\n32context)\n(continues on next page)\n834Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\n33iffeedback.isCanceled():\n34return{}\n35buffer_result=processing.run('native:buffer',\n36{'INPUT': parameters['INPUT'],\n37'OUTPUT': parameters['BUFFER_OUTPUT'],\n38'DISTANCE': bufferdist,\n39'SEGMENTS':10,\n40'DISSOLVE':True,\n41\n'END_CAP_STYLE':0,\n42'JOIN_STYLE':0,\n43'MITER_LIMIT':10\n44},\n45is_child_algorithm=True,\n46context=context,\n47feedback\n=feedback)\n48\niffeedback.isCanceled():\n49return{}\n50rasterized_result=processing.run('qgis:rasterize',\n51{'LAYER': buffer_result['OUTPUT'],\n52'EXTENT': buffer_result['OUTPUT'],\n53'MAP_UNITS_PER_PIXEL': rastercellsize,\n54'OUTPUT': parameters['OUTPUT']\n55},\n56is_child_algorithm=True, context=context,\n57feedback=feedback)\n58\niffeedback.isCanceled():\n59return{}\n60return{'OUTPUT': rasterized_result['OUTPUT'],\n61'BUFFER_OUTPUT': buffer_result['OUTPUT'],\n62'NUMBEROFFEATURES': numfeatures}\nAs you can see, it involves two algorithms (‘native:buffer’ and ‘qgis:rasterize’). The last one (‘qgis:rasterize’) creates a\nraster layer from the buffer layer that was generated by the first one (‘native:buffer’).\nThe part of the code where this processing takes place is not difficult to understand if you have read the previous\nchapter. The first lines, however, need some additional explanation. They provide the information that is needed to\nturn your code into an algorithm that can be run from any of the GUI components, like the toolbox or the graphical\nmodeler.\nThese lines are all calls to the@algdecorator functions that help simplify the coding of the algorithm.\n•The @alg decorator is used to define the name and location of the algorithm in the Toolbox.\n•The @alg.input decorator is used to define the inputs of the algorithm.\n•The @alg.output decorator is used to define the outputs of the algorithm.\n24.9. Writing new Processing algorithms as Python scripts835\n\nQGIS Desktop 3.22 User Guide\n24.9.3Input and output types for Processing Algorithms\nHere is the list of input and output types that are supported in Processing with their corresponding alg decorator\nconstants (thealgfactory.pyfile contains the complete list of alg constants). Sorted on class name.\nInput types\nClassAlg constantDescription\nQgsProcessingParameterAnnota-\ntionLayer\nalg.ANNOTATION_LAYERAn annotation layer\nQgsProcessingParameterAuthCon-\nfig\nalg.AUTH_CFGAllows users to select\nfrom available authenti-\ncation configurations or\ncreate new authentica-\ntion configurations\nQgsProcessingParameterBandalg.BANDA band of a raster layer\nQgsProcessingParameterBooleanalg.BOOLA boolean value\nQgsProcessingParameterColoralg.COLORA color\nQgsProcessingParameterCoordina-\nteOperation\nalg.\nCOORDINATE_OPERATION\nA coordinate operation\n(for  CRS  transforma-\ntions)\nQgsProcessingParameterCrsalg.CRSA Coordinate Reference\nSystem\nQgsProcessingParameterDatabas-\neSchema\nalg.DATABASE_SCHEMAA database schema\nQgsProcessingParameter-\nDatabaseTable\nalg.DATABASE_TABLEA database table\nQgsProcessingParameterDateTimealg.DATETIMEA datetime (or a pure\ndate or time)\nQgsProcessingParameterDistancealg.DISTANCEA double numeric pa-\nrameter for distance val-\nues\nQgsProcessingParameterEnumalg.ENUMAn enumeration, allow-\ning for selection from a\nset of predefined values\nQgsProcessingParameterExpres-\nsion\nalg.EXPRESSIONAn expression\nQgsProcessingParameterExtentalg.EXTENTA spatial extent defined\nby xmin, xmax, ymin,\nymax\nQgsProcessingParameterFieldalg.FIELDA field in the attribute ta-\nble of a vector layer\nQgsProcessingParameterFilealg.FILEA filename of an existing\nfile\nQgsProcessingParameterFileDes-\ntination\nalg.FILE_DESTA filename for a newly\ncreated output file\nQgsProcessingParameterFold-\nerDestination\nalg.FOLDER_DESTA  folder  (destination\nfolder)\nQgsProcessingParameterGeometryalg.GEOMETRYA geometry\nQgsProcessingParameterNumberalg.INTAn integer\nQgsProcessingParameterLayoutalg.LAYOUTA layout\nQgsProcessingParameterLay-\noutItem\nalg.LAYOUT_ITEMA layout item\nQgsProcessingParameterMapLayeralg.MAPLAYERA map layer\nQgsProcessingParameterMapThemealg.MAP_THEMEA project map theme\ncontinues on next page\n836Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nTable 24.3 – continued from previous page\nClassAlg constantDescription\nQgsProcessingParameterMatrixalg.MATRIXA matrix\nQgsProcessingParameterMeshLayeralg.MESH_LAYERA mesh layer\nQgsProcessingParameterMultiple-\nLayers\nalg.MULTILAYERA set of layers\nQgsProcessingParameterNumberalg.NUMBERA numerical value\nQgsProcessingParameterPointalg.POINTA point\nQgsProcessingParameterPoint-\nCloudLayer\nalg.POINT_CLOUD_LAYERA point cloud layer\nQgsProcessingParameterProvider-\nConnection\nalg.\nPROVIDER_CONNECTION\nAn available connection\nfor a database provider\nQgsProcessingParameterRangealg.RANGEA number range\nQgsProcessingParameterRaster-\nLayer\nalg.RASTER_LAYERA raster layer\nQgsProcessingParameterRaster-\nDestination\nalg.RASTER_LAYER_DESTA raster layer\nQgsProcessingParameterScalealg.SCALEA map scale\nQgsProcessingParameterFea-\ntureSink\nalg.SINKA feature sink\nQgsProcessingParameterFeature-\nSource\nalg.SOURCEA feature source\nQgsProcessingParameterStringalg.STRINGA text string\nQgsProcessingParameterVector-\nLayer\nalg.VECTOR_LAYERA vector layer\nQgsProcessingParameterVec-\ntorDestination\nalg.VECTOR_LAYER_DESTA vector layer\nOutput types\nClassAlg constantDescription\nQgsProcessingOutputBooleanalg.BOOLA boolean value\nQgsProcessingOutputNumberalg.DISTANCEA double numeric parameter\nfor distance values\nQgsProcessingOutputFilealg.FILEA filename of an existing file\nQgsProcessingOutputFolderalg.FOLDERA folder\nQgsProcessingOutputHtmlalg.HTMLHTML\nQgsProcessingOutputNumberalg.INTA integer\nQgsProcessingOutputLayerDefini-\ntion\nalg.LAYERDEFA layer definition\nQgsProcessingOutputMapLayeralg.MAPLAYERA map layer\nQgsProcessingOutputMultipleLayersalg.MULTILAYERA set of layers\nQgsProcessingOutputNumberalg.NUMBERA numerical value\nQgsProcessingOutputRasterLayeralg.RASTER_LAYERA raster layer\nQgsProcessingOutputStringalg.STRINGA text string\nQgsProcessingOutputVectorLayeralg.VECTOR_LAYERA vector layer\n24.9. Writing new Processing algorithms as Python scripts837\n\nQGIS Desktop 3.22 User Guide\n24.9.4Handing algorithm output\nWhen you declare an output representing a layer (raster or vector), the algorithm will try to add it to QGIS once it is\nfinished.\n•Raster layer output: QgsProcessingParameterRasterDestination / alg.RASTER_LAYER_DEST.\n•Vector layer output: QgsProcessingParameterVectorDestination / alg.VECTOR_LAYER_DEST.\nSo even if theprocessing.run()method does not add the layers it creates to the user’s current project, the two\noutput layers (buffer and raster buffer) will be loaded, since they are saved to the destinations entered by the user (or\nto temporary destinations if the user does not specify destinations).\nIf a layer is created as output of an algorithm, it should be declared as such. Otherwise, you will not be able to\nproperly use the algorithm in the modeler, since what is declared will not match what the algorithm really creates.\nYou can return strings, numbers and more by specifying them in the result dictionary (as demonstrated for “NUM-\nBEROFFEATURES”), but they should always be explicitly defined as outputs from your algorithm. We encourage\nalgorithms to output as many useful values as possible, since these can be valuable for use in later algorithms when\nyour algorithm is used as part of a model.\n24.9.5Communicating with the user\nIf your algorithm takes a long time to process, it is a good idea to inform the user about the progress. You can use\nfeedback(QgsProcessingFeedback) for this.\nThe progress text and progressbar can be updated using two methods:\nsetProgressText(text)andset-\nProgress(percent).\nYou can provide more information by usingpushCommandInfo(text),pushDebugInfo(text),push-\nInfo(text)andreportError(text).\nIf your script has a problem, the correct way of handling it is to raise aQgsProcessingException. You can\npass a message as an argument to the constructor of the exception. Processing will take care of handling it and\ncommunicating with the user, depending on where the algorithm is being executed from (toolbox, modeler, Python\nconsole, ...)\n24.9.6Documenting your scripts\nYou can document your scripts by overloading thehelpString()andhelpUrl()methods ofQgsPro-\ncessingAlgorithm\n.\n24.9.7Flags\nYoucanoverridetheflags()methodofQgsProcessingAlgorithmtotellQGISmoreaboutyouralgorithm.\nYou can for instance tell QGIS that the script shall be hidden from the modeler, that it can be canceled, that it is not\nthread safe, and more.\nTip:By default, Processing runs algorithms in a separate thread in order to keep QGIS responsive while the pro-\ncessing task runs. If your algorithm is regularly crashing, you are probably using API calls which are not safe to do in\na background thread. Try returning the QgsProcessingAlgorithm.FlagNoThreading flag from your algorithm’s flags()\nmethod to force Processing to run your algorithm in the main thread instead.\n838Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n24.9.8Best practices for writing script algorithms\nHere’s a quick summary of ideas to consider when creating your script algorithms and, especially, if you want to share\nthem with other QGIS users. Following these simple rules will ensure consistency across the different Processing\nelements such as the toolbox, the modeler or the batch processing interface.\n•Do not load resulting layers. Let Processing handle your results and load your layers if needed.\n•Always declare the outputs your algorithm creates.\n•Do not show message boxes or use any GUI element from the script. If you want to communicate with the user,\nuse the methods of the feedback object (QgsProcessingFeedback) or throw aQgsProcessingEx-\nception.\nThere are already many processing algorithms available in QGIS. You can find code onhttps://github.com/qgis/\nQGIS/blob/release-3_22/python/plugins/processing/algs/qgis.\n24.10Configuring external applications\nThe processing framework can be extended using additional applications. Algorithms that rely on external applications\nare managed by their own algorithm providers. Additional providers can be found as separate plugins, and installed\nusing the QGIS Plugin Manager.\nThis section will show you how to configure the Processing framework to include these additional applications, and it\nwill explain some particular features of the algorithms based on them. Once you have correctly configured the system,\nyou will be able to execute external algorithms from any component like the toolbox or the graphical modeler, just\nlike you do with any other algorithm.\nBy default, algorithms that rely on an external application not shipped with QGIS are not enabled. You can enable\nthem in the Processing settings dialog if they are installed on your system.\n24.10.1A note for Windows users\nIf you are not an advanced user and you are running QGIS on Windows, you might not be interested in reading the\nrest of this chapter. Make sure you install QGIS in your system using the standalone installer. That will automatically\ninstall SAGA and GRASS in your system and configure them so they can be run from QGIS. All the algorithms from\nthese providers will be ready to be run without needing any further configuration. If installing with the OSGeo4W\napplication, make sure that you also select SAGA and GRASS for installation.\n24.10.2A note on file formats\nWhen using external software, opening a file in QGIS does not mean that it can be opened and processed in that other\nsoftware. In most cases, other software can read what you have opened in QGIS, but in some cases, that might not\nbe true. When using databases or uncommon file formats, whether for raster or vector layers, problems might arise.\nIf that happens, try to use well-known file formats that you are sure are understood by both programs, and check the\nconsole output (in the log panel) to find out what is going wrong.\nYou might for instance get trouble and not be able to complete your work if you call an external algorithm with a\nGRASS raster layers as input. For this reason, such layers will not appear as available to algorithms.\nYou should, however, not have problems with vector layers, since QGIS automatically converts from the original file\nformat to one accepted by the external application before passing the layer to it. This adds extra processing time,\nwhich might be significant for large layers, so do not be surprised if it takes more time to process a layer from a DB\nconnection than a layer from a Shapefile format dataset of similar size.\nProviders not using external applications can process any layer that you can open in QGIS, since they open it for\nanalysis through QGIS.\n24.10. Configuring external applications839\n\nQGIS Desktop 3.22 User Guide\nAll raster and vector output formats produced by QGIS can be used as input layers. Some providers do not support\ncertain formats, but all can export to common formats that can later be transformed by QGIS automatically. As for\ninput layers, if a conversion is needed, that might increase the processing time.\n24.10.3A note on vector layer selections\nExternal applications may also be made aware of the selections that exist in vector layers within QGIS. However,\nthat requires rewriting all input vector layers, just as if they were originally in a format not supported by the external\napplication. Only when no selection exists, or theUse only selected featuresoption is not enabled in the processing\ngeneral configuration, can a layer be directly passed to an external application.\nIn other cases, exporting only selected features is needed, which causes longer execution times.\n24.10.4SAGA\nSAGA algorithms can be run from QGIS if SAGA is included with the QGIS installation.\nIf you are running Windows, both the stand-alone installer and the OSGeo4W installer include SAGA.\nAbout SAGA grid system limitations\nMost SAGA algorithms that require several input raster layers require them to have the same grid system. That is,\nthey must cover the same geographic area and have the same cell size, so their corresponding grids match. When\ncalling SAGA algorithms from QGIS, you can use any layer, regardless of its cell size and extent. When multiple\nraster layers are used as input for a SAGA algorithm, QGIS resamples them to a common grid system and then passes\nthem to SAGA (unless the SAGA algorithm can operate with layers from different grid systems).\nThe definition of that common grid system is controlled by the user, and you will find several parameters in the SAGA\ngroup of the settings window to do so. There are two ways of setting the target grid system:\n•Setting it manually. You define the extent by setting the values of the following parameters:\n–Resampling min X\n–Resampling max X\n–Resampling min Y\n–Resampling max Y\n–Resampling cellsize\nNotice that QGIS will resample input layers to that extent, even if they do not overlap with it.\n•Setting it automatically from input layers. To select this option, just check theUse min covering grid system\nfor resamplingoption. All the other settings will be ignored and the minimum extent that covers all the input\nlayers will be used. The cell size of the target layer is the maximum of all cell sizes of the input layers.\nFor algorithms that do not use multiple raster layers, or for those that do not need a unique input grid system, no\nresampling is performed before calling SAGA, and those parameters are not used.\n840Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nLimitations for multi-band layers\nUnlike QGIS, SAGA has no support for multi-band layers. If you want to use a multiband layer (such as an RGB or\nmultispectral image), you first have to split it into single-banded images. To do so, you can use the ‘SAGA/Grid\n- Tools/Split RGB image’ algorithm (which creates three images from an RGB image) or the ‘SAGA/Grid -\nTools/Extract band’ algorithm (to extract a single band).\nLimitations in cell size\nSAGA assumes that raster layers have the same cell size in the X and Y axis. If you are working with a layer with\ndifferent values for horizontal and vertical cell size, you might get unexpected results. In this case, a warning will be\nadded to the processing log, indicating that an input layer might not be suitable to be processed by SAGA.\nLogging\nWhen QGIS calls SAGA, it does so using its command-line interface, thus passing a set of commands to perform\nall the required operations. SAGA shows its progress by writing information to the console, which includes the\npercentage of processing already done, along with additional content. This output is filtered and used to update the\nprogress bar while the algorithm is running.\nBoth the commands sent by QGIS and the additional information printed by SAGA can be logged along with other\nprocessing log messages, and you might find them useful to track what is going on when QGIS runs a SAGA algo-\nrithm. You will find two settings, namelyLog console outputandLog execution commands, to activate that logging\nmechanism.\nMost other providers that use external applications and call them through the command-line have similar options, so\nyou will find them as well in other places in the processing settings list.\n24.10.5R scripts\nTo enable R in Processing you need to install theProcessing R Providerplugin and configure R for QGIS.\nConfiguration is done inProvider►Rin theProcessingtab ofSettings►Options.\nDepending on your operating system, you may have to useR folderto specify where your R binaries are located.\nNote:OnWindowsthe R executable file is normally in a folder (R-<version>) underC:\\Program Files\\\nR\\. Specify the folder andNOTthe binary!\nOnLinuxyou just have to make sure that the R folder is in the PATH environment variable. IfRin a terminal\nwindow starts R, then you are ready to go.\nAfter installing theProcessing R Providerplugin, you will find some example scripts in theProcessing Toolbox:\n•Scatterplotruns an R function that produces a scatter plot from two numerical fields of the provided vector\nlayer.\n•test_sfdoes some operations that depend on thesfpackage and can be used to check if the R packagesf\nis installed. If the package is not installed, R will try to install it (and all the packages it depends on) for\nyou, using thePackage repositoryspecified inProvider►Rin the Processing options. The default ishttps:\n//cran.r-project.org/\n. Installing may take some time...\n•test_spcan be used to check if the R packagespis installed. If the package is not installed, R will try to install\nit for you.\n24.10. Configuring external applications841\n\nQGIS Desktop 3.22 User Guide\nIf you have R configured correctly for QGIS, you should be able to run these scripts.\n842Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nAdding R scripts from the QGIS collection\nR integration in QGIS is different from that of SAGA in that there is not a predefined set of algorithms you can run\n(except for some example script that come with theProcessing R Providerplugin).\nA set of example R scripts is available in the QGIS Repository. Perform the following steps to load and enable them\nusing theQGIS Resource Sharingplugin.\n1.Add theQGIS Resource Sharingplugin (you may have to enableShow also experimental pluginsin the Plugin\nManagerSettings)\n2.Open it (Plugins –> Resource Sharing –> Resource Sharing)\n3.Choose theSettingstab\n4.ClickReload repositories\n5.Choose theAlltab\n6.SelectQGIS R script collectionin the list and click on theInstallbutton\n7.The collection should now be listed in theInstalledtab\n8.Close the plugin\n9.Open theProcessing Toolbox, and if everything is OK, the example scripts will be present under R, in various\ngroups (only some of the groups are expanded in the screenshot below).\n24.10. Configuring external applications843\n\nQGIS Desktop 3.22 User Guide\nFig. 24.33: TheProcessing Toolboxwith some R scripts shown\n844Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nThe scripts at the top are the example scripts from theProcessing R Providerplugin.\n10.If, for some reason, the scripts are not available in theProcessing Toolbox, you can try to:\n1.Open the Processing settings (Settings►Options►Processingtab)\n2.Go toProviders►R►R scripts folder\n•On Ubuntu, set the path to (or, better, include in the path):\n/home/<user>/.local/share/QGIS/QGIS3/profiles/default/resource_sharing/repositories/github.com/qgis/QGIS-\nResources/collections/rscripts\n•On Windows, set the path to (or, better, include in the path):\nC:\\Users\\<user>\\AppData\\Roaming\\QGIS\\QGIS3\\profiles\\default\\resource_sharing\\repositories\\github.com\\qgis\\QGIS-\nResources\\collections\\rscripts\nToedit, double-click. Youcanthenchoosetojustpaste/typethepath, oryoucannavigatetothedirectory\nby using the...button and press theAddbutton in the dialog that opens. It is possible to provide several\ndirectories here. They will be separated by a semicolon (“;”).\nIf you would like to get all the R scrips from the QGIS 2 on-line collection, you can selectQGIS R script collection\n(from QGIS 2)instead ofQGIS R script collection. You will probably find that scripts that depend on vector data input\nor output will not work.\nCreating R scripts\nYou can write scripts and call R commands, as you would do from R. This section shows you the syntax for using R\ncommands in QGIS, and how to use QGIS objects (layers, tables) in them.\nTo add an algorithm that calls an R function (or a more complex R script that you have developed and you would like\nto have available from QGIS), you have to create a script file that performs the R commands.\nR script files have the extension.rsx, and creating them is pretty easy if you just have a basic knowledge of R syntax\nand R scripting. They should be stored in the R scripts folder. You can specify the folder (R scripts folder) in theR\nsettings group in Processing settings dialog).\n24.10. Configuring external applications845\n\nQGIS Desktop 3.22 User Guide\nLet’s have a look at a very simple script file, which calls the R methodspsampleto create a random grid within the\nboundary of the polygons in a given polygon layer. This method belongs to themaptoolspackage. Since almost\nall the algorithms that you might like to incorporate into QGIS will use or generate spatial data, knowledge of spatial\npackages likemaptoolsandsp/sf, is very useful.\n##Random points within layer extent=name\n##Point pattern analysis=group\n##Vector_layer=vector\n##Number_of_points=number 10\n##Output=output vector\nlibrary(sp)\nspatpoly=as(Vector_layer,\"Spatial\")\npts=spsample(spatpoly,Number_of_points,type=\"random\")\nspdf=SpatialPointsDataFrame(pts,as.data.frame(pts))\nOutput=st_as_sf(spdf)\nThe first lines, which start with a double Python comment sign (##), define the display name and group of the script,\nand tell QGIS about its inputs and outputs.\nNote:To find out more about how to write your own R scripts, have a look at the R Intro section in the training\nmanual and consult theQGIS R Syntaxsection.\nWhen you declare an input parameter, QGIS uses that information for two things: creating the user interface to ask\nthe user for the value of that parameter, and creating a corresponding R variable that can be used as R function input.\nIn the above example, we have declared an input of typevector, namedVector_layer. When executing the\nalgorithm, QGIS will open the layer selected by the user and store it in a variable namedVector_layer. So, the\nname of a parameter is the name of the variable that you use in R for accessing the value of that parameter (you\nshould therefore avoid using reserved R words as parameter names).\nSpatial parameters such as vector and raster layers are read using thest_read()(orreadOGR) andbrick()\n(orreadGDAL) commands (you do not have to worry about adding those commands to your description file – QGIS\nwill do it), and they are stored assf(orSpatial*DataFrame) objects.\nTable fields are stored as strings containing the name of the selected field.\nVector files can be read using thereadOGR()command instead ofst_read()by specifying\n##load_vector_using_rgdal.  This will produce aSpatial*DataFrameobject instead of an\nsfobject.\nRaster  files  can  be  read  using  thereadGDAL()command  instead  ofbrick()by  specifying\n##load_raster_using_rgdal.\nIf you are an advanced user and do not want QGIS to create the object for the layer, you can use\n##pass_filenamesto indicate that you prefer a string with the filename. In this case, it is up to you to open the\nfile before performing any operation on the data it contains.\nWith the above information, it is possible to understand the first lines of the R script (the first line not starting with a\nPython comment character).\nlibrary(sp)\nspatpoly=as(Vector_layer,\"Spatial\")\npts\n=spsample(polyg,numpoints,type=\"random\")\nThespsamplefunction is provided by thesplibrary, so the first thing we do is to load that library. The variable\nVector_layercontains ansfobject. Since we are going to use a function (spsample) from thesplibrary, we\nmust convert thesfobject to aSpatialPolygonsDataFrameobject using theasfunction.\nThen we call thespsamplefunction with this object and thenumpointsinput parameter (which specifies the\nnumber of points to generate).\nSince we have declared a vector output namedOutput, we have to create a variable namedOutputcontaining an\nsfobject.\n846Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\nWe do this in two steps. First we create aSpatialPolygonsDataFrameobject from the result of the function,\nusing theSpatialPointsDataFramefunction, and then we convert that object to ansfobject using thest_as_sf\nfunction (of thesflibrary).\nYou can use whatever names you like for your intermediate variables. Just make sure that the variable storing your\nfinal result has the defined name (in this caseOutput), and that it contains a suitable value (ansfobject for vector\nlayer output).\nIn this case, the result obtained from thespsamplemethod had to be converted explicitly into ansfobject via a\nSpatialPointsDataFrameobject, since it is itself an object of classppp, which can not be returned to QGIS.\nIf your algorithm generates raster layers, the way they are saved will depend on whether or not you have used the\n##dontuserasterpackageoption. If you have used it, layers are saved using thewriteGDAL()method. If\nnot, thewriteRaster()method from therasterpackage will be used.\nIf you have used the##pass_filenamesoption, outputs are generated using therasterpackage (withwrit-\neRaster()).\nIf your algorithm does not generate a layer, but a text result in the console instead, you have to indicate that you want\nthe console to be shown once the execution is finished. To do so, just start the command lines that produce the results\nyou want to print with the>(‘greater than’) sign. Only output from lines prefixed with>are shown. For instance,\nhere is the description file of an algorithm that performs a normality test on a given field (column) of the attributes\nof a vector layer:\n##layer=vector\n##field=field layer\n##nortest=group\nlibrary(nortest)\n>lillie.test(layer[[field]])\nThe output of the last line is printed, but the output of the first is not (and neither are the outputs from other command\nlines added automatically by QGIS).\nIf your algorithm creates any kind of graphics (using theplot()method), add the following line\n(output_plots_to_htmlused to beshowplots):\n##output_plots_to_html\nThis will cause QGIS to redirect all R graphical outputs to a temporary file, which will be opened once R execution\nhas finished.\nBoth graphics and console results will be available through the processing results manager.\nFor more information, please check the R scripts in the official QGIS collection (you download and install them using\ntheQGIS Resource Sharingplugin, as explained elsewhere). Most of them are rather simple and will greatly help you\nunderstand how to create your own scripts.\nNote:Thesf,rgdalandrasterlibraries are loaded by default, so you do not have to add the correspond-\ninglibrary()commands. However, other libraries that you might need have to be explicitly loaded by typing:\nlibrary(ggplot2)(to load theggplot2library). If the package is not already installed on your machine,\nProcessing will try to download and install it. In this way the package will also become available in R Standalone.Be\nawarethat if the package has to be downloaded, the script may take a long time to run the first time.\n24.10. Configuring external applications847\n\nQGIS Desktop 3.22 User Guide\n24.10.6R libraries\nThe R scriptsp_testtries to load the R packagesspandraster.\nR libraries installed when running sf_test\nThe R scriptsf_testtries to loadsfandraster. If these two packages are not installed, R may try to load and\ninstall them (and all the libraries that they depend on).\nThe  following  R  libraries  end  up  in~/.local/share/QGIS/QGIS3/profiles/default/\nprocessing/rscriptsaftersf_testhas been run from the Processing Toolbox on Ubuntu with\nversion 2.0 of theProcessing R Providerplugin and a fresh install ofR3.4.4 (aptpackager-base-coreonly):\nabind, askpass, assertthat, backports, base64enc, BH, bit, bit64, blob, brew,␣\n,→callr, classInt, cli, colorspace, covr, crayon, crosstalk, curl, DBI, deldir,\ndesc, dichromat, digest, dplyr, e1071, ellipsis, evaluate, fansi, farver, fastmap,␣\n,→gdtools, ggplot2, glue, goftest, gridExtra, gtable, highr, hms,\nhtmltools, htmlwidgets, httpuv, httr, jsonlite, knitr, labeling, later, lazyeval,␣\n,→leafem, leaflet, leaflet.providers, leafpop, leafsync, lifecycle, lwgeom,\nmagrittr, maps, mapview, markdown, memoise, microbenchmark, mime, munsell, odbc,␣\n,→openssl, pillar, pkgbuild, pkgconfig, pkgload, plogr, plyr, png, polyclip,\npraise, prettyunits, processx, promises, ps, purrr, R6, raster, RColorBrewer, Rcpp,\n,→reshape2, rex, rgeos, rlang, rmarkdown, RPostgres, RPostgreSQL,\nrprojroot, RSQLite, rstudioapi, satellite, scales, sf, shiny, sourcetools, sp,␣\n,→spatstat, spatstat.data, spatstat.utils, stars, stringi, stringr, svglite,\nsys, systemfonts, tensor, testthat, tibble, tidyselect, tinytex, units, utf8, uuid,\n,→vctrs, viridis, viridisLite, webshot, withr, xfun, XML, xtable\n24.10.7GRASS\nConfiguring GRASS is not much different from configuring SAGA. First, the path to the GRASS folder has to be\ndefined, but only if you are running Windows.\nBy default, the Processing framework tries to configure its GRASS connector to use the GRASS distribution that\nships along with QGIS. This should work without problems for most systems, but if you experience problems, you\nmight have to configure the GRASS connector manually. Also, if you want to use a different GRASS installation, you\ncan change the setting to point to the folder where the other version is installed. GRASS 7 is needed for algorithms\nto work correctly.\nIf you are running Linux, you just have to make sure that GRASS is correctly installed, and that it can be run without\nproblem from a terminal window.\nGRASS algorithms use a region for calculations. This region can be defined manually using values similar to the ones\nfound in the SAGA configuration, or automatically, taking the minimum extent that covers all the input layers used\nto execute the algorithm each time. If the latter approach is the behavior you prefer, just check theUse min covering\nregionoption in the GRASS configuration parameters.\n24.10.8LAStools\nTo useLAStoolsin QGIS, you need to download and install LAStools on your computer and install the LAStools\nplugin (available from the official repository) in QGIS.\nOn Linux platforms, you will need\nWineto be able to run some of the tools.\nLAStools is activated and configured in the Processing options (Settings►Options,Processingtab,Providers►LAS-\ntools), where you can specify the location of LAStools (LAStools folder) and Wine (Wine folder). On Ubuntu, the\ndefault Wine folder is/usr/bin.\n848Chapter 24. QGIS processing framework\n\nQGIS Desktop 3.22 User Guide\n24.10.9OTB Applications\nOTB applications are fully supported within the QGIS Processing framework.\nOTB(Orfeo ToolBox) is an image processing library for remote sensing data. It also provides applications that provide\nimage processing functionalities. The list of applications and their documentation are available inOTB CookBook\nNote:Note that OTB is not distributed with QGIS and needs to be installed separately. Binary packages for OTB\ncan be found on thedownload page.\nTo configure QGIS processing to find the OTB library:\n1.Open the processing settings:Settings►Options►Processing(left panel)*\n2.You can see OTB under “Providers”:\n1.Expand theOTBtab\n2.Tick theActivateoption\n3.Set theOTB folder. This is the location of your OTB installation.\n4.Set  theOTB  application  folder.This  is  the  location  of  your  OTB  applications  (\n<PATH_TO_OTB_INSTALLATION>/lib/otb/applications)\n5.Click “ok” to save the settings and close the dialog.\nIf settings are correct, OTB algorithms will be available in theProcessing Toolbox.\nDocumentation of OTB settings available in QGIS Processing\n•Activate: This is a checkbox to activate or deactivate the OTB provider. An invalid OTB setting will uncheck\nthis when saved.\n•OTB folder: This is the directory where OTB is available.\n•OTB application folder: This is the location(s) of OTB applications.\nMultiple paths are allowed.\n•Logger level(optional): Level of logger to use by OTB applications.\nThe level of logging controls the amount of detail printed during algorithm execution. Possible values for logger\nlevel areINFO,WARNING,CRITICAL,DEBUG. This value isINFOby default. This is an advanced user\nconfiguration.\n•Maximum RAM to use(optional): by default, OTB applications use all available system RAM.\nYou can, however, instruct OTB to use a specific amount of RAM (in MB) using this option. A value of 256\nis ignored by the OTB processing provider. This is an advanced user configuration.\n•Geoid file(optional): Path to the geoid file.\nThis option sets the value of the elev.dem.geoid and elev.geoid parameters in OTB applications. Setting this\nvalue globally enables users to share it across multiple processing algorithms. Empty by default.\n•SRTM tiles folder(optional): Directory where SRTM tiles are available.\nSRTM data can be stored locally to avoid downloading of files during processing. This option sets the value of\nelev.dem.path and elev.dem parameters in OTB applications. Setting this value globally enables users to share\nit across multiple processing algorithms. Empty by default.\n24.10. Configuring external applications849\n\nQGIS Desktop 3.22 User Guide\nCompatibility between QGIS and OTB versions\nAll OTB versions (from OTB 6.6.1) are compatible with the latest QGIS version.\nTroubleshoot\nIf you have issues with OTB applications in QGIS Processing, please open an issue on theOTB bug tracker, using\ntheqgislabel.\nAdditional information about OTB and QGIS can be foundhere\n850Chapter 24. QGIS processing framework\n\nCHAPTER\nTWENTYFIVE\nPROCESSING PROVIDERS AND ALGORITHMS\nProcessing algorithms and their parameters (as presented in the user interface) are documented here.\n25.1QGIS algorithm provider\nQGIS algorithm provider implements various analysis and geoprocessing operations using mostly only QGIS API. So\nalmost all algorithms from this provider will work “out of the box” without any additional configuration.\nThis provider incorporates some algorithms from plugins and also adds its own algorithms.\n25.1.1Cartography\nAlign points to features\nCalculates the rotation required to align point features with their nearest feature from another reference layer. A new\nfield is added to the output layer which is filled with the angle (in degrees, clockwise) to the nearest reference feature.\nOptionally, the output layer’s symbology can be set to automatically use the calculated rotation field to rotate marker\nsymbols. If desired, a maximum distance to use when aligning points can be set, to avoid aligning isolated points to\ndistant features.\nHint:This algorithm is designed for use cases like aligning building point symbols to follow the nearest road\ndirection.\nAllowsfeatures in-place modification\n851\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Point features to calculate the rotation for\nReference layerREFER-\nENCE_LAYER\n[vector: any]Layer to find the closest feature from for ro-\ntation calculation\nMaximum   dis-\ntance to consider\nOptional\nMAX_DISTANCE[number]\nDefault: Not set\nIf no reference feature is found within this\ndistance, no rotation is assigned to the point\nfeature.\nAngle field nameFIELD_NAME[string]\nDefault: ‘rotation’\nField in which to store the rotation value.\nAutomatically ap-\nply symbology\nAP-\nPLY_SYMBOLOGY\n[boolean]\nDefault: True\nRotates the symbol marker of the features\nusing the angle field value\nAligned layerOUTPUT[vector: point]\nDefault:[Save\nto  temporary\nfile]\nSpecify the rotated output vector layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nAligned layerOUTPUT[vector: point]The point layer appended with a rotation\nfield. If loaded to QGIS, it is applied by de-\nfault the input layer symbology, with a data-\ndefined rotation of its marker symbol.\nPython code\nAlgorithm ID:native:angletonearest\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCombine style databases\nCombines multiple QGIS style databases into a single style database. If items of the same type with the same name\nexist in different source databases these will be renamed to have unique names in the output combined database.\nSee also:\nCreate style database from project\n852Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput databasesINPUT[file] [list]Files containing QGIS style items\nObjects to com-\nbine\nOBJECTS[enumeration] [list]Types of style items in the input databases\nyou would like to put in the new database.\nThese can be:\n•0 —Symbols\n•1 —Color ramps\n•2 —Text formats\n•3 —Label settings\nOutputstyle\ndatabase\nOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nOutput.XMLfile combining the selected\nstyle items. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nColor ramp countCOLORRAMPS[number]\nLabel   settings\ncount\nLABELSETTINGS[number]\nOutputstyle\ndatabase\nOUTPUT[file]Output.XMLfile combining the selected\nstyle items\nSymbol countSYMBOLS[number]\nText format countTEXTFORMATS[number]\nPython code\nAlgorithm ID:native:combinestyles\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate categorized renderer from styles\nSets a vector layer’s renderer to a categorized renderer using matching symbols from a style database. If no style file\nis specified, symbols from the user’s currentsymbol libraryare used instead.\nA specified expression or field is used to create categories for the renderer. Each category is individually matched\nto the symbols which exist within the specified QGIS XML style database. Whenever a matching symbol name is\nfound, the category’s symbol will be set to this matched symbol.\nIf desired, outputs can also be tables containing lists of the categories which could not be matched to symbols, and\nsymbols which were not matched to categories.\n25.1. QGIS algorithm provider853\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer to apply a categorized style to\nCategorize  using\nexpression\nFIELD[expression]Field or expression to categorize the fea-\ntures\nStyle   database\n(leave blank to use\nsaved symbols)\nSTYLE[file]File (.XML) containing the symbols to ap-\nplytotheinputlayercategories. Thefilecan\nbe obtained from the Style ManagerShare\nsymbolstool. If no file is specified, QGIS\nlocal symbols library is used.\nUse case-sensitive\nmatch to symbol\nnames\nCASE_SENSITIVE[boolean]\nDefault: False\nIf True (checked), applies a case sensi-\ntive comparison between the categories and\nsymbols names\nIgnorenon-\nalphanumeric\ncharacters  while\nmatching\nTOLERANT[boolean]\nDefault: False\nIf True (checked), non-alphanumeric char-\nacters in the categories and symbols names\nwill be ignored, allowing greater tolerance\nduring the match.\nNon-matching\ncategories\nOptional\nNON_MATCHING_CATEGORIES[table]\nDefault:[Skip\noutput]\nOutput table for categories which do not\nmatch any symbol in the database. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nNon-matching\nsymbol names\nOptional\nNON_MATCHING_SYMBOLS[table]\nDefault:[Skip\noutput]\nOutput table for symbols from the provided\nstyle database which do not match any cat-\negory. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nNon-matching\ncategories\nNON_MATCHING_CATEGORIES[table]Lists categories which could not be matched\nto any symbol in the provided style database\nNon-matching\nsymbol names\nNON_MATCHING_SYMBOLS[table]Lists symbols from the provided style\ndatabase which could not match any cate-\ngory\nCategorized layerOUTPUT[same as input]The input vector layer with the categorized\nstyle applied. No new layer is output.\n854Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:categorizeusingstyle\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate style database from project\nExtracts all style objects (symbols, color ramps, text formats and label settings) from a QGIS project.\nThe extracted symbols are saved to a QGIS style database (XMLformat), which can be managed and imported via\ntheStyle Managerdialog.\nSee also:\nCombine style databases\nParameters\nLabelNameTypeDescription\nInput    project\n(leave blank to use\ncurrent)\nOptional\nINPUT[file]A QGIS project file to extract the style items\nfrom\nObjects to extractOBJECTS[enumeration] [list]Types of style items in the input project you\nwouldliketoputinthenewdatabase. These\ncan be:\n•0 —Symbols\n•1 —Color ramps\n•2 —Text formats\n•3 —Label settings\nOutputstyle\ndatabase\nOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output.XMLfile for the se-\nlected style items. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nColor ramp countCOLORRAMPS[number]Number of color ramps\nLabel   settings\ncount\nLABELSETTINGS[number]Number of label settings\nOutputstyle\ndatabase\nOUTPUT[file]Output.XMLfile for the selected style\nitems\nSymbol countSYMBOLS[number]Number of symbols\nText format countTEXTFORMATS[number]Number of text formats\n25.1. QGIS algorithm provider855\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:stylefromproject\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport atlas layout as image\nExports the atlas of a print layout as image files (e.g. PNG or JPEG images).\nIf a coverage layer is set, the selected layout’s atlas settings exposed in this algorithm will be overwritten. In this case,\nan empty filter or sort by expression will turn those settings off.\nParameters\nBasic parameters\nLabelNameTypeDescription\nAtlas layoutLAYOUT[layout]Layout to export\nCoverage layer\nOptional\nCOVER-\nAGE_LAYER\n[vector: any]Layer to use to generate the atlas\nFilter expressionFIL-\nTER_EXPRESSION\n[expression]Expression to use to filter out atlas features\nSort expression\nOptional\nSORTBY_EXPRESSION[expression]Expression to use to sort the atlas features\nReverse sort order\nOptional\nSORTBY_REVERSE[boolean]Determines if sorting should be inverted.\nUsed when a sort expression is provided.\nOutput  filename\nexpression\nFILE-\nNAME_EXPRESSION\n[expression]\nDefault:‘out-\nput_’||@atlas_featurenumber\nExpression for use to generate filenames\nOutput folderFOLDER[folder]Destination folder where the images will be\ngenerated\n856Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nMap layers to as-\nsign to unlocked\nmap item(s)\nOptional\nLAYERS[enumeration]\n[layer]\nLayers to display in the map item(s) whose\ncontents are not locked\nImage formatEXTENSION[list]\nDefault: png\nFile format of the generated output(s). The\nlist of available formats varies depending on\nOS and installed drivers.\nDPI\nOptional\nDPI\nDefault: Not set\n[number]DPI of the output file(s). If not set, the\nvalue in the print layout settings will be\nused.\nGenerate  world\nfile\nGEOREFERENCE[boolean]\nDefault: True\nDetermines if a world file should be gener-\nated\nExportRDFmeta-\ndata\nIN-\nCLUDE_METADATA\n[boolean]\nDefault: True\nDetermines if RDF metadata (title, author,\n...) should be generated\nEnable antialias-\ning\nANTIALIAS[boolean]\nDefault: True\nDetermines if antialiasing should be en-\nabled\nOutputs\nLabelNameTypeDescription\nImage fileOUTPUT[file]Image files generated by the atlas layout\nPython code\nAlgorithm ID:native:atlaslayouttoimage\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport atlas layout as PDF\nExports the atlas of a print layout as a PDF file(s).\nIf a coverage layer is set, the selected layout’s atlas settings exposed in this algorithm will be overwritten. In this case,\nan empty filter or sort by expression will turn those settings off.\n25.1. QGIS algorithm provider857\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nAtlas layoutLAYOUT[layout]Layout to export\nCoverage layer\nOptional\nCOVER-\nAGE_LAYER\n[vector: any]Layer to use to generate the atlas\nFilter expressionFIL-\nTER_EXPRESSION\n[expression]Expression to use to filter out atlas features\nSort expression\nOptional\nSORTBY_EXPRESSION[expression]Expression to use to sort the atlas features\nReverse sort order\nOptional\nSORTBY_REVERSE[boolean]Determines if sorting should be inverted.\nUsed when a sort expression is provided.\nAdvanced parameters\nLabelNameTypeDescription\nMap layers to as-\nsign to unlocked\nmap item(s)\nOptional\nLAYERS[enumeration]\n[layer]\nLayers to display in the map item(s) whose\ncontents are not locked\nDPI\nOptional\nDPI\nDefault: Not set\n[number]DPI of the output file(s). If not set, the\nvalue in the print layout settings will be\nused.\nAlways export as\nvectors\nFORCE_VECTOR[boolean]\nDefault: False\nDetermines if vectorial data should be left\nas vectors\nAppend georefer-\nence information\nGEOREFERENCE[boolean]\nDefault: True\nDetermines if a world file should be gener-\nated\nExportRDFmeta-\ndata\nIN-\nCLUDE_METADATA\n[boolean]\nDefault: True\nDetermines if RDF metadata (title, author,\n...) should be generated\nDisabletiled\nraster  layer  ex-\nports\nDISABLE_TILED[boolean]\nDefault: False\nDetermines if raster should be tiled\nSimplify  geome-\ntries  to  reduce\noutput file size\nSIMPLIFY[boolean]\nDefault: True\nDetermines if geometries should be simpli-\nfied to reduce output file size\nText exportTEXT_FORMAT[list]\nDefault: 0\nDetermines if text should be exported as\npath or text objects. Possible options are:\n•0 - Always export text as paths (rec-\nommended)\n•1 - Always export texts as text objects\nPDF fileOUTPUT[file]\nDefault:  [Save to\ntemporary file]\nName (including path) of the output file.\nOne of:\n•Save to a Temporary File\n•Save to File...\n858Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nPDF fileOUTPUT[file]PDF file corresponding to the exported atlas\nlayout\nPython code\nAlgorithm ID:native:atlaslayouttopdf\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport print layout as image\nExports a print layout as an image file (e.g. PNG or JPEG images)\nParameters\nBasic parameters\nLabelNameTypeDescription\nPrint layoutLAYOUT[layout]Layout to export\nImage fileOUTPUT[file]\nDefault:  [Save to\ntemporary file]\nName (including path) of the output file.\nOne of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nMap layers to as-\nsign to unlocked\nmap item(s)\nOptional\nLAYERS[enumeration]\n[layer]\nLayers to display in the map item(s) whose\ncontents are not locked\nDPI\nOptional\nDPI\nDefault: Not set\n[number]DPI of the output file(s). If not set, the\nvalue in the print layout settings will be\nused.\nGenerate  world\nfile\nGEOREFERENCE[boolean]\nDefault: True\nDetermines if a world file should be gener-\nated\nExportRDFmeta-\ndata\nIN-\nCLUDE_METADATA\n[boolean]\nDefault: True\nDetermines if RDF metadata (title, author,\n...) should be generated\nEnable antialias-\ning\nANTIALIAS[boolean]\nDefault: True\nDetermines if antialiasing should be en-\nabled\n25.1. QGIS algorithm provider859\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nImage fileOUTPUT[file]Image file corresponding to the exported\nprint layout\nPython code\nAlgorithm ID:native:printlayouttoimage\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport print layout as PDF\nExports a print layout as a PDF file.\nParameters\nBasic parameters\nLabelNameTypeDescription\nPrint LayoutLAYOUT[layout]Layout to export\nPDF fileOUTPUT[file]\nDefault:  [Save to\ntemporary file]\nName (including path) of the output file.\nOne of:\n•Save to a Temporary File\n•Save to File...\n860Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nMap layers to as-\nsign to unlocked\nmap item(s)\nOptional\nLAYERS[enumeration]\n[layer]\nLayers to display in the map item(s) whose\ncontents are not locked\nDPI\nOptional\nDPI\nDefault: Not set\n[number]DPI of the output file(s). If not set, the\nvalue in the print layout settings will be\nused.\nAlways export as\nvectors\nFORCE_VECTOR[boolean]\nDefault: False\nDetermines if vectorial data should be left\nas vectors\nAppend georefer-\nence information\nGEOREFERENCE[boolean]\nDefault: True\nDetermines if a world file should be gener-\nated\nExportRDFmeta-\ndata\nIN-\nCLUDE_METADATA\n[boolean]\nDefault: True\nDetermines if RDF metadata (title, author,\n...) should be generated\nDisabletiled\nraster  layer  ex-\nports\nDISABLE_TILED[boolean]\nDefault: False\nDetermines if raster should be tiled\nSimplify  geome-\ntries  to  reduce\noutput file size\nSIMPLIFY[boolean]\nDefault: True\nDetermines if geometries should be simpli-\nfied to reduce output file size\nText exportTEXT_FORMAT[list]\nDefault: 0\nDetermines if text should be exported as\npath or text objects. Possible options are:\n•0 - Always export text as paths (rec-\nommended)\n•1 - Always export texts as text objects\nExport layers as\nseparate PDF files\nSEPA-\nRATE_LAYERS\n[boolean]\nDefault: False\nIf True, then a separate PDF file will be\ncreated per layer per map item in the lay-\nout. Additionally, separate PDF files may\nbe created for other complex layout items,\nresulting in a set of PDF files which contain\nlogical atomic components of the layout.\nOutputs\nLabelNameTypeDescription\nPDF fileOUTPUT[file]PDF file(s) corresponding to the exported\nprint layout\nPython code\nAlgorithm ID:native:printlayouttopdf\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider861\n\nQGIS Desktop 3.22 User Guide\nPrint layout map extent to layer\nCreates a polygon layer containing the extent of a print layout map item (or items), with attributes specifying the map\nsize (in layout units, i.e. thereference mapunits), scale and rotation.\nIf the map item parameter is specified, then only the matching map extent will be exported. If it is not specified, all\nmap extents from the layout will be exported.\nOptionally, a specific output CRS can be specified. If it is not specified, the original map item CRS will be used.\nParameters\nBasic parameters\nLabelNameTypeDescription\nPrint layoutLAYOUT[enumeration]A print layout in the current project\nMap item\nOptional\nMAP[enumeration]\nDefault:All the map\nitems\nThe map item(s) whose information you\nwant to extract. If none is provided then\nall the map items are processed.\nExtentOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the ex-\ntent(s). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nOverrride CRS\nOptional\nCRS[crs]\nDefault:The layout\nCRS\nSelect the CRS for the layer in which the\ninformation will be reported.\nOutputs\nLabelNameTypeDescription\nMap heightHEIGHT[number]\nExtentOUTPUT[vector: polygon]Output polygon vector layer containing ex-\ntents of all the input layout map item(s)\nMap rotationROTATION[number]\nMap scaleSCALE[number]\nMap widthWIDTH[number]\n862Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:printlayoutmapextenttolayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSet layer style\nApplies a provided style to a layer. The style must be defined in aQMLfile.\nNo new output are created: the style is immediately assigned to the layer.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[layer]Input layer you want to apply the style to\nStyle fileSTYLE[file]Path to the.qmlfile of the style\nOutputs\nLabelNameTypeDescription\nOUTPUT[same as input]The input layer with the new style assigned.\nNo new layer is created.\nPython code\nAlgorithm ID:native:setlayerstyle\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTopological coloring\nAssigns a color index to polygon features in such a way that no adjacent polygons share the same color index, whilst\nminimizing the number of colors required.\nThe algorithm allows choice of method to use when assigning colors.\nA minimum number of colors can be specified if desired. The color index is saved to a new attribute namedcolor_id.\nThe following example shows the algorithm with four different colors chosen; as you can see each color class has the\nsame amount of features.\n25.1. QGIS algorithm provider863\n\nQGIS Desktop 3.22 User Guide\nFig. 25.1: Topological colors example\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]The input polygon layer\nMinimumnumber\nof colors\nMIN_COLORS[number]\nDefault: 4\nThe minimum number of colors to assign.\nMinimum 1, maximum 1000.\nMinimum   dis-\ntance   between\nfeatures\nMIN_DISTANCE[number]\nDefault: 0.0\nPrevent nearby (but non-touching) features\nfrom being assigned equal colors.  Mini-\nmum 0.0.\nBalance color as-\nsignment\nBALANCE[enumeration]\nDefault: 0\nOptions are:\n•0 — By feature count\nAttempts to assign colors so that the\ncount of features assigned to each in-\ndividual color index is balanced.\n•1 — By assigned area\nAssigns colors so that the total area\nof features assigned to each color is\nbalanced. This mode can be useful\nto help avoid large features resulting\nin one of the colors appearing more\ndominant on a colored map.\n•2 — By distance between colors\nAssigns colors in order to maximize\nthe distance between features of the\nsame color. This mode helps to cre-\nate a more uniform distribution of\ncolors across a map.\ncontinues on next page\n864Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.2 – continued from previous page\nLabelNameTypeDescription\nColoredOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nColoredOUTPUT[vector: polygon]Polygon  vector  layer  with  an  added\ncolor_idcolumn\nPython code\nAlgorithm ID:qgis:topologicalcoloring\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTransfer annotations from main layer\nTransfers all annotations from the main annotation layer in a project to a new annotation layer. Items placement can\nthen be adjusted within the layer stack.\nParameters\nLabelNameTypeDescription\nNew layer nameLAYER_NAME[string]\nDefault:  ‘Annota-\ntions’\nName of the annotations layer to create\n25.1. QGIS algorithm provider865\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nNew layer nameOUTPUT[layer]A layer with items from the main annotation\nlayer\nPython code\nAlgorithm ID:native:transferannotationsfrommain\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.2Database\nExport to PostgreSQL\nExports a vector layer to a PostgreSQL database, creating a new relation. If a relation with the same name exists,\nit can be removed before the new relation is created. Prior to this a connection between QGIS and the PostgreSQL\ndatabase has to be created (see egCreating a stored Connection).\nParameters\nLabelNameTypeDescription\nLayer to importINPUT[vector: any]Vector layer to add to the database\nDatabase (connec-\ntion name)\nDATABASE[string]Name of the database connection (not the\ndatabase name). Existing connections will\nbe shown in the combobox.\nSchema  (schema\nname)\nOptional\nSCHEMA[string]\nDefault: ‘public’\nName of the schema to store the data. It\ncan be a new one or already exist.\nTable to import to\n(leave blank to use\nlayer name)\nOptional\nTABLENAME[string]\nDefault: ‘’\nDefines a table name for the imported vec-\ntor file. If nothing is added, the layer name\nwill be used.\nPrimary key field\nOptional\nPRIMARY_KEY[tablefield: any]Sets the primary key field from an existing\nfield in the vector layer. A column with\nuniquevalues can be used as Primary key\nfor the database.\nGeometry columnGEOME-\nTRY_COLUMN\n[string]\nDefault: ‘geom’\nDefines the name of the geometry column\nin the new PostGIS table. Geometry infor-\nmation for the features is stored in this col-\numn.\nEncoding\nOptional\nENCODING[string]\nDefault: ‘UTF-8’\nDefines the encoding of the output layer\ncontinues on next page\n866Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.4 – continued from previous page\nLabelNameTypeDescription\nOverwriteOVERWRITE[boolean]\nDefault: True\nIf the specified table exists, setting this\noption toTruewill make sure that it is\ndeleted and a new table will be created be-\nfore the features are added. If this option is\nFalseand the table exists, the algorithm\nwill throw an exception (“relation already\nexists”).\nCreate spatial in-\ndex\nCREATEINDEX[boolean]\nDefault: True\nSpecifies whether to create a spatial index\nor not\nConvertfield\nnames to lower-\ncase\nLOWER-\nCASE_NAMES\n[boolean]\nDefault: True\nConverts the field names of the input vector\nlayer to lowercase\nDrop length con-\nstraint on charac-\nter fields\nDROP_STRING_LENGTH[boolean]\nDefault: False\nShould length constraints on character fields\nbe dropped or not\nCreate single-part\ngeometries instead\nof multi-part\nFORCE_SINGLEPART[boolean]\nDefault: False\nShould the features of the output layer be\nsingle-part instead of multi-part. By default\nthe existing geometries information are pre-\nserved.\nOutputs\nThe algorithm has no output.\nPython code\nAlgorithm ID:qgis:importintopostgis\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport to SpatiaLite\nExports a vector layer to a SpatiaLite database. Prior to this a connection between QGIS and the SpatiaLite database\nhas to be created (see egSpatiaLite Layers).\nParameters\nLabelNameTypeDescription\nLayer to importINPUT[vector: any]Vector layer to add to the database\nFile databaseDATABASE[vector: any]The SQLite/SpatiaLite database file to con-\nnect to\nTable to import to\n(leave blank to use\nlayer name)\nOptional\nTABLENAME[string]\nDefault: ‘’\nDefines the table name for the imported\nvector file. If nothing is specified, the layer\nname will be used.\ncontinues on next page\n25.1. QGIS algorithm provider867\n\nQGIS Desktop 3.22 User Guide\nTable 25.5 – continued from previous page\nLabelNameTypeDescription\nPrimary key field\nOptional\nPRIMARY_KEY[tablefield: any]Use a field in the input vector layer as the\nprimary key\nGeometry columnGEOME-\nTRY_COLUMN\n[string]\nDefault: ‘geom’\nDefines the name of the geometry column\nin the new SpatiaLite table. Geometry in-\nformation for the features is stored in this\ncolumn.\nEncoding\nOptional\nENCODING[string]\nDefault: ‘UTF-8’\nDefines the encoding of the output layer\nOverwriteOVERWRITE[boolean]\nDefault: True\nIf the specified table exists, setting this\noption toTruewill make sure that it is\ndeleted and a new table will be created be-\nfore the features of the layer is added. If\nthis option isFalseand the table exists,\nthe algorithm will throw an exception (“ta-\nble already exists”).\nCreate spatial in-\ndex\nCREATEINDEX[boolean]\nDefault: True\nSpecifies whether to create a spatial index\nor not\nConvertfield\nnames to lower-\ncase\nLOWER-\nCASE_NAMES\n[boolean]\nDefault: True\nConvert the field names of the input vector\nlayer to lowercase\nDrop length con-\nstraint on charac-\nter fields\nDROP_STRING_LENGTH[boolean]\nDefault: False\nShould length constraints on character fields\nbe dropped or not\nCreate single-part\ngeometries instead\nof multi-part\nFORCE_SINGLEPART[boolean]\nDefault: False\nShould the features of the output layer be\nsingle-part instead of multi-part. By default\nthe existing geometries information are pre-\nserved.\nOutputs\nThe algorithm has no output.\nPython code\nAlgorithm ID:qgis:importintospatialite\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n868Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPackage layers\nAdds layers to a GeoPackage.\nIf the GeoPackage exists andOverwrite existing GeoPackageis checked, it will be overwritten (removed\nand recreated). If the GeoPackage exists andOverwrite existing GeoPackageis not checked, the layer\nwill be appended.\nParameters\nLabelNameTypeDescription\nInput layersLAYERS[vector: any] [list]The (vector) layers to import into the\nGeoPackage.  Raster layers are not sup-\nported.   If a raster layer is added, a\nQgsProcessingExceptionwill be\nthrown.\nOverwrite existing\nGeoPackage\nOVERWRITE[boolean]\nDefault: False\nIf the specified GeoPackage exists, setting\nthis option toTruewill make sure that it is\ndeleted and a new one will be created before\nthelayersareadded. IfsettoFalse, layers\nwill be appended.\nSave layer styles\ninto GeoPackage\nSAVE_STYLES[boolean]\nDefault: True\nSave the layer styles\nSave only selected\nfeatures\nSE-\nLECTED_FEATURES_ONLY\n[boolean]\nDefault: False\nIf a layer has a selection, setting this option\ntoTruewill result in only selected features\nbeing saved. For layers without a selection\nall features will be saved.\nDestination\nGeoPackage\nOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecify where to store the GeoPackage file.\nOne of\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nLayers within new\npackage\nOUTPUT_LAYERS[string] [list]The list of layers added to the GeoPackage.\nPython code\nAlgorithm ID:native:package\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThe\nalgorithm id\nis displayed when you hover over the algorithm in the Processing Toolbox. The\nparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider869\n\nQGIS Desktop 3.22 User Guide\nPostgreSQL execute and load SQL\nAllows a SQL database query to be performed on a PostgreSQL database connected to QGIS and loads the result.\nThe algorithmwon’tcreate a new layer: it is designed to run queries on the layer itself.\nExample\n1.Set all the values of an existing field to a fixed value. The SQL query string will be:\nUPDATEyour_tableSETfield_to_update=20;\nIn the example above, the values of the fieldfield_to_updateof the tableyour_tablewill be all set\nto20.\n2.Create a newareacolumn and calculate the area of each feature with theST_AREAPostGIS function.\n-- Create the new column \"area\" on the table your_table\"\nALTERTABLEyour_tableADDCOLUMNareadoubleprecision;\n-- Update the \"area\" column and calculate the area of each feature:\nUPDATEyour_tableSETarea=ST_AREA(geom);\nSee also:\nPostgreSQL execute SQL,Execute SQL,SpatiaLite execute SQL\nParameters\nLabelNameTypeDescription\nDatabase (connec-\ntion name)\nDATABASE[string]The database connection (not the database\nname). Existing connections will be shown\nin the combobox.\nSQL querySQL[string]Defines the SQL query, for example'UP-\nDATE my_table SET field=10'.\nUnique ID field\nname\nID_FIELD[string]\nDefault: id\nSets the primary key field (a column in the\nresult table)\nGeometry   field\nname\nOptional\nGEOME-\nTRY_FIELD\n[string]\nDefault: ‘geom’\nName of the geometry column (a column in\nthe result table)\nOutputs\nLabelNameTypeDescription\nSQL layerOUTPUT[vector: any]The resulting vector layer to be loaded into\nQGIS.\nPython code\nAlgorithm ID:qgis:postgisexecuteandloadsql\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n870Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPostgreSQL execute SQL\nAllows a SQL database query to be performed on a PostgreSQL database connected to QGIS. The algorithmwon’t\ncreate a new layer: it is designed to run queries on the layer itself.\nExample\n1.Set all the values of an existing field to a fixed value. The SQL query string will be:\nUPDATEyour_tableSETfield_to_update=20;\nIn the example above, the values of the fieldfield_to_updateof the tableyour_tablewill be all set\nto20.\n2.Create a newareacolumn and calculate the area of each feature with theST_AREAPostGIS function.\n-- Create the new column \"area\" on the table your_table\"\nALTERTABLEyour_tableADDCOLUMNareadoubleprecision;\n-- Update the \"area\" column and calculate the area of each feature:\nUPDATEyour_tableSETarea=ST_AREA(geom);\nSee also:\nPostgreSQL execute and load SQL,Execute SQL,SpatiaLite execute SQL\nParameters\nLabelNameTypeDescription\nDatabase (connec-\ntion name)\nDATABASE[string]The database connection (not the database\nname). Existing connections will be shown\nin the combobox.\nSQL querySQL[string]Defines the SQL query, for example'UP-\nDATE my_table SET field=10'.\nOutputs\nNo output is created. The SQL query is executed in place.\nPython code\nAlgorithm ID:native:postgisexecutesql\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider871\n\nQGIS Desktop 3.22 User Guide\nSpatiaLite execute SQL\nAllows a SQL database query to be performed on a SpatiaLite database. The algorithmwon’tcreate a new layer: it\nis designed to run queries on the layer itself.\nSee also:\nPostgreSQL execute SQL,Execute SQL\nFor some SQL query examples seePostGIS SQL Query Examples.\nParameters\nLabelNameTypeDescription\nFile DatabaseDATABASE[vector]The SQLite/SpatiaLite database file to con-\nnect to\nSQL querySQL[string]\nDefault: ‘’\nDefines the SQL query, for example'UP-\nDATE my_table SET field=10'.\nOutputs\nNo output is created. The SQL query is executed in place.\nPython code\nAlgorithm ID:native:spatialiteexecutesql\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSpatiaLite execute SQL (registered DB)\nAllows a SQL database query to be performed on a SpatiaLite database connected to QGIS. The algorithmwon’t\ncreate a new layer: it is designed to run queries on the layer itself.\nSee also:\nPostgreSQL execute SQL,Execute SQL\nFor some SQL query examples seePostGIS SQL Query Examples.\nParameters\nLabelNameTypeDescription\nDatabaseDATABASE[enumeration]\nDefault: not set\nSelect a SQLite/SpatiaLite database con-\nnected to the current session\nSQL querySQL[string]\nDefault: ‘’\nDefines the SQL query, for example'UP-\nDATE my_table SET field=10'.\n872Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nNo output is created. The SQL query is executed in place.\nPython code\nAlgorithm ID:native:spatialiteexecutesqlregistered\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.3File tools\nDownload file\nDownloads a file specified using a URL (using for instancehttp:orfile:). In other words you can copy/paste\na URL and download the file.\nParameters\nBasic parameters\nLabelNameTypeDescription\nURLURL[string]The URL of the file to download.\nFile destination\nOptional\nOUTPUT[string]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the file destination. One of:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nMethodMETHOD[enumeration]\nDefault: 0\nThe HTTP method to use for the request.\nOptions are:\n•0 — GET\n•1 — POST\nData\nOptional\nDATA[string]The data to add in the body if the request is\na POST.\n25.1. QGIS algorithm provider873\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nFile destinationOUTPUT[string]The location of the downloaded file\nPython code\nAlgorithm ID:qgis:filedownloader\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.4GPS\nConvert GPS data\nUses theGPSBabel toolto convert a GPS data file from a range of formats to the GPX standard format.\nParameters\nLabelNameTypeDescription\nInput fileINPUT[file]File containing the data to convert\nFormatFORMAT[enumeration]Format of the file to convert, fromthis list.\nFeature typeFEATURE_TYPE[enumeration]\nDefault: 0\nThe type of data to convert\n•0 — Waypoints\n•1 — Routes\n•2 — Tracks\nOutputOUTPUT[vector: any]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output GPX file. One\nof:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT_LAYER[vector: any]Output layer with data in GPX standard for-\nmat\n874Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:convertgpsdata\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConvert GPX feature type\nUses theGPSBabel toolto convert GPX features from one type to another (e.g. converting all waypoint features to\na route).\nParameters\nLabelNameTypeDescription\nInput fileINPUT[file]File containing the data to convert\nConversionCONVERSION[enumeration]\nDefault: 0\nThe type of conversion to apply\n•0 — Waypoints from a route\n•1 — Waypoints from a track\n•2 — Routes from waypoints\n•3 — Tracks from waypoints\nOutputOUTPUT[vector:  point or\nline]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[vector: any]Output layer with converted GPX features\nPython code\nAlgorithm ID:native:convertgpxfeaturetype\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider875\n\nQGIS Desktop 3.22 User Guide\nDownload GPS data from device\nUses theGPSBabel toolto download data from a GPS device into the GPX standard format.\nParameters\nLabelNameTypeDescription\nDeviceDEVICE[file]The GPS device used to create the data\nPortPORT[enumeration]The port the device is connected to.\nFeature typeFEATURE_TYPE[enumeration]\nDefault: 0\nThe type of data to convert\n•0 — Waypoints\n•1 — Routes\n•2 — Tracks\nOutputOUTPUT[vector: any]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT_LAYER[vector: any]Output layer with data in GPX standard for-\nmat\nPython code\nAlgorithm ID:native:downloadgpsdata\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nUpload GPS data to device\nUses theGPSBabel toolto upload data to a GPS device from the GPX standard format.\nParameters\nLabelNameTypeDescription\nInput fileINPUT[file].GPXfile containing the data to upload\nDeviceDEVICE[file]The GPS device to upload the data to\nPortPORT[enumeration]The port the device is connected to.\ncontinues on next page\n876Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.12 – continued from previous page\nLabelNameTypeDescription\nFeature typeFEATURE_TYPE[enumeration]\nDefault: 0\nThe type of data to upload\n•0 — Waypoints\n•1 — Routes\n•2 — Tracks\nOutputs\nNo output is provided. If successful, data are loaded to the device.\nPython code\nAlgorithm ID:native:uploadgpsdata\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.5Interpolation\nHeatmap (kernel density estimation)\nCreates a density (heatmap) raster of an input point vector layer using kernel density estimation.\nThe density is calculated based on the number of points in a location, with larger numbers of clustered points resulting\nin larger values. Heatmaps allow easy identification ofhotspotsand clustering of points.\nParameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Point vector layer to use for the heatmap\nRadiusRADIUS[number]\nDefault: 100.0\nHeatmap search radius (or kernel band-\nwidth) in map units. The radius specifies\nthe distance around a point at which the in-\nfluence of the point will be felt. Larger val-\nues result in greater smoothing, but smaller\nvalues may show finer details and variation\nin point density.\ncontinues on next page\n25.1. QGIS algorithm provider877\n\nQGIS Desktop 3.22 User Guide\nTable 25.13 – continued from previous page\nLabelNameTypeDescription\nOutput raster sizePIXEL_SIZE[number]\nDefault: 0.1\nPixel size of the output raster layer in layer\nunits.\nIn the GUI, the size can be specified by the\nnumber of rows (Number  of  rows)\n/ columns (Number of columns)or\nthe pixel size(Pixel Size X/Pixel\nSize Y). Increasing the number of rows\nor columns will decrease the cell size and\nincrease the file size of the output raster.\nThe values inRows,Columns,Pixel\nSize XandPixel Size Ywill be up-\ndated simultaneously - doubling the number\nof rows will double the number of columns,\nand the cell size will be halved. The extent\nof the output raster will remain the same\n(approximately).\nRadius from field\nOptional\nRADIUS_FIELD[tablefield:nu-\nmeric]\nSets the search radius for each feature from\nan attribute field in the input layer.\nWeight from field\nOptional\nWEIGHT_FIELD[tablefield:nu-\nmeric]\nAllows input features to be weighted by an\nattribute field. This can be used to increase\nthe influence certain features have on the re-\nsultant heatmap.\nKernel shapeKERNEL[enumeration]\nDefault:0\nControls the rate at which the influence of\na point decreases as the distance from the\npoint increases. Different kernels decay at\ndifferent rates, so a triweight kernel gives\nfeatures greater weight for distances closer\nto the point then the Epanechnikov ker-\nnel does.  Consequently, triweight results\nin “sharper” hotspots and Epanechnikov re-\nsults in “smoother” hotspots.\nThere are many shapes available (please see\nthe\nWikipedia pagefor further informa-\ntion):\n•0 — Quartic\n•1 — Triangular\n•2 — Uniform\n•3 — Triweight\n•4 — Epanechnikov\ncontinues on next page\n878Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.13 – continued from previous page\nLabelNameTypeDescription\nDecay ratio (Tri-\nangular  kernels\nonly)\nOptional\nDECAY[number]\nDefault:0.0\nCan be used with Triangular kernels to fur-\nther control how heat from a feature de-\ncreases with distance from the feature.\n•A value of 0 (=minimum) indicates\nthat the heat will be concentrated in\nthe center of the given radius and\ncompletely extinguished at the edge.\n•A value of 0.5 indicates that pixels at\nthe edge of the radius will be given\nhalf the heat as pixels at the center of\nthe search radius.\n•A value of 1 means the heat is spread\nevenly over the whole search radius\ncircle. (This is equivalent to the ‘Uni-\nform’ kernel.)\n•A value greater than 1 indicates that\nthe heat is higher towards the edge of\nthe search radius than at the center.\nOutput value scal-\ning\nOUTPUT_VALUE[enumeration]\nDefault:Raw\nAllow to change the values of the output\nheatmap raster. One of:\n•0 — Raw\n•1 — Scaled\nHeatmapOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with kernel\ndensity values. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nHeatmapOUTPUT[raster]Raster layer with kernel density values\nExample: Creating a Heatmap\nFor the following example, we will use theairportsvector point layer from the QGIS sample dataset (seeDown-\nloading sample data). Another excellent QGIS tutorial on making heatmaps can be found athttp://qgistutorials.com.\nInFig. 25.2, the airports of Alaska are shown.\n25.1. QGIS algorithm provider879\n\nQGIS Desktop 3.22 User Guide\nFig. 25.2: Airports of Alaska\n1.Open theHeatmap (Kernel Density Estimation)algorithm from the QGISInterpolationgroup\n2.In thePoint layerfield, selectairportsfrom the list of point layers loaded in the current project.\n3.Change theRadiusto1000000meters.\n4.Change thePixel size Xto1000. ThePixel size Y,RowsandColumnswill be automatically updated.\n5.Click onRunto create and load the airports heatmap (seeFig. 25.4).\n880Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.3: The Heatmap Dialog\nQGIS will generate the heatmap and add it to your map window. By default, the heatmap is shaded in greyscale,\nwith lighter areas showing higher concentrations of airports. The heatmap can now be styled in QGIS to improve its\nappearance.\n25.1. QGIS algorithm provider881\n\nQGIS Desktop 3.22 User Guide\nFig. 25.4: The heatmap after loading looks like a grey surface\n1.Open the properties dialog of theheatmap_airportslayer (select the layerheatmap_airports, open\nthe context menu with the right mouse button and selectProperties).\n2.Select theSymbologytab.\n3.Change theRender typeto ‘Singleband pseudocolor’.\n4.Select a suitableColor ramp, for instanceYlOrRd.\n5.Click theClassifybutton.\n6.PressOKto update the layer.\nThe final result is shown in\nFig. 25.5.\n882Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.5: Styled heatmap of airports of Alaska\nPython code\nAlgorithm ID:qgis:heatmapkerneldensityestimation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nIDW Interpolation\nGenerates an Inverse Distance Weighted (IDW) interpolation of a point vector layer.\nSample points are weighted during interpolation such that the influence of one point relative to another declines with\ndistance from the unknown point you want to create.\nThe IDW interpolation method also has some disadvantages: the quality of the interpolation result can decrease, if\nthe distribution of sample data points is uneven.\nFurthermore, maximum and minimum values in the interpolated surface can only occur at sample data points.\n25.1. QGIS algorithm provider883\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layer(s)INTERPOLA-\nTION_DATA\n[string]Vector layer(s) and field(s) to use for the in-\nterpolation, coded in a string (see thePa-\nrameterInterpolationDataclass\ninInterpolationWidgetsfor more details).\nThe following GUI elements are provided\nto compose the interpolation data string:\n•Vector layer[vector: any]\n•Interpolation attribute[tablefield:\nnumeric]: Attribute to use in the in-\nterpolation\n•UseZ-coordinateforinterpolation\n[boolean]: Uses the layer’s stored Z\nvalues (Default: False)\nFor each of the added layer-field combina-\ntions, a type can be chosen:\n•Points\n•Structured lines\n•Break lines\nIn the string, the layer-field elements are\nseparated by'::|::'. The sub-elements\nof the layer-field elements are separated by\n'::~::'.\nDistance   coeffi-\ncient P\nDIS-\nTANCE_COEFFICIENT\n[number]\nDefault: 2.0\nSets the distance coefficient for the interpo-\nlation. Minimum: 0.0, maximum: 100.0.\nExtent   (xmin,\nxmax,ymin,\nymax)\nEXTENT[extent]Extent of the output raster layer.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nOutput raster sizePIXEL_SIZE[number]\nDefault: 0.1\nPixel size of the output raster layer in layer\nunits.\nIn the GUI, the size can be specified by the\nnumber of rows (\nNumber  of  rows\n)\n/ columns (Number of columns)or\nthe pixel size(Pixel Size X/Pixel\nSize Y). Increasing the number of rows\nor columns will decrease the cell size and\nincrease the file size of the output raster.\nThe values in\nRows\n,\nColumns\n,\nPixel\nSize XandPixel Size Ywill be up-\ndated simultaneously - doubling the number\nof rows will double the number of columns,\nand the cell size will be halved. The extent\nof the output raster will remain the same\n(approximately).\ncontinues on next page\n884Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.15 – continued from previous page\nLabelNameTypeDescription\nInterpolatedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nRaster layer of interpolated values. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nInterpolatedOUTPUT[raster]Raster layer of interpolated values\nPython code\nAlgorithm ID:qgis:idwinterpolation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nLine Density\nCalculates for each raster cell, the density measure of linear features within a circular neighbourhood. This measure\nis obtained by summing all the line segments intersecting the circular neighbourhood and dividing this sum by the\narea of such neighbourhood. A weighting factor can be applied to the line segments.\nFig. 25.6: Line density example. Input layer source: Roads Overijssel - The Netherlands (OSM).\n25.1. QGIS algorithm provider885\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput line layerINPUT[vector: any]Input vector layer containing line features\nWeight fieldWEIGHT[number]Field of the layer containing the weight fac-\ntor to use during the calculation\nSearch RadiusRADIUS[number]\nDefault: 10\nRadius of the circular neighbourhood.\nUnits can be specified here.\nPixel sizePIXEL_SIZE[number]\nDefault: 10\nPixel size of the output raster layer in layer\nunits. The raster has square pixels.\nLinedensityrasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nThe output as a raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nLinedensityrasterOUTPUT[raster]The output line density raster layer.\nPython code\nAlgorithm ID:native:linedensity\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTIN Interpolation\nGenerates a Triangulated Irregular Network (TIN) interpolation of a point vector layer.\nWith the TIN method you can create a surface formed by triangles of nearest neighbor points. To do this, circumcircles\naround selected sample points are created and their intersections are connected to a network of non overlapping and\nas compact as possible triangles. The resulting surfaces are not smooth.\nThe algorithm creates both the raster layer of the interpolated values and the vector line layer with the triangulation\nboundaries.\nParameters\n886Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nLabelNameTypeDescription\nInput layer(s)INTERPOLA-\nTION_DATA\n[string]Vector layer(s) and field(s) to use for the in-\nterpolation, coded in a string (see thePa-\nrameterInterpolationDataclass\ninInterpolationWidgetsfor more details).\nThe following GUI elements are provided\nto compose the interpolation data string:\n•Vector layer[vector: any]\n•Interpolation attribute[tablefield:\nnumeric]: Attribute to use in the in-\nterpolation\n•UseZ-coordinateforinterpolation\n[boolean]: Uses the layer’s stored Z\nvalues (Default: False)\nFor each of the added layer-field combina-\ntions, a type can be chosen:\n•Points\n•Structured lines\n•Break lines\nIn the string, the layer-field elements are\nseparated by'::|::'. The sub-elements\nof the layer-field elements are separated by\n'::~::'.\nInterpolation\nmethod\nMETHOD[enumeration]\nDefault: 0\nSet the interpolation method to be used.\nOne of:\n•Linear\n•Clough-Toucher (cubic)\nExtent   (xmin,\nxmax,ymin,\nymax)\nEXTENT[extent]Extent of the output raster layer.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nOutput raster sizePIXEL_SIZE[number]\nDefault: 0.1\nPixel size of the output raster layer in layer\nunits.\nIn the GUI, the size can be specified by the\nnumber of rows (Number  of  rows)\n/ columns (Number of columns)or\nthe pixel size(Pixel Size X/Pixel\nSize Y). Increasing the number of rows\nor columns will decrease the cell size and\nincrease the file size of the output raster.\nThe values inRows,Columns,Pixel\nSize XandPixel Size Ywill be up-\ndated simultaneously - doubling the number\nof rows will double the number of columns,\nand the cell size will be halved. The extent\nof the output raster will remain the same\n(approximately).\ncontinues on next page\n25.1. QGIS algorithm provider887\n\nQGIS Desktop 3.22 User Guide\nTable 25.19 – continued from previous page\nLabelNameTypeDescription\nInterpolatedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nThe output TIN interpolation as a raster\nlayer. One of:\n•Save to a Temporary File\n•Save to File...\nTriangulationTRIANGULATION[vector: line]\nDefault:[Skip\noutput]\nThe output TIN as a vector layer. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nInterpolatedOUTPUT[raster]The output TIN interpolation as a raster\nlayer\nTriangulationTRIANGULATION[vector: line]The output TIN as a vector layer.\nPython code\nAlgorithm ID:qgis:tininterpolation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.6Layer tools\nExport layer(s) information\nNEW in 3.18\nCreates a polygon layer with features corresponding to the extent of selected layer(s).\nAdditional layer details (CRS, provider name, file path, layer name, subset filter, abstract and attribution) are attached\nas attributes to each feature.\n888Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layersLAYERS[vector: any][list]Input vector layers to get information on.\nOutputOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output layer with infor-\nmation. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[vector: polygon]Polygon vector layer showing extent of in-\nput layers and associated information in at-\ntributes.\nPython code\nAlgorithm ID:native:exportlayersinformation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport to spreadsheet\nExports the attributes of a selection of vector layers into a spreadsheet document or optionally appends them to an\nexisting spreadsheet as additional sheets.\n25.1. QGIS algorithm provider889\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layersLAYERS[vector: any][list]Input vector layers. The output spreadsheet\nwill consist of a sheet, for each layer, that\ncontains the attributes of this layer.\nUse field aliases as\ncolumn headings\nUSE_ALIAS[boolean]\nDefault: False\nUse the field aliases from the attribute table\nfor the spreadsheet.\nExport formatted\nvalues instead of\nraw values\nFORMAT-\nTED_VALUES\n[boolean]\nDefault: False\nIfTrue, exports the formatted, human\nreadable values (e.g., from avalue map or\nvalue relation) to the spreadsheet.\nOverwrite existing\nspreadsheet\nOVERWRITE[boolean]\nDefault: True\nIf the specified spreadsheet exists, setting\nthis option toTruewill overwrite the ex-\nisting spreadsheet. If this option isFalse\nand the spreadsheet exists, the layers will be\nappended as additional sheets.\nDestination\nspreadsheet\nOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nOutput spreadsheet with a sheet for every\nlayer. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nDestination\nspreadsheet\nOUTPUT[file]Spreadsheet with a sheet for every layer.\nLayers   within\nspreadsheet\nOUTPUT_LAYERS[list]The list of sheets added to the spreadsheet.\nPython code\nAlgorithm ID:native:exporttospreadsheet\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract layer extent\nGenerates a vector layer with the minimum bounding box (rectangle with N-S orientation) that covers all the input\nfeatures.\nThe output layer contains a single bounding box for the whole input layer.\n890Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.7: In red the bounding box of the source layer\nDefault menu:Vector►Research Tools\nParameters\nLabelNameTypeDescription\nLayerINPUT[layer]Input layer\nExtentOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the polygon vector layer for the out-\nput extent. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider891\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nExtentOUTPUT[vector: polygon]Output (polygon) vector layer with the ex-\ntent (minimum bounding box)\nPython code\nAlgorithm ID:qgis:polygonfromlayerextent\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.7Mesh\nExport contours\nCreates contours as a vector layer from a mesh scalar dataset.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nIncrement   be-\ntween   contour\nlevels\nOptional\nINCREMENT[number]\nDefault:Not set\nInterval between generated levels.\nMinimum contour\nlevel\nOptional\nMINIMUM[number]\nDefault:Not set\nStarting level values of contours.\nMaximum  con-\ntour level\nOptional\nMAXIMUM[number]\nDefault:Not set\nMaximum values of contours, i.e. no gen-\nerated levels will be greater than this value.\nList of contours\nlevel\nOptional\nCON-\nTOUR_LEVEL_LIST\n[number]\nDefault:Not set\nList of wanted levels of contours (separated\nby commas). If filled, the increment, mini-\nmum, and maximum fields will not be con-\nsidered.\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\ncontinues on next page\n892Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.21 – continued from previous page\nLabelNameTypeDescription\nExported contour\nlines\nOUTPUT_LINES[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line layer representing\nthe contours of the mesh layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nExported contour\npolygons\nOUT-\nPUT_POLYGONS\n[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon layer represent-\ning the contours of the mesh layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExported contour\nlines\nOUTPUT_LINES[vector: line]Line layer representing the contours of the\nmesh layer.\nExported contour\npolygons\nOUT-\nPUT_POLYGONS\n[vector: polygon]Polygon layer representing the contours of\nthe mesh layer.\nPython code\nAlgorithm ID:native:meshcontours\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider893\n\nQGIS Desktop 3.22 User Guide\nExport cross section dataset values on lines from mesh\nExtracts a mesh dataset’s values from lines contained in a vector layer.\nEach line is discretized with a resolution distance parameter for extraction of values on its vertices.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nLines for data ex-\nport\nINPUT_LINES[vector: line]Lines where the data will be extracted from\nthe dataset mesh\nLine segmentation\nresolution\nRESOLUTION[number]\nDefault: 10.0\nThe distance between points on the lines\nwhere the data will be extracted from the\ndataset mesh.\nDigits count for\ndataset value\nDATASET_DIGITS[number]\nDefault: 2\nNumber of digits to round dataset values\nExported   data\nCSV file\nOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nExported   data\nCSV file\nOUTPUT[file]\nPython code\nAlgorithm ID:native:meshexportcrosssection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n894Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExport mesh edges\nExports a mesh layer’s edges to a line vector layer, with the dataset values on edges as attribute values.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\nExport vector op-\ntion\nVECTOR_OPTION[enumeration]Coordinate type of vector value exporta-\ntion.\n•0 — Cartesian (x,y)\n•1 — Polar (magnitude, degree)\n•2 — Cartesian and polar\nOutput   vector\nlayer\nOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output file. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOutput   vector\nlayer\nOUTPUT[vector: line]Output vector line layer containing the\nedges of the input mesh layer with associ-\nated dataset values\nPython code\nAlgorithm ID:native:exportmeshedges\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider895\n\nQGIS Desktop 3.22 User Guide\nExport mesh faces\nExports a mesh layer’s faces to a polygon vector layer, with the dataset values on faces as attribute values.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\nExport vector op-\ntion\nVECTOR_OPTION[enumeration]Coordinate type of vector value exporta-\ntion.\n•0 — Cartesian (x,y)\n•1 — Polar (magnitude, degree)\n•2 — Cartesian and polar\nOutput   vector\nlayer\nOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output file. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOutput   vector\nlayer\nOUTPUT[vector: polygon]Output vector polygon layer containing the\nfaces of the input mesh layer with associ-\nated dataset values\nPython code\nAlgorithm ID:native:exportmeshfaces\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n896Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExport mesh on grid\nExports a mesh layer’s dataset values to a gridded point vector layer, with the dataset values on this point as attribute\nvalues.\nFor data on volume (3D stacked dataset values), the exported dataset values are averaged on faces using the method\ndefined inthe mesh layer properties(default is Multi level averaging method). 1D meshes are not supported.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nExtent\nOptional\nEXTENT[extent]Specify the spatial extent on which to pro-\ncess the data.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nGrid spacing\nOptional\nGRID_SPACING[number]\nDefault: 10.0\nSpacing between the sample points to use\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\nExport vector op-\ntion\nVECTOR_OPTION[enumeration]Coordinate type of vector value exporta-\ntion.\n•0 — Cartesian (x,y)\n•1 — Polar (magnitude, degree)\n•2 — Cartesian and polar\nOutput   vector\nlayer\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output file. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider897\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutput   vector\nlayer\nOUTPUT[vector: point]Output vector point layer with dataset val-\nues computed from the overlaid face.\nPython code\nAlgorithm ID:native:exportmeshongrid\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport mesh vertices\nExports a mesh layer’s vertices to a point vector layer, with the dataset values on vertices as attribute values.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\nExport vector op-\ntion\nVECTOR_OPTION[enumeration]Coordinate type of vector value exporta-\ntion.\n•0 — Cartesian (x,y)\n•1 — Polar (magnitude, degree)\n•2 — Cartesian and polar\nOutput   vector\nlayer\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output file. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n898Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutput   vector\nlayer\nOUTPUT[vector: point]Output vector point layer containing the\nvertices of the input mesh layer with asso-\nciated dataset values\nPython code\nAlgorithm ID:native:exportmeshvertices\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport time series values from points of a mesh dataset\nExtracts a mesh dataset’s time series values from points contained in a vector layer.\nIf the time step is kept to its default value (0 hours), the time step used is the one of the two first datasets of the first\nselected dataset group.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to extract data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nStarting timeSTARTING_TIME[datetime]The start of the time range to take into ac-\ncount\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nFinishing timeFINISH-\nING_TIME\n[datetime]The end of the time range to take into ac-\ncount\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nTime step (hours)\nOptional\nTIME_STEP[number]\nDefault: 0\nTime between two consecutive steps to ex-\ntract. Keep0to use time step of the first\nselected dataset group.\nPoints for data ex-\nport\nINPUT_POINTS[vector: point]Vector layer containing points where the\ndata will be extracted from the dataset mesh\nDigits count for\ncoordinates\nCOORDI-\nNATES_DIGITS\n[number]Numberofdigitstoroundcoordinatevalues\nDefault: 2\nDigits count for\ndataset value\nDATASET_DIGITS[number]\nDefault: 2\nNumber of digits to round dataset values\ncontinues on next page\n25.1. QGIS algorithm provider899\n\nQGIS Desktop 3.22 User Guide\nTable 25.27 – continued from previous page\nLabelNameTypeDescription\nExported   data\nCSV file\nOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nExported   data\nCSV file\nOUTPUT[file].CSVfile containing the mesh dataset time\nseries values at the overlaying point features\nPython code\nAlgorithm ID:native:meshexporttimeseries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRasterize mesh dataset\nCreates a raster layer from a mesh dataset.\nFor data on volume (3D stacked dataset values), the exported dataset values are averaged on faces using the method\ndefined inthe mesh layer properties(default is Multi level averaging method). 1D meshes are not supported.\nParameters\nLabelNameTypeDescription\nInput mesh layerINPUT[mesh]The mesh layer to export data from\nDataset groupsDATASET_GROUPS[layer][list]The dataset groups\nDataset timeDATASET_TIME[datetime]The time range to take into account\n•0 — Current canvas time\n•1 — Defined date/time\n•2 — Dataset group time step\nExtent\nOptional\nEXTENT[extent]Specify the spatial extent on which to pro-\ncess the data.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\ncontinues on next page\n900Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.28 – continued from previous page\nLabelNameTypeDescription\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size of the output raster layer.\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\nOutput   raster\nlayer\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput   raster\nlayer\nOUTPUT[raster]Output raster layer with dataset values com-\nputed from the mesh layer.\nPython code\nAlgorithm ID:native:meshrasterize\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTIN mesh creation\nCreates a TIN mesh layer from vector layers. The TIN mesh is created using a Delaunay triangulation.\nParameters\nLabelNameTypeDescription\nInput layersSOURCE_DATA[vector: any][list]Vector layers to combine to generate the\nmesh layer\nVector layerGUI ONLY[vector: any][list]A selector for the vector layers to combine\nto generate the mesh layer\nValue on vertexGUI ONLY[tablefield: any]A selector of the field to use from the se-\nlected layer. Each vertex is assigned the\ncorresponding value of its original feature.\nUse Z-coordinate\nfor value on vertex\nGUI ONLY[boolean]\nDefault: False\nIf checked, the Z value of vector layer\npoints or polygons/lines vertices will be\nusedtoassigntheZvalueofthevertexmesh\nlayer. Only available if the input layers are\n3D.\ncontinues on next page\n25.1. QGIS algorithm provider901\n\nQGIS Desktop 3.22 User Guide\nTable 25.29 – continued from previous page\nLabelNameTypeDescription\nOutput formatMESH_FORMAT[enumeration]\nDefault: 2DM\nOutput format of the generated layer\n•0 — 2DM\n•1 — SELAFIN\n•2 — PLY\n•3 — Ugrid\nOutput coordinate\nsystem\nOptional\nCRS_OUTPUT[crs]Coordinate Reference System to assign to\nthe output\nOutput fileOUTPUT_MESH[mesh]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput fileOUTPUT_MESH[mesh]Output mesh layer with dataset values com-\nputed from the vector layers.\nPython code\nAlgorithm ID:native:tinmeshcreation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.8Modeler tools\nWarning:These tools are only available in the Graphical Modeler. They are not available in the Processing\nToolbox.\nConditional branch\nAdds a conditional branch into a model, allowing parts of the model to be executed based on the result of an expression\nevaluation. Mostly by using tool dependencies to control the flow of a model.\n902Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nFieldBRANCH[string]Name of the condition\nFieldCONDITION[expression]Expression to evaluate\nOutputs\nNone.\nPython code\nAlgorithm ID:native:condition\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate directory\nCreates a new directory on a file system. Directories will be created recursively, creating all required parent directories\nin order to construct the full specified directory path. No errors will be raised if the directory already exists.\nParameters\nLabelNameTypeDescription\nDirectory pathPATH[string]Folder path to create\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[folder]Created folder\nPython code\nAlgorithm ID:native:createdirectory\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider903\n\nQGIS Desktop 3.22 User Guide\nFeature filter\nFilters features from the input layer and redirects them to one or several outputs. If you do not know about any\nattribute names that are common to all possible input layers, filtering is only possible on the feature geometry and\ngeneral record mechanisms, such as\n$id\nand\nuuid\n.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer.\nOutputs and fil-\nters\n(one or more)\nOUTPUT_<name\nof  the  fil-\nter>\n[same as input]The output layers with filters (as many as\nthere are filters).\nOutputs\nLabelNameTypeDescription\nOutput\n(one or more)\nna-\ntive:filter_1:OUTPUT_<name\nof filter>\n[same as input]The output layers with filtered features (as\nmany as there are filters).\nPython code\nAlgorithm ID:native:filter\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFilter by geometry type\nFilters features by their geometry type. Incoming features will be directed to different outputs based on whether they\nhave a point, line or polygon geometry.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to evaluate\n904Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nPoint features\nOptional\nPOINTS[vector: point]Layer with points\nLine features\nOptional\nLINES[vector: line]Layer with lines\nPolygon features\nOptional\nPOLYGONS[vector: polygon]Layer with polygons\nFeatures with no\ngeometry\nOptional\nNO_GEOMETRY[table]Geometry-less vector layer\nPython code\nAlgorithm ID:native:filterbygeometry\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFilter layers by type\nFilters layers by their type. Incoming layers will be directed to different outputs based on whether they are a vector\nor raster layer.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[layer]Generic Map Layer\nOutputs\nLabelNameTypeDescription\nVector features\nOptional\nVECTOR[vector]A Vector Layer of the input, if compatible\nRaster layer\nOptional\nRASTER[raster]A Raster Layer of the input, if compatible\n25.1. QGIS algorithm provider905\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:filterlayersbytype\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nLoad layer into project\nLoads a layer to the current project.\nParameters\nLabelNameTypeDescription\nLayerINPUT[layer]Layer to load in the legend\nLoaded    layer\nname\nNAME[string]Name of the loaded layer\nOutputs\nLabelNameTypeDescription\nLayerOUTPUT[same as input]The (renamed) loaded layer\nPython code\nAlgorithm ID:native:loadlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaise exception\nRaises an exception and cancels a model’s execution. The exception message can be customized, and optionally an\nexpression based condition can be specified. If an expression condition is used, then the exception will only be raised\nif the expression result is true. A false result indicates that no exception will be raised, and the model execution can\ncontinue uninterrupted.\n906Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nMessageMESSAGE[string]Message to display\nCondition\nOptional\nCONDITION[expression]Expression to evaluate if true\nOutputs\nA message in the log panel.\nPython code\nAlgorithm ID:native:raiseexception\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaise warning\nRaises a warning message in the log. The warning message can be customized, and optionally an expression based\ncondition can be specified. If an expression condition is used, then the warning will only be logged if the expression\nresult is true. A false result indicates that no warning will be logged.\nParameters\nLabelNameTypeDescription\nMessageMESSAGE[string]Message to display\nCondition\nOptional\nCONDITION[expression]Expression to evaluate if true\nOutputs\nA message in the log panel.\nPython code\nAlgorithm ID:native:raisewarning\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider907\n\nQGIS Desktop 3.22 User Guide\nRename layer\nRenames a layer.\nParameters\nLabelNameTypeDescription\nLayerINPUT[layer]Layer to rename\nNew nameNAME[string]The new name of the layer\nOutputs\nLabelNameTypeDescription\nLayerOUTPUT[same as input]The (renamed) output layer\nPython code\nAlgorithm ID:native:renamelayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSave log to file\nSaves the model’s execution log to a file. Optionally, the log can be saved in a HTML formatted version.\nParameters\nLabelNameTypeDescription\nUse HTMLUSE_HTML[Boolean]\nDefault: False\nUse HTML formatting\nOutputs\nLabelNameTypeDescription\nFileOUTPUT[string]Destination of the log\n908Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:savelog\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSet project variable\nSets an expression variable for the current project.\nParameters\nLabelNameTypeDescription\nVariable nameNAME[string]Name of the variable\nVariable valueVALUE[string]Value to be stored\nOutputs\nNone.\nPython code\nAlgorithm ID:native:setprojectvariable\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nString concatenation\nConcatenates two strings into a single one in the Processing Modeler.\nParameters\nLabelNameTypeDescription\nInput 1INPUT_1[string]First string\nInput 2INPUT_2[string]Second string\n25.1. QGIS algorithm provider909\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nConcatenationCONCATENATION[string]The concatenated string\nPython code\nAlgorithm ID:native:stringconcatenation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nVariable distance buffer\nWarning:This algorithm is deprecated and can be removed anytime. Prefer usingBufferalgorithm instead.\nComputes a buffer area for all the features in an input layer.\nThe size of the buffer for a given feature is defined by an attribute, so it allows different features to have different\nbuffer sizes.\nSee also:\nBuffer\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nDistance fieldDISTANCE[tablefield:nu-\nmeric]\nAttribute for the distance radius of the\nbuffer\nSegmentsSEGMENTS[number]\nDefault:5\nControls the number of line segments to use\nto approximate a quarter circle when creat-\ning rounded offsets.\nDissolve resultDISSOLVE[boolean]\nDefault:False\nChoose   to   dissolve   the   final\nbuffer,  resulting  in  a  single  fea-\nture   covering   all   input   features.\nFig. 25.8: Normal and dissolved buffer\ncontinues on next page\n910Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.30 – continued from previous page\nLabelNameTypeDescription\nEnd cap styleEND_CAP_STYLE[enumeration]\nDefault: Round\nControlshowlineendings\nare    handled    in    the    buffer.\nFig. 25.9: Round, flat and square cap styles\nJoin styleJOIN_STYLE[enumeration]\nDefault: Round\nSpecifies whether round, miter or beveled\njoinsshouldbeused whenoffsettingcorners\nin a line.\nMiter limitMITER_LIMIT[number]\nDefault: 2.0\nOnly applicable for mitered join styles, and\ncontrols the maximum distance from the\noffset curve to use when creating a mitered\njoin.\nOutputs\nLabelNameTypeDescription\nBufferOUTPUT[vector: polygon]Buffer polygon vector layer.\nPython code\nAlgorithm ID:qgis:variabledistancebuffer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider911\n\nQGIS Desktop 3.22 User Guide\n25.1.9Network analysis\nService area (from layer)\nReturns all the edges or parts of edges of a network that can be reached within a distance or a time, starting from a\npoint layer. This allows evaluation of accessibility within a network, e.g. what are the places I can navigate to on a\nroad network without spending cost greater than a given value (the cost can be distance or time).\nParameters\nBasic parameters\nLabelNameTypeDescription\nVector layer repre-\nsenting network\nINPUT[vector: line]Line vector layer representing the network\nto be covered\nVector layer with\nstart points\nSTART_POINTS[vector: point]Point vector layer whose features are used\nas start points to generate the service areas\nPath type to calcu-\nlate\nSTRATEGY[enumeration]\nDefault: 0\nThe type of path to calculate. One of:\n•0 — Shortest\n•1 — Fastest\nTravel cost (dis-\ntance for “Short-\nest”,  time  for\n“Fastest”)\nTRAVEL_COST[number]\nDefault: 0\nThe value is estimated as a distance (in the\nnetwork layer units) when looking for the\nShortestpath and as time (in hours) for the\nFastestpath.\nServicearea\n(lines)\nOUTPUT_LINES[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line layer for the service\narea. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nServicearea\n(boundary nodes)\nOUTPUT[vector: point]\nDefault:[Skip\noutput]\nSpecify the output point layer for the ser-\nvice area boundary nodes. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n912Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nDirection field\nOptional\nDIREC-\nTION_FIELD\n[tablefield: string]\nDefault: 0.0\nThe field used to specify directions for the\nnetwork edges.\nThe values used in this field are specified\nwith the three parametersValue  for\nforward  direction,Value  for\nbackward  directionandValue\nfor both directions. Forward and\nreverse directions correspond to a one-way\nedge, “both directions” indicates a two-way\nedge. If a feature does not have a value in\nthis field, or no field is set then the default\ndirection setting (provided with theDe-\nfault directionparameter) is used.\nValue for forward\ndirection\nOptional\nVALUE_FORWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a forward direction\nValue for back-\nward direction\nOptional\nVALUE_BACKWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a backward direction\nValue for both di-\nrections\nOptional\nVALUE_BOTH[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nbidirectional edges\nDefault directionDE-\nFAULT_DIRECTION\n[enumeration]\nDefault: 2\nIf a feature has no value set in the direction\nfield or if no direction field is set, then this\ndirection value is used. One of:\n•0 — Forward direction\n•1 — Backward direction\n•2 — Both directions\nSpeed field\nOptional\nSPEED_FIELD[tablefield: string]Field providing the speed value (inkm/h)\nfor the edges of the network when looking\nfor the fastest path.\nIf a feature does not have a value in this\nfield, or no field is set then the default\nspeed value (provided with theDefault\nspeedparameter) is used.\nDefault    speed\n(km/h)\nDEFAULT_SPEED[number]\nDefault: 50.0\nValue to use to calculate the travel time if\nno speed field is provided for an edge\nTopology   toler-\nance\nTOLERANCE[number]\nDefault: 0.0\nTwo lines with nodes closer than the speci-\nfied tolerance are considered connected\nIncludeup-\nper/lower  bound\npoints\nIN-\nCLUDE_BOUNDS\n[boolean]\nDefault: False\nCreates a point layer output with two points\nfor each edge at the boundaries of the ser-\nvice area. One point is the start of that edge,\nthe other is the end.\n25.1. QGIS algorithm provider913\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nServicearea\n(boundary nodes)\nOUTPUT[vector: point]The output point layer with the service area\nboundary nodes.\nServicearea\n(lines)\nOUTPUT_LINES[vector: line]Line layer representing the parts of the net-\nworkthatcanbeservicedbythestartpoints,\nfor the given cost.\nPython code\nAlgorithm ID:qgis:serviceareafromlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nService area (from point)\nReturns all the edges or parts of edges of a network that can be reached within a given distance or time, starting from\na point feature. This allows the evaluation of accessibility within a network, e.g. what are the places I can navigate\nto on a road network without spending a cost greater than a given value (the cost can be distance or time).\nParameters\nBasic parameters\nLabelNameTypeDescription\nVector layer rep-\nresenting the net-\nwork\nINPUT[vector: line]Line vector layer representing the network\nto be covered\nStart point (x, y)START_POINT[coordinates]Coordinate of the point to calculate the ser-\nvice area around.\nPath type to calcu-\nlate\nSTRATEGY[enumeration]\nDefault: 0\nThe type of path to calculate. One of:\n•0 — Shortest\n•1 — Fastest\nTravel cost (dis-\ntance for “Short-\nest”,  time  for\n“Fastest”)\nTRAVEL_COST[number]\nDefault: 0\nThe value is estimated as a distance (in the\nnetwork layer units) when looking for the\nShortestpath and as time (in hours) for the\nFastestpath.\ncontinues on next page\n914Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.33 – continued from previous page\nLabelNameTypeDescription\nServicearea\n(lines)\nOUTPUT_LINES[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line layer for the service\narea. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nServicearea\n(boundary nodes)\nOUTPUT[vector: point]\nDefault:[Skip\noutput]\nSpecify the output point layer for the ser-\nvice area boundary nodes. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nDirection field\nOptional\nDIREC-\nTION_FIELD\n[tablefield: string]\nDefault: 0.0\nThe field used to specify directions for the\nnetwork edges.\nThe values used in this field are specified\nwith the three parametersValue  for\nforward  direction,Value  for\nbackward  directionandValue\nfor both directions. Forward and\nreverse directions correspond to a one-way\nedge, “both directions” indicates a two-way\nedge. If a feature does not have a value in\nthis field, or no field is set then the default\ndirection setting (provided with theDe-\nfault directionparameter) is used.\nValue for forward\ndirection\nOptional\nVALUE_FORWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a forward direction\nValue for back-\nward direction\nOptional\nVALUE_BACKWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a backward direction\nValue for both di-\nrections\nOptional\nVALUE_BOTH[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nbidirectional edges\nDefault directionDE-\nFAULT_DIRECTION\n[enumeration]\nDefault: 2\nIf a feature has no value set in the direction\nfield or if no direction field is set, then this\ndirection value is used. One of:\n•0 — Forward direction\n•1 — Backward direction\n•2 — Both directions\ncontinues on next page\n25.1. QGIS algorithm provider915\n\nQGIS Desktop 3.22 User Guide\nTable 25.34 – continued from previous page\nLabelNameTypeDescription\nSpeed field\nOptional\nSPEED_FIELD[tablefield: string]Field providing the speed value (inkm/h)\nfor the edges of the network when looking\nfor the fastest path.\nIf a feature does not have a value in this\nfield, or no field is set then the default\nspeed value (provided with theDefault\nspeedparameter) is used.\nDefault    speed\n(km/h)\nDEFAULT_SPEED[number]\nDefault: 50.0\nValue to use to calculate the travel time if\nno speed field is provided for an edge\nTopology   toler-\nance\nTOLERANCE[number]\nDefault: 0.0\nTwo lines with nodes closer than the speci-\nfied tolerance are considered connected\nIncludeup-\nper/lower  bound\npoints\nIN-\nCLUDE_BOUNDS\n[boolean]\nDefault: False\nCreates a point layer output with two points\nfor each edge at the boundaries of the ser-\nvice area. One point is the start of that edge,\nthe other is the end.\nOutputs\nLabelNameTypeDescription\nServicearea\n(boundary nodes)\nOUTPUT[vector: point]The output point layer with the service area\nboundary nodes.\nServicearea\n(lines)\nOUTPUT_LINES[vector: line]Line layer representing the parts of the net-\nwork that can be serviced by the start point,\nfor the given cost.\nPython code\nAlgorithm ID:native:serviceareafrompoint\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nShortest path (layer to point)\nComputes the optimal (shortest or fastest) routes from multiple start points defined by a vector layer and a given end\npoint.\n916Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nVector layer repre-\nsenting network\nINPUT[vector: line]Line vector layer representing the network\nto be covered\nPath type to calcu-\nlate\nSTRATEGY[enumeration]\nDefault: 0\nThe type of path to calculate. One of:\n•0 — Shortest\n•1 — Fastest\nVector layer with\nstart points\nSTART_POINTS[vector: point]Point vector layer whose features are used\nas start points of the routes\nEnd point (x, y)END_POINT[coordinates]Point feature representing the end point of\nthe routes\nShortest pathOUTPUT[vector: line]Specify the output line layer for the shortest\npaths. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nDirection field\nOptional\nDIREC-\nTION_FIELD\n[tablefield: string]\nDefault: 0.0\nThe field used to specify directions for the\nnetwork edges.\nThe values used in this field are specified\nwith the three parametersValue  for\nforward  direction,Value  for\nbackward  directionandValue\nfor both directions. Forward and\nreverse directions correspond to a one-way\nedge, “both directions” indicates a two-way\nedge. If a feature does not have a value in\nthis field, or no field is set then the default\ndirection setting (provided with theDe-\nfault directionparameter) is used.\nValue for forward\ndirection\nOptional\nVALUE_FORWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a forward direction\nValue for back-\nward direction\nOptional\nVALUE_BACKWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a backward direction\nValue for both di-\nrections\nOptional\nVALUE_BOTH[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nbidirectional edges\ncontinues on next page\n25.1. QGIS algorithm provider917\n\nQGIS Desktop 3.22 User Guide\nTable 25.36 – continued from previous page\nLabelNameTypeDescription\nDefault directionDE-\nFAULT_DIRECTION\n[enumeration]\nDefault: 2\nIf a feature has no value set in the direction\nfield or if no direction field is set, then this\ndirection value is used. One of:\n•0 — Forward direction\n•1 — Backward direction\n•2 — Both directions\nSpeed field\nOptional\nSPEED_FIELD[tablefield: string]Field providing the speed value (inkm/h)\nfor the edges of the network when looking\nfor the fastest path.\nIf a feature does not have a value in this\nfield, or no field is set then the default\nspeed value (provided with theDefault\nspeedparameter) is used.\nDefault    speed\n(km/h)\nDEFAULT_SPEED[number]\nDefault: 50.0\nValue to use to calculate the travel time if\nno speed field is provided for an edge\nTopology   toler-\nance\nTOLERANCE[number]\nDefault: 0.0\nTwo lines with nodes closer than the speci-\nfied tolerance are considered connected\nOutputs\nLabelNameTypeDescription\nShortest pathOUTPUT[vector: line]Line layer of the shortest or fastest path\nfrom each of the start points to the end point\nPython code\nAlgorithm ID:native:shortestpathlayertopoint\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n918Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nShortest path (point to layer)\nComputes the optimal (shortest or fastest) routes between a given start point and multiple end points defined by a\npoint vector layer.\nParameters\nBasic parameters\nLabelNameTypeDescription\nVector layer repre-\nsenting network\nINPUT[vector: line]Line vector layer representing the network\nto be covered\nPath type to calcu-\nlate\nSTRATEGY[enumeration]\nDefault: 0\nThe type of path to calculate. One of:\n•0 — Shortest\n•1 — Fastest\nStart point (x, y)START_POINT[coordinates]Point feature representing the start point of\nthe routes\nVector layer with\nend points\nEND_POINTS[vector: point]Point vector layer whose features are used\nas end points of the routes\nShortest pathOUTPUT[vector: line]Specify the output line layer for the shortest\npaths. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nDirection field\nOptional\nDIREC-\nTION_FIELD\n[tablefield: string]\nDefault: 0.0\nThe field used to specify directions for the\nnetwork edges.\nThe values used in this field are specified\nwith the three parametersValue  for\nforward  direction,Value  for\nbackward  directionandValue\nfor both directions. Forward and\nreverse directions correspond to a one-way\nedge, “both directions” indicates a two-way\nedge. If a feature does not have a value in\nthis field, or no field is set then the default\ndirection setting (provided with theDe-\nfault directionparameter) is used.\nValue for forward\ndirection\nOptional\nVALUE_FORWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a forward direction\nValue for back-\nward direction\nOptional\nVALUE_BACKWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a backward direction\ncontinues on next page\n25.1. QGIS algorithm provider919\n\nQGIS Desktop 3.22 User Guide\nTable 25.38 – continued from previous page\nLabelNameTypeDescription\nValue for both di-\nrections\nOptional\nVALUE_BOTH[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nbidirectional edges\nDefault directionDE-\nFAULT_DIRECTION\n[enumeration]\nDefault: 2\nIf a feature has no value set in the direction\nfield or if no direction field is set, then this\ndirection value is used. One of:\n•0 — Forward direction\n•1 — Backward direction\n•2 — Both directions\nSpeed field\nOptional\nSPEED_FIELD[tablefield: string]Field providing the speed value (inkm/h)\nfor the edges of the network when looking\nfor the fastest path.\nIf a feature does not have a value in this\nfield, or no field is set then the default\nspeed value (provided with theDefault\nspeedparameter) is used.\nDefault    speed\n(km/h)\nDEFAULT_SPEED[number]\nDefault: 50.0\nValue to use to calculate the travel time if\nno speed field is provided for an edge\nTopology   toler-\nance\nTOLERANCE[number]\nDefault: 0.0\nTwo lines with nodes closer than the speci-\nfied tolerance are considered connected\nOutputs\nLabelNameTypeDescription\nShortest pathOUTPUT[vector: line]Line layer of the shortest or fastest path\nfrom each of the start points to the end point\nPython code\nAlgorithm ID:native:shortestpathpointtolayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nShortest path (point to point)\nComputes the optimal (shortest or fastest) route between a given start point and a given end point.\n920Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nVector layer repre-\nsenting network\nINPUT[vector: line]Line vector layer representing the network\nto be covered\nPath type to calcu-\nlate\nSTRATEGY[enumeration]\nDefault: 0\nThe type of path to calculate. One of:\n•0 — Shortest\n•1 — Fastest\nStart point (x, y)START_POINT[coordinates]Point feature representing the start point of\nthe routes\nEnd point (x, y)END_POINT[coordinates]Point feature representing the end point of\nthe routes\nShortest pathOUTPUT[vector: line]Specify the output line layer for the shortest\npaths. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nDirection field\nOptional\nDIREC-\nTION_FIELD\n[tablefield: string]\nDefault: 0.0\nThe field used to specify directions for the\nnetwork edges.\nThe values used in this field are specified\nwith the three parametersValue  for\nforward  direction,Value  for\nbackward  directionandValue\nfor both directions. Forward and\nreverse directions correspond to a one-way\nedge, “both directions” indicates a two-way\nedge. If a feature does not have a value in\nthis field, or no field is set then the default\ndirection setting (provided with theDe-\nfault directionparameter) is used.\nValue for forward\ndirection\nOptional\nVALUE_FORWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a forward direction\nValue for back-\nward direction\nOptional\nVALUE_BACKWARD[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nedges with a backward direction\nValue for both di-\nrections\nOptional\nVALUE_BOTH[string]\nDefault:  ‘’ (empty\nstring)\nValue set in the direction field to identify\nbidirectional edges\ncontinues on next page\n25.1. QGIS algorithm provider921\n\nQGIS Desktop 3.22 User Guide\nTable 25.40 – continued from previous page\nLabelNameTypeDescription\nDefault directionDE-\nFAULT_DIRECTION\n[enumeration]\nDefault: 2\nIf a feature has no value set in the direction\nfield or if no direction field is set, then this\ndirection value is used. One of:\n•0 — Forward direction\n•1 — Backward direction\n•2 — Both directions\nSpeed field\nOptional\nSPEED_FIELD[tablefield: string]Field providing the speed value (inkm/h)\nfor the edges of the network when looking\nfor the fastest path.\nIf a feature does not have a value in this\nfield, or no field is set then the default\nspeed value (provided with theDefault\nspeedparameter) is used.\nDefault    speed\n(km/h)\nDEFAULT_SPEED[number]\nDefault: 50.0\nValue to use to calculate the travel time if\nno speed field is provided for an edge\nTopology   toler-\nance\nTOLERANCE[number]\nDefault: 0.0\nTwo lines with nodes closer than the speci-\nfied tolerance are considered connected\nOutputs\nLabelNameTypeDescription\nShortest pathOUTPUT[vector: line]Line layer of the shortest or fastest path\nfrom each of the start point to the end point\nPython code\nAlgorithm ID:native:shortestpathpointtopoint\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.10Plots\nBar plot\nCreates a bar plot from a category and a layer field.\n922Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nCategory   field\nname\nNAME_FIELD[tablefield: any]Categorical field to use for grouping the\nbars (X axis)\nValue fieldVALUE_FIELD[tablefield: any]Value to use for the plot (Y axis).\nBar plotOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nBar plotOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:barplot\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nBox plot\nCreates a box plot from a category field and a numerical layer field.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nCategory   name\nfield\nNAME_FIELD[tablefield: any]Categorical field to use for grouping the\nboxes (X axis)\nValue fieldVALUE_FIELD[tablefield: any]Value to use for the plot (Y axis).\nAdditional statis-\ntic lines\nMSD[enumeration]\nDefault: 0\nAdditional statistics information to add to\nthe plot. One of:\n•0 — Show Mean\n•1 — Show Standard Deviation\n•2 — Don’t show mean and standard\ndeviation\ncontinues on next page\n25.1. QGIS algorithm provider923\n\nQGIS Desktop 3.22 User Guide\nTable 25.41 – continued from previous page\nLabelNameTypeDescription\nBox plotOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nBox plotOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:boxplot\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMean and standard deviation plot\nCreates a box plot with mean and standard deviation values.\nParameters\nLabelNameTypeDescription\nInput tableINPUT[vector: any]Input vector layer\nCategory   name\nfield\nNAME_FIELD[tablefield: any]Categorical field to use for grouping the\nboxes (X axis)\nValue fieldVALUE_FIELD[tablefield: any]Value to use for the plot (Y axis).\nPlotOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nPlotOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\n924Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:meanandstandarddeviationplot\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPolar plot\nGenerates a polar plot based on the value of an input vector layer.\nTwo fields must be entered as parameters: one that defines the category each feature (to group features) and another\none with the variable to plot (this has to be a numeric one).\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nCategory   name\nfield\nNAME_FIELD[tablefield: any]Categorical field to use for grouping the fea-\ntures (X axis)\nValue fieldVALUE_FIELD[tablefield: any]Value to use for the plot (Y axis).\nPolar plotOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nPolar plotOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:polarplot\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider925\n\nQGIS Desktop 3.22 User Guide\nRaster layer histogram\nGenerates a histogram with the values of a raster layer.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nBand numberBAND[raster band]Raster band to use for the histogram\nnumber of binsBINS[number]\nDefault: 10\nThe number of bins to use in the histogram\n(X axis). Minimum 2.\nHistogramOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nHistogramOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:rasterlayerhistogram\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nVector layer histogram\nGenerates a histogram with the values of the attribute of a vector layer.\nThe attribute to use for computing the histogram must be numeric.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nAttributeFIELD[tablefield: any]Value to use for the plot (Y axis).\nnumber of binsBINS[number]\nDefault: 10\nThe number of bins to use in the histogram\n(X axis). Minimum 2.\nHistogramOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\n926Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nHistogramOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:vectorlayerhistogram\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nVector layer scatterplot\nCreates a simpleX-Yscatter plot for a vector layer.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nX attributeXFIELD[tablefield: any]Field to use for the X axis\nY attributeYFIELD[tablefield: any]Field to use for the Y axis\nScatterplotOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nScatterplotOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:vectorlayerscatterplot\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider927\n\nQGIS Desktop 3.22 User Guide\nVector layer scatterplot 3D\nCreates a 3D scatter plot for a vector layer.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nX attributeXFIELD[tablefield: any]Field to use for the X axis\nY attributeYFIELD[tablefield: any]Field to use for the Y axis\nZ attributeZFIELD[tablefield: any]Field to use for the Z axis\nHistogramOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for the plot. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nHistogramOUTPUT[html]HTML file with the plot. Available in the\nProcessing►Result Viewer.\nPython code\nAlgorithm ID:qgis:scatter3dplot\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.11Raster analysis\nCell stack percent rank from value\nCalculates the cell-wise percentrank value of a stack of rasters based on a single input value and writes them to an\noutput raster.\nAt each cell location, the specified value is ranked among the respective values in the stack of all overlaid and sorted\ncell values from the input rasters. For values outside of the stack value distribution, the algorithm returns NoData\nbecause the value cannot be ranked among the cell values.\nThere are two methods for percentile calculation:\n•Inclusive linear interpolation (PERCENTRANK.INC)\n•Exclusive linear interpolation (PERCENTRANK.EXC)\nThe linear interpolation method return the unique percent rank for different values. Both interpolation methods follow\ntheir counterpart methods implemented by\nLibreOfficeor Microsoft Excel.\nThe output raster’s extent and resolution is defined by a reference raster. Input raster layers that do not match the cell\nsize of the reference raster layer will be resampled using nearest neighbor resampling. NoData values in any of the\n928Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\ninput layers will result in a NoData cell output if the “Ignore NoData values” parameter is not set. The output raster\ndata type will always beFloat32.\nFig. 25.10: Percent ranking Value = 1.NoDatacells (grey) are ignored.\nSee also:\nCell stack percentile,Cell stack percentrank from raster layer\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]Raster layers to evaluate.  If multiband\nrasters are used in the data raster stack, the\nalgorithm will always perform the analysis\non the first band of the rasters\nMethodMETHOD[enumeration]\nDefault: 0\nMethod for percentile calculation:\n•0 — Inclusive linear interpolation\n(PERCENTRANK.INC)\n•1 — Exclusive linear interpolation\n(PERCENTRANK.EXC)\nValueVALUE[number]\nDefault: 10.0\nValue to rank among the respective values\nin the stack of all overlaid and sorted cell\nvalues from the input rasters\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: True\nIf unchecked, any NoData cells in the in-\nput layers will result in a NoData cell in the\noutput raster\nReference layerREFER-\nENCE_LAYER\n[raster]The reference layer for the output layer cre-\nation (extent, CRS, pixel dimensions)\ncontinues on next page\n25.1. QGIS algorithm provider929\n\nQGIS Desktop 3.22 User Guide\nTable 25.42 – continued from previous page\nLabelNameTypeDescription\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOUT-\nPUT_NODATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:cellstackpercentrankfromvalue\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCell stack percentile\nCalculates the cell-wise percentile value of a stack of rasters and writes the results to an output raster. The percentile\nto return is determined by the percentile input value (ranges between 0 and 1). At each cell location, the specified\npercentile is obtained using the respective value from the stack of all overlaid and sorted cell values of the input\nrasters.\nThere are three methods for percentile calculation:\n•Nearest rank: returns the value that is nearest to the specified percentile\n•Inclusive linear interpolation (PERCENTRANK.INC)\n•Exclusive linear interpolation (PERCENTRANK.EXC)\n930Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nThe linear interpolation methods return the unique values for different percentiles. Both interpolation methods follow\ntheir counterpart methods implemented byLibreOfficeor Microsoft Excel.\nThe output raster’s extent and resolution is defined by a reference raster. Input raster layers that do not match the cell\nsize of the reference raster layer will be resampled using nearest neighbor resampling. NoData values in any of the\ninput layers will result in a NoData cell output if the “Ignore NoData values” parameter is not set. The output raster\ndata type will always beFloat32.\nFig. 25.11: Percentile = 0.25.NoDatacells (grey) are ignored.\nSee also:\nCell stack percentile,Cell stack percentrank from raster layer\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]Raster layers to evaluate.  If multiband\nrasters are used in the data raster stack, the\nalgorithm will always perform the analysis\non the first band of the rasters\nMethodMETHOD[enumeration]\nDefault: 0\nMethod for percentile calculation:\n•0 — Nearest rank: returns the value\nthat is nearest to the specified per-\ncentile\n•1 — Inclusive linear interpolation\n(PERCENTILE.INC)\n•2 — Exclusive linear interpolation\n(PERCENTILE.EXC)\ncontinues on next page\n25.1. QGIS algorithm provider931\n\nQGIS Desktop 3.22 User Guide\nTable 25.44 – continued from previous page\nLabelNameTypeDescription\nPercentileVALUE[number]\nDefault: 0.25\nValue to rank among the respective values\nin the stack of all overlaid and sorted cell\nvalues from the input rasters. Between 0\nand 1.\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: True\nIf unchecked, any NoData cells in the in-\nput layers will result in a NoData cell in the\noutput raster\nReference layerREFER-\nENCE_LAYER\n[raster]The reference layer for the output layer cre-\nation (extent, CRS, pixel dimensions)\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOUT-\nPUT_NODATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:cellstackpercentile\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n932Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nCell stack percentrank from raster layer\nCalculates the cell-wise percentrank value of a stack of rasters based on an input value raster and writes them to an\noutput raster.\nAt each cell location, the current value of the value raster is ranked among the respective values in the stack of all\noverlaid and sorted cell values of the input rasters. For values outside of the the stack value distribution, the algorithm\nreturns NoData because the value cannot be ranked among the cell values.\nThere are two methods for percentile calculation:\n•Inclusive linear interpolation (PERCENTRANK.INC)\n•Exclusive linear interpolation (PERCENTRANK.EXC)\nThe linear interpolation methods return the unique values for different percentiles. Both interpolation methods follow\ntheir counterpart methods implemented byLibreOfficeor Microsoft Excel.\nThe output raster’s extent and resolution is defined by a reference raster. Input raster layers that do not match the cell\nsize of the reference raster layer will be resampled using nearest neighbor resampling. NoData values in any of the\ninput layers will result in a NoData cell output if the “Ignore NoData values” parameter is not set. The output raster\ndata type will always beFloat32.\nFig. 25.12: Ranking the value raster layer cells.NoDatacells (grey) are ignored.\nSee also:\nCell stack percentile,Cell stack percent rank from value\n25.1. QGIS algorithm provider933\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]Raster layers to evaluate.  If multiband\nrasters are used in the data raster stack, the\nalgorithm will always perform the analysis\non the first band of the rasters\nValue raster layerIN-\nPUT_VALUE_RASTER\n[raster]The layer to rank the values among the stack\nof all overlaid layers\nValue raster bandVALUE_RASTER_BAND[integer]\nDefault: 1\nBand of the “value raster layer” to compare\nto\nMethodMETHOD[enumeration]\nDefault: 0\nMethod for percentile calculation:\n•0 — Inclusive linear interpolation\n(PERCENTRANK.INC)\n•1 — Exclusive linear interpolation\n(PERCENTRANK.EXC)\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: True\nIf unchecked, any NoData cells in the in-\nput layers will result in a NoData cell in the\noutput raster\nReference layerREFER-\nENCE_LAYER\n[raster]The reference layer for the output layer cre-\nation (extent, CRS, pixel dimensions)\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOUT-\nPUT_NODATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\n934Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:cellstackpercentrankfromrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCell statistics\nComputes per-cell statistics based on input raster layers and for each cell writes the resulting statistics to an output\nraster. At each cell location, the output value is defined as a function of all overlaid cell values of the input rasters.\nBy default, a NoData cell in ANY of the input layers will result in a NoData cell in the output raster. If theIgnore\nNoData valuesoption is checked, then NoData inputs will be ignored in the statistic calculation. This may result in\nNoData output for locations where all cells are NoData.\nTheReference layerparameter specifies an existing raster layer to use as a reference when creating the output raster.\nThe output raster will have the same extent, CRS, and pixel dimensions as this layer.\nCalculation details:Input raster layers that do not match the cell size of the reference raster layer will be resampled\nusingnearest neighbor resampling. The output raster data type will be set to the most complex data type\npresent in the input datasets except when using the functionsMean,Standard deviationandVariance\n(data type is alwaysFloat32orFloat64depending on input float type) orCountandVariety(data type is\nalwaysInt32).\n•Count: The count statistic will always result in the number of cells without NoData values at the current cell\nlocation.\n•Median: If the number of input layers is even, the median will be calculated as the arithmetic mean of the\ntwo middle values of the ordered cell input values.\n•Minority/Majority: If no unique minority or majority could be found, the result is NoData, except all\ninput cell values are equal.\n25.1. QGIS algorithm provider935\n\nQGIS Desktop 3.22 User Guide\nFig. 25.13: Example with all the statistic functions.NoDatacells (grey) are taken into account.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]Input raster layers\nStatisticSTATISTIC[enumeration]\nDefault: 0\nAvailable statistics. Options:\n•0 — Sum\n•1 — Count\n•2 — Mean\n•3 — Median\n•4 — Standard deviation\n•5 — Variance\n•6 — Minimum\n•7 — Maximum\n•8 — Minority (least common value)\n•9 — Majority (most common value)\n•10 — Range (max - min)\n•11 — Variety (unique value count)\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: True\nCalculate statistics also for all cells stacks,\nignoring NoData occurrence.\nReference layerREF_LAYER[raster]The reference layer to create the output\nlayer from (extent, CRS, pixel dimensions)\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n936Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOptional\nOUT-\nPUT_NO_DATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nOutput rasterOUTPUT[raster]Output raster layer containing the result\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nPython code\nAlgorithm ID:native:cellstatistics\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nEqual to frequency\nEvaluates on a cell-by-cell basis the frequency (number of times) the values of an input stack of rasters are equal to\nthe value of a value layer. The output raster extent and resolution are defined by the input raster layer and is always\nofInt32type.\nIf multiband rasters are used in the data raster stack, the algorithm will always perform the analysis on the first band\nof the rasters - use GDAL to use other bands in the analysis. The output NoData value can be set manually.\n25.1. QGIS algorithm provider937\n\nQGIS Desktop 3.22 User Guide\nFig. 25.14: For each cell in the output raster, the value represents the number of times that the corresponding cells\nin the list of rasters are the same as the value raster.NoDatacells (grey) are taken into account.\nSee also:\nGreater than frequency,Less than frequency\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput value rasterIN-\nPUT_VALUE_RASTER\n[raster]The input value layer serves as reference\nlayer for the sample layers\nValue raster bandIN-\nPUT_VALUE_RASTER_BAND\n[raster band]\nDefault:  The first\nband of the raster\nlayer\nSelect the band you want to use as sample\nInput raster layersINPUT_RASTERS[raster] [list]Raster layers to evaluate.  If multiband\nrasters are used in the data raster stack, the\nalgorithm will always perform the analysis\non the first band of the rasters\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: False\nIf unchecked, any NoData cells in the value\nraster or the data layer stack will result in a\nNoData cell in the output raster\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n938Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOptional\nOUT-\nPUT_NO_DATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nCount of cells with\nequal value occur-\nrences\nFOUND_LOCATIONS_COUNT[number]\nHeight in pixelsHEIGHT_IN_PIXELS[number]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nMean frequency at\nvalid cell locations\nMEAN_FREQUENCY_PER_LOCATION[number]\nCount of value oc-\ncurrences\nOCCUR-\nRENCE_COUNT\n[number]\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nPython code\nAlgorithm ID:native:equaltofrequency\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFuzzify raster (gaussian membership)\nTransforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Gaussian mem-\nbership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership\nof the defined fuzzy set, whereas a value of 1 means full membership. The gaussian membership function is defined\nas, wheref1is the spread andf2the midpoint.\n25.1. QGIS algorithm provider939\n\nQGIS Desktop 3.22 User Guide\nFig. 25.15: Fuzzify raster example. Input raster source: Land Tirol - data.tirol.gv.at.\nSee also:\nFuzzify raster (large membership)Fuzzify raster (linear membership),Fuzzify raster (near membership),Fuzzify raster\n(power membership),Fuzzify raster (small membership)\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Input raster layer\nBand NumberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat you want to fuzzify.\nFunction   mid-\npoint\nFUZZYMIDPOINT[number]\nDefault: 10\nMidpoint of the gaussian function\nFunction spreadFUZZYSPREAD[number]\nDefault: 0.01\nSpread of the gaussian function\nFuzzified rasterOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nFuzzified rasterOUTPUT[same as input]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\n940Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:fuzzifyrastergaussianmembership\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFuzzify raster (large membership)\nTransforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Large mem-\nbership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership\nof the defined fuzzy set, whereas a value of 1 means full membership. The large membership function is defined as\n, wheref1is the spread andf2the midpoint.\nSee also:\nFuzzify raster (gaussian membership),Fuzzify raster (linear membership),Fuzzify raster (near membership),Fuzzify\nraster (power membership),Fuzzify raster (small membership)\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Input raster layer\nBand NumberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat you want to fuzzify.\nFunction   mid-\npoint\nFUZZYMIDPOINT[number]\nDefault: 50\nMidpoint of the large function\nFunction spreadFUZZYSPREAD[number]\nDefault: 5\nSpread of the large function\nFuzzified rasterOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nFuzzified rasterOUTPUT[same as input]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\n25.1. QGIS algorithm provider941\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:fuzzifyrasterlargemembership\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFuzzify raster (linear membership)\nTransforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Linear mem-\nbership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no mem-\nbership of the defined fuzzy set, whereas a value of 1 means full membership. The linear function is defined as\n, whereais the low bound andbthe high bound. This equation assigns membership values\nusing a linear transformation for pixel values between the low and high bounds. Pixels values smaller than the low\nbound are given 0 membership whereas pixel values greater than the high bound are given 1 membership.\nSee also:\nFuzzify raster (gaussian membership),Fuzzify raster (large membership),Fuzzify raster (near membership),Fuzzify\nraster (power membership),Fuzzify raster (small membership)\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Input raster layer\nBand NumberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat you want to fuzzify.\nLow fuzzy mem-\nbership bound\nFUZZYLOWBOUND[number]\nDefault: 0\nLow bound of the linear function\nHigh fuzzy mem-\nbership bound\nFUZZYHIGH-\nBOUND\n[number]\nDefault: 1\nHigh bound of the linear function\nFuzzified rasterOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n942Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nFuzzified rasterOUTPUT[same as input]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:fuzzifyrasterlinearmembership\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFuzzify raster (near membership)\nTransforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Near mem-\nbership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership\nof the defined fuzzy set, whereas a value of 1 means full membership. The near membership function is defined as\n, wheref1is the spread andf2the midpoint.\nSee also:\nFuzzify raster (gaussian membership),Fuzzify raster (large membership),Fuzzify raster (linear membership),Fuzzify\nraster (power membership),Fuzzify raster (small membership)\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Input raster layer\nBand NumberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat you want to fuzzify.\nFunction   mid-\npoint\nFUZZYMIDPOINT[number]\nDefault: 50\nMidpoint of the near function\nFunction spreadFUZZYSPREAD[number]\nDefault: 0.01\nSpread of the near function\nFuzzified rasterOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n25.1. QGIS algorithm provider943\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nFuzzified rasterOUTPUT[same as input]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:fuzzifyrasternearmembership\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFuzzify raster (power membership)\nTransforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Power mem-\nbership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no mem-\nbership of the defined fuzzy set, whereas a value of 1 means full membership. The power function is defined as\n, whereais the low bound,bis the high bound, andf1the exponent. This equation assigns\nmembership values using the power transformation for pixel values between the low and high bounds. Pixels values\nsmaller than the low bound are given 0 membership whereas pixel values greater than the high bound are given 1\nmembership.\nSee also:\nFuzzify raster (gaussian membership),Fuzzify raster (large membership),Fuzzify raster (linear membership),Fuzzify\nraster (near membership),Fuzzify raster (small membership)\n944Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Input raster layer\nBand NumberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat you want to fuzzify.\nLow fuzzy mem-\nbership bound\nFUZZYLOWBOUND[number]\nDefault: 0\nLow bound of the power function\nHigh fuzzy mem-\nbership bound\nFUZZYHIGH-\nBOUND\n[number]\nDefault: 1\nHigh bound of the power function\nHigh fuzzy mem-\nbership bound\nFUZZYEXPONENT[number]\nDefault: 2\nExponent of the power function\nFuzzified rasterOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nFuzzified rasterOUTPUT[same as input]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:fuzzifyrasterpowermembership\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider945\n\nQGIS Desktop 3.22 User Guide\nFuzzify raster (small membership)\nTransforms an input raster to a fuzzified raster by assigning a membership value to each pixel, using a Small mem-\nbership function. Membership values range from 0 to 1. In the fuzzified raster, a value of 0 implies no membership\nof the defined fuzzy set, whereas a value of 1 means full membership. The small membership function is defined as\n, wheref1is the spread andf2the midpoint.\nSee also:\nFuzzify raster (gaussian membership),Fuzzify raster (large membership)Fuzzify raster (linear membership),Fuzzify\nraster (near membership),Fuzzify raster (power membership)\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Input raster layer\nBand NumberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat you want to fuzzify.\nFunction   mid-\npoint\nFUZZYMIDPOINT[number]\nDefault: 50\nMidpoint of the small function\nFunction spreadFUZZYSPREAD[number]\nDefault: 5\nSpread of the small function\nFuzzified rasterOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nFuzzified rasterOUTPUT[same as input]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\n946Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:fuzzifyrastersmallmembership\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGreater than frequency\nEvaluates on a cell-by-cell basis the frequency (number of times) the values of an input stack of rasters are equal to\nthe value of a value raster. The output raster extent and resolution is defined by the input raster layer and is always\nofInt32type.\nIf multiband rasters are used in the data raster stack, the algorithm will always perform the analysis on the first band\nof the rasters - use GDAL to use other bands in the analysis. The output NoData value can be set manually.\nFig. 25.16: For each cell in the output raster, the value represents the number of times that the corresponding cells\nin the list of rasters are greater than the value raster.NoDatacells (grey) are taken into account.\nSee also:\nEqual to frequency,Less than frequency\n25.1. QGIS algorithm provider947\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput value rasterIN-\nPUT_VALUE_RASTER\n[raster]The input value layer serves as reference\nlayer for the sample layers\nValue raster bandIN-\nPUT_VALUE_RASTER_BAND\n[raster band]\nDefault:  The first\nband of the raster\nlayer\nSelect the band you want to use as sample\nInput raster layersINPUT_RASTERS[raster] [list]Raster layers to evaluate.  If multiband\nrasters are used in the data raster stack, the\nalgorithm will always perform the analysis\non the first band of the rasters\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: False\nIf unchecked, any NoData cells in the value\nraster or the data layer stack will result in a\nNoData cell in the output raster\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOptional\nOUT-\nPUT_NO_DATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nCount of cells with\nequal value occur-\nrences\nFOUND_LOCATIONS_COUNT[number]\nHeight in pixelsHEIGHT_IN_PIXELS[number]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nMean frequency at\nvalid cell locations\nMEAN_FREQUENCY_PER_LOCATION[number]\nCount of value oc-\ncurrences\nOCCUR-\nRENCE_COUNT\n[number]\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\n948Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:greaterthanfrequency\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nHighest position in raster stack\nEvaluates on a cell-by-cell basis the position of the raster with the highest value in a stack of rasters. Position counts\nstart with 1 and range to the total number of input rasters. The order of the input rasters is relevant for the algorithm.\nIf multiple rasters feature the highest value, the first raster will be used for the position value.\nIf multiband rasters are used in the data raster stack, the algorithm will always perform the analysis on the first band\nof the rasters - use GDAL to use other bands in the analysis. Any NoData cells in the raster layer stack will result in\na NoData cell in the output raster unless the “ignore NoData” parameter is checked. The output NoData value can be\nset manually. The output rasters extent and resolution is defined by a reference raster layer and is always ofInt32\ntype.\nSee also:\nLowest position in raster stack\n25.1. QGIS algorithm provider949\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput raster layersINPUT_RASTERS[raster] [list]List of raster layers to compare with\nReference layerREFER-\nENCE_LAYER\n[raster]The reference layer for the output layer cre-\nation (extent, CRS, pixel dimensions)\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: False\nIf unchecked, any NoData cells in the data\nlayer stack will result in a NoData cell in the\noutput raster\nOutput layerOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster containing\nthe result. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOUT-\nPUT_NODATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:highestpositioninrasterstack\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n950Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nLess than frequency\nEvaluates on a cell-by-cell basis the frequency (number of times) the values of an input stack of rasters are less than\nthe value of a value raster. The output raster extent and resolution is defined by the input raster layer and is always\nof\nInt32\ntype.\nIf multiband rasters are used in the data raster stack, the algorithm will always perform the analysis on the first band\nof the rasters - use GDAL to use other bands in the analysis. The output NoData value can be set manually.\nFig. 25.17: For each cell in the output raster, the value represents the number of times that the corresponding cells\nin the list of rasters are less than the value raster.NoDatacells (grey) are taken into account.\nSee also:\nEqual to frequency,Greater than frequency\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput value rasterIN-\nPUT_VALUE_RASTER\n[raster]The input value layer serves as reference\nlayer for the sample layers\nValue raster bandIN-\nPUT_VALUE_RASTER_BAND\n[raster band]\nDefault:  The first\nband of the raster\nlayer\nSelect the band you want to use as sample\nInput raster layersINPUT_RASTERS[raster] [list]Raster layers to evaluate.  If multiband\nrasters are used in the data raster stack, the\nalgorithm will always perform the analysis\non the first band of the rasters\ncontinues on next page\n25.1. QGIS algorithm provider951\n\nQGIS Desktop 3.22 User Guide\nTable 25.56 – continued from previous page\nLabelNameTypeDescription\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: False\nIf unchecked, any NoData cells in the value\nraster or the data layer stack will result in a\nNoData cell in the output raster\nOutput layerOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOptional\nOUT-\nPUT_NO_DATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nCount of cells with\nequal value occur-\nrences\nFOUND_LOCATIONS_COUNT[number]\nHeight in pixelsHEIGHT_IN_PIXELS[number]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nMean frequency at\nvalid cell locations\nMEAN_FREQUENCY_PER_LOCATION[number]\nCount of value oc-\ncurrences\nOCCUR-\nRENCE_COUNT\n[number]\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nPython code\nAlgorithm ID:native:lessthanfrequency\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n952Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nLowest position in raster stack\nEvaluates on a cell-by-cell basis the position of the raster with the lowest value in a stack of rasters. Position counts\nstart with 1 and range to the total number of input rasters. The order of the input rasters is relevant for the algorithm.\nIf multiple rasters feature the lowest value, the first raster will be used for the position value.\nIf multiband rasters are used in the data raster stack, the algorithm will always perform the analysis on the first band\nof the rasters - use GDAL to use other bands in the analysis. Any NoData cells in the raster layer stack will result in\na NoData cell in the output raster unless the “ignore NoData” parameter is checked. The output NoData value can be\nset manually. The output rasters extent and resolution is defined by a reference raster layer and is always ofInt32\ntype.\nSee also:\nHighest position in raster stack\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput raster layersINPUT_RASTERS[raster] [list]List of raster layers to compare with\nReference layerREFER-\nENCE_LAYER\n[raster]The reference layer for the output layer cre-\nation (extent, CRS, pixel dimensions)\nIgnore   NoData\nvalues\nIGNORE_NODATA[boolean]\nDefault: False\nIf unchecked, any NoData cells in the data\nlayer stack will result in a NoData cell in the\noutput raster\nOutput layerOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster containing\nthe result. One of:\n•Save to a Temporary File\n•Save to File...\n25.1. QGIS algorithm provider953\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nOUT-\nPUT_NODATA_VALUE\n[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer containing the result\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nPython code\nAlgorithm ID:native:lowestpositioninrasterstack\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster boolean AND\nCalculates the booleanANDfor a set of input rasters. If all of the input rasters have a non-zero value for a pixel, that\npixel will be set to1in the output raster. If any of the input rasters have0values for the pixel it will be set to0in\nthe output raster.\nThe reference layer parameter specifies an existing raster layer to use as a reference when creating the output raster.\nThe output raster will have the same extent, CRS, and pixel dimensions as this layer.\nBy default, a nodata pixel in ANY of the input layers will result in a nodata pixel in the output raster. If theTreat\nnodata values as falseoption is checked, then nodata inputs will be treated the same as a0input value.\nSee also:\nRaster boolean OR\n954Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]List of input raster layers\nReference layerREF_LAYER[raster]The reference layer to create the output\nlayer from (extent, CRS, pixel dimensions)\nTreat nodata val-\nues as false\nNO-\nDATA_AS_FALSE\n[boolean]\nDefault: False\nTreat nodata values in the input files as 0\nwhen performing the operation\nOutput layerOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster containing\nthe result. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nNO_DATA[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nOutput raster data type. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — Int32\n•4 — UInt32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nExtentEXTENT[string]The spatial extent of the output raster layer\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nNODATA  pixel\ncount\nNO-\nDATA_PIXEL_COUNT\n[integer]The count of nodata pixels in the output\nraster layer\nTrue pixel countTRUE_PIXEL_COUNT[integer]The count of True pixels (value = 1) in the\noutput raster layer\ncontinues on next page\n25.1. QGIS algorithm provider955\n\nQGIS Desktop 3.22 User Guide\nTable 25.62 – continued from previous page\nLabelNameTypeDescription\nFalse pixel countFALSE_PIXEL_COUNT[integer]The count of False pixels (value = 0) in the\noutput raster layer\nOutput layerOUTPUT[raster]Output raster layer containing the result\nPython code\nAlgorithm ID:native:rasterbooleanand\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster boolean OR\nCalculates the booleanORfor a set of input rasters. If all of the input rasters have a zero value for a pixel, that pixel\nwill be set to0in the output raster. If any of the input rasters have1values for the pixel it will be set to1in the\noutput raster.\nThe reference layer parameter specifies an existing raster layer to use as a reference when creating the output raster.\nThe output raster will have the same extent, CRS, and pixel dimensions as this layer.\nBy default, a nodata pixel in ANY of the input layers will result in a nodata pixel in the output raster. If theTreat\nnodata values as falseoption is checked, then nodata inputs will be treated the same as a0input value.\nSee also:\nRaster boolean AND\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]List of input raster layers\nReference layerREF_LAYER[raster]The reference layer to create the output\nlayer from (extent, CRS, pixel dimensions)\nTreat nodata val-\nues as false\nNO-\nDATA_AS_FALSE\n[boolean]\nDefault: False\nTreat nodata values in the input files as 0\nwhen performing the operation\nOutput layerOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster containing\nthe result. One of:\n•Save to a Temporary File\n•Save to File...\n956Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nNO_DATA[number]\nDefault: -9999.0\nValue to use for nodata in the output layer\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nOutput raster data type. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — Int32\n•4 — UInt32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nExtentEXTENT[string]The spatial extent of the output raster layer\nCRS   authority\nidentifier\nCRS_AUTHID[crs]The coordinate reference system of the out-\nput raster layer\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\nNODATA  pixel\ncount\nNO-\nDATA_PIXEL_COUNT\n[integer]The count of nodata pixels in the output\nraster layer\nTrue pixel countTRUE_PIXEL_COUNT[integer]The count of True pixels (value = 1) in the\noutput raster layer\nFalse pixel countFALSE_PIXEL_COUNT[integer]The count of False pixels (value = 0) in the\noutput raster layer\nOutput layerOUTPUT[raster]Output raster layer containing the result\nPython code\nAlgorithm ID:native:rasterbooleanor\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider957\n\nQGIS Desktop 3.22 User Guide\nRaster calculator\nPerforms algebraic operations using raster layers.\nThe resulting layer will have its values computed according to an expression. The expression can contain numerical\nvalues, operators and references to any of the layers in the current project.\nNote:When using the calculator inThe batch processing interfaceor from theQGIS Python consolethe files to use\nhave to be specified. The corresponding layers are referred using the base name of the file (without the full path).\nFor instance, if using a layer atpath/to/my/rasterfile.tif, the first band of that layer will be referred as\nrasterfile.tif@1.\nSee also:\nRaster Calculator\nParameters\nLabelNameTypeDescription\nLayersGUI onlyShows the list of all raster layers loaded\nin the legend.  These can be used to\nfill the expression box (double click to\nadd).   Raster layers are referred by\ntheir name and the number of the band:\nlayer_name@band_number. For in-\nstance, the first band from a layer named\nDEMwill be referred asDEM@1.\nOperatorsGUI onlyContains some calculator like buttons that\ncan be used to fill the expression box.\nExpressionEXPRESSION[string]Expression that will be used to calculate the\noutput raster layer. You can use the opera-\ntor buttons provided to type directly the ex-\npression in this box.\nPredefined expres-\nsions\nGUI onlyYou can use the predefinedNDVIexpres-\nsion or you can define new expressions for\ncalculations. TheAdd...button loads a de-\nfined expression (and lets you set the param-\neters). TheSave...button lets you define a\nnew expression.\nReference layer(s)\n(used  for  auto-\nmated    extent,\ncellsize, and CRS)\nOptional\nLAYERS[raster] [list]Layer(s) that will be used to fetch extent,\ncell size and CRS. By choosing the layer in\nthis box you avoid filling in all the other pa-\nrameters by hand. Raster layers are referred\nby their name and the number of the band:\nlayer_name@band_number. For in-\nstance, the first band from a layer named\nDEMwill be referred asDEM@1.\nCell size (use 0 or\nempty to set it au-\ntomatically)\nOptional\nCELLSIZE[number]Cell size of the output raster layer. If the\ncell size is not specified, the minimum cell\nsize of the selected reference layer(s) will\nbe used. The cell size will be the same for\nthe X and Y axes.\ncontinues on next page\n958Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.66 – continued from previous page\nLabelNameTypeDescription\nOutput extent\nOptional\nEXTENT[extent]Specify the spatial extent of the output\nraster layer. If the extent is not specified,\nthe minimum extent that covers all the se-\nlected reference layers will be used.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nOutput CRS\nOptional\nCRS[crs]CRS of the output raster layer. If the output\nCRS is not specified, the CRS of the first\nreference layer will be used.\nOutputOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[raster]Output raster file with the calculated values.\nPython code\nAlgorithm ID:qgis:rastercalculator\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster layer properties\nNEW in 3.20\nReturns basic properties of the given raster layer, including the extent, size in pixels and dimensions of pixels (in map\nunits), number of bands, and no data value.\nThis algorithm is intended for use as a means of extracting these useful properties to use as the input values to other\nalgorithms in a model - e.g. to allow to pass an existing raster’s pixel sizes over to a GDAL raster algorithm.\n25.1. QGIS algorithm provider959\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nBand number\nOptional\nBAND[raster band]\nDefault: Not set\nWhether to also return properties of a spe-\ncific band. If a band is specified, the noData\nvalue for the selected band is also returned.\nOutputs\nLabelNameTypeDescription\nNumber of bands\nin raster\nBAND_COUNT[number]The number of bands in the raster\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The raster layer extent in the CRS\nBand has a No-\nData value set\nHAS_NODATA_VALUE[Boolean]Indicates whether the raster layer has a\nvalue set for NODATA pixels in the se-\nlected band\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of columns in the raster layer\nBand    NoData\nvalue\nNODATA_VALUE[number]The value (if set) of the NoData pixels in\nthe selected band\nPixel size (height)\nin map units\nPIXEL_HEIGHT[integer]Vertical size in map units of the pixel\nPixel size (width)\nin map units\nPIXEL_WIDTH[integer]Horizontal size in map units of the pixel\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of rows in the raster layer\nMaximum    x-\ncoordinate\nX_MAX[number]\nMinimumx-\ncoordinate\nX_MIN[number]\nMaximum    y-\ncoordinate\nY_MAX[number]\nMinimumy-\ncoordinate\nY_MIN[number]\nPython code\nAlgorithm ID:native:rasterlayerproperties\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n960Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nRaster layer statistics\nCalculates basic statistics from the values in a given band of the raster layer. The output is loaded in theProcessing\n►Results viewermenu.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nBand numberBAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose the band\nyou want to get statistics for.\nStatisticsOUT-\nPUT_HTML_FILE\n[html]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nMaximum valueMAX[number]\nMean valueMEAN[number]\nMinimum valueMIN[number]\nStatisticsOUT-\nPUT_HTML_FILE\n[html]The output file contains the following infor-\nmation:\n•Analyzed file: path of the raster layer\n•Minimum value: minimum value of\nthe raster\n•Maximum value: maximum value of\nthe raster\n•Range: difference between the max-\nimum and minimum values\n•Sum: total sum of the values\n•Mean value: mean of the values\n•Standard deviation: standard devia-\ntion of the values\n•Sum of the squares:  sum of the\nsquared differences of each observa-\ntion from the overall mean\nRangeRANGE[number]\nStandard  devia-\ntion\nSTD_DEV[number]\nSumSUM[number]\nSum   of   the\nsquares\nSUM_OF_SQUARES[number]\n25.1. QGIS algorithm provider961\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:rasterlayerstatistics\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster layer unique values report\nReturns the count and area of each unique value in a given raster layer.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nBand numberBAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose the band\nyou want to get statistics for.\nUnique values re-\nport\nOUT-\nPUT_HTML_FILE\n[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nUnique values ta-\nble\nOUTPUT_TABLE[table]\nDefault:[Skip\noutput]\nSpecification of the table for unique values:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nNODATA  pixel\ncount\nNO-\nDATA_PIXEL_COUNT\n[number]The number of NODATA pixels in the out-\nput raster layer\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[integer]The count of pixels in the output raster layer\ncontinues on next page\n962Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.69 – continued from previous page\nLabelNameTypeDescription\nUnique values re-\nport\nOUT-\nPUT_HTML_FILE\n[html]The output HTML file contains the follow-\ning information:\n•Analyzed file: the path of the raster\nlayer\n•Extent: xmin, ymin, xmax, ymax co-\nordinates of the extent\n•Projection: projection of the layer\n•Width in pixels: number of columns\nand pixel width size\n•Height in pixels: number of rows and\npixel width size\n•Total pixel count: count of all the\npixels\n•NODATA pixel count: count of pix-\nels with NODATA value\nUnique values ta-\nble\nOUTPUT_TABLE[table]A table with three columns:\n•value: pixel value\n•count: count of pixels with this value\n•m\n2\n: total area in square meters of\npixels with this value.\nWidth in pixelsWIDTH_IN_PIXELS[integer]The number of columns in the output raster\nlayer\nPython code\nAlgorithm ID:native:rasterlayeruniquevaluesreport\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster layer zonal statistics\nCalculates statistics for a raster layer’s values, categorized by zones defined in another raster layer.\nSee also:\nZonal statistics\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput LayerINPUT[raster]Input raster layer\ncontinues on next page\n25.1. QGIS algorithm provider963\n\nQGIS Desktop 3.22 User Guide\nTable 25.70 – continued from previous page\nLabelNameTypeDescription\nBand numberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband choose the band\nfor which you want to calculate the statis-\ntics.\nZones layerZONES[raster]Raster layer defining zones. Zones are given\nby contiguous pixels having the same pixel\nvalue.\nZones band num-\nber\nZONES_BAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat defines the zones\nStatisticsOUTPUT_TABLE[table]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output report. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nReference layer\nOptional\nREF_LAYER[enumeration]\nDefault: 0\nRaster layer used to calculate the centroids\nthat will be used as reference when deter-\nmining the zones in the output layer. One\nof:\n•0 — Input layer: zones are deter-\nmined by sampling the zone raster\nlayer value at the centroid of each\npixel from the source raster layer\n•1 — Zones layer: the input raster\nlayer will be sampled at the centroid\nof each pixel from the zones raster\nlayer\nOutputs\nLabelNameTypeDescription\nCRS   authority\nidentifier\nCRS_AUTHID[string]The coordinate reference system of the out-\nput raster layer\nExtentEXTENT[string]The spatial extent of the output raster layer\nHeight in pixelsHEIGHT_IN_PIXELS[integer]The number of rows in the output raster\nlayer\nNODATA  pixel\ncount\nNO-\nDATA_PIXEL_COUNT\n[number]The number of NODATA pixels in the out-\nput raster layer\ncontinues on next page\n964Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.72 – continued from previous page\nLabelNameTypeDescription\nStatisticsOUTPUT_TABLE[table]The output layer contains the following in-\nformationfor each zone:\n•Area: the area in square raster units\nin the zone;\n•Sum: the total sum of the pixel values\nin the zone;\n•Count: the number of pixels in the\nzone;\n•Min: the minimum pixel value in the\nzone;\n•Max: the maximum pixel value in the\nzone;\n•Mean: the mean of the pixel values\nin the zone;\nTotal pixel countTO-\nTAL_PIXEL_COUNT\n[number]The count of pixels in the output raster layer\nWidth in pixelsWIDTH_IN_PIXELS[number]The number of columns in the output raster\nlayer\nPython code\nAlgorithm ID:native:rasterlayerzonalstats\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster surface volume\nCalculates the volume under a raster surface relative to a given base level. This is mainly useful for Digital Elevation\nModels (DEM).\nParameters\nLabelNameTypeDescription\nINPUT layerINPUT[raster]Input raster, representing a surface\nBand numberBAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nthat shall define the surface.\nBase levelLEVEL[number]\nDefault: 0.0\nDefine a base or reference value. This base\nis used in the volume calculation according\nto theMethodparameter (see below).\ncontinues on next page\n25.1. QGIS algorithm provider965\n\nQGIS Desktop 3.22 User Guide\nTable 25.73 – continued from previous page\nLabelNameTypeDescription\nMethodMETHOD[enumeration]\nDefault: 0\nDefine the method for the volume calcu-\nlation given by the difference between the\nraster pixel value and theBase level.\nOptions:\n•0 — Count Only Above Base Level:\nonly pixels above the base level will\nadd to the volume.\n•1 — Count Only Below Base Level:\nonly pixels below the base level will\nadd to the volume.\n•2 — Subtract Volumes Below Base\nlevel: pixels above the base level will\nadd to the volume, pixels below the\nbase level will subtract from the vol-\nume.\n•3 — Add Volumes Below Base level:\nAdd the volume regardless whether\nthe pixel is above or below the base\nlevel. This is equivalent to sum the\nabsolute values of the difference be-\ntween the pixel value and the base\nlevel.\nSurface  volume\nreport\nOUT-\nPUT_HTML_FILE\n[html]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output HTML report.\nOne of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nSurfacevolumeta-\nble\nOUTPUT_TABLE[table]\nDefault:[Skip\noutput]\nSpecification of the output table. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nVolumeVOLUME[number]The calculated volume\nAreaAREA[number]The area in square map units\nPixel_countPIXEL_COUNT[number]The total number of pixels that have been\nanalyzed\nSurface  volume\nreport\nOUT-\nPUT_HTML_FILE\n[html]The output report (containing volume, area\nand pixel count) in HTML format\nSurfacevolumeta-\nble\nOUTPUT_TABLE[table]The output table (containing volume, area\nand pixel count)\n966Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:rastersurfacevolume\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nReclassify by layer\nReclassifies a raster band by assigning new class values based on the ranges specified in a vector table.\nParameters\nBasic parameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Raster layer to reclassify\nBand numberRASTER_BAND[raster band]\nDefault:  The first\nband of the raster\nlayer\nIf the raster is multiband, choose the band\nyou want to reclassify.\nLayer containing\nclass breaks\nINPUT_TABLE[vector: any]Vector layer containing the values to use for\nclassification.\nMinimum  class\nvalue field\nMIN_FIELD[tablefield:nu-\nmeric]\nField with the minimum value of the range\nfor the class.\nMaximum  class\nvalue field\nMAX_FIELD[tablefield:nu-\nmeric]\nField with the maximum value of the range\nfor the class.\nOutput value fieldVALUE_FIELD[tablefield:nu-\nmeric]\nField with the value that will be assigned to\nthe pixels that fall in the class (between the\ncorresponding min and max values).\nReclassified rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nNO_DATA[number]\nDefault: -9999.0\nValue to apply to no data values.\nRange boundariesRANGE_BOUNDARIES[enumeration]\nDefault: 0\nDefines comparison rules for the classifica-\ntion. Options:\n•0 — min < value <= max\n•1 — min <= value < max\n•2 — min <= value <= max\n•3 — min < value < max\ncontinues on next page\n25.1. QGIS algorithm provider967\n\nQGIS Desktop 3.22 User Guide\nTable 25.75 – continued from previous page\nLabelNameTypeDescription\nUse no data when\nno range matches\nvalue\nNO-\nDATA_FOR_MISSING\n[boolean]\nDefault: False\nApplies the no data value to band values that\ndo not fall in any class. If False, the original\nvalue is kept.\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the format of the output raster file.\nOptions:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — Int32\n•4 — UInt32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nReclassified rasterOUTPUT[raster]Output raster layer with reclassified band\nvalues\nPython code\nAlgorithm ID:native:reclassifybylayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nReclassify by table\nReclassifies a raster band by assigning new class values based on the ranges specified in a fixed table.\nParameters\nBasic parameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Raster layer to reclassify\nBand numberRASTER_BAND[raster band]\nDefault: 1\nRaster band for which you want to recalcu-\nlate values.\ncontinues on next page\n968Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.76 – continued from previous page\nLabelNameTypeDescription\nReclassification\ntable\nTABLE[table]A 3-columns table to fill with the values to\nset the boundaries of each class (Minimum\nandMaximum) and the newValueto as-\nsign to the band values that fall in the class.\nReclassified rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput no data\nvalue\nNO_DATA[number]\nDefault: -9999.0\nValue to apply to no data values.\nRange boundariesRANGE_BOUNDARIES[enumeration]\nDefault: 0\nDefines comparison rules for the classifica-\ntion. Options:\n•0 — min < value <= max\n•1 — min <= value < max\n•2 — min <= value <= max\n•3 — min < value < max\nUse no data when\nno range matches\nvalue\nNO-\nDATA_FOR_MISSING\n[boolean]\nDefault: False\nApplies the no data value to band values that\ndo not fall in any class. If False, the original\nvalue is kept.\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the format of the output raster file.\nOptions:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — Int32\n•4 — UInt32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nReclassified rasterOUTPUT[raster]Output raster layer with reclassified band\nvalues\n25.1. QGIS algorithm provider969\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:reclassifybytable\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRescale raster\nRescales raster layer to a new value range, while preserving the shape (distribution) of the raster’s histogram (pixel\nvalues). Input values are mapped using a linear interpolation from the source raster’s minimum and maximum pixel\nvalues to the destination minimum and miximum pixel range.\nBy default the algorithm preserves the original NODATA value, but there is an option to override it.\nFig. 25.18: Rescaling values of a raster layer from [0 - 50] to [100 - 1000]\n970Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput RasterINPUT[raster]Raster layer to use for rescaling\nBand numberBand[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband,\nchoose a band.\nNew minimum valueMINIMUM[number]\nDefault value: 0.0\nMinimum pixel value to use in\nthe rescaled layer\nNew maximum valueMAXIMUM[number]\nDefaultvalue:\n255.0\nMaximum pixel value to use in\nthe rescaled layer\nNew NODATA value\nOptional\nNODATA[number]\nDefault value: Not\nset\nValue to assign to the NO-\nDATA pixels. If unset, original\nNODATA values are preserved.\nRescaledOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification  of  the  output\nraster layer. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nRescaledOUTPUT[raster]Output raster layer with rescaled band val-\nues\nPython code\nAlgorithm ID:native:rescaleraster\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRound raster\nRounds the cell values of a raster dataset according to the specified number of decimals.\nAlternatively, a negative number of decimal places may be used to round values to powers of a base n. For example,\nwith a Base value n of 10 and Decimal places of -1, the algorithm rounds cell values to multiples of 10, -2 rounds\nto multiples of 100, and so on. Arbitrary base values may be chosen, the algorithm applies the same multiplicative\nprinciple. Rounding cell values to multiples of a base n may be used to generalize raster layers.\nThe algorithm preserves the data type of the input raster. Therefore byte/integer rasters can only be rounded to\nmultiples of a base n, otherwise a warning is raised and the raster gets copied as byte/integer raster.\n25.1. QGIS algorithm provider971\n\nQGIS Desktop 3.22 User Guide\nFig. 25.19: Rounding values of a raster\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput rasterINPUT[raster]The raster to process.\nBand numberBAND[number]\nDefault: 1\nThe band of the raster\nRounding  direc-\ntion\nROUND-\nING_DIRECTION\n[list]\nDefault: 1\nHow to choose the target rounded value.\nOptions are:\n•0 — Round up\n•1 — Round to nearest\n•2 — Round down\nNumber of deci-\nmals places\nDECI-\nMAL_PLACES\n[number]\nDefault: 2\nNumber of decimals places to round to.\nUse negative values to round cell values to\na multiple of a base n\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nBase n for round-\ning to multiples of\nn\nBASE_N[number]\nDefault: 10\nWhen theDECIMAL_PLACESparameter\nis negative, raster values are rounded to\nmultiples of the base n value\n972Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]The output raster layer with values rounded\nfor the selected band.\nPython code\nAlgorithm ID:native:roundrastervalues\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSample raster values\nExtracts raster values at the point locations. If the raster layer is multiband, each band is sampled.\nThe attribute table of the resulting layer will have as many new columns as the raster layer band count.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: point]Point vector layer to use for\nsampling\nRaster LayerRASTERCOPY[raster]Raster layer to sample at the\ngiven point locations.\nOutput column prefixCOLUMN_PREFIX[string]\nDefault:    ‘SAM-\nPLE_’\nPrefix for the names of the\nadded columns.\nSampled\nOptional\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer con-\ntaining the sampled values. One\nof:\n•Create Temporary Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Ta-\nble...\nThe file encoding can also be\nchanged here.\n25.1. QGIS algorithm provider973\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nSampledOUTPUT[vector: point]The output layer containing the sampled\nvalues.\nPython code\nAlgorithm ID:native:rastersampling\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nZonal histogram\nAppends fields representing counts of each unique value from a raster layer contained within polygon features.\nThe output layer attribute table will have as many fields as the unique values of the raster layer that intersects the\npolygon(s).\nFig. 25.20: Raster layer histogram example\n974Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Input raster layer.\nBand numberRASTER_BAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose a band.\nVector layer con-\ntaining zones\nINPUT_VECTOR[vector: polygon]Vector polygon layer that defines the zones.\nOutput  column\nprefix\nCOLUMN_PREFIX\nOptional\n[string]\nDefault: ‘HISTO_’\nPrefix for the output columns names.\nOutput zonesOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector polygon layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOutput zonesOUTPUT[vector: polygon]The output vector polygon layer.\nPython code\nAlgorithm ID:native:zonalhistogram\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nZonal statistics\nCalculates statistics of a raster layer for each feature of an overlapping polygon vector layer.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Vector polygon layer that contains the\nzones.\nRaster layerINPUT_RASTER[raster]Input raster layer.\ncontinues on next page\n25.1. QGIS algorithm provider975\n\nQGIS Desktop 3.22 User Guide\nTable 25.80 – continued from previous page\nLabelNameTypeDescription\nRaster bandRASTER_BAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose a band for\nthe statistics.\nOutput  column\nprefix\nCOLUMN_PREFIX[string]\nDefault: ‘_’\nPrefix for the output columns names.\nStatistics to calcu-\nlate\nSTATISTICS[enumeration] [list]\nDefault: [0,1,2]\nList of statistical operator for the output.\nOptions:\n•0 — Count\n•1 — Sum\n•2 — Mean\n•3 — Median\n•4 — St. dev.\n•5 — Minimum\n•6 — Maximum\n•7 — Range\n•8 — Minority\n•9 — Majority\n•10 — Variety\n•11 — Variance\nZonal StatisticsOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector polygon layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nZonal StatisticsOUTPUT[vector: polygon]The zone vector layer with added statistics.\nPython code\nAlgorithm ID:native:zonalstatisticsfb\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n976Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\n25.1.12Raster Creation\nCreate constant raster layer\nGenerates raster layer for given extent and cell size filled with the specified value.\nAdditionally an output data type can be specified. The algorithm will abort if a value has been entered that cannot be\nrepresented by the selected output raster data type.\nParameters\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 0.1\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nConstant valueNUMBER[number]\nDefault: 1\nConstant pixel value for the output raster\nlayer.\nConstantOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 5\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Integer16\n•2 — Unsigned Integer16\n•3 — Integer32\n•4 — Unsigned Integer32\n•5 — Float32\n•6 — Float64\n25.1. QGIS algorithm provider977\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nConstantOUTPUT[raster]Raster covering the desired extent with the\nspecified pixel size and value.\nPython code\nAlgorithm ID:native:createconstantrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (binomial distribution)\nGenerates a raster layer for given extent and cell size filled with binomially distributed random values.\nBy default, the values will be chosen given an N of 10 and a probability of 0.5. This can be overridden by using the\nadvanced parameter for N and probability. The raster data type is set to Integer types (Integer16 by default). The\nbinomial distribution random values are defined as positive integer numbers. A floating point raster will represent a\ncast of integer values to floating point.\nParameters\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 0.1\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n978Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Integer16\n•1 — Unsigned Integer16\n•2 — Integer32\n•3 — Unsigned Integer32\n•4 — Float32\n•5 — Float64\nNN[number]\nDefault: 10\nProbabilityPROBABILITY[number]\nDefault: 0.5\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with random values\nPython code\nAlgorithm ID:native:createrandombinomialrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (exponential distribution)\nGenerates a raster layer for given extent and cell size filled with exponentially distributed random values.\nBy default, the values will be chosen given a lambda of 1.0. This can be overridden by using the advanced parameter\nfor lambda. The raster data type is set to Float32 by default as the exponential distribution random values are floating\npoint numbers.\nParameters\n25.1. QGIS algorithm provider979\n\nQGIS Desktop 3.22 User Guide\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Float32\n•1 — Float64\nLambdaLAMBDA[number]\nDefault: 1.0\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with random values\n980Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:createrandomexponentialrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (gamma distribution)\nGenerates a raster layer for given extent and cell size filled with gamma distributed random values.\nBy default, the values will be chosen given an alpha and beta value of 1.0. This can be overridden by using the\nadvanced parameter for alpha and beta. The raster data type is set to Float32 by default as the gamma distribution\nrandom values are floating point numbers.\nParameters\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n25.1. QGIS algorithm provider981\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Float32\n•1 — Float64\nAlphaALPHA[number]\nDefault: 1.0\nBetaBETA[number]\nDefault: 1.0\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with randomly distributed\nvalues\nPython code\nAlgorithm ID:native:createrandomgammarasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (geometric distribution)\nGenerates a raster layer for given extent and cell size filled with geometrically distributed random values.\nBy default, the values will be chosen given a probability of 0.5. This can be overridden by using the advanced param-\neter for mean value. The raster data type is set to Integer types (Integer16 by default). The geometric distribution\nrandom values are defined as positive integer numbers. A floating point raster will represent a cast of integer values\nto floating point.\nParameters\n982Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Integer16\n•1 — Unsigned Integer16\n•2 — Integer32\n•3 — Unsigned Integer32\n•4 — Float32\n•5 — Float64\nProbabilityPROBABILITY[number]\nDefault: 0.5\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with randomly distributed\nvalues\n25.1. QGIS algorithm provider983\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:createrandomgeometricrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (negative binomial distribution)\nGenerates a raster layer for given extent and cell size filled with negative binomially distributed random values.\nBy default, the values will be chosen given a distribution parameter k of 10.0 and a probability of 0.5. This can\nbe overridden by using the advanced parameters for k and probability. The raster data type is set to Integer types\n(Integer16 by default). The negative binomial distribution random values are defined as positive integer numbers. A\nfloating point raster will represent a cast of integer values to floating point.\nParameters\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n984Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Integer16\n•1 — Unsigned Integer16\n•2 — Integer32\n•3 — Unsigned Integer32\n•4 — Float32\n•5 — Float64\nDistribution  pa-\nrameter k\nK_PARAMETER[number]\nDefault: 10\nProbabilityPROBABILITY[number]\nDefault: 0.5\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with randomly distributed\nvalues\nPython code\nAlgorithm ID:native:createrandomnegativebinomialrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (normal distribution)\nGenerates a raster layer for given extent and cell size filled with normally distributed random values.\nBy default, the values will be chosen given a mean of 0.0 and a standard deviation of 1.0. This can be overridden\nby using the advanced parameters for mean and standard deviation value. The raster data type is set to Float32 by\ndefault as the normal distribution random values are floating point numbers.\n25.1. QGIS algorithm provider985\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Float32\n•1 — Float64\nMean of normal\ndistribution\nMEAN[number]\nDefault: 0.0\nStandard   devi-\nation of normal\ndistribution\nSTDDEV[number]\nDefault: 1.0\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with randomly distributed\nvalues\n986Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:createrandomnormalrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (poisson distribution)\nGenerates a raster layer for given extent and cell size filled with poisson distributed random values.\nBy default, the values will be chosen given a mean of 1.0. This can be overridden by using the advanced parameter\nfor mean value. The raster data type is set to Integer types (Integer16 by default). The poisson distribution random\nvalues are positive integer numbers. A floating point raster will represent a cast of integer values to floating point.\nParameters\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n25.1. QGIS algorithm provider987\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 0\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Integer16\n•1 — Unsigned Integer16\n•2 — Integer32\n•3 — Unsigned Integer32\n•4 — Float32\n•5 — Float64\nMeanMEAN[number]\nDefault: 1.0\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with randomly distributed\nvalues\nPython code\nAlgorithm ID:native:createrandompoissonrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate random raster layer (uniform distribution)\nGenerates a raster layer for given extent and cell size filled with random values.\nBy default, the values will range between the minimum and maximum value of the specified output raster type. This\ncan be overridden by using the advanced parameters for lower and upper bound value. If the bounds have the same\nvalue or both are zero (default) the algorithm will create random values in the full value range of the chosen raster\ndata type. Choosing bounds outside the acceptable range of the output raster type will abort the algorithm.\nParameters\n988Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nBasic parameters\nLabelNameTypeDescription\nDesired extentEXTENT[extent]Specify the spatial extent of the output\nraster layer. It will internally be extended\nto a multiple of the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTarget CRSTARGET_CRS[crs]\nDefault:   Project\nCRS\nCRS for the output raster layer\nPixel sizePIXEL_SIZE[number]\nDefault: 1.0\nPixel size (X=Y) in map units. Minimum\nvalue: 0.01\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nOutput   raster\ndata type\nOUTPUT_TYPE\nDefault: 5\n[enumeration]Defines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Integer16\n•2 — Unsigned Integer16\n•3 — Integer32\n•4 — Unsigned Integer32\n•5 — Float32\n•6 — Float64\nLower bound for\nrandom  number\nrange\nLOWER_BOUND[number]\nDefault: 0.0\nUpper bound for\nrandom  number\nrange\nUPPER_BOUND[number]\nDefault: 0.0\n25.1. QGIS algorithm provider989\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]Raster covering the desired extent with the\ncell size filled with randomly distributed\nvalues\nPython code\nAlgorithm ID:native:createrandomuniformrasterlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.13Raster terrain analysis\nAspect\nCalculates the aspect of the Digital Terrain Model in input. The final aspect raster layer contains values from 0 to\n360 that express the slope direction, starting from north (0°) and continuing clockwise.\nFig. 25.21: Aspect values\nThe following picture shows the aspect layer reclassified with a color ramp:\n990Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.22: Aspect layer reclassified\nParameters\nLabelNameTypeDescription\nElevation layerINPUT[raster]Digital Terrain Model raster layer\nZ factorZ_FACTOR[number]\nDefault: 1.0\nVertical exaggeration.  This parameter is\nuseful when the Z units differ from the X\nand Y units, for example feet and meters.\nYou can use this parameter to adjust for\nthis. The default is 1 (no exaggeration).\nAspectOUTPUT[raster]Specify the output aspect raster layer. One\nof:\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider991\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nAspectOUTPUT[raster]The output aspect raster layer\nPython code\nAlgorithm ID:qgis:aspect\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nHillshade\nCalculates the hillshade raster layer given an input Digital Terrain Model.\nThe shading of the layer is calculated according to the sun position: you have the options to change both the horizontal\nangle (azimuth) and the vertical angle (sun elevation) of the sun.\nFig. 25.23: Azimuth and vertical angle\nThe hillshade layer contains values from 0 (complete shadow) to 255 (complete sun). Hillshade is used usually to\nbetter understand the relief of the area.\n992Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.24: Hillshade layer with azimuth 300 and vertical angle 45\nParticularly interesting is to give the hillshade layer a transparency value and overlap it with the elevation raster:\nFig. 25.25: Overlapping the hillshade with the elevation layer\n25.1. QGIS algorithm provider993\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nElevation layerINPUT[raster]Digital Terrain Model raster layer\nZ factorZ_FACTOR[number]\nDefault: 1.0\nVertical exaggeration.  This parameter is\nuseful when the Z units differ from the X\nand Y units, for example feet and meters.\nYou can use this parameter to adjust for\nthis. Increasing the value of this parame-\nter will exaggerate the final result (making\nit look more “hilly”). The default is 1 (no\nexaggeration).\nAzimuth   (hori-\nzontal angle)\nAZIMUTH[number]\nDefault: 300.0\nSet the horizontal angle (in degrees) of the\nsun (clockwise direction). Range: 0 to 360.\n0 is north.\nVertical angleV_ANGLE[number]\nDefault: 40.0\nSet the vertical angle (in degrees) of the sun,\nthat is the height of the sun. Values can go\nfrom 0 (minimum elevation) to 90 (maxi-\nmum elevation).\nHillshadeOUTPUT[raster]Specify the output hillshade raster layer.\nOne of:\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nHillshadeOUTPUT[raster]The output hillshade raster layer\nPython code\nAlgorithm ID:qgis:hillshade\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nHypsometric curves\nCalculates hypsometric curves for an input Digital Elevation Model. Curves are produced as CSV files in an output\nfolder specified by the user.\nA hypsometric curve is a cumulative histogram of elevation values in a geographical area.\nYou can use hypsometric curves to detect differences in the landscape due to the geomorphology of the territory.\n994Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nDEM to analyzeINPUT_DEM[raster]Digital Terrain Model raster layer to use for\ncalculating altitudes\nBoundary layerBOUND-\nARY_LAYER\n[vector: polygon]Polygon vector layer with boundaries of ar-\neas used to calculate hypsometric curves\nStepSTEP[number]\nDefault: 100.0\nVertical distance between curves\nUse % of area in-\nstead of absolute\nvalue\nUSE_PERCENTAGE[boolean]\nDefault: False\nWrite area percentage to “Area” field of the\nCSV file instead of the absolute area\nHypsometric\ncurves\nOUT-\nPUT_DIRECTORY\n[folder]Specify the output folder for the hypsomet-\nric curves. One of:\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nHypsometric\ncurves\nOUT-\nPUT_DIRECTORY\n[folder]Directory containing the files with the hyp-\nsometric curves. For each feature from the\ninput vector layer, a CSV file with area and\naltitude values will be created.\nThe file names start withhistogram_,\nfollowed by layer name and feature ID.\n25.1. QGIS algorithm provider995\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:hypsometriccurves\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRelief\nCreates a shaded relief layer from digital elevation data. You can specify the relief color manually, or you can let the\nalgorithm choose automatically all the relief classes.\nFig. 25.26: Relief layer\nParameters\nLabelNameTypeDescription\nElevation layerINPUT[raster]Digital Terrain Model raster layer\nZ factorZ_FACTOR[number]\nDefault: 1.0\nVertical exaggeration.  This parameter is\nuseful when the Z units differ from the X\nand Y units, for example feet and meters.\nYou can use this parameter to adjust for\nthis. Increasing the value of this parame-\nter will exaggerate the final result (making\nit look more “hilly”). The default is 1 (no\nexaggeration).\ncontinues on next page\n996Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.83 – continued from previous page\nLabelNameTypeDescription\nGenerate   relief\nclasses automati-\ncally\nAUTO_COLORS[boolean]\nDefault: False\nIf you check this option the algorithm will\ncreate all the relief color classes automati-\ncally\nRelief colors\nOptional\nCOLORS[table widget]Use the table widget if you want to\nchoose the relief colors manually.  You\ncan add as many color classes as you\nwant:  for each class you can choose\nthe lower and upper bound and finally\nby clicking on the color row you can\nchoose the color thanks to the color widget.\nFig. 25.27: Manually setting of relief color\nclasses\nThe buttons in the right side panel give you\nthe chance to: add or remove color classes,\nchange the order of the color classes al-\nready defined, open an existing file with\ncolor classes and save the current classes as\nfile.\nReliefOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output relief raster layer. One\nof:\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\nFrequency distri-\nbution\nFRE-\nQUENCY_DISTRIBUTION\n[table]\nDefault:[Skip\noutput]\nSpecify the CSV table for the output fre-\nquency distribution. One of:\n•Skip Output\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nReliefOUTPUT[raster]The output relief raster layer\nFrequency distri-\nbution\nOUTPUT[table]The output frequency distribution\n25.1. QGIS algorithm provider997\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:relief\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRuggedness index\nCalculates the quantitative measurement of terrain heterogeneity described by Riley et al. (1999). It is calculated for\nevery location, by summarizing the change in elevation within the 3x3 pixel grid.\nEach pixel contains the difference in elevation from a center cell and the 8 cells surrounding it.\nFig. 25.28: Ruggedness layer from low (red) to high values (green)\n998Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nElevation layerINPUT[raster]Digital Terrain Model raster layer\nZ factorZ_FACTOR[number]\nDefault: 1.0\nVertical exaggeration.  This parameter is\nuseful when the Z units differ from the X\nand Y units, for example feet and meters.\nYou can use this parameter to adjust for\nthis. Increasing the value of this parame-\nter will exaggerate the final result (making\nit look more rugged). The default is 1 (no\nexaggeration).\nRuggednessOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output ruggedness raster layer.\nOne of:\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRuggednessOUTPUT[raster]The output ruggedness raster layer\nPython code\nAlgorithm ID:qgis:ruggednessindex\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider999\n\nQGIS Desktop 3.22 User Guide\nSlope\nCalculates the slope from an input raster layer. The slope is the angle of inclination of the terrain and is expressed in\ndegrees.\nFig. 25.29: Flat areas in red, steep areas in blue\nParameters\nLabelNameTypeDescription\nElevation layerINPUT[raster]Digital Terrain Model raster layer\nZ factorZ_FACTOR[number]\nDefault: 1.0\nVertical exaggeration.  This parameter is\nuseful when the Z units differ from the X\nand Y units, for example feet and meters.\nYou can use this parameter to adjust for\nthis. Increasing the value of this parame-\nter will exaggerate the final result (making\nit steeper). The default is 1 (no exaggera-\ntion).\nSlopeOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output slope raster layer. One\nof:\n•Save  to  a  Temporary  Layer\n(TEMPORARY_OUTPUT)\n•Save to File...\nThe file encoding can also be changed here.\n1000Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nSlopeOUTPUT[raster]The output slope raster layer\nPython code\nAlgorithm ID:qgis:slope\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.14Raster tools\nConvert map to raster\nCreates a raster image of map canvas content.\nAmap themecan be selected to render a predetermined set of layers with a defined style for each layer.\nAlternatively, a single layer can be selected if no map theme is set.\nIf neither map theme nor layer is set, the current map content will be rendered. The minimum extent entered will\ninternally be extended to be a multiple of the tile size.\nParameters\nLabelNameTypeDescription\nMinimum extent\nto render (xmin,\nxmax,ymin,\nymax)\nEXTENT[extent]Specify the extent of the output raster layer.\nIt will internally be extended to a multiple\nof the tile size.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nTile sizeTILE_SIZE[number]\nDefault: 1024\nSize of the tile of the output raster layer.\nMinimum value: 64.\nMap  units  per\npixel\nMAP_UNITS_PER_PIXEL[number]\nDefault: 100.0\nPixel size (in map units). Minimum value:\n0.0\nMake background\ntransparent\nMAKE_BACKGROUND_TRANSPARENT[boolean]\nDefault: False\nAllows exporting the map with a transpar-\nent background.  Outputs an RGBA (in-\nstead of RGB) image if set toTrue.\nMap theme to ren-\nder\nOptional\nMAP_THEME[enumeration]Use an existingmap themefor the render-\ning.\ncontinues on next page\n25.1. QGIS algorithm provider1001\n\nQGIS Desktop 3.22 User Guide\nTable 25.84 – continued from previous page\nLabelNameTypeDescription\nSinglelayertoren-\nder\nOptional\nLAYER[enumeration]Choose a single layer for the rendering\nOutput layerOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[raster]Output raster layer\nPython code\nAlgorithm ID:native:rasterize\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFill NoData cells\nResets the NoData values in the input raster to a chosen value, resulting in raster dataset with no NoData pixels.\nThe algorithm respects the input raster data type, e.g. a floating point fill value will be truncated when applied to an\ninteger raster.\nFig. 25.30: Filling NoData values (in grey) of a raster\n1002Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput rasterINPUT[raster]The raster to process.\nBand numberBAND[number]\nDefault: 1\nThe band of the raster\nFill valueFILL_VALUE[number]\nDefault: 1.0\nSet the value to use for the NoData pixels\nOutput rasterOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput rasterOUTPUT[raster]The output raster layer with filled data cells.\nPython code\nAlgorithm ID:native:fillnodata\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGenerate XYZ tiles (Directory)\nGenerates raster “XYZ” tiles using the current QGIS project as individual images to a directory structure.\nParameters\nLabelNameTypeDescription\nExtent   (xmin,\nxmax,ymin,\nymax)\nEXTENT[extent]Specify the extent of the tiles. It will inter-\nnally be extended to a multiple of the tile\nsize.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nMinimum zoomZOOM_MIN[number]\nDefault: 12\nMinimum 0, maximum 25.\ncontinues on next page\n25.1. QGIS algorithm provider1003\n\nQGIS Desktop 3.22 User Guide\nTable 25.85 – continued from previous page\nLabelNameTypeDescription\nMaximum zoomZOOM_MAX[number]\nDefault: 12\nMinimum 0, maximum 25.\nDPIDPI[number]\nDefault: 96\nMinimum 48, maximum 600.\nBackground color\nOptional\nBACK-\nGROUND_COLOR\n[color]\nDefault: QColor(0,\n0, 0, 0)\nChoose the background color for the tiles\nTile formatTILE_FORMAT[enumeration]\nDefault: 0\nOne of:\n•0 — PNG\n•1 — JPG\nQuality    (JPG\nonly)\nOptional\nQUALITY[number]\nDefault: 75\nMinimum 1, maximum 100.\nMetatile size\nOptional\nMETATILESIZE[number]\nDefault: 4\nSpecify a custom metatile size when gener-\nating XYZ tiles. Larger values may speed\nup the rendering of tiles and provide better\nlabelling (fewer gaps without labels) at the\nexpense of using more memory. Minimum\n1, maximum 20.\nTile width\nOptional\nTILE_WIDTH[number]\nDefault: 256\nMinimum 1, maximum 4096.\nTile height\nOptional\nTILE_HEIGHT[number]\nDefault: 256\nMinimum 1, maximum 4096.\nUse inverted tile Y\naxis (TMS conven-\ntions)\nOptional\nTMS_CONVENTION[boolean]\nDefault: False\nOutput directoryOUT-\nPUT_DIRECTORY\n[folder]\nDefault:[Save\nto  temporary\nfolder]\nSpecification of the output raster. One of:\n•Skip Output\n•Save to a Temporary Directory\n•Save to Directory\nOutputhtml\n(Leaflet)\nOUTPUT_HTML[html]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output HTML file. One\nof:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput directoryOUT-\nPUT_DIRECTORY\n[folder]Output directory (for the tiles)\nOutputhtml\n(Leaflet)\nOUTPUT_HTML[html]The output HTML (Leaflet) file\n1004Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:tilesxyzdirectory\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGenerate XYZ tiles (MBTiles)\nGenerates raster “XYZ” tiles using the current QGIS project as a single file in the “MBTiles” format.\nParameters\nLabelNameTypeDescription\nExtent   (xmin,\nxmax,ymin,\nymax)\nEXTENT[extent]Specify the extent of the tiles. It will inter-\nnally be extended to a multiple of the tile\nsize.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nMinimum zoomZOOM_MIN[number]\nDefault: 12\nMinimum 0, maximum 25.\nMaximum zoomZOOM_MAX[number]\nDefault: 12\nMinimum 0, maximum 25.\nDPIDPI[number]\nDefault: 96\nMinimum 48, maximum 600.\nBackground color\nOptional\nBACK-\nGROUND_COLOR\n[color]\nDefault: QColor(0,\n0, 0, 0)\nChoose the background color for the tiles\nTile formatTILE_FORMAT[enumeration]\nDefault: 0\nOne of:\n•0 — PNG\n•1 — JPG\nQuality    (JPG\nonly)\nOptional\nQUALITY[number]\nDefault: 75\nMinimum 1, maximum 100.\nMetatile size\nOptional\nMETATILESIZE[number]\nDefault: 4\nSpecify a custom metatile size when gener-\nating XYZ tiles. Larger values may speed\nup the rendering of tiles and provide better\nlabelling (fewer gaps without labels) at the\nexpense of using more memory. Minimum\n1, maximum 20.\ncontinues on next page\n25.1. QGIS algorithm provider1005\n\nQGIS Desktop 3.22 User Guide\nTable 25.86 – continued from previous page\nLabelNameTypeDescription\nOutput file (for\nMBTiles)\nOUTPUT_FILE[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nOutput file (for\nMBTiles)\nOUTPUT_FILE[file]The output file.\nPython code\nAlgorithm ID:qgis:tilesxyzmbtiles\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.15Vector analysis\nBasic statistics for fields\nGenerates basic statistics for a field of the attribute table of a vector layer.\nNumeric, date, time and string fields are supported.\nThe statistics returned will depend on the field type.\nStatistics are generated as an HTML file and are available in theProcessing►Results viewer.\nDefault menu:Vector►Analysis Tools\nParameters\nLabelNameTypeDescription\nInput vectorINPUT_LAYER[vector: any]Vector layer to calculate the statistics on\nField to calculate\nstatistics on\nFIELD_NAME[tablefield: any]Any supported table field to calculate the\nstatistics\nStatistics\nOptional\nOUT-\nPUT_HTML_FILE\n[html]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the file for the calculated\nstatistics. One of:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\n1006Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nStatisticsOUT-\nPUT_HTML_FILE\n[html]HTML file with the calcu-\nlated statistics\nCountCOUNT[number]\nNumber of unique valuesUNIQUE[number]\nNumber of empty (null) valuesEMPTY[number]\nNumber of non-empty valuesFILLED[number]\nMinimum valueMIN[same as input]\nMaximum valueMAX[same as input]\nMinimum lengthMIN_LENGTH[number]\nMaximum lengthMAX_LENGTH[number]\nMean lengthMEAN_LENGTH[number]\nCoefficient of VariationCV[number]\nSumSUM[number]\nMean valueMEAN[number]\nStandard deviationSTD_DEV[number]\nRangeRANGE[number]\nMedianMEDIAN[number]\nMinority (rarest occurring value)MINORITY[same as input]\nMajority (most frequently occur-\nring value)\nMAJORITY[same as input]\nFirst quartileFIRSTQUARTILE[number]\nThird quartileTHIRDQUARTILE[number]\nInterquartile Range (IQR)IQR[number]\nPython code\nAlgorithm ID:qgis:basicstatisticsforfields\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nClimb along line\nCalculates the total climb and descent along line geometries. The input layer must have Z values present. If Z values\nare not available, theDrape (set Z value from raster)algorithm may be used to add Z values from a DEM layer.\nThe output layer is a copy of the input layer with additional fields that contain the total climb (climb), total descent\n(descent), the minimum elevation (minelev) and the maximum elevation (maxelev) for each line geometry.\nIf the input layer contains fields with the same names as these added fields, they will be renamed (field names will be\naltered to “name_2”, “name_3”, etc, finding the first non-duplicate name).\n25.1. QGIS algorithm provider1007\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nLine layerINPUT[vector: line]Line layer to calculate the climb for. Must\nhave Z values\nClimb layerOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output (line) layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nClimb layerOUTPUT[vector: line]Line layer containing new attributes with\nthe results from climb calculations.\nTotal climbTOTALCLIMB[number]The sum of the climb for all the line geome-\ntries in the input layer\nTotal descentTOTALDESCENT[number]The sum of the descent for all the line ge-\nometries in the input layer\nMinimum  eleva-\ntion\nMINELEVATION[number]The minimum elevation for the geometries\nin the layer\nMaximum eleva-\ntion\nMAXELEVATION[number]The maximum elevation for the geometries\nin the layer\nPython code\nAlgorithm ID:qgis:climbalongline\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCount points in polygon\nTakes a point and a polygon layer and counts the number of points from the point layer in each of the polygons of the\npolygon layer.\nA new polygon layer is generated, with the exact same content as the input polygon layer, but containing an additional\nfield with the points count corresponding to each polygon.\n1008Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.31: The labels in the polygons show the point count\nAn optional weight field can be used to assign weights to each point. Alternatively, a unique class field can be specified.\nIf both options are used, the weight field will take precedence and the unique class field will be ignored.\nDefault menu:Vector►Analysis Tools\nParameters\nLabelNameTypeDescription\nPolygonsPOLYGONS[vector: polygon]Polygon layer whose features are associated\nwith the count of points they contain\nPointsPOINTS[vector: point]Point layer with features to count\nWeight field\nOptional\nWEIGHT[tablefield: any]A field from the point layer. The count gen-\nerated will be the sum of the weight field of\nthe points contained by the polygon. If the\nweight field is not numeric, the count will\nbe0.\nClass field\nOptional\nCLASSFIELD[tablefield: any]Points are classified based on the selected\nattribute and if several points with the same\nattribute value are within the polygon, only\none of them is counted. The final count\nof the points in a polygon is, therefore, the\ncount of different classes that are found in\nit.\nCount field nameFIELD[string]\nDefault:   ‘NUM-\nPOINTS’\nThe name of the field to store the count of\npoints\ncontinues on next page\n25.1. QGIS algorithm provider1009\n\nQGIS Desktop 3.22 User Guide\nTable 25.88 – continued from previous page\nLabelNameTypeDescription\nCountOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCountOUTPUT[vector: polygon]Resulting layer with the attribute table con-\ntaining the new column with the points\ncount\nPython code\nAlgorithm ID:native:countpointsinpolygon\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDBSCAN clustering\nClusters point features based on a 2D implementation of Density-based spatial clustering of applications with noise\n(DBSCAN) algorithm.\nThe algorithm requires two parameters, a minimum cluster size, and the maximum distance allowed between clustered\npoints.\nSee also:\nST-DBSCAN clustering,K-means clustering\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Layer to analyze\nMinimum cluster\nsize\nMIN_SIZE[number]\nDefault: 5\nMinimum number of features to generate a\ncluster\nMaximum   dis-\ntance   between\nclustered points\nEPS[number]\nDefault: 1.0\nDistance beyond which two features can not\nbelong to the same cluster (eps)\ncontinues on next page\n1010Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.89 – continued from previous page\nLabelNameTypeDescription\nClustersOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the vector layer for the result of the\nclustering. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nTreatborder\npoints  as  noise\n(DBSCAN*)\nOptional\nDBSCAN*[boolean]\nDefault: False\nIf checked, points on the border of a clus-\nter are themselves treated as unclustered\npoints, and only points in the interior of a\ncluster are tagged as clustered.\nCluster field nameFIELD_NAME[string]\nDefault:   ‘CLUS-\nTER_ID’\nName of the field where the associated clus-\nter number shall be stored\nCluster size field\nname\nSIZE_FIELD_NAME[string]\nDefault:   ‘CLUS-\nTER_SIZE’\nName of the field with the count of features\nin the same cluster\nOutputs\nLabelNameTypeDescription\nClustersOUTPUT[vector: point]Vector layer containing the original features\nwith a field setting the cluster they belong to\nNumber of clus-\nters\nNUM_CLUSTERS[number]The number of clusters discovered\nPython code\nAlgorithm ID:native:dbscanclustering\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1011\n\nQGIS Desktop 3.22 User Guide\nDistance matrix\nCalculates for point features distances to their nearest features in the same layer or in another layer.\nDefault menu:Vector►Analysis Tools\nSee also:\nJoin attributes by nearest\nParameters\nLabelNameTypeDescription\nInput point layerINPUT[vector: point]Point layer for which the distance matrix is\ncalculated (frompoints)\nInput unique ID\nfield\nINPUT_FIELD[tablefield: any]Field to use to uniquely identify features of\nthe input layer. Used in the output attribute\ntable.\nTarget point layerTARGET[vector: point]Point layer containing the nearest point(s)\nto search (topoints)\nTarget unique ID\nfield\nTARGET_FIELD[tablefield: any]Field to use to uniquely identify features of\nthe target layer. Used in the output attribute\ntable.\nOutput   matrix\ntype\nMATRIX_TYPE[enumeration]\nDefault: 0\nDifferent types of calculation are available:\n•0 — Linear (N *kx 3) distance ma-\ntrix: for each input point, reports the\ndistance to each of theknearest tar-\nget points. The output matrix con-\nsists of up tokrows per input point,\nand each row has three columns:In-\nputID,TargetIDandDistance.\n•1 — Standard (N x T) distance ma-\ntrix\n•2 — Summary distance matrix\n(mean, std.  dev., min, max): for\neach input point, reports statistics on\nthe distances to its target points.\nUse  only  the\nnearest (k) target\npoints\nNEAR-\nEST_POINTS\n[number]\nDefault: 0\nYou can choose to calculate the distance to\nall the points in the target layer (0) or limit\nto a number (k) of closest features.\nDistance matrixOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1012Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nDistance matrixOUTPUT[vector: point]Point (or MultiPoint for the “Linear (N *k\nx 3)” case) vector layer containing the dis-\ntance calculation for each input feature. Its\nfeatures and attribute table depend on the\nselected output matrix type.\nPython code\nAlgorithm ID:qgis:distancematrix\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDistance to nearest hub (line to hub)\nCreates lines that join each feature of an input vector to the nearest feature in a destination layer. Distances are\ncalculated based on thecenterof each feature.\nFig. 25.32: Display the nearest hub for the red input features\nSee also:\nDistance to nearest hub (points),Join attributes by nearest\n25.1. QGIS algorithm provider1013\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nSource    points\nlayer\nINPUT[vector: any]Vector layer for which the nearest feature is\nsearched\nDestination hubs\nlayer\nHUBS[vector: any]Vector layer containing the features to\nsearch for\nHub layer name\nattribute\nFIELD[tablefield: any]Field to use to uniquely identify features of\nthe destination layer. Used in the output at-\ntribute table\nMeasurement unitUNIT[enumeration]\nDefault: 0\nUnits in which to report the distance to the\nclosest feature:\n•0 — Meters\n•1 — Feet\n•2 — Miles\n•3 — Kilometers\n•4 — Layer units\nHub distanceOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer con-\nnecting the matching points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nHub distanceOUTPUT[vector: line]Line vector layer with the attributes of the\ninput features, the identifier of their closest\nfeature and the calculated distance.\nPython code\nAlgorithm ID:qgis:distancetonearesthublinetohub\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1014Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nDistance to nearest hub (points)\nCreatesapointlayerrepresentingthecenteroftheinputfeatureswiththeadditionoftwofieldscontainingtheidentifier\nof the nearest feature (based on its center point) and the distance between the points.\nSee also:\nDistance to nearest hub (line to hub),Join attributes by nearest\nParameters\nLabelNameTypeDescription\nSource    points\nlayer\nINPUT[vector: any]Vector layer for which the nearest feature is\nsearched\nDestination hubs\nlayer\nHUBS[vector: any]Vector layer containing the features to\nsearch for\nHub layer name\nattribute\nFIELD[tablefield: any]Field to use to uniquely identify features of\nthe destination layer. Used in the output at-\ntribute table\nMeasurement unitUNIT[enumeration]\nDefault: 0\nUnits in which to report the distance to the\nclosest feature:\n•0 — Meters\n•1 — Feet\n•2 — Miles\n•3 — Kilometers\n•4 — Layer units\nHub distanceOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output point vector layer with\nthe nearest hub. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nHub distanceOUTPUT[vector: point]Point vector layer representing the center of\nthe source features with their attributes, the\nidentifier of their closest feature and the cal-\nculated distance.\n25.1. QGIS algorithm provider1015\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:distancetonearesthubpoints\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nJoin by lines (hub lines)\nCreates hub and spoke diagrams by connecting lines from points on the Spoke layer to matching points in the Hub\nlayer.\nDetermination of which hub goes with each point is based on a match between the Hub ID field on the hub points\nand the Spoke ID field on the spoke points.\nIf input layers are not point layers, a point on the surface of the geometries will be taken as the connecting location.\nOptionally, geodesic lines can be created, which represent the shortest path on the surface of an ellipsoid. When\ngeodesic mode is used, it is possible to split the created lines at the antimeridian (±180 degrees longitude), which\ncan improve rendering of the lines. Additionally, the distance between vertices can be specified. A smaller distance\nresults in a denser, more accurate line.\nFig. 25.33: Join points based on a common field / attribute\nParameters\nBasic parameters\nLabelNameTypeDescription\nHub layerHUBS[vector: any]Input layer\nHub ID fieldHUB_FIELD[tablefield: any]Field of the hub layer with ID to join\nHub layer fields to\ncopy (leave empty\nto copy all fields)\nOptional\nHUB_FIELDS[tablefield:    any]\n[list]\nThe field(s) of the hub layer to be copied. If\nno field(s) are chosen all fields are taken.\nSpoke layerSPOKES[vector: any]Additional spoke point layer\nSpoke ID fieldSPOKE_FIELD[tablefield: any]Field of the spoke layer with ID to join\ncontinues on next page\n1016Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.93 – continued from previous page\nLabelNameTypeDescription\nSpoke layer fields\nto  copy  (leave\nempty to copy all\nfields)\nOptional\nSPOKE_FIELDS[tablefield:    any]\n[list]\nField(s) of the spoke layer to be copied. If\nno fields are chosen all fields are taken.\nCreate  geodesic\nlines\nGEODESIC[boolean]\nDefault: False\nCreate geodesic lines (the shortest path on\nthe surface of an ellipsoid)\nHub linesOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output hub line vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nDistance between\nvertices (geodesic\nlines only)\nGEODESIC_DISTANCE[number]\nDefault:   1000.0\n(kilometers)\nDistance between consecutive vertices (in\nkilometers). A smaller distance results in\na denser, more accurate line\nSplit lines at an-\ntimeridian (±180\ndegrees longitude)\nANTIMERID-\nIAN_SPLIT\n[boolean]\nDefault: False\nSplit lines at ±180 degrees longitude (to im-\nprove rendering of the lines)\nOutputs\nLabelNameTypeDescription\nHub linesOUTPUT[vector: line]The resulting line layer connecting match-\ning points in input layers\nPython code\nAlgorithm ID:native:hublines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1017\n\nQGIS Desktop 3.22 User Guide\nK-means clustering\nCalculates the 2D distance based k-means cluster number for each input feature.\nK-means clustering aims to partition the features into k clusters in which each feature belongs to the cluster with the\nnearest mean. The mean point is represented by the barycenter of the clustered features.\nIf input geometries are lines or polygons, the clustering is based on the centroid of the feature.\nFig. 25.34: A five class point clusters\nSee also:\nDBSCAN clustering,ST-DBSCAN clustering\n1018Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to analyze\nNumber of clus-\nters\nCLUSTERS[number]\nDefault: 5\nNumber of clusters to create with the fea-\ntures\nClustersOUTPUT[vector: any]\nDefault:[Create\ntemporary\nlayer]\nSpecify the output vector layer for gener-\nated the clusters. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nCluster field nameFIELD_NAME[string]\nDefault:   ‘CLUS-\nTER_ID’\nName of the field where the associated clus-\nter number shall be stored\nCluster size field\nname\nSIZE_FIELD_NAME[string]\nDefault:   ‘CLUS-\nTER_SIZE’\nName of the field with the count of features\nin the same cluster\nOutputs\nLabelNameTypeDescription\nClustersOUTPUT[vector: any]Vector layer containing the original features\nwith fields specifying the cluster they belong\nto and their number in it\nPython code\nAlgorithm ID:native:kmeansclustering\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1019\n\nQGIS Desktop 3.22 User Guide\nList unique values\nLists unique values of an attribute table field and counts their number.\nDefault menu:Vector►Analysis Tools\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to analyze\nTarget field(s)FIELDS[tablefield: any]Field to analyze\nUnique values\nOptional\nOUTPUT[table]\nDefault:[Create\ntemporary\nlayer]\nSpecify the summary table layer with\nunique values. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nHTML report\nOptional\nOUT-\nPUT_HTML_FILE\n[html]\nDefault:[Save\nto  temporary\nfile]\nHTML report of unique values in thePro-\ncessing►Results viewer. One of:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nUnique valuesOUTPUT[table]Summary table layer with unique values\nHTML reportOUT-\nPUT_HTML_FILE\n[html]HTML report of unique values.   Can\nbe opened from theProcessing►Results\nviewer\nTotal unique val-\nues\nTOTAL_VALUES[number]The number of uniqe values in the input\nfield\nUNIQUE_VALUESUnique values[string]A string with the comma separated list of\nunique values found in the input field\nPython code\nAlgorithm ID:qgis:listuniquevalues\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThe\nalgorithm id\nis displayed when you hover over the algorithm in the Processing Toolbox. The\nparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1020Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nMean coordinate(s)\nComputes a point layer with the center of mass of geometries in an input layer.\nAn attribute can be specified as containing weights to be applied to each feature when computing the center of mass.\nIf an attribute is selected in the parameter, features will be grouped according to values in this field. Instead of a\nsingle point with the center of mass of the whole layer, the output layer will contain a center of mass for the features\nin each category.\nDefault menu:Vector►Analysis Tools\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nWeight field\nOptional\nWEIGHT[tablefield:nu-\nmeric]\nField to use if you want to perform a\nweighted mean\nUnique ID fieldUID[tablefield:nu-\nmeric]\nUnique field on which the calculation of the\nmean will be made\nMean coordinatesOUTPUT[vector: point]\nDefault:[Create\ntemporary\nlayer]\nSpecify the (point vector) layer for the re-\nsult. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nMean coordinatesOUTPUT[vector: point]Resulting point(s) layer\nPython code\nAlgorithm ID:native:meancoordinates\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1021\n\nQGIS Desktop 3.22 User Guide\nNearest neighbour analysis\nPerforms nearest neighbor analysis for a point layer. The output tells you how your data are distributed (clustered,\nrandomly or distributed).\nOutput is generated as an HTML file with the computed statistical values:\n•Observed mean distance\n•Expected mean distance\n•Nearest neighbour index\n•Number of points\n•Z-Score: Comparing the Z-Score with the normal distribution tells you how your data are distributed. A low\nZ-Score means that the data are unlikely to be the result of a spatially random process, while a high Z-Score\nmeans that your data are likely to be a result of a spatially random process.\nDefault menu:Vector►Analysis Tools\nSee also:\nJoin attributes by nearest\n1022Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Point vector layer to calculate the statistics\non\nNearest neighbour\nOptional\nOUT-\nPUT_HTML_FILE\n[html]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the HTML file for the com-\nputed statistics. One of:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nNearest neighbourOUT-\nPUT_HTML_FILE\n[html]HTML file with the computed statistics\nObserved  mean\ndistance\nOBSERVED_MD[number]Observed mean distance\nExpected  mean\ndistance\nEXPECTED_MD[number]Expected mean distance\nNearest neighbour\nindex\nNN_INDEX[number]Nearest neighbour index\nNumber of pointsPOINT_COUNT[number]Number of points\nZ-ScoreZ_SCORE[number]Z-Score\nPython code\nAlgorithm ID:native:nearestneighbouranalysis\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nOverlap analysis\nCalculates the area and percentage cover by which features from an input layer are overlapped by features from a\nselection of overlay layers.\nNew attributes are added to the output layer reporting the total area of overlap and percentage of the input feature\noverlapped by each of the selected overlay layers.\n25.1. QGIS algorithm provider1023\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer.\nOverlap layersLAYERS[vector: any] [list]The overlay layers.\nOutput layerOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[same as input]The output layer with additional fields re-\nporting the overlap (in map units and per-\ncentage) of the input feature overlapped by\neach of the selected layers.\nPython code\nAlgorithm ID:native:calculatevectoroverlaps\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nST-DBSCAN clustering\nNEW in 3.22\nClusters point features based on a 2D implementation of spatiotemporal Density-based clustering of applications with\nnoise (ST-DBSCAN) algorithm.\nSee also:\nDBSCAN clustering,K-means clustering\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Layer to analyze\nDate/time fieldDATE-\nTIME_FIELD\n[tablefield: date]Field containing the temporal information\ncontinues on next page\n1024Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.96 – continued from previous page\nLabelNameTypeDescription\nMinimum cluster\nsize\nMIN_SIZE[number]\nDefault: 5\nMinimum number of features to generate a\ncluster\nMaximum   dis-\ntance   between\nclustered points\nEPS[number]\nDefault: 1.0\nDistance beyond which two features can not\nbelong to the same cluster (eps)\nMaximum  time\nduration between\nclustered points\nEPS2[number]\nDefault: 0.0 (days)\nTime duration beyond which two features\ncan not belong to the same cluster (eps2).\nAvailable time units are milliseconds, sec-\nonds, minutes, hours, days and weeks.\nClustersOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the vector layer for the result of the\nclustering. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nTreatborder\npoints  as  noise\n(DBSCAN*)\nOptional\nDBSCAN*[boolean]\nDefault: False\nIf checked, points on the border of a clus-\nter are themselves treated as unclustered\npoints, and only points in the interior of a\ncluster are tagged as clustered.\nCluster field nameFIELD_NAME[string]\nDefault:   ‘CLUS-\nTER_ID’\nName of the field where the associated clus-\nter number shall be stored\nCluster size field\nname\nSIZE_FIELD_NAME[string]\nDefault:   ‘CLUS-\nTER_SIZE’\nName of the field with the count of features\nin the same cluster\nOutputs\nLabelNameTypeDescription\nClustersOUTPUT[vector: point]Vector layer containing the original features\nwith a field setting the cluster they belong to\nNumber of clus-\nters\nNUM_CLUSTERS[number]The number of clusters discovered\nPython code\nAlgorithm ID:native:stdbscanclustering\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1025\n\nQGIS Desktop 3.22 User Guide\nStatistics by categories\nCalculates statistics of a field depending on a parent class. The parent class is a combination of values from other\nfields.\nParameters\nLabelNameTypeDescription\nInput vector layerINPUT[vector: any]Input vector layer with unique classes and\nvalues\nField to calculate\nstatistics  on  (if\nempty, only count\nis calculated)\nOptional\nVAL-\nUES_FIELD_NAME\n[tablefield: any]If empty only the count will be calculated\nField(s) with cate-\ngories\nCATE-\nGORIES_FIELD_NAME\n[vector: any] [list]The fields that (combined) define the cate-\ngories\nStatistics by cate-\ngory\nOUTPUT[table]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output table for the generated\nstatistics. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nStatistics by cate-\ngory\nOUTPUT[table]Table containing the statistics\nDepending on the type of the field being analyzed, the following statistics are returned for each grouped value:\nStatisticsStringNumericDate\nCount (COUNT)\nUnique values (UNIQUE)\nEmpty (null) values (EMPTY)\nNon-empty values (FILLED)\nMinimal value (MIN)\nMaximal value (MAX)\nRange (RANGE)\nSum (SUM)\nMean value (MEAN)\nMedian value (MEDIAN)\nStandard Deviation (STD_DEV)\nCoefficient of variation (CV)\ncontinues on next page\n1026Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.98 – continued from previous page\nStatisticsStringNumericDate\nMinority (rarest occurring value -MINORITY)\nMajority (most frequently occurring value -MAJORITY)\nFirst Quartile (FIRSTQUARTILE)\nThird Quartile (THIRDQUARTILE)\nInter Quartile Range (IQR)\nMinimum Length (MIN_LENGTH)\nMean Length (MEAN_LENGTH)\nMaximum Length (MAX_LENGTH)\nPython code\nAlgorithm ID:qgis:statisticsbycategories\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSum line lengths\nTakes a polygon layer and a line layer and measures the total length of lines and the total number of them that cross\neach polygon.\nThe resulting layer has the same features as the input polygon layer, but with two additional attributes containing the\nlength and count of the lines across each polygon.\nDefault menu:Vector►Analysis Tools\nParameters\nLabelNameTypeDescription\nLinesLINES[vector: line]Input vector line layer\nPolygonsPOLYGONS[vector: polygon]Polygon vector layer\nLines length field\nname\nLEN_FIELD[string]\nDefault: ‘LENGTH’\nName of the field for the lines length\nLines count field\nname\nCOUNT_FIELD[string]\nDefault: ‘COUNT’\nName of the field for the lines count\nLine lengthOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon layer with gen-\nerated statistics. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1027\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nLine lengthOUTPUT[vector: polygon]Polygon output layer with fields of lines\nlength and line count\nPython code\nAlgorithm ID:native:sumlinelengths\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.16Vector creation\nArray of offset (parallel) lines\nCreates copies of line features in a layer, by creating multiple offset versions of each feature. Each new version is\nincrementally offset by a specified distance.\nPositive distance will offset lines to the left, and negative distances will offset them to the right.\nFig. 25.35: In blue the source layer, in red the offset one\nAllowsfeatures in-place modification\nSee also:\nOffset lines,Array of translated features\n1028Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer to use for the offsets.\nNumber of fea-\ntures to create\nCOUNT[number]\nDefault: 10\nNumber of offset copies to generate for\neach feature\nOffset  step  dis-\ntance\nOFFSET[number]\nDefault: 1.0\nDistance between two consecutive offset\ncopies\nOffset linesOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line layer with offset fea-\ntures. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nSegmentsSEGMENTS[number]\nDefault: 8\nNumber of line segments to use to approxi-\nmate a quarter circle when creating rounded\noffsets\nJoin styleJOIN_STYLE[enumeration]\nDefault: 0\nSpecify whether round, miter or beveled\njoins should be used when offsetting cor-\nners in a line. One of:\n•0 — Round\n•1 — Miter\n•2 — Bevel\nFig. 25.36: Round, miter, and bevel join\nstyles\nMiter limitMITER_LIMIT[number]\nDefault: 2.0\nOnly applicable for mitered join styles, and\ncontrols the maximum distance from the\noffset curve to use when creating a mitered\njoin.\n25.1. QGIS algorithm provider1029\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOffset linesOUTPUT[vector: line]Output line layer with offset features. The\noriginal features are also copied.\nPython code\nAlgorithm ID:native:arrayoffsetlines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nArray of translated features\nCreates copies of features in a layer by creating multiple translated versions of each. Each copy is incrementally\ndisplaced by a preset amount in the X, Y and/or Z axis.\nM values present in the geometry can also be translated.\nFig. 25.37: Input layers in blue tones, output layers with translated features in red tones\nAllowsfeatures in-place modification\nSee also:\nTranslate,Array of offset (parallel) lines\n1030Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer to translate\nNumber of fea-\ntures to create\nCOUNT[number]\nDefault: 10\nNumber of copies to generate for each fea-\nture\nStep distance (x-\naxis)\nDELTA_X[number]\nDefault: 0.0\nDisplacement to apply on the X axis\nStep distance (y-\naxis)\nDELTA_Y[number]\nDefault: 0.0\nDisplacement to apply on the Y axis\nStep distance (z-\naxis)\nDELTA_Z[number]\nDefault: 0.0\nDisplacement to apply on the Z axis\nStep distance (m\nvalues)\nDELTA_M[number]\nDefault: 0.0\nDisplacement to apply on M\nTranslatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nOutput vector layer with translated (moved)\ncopies of the features. The original features\nare also copied. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nTranslatedOUTPUT[same as input]Output vector layer with translated (moved)\ncopies of the features. The original features\nare also copied.\nPython code\nAlgorithm ID:native:arraytranslatedfeatures\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1031\n\nQGIS Desktop 3.22 User Guide\nCreate grid\nCreates a vector layer with a grid covering a given extent. Grid cells can have different shapes:\nFig. 25.38: Different grid cell shapes\nThe size of each element in the grid is defined using a horizontal and vertical spacing.\nThe CRS of the output layer must be defined.\nThe grid extent and the spacing values must be expressed in the coordinates and units of this CRS.\nDefault menu:Vector►Research Tools\nParameters\nLabelNameTypeDescription\nGrid typeTYPE[enumeration]\nDefault: 0\nShape of the grid. One of:\n•0 — Point\n•1 — Line\n•2 — Rectangle (polygon)\n•3 — Diamond (polygon)\n•4 — Hexagon (polygon)\nGrid extentEXTENT[extent]Extent of the grid\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nHorizontal  spac-\ning\nHSPACING[number]\nDefault: 1.0\nSize of a grid cell on the X-axis\nVertical spacingVSPACING[number]\nDefault: 1.0\nSize of a grid cell on the Y-axis\nHorizontal overlayHOVERLAY[number]\nDefault: 0.0\nOverlay distance between two consecutive\ngrid cells on the X-axis\nVertical overlayVOVERLAY[number]\nDefault: 0.0\nOverlay distance between two consecutive\ngrid cells on the Y-axis\nGrid CRSCRS[crs]\nDefault:Project\nCRS\nCoordinate reference system to apply to the\ngrid\ncontinues on next page\n1032Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.103 – continued from previous page\nLabelNameTypeDescription\nGridOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nResulting vector grid layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nGridOUTPUT[vector: any]Resulting vector grid layer. The output ge-\nometry type (point, line or polygon) de-\npends on theGrid type.\nPython code\nAlgorithm ID:native:creategrid\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate points layer from table\nCreates points layer from a table with columns that contain coordinates fields.\nBesides X and Y coordinates you can also specify Z and M fields.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer or a table.\nX fieldXFIELD[tablefield: any]Field containing the X coordinate\nY fieldYFIELD[tablefield: any]Field containing the Y coordinate\nZ field\nOptional\nZFIELD[tablefield: any]Field containing the Z coordinate\nM field\nOptional\nMFIELD[tablefield: any]Field containing the M value\nTarget CRSTARGET_CRS[crs]\nDefault:\nEPSG:4326\nCoordinate reference system to use for\nlayer.  The provided coordinates are as-\nsumed to be compliant.\ncontinues on next page\n25.1. QGIS algorithm provider1033\n\nQGIS Desktop 3.22 User Guide\nTable 25.104 – continued from previous page\nLabelNameTypeDescription\nPoints from tableOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the resulting point layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPoints from tableOUTPUT[vector: point]The resulting point layer\nPython code\nAlgorithm ID:native:createpointslayerfromtable\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGenerate points (pixel centroids) along line\nGenerates a point vector layer from an input raster and line layer.\nThe points correspond to the pixel centroids that intersect the line layer.\nFig. 25.39: Points of the pixel centroids\n1034Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Input raster layer\nVector layerINPUT_VECTOR[vector: line]Input line vector layer\nPoints along lineOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nResulting point layer with pixel centroids.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPoints along lineOUTPUT[vector: point]Resulting point layer with pixel centroids\nPython code\nAlgorithm ID:qgis:generatepointspixelcentroidsalongline\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGenerate points (pixel centroids) inside polygon\nGenerates a point vector layer from an input raster and polygon layer.\nThe points correspond to the pixel centroids that intersect the polygon layer.\n25.1. QGIS algorithm provider1035\n\nQGIS Desktop 3.22 User Guide\nFig. 25.40: Points of the pixel centroids\n1036Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Input raster layer\nVector layerINPUT_VECTOR[vector: polygon]Input polygon vector layer\nPoints inside poly-\ngons\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nResulting point layer of pixel centroids.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPoints inside poly-\ngons\nOUTPUT[vector: point]Resulting point layer of pixel centroids\nPython code\nAlgorithm ID:native:generatepointspixelcentroidsinsidepolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nImport geotagged photos\nCreates a point layer corresponding to the geotagged locations from JPEG images from a source folder.\nThe point layer will contain a single PointZ feature per input file from which the geotags could be read. Any altitude\ninformation from the geotags will be used to set the point’s Z value.\nBesides longitude and latitude also altitude, direction and timestamp information, if present in the photo, will be\nadded to the point as attributes.\nParameters\nLabelNameTypeDescription\nInput folderFOLDER[folder]Path to the source folder containing the geo-\ntagged photos\nScan recursivelyRECURSIVE[boolean]\nDefault: False\nIf checked, the folder and its subfolders will\nbe scanned\ncontinues on next page\n25.1. QGIS algorithm provider1037\n\nQGIS Desktop 3.22 User Guide\nTable 25.105 – continued from previous page\nLabelNameTypeDescription\nPhotos\nOptional\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the point vector layer for the geo-\ntagged photos. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nInvalid photos ta-\nble\nOptional\nINVALID[table]\nDefault:[Skip\noutput]\nSpecify the table of unreadable or non-\ngeotagged photos. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPhotosOUTPUT[vector: point]Point vector layer with geotagged photos.\nThe form of the layer is automatically filled\nwith paths and photo previews settings.\nInvalid photos ta-\nble\nOptional\nINVALID[table]Table of unreadable or non-geotagged pho-\ntos can also be created.\nPython code\nAlgorithm ID:native:importphotos\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPoints to path\nConverts a point layer to a line layer, by joining points in an order defined by an expression or a field in the input\npoint layer.\nPoints can be grouped by a field or an expression to distinguish line features.\nIn addition to the line vector layer, a text file is output that describes the resulting line as a start point and a sequence\nof bearings / directions (relative to azimuth) and distances.\n1038Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput point layerINPUT[vector: point]Input point vector layer\nCreate    closed\npaths\nCLOSE_PATH[boolean]\nDefault: False\nIf checked, the first and last points of the\nline will be connected and close the gener-\nated path\nOrder expression\nNEW in 3.18\nOptional\nOR-\nDER_EXPRESSION\n[expression]Field or expression providing the order to\nconnect the points in the path. If not set,\nthe feature ID ($id) is used.\nSort text contain-\ning numbers natu-\nrallyNEW in 3.\n18\nOptional\nNATURAL_SORT[boolean]\nDefault: False\nIf checked, naturally sorts the features\nbased on the provided expression (i.e., ‘a9’\n< ‘a10’).\nPath  group  ex-\npression\nOptional\nGROUP_EXPRESSION[expression]Point features of the same value in the field\nor expression will be grouped in the same\nline. If not set, a single path is drawn with\nall the input points.\nPathsOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the line vector layer of the path.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nDirectory for text\noutput\nOptional\nOUT-\nPUT_TEXT_DIR\n[folder]\nDefault:[Skip\noutput]\nSpecify the directory that will contain the\ndescription files of points and paths. One\nof:\n•Skip Output\n•Save to a Temporary Directory\n•Save to Directory\nOutputs\nLabelNameTypeDescription\nPathsOUTPUT[vector: line]Line vector layer of the path\nDirectory for text\noutput\nOUT-\nPUT_TEXT_DIR\n[folder]Directory containing description files of\npoints and paths\nPython code\nAlgorithm ID:native:pointstopath\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1039\n\nQGIS Desktop 3.22 User Guide\nRandom points along line\nCreates a new point layer, with points placed on the lines of another layer.\nFor each line in the input layer, a given number of points is added to the resulting layer. The procedure for adding a\npoint is to:\n1.randomly select a line feature from the input layer\n2.if the feature is multi-part, randomly select a part of it\n3.randomly select a segment of that line\n4.randomly select a position on that segment.\nThe procedure means that curved parts of the lines (with relatively short segments) will get more points than straight\nparts (with relatively long segments), as demonstrated in the illustration below, where the output of theRandom points\nalong linesalgorithm can be compared with the output of theRandom points on linesalgorithm (that produces points\nwith an, on average, even distribution along the lines).\nFig. 25.41: Example algorithm output. Left:Random points along line, right:Random points on lines\nA minimum distance can be specified, to avoid points being too close to each other.\nSee also:\nRandom points on lines\n1040Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput point layerINPUT[vector: line]Input line vector layer\nNumber of pointsPOINTS_NUMBER[number]\nDefault: 1\nNumber of points to create\nMinimum   dis-\ntance   between\npoints\nMIN_DISTANCE[number]\nDefault: 0.0\nThe minimum distance between points\nRandom pointsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nThe output random points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRandom pointsOUTPUT[vector: point]The output random points layer.\nPython code\nAlgorithm ID:qgis:qgisrandompointsalongline\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom points in extent\nCreates a new point layer with a given number of random points, all of them within a given extent.\nA distance factor can be specified, to avoid points being too close to each other. If the minimum distance between\npoints makes it impossible to create new points, either distance can be decreased or the maximum number of attempts\nmay be increased.\nDefault menu:Vector►Research Tools\n25.1. QGIS algorithm provider1041\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput extentEXTENT[extent]Map extent for the random points\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nNumber of pointsPOINTS_NUMBER[number]\nDefault: 1\nNumber of point to create\nMinimum   dis-\ntance   between\npoints\nMIN_DISTANCE[number]\nDefault: 0.0\nThe minimum distance between points\nTarget CRSTARGET_CRS[crs]\nDefault:Project\nCRS\nCRS of the random points layer\nRandom pointsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nThe output random points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nMaximum  num-\nber  of  search\nattempts   given\nthe    minimum\ndistance\nMAX_ATTEMPTS[number]\nDefault: 200\nMaximum number of attempts to place the\npoints\nOutputs\nLabelNameTypeDescription\nRandom pointsOUTPUT[vector: point]The output random points layer.\n1042Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:randompointsinextent\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom points in layer bounds\nCreates a new point layer with a given number of random points, all of them within the extent of a given layer.\nA minimum distance can be specified, to avoid points being too close to each other.\nDefault menu:Vector►Research Tools\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input polygon layer defining the area\nNumber of pointsPOINTS_NUMBER[number]\nDefault: 1\nNumber of points to create\nMinimum   dis-\ntance   between\npoints\nMIN_DISTANCE[number]\nDefault: 0.0\nThe minimum distance between points\nRandom pointsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nThe output random points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRandom pointsOUTPUT[vector: point]The output random points layer.\nPython code\nAlgorithm ID:qgis:randompointsinlayerbounds\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1043\n\nQGIS Desktop 3.22 User Guide\nRandom points in polygons\nCreates a point layer with points placed inside the polygons of another layer.\nFor each feature (polygon / multi-polygon) geometry in the input layer, the given number of points is added to the\nresult layer.\nPer feature and global minimum distances can be specified in order to avoid points being too close in the output point\nlayer. If a minimum distance is specified, it may not be possible to generate the specified number of points for each\nfeature. The total number of generated points and missed points are available as output from the algorithm.\nThe illustration below shows the effect of per feature and global minimum distances and zero/non-zero minimum\ndistances (generated with the same seed, so at least the first point generated will be the same).\nFig. 25.42: Ten points per polygon feature,left: min. distances = 0,middle: min.distances = 1,right: min. distance\n= 1, global min. distance = 0\nThe maximum number of tries per point can be specified. This is only relevant for non-zero minimum distance.\nA seed for the random number generator can be provided, making it possible to get identical random number se-\nquences for different runs of the algorithm.\nThe attributes of the polygon feature on which a point was generated can be included (Include polygon attributes).\nIf you want approximately the same point density for all the features, you can data-define the number of points using\nthe area of the polygon feature geometry.\nSee also:\nRandom points inside polygons\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput   polygon\nlayer\nINPUT[vector: line]Input polygon vector layer\nNumber of points\nfor each feature\nPOINTS_NUMBER[number]\nDefault: 1\nNumber of points to create\nMinimum   dis-\ntance   between\npoints\nOptional\nMIN_DISTANCE[number]\nDefault: 0.0\nThe minimum distance between points\nwithin one polygon feature\ncontinues on next page\n1044Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.108 – continued from previous page\nLabelNameTypeDescription\nRandom points in\npolygons\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nThe output random points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nGlobal minimum\ndistance between\npoints\nOptional\nMIN_DISTANCE_GLOBAL[number]\nDefault: 0.0\nThe global minimum distance between\npoints. Should be smaller than theMini-\nmum distance between points (per feature)\nfor that parameter to have an effect.\nMaximum  num-\nber  of  search\nattempts (for Min.\ndist. > 0)\nOptional\nMAX_TRIES_PER_POINT[number]\nDefault: 10\nThe maximum number of tries per point.\nOnly relevant if the minimum distance be-\ntween points is set (and greater than 0).\nRandom seed\nOptional\nSEED[number]\nDefault: Not set\nThe seed to use for the random number gen-\nerator.\nInclude  polygon\nattributes\nIN-\nCLUDE_POLYGON_ATTRIBUTES\n[boolean]\nDefault: True\nIf set, a point will get the attributes from the\nline on which it is placed.\nOutputs\nLabelNameTypeDescription\nRandom points in\npolygons\nOUTPUT[vector: point]The output random points layer.\nNumber of fea-\ntures with empty\nor no geometry\nFEA-\nTURES_WITH_EMPTY_OR_NO_GEOMETRY\n[number]\nTotal number of\npoints generated\nOUTPUT_POINTS[number]\nNumber of missed\npoints\nPOINTS_MISSED[number]The number of points that could not be gen-\nerated due to the minimum distance con-\nstraint.\nNumber of fea-\ntures with missed\npoints\nPOLY-\nGONS_WITH_MISSED_POINTS\n[number]Not including features with empty or no ge-\nometry\n25.1. QGIS algorithm provider1045\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:randompointsinpolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom points inside polygons\nCreates a new point layer with a given number of random points inside each polygon of the input polygon layer.\nTwo sampling strategies are available:\n•Points count: number of points for each feature\n•Points density: density of points for each feature\nA minimum distance can be specified, to avoid points being too close to each other.\nDefault menu:Vector►Research Tools\nSee also:\nRandom points in polygons\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input polygon vector layer\nSampling strategySTRATEGY[enumeration]\nDefault: 0\nSampling strategy to use. One of:\n•0 — Points count: number of points\nfor each feature\n•1 — Points density: density of points\nfor each feature\nPoint  count  or\ndensity\nVALUE[number]\nDefault: 1.0\nThe number or density of points, depending\non the chosenSampling strategy.\nMinimum   dis-\ntance   between\npoints\nMIN_DISTANCE[number]\nDefault: 0.0\nThe minimum distance between points\nRandom pointsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nThe output random points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1046Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nRandom pointsOUTPUT[vector: point]The output random points layer.\nPython code\nAlgorithm ID:qgis:randompointsinsidepolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom points on lines\nCreates a point layer with points placed on the lines of another layer.\nFor each feature (line / multi-line) geometry in the input layer, the given number of points is added to the result layer.\nPer feature and global minimum distances can be specified in order to avoid points being too close in the output point\nlayer. If a minimum distance is specified, it may not be possible to generate the specified number of points for each\nfeature. The total number of generated points and missed points are available as output from the algorithm.\nThe illustration below shows the effect of per feature and global minimum distances and zero/non-zero minimum\ndistances (generated with the same seed, so at least the first point generated will be the same).\nFig. 25.43: Five points per line feature,left: min. distances = 0,middle: min.distances != 0,right: min. distance !=\n0, global min. distance = 0\n25.1. QGIS algorithm provider1047\n\nQGIS Desktop 3.22 User Guide\nThe maximum number of tries per point can be specified. This is only relevant for non-zero minimum distance.\nA seed for the random number generator can be provided, making it possible to get identical random number se-\nquences for different runs of the algorithm.\nThe attributes of the line feature on which a point was generated can be included (Include line attributes).\nIf you want approximately the same point density for all the line features, you can data-define the number of points\nusing the length of the line feature geometry.\nSee also:\nRandom points along line\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput line layerINPUT[vector: line]Input line vector layer\nNumber of points\nfor each feature\nPOINTS_NUMBER[number]\nDefault: 1\nNumber of points to create\nMinimum   dis-\ntance   between\npoints (per fea-\nture)\nOptional\nMIN_DISTANCE[number]\nDefault: 0.0\nThe minimum distance between points\nwithin one line feature\nRandom points on\nlines\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nThe output random points. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nGlobal minimum\ndistance between\npoints\nOptional\nMIN_DISTANCE_GLOBAL[number]\nDefault: 0.0\nThe global minimum distance between\npoints. Should be smaller than theMini-\nmum distance between points (per feature)\nfor that parameter to have an effect.\nMaximum  num-\nber  of  search\nattempts (for Min.\ndist. > 0)\nOptional\nMAX_TRIES_PER_POINT[number]\nDefault: 10\nThe maximum number of tries per point.\nOnly relevant if the minimum distance be-\ntween points is set (and greater than 0).\nRandom seed\nOptional\nSEED[number]\nDefault: Not set\nThe seed to use for the random number gen-\nerator.\nIncludeline\nattributes\nIN-\nCLUDE_LINE_ATTRIBUTES\n[boolean]\nDefault: True\nIf set, a point will get the attributes from the\nline on which it is placed.\n1048Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nRandom points on\nlines\nOUTPUT[vector: point]The output random points layer.\nNumber of fea-\ntures with empty\nor no geometry\nFEA-\nTURES_WITH_EMPTY_OR_NO_GEOMETRY\n[number]\nNumber of fea-\ntures with missed\npoints\nLINES_WITH_MISSED_POINTS[number]Not including features with empty or no ge-\nometry\nTotal number of\npoints generated\nPOINTS_GENERATED[number]\nNumber of missed\npoints\nPOINTS_MISSED[number]The number of points that could not be gen-\nerated due to the minimum distance con-\nstraint.\nPython code\nAlgorithm ID:native:randompointsonlines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster pixels to points\nCreates a vector layer of points corresponding to each pixel in a raster layer.\nConverts a raster layer to a vector layer, by creating point features for each individual pixel’s center in the raster layer.\nAny nodata pixels are skipped in the output.\nParameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Input raster layer\nBand numberRASTER_BAND[raster band]Raster band to extract data from\nField nameFIELD_NAME[string]\nDefault: ‘VALUE’\nName of the field to store the raster band\nvalue\nVector pointsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the resulting point layer of pixels\ncentroids. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1049\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nVector pointsOUTPUT[vector: point]Resulting point layer with pixels centroids\nPython code\nAlgorithm ID:native:pixelstopoints\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster pixels to polygons\nCreates a vector layer of polygons corresponding to each pixel in a raster layer.\nConverts a raster layer to a vector layer, by creating polygon features for each individual pixel’s extent in the raster\nlayer. Any nodata pixels are skipped in the output.\nParameters\nLabelNameTypeDescription\nRaster layerINPUT_RASTER[raster]Input raster layer\nBand numberRASTER_BAND[raster band]Raster band to extract data from\nField nameFIELD_NAME[string]\nDefault: ‘VALUE’\nName of the field to store the raster band\nvalue\nVector polygonsOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the resulting polygon layer of pixel\nextents. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nVector polygonsOUTPUT[vector: polygon]Resulting polygon layer of pixel extents\n1050Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:pixelstopolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRegular points\nCreates a new point layer with its points placed in a regular grid within a given extent.\nThe grid is specified either by the spacing between the points (same spacing for all dimensions) or by the number\nof points to generate. In the latter case, the spacing will be determined from the extent. In order to generate a full\nrectangular grid, at least the number of points specified by the user is generated for the latter case.\nRandom offsets to the point spacing can be applied, resulting in a non-regular point pattern.\nDefault menu:Vector►Research Tools\nParameters\nLabelNameTypeDescription\nInputextent\n(xmin,    xmax,\nymin, ymax)\nEXTENT[extent]Map extent for the random points\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nPointspac-\ning/count\nSPACING[number]\nDefault: 100\nSpacing between the points, or the num-\nber of points, depending on whetherUse\npoint spacingis checked or not.\nInitial inset from\ncorner (LH side)\nINSET[number]\nDefault: 0.0\nOffsets the points relative to the upper left\ncorner. The value is used for both the X and\nY axis.\nApply random off-\nset to point spac-\ning\nRANDOMIZE[boolean]\nDefault: False\nIf checked the points will have a random\nspacing\nUse point spacingIS_SPACING[boolean]\nDefault: True\nIf unchecked the point spacing is not taken\ninto account\nOutput layer CRSCRS[crs]\nDefault:Project\nCRS\nCRS of the random points layer\ncontinues on next page\n25.1. QGIS algorithm provider1051\n\nQGIS Desktop 3.22 User Guide\nTable 25.115 – continued from previous page\nLabelNameTypeDescription\nRegular pointsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output regular point layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRegular pointsOUTPUT[vector: point]The output regular point layer.\nPython code\nAlgorithm ID:qgis:regularpoints\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.17Vector general\nAssign projection\nAssigns a new projection to a vector layer.\nIt creates a new layer with the exact same features and geometries as the input one, but assigned to a new CRS. The\ngeometries arenotreprojected, they are just assigned to a different CRS.\nThis algorithm can be used to repair layers which have been assigned an incorrect projection.\nAttributes are not modified by this algorithm.\nSee also:\nDefine Shapefile projection,Find projection,Reproject layer\n1052Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer with wrong or missing CRS\nAssigned CRSCRS[crs]\nDefault:\nEPSG:4326\n- WGS84\nSelect the new CRS to assign to the vector\nlayer\nAssigned CRS\nOptional\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer containing only the\nduplicates. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nAssigned CRSOUTPUT[same as input]Vector layer with assigned projection\nPython code\nAlgorithm ID:native:assignprojection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nBatch Nominatim geocoder\nPerforms batch geocoding using the Nominatim service against an input layer string field. The output layer will have a\npoint geometry reflecting the geocoded location as well as a number of attributes associated to the geocoded location.\nNote:This algorithm is compliant with theusage policyof the Nominatim geocoding service provided by the\nOpenStreetMap Foundation.\n25.1. QGIS algorithm provider1053\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer to geocode the features\nAddress fieldFIELD[tablefield: string]Field containing the addresses to geocode\nGeocodedOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer containing only the\ngeocoded addresses. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nGeocodedOUTPUT[vector: point]Vector layer with point features corre-\nsponding to the geocoded addresses\nPython code\nAlgorithm ID:native:batchnominatimgeocoder\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConvert layer to spatial bookmarks\nCreates spatial bookmarks corresponding to the extent of features contained in a layer.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: line, poly-\ngon]\nThe input vector layer\nBookmark  desti-\nnation\nDESTINATION[enumeration]\nDefault: 0\nSelect the destination for the bookmarks.\nOne of:\n•0 — Project bookmarks\n•1 — User bookmarks\nName fieldNAME_EXPRESSION[expression]Field or expression that will give names to\nthe generated bookmarks\nGroup fieldGROUP_EXPRESSION[expression]Field or expression that will provide groups\nfor the generated bookmarks\n1054Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nCount of book-\nmarks added\nCOUNT[number]\nPython code\nAlgorithm ID:native:layertobookmarks\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConvert spatial bookmarks to layer\nCreates a new layer containing polygon features for stored spatial bookmarks. The export can be filtered to only\nbookmarks belonging to the current project, to all user bookmarks, or a combination of both.\nParameters\nLabelNameTypeDescription\nBookmark sourceSOURCE[enumeration] [list]\nDefault: [0,1]\nSelect the source(s) of the bookmarks. One\nor more of:\n•0 — Project bookmarks\n•1 — User bookmarks\nOutput CRSCRS[crs]\nDefault:\nEPSG:4326\n- WGS 84\nThe CRS of the output layer\nOutputOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1055\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[vector: polygon]The output (bookmarks) vector layer\nPython code\nAlgorithm ID:native:bookmarkstolayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate attribute index\nCreates an index against a field of the attribute table to speed up queries. The support for index creation depends on\nboth the layer’s data provider and the field type.\nNo outputs are created: the index is stored on the layer itself.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Select the vector layer you want to create an\nattribute index for\nAttribute to indexFIELD[tablefield: any]Field of the vector layer\nOutputs\nLabelNameTypeDescription\nIndexed layerOUTPUT[same as input]A copy of the input vector layer with an in-\ndex for the specified field\nPython code\nAlgorithm ID:native:createattributeindex\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1056Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nCreate spatial index\nCreates an index to speed up access to the features in a layer based on their spatial location. Support for spatial index\ncreation is dependent on the layer’s data provider.\nNo new output layers are created.\nDefault menu:Vector►Data Management Tools\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer\nOutputs\nLabelNameTypeDescription\nIndexed layerOUTPUT[same as input]A copy of the input vector layer with a spa-\ntial index\nPython code\nAlgorithm ID:native:createspatialindex\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDefine Shapefile projection\nSets the CRS (projection) of an existing Shapefile format dataset to the provided CRS. It is very useful when a\nShapefile format dataset is missing theprjfile and you know the correct projection.\nContrary to the\nAssign projectionalgorithm, it modifies the current layer and will not output a new layer.\nNote:For Shapefile datasets, the.prjand.qpjfiles will be overwritten - or created if missing - to match the\nprovided CRS.\nDefault menu:Vector►Data Management Tools\nSee also:\nAssign projection,Find projection,Reproject layer\n25.1. QGIS algorithm provider1057\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer with missing projection infor-\nmation\nCRSCRS[crs]Select the CRS to assign to the vector layer\nOutputs\nLabelNameTypeDescription\nINPUT[same as input]The input vector layer with the defined pro-\njection\nPython code\nAlgorithm ID:qgis:definecurrentprojection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDelete duplicate geometries\nFinds and removes duplicated geometries.\nAttributes are not checked, so in case two features have identical geometries but different attributes, only one of them\nwill be added to the result layer.\nSee also:\nDrop geometries,Remove null geometries,Delete duplicates by attribute\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The layer with duplicate geometries you\nwant to clean\nCleanedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1058Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nCount  of  dis-\ncarded  duplicate\nrecords\nDUPLI-\nCATE_COUNT\n[number]Count of discarded duplicate records\nCleanedOUTPUT[same as input]The output layer without any duplicated ge-\nometries\nCount of retained\nrecords\nRE-\nTAINED_COUNT\n[number]Count of unique records\nPython code\nAlgorithm ID:native:deleteduplicategeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDelete duplicates by attribute\nDeletes duplicate rows by only considering the specified field / fields. The first matching row will be retained, and\nduplicates will be discarded.\nOptionally, these duplicate records can be saved to a separate output for analysis.\nSee also:\nDelete duplicate geometries\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer\nFields to match\nduplicates by\nFIELDS[tablefield:    any]\n[list]\nFields defining duplicates.  Features with\nidentical values for all these fields are con-\nsidered duplicates.\nFiltered (no dupli-\ncates)\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer containing the\nunique features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\ncontinues on next page\n25.1. QGIS algorithm provider1059\n\nQGIS Desktop 3.22 User Guide\nTable 25.116 – continued from previous page\nLabelNameTypeDescription\nFiltered  (dupli-\ncates)\nOptional\nDUPLICATES[same as input]\nDefault:[Skip\noutput]\nSpecify the output layer containing only the\nduplicates. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nFiltered  (dupli-\ncates)\nOptional\nDUPLICATES[same as input]\nDefault:[Skip\noutput]\nVector layer containing the removed fea-\ntures. Will not be produced if not specified\n(left as[Skip output]).\nCount  of  dis-\ncarded  duplicate\nrecords\nDUPLI-\nCATE_COUNT\n[number]Count of discarded duplicate records\nFiltered (no dupli-\ncates)\nOUTPUT[same as input]Vector layer containing the unique features.\nCount of retained\nrecords\nRE-\nTAINED_COUNT\n[number]Count of unique records\nPython code\nAlgorithm ID:native:removeduplicatesbyattribute\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDetect dataset changes\nCompares two vector layers, and determines which features are unchanged, added or deleted between the two. It is\ndesigned for comparing two different versions of the same dataset.\n1060Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.44: Detect dataset change example\nParameters\nLabelNameTypeDescription\nOriginal layerORIGINAL[vector: any]The vector layer considered as the original\nversion\nRevised layerREVISED[vector: any]The revised or modified vector layer\nAttributes to con-\nsider for match\nOptional\nCOM-\nPARE_ATTRIBUTES\n[tablefield:    any]\n[list]\nAttributes to consider for match. By de-\nfault, all attributes are compared.\nGeometry  com-\nparison behavior\nOptional\nMATCH_TYPE[enumeration]\nDefault: 1\nDefines the criteria for comparison. Op-\ntions:\n•0 — Exact Match: includes the order\nand vertices count of geometries\n•1 — Tolerant Match (Topological\nEquality): geometries are considered\nequal\nUnchanged  fea-\ntures\nUNCHANGED[vector:  same as\nOriginal layer]\nSpecify the output vector layer containing\nthe unchanged features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdded featuresADDED[vector:  same as\nOriginal layer]\nSpecify the output vector layer containing\nthe added features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\ncontinues on next page\n25.1. QGIS algorithm provider1061\n\nQGIS Desktop 3.22 User Guide\nTable 25.118 – continued from previous page\nLabelNameTypeDescription\nDeleted featuresDELETED[vector:  same as\nOriginal layer]\nSpecify the output vector layer containing\nthe deleted features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nUnchanged  fea-\ntures\nUNCHANGED[vector:  same as\nOriginal layer]\nVector layer containing the unchanged fea-\ntures.\nAdded featuresADDED[vector:  same as\nOriginal layer]\nVector layer containing the added features.\nDeleted featuresDELETED[vector:  same as\nOriginal layer]\nVector layer containing the deleted features.\nCount  of  un-\nchanged features\nUN-\nCHANGED_COUNT\n[number]Count of unchanged features.\nCount of features\nadded in revised\nlayer\nADDED_COUNT[number]Count of features added in revised layer.\nCount of features\ndeleted from orig-\ninal layer\nDELETED_COUNT[number]Count of features deleted from original\nlayer.\nPython code\nAlgorithm ID:native:detectvectorchanges\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDrop geometries\nCreates a simplegeometrylesscopy of the input layer attribute table. It keeps the attribute table of the source layer.\nIf the file is saved in a local folder, you can choose between many file formats.\nAllowsfeatures in-place modification\nSee also:\nDelete duplicate geometries,Remove null geometries\n1062Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nDropped  geome-\ntries\nOUTPUT[table]Specify the output geometryless layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nDropped  geome-\ntries\nOUTPUT[table]The output geometryless layer. A copy of\nthe original attribute table.\nPython code\nAlgorithm ID:native:dropgeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExecute SQL\nRuns a simple or complex query withSQLsyntax on the source layer.\nInput datasources are identified withinput1,input2...inputNand a simple query will look likeSELECT *\nFROM input1.\nBeside a simple query, you can add expressions or variables within theSQL queryparameter itself. This is\nparticulary useful if this algorithm is executed within a Processing model and you want to use a model input as a\nparameter of the query. An example of a query will then beSELECT * FROM [% @table %]where@table\nis the variable that identifies the model input.\nThe result of the query will be added as a new layer.\nSee also:\nSpatiaLite execute SQL,PostgreSQL execute SQL\n25.1. QGIS algorithm provider1063\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nAdditional   in-\nput  datasources\n(called   input1,\n.., inputN in the\nquery)\nIN-\nPUT_DATASOURCES\n[vector: any] [list]List of layers to query. In the SQL editor\nyou can refer these layers with theirreal\nname or also withinput1,input2,inputN\ndepending on how many layers have been\nchosen.\nSQL queryINPUT_QUERY[string]Type the string of your SQL query, e.g.\nSELECT * FROM input1.\nUnique identifier\nfield\nOptional\nIN-\nPUT_UID_FIELD\n[string]Specify the column with unique ID\nGeometry field\nOptional\nIN-\nPUT_GEOMETRY_FIELD\n[string]Specify the geometry field\nGeometry type\nOptional\nIN-\nPUT_GEOMETRY_TYPE\n[enumeration]\nDefault: 0\nChoose the geometry of the result. By de-\nfault the algorithm will autodetect it. One\nof:\n•0 — Autodetect\n•1 — No geometry\n•2 — Point\n•3 — LineString\n•4 — Polygon\n•5 — MultiPoint\n•6 — MultiLineString\n•7 — MultiPolygon\nCRS\nOptional\nIN-\nPUT_GEOMETRY_CRS\n[crs]The CRS to assign to the output layer\nSQL OutputOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer created by the\nquery. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSQL OutputOUTPUT[vector: any]Vector layer created by the query\nPython code\nAlgorithm ID:qgis:executesql\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1064Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExport layers to DXF\nNEW in 3.18\nExports layers to DXF file. For each layer, you can choose a field whose values are used to split features in generated\ndestination layers in DXF output.\nSee also:\nCreating new DXF files\nParameters\nLabelNameTypeDescription\nInput layersLAYERS[vector: any][list]Input vector layers to export\nSymbology modeSYMBOL-\nOGY_MODE\n[enumeration]\nDefault: 0\nType of symbology to apply to output lay-\ners. You can choose between:\n•0 — No Symbology\n•1 — Feature Symbology\n•2 — Symbol Layer Symbology\nSymbology scaleSYMBOL-\nOGY_SCALE\n[scale]\nDefault:  1:1 000\n000\nDefault scale of data export.\nEncodingENCODING[enumeration]Encoding to apply to layers.\nCRSCRS[crs]Choose the CRS for the output layer.\nUse layer title as\nname\nUSE_LAYER_TITLE[boolean]\nDefault: False\nName the output layer with the layer title\n(as set in QGIS) instead of the layer name.\nForce 2DFORCE_2D[boolean]\nDefault: False\nExport labels as\nMTEXT elements\nMTEXT[boolean]\nDefault: False\nExports labels as MTEXT or TEXT ele-\nments\nDXFOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output DXF file. One\nof:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nDXFOUTPUT[file].DXFfile containing the input layers\nPython code\nAlgorithm ID:native:dxfexport\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1065\n\nQGIS Desktop 3.22 User Guide\nExtract selected features\nSaves the selected features as a new layer.\nNote:If the selected layer has no selected features, the newly created layer will be empty.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Layer to save the selection from\nSelected featuresOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the vector layer for the selected fea-\ntures. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSelected featuresOUTPUT[same as input]Vector layer with only the selected features,\nor no feature if none was selected.\nPython code\nAlgorithm ID:native:saveselectedfeatures\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract Shapefile encoding\nExtracts the attribute encoding information embedded in a Shapefile. Both the encoding specified by an optional\n.cpgfile and any encoding details present in the.dbfLDID header block are considered.\n1066Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]ESRI Shapefile (.SHP) Layer to extract the\nencoding information.\nOutputs\nLabelNameTypeDescription\nShapefile  encod-\ning\nENCODING[string]Encoding information specified in the input\nfile\nCPG encodingCPG_ENCODING[string]Encoding information specified in any op-\ntional.CPGfile\nLDID encodingLDID_ENCODING[string]Encoding information specified in.dbf\nLDID header block\nPython code\nAlgorithm ID:native:shpencodinginfo\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFind projection\nCreates a shortlist of candidate coordinate reference systems, for instance for a layer with an unknown projection.\nThe area that the layer is expected to cover must be specified via the target area parameter. The coordinate reference\nsystem for this target area must be known to QGIS.\nThe algorithm operates by testing the layer’s extent in every known reference system and then listing any for which\nthe bounds would be near the target area if the layer was in this projection.\nSee also:\nAssign projection,Define Shapefile projection,Reproject layer\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Layer with unknown projection\ncontinues on next page\n25.1. QGIS algorithm provider1067\n\nQGIS Desktop 3.22 User Guide\nTable 25.122 – continued from previous page\nLabelNameTypeDescription\nTarget area for\nlayer(xmin, xmax,\nymin, ymax)\nTARGET_AREA[extent]The area that the layer covers.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nCRS candidatesOUTPUT[table]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the table (geometryless layer) for\nthe CRS suggestions (EPSG codes). One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCRS candidatesOUTPUT[table]A table with all the CRS (EPSG codes) of\nthe matching criteria.\nPython code\nAlgorithm ID:qgis:findprojection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFlatten relationship\nFlattens arelationshipfor a vector layer, exporting a single layer containing one parent feature per related child feature.\nThis master feature contains all the attributes for the related features. This allows to have the relation as a plain table\nthat can be e.g. exported to CSV.\n1068Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.45: Form of a region with related children (left) - A duplicate region feature for each related child, with joined\nattributes (right)\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Layer with the relationship that should be\nde-normalized\nFlattened Layer\nOptional\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (flattened) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nFlattened layerOUTPUT[same as input]A layer containing master features with all\nthe attributes for the related features\nPython code\nAlgorithm ID:native:flattenrelationships\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1069\n\nQGIS Desktop 3.22 User Guide\nJoin attributes by field value\nTakes an input vector layer and creates a new vector layer that is an extended version of the input one, with additional\nattributes in its attribute table.\nThe additional attributes and their values are taken from a second vector layer. An attribute is selected in each of\nthem to define the join criteria.\nSee also:\nJoin attributes by nearest,Join attributes by location\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer. The output layer will\nconsist of the features of this layer with at-\ntributes from matching features in the sec-\nond layer.\nTable fieldFIELD[tablefield: any]Field of the source layer to use for the join\nInput layer 2INPUT_2[vector: any]Layer with the attribute table to join\nTable field 2FIELD_2[tablefield: any]Field of the second (join) layer to use for\nthe join The type of the field must be equal\nto (or compatible with) the input table field\ntype.\nLayer 2 fields to\ncopy\nOptional\nFIELDS_TO_COPY[tablefield:    any]\n[list]\nSelect the specific fields you want to add.\nBy default all the fields are added.\nJoin typeMETHOD[enumeration]\nDefault: 1\nThe type of the final joined layer. One of:\n•0 — Create separate feature for each\nmatching feature (one-to-many)\n•1 — Take attributes of the first\nmatching feature only (one-to-one)\nDiscard  records\nwhich could not\nbe joined\nDIS-\nCARD_NONMATCHING\n[boolean]\nDefault: True\nCheck if you don’t want to keep the features\nthat could not be joined\nJoined field prefix\nOptional\nPREFIX[string]Add a prefix to joined fields in order to eas-\nily identify them and avoid field name colli-\nsion\nJoined layerOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the join.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\ncontinues on next page\n1070Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.124 – continued from previous page\nLabelNameTypeDescription\nUnjoinable  fea-\ntures from first\nlayer\nNON_MATCHING[same as input]\nDefault:[Skip\noutput]\nSpecify the output vector layer for unjoin-\nable features from first layer. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nNumber of joined\nfeatures from in-\nput table\nJOINED_COUNT[number]\nUnjoinable  fea-\ntures from first\nlayer\nOptional\nNON_MATCHING[same as input]Vector layer with the non-matched features\nJoined layerOUTPUT[same as input]Output vector layer with added attributes\nfrom the join\nNumber  of  un-\njoinable features\nfrom input table\nOptional\nUNJOIN-\nABLE_COUNT\n[number]\nPython code\nAlgorithm ID:native:joinattributestable\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nJoin attributes by location\nTakes an input vector layer and creates a new vector layer that is an extended version of the input one, with additional\nattributes in its attribute table.\nThe additional attributes and their values are taken from a second vector layer. A spatial criteria is applied to select\nthe values from the second layer that are added to each feature from the first layer.\nDefault menu:Vector►Data Management Tools\nSee also:\nJoin attributes by nearest,Join attributes by field value,Join attributes by location (summary)\n25.1. QGIS algorithm provider1071\n\nQGIS Desktop 3.22 User Guide\nExploring spatial relations\nGeometric predicates are boolean functions used to determine the spatial relation a feature has with another by\ncomparing whether and how their geometries share a portion of space.\nFig. 25.46: Looking for spatial relations between layers\nUsing the figure above, we are looking for the green circles by spatially comparing them to the orange rectangle\nfeature. Available geometric predicates are:\nIntersectTests whether a geometry intersects another. Returns 1 (true) if the geometries spatially intersect (share\nany portion of space - overlap or touch) and 0 if they don’t. In the picture above, this will return circles 1, 2\nand 3.\nContainReturns 1 (true) if and only if no points of b lie in the exterior of a, and at least one point of the interior of\nb lies in the interior of a. In the picture, no circle is returned, but the rectangle would be if you would look for\nit the other way around, as it contains circle 1 completely. This is the opposite ofare within.\nDisjointReturns 1 (true) if the geometries do not share any portion of space (no overlap, not touching). Only circle\n4 is returned.\nEqualReturns 1 (true) if and only if geometries are exactly the same. No circles will be returned.\nTouchTests whether a geometry touches another. Returns 1 (true) if the geometries have at least one point in\ncommon, but their interiors do not intersect. Only circle 3 is returned.\nOverlapTests whether a geometry overlaps another. Returns 1 (true) if the geometries share space, are of the same\ndimension, but are not completely contained by each other. Only circle 2 is returned.\nAre withinTests whether a geometry is within another. Returns 1 (true) if geometry a is completely inside geometry\nb. Only circle 1 is returned.\nCrossReturns 1 (true) if the supplied geometries have some, but not all, interior points in common and the actual\ncrossing is of a lower dimension than the highest supplied geometry. For example, a line crossing a polygon\nwill cross as a line (true). Two lines crossing will cross as a point (true). Two polygons cross as a polygon\n(false). In the picture, no circles will be returned.\n1072Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer. The output layer will\nconsist of the features of this layer with at-\ntributes from matching features in the sec-\nond layer.\nJoin layerJOIN[vector: any]The attributes of this vector layer will be\naddedto the source layer attribute table.\nGeometric predi-\ncate\nPREDICATE[enumeration] [list]\nDefault: [0]\nSelect the geometric criteria. One or more\nof:\n•0 — intersects\n•1 — contains\n•2 — equals\n•3 — touches\n•4 — overlaps\n•5 — within\n•6 — crosses\nFields  to  add\n(leave  empty  to\nuse all fields)\nOptional\nJOIN_FIELDS[tablefield:    any]\n[list]\nSelect the specific fields you want to add.\nBy default all the fields are added.\nJoin typeMETHOD[enumeration]The type of the final joined layer. One of:\n•0 — Create separate feature for each\nmatching feature (one-to-many)\n•1 — Take attributes of the first\nmatching feature only (one-to-one)\n•2 — Take attributes of the feature\nwith largest overlap only (one-to-\none)\nDiscard  records\nwhich could not\nbe joined\nDIS-\nCARD_NONMATCHING\n[boolean]\nDefault: False\nRemove from the output the input layer\nrecords which could not be joined\nJoined field prefix\nOptional\nPREFIX[string]Add a prefix to joined fields in order to eas-\nily identify them and avoid field name colli-\nsion\nJoined layerOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the join.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nUnjoinable  fea-\ntures from first\nlayer\nNON_MATCHING[same as input]\nDefault:[Skip\noutput]\nSpecify the output vector layer for unjoin-\nable features from first layer. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1073\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nNumber of joined\nfeatures from in-\nput table\nJOINED_COUNT[number]\nUnjoinable  fea-\ntures from first\nlayer\nOptional\nNON_MATCHING[same as input]Vector layer of the non-matched features\nJoined layerOUTPUT[same as input]Output vector layer with added attributes\nfrom the join\nPython code\nAlgorithm ID:native:joinattributesbylocation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nJoin attributes by location (summary)\nTakes an input vector layer and creates a new vector layer that is an extended version of the input one, with additional\nattributes in its attribute table.\nThe additional attributes and their values are taken from a second vector layer. A spatial criteria is applied to select\nthe values from the second layer that are added to each feature from the first layer.\nThe algorithm calculates a statistical summary for the values from matching features in the second layer (e.g. maxi-\nmum value, mean value, etc).\nSee also:\nJoin attributes by location\nExploring spatial relations\nGeometric predicates are boolean functions used to determine the spatial relation a feature has with another by\ncomparing whether and how their geometries share a portion of space.\n1074Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.47: Looking for spatial relations between layers\nUsing the figure above, we are looking for the green circles by spatially comparing them to the orange rectangle\nfeature. Available geometric predicates are:\nIntersectTests whether a geometry intersects another. Returns 1 (true) if the geometries spatially intersect (share\nany portion of space - overlap or touch) and 0 if they don’t. In the picture above, this will return circles 1, 2\nand 3.\nContainReturns 1 (true) if and only if no points of b lie in the exterior of a, and at least one point of the interior of\nb lies in the interior of a. In the picture, no circle is returned, but the rectangle would be if you would look for\nit the other way around, as it contains circle 1 completely. This is the opposite ofare within.\nDisjointReturns 1 (true) if the geometries do not share any portion of space (no overlap, not touching). Only circle\n4 is returned.\nEqualReturns 1 (true) if and only if geometries are exactly the same. No circles will be returned.\nTouchTests whether a geometry touches another. Returns 1 (true) if the geometries have at least one point in\ncommon, but their interiors do not intersect. Only circle 3 is returned.\nOverlapTests whether a geometry overlaps another. Returns 1 (true) if the geometries share space, are of the same\ndimension, but are not completely contained by each other. Only circle 2 is returned.\nAre withinTests whether a geometry is within another. Returns 1 (true) if geometry a is completely inside geometry\nb. Only circle 1 is returned.\nCrossReturns 1 (true) if the supplied geometries have some, but not all, interior points in common and the actual\ncrossing is of a lower dimension than the highest supplied geometry. For example, a line crossing a polygon\nwill cross as a line (true). Two lines crossing will cross as a point (true). Two polygons cross as a polygon\n(false). In the picture, no circles will be returned.\n25.1. QGIS algorithm provider1075\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer. The output layer will\nconsist of the features of this layer with at-\ntributes from matching features in the sec-\nond layer.\nJoin layerJOIN[vector: any]The attributes of this vector layer will be\naddedto the source layer attribute table.\nGeometric predi-\ncate\nPREDICATE[enumeration] [list]\nDefault: [0]\nSelect the geometric criteria. One or more\nof:\n•0 — intersects\n•1 — contains\n•2 — equals\n•3 — touches\n•4 — overlaps\n•5 — within\n•6 — crosses\nFields to summa-\nrize (leave empty\nto use all fields)\nOptional\nJOIN_FIELDS[tablefield:    any]\n[list]\nSelect the specific fields you want to add\nand summarize. By default all the fields are\nadded.\nSummaries   to\ncalculate   (leave\nempty to use all\nfields)\nOptional\nSUMMARIES[enumeration] [list]\nDefault: []\nChoose which type of summary you want to\nadd to each field and for each feature. One\nor more of:\n•0 — count\n•1 — unique\n•2 — min\n•3 — max\n•4 — range\n•5 — sum\n•6 — mean\n•7 — median\n•8 — stddev\n•9 — minority\n•10 — majority\n•11 — q1\n•12 — q3\n•13 — iqr\n•14 — empty\n•15 — filled\n•16 — min_length\n•17 — max_length\n•18 — mean_length\nDiscard  records\nwhich could not\nbe joined\nDIS-\nCARD_NONMATCHING\n[boolean]\nDefault: False\nRemove from the output the input layer\nrecords which could not be joined\ncontinues on next page\n1076Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.126 – continued from previous page\nLabelNameTypeDescription\nJoined layerOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the join.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nJoined layerOUTPUT[same as input]Output vector layer with summarized at-\ntributes from the join\nPython code\nAlgorithm ID:qgis:joinbylocationsummary\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nJoin attributes by nearest\nTakes an input vector layer and creates a new vector layer with additional fields in its attribute table. The additional\nattributes and their values are taken from a second vector layer. Features are joined by finding the closest features\nfrom each layer.\nBy default only the nearest feature is joined, but the join can also join to the k-nearest neighboring features.\nIf a maximum distance is specified, only features which are closer than this distance will be matched.\nSee also:\nNearest neighbour analysis,Join attributes by field value,Join attributes by location,Distance matrix\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer.\nInput layer 2INPUT_2[vector: any]The join layer.\nLayer 2 fields to\ncopy (leave empty\nto copy all fields)\nFIELDS_TO_COPY[fields]Join layer fields to copy (if empty, all fields\nwill be copied).\nDiscard  records\nwhich could not\nbe joined\nDIS-\nCARD_NONMATCHING\n[boolean]\nDefault: False\nRemove from the output the input layer\nrecords which could not be joined\ncontinues on next page\n25.1. QGIS algorithm provider1077\n\nQGIS Desktop 3.22 User Guide\nTable 25.127 – continued from previous page\nLabelNameTypeDescription\nJoined field prefixPREFIX[string]Joined field prefix\nMaximum nearest\nneighbors\nNEIGHBORS[number]\nDefault: 1\nMaximum number of nearest neighbors\nMaximum   dis-\ntance\nMAX_DISTANCE[number]Maximum search distance\nJoined layerOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the vector layer containing the\njoined features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nUnjoinable  fea-\ntures from first\nlayer\nNON_MATCHING[same as input]\nDefault:[Skip\noutput]\nSpecify the vector layer containing the fea-\ntures that could not be joined. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nJoined layerOUTPUT[same as input]The output joined layer.\nUnjoinable  fea-\ntures from first\nlayer\nNON_MATCHING[same as input]Layer containing the features from first\nlayer that could not be joined to any features\nin the join layer.\nNumber of joined\nfeatures from in-\nput table\nJOINED_COUNT[number]Number of features from the input table\nthat have been joined.\nNumber  of  un-\njoinable features\nfrom input table\nUNJOIN-\nABLE_COUNT\n[number]Number of features from the input table\nthat could not be joined.\nPython code\nAlgorithm ID:native:joinbynearest\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1078Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nMerge vector layers\nCombines multiple vector layers of thesame geometrytype into a single one.\nThe attribute table of the resulting layer will contain the fields from all input layers. If fields with the same name but\ndifferent types are found then the exported field will be automatically converted into a string type field. New fields\nstoring the original layer name and source are also added.\nIf any input layers contain Z or M values, then the output layer will also contain these values. Similarly, if any of the\ninput layers are multi-part, the output layer will also be a multi-part layer.\nOptionally, the destination coordinate reference system (CRS) for the merged layer can be set. If it is not set, the\nCRS will be taken from the first input layer. All layers will be reprojected to match this CRS.\nDefault menu:Vector►Data Management Tools\nSee also:\nSplit vector layer\nParameters\nLabelNameTypeDescription\nInput LayersLAYERS[vector: any] [list]The layers that are to be merged into a sin-\ngle layer. Layers should be of the same ge-\nometry type.\nDestination CRS\nOptional\nCRS[crs]Choose the CRS for the output layer. If not\nspecified, the CRS of the first input layer is\nused.\nMergedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nMergedOUTPUT[same as input]Output vector layer containing all the fea-\ntures and attributes from the input layers.\n25.1. QGIS algorithm provider1079\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:mergevectorlayers\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nOrder by expression\nSorts a vector layer according to an expression: changes the feature index according to an expression.\nBe careful, it might not work as expected with some providers, the order might not be kept every time.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer to sort\nExpressionEXPRESSION[expression]Expression to use for the sorting\nSort ascendingASCENDING[boolean]\nDefault: True\nIf checked the vector layer will be sorted\nfrom small to large values.\nSort nulls firstNULLS_FIRST[boolean]\nDefault: False\nIf checked, Null values are placed first\nOrderedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOrderedOUTPUT[same as input]Output (sorted) vector layer\nPython code\nAlgorithm ID:native:orderbyexpression\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1080Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nRepair Shapefile\nRepairs a broken ESRI Shapefile dataset by (re)creating the SHX file.\nParameters\nLabelNameTypeDescription\nInput ShapefileINPUT[file]Full path to the ESRI Shapefile dataset with\na missing or broken SHX file\nOutputs\nLabelNameTypeDescription\nRepaired layerOUTPUT[vector: any]The input vector layer with the SHX file re-\npaired\nPython code\nAlgorithm ID:native:repairshapefile\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nReproject layer\nReprojects a vector layer in a different CRS. The reprojected layer will have the same features and attributes of the\ninput layer.\nAllowsfeatures in-place modification\nSee also:\nAssign projection,Define Shapefile projection,Find projection\n25.1. QGIS algorithm provider1081\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer to reproject\nTarget CRSTARGET_CRS[crs]\nDefault:\nEPSG:4326\n- WGS 84\nDestination coordinate reference system\nCoordinate Oper-\nation\nOptional\nOPERATION[string]Specific operation to use for a particular re-\nprojection task, instead of always forcing\nuse of the current project’s transformation\nsettings. Useful when reprojecting a partic-\nular layer and control over the exact trans-\nformation pipeline is required.  Requires\nproj version >= 6.\nRead more atDatum Transformations.\nReprojectedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nReprojectedOUTPUT[same as input]Output (reprojected) vector layer\nPython code\nAlgorithm ID:native:reprojectlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSave vector features to file\nSaves vector features to a specified file dataset.\nFor dataset formats supporting layers, an optional layer name parameter can be used to specify a custom string.\nOptional GDAL-defined dataset and layer options can be specified. For more information on this, read the online\nGDAL documentationon the format.\n1082Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nVector featuresINPUT[vector: any]Input vector layer.\nSaved featuresOUTPUT[same as input]\nDefault:\n[Save\nto  temporary\nfile]\nSpecify the file to save the features to. One\nof:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nLayer name\nOptional\nLAYER_NAME[string]Name to use for the output layer\nGDAL dataset op-\ntions\nOptional\nDATA-\nSOURCE_OPTIONS\n[string]GDAL dataset creation options of the out-\nput format.  Separate individual options\nwith semicolons.\nGDAL layer op-\ntions\nOptional\nLAYER_OPTIONS[string]GDAL layer creation options of the output\nformat.  Separate individual options with\nsemicolons.\nOutputs\nLabelNameTypeDescription\nSaved featuresOUTPUT[same as input]Vector layer with the saved features.\nFile  name  and\npath\nFILE_PATH[string]Output file name and path.\nLayer nameLAYER_NAME[string]Name of the layer, if any.\nPython code\nAlgorithm ID:native:savefeatures\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1083\n\nQGIS Desktop 3.22 User Guide\nSet layer encoding\nSets the encoding used for reading a layer’s attributes. No permanent changes are made to the layer, rather it affects\nonly how the layer is read during the current session.\nNote:Changing the encoding is only supported for some vector layer data sources.\nParameters\nLabelNameTypeDescription\nSaved featuresINPUT[vector: any]Vector layer to set the encoding.\nEncodingENCODING[string]Text encoding to assign to the layer in the\ncurrent QGIS session.\nOutputs\nLabelNameTypeDescription\nOutput layerOUTPUT[same as input]Input vector layer with the set encoding.\nPython code\nAlgorithm ID:native:setlayerencoding\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSplit features by character\nFeatures are split into multiple output features by splitting a field’s value at a specified character. For instance, if a\nlayer contains features with multiple comma separated values contained in a single field, this algorithm can be used to\nsplit these values up across multiple output features. Geometries and other attributes remain unchanged in the output.\nOptionally, the separator string can be a regular expression for added flexibility.\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer\nSplit using values\nin the field\nFIELD[tablefield: any]Field to use for splitting\nSplit value using\ncharacter\nCHAR[string]Character to use for splitting\nUse regular ex-\npression separator\nREGEX[boolean]\nDefault: False\ncontinues on next page\n1084Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.129 – continued from previous page\nLabelNameTypeDescription\nSplitOUTPUT[same as input]\nDefault:Cre-\nate temporary\nlayer\nSpecify output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSplitOUTPUT[same as input]The output vector layer.\nPython code\nAlgorithm ID:native:splitfeaturesbycharacter\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSplit vector layer\nCreates a set of vectors in an output folder based on an input layer and an attribute. The output folder will contain as\nmany layers as the unique values found in the desired field.\nThe number of files generated is equal to the number of different values found for the specified attribute.\nIt is the opposite operation ofmerging.\nDefault menu:Vector►Data Management Tools\nSee also:\nMerge vector layers\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer\nUnique ID fieldFIELD[tablefield: any]Field to use for splitting\nOutput directoryOUTPUT[folder]\nDefault:[Save\nto  temporary\nfolder]\nSpecify the directory for the output layers.\nOne of:\n•Save to a Temporary Directory\n•Save to Directory\n25.1. QGIS algorithm provider1085\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOutput file type\nOptional\nFILE_TYPE[enumeration]\nDefault:gpkgin\nthe dialog window\nSelect the extension of the output files. If\nnot specified or invalid, the output files for-\nmat will be the one set in the “Default out-\nput vector layer extension” Processing set-\nting.\nOutputs\nLabelNameTypeDescription\nOutput directoryOUTPUT[folder]The directory for the output layers\nOutput layersOUTPUT_LAYERS[same  as  input]\n[list]\nThe output vector layers resulting from the\nsplit.\nPython code\nAlgorithm ID:native:splitvectorlayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTruncate table\nTruncates a layer, by deleting all features from within the layer.\nWarning:This algorithm modifies the layer in place, and deleted features cannot be restored!\nParameters\nLabelNameTypeDescription\nInput LayerINPUT[vector: any]Input vector layer\nOutputs\nLabelNameTypeDescription\nTruncated layerOUTPUT[folder]The truncated (empty) layer\n1086Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:truncatetable\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.18Vector geometry\nAdd geometry attributes\nComputes geometric properties of the features in a vector layer and includes them in the output layer.\nIt generates a new vector layer with the same content as the input one, but with additional attributes, containing\ngeometric measurements based on a selected CRS.\nThe attributes added to the table depend on the geometry type and dimension of the input layer:\n•forpointlayers: X (xcoord), Y (ycoord), Z (zcoord) coordinates and/or M value (mvalue)\n•forlinelayers:lengthand, for the LineString and CompoundCurve geometry types, the featuresinuos-\nityand straight distance (straightdis)\n•forpolygonlayers:perimeterandarea\nDefault menu:Vector►Geometry Tools\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nCalculate usingCALC_METHOD[enumeration]\nDefault: 0\nCalculation parameters to use for the geo-\nmetric properties. One of:\n•0 — Layer CRS\n•1 — Project CRS\n•2 — Ellipsoidal\nAdded geom infoOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (input copy with geom-\netry) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1087\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nAdded geom infoOUTPUT[same as input]Copy of the input vector layer with the ad-\ndition of the geometry fields\nPython code\nAlgorithm ID:qgis:exportaddgeometrycolumns\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nAffine transform\nApplies an affine transformation to the layer geometries. Affine transformations can include translation, scaling and\nrotation. The operations are performed in the following order: scale, rotation, and translation.\nZ and M values (if present) can be translated and scaled.\nFig. 25.48: Vector point layer (green dots) before (left), and after (rigth) an affine transformation (translation).\nAllowsfeatures in-place modificationof point, line, and polygon features\nSee also:\nTranslate\n1088Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nTranslation   (x-\naxis)\nDELTA_X[number]\nDefault: 0\nDisplacement to apply on the X axis.\nTranslation   (y-\naxis)\nDELTA_Y[number]\nDefault: 0\nDisplacement to apply on the Y axis.\nTranslation   (z-\naxis)\nDELTA_Z[number]\nDefault: 0\nDisplacement to apply on the Z axis.\nTranslation  (m-\nvalues)\nDELTA_M[number]\nDefault: 0\nOffset to apply on m values.\nScalefactor\n(x-axis)\nSCALE_X[number]\nDefault: 1\nScaling value (expansion or contraction) to\napply on the X axis.\nScalefactor\n(y-axis)\nSCALE_Y[number]\nDefault: 1\nScaling value (expansion or contraction) to\napply on the Y axis.\nScalefactor\n(z-axis)\nSCALE_Z[number]\nDefault: 1\nScaling value (expansion or contraction) to\napply on the Z axis.\nScalefactor\n(m-values)\nSCALE_M[number]\nDefault: 1\nScaling value (expansion or contraction) to\napply on m values.\nRotation  around\nz-axis(de-\ngrees   counter-\nclockwise)\nROTATION_Z[number]\nDefault: 0\nAngle of the rotation in degrees.\nTransformedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nTransformedOUTPUT[same as input]Output (transformed) vector layer.\n25.1. QGIS algorithm provider1089\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:affinetransform\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nAggregate\nTakes a vector or table layer and creates a new layer by aggregating features based on agroup byexpression.\nFeatures for whichgroup byexpression returns the same value are grouped together.\nIt is possible to group all source features together using constant value ingroup byparameter, example: NULL.\nIt is also possible to group features by multiple fields using Array function, example: Array(“Field1”, “Field2”).\nGeometries (if present) are combined into one multipart geometry for each group. Output attributes are computed\ndepending on each given aggregate definition.\nThis algorithm allows to use the default\naggregates functionsof the QGIS Expression engine.\nSee also:\nCollect geometries,Dissolve\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nGroup by expres-\nsion\nGROUP_BY[tablefield: any]\nDefault: ‘NULL’\nChoose the grouping field. IfNULLall fea-\ntures will be grouped.\ncontinues on next page\n1090Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.134 – continued from previous page\nLabelNameTypeDescription\nAggregatesAGGREGATES[list]List of output layer field definitions. Exam-\nple of a field definition:\n{‘aggregate’: ‘sum’, ‘delimiter’: ‘,’, ‘input’: ‘\n$area’, ‘length’: 10, ‘name’: ‘totarea’, ‘preci-\nsion’: 0, ‘type’: 6}\nBy default, the list contains all the fields of\nthe input layer. In the GUI, you can edit\nthese fields and their definitions, and you\ncan also:\n•Click thebutton to add a new\nfield.\n•Clickto delete the selected field.\n•Useandto change order of\nthe fields.\n•Clickto reset to the default (the\nfields of the input layer).\nFor each of the fields you’d like to retrieve\ninformation from, you need to define the\nfollowing:\nInput expression[expression] (input)\nField or expression from the input\nlayer.\nAggregate function[enumeration] (aggregate)\nFunctionto use on the input expres-\nsion to return the aggregated value.\nDefault:concatenate(for string data\ntype),sum(for numeric data type)\nDelimiter[string] (delimiter)\nText string to separate aggregated\nvalues,  for example in case of\nconcatenation.\nDefault:,\nOutput field name[string] (name)\nName of the aggregated field in the\noutput layer. By default input field\nname is kept.\nType[enumeration] (type)Data type\nof the output field. One of:\n•1 — Boolean\n•2 — Integer\n•4 — Integer64\n•6 — Double\n•10 — String\n•14 — Date\n•16 — DateTime\nLength[number] (length)Length of\nthe output field.\nPrecision[number] (precision)\nPrecision of the output field.\nLoad fields from\nlayer\nGUI only[vector: any]You can load fields from another layer and\nuse them for the aggregation\ncontinues on next page\n25.1. QGIS algorithm provider1091\n\nQGIS Desktop 3.22 User Guide\nTable 25.134 – continued from previous page\nLabelNameTypeDescription\nAggregatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (aggregate) layer One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nAggregatedOUTPUT[same as input]Multigeometry vector layer with the aggre-\ngated values\nPython code\nAlgorithm ID:native:aggregate\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nBoundary\nReturns the closure of the combinatorial boundary of the input geometries (i.e. the topological boundary of the\ngeometry).\nOnly for polygon and line layers.\nForpolygon geometries, the boundary consists of all the lines making up the rings of the polygon.\n1092Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.49: Boundaries (black dashed line) of the source polygon layer\nForlines geometries, the boundaries are their end points.\nFig. 25.50: Boundary layer (red points) for lines. In yellow a selected feature.\n25.1. QGIS algorithm provider1093\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nBoundaryOUTPUT[vector: point, line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (boundary) layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nBoundaryOUTPUT[vector: point, line]Boundaries from the input layer (point for\nline, and line for polygon)\nPython code\nAlgorithm ID:native:boundary\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nBounding boxes\nCalculates the bounding box (envelope) of each feature in an input layer. Polygon and line geometries are supported.\n1094Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.51: Black lines represent the bounding boxes of each polygon feature\nAllowsfeatures in-place modificationof polygon features\nSee also:\nMinimum bounding geometry\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nBoundsOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (bounding box) layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1095\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nBoundsOUTPUT[vector: polygon]Bounding boxes of input layer\nPython code\nAlgorithm ID:native:boundingboxes\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nBuffer\nComputes a buffer area for all the features in an input layer, using a fixed distance.\nIt is possible to use a negative distance for polygon input layers. In this case the buffer will result in a smaller polygon\n(setback).\nFig. 25.52: Buffer (in yellow) of points, line and polygon\nAllowsfeatures in-place modificationof polygon features\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nVariable distance buffer,Multi-ring buffer (constant distance),Variable width buffer (by M value)\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nDistanceDISTANCE[number]\nDefault: 10.0\nBuffer distance (from the boundary of each\nfeature). You can use the Data Defined but-\nton on the right to choose a field from which\nthe radius will be calculated. This way you\ncan have different radius for each feature\n(see\nVariable distance buffer).\ncontinues on next page\n1096Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.135 – continued from previous page\nLabelNameTypeDescription\nSegmentsSEGMENTS[number]\nDefault: 5\nControls the number of line segments to use\nto approximate a quarter circle when creat-\ning rounded offsets.\nEnd cap styleEND_CAP_STYLE[enumeration]\nDefault: 0\nControls how line endings are handled in\nthe buffer. One of:\n•0 — Round\n•1 — Flat\n•2 — Square\nFig. 25.53: Round, flat and square cap\nstyles\nJoin styleJOIN_STYLE[enumeration]\nDefault: 0\nSpecifies whether round, miter or beveled\njoinsshouldbeused whenoffsettingcorners\nin a line. Options are:\n•0 — Round\n•1 — Miter\n•2 — Bevel\nFig. 25.54: Round, miter, and bevel join\nstyles\nMiter limitMITER_LIMIT[number]\nDefault: 2.0\nControls the maximum distance from the\noffset curve to use when creating a mitered\njoin (only applicable for miter join styles).\nMinimum: 1.\nDissolve resultDISSOLVE[boolean]\nDefault: False\nDissolve the final buffer.   IfTrue\n(checked), overlapping buffers will be dis-\nsolved (combined) into a new feature.\nFig. 25.55: Standard and dissolved buffer\nBufferedOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (buffer) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1097\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nBufferedOUTPUT[vector: polygon]Output (buffer) polygon layer\nPython code\nAlgorithm ID:native:buffer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCentroids\nCreates a new point layer, with points representing the centroids of the geometries of the input layer.\nThe centroid is a single point representing the barycenter (of all parts) of the feature, so it can be outside the feature\nborders. But can also be a point on each part of the feature.\nThe attributes of the points in the output layer are the same as for the original features.\nFig. 25.56: The red stars represent the centroids of the features of the input layer.\nAllowsfeatures in-place modificationof point features\nDefault menu:Vector►Geometry Tools\nSee also:\nPoint on Surface\n1098Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nCreate  centroid\nfor each part\nALL_PARTS[boolean]\nDefault: False\nIf True (checked), a centroid will be created\nfor each part of the geometry\nCentroidsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (centroid) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCentroidsOUTPUT[vector: point]Output point vector layer (centroids)\nPython code\nAlgorithm ID:native:centroids\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCheck validity\nPerforms a validity check on the geometries of a vector layer.\nThe geometries are classified in three groups (valid, invalid and error) and for each group, a vector layer with its\nfeatures is generated:\n•TheValid outputlayer contains only the valid features (without topological errors).\n•TheInvalid outputlayer contains all the invalid features found by the algorithm.\n•TheError outputlayer is a point layer that points to where the invalid features were found.\nThe attribute tables of the generated layers will contain some additional information (“message” for theerrorlayer,\n“FID” and “_errors” for theinvalidlayer and only “FID” for thevalidlayer):\nThe attribute table of each generated vector layer will contain some additional information (number of errors found\nand types of error):\n25.1. QGIS algorithm provider1099\n\nQGIS Desktop 3.22 User Guide\nFig. 25.57: Left: the input layer. Right: the valid layer (green), the invalid layer (orange)\nDefault menu:Vector►Geometry Tools\nSee also:\nFix geometriesand the core pluginGeometry Checker Plugin\nParameters\nLabelNameTypeDescription\nInput layerINPUT_LAYER[vector: any]Input vector layer\nMethodMETHOD[enumeration]\nDefault: 2\nMethod to use to check validity. Options:\n•0: The one selected in digitizing set-\ntings\n•1: QGIS\n•2: GEOS\nIgnoreringselfin-\ntersection\nIG-\nNORE_RING_SELF_INTERSECTION\n[boolean]\nDefault: False\nIgnore self intersecting rings when check-\ning for validity.\nValid outputVALID_OUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the vector layer to contain a copy of\nthe valid features of the source layer. One\nof:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nInvalid outputIN-\nVALID_OUTPUT\n[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nVector layer containing copy of the invalid\nfeatures of the source layer with the field\n_errorslisting the summary of the er-\nror(s) found. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\ncontinues on next page\n1100Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.136 – continued from previous page\nLabelNameTypeDescription\nError outputERROR_OUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nPoint layer of the exact position of the valid-\nity problems detected with themessage\nfield describing the error(s) found. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCount of errorsERROR_COUNT[number]The number of geometries that caused er-\nrors.\nError outputERROR_OUTPUT[vector: point]Point layer of the exact position of the valid-\nity problems detected with themessage\nfield describing the error(s) found.\nCount of invalid\nfeatures\nINVALID_COUNT[number]The number of invalid geometries.\nInvalid outputIN-\nVALID_OUTPUT\n[same as input]Vector layer containing copy of the invalid\nfeatures of the source layer with the field\n_errorslisting the summary of the er-\nror(s) found.\nCount of valid fea-\ntures\nVALID_COUNT[number]The number of valid geometries.\nValid outputVALID_OUTPUT[same as input]Vector layer containing a copy of the valid\nfeatures of the source layer.\nPython code\nAlgorithm ID:qgis:checkvalidity\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTypes of error messages and their meanings\n25.1. QGIS algorithm provider1101\n\nQGIS Desktop 3.22 User Guide\nTable 25.138: If the GEOS method is used the following error messages\ncan occur:\nError messageExplanationExample\nRepeated pointThis error happens when a given\nvertex is repeated.\nRing self-intersectionThis error happens when a ge-\nometry touches itself and gen-\nerates a ring.\nSelf-intersectionThis error happens when a ge-\nometry touches itself.\nTopology validation error\nHole lies outside shell\nHoles are nested\nInterior is disconnected\ncontinues on next page\n1102Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.138 – continued from previous page\nError messageExplanationExample\nNested shellsThis error happens when a poly-\ngon geometry is on top of an-\nother polygon geometry.\nDuplicate ringsThis error happens when two\nrings (exterior or interior) of a\npolygon geometry are identical\nToo few points in geometry\ncomponent\nInvalid coordinateFor a point geometry, this er-\nror happens when the geometry\ndoes not have a proper coordi-\nnate pair. The coordinate pair\ndoes not contain a latitude value\nand a longitude value in that or-\nder.\nRing is not closed\nTable 25.139: If the QGIS method is used the following error messages\ncan occur:\nError messageExplanationExample\nSegment %1 of ring %2 of polygon\n%3 intersects segment %4 of ring\n%5 of polygon %6 at %7\nRing %1 with less than four points\nRing %1 not closed\nLine %1 with less than two points\ncontinues on next page\n25.1. QGIS algorithm provider1103\n\nQGIS Desktop 3.22 User Guide\nTable 25.139 – continued from previous page\nError messageExplanationExample\nLine %1 contains %n duplicate\nnode(s) at %2\nThis error happens when consecu-\ntive points on a line have the same\ncoordinates.\nSegments %1 and %2 of line %3 in-\ntersect at %4\nThis error happens when a line self\nintersects (two segments of the line\nintersect each other).\nRing self-intersectionThis error happens when an outer or\ninner (island) ring / boundary of a\npolygon geometry intersects itself.\nRing %1 of polygon %2 not in ex-\nterior ring\nPolygon %1 lies inside polygon %2This error happens when a part of\na MultiPolygon geometry is inside a\nhole of a MultiPolygon geometry.\n1104Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nCollect geometries\nTakes a vector layer and collects its geometries into new multipart geometries.\nOne or more attributes can be specified to collect only geometries belonging to the same class (having the same value\nfor the specified attributes), alternatively all geometries can be collected.\nAll output geometries will be converted to multi geometries, even those with just a single part. This algorithm does\nnot dissolve overlapping geometries - they will be collected together without modifying the shape of each geometry\npart.\nSee the ‘Promote to multipart’ or ‘Aggregate’ algorithms for alternative options.\nDefault menu:Vector►Geometry Tools\nSee also:\nAggregate,Promote to multipart,Dissolve\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nUnique ID fieldsFIELD[tablefield:    any]\n[list]\nChoose one or more attributes to collect the\ngeometries\nCollectedOUTPUT[same as input]Vector layer with collected geometries\nOutputs\nLabelNameTypeDescription\nCollectedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the col-\nlected geometries. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nPython code\nAlgorithm ID:native:collect\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1105\n\nQGIS Desktop 3.22 User Guide\nConcave hull (alpha shapes)\nComputes the concave hull of the features in an input point layer.\nFig. 25.58: Concave hulls with different thresholds (0.3, 0.6, 0.9)\nSee also:\nConvex hull,Concave hull (k-nearest neighbor)\nParameters\nLabelNameTypeDescription\nInput point layerINPUT[vector: point]Input point vector layer\nThresholdALPHA[number]\nDefault: 0.3\nNumber from 0 (maximum concave hull) to\n1 (convex hull).\nAllow holesHOLES[boolean]\nDefault: True\nChoose whether to allow holes in the final\nconcave hull\nSplit multipart ge-\nometry into sin-\nglepart geometries\nNO_MULTIGEOMETRY[boolean]\nDefault: True\nCheck if you want to have singlepart ge-\nometries instead of multipart ones.\nConcave hullOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1106Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nConcave hullOUTPUT[vector: polygon]The output vector layer\nPython code\nAlgorithm ID:qgis:concavehull\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConcave hull (k-nearest neighbor)\nGenerates a concave hull polygon from a set of points. If the input layer is a line or polygon layer, it will use the\nvertices.\nThe number of neighbors to consider determines the concaveness of the output polygon. A lower number will result in\na concave hull that follows the points very closely, while a higher number will have a smoother shape. The minimum\nnumber of neighbor points to consider is 3. A value equal to or greater than the number of points will result in a\nconvex hull.\nIf a field is selected, the algorithm will group the features in the input layer using unique values in that field and\ngenerate individual polygons in the output layer for each group.\nSee also:\nConcave hull (alpha shapes)\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nNumber of neigh-\nboring    points\nto  consider  (a\nlower number is\nmore concave, a\nhigher number is\nsmoother)\nKNEIGHBORS[number]\nDefault: 3\nDetermines the concaveness of the output\npolygon. A small number will result in a\nconcave hull that follows the points very\nclosely, while a high number will make the\npolygon look more like the convex hull (if\nthe number is equal to or larger than the\nnumber of features, the result will be the\nconvex hull). Minimum value: 3.\nField\nOptional\nFIELD[tablefield: any]\nDefault: None\nIf specified, one concave hull polygon is\ngenerated for each unique value of the field\n(by selecting features using this value).\nConcave hullOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1107\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nConcave hullOUTPUT[vector: polygon]The output vector layer\nPython code\nAlgorithm ID:qgis:knearestconcavehull\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConvert geometry type\nGenerates a new layer based on an existing one, with a different type of geometry.\nThe attribute table of the output layer is the same as the one of the input layer.\nNot all conversions are possible. For instance, a line layer can be converted to a point layer, but a point layer cannot\nbe converted to a line layer.\nSee also:\nPolygonize,Lines to polygons,Polygons to lines,Points to path\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nNew   geometry\ntype\nTYPE[enumeration]\nDefault: 0\nGeometry type to apply to the output fea-\ntures. One of:\n•0 — Centroids\n•1 — Nodes\n•2 — Linestrings\n•3 — Multilinestrings\n•4 — Polygons\nConvertedOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1108Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nConvertedOUTPUT[vector: any]Output vector layer - the type depends on\nthe parameters\nPython code\nAlgorithm ID:qgis:convertgeometrytype\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConvert to curved geometries\nConverts a geometry into its curved geometry equivalent.\nAlready curved geometries will be retained without change.\nAllowsfeatures in-place modificationof line and polygon features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector:   line  or\npolygon]\nInput vector layer\nMaximum   dis-\ntance tolerance\nDISTANCE[number]\nDefault: 0.000001\nThe maximum distance allowed between\nthe original location of vertices and where\nthey would fall on the converted curved ge-\nometries\nMaximum  angle\ntolerance\nANGLE[number]\nDefault: 0.000001\nSegments are considered as suitable for re-\nplacing with an arc if the points are all reg-\nularly spaced on the candidate arc. This\nparameter specifies the maximum angular\ndeviation (in degrees) allowed when testing\nfor regular point spacing. Between 0 and\n45°.\nCurvesOUTPUT[vector: compound-\ncurve or curvepoly-\ngon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1109\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nCurvesOUTPUT[vector: compound-\ncurve or curvepoly-\ngon]\nOutput vector layer with curved geometries\nPython code\nAlgorithm ID:native:converttocurves\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nConvex hull\nCalculates the convex hull for each feature in an input layer.\nSeethe‘Minimumboundinggeometry’algorithmforaconvexhullcalculationwhichcoversthewholelayerorgrouped\nsubsets of features.\nFig. 25.59: Black lines identify the convex hull for each layer feature\nAllowsfeatures in-place modificationof polygon features\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nMinimum bounding geometry,Concave hull (alpha shapes)\n1110Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nConvex hullOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nConvex hullOUTPUT[vector: polygon]The output (convex hull) vector layer\nPython code\nAlgorithm ID:native:convexhull\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate layer from extent\nCreates a new vector layer that contains a single feature with geometry matching the extent of the input layer.\nIt can be used in models to convert a literal extent (xmin,xmax,ymin,ymaxformat) into a layer which can be\nused for other algorithms which require a layer based input.\nSee also:\nCreate layer from point\n25.1. QGIS algorithm provider1111\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nExtent   (xmin,\nxmax,ymin,\nymax)\nINPUT[extent]Input extent\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nExtentOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtentOUTPUT[vector: polygon]The output (extent) vector layer\nPython code\nAlgorithm ID:native:extenttolayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nCreate layer from point\nCreates a new vector layer that contains a single feature with geometry matching a point parameter. It can be used in\nmodels to convert a point into a point layer for algorithms which require a layer based input.\nSee also:\nCreate layer from extent\n1112Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nPointINPUT[coordinates]Input point, including CRS info (example:\n397254,6214446 [EPSG:32632]).\nIf the CRS is not provided, the Project CRS\nwill be used.\nThe point can be specified by clicking on\nthe map canvas.\nPointOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPointOUTPUT[vector: point]The output point vector layer containing the\ninput point.\nPython code\nAlgorithm ID:native:pointtolayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1113\n\nQGIS Desktop 3.22 User Guide\nCreate wedge buffers\nCreates wedge shaped buffers from input points.\nFig. 25.60: Wedge buffers\nThe native output from this algorithm are CurvePolygon geometries, but these may be automatically segmentized to\nPolygons depending on the output format.\nSee also:\nBuffer,Variable width buffer (by M value),Tapered buffers\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Input point vector layer\nAzimuth (degrees\nfrom North)\nAZIMUTH[number]\nDefault: 0.0\nAngle (in degrees) as the middle value of\nthe wedge\ncontinues on next page\n1114Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.142 – continued from previous page\nLabelNameTypeDescription\nWedge width (in\ndegrees)\nWIDTH[number]\nDefault: 45.0\nWidth (in degrees) of the buffer.  The\nwedge will extend to half of the angular\nwidth either side of the azimuth direction.\nFig. 25.61: Azimuth and width values of\nthe wedge buffer\nOuter radiusOUTER_RADIUS[number]\nDefault: 1.0\nThe outersize(length) of the wedge: the\nsize is meant from the source point to the\nedge of the wedge shape.\nInner radius\nOptional\nINNER_RADIUS[number]\nDefault: 0.0\nInner radius value. If 0 the wedge will begin\nfrom the source point.\nBuffersOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nBuffersOUTPUT[vector: polygon]The output (wedge buffer) vector layer\nPython code\nAlgorithm ID:native:wedgebuffers\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1115\n\nQGIS Desktop 3.22 User Guide\nDelaunay triangulation\nCreates a polygon layer with the Delaunay triangulation corresponding to the input point layer.\nFig. 25.62: Delaunay triangulation on points\nDefault menu:Vector►Geometry Tools\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Input point vector layer\nDelaunay triangu-\nlation\nOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(\nTEMPORARY_OUTPUT\n)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1116Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nDelaunay triangu-\nlation\nOUTPUT[vector: polygon]The output (Delaunay triangulation) vector\nlayer\nPython code\nAlgorithm ID:qgis:delaunaytriangulation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDelete holes\nTakes a polygon layer and removes holes in polygons. It creates a new vector layer in which polygons with holes have\nbeen replaced by polygons with only their external ring. Attributes are not modified.\nAn optional minimum area parameter allows removing only holes which are smaller than a specified area threshold.\nLeaving this parameter at0.0results in all holes being removed.\nFig. 25.63: Before and after the cleaning\nAllowsfeatures in-place modificationof polygon features\n25.1. QGIS algorithm provider1117\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input polygon vector layer\nRemove holes with\narea less than\nOptional\nMIN_AREA[number]\nDefault: 0.0\nOnly holes with an area less than this thresh-\nold will be deleted. With a value of0.0,all\nthe holes will be deleted.\nCleanedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCleanedOUTPUT[same as input]The output (cleaned) vector layer\nPython code\nAlgorithm ID:native:deleteholes\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDensify by count\nTakes a polygon or line layer and generates a new one in which the geometries have a larger number of vertices than\nthe original one.\nIf the geometries have Z or M values present then these will be linearly interpolated at the added vertices.\nThe number of new vertices to add to each segment is specified as an input parameter.\n1118Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.64: Red points show the vertices before and after the densify\nAllowsfeatures in-place modificationof line and polygon features\nDefault menu:Vector►Geometry Tools\nSee also:\nDensify by interval\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nVertices to addVERTICES[number]\nDefault: 1\nNumber of vertices to add to each segment\nDensifiedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1119\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nDensifiedOUTPUT[same as input]The output (densified) vector layer\nPython code\nAlgorithm ID:native:densifygeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDensify by interval\nTakes a polygon or line layer and generates a new one in which the geometries have a larger number of vertices than\nthe original one.\nThe geometries are densified by adding regularly placed extra vertices inside each segment so that the maximum\ndistance between any two vertices does not exceed the specified distance.\nIf the geometries have Z or M values present then these will be linearly interpolated at the added vertices.\nExample\nSpecifying a distance of 3 would cause the segment[0 0] -> [10 0]to be converted to[0 0] -> [2.5\n0] -> [5 0] -> [7.5 0] -> [10 0], since 3 extra vertices are required on the segment and spacing these\nat 2.5 increments allows them to be evenly spaced over the segment.\nFig. 25.65: Densify geometry at a given interval\nAllowsfeatures in-place modificationof line and polygon features\nSee also:\nDensify by count\n1120Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nInterval  between\nvertices to add\nINTERVAL[number]\nDefault: 1.0\nMaximum distance between two consecu-\ntive vertices\nDensifiedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nDensifiedOUTPUT[same as input]The output (densified) vector layer\nPython code\nAlgorithm ID:native:densifygeometriesgivenaninterval\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDissolve\nTakes a vector layer and combines its features into new features. One or more attributes can be specified to dissolve\nfeatures belonging to the same class (having the same value for the specified attributes), alternatively all features can\nbe dissolved to a single feature.\nAll output geometries will be converted to multi geometries. In case the input is a polygon layer, common boundaries\nof adjacent polygons being dissolved will get erased.\nThe resulting attribute table will have the same fields as the input layer. The values in the output layer’s fields are the\nones of the first input feature that happens to be processed.\n25.1. QGIS algorithm provider1121\n\nQGIS Desktop 3.22 User Guide\nFig. 25.66: Dissolve the polygon layer on a common attribute\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nAggregate,Collect geometries\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nDissolve field(s)\nOptional\nFIELD[tablefield:    any]\n[list]\nDefault: []\nFeatures having the same value for the se-\nlected field(s) will be replaced with a single\none and their geometries are merged.\nIf no field is provided then all the features\nare dissolved, resulting in a single (multi-\npart) feature.\nDissolvedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nDissolvedOUTPUT[same as input]The output vector layer with dissolved ge-\nometries\nPython code\nAlgorithm ID:native:dissolve\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1122Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nDrape (set Z value from raster)\nUses values sampled from a band within a raster layer to set the Z value for every overlapping vertex in the feature\ngeometry. The raster values can optionally be scaled by a preset amount.\nIf Z values already exist in the layer, they will be overwritten with the new value. If no Z values exist, the geometry\nwill be upgraded to include the Z dimension.\nAllowsfeatures in-place modificationof point, line, and polygon features with Z enabled\nSee also:\nSet M value from raster,Set Z value\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nRaster layerRASTER[raster]Raster layer with Z values\nBand numberBAND[raster band]\nDefault: 1\nThe raster band to take the Z values from\nValue  for  no-\ndata  or  non-\nintersecting\nvertices\nNODATA[number]\nDefault: 0\nValue to use in case the vertex does not in-\ntersect (a valid pixel of) the raster\nScale factorSCALE[number]\nDefault: 1.0\nScaling value: the band values are multi-\nplied by this value.\nUpdatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer (with Z val-\nues from the raster layer). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nUpdatedOUTPUT[same as input]The output vector layer with Z values from\nthe raster layer\n25.1. QGIS algorithm provider1123\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:setzfromraster\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDrop M/Z values\nRemoves M (measure) or Z (altitude) values from input geometries.\nSee also:\nSet M value,Set Z value\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer with M or Z values\nDrop M ValuesDROP_M_VALUES[boolean]\nDefault: False\nRemoves the M values from the geometries\nDrop Z ValuesDROP_Z_VALUES[boolean]\nDefault: False\nRemoves the Z values from the geometries\nZ/M DroppedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nZ/M DroppedOUTPUT[same as input]The output vector layer (identical to the in-\nput layer, except that the M and/or Z dimen-\nsions have been removed from the geome-\ntries).\n1124Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:dropmzvalues\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nEliminate selected polygons\nCombines selected polygons of the input layer with certain adjacent polygons by erasing their common boundary.\nThe adjacent polygon can be either the one with the largest or smallest area or the one sharing the largest common\nboundary with the polygon to be eliminated.\nEliminate is normally used to get rid of sliver polygons, i.e. tiny polygons that are a result of polygon intersection\nprocesses where boundaries of the inputs are similar but not identical.\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nFix geometries\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input polygon vector layer\nMerge  selection\nwith the neighbor-\ning polygon with\nthe\nMODE[enumeration]\nDefault: None\nChoose the parameter to use in order to get\nrid of the selected polygons:\n•0 — Largest Area\n•1 — Smallest Area\n•2 — Largest Common Boundary\nEliminatedOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nEliminatedOUTPUT[vector: polygon]The output polygon vector layer.\n25.1. QGIS algorithm provider1125\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:eliminateselectedpolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExplode lines\nTakes a lines layer and creates a new one in which each line layer is replaced by a set of lines representing the segments\nin the original line.\nEach line in the resulting layer contains only a start and an end point, with no intermediate vertices between them.\nFig. 25.67: The original line layer and the exploded one\nAllowsfeatures in-place modificationof line features\nSee also:\nSubdivide,Line substring\n1126Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nExplodedOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExplodedOUTPUT[vector: line]The output line vector layer with features\nrepresenting each segment of the input\nlayer.\nPython code\nAlgorithm ID:native:explodelines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtend lines\nExtends line geometry by a specified amount at the start and end of the line.\nLines are extended using the bearing of the first and last segment in the line.\nFig. 25.68: The red dashes represent the initial and final extension of the original layer\n25.1. QGIS algorithm provider1127\n\nQGIS Desktop 3.22 User Guide\nAllowsfeatures in-place modificationof line features\nSee also:\nLine substring\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nStart distanceSTART_DISTANCE[number]Distance by which to extend the first seg-\nment of the line (starting point)\nEnd distanceEND_DISTANCE[number]Distance by which to extend the last seg-\nment of the line (ending point)\nExtendedOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtendedOUTPUT[vector: line]The output (extended) line vector layer.\nPython code\nAlgorithm ID:native:extendlines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract M values\nExtracts M values from geometries into feature attributes.\nBy default only the M value from the first vertex of each feature is extracted, however the algorithm can optionally\ncalculate statistics on all of the geometry’s M values, including sum, mean, minimum and maximum.\nSee also:\nExtract Z values,Set M value,Drop M/Z values\n1128Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nSummaries to cal-\nculate\nSUMMARIES[enumeration]\nDefault: [0]\nStatistics on the M values of a geometry.\nOne or more of:\n•0 — First\n•1 — Last\n•2 — Count\n•3 — Sum\n•4 — Mean\n•5 — Median\n•6 — St.dev (pop)\n•7 — Minimum\n•8 — Maximum\n•9 — Range\n•10 — Minority\n•11 — Majority\n•12 — Variety\n•13 — Q1\n•14 — Q3\n•15 — IQR\nOutput  column\nprefix\nCOLUMN_PREFIX[string]\nDefault: ‘m_’\nThe prefix for the output (M) column\nExtractedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtractedOUTPUT[same as input]The output vector layer (with M values)\nPython code\nAlgorithm ID:native:extractmvalues\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1129\n\nQGIS Desktop 3.22 User Guide\nExtract specific vertices\nTakes a vector layer and generates a point layer with points representing specific vertices in the input geometries.\nFor instance, this algorithm can be used to extract the first or last vertices in the geometry. The attributes associated\nto each point are the same ones associated to the feature that the vertex belongs to.\nThe vertex indices parameter accepts a comma separated string specifying the indices of the vertices to extract. The\nfirst vertex corresponds to an index of 0, the second vertex has an index of 1, etc. Negative indices can be used to find\nvertices at the end of the geometry, e.g., an index of -1 corresponds to the last vertex, -2 corresponds to the second\nlast vertex, etc.\nAdditional fields are added to the vertices indicating the specific vertex position (e.g., 0, -1, etc), the original vertex\nindex, the vertex’s part and its index within the part (as well as its ring for polygons), distance along the original\ngeometry and bisector angle of vertex for the original geometry.\nAllowsfeatures in-place modificationof point features\nSee also:\nExtract vertices,Filter vertices by M value,Filter vertices by Z value\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nVertex indicesVERTICES[string]\nDefault: ‘0’\nComma-separated string of the indices of\nthe vertices to extract.\nVerticesOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nVerticesOUTPUT[vector: point]The output (point) vector layer containing\nthe specified vertices from the input layer\ngeometries.\nPython code\nAlgorithm ID\n:\nnative:extractspecificvertices\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1130Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExtract vertices\nTakes a vector layer and generates a point layer with points representing the vertices in the input geometries.\nThe attributes associated to each point are the same ones associated to the feature that the vertex belongs to.\nAdditional fields are added to the vertices indicating the vertex index (beginning at 0), the feature’s part and its index\nwithin the part (as well as its ring for polygons), distance along original geometry and bisector angle of vertex for\noriginal geometry.\nFig. 25.69: Vertices extracted for line and polygon layer\nAllowsfeatures in-place modificationof point features\nDefault menu:Vector►Geometry Tools\nSee also:\nExtract specific vertices,Filter vertices by M value,Filter vertices by Z value\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nVerticesOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nVerticesOUTPUT[vector: point]The output (point) vector layer containing\nthe vertices from the input layer geometries.\n25.1. QGIS algorithm provider1131\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:extractvertices\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract Z values\nExtracts Z values from geometries into feature attributes.\nBy default only the Z value from the first vertex of each feature is extracted, however the algorithm can optionally\ncalculate statistics on all of the geometry’s Z values, including sum, mean, minimum and maximum.\nSee also:\nExtract M values,Set Z value,Drop M/Z values\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nSummaries to cal-\nculate\nSUMMARIES[enumeration]\nDefault: [0]\nStatistics on the Z values of a geometry.\nOne or more of:\n•0 — First\n•1 — Last\n•2 — Count\n•3 — Sum\n•4 — Mean\n•5 — Median\n•6 — St.dev (pop)\n•7 — Minimum\n•8 — Maximum\n•9 — Range\n•10 — Minority\n•11 — Majority\n•12 — Variety\n•13 — Q1\n•14 — Q3\n•15 — IQR\nOutput  column\nprefix\nCOLUMN_PREFIX[string]\nDefault: ‘z_’\nThe prefix for the output (Z) column\nExtractedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n1132Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nExtractedOUTPUT[same as input]The output vector layer (with Z values)\nPython code\nAlgorithm ID:native:extractzvalues\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFilter vertices by M value\nFilters away vertices based on their M value, returning geometries with only vertex points that have a M value greater\nthan or equal to the specified minimum value and/or less than or equal to the maximum value.\nIf the minimum value is not specified then only the maximum value is tested, and similarly if the maximum value is\nnot specified then only the minimum value is tested.\nFig. 25.70: The red line represents the black line with only vertices whose M value is <=10.\nAllowsfeatures in-place modificationof line and polygon features with M enabled\nNote:Depending on the input geometry attributes and the filters used, the resultant geometries created by this\nalgorithm may no longer be valid.\nSee also:\nFilter vertices by Z value,Extract vertices,Extract specific vertices\n25.1. QGIS algorithm provider1133\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer to remove\nvertices from\nMinimum\nOptional\nMIN[number]\nDefault:Not set\nMinimum of M values allowed\nMaximum\nOptional\nMAX[number]\nDefault:Not set\nMaximum of M values allowed\nFilteredOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nFilteredOUTPUT[same as input]The output vector layer of features with\nonly the filtered vertices.\nPython code\nAlgorithm ID:native:filterverticesbym\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFilter vertices by Z value\nFilters away vertices based on their Z value, returning geometries with only vertex points that have a Z value greater\nthan or equal to the specified minimum value and/or less than or equal to the maximum value.\nIf the minimum value is not specified then only the maximum value is tested, and similarly if the maximum value is\nnot specified then only the minimum value is tested.\nFig. 25.71: The red line represents the black line with only vertices whose Z value is <=10.\n1134Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAllowsfeatures in-place modificationof line and polygon features with Z enabled\nNote:Depending on the input geometry attributes and the filters used, the resultant geometries created by this\nalgorithm may no longer be valid. You may need to run theFix geometriesalgorithm to ensure their validity.\nSee also:\nFilter vertices by M value,Extract vertices,Extract specific vertices\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer to remove\nvertices from\nMinimum\nOptional\nMIN[number]\nDefault:Not set\nMinimum of Z values allowed\nMaximum\nOptional\nMAX[number]\nDefault:Not set\nMaximum of Z values allowed\nFilteredOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nFilteredOUTPUT[same as input]The output vector layer of features with\nonly the filtered vertices.\nPython code\nAlgorithm ID:native:filterverticesbyz\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1135\n\nQGIS Desktop 3.22 User Guide\nFix geometries\nAttempts to create a valid representation of a given invalid geometry without losing any of the input vertices. Already\nvalid geometries are returned without further intervention. Always outputs multi-geometry layer.\nAllowsfeatures in-place modificationof point, line, and polygon features without M enabled\nNote:M values will be dropped from the output.\nSee also:\nCheck validity\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nFixed geometriesOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nFixed geometriesOUTPUT[same as input]The output vector layer with fixed geome-\ntries.\nPython code\nAlgorithm ID:native:fixgeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1136Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nForce right-hand-rule\nForces polygon geometries to respect the Right-Hand-Rule, in which the area that is bounded by a polygon is to the\nright of the boundary. In particular, the exterior ring is oriented in a clockwise direction and any interior rings in a\ncounter-clockwise direction.\nAllowsfeatures in-place modificationof polygon features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input vector layer\nReorientedOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nReorientedOUTPUT[vector: polygon]The output vector layer with reoriented ge-\nometries.\nPython code\nAlgorithm ID:native:forcerhr\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGeodesic line split at antimeridian\nSplits a line into multiple geodesic segments, whenever the line crosses the antimeridian (±180 degrees longitude).\nSplitting at the antimeridian helps the visual display of the lines in some projections. The returned geometry will\nalways be a multi-part geometry.\nWhenever line segments in the input geometry cross the antimeridian, they will be split into two segments, with the\nlatitude of the breakpoint being determined using a geodesic line connecting the points either side of this segment.\nThe current project ellipsoid setting will be used when calculating this breakpoint.\nIf the input geometry contains M or Z values, these will be linearly interpolated for the new vertices created at the\nantimeridian.\nAllowsfeatures in-place modificationof line features\n25.1. QGIS algorithm provider1137\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nSplitOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSplitOUTPUT[vector: line]The output line vector layer split at the an-\ntimeridian.\nPython code\nAlgorithm ID:native:antimeridiansplit\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGeometry by expression\nUpdates existing geometries (or creates new geometries) for input features by use of a QGIS expression.\nThis allows complex geometry modifications which can utilize all the flexibility of the QGIS expression engine to\nmanipulate and create geometries for output features.\nFor help with QGIS expression functions, see the inbuilt help available in the\nexpression builder.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nOutput geometry\ntype\nOUT-\nPUT_GEOMETRY\n[enumeration]\nDefault: 0\nThe output geometry strongly depends on\nthe expression: for instance, if you create a\nbuffer the geometry type has to be polygon.\nOne of:\n•0 — Polygon\n•1 — Line\n•2 — Point\ncontinues on next page\n1138Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.146 – continued from previous page\nLabelNameTypeDescription\nOutput geometry\nhas z values\nWITH_Z[boolean]\nDefault: False\nChoose if the output geometry should in-\nclude the Z dimension\nOutput geometry\nhas m values\nWITH_M[boolean]\nDefault: False\nChoose if the output geometry should in-\nclude the M dimension\nGeometry expres-\nsion\nEXPRESSION[expression]\nDefault:  ‘$geome-\ntry’\nAdd the geometry expression you want to\nuse. You can use the button to open the Ex-\npression Dialog. The dialog lists all the rel-\nevant expressions, together with their help\nand guide.\nModified geome-\ntry\nOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nModified geome-\ntry\nOUTPUT[vector: any]The output vector layer\nPython code\nAlgorithm ID:native:geometrybyexpression\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nInterpolate point on line\nCreates a point geometry interpolated at a set distance along line or curve geometries.\nZ and M values are linearly interpolated from existing values.\nIf a multipart geometry is encountered, only the first part is considered when calculating the substring.\nIf the specified distance is greater than the input feature’s length, the resultant feature will have a null geometry.\nFig. 25.72: Interpolated point at 500m of the beginning of the line\n25.1. QGIS algorithm provider1139\n\nQGIS Desktop 3.22 User Guide\nSee also:\nPoints along geometry\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nDistanceDISTANCE[number]\nDefault: 0.0\nDistance from the beginning of the line\nInterpolated\npoints\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nInterpolated\npoints\nOUTPUT[vector: point]The output point vector layer with features\nat a set distance along the line or polygon\nboundary\nPython code\nAlgorithm ID:native:interpolatepoint\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nKeep N biggest parts\nTakes a layer with polygons or multipolygons and returns a new layer in which only thenlargest polygons of each\nmultipolygon feature are kept. If a feature hasnor fewer parts, the feature will just be copied.\n1140Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.73: Clockwise from top left: original multipart feature, one, two and three biggest parts kept\nParameters\nLabelNameTypeDescription\nPolygonsINPUT[vector: polygon]Input polygon vector layer\nParts to keepPARTS[number]\nDefault: 1\nNumber of parts to keep. If 1, only the\nbiggest part of the feature will be kept.\nPartsOUTPUT[vector: polygon]\nDefault:\n[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPartsOUTPUT[vector: polygon]The output polygon vector layer with the N\nbiggest parts of each feature\n25.1. QGIS algorithm provider1141\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:keepnbiggestparts\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nLine substring\nReturns the portion of a line (or curve) which falls between the specified start and end distances (measured from the\nbeginning of the line).\nZ and M values are linearly interpolated from existing values.\nIf a multipart geometry is encountered, only the first part is considered when calculating the substring.\nFig. 25.74: Substring line with starting distance set at 0 meters and the ending distance at 250 meters.\nAllowsfeatures in-place modificationof line features\nSee also:\nExtend lines\n1142Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nStart distanceSTART_DISTANCE[number]Distance along the input line to the start\npoint of the output feature\nEnd distanceEND_DISTANCE[number]Distance along the input line to the end\npoint of the output feature\nSubstringOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSubstringOUTPUT[vector: line]The output line vector layer.\nPython code\nAlgorithm ID:native:linesubstring\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nLines to polygons\nGenerates a polygon layer using as polygon rings the lines from an input line layer.\nThe attribute table of the output layer is the same as the one of the input layer.\nDefault menu:Vector►Geometry Tools\nSee also:\nPolygons to lines,Polygonize,Convert geometry type\n25.1. QGIS algorithm provider1143\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nPolygonsOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPolygonsOUTPUT[vector: polygon]The output polygon vector layer.\nPython code\nAlgorithm ID:qgis:linestopolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMerge lines\nJoins all connected parts of MultiLineString geometries into single LineString geometries.\nIf any parts of the input MultiLineString geometries are not connected, the resultant geometry will be a Multi-\nLineString containing any lines which could be merged and any non-connected line parts.\nAllowsfeatures in-place modificationof line features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nMergedOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n1144Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nMergedOUTPUT[vector: line]The output (merged) line vector layer.\nPython code\nAlgorithm ID:native:mergelines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMinimum bounding geometry\nCreates geometries which enclose the features from an input layer. The features can be grouped by a field. The output\nlayer will then contain one feature per group value with a geometry (MBB) that covers the geometries of the features\nwith matching value.\nThe following enclosing geometry types are supported:\n•bounding box (envelope)\n•oriented rectangle\n•circle\n•convex hull\nFig. 25.75: Clockwise from top left: envelope, oriented rectangle, circle, convex hull\nSee also:\nMinimum enclosing circles\n25.1. QGIS algorithm provider1145\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nField\nOptional\nFIELD[tablefield: any]Features can be grouped by a field. If set,\nthis causes the output layer to contain one\nfeature per grouped value with a minimal\ngeometry covering only the features with\nmatching values.\nGeometry typeTYPE[enumeration]\nDefault: 0\nEnclosing geometry types. One of:\n•0 — Envelope (Bounding Box)\n•1 — Minimum Oriented Rectangle\n•2 — Minimum Enclosing Circle\n•3 — Convex Hull\nBounding geome-\ntry\nOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nBounding geome-\ntry\nOUTPUT[vector: polygon]The output (bounding) polygon vector\nlayer.\nPython code\nAlgorithm ID:qgis:minimumboundinggeometry\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMinimum enclosing circles\nCalculates the minimum enclosing circles of the features in the input layer.\n1146Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.76: Enclosing circles for each feature\nAllowsfeatures in-place modificationof polygon features\nSee also:\nMinimum bounding geometry\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nNumber of seg-\nment in circles\nSEGMENTS[number]\nDefault: 72\nThe number of segment used to approx-\nimate a circle.  Minimum 8, maximum\n100000.\nMinimum enclos-\ning circles\nOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1147\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nMinimum enclos-\ning circles\nOUTPUT[vector: polygon]The output polygon vector layer.\nPython code\nAlgorithm ID:native:minimumenclosingcircle\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMulti-ring buffer (constant distance)\nComputes multi-ring (donut) buffer for the features of the input layer, using a fixed or dynamic distance and number\nof rings.\nFig. 25.77: Multi-ring buffer for a line, point and polygon layer\nAllowsfeatures in-place modificationof polygon features\nSee also:\nBuffer,Variable distance buffer,Rectangles, ovals, diamonds,Single sided buffer\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nNumber of ringsRINGS[number]\nDefault: 1\nThe number of rings. It can be a unique\nvalue (same number of rings for all the fea-\ntures) or it can be taken from features data\n(the number of rings depends on feature\nvalues).\ncontinues on next page\n1148Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.149 – continued from previous page\nLabelNameTypeDescription\nDistance between\nrings\nDISTANCE[number]\nDefault: 1.0\nDistance between the rings.  It can be a\nunique value (same distance for all the fea-\ntures) or it can be taken from features data\n(the distance depends on feature values).\nMulti-ring buffer\n(constant    dis-\ntance)\nOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nMulti-ring buffer\n(constant    dis-\ntance)\nOUTPUT[vector: polygon]The output polygon vector layer.\nPython code\nAlgorithm ID:native:multiringconstantbuffer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMultipart to singleparts\nSplits multipart features in the input layer into singlepart features.\nThe attributes of the output layer are the same as the original ones but divided into single features.\nFig. 25.78: Left the multipart source layer and right the single part output result\nAllowsfeatures in-place modificationof point, line, and polygon features\nDefault menu:Vector►Geometry Tools\nSee also:\nCollect geometries,Promote to multipart\n25.1. QGIS algorithm provider1149\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nSingle partsOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSingle partsOUTPUT[same as input]The output vector layer.\nPython code\nAlgorithm ID:native:multiparttosingleparts\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nOffset lines\nOffsets lines by a specified distance. Positive distances will offset lines to the left, and negative distances will offset\nthem to the right.\nFig. 25.79: In blue the source layer, in red the offset one\nAllowsfeatures in-place modificationof line features\n1150Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nSee also:\nArray of offset (parallel) lines,Translate\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nDistanceDISTANCE[number]\nDefault: 10.0\nOffset distance. You can use the Data De-\nfined button on the right to choose a field\nfrom which the radius will be calculated.\nThis way you can have different radius for\neach feature (see\nVariable distance buffer).\nSegmentsSEGMENTS[number]\nDefault: 8\nControls the number of line segments to use\nto approximate a quarter circle when creat-\ning rounded offsets.\nJoin styleJOIN_STYLE[enumeration]\nDefault: 0\nSpecifies whether round, miter or beveled\njoinsshouldbeused whenoffsettingcorners\nin a line. Options are:\n•0 — Round\n•1 — Miter\n•2 — Bevel\nFig. 25.80: Round, miter, and bevel join\nstyles\nMiter limitMITER_LIMIT[number]\nDefault: 2.0\nControls the maximum distance from the\noffset curve to use when creating a mitered\njoin (only applicable for miter join styles).\nMinimum: 1.\nOffsetOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (offset) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOffsetOUTPUT[vector: line]Output (offset) line layer\n25.1. QGIS algorithm provider1151\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:offsetline\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nOriented minimum bounding box\nCalculates the minimum area rotated rectangle for each feature in the input layer.\nFig. 25.81: Oriented minimum bounding box\nAllowsfeatures in-place modificationof polygon features\nSee also:\nMinimum bounding geometry\n1152Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nBounding boxesOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nBounding boxesOUTPUT[vector: polygon]The output polygon vector layer.\nPython code\nAlgorithm ID:native:orientedminimumboundingbox\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nOrthogonalize\nAttempts to orthogonalize the geometries of the input line or polygon layer. This process shifts the vertices in the\ngeometries to try to make every angle in the geometry either a right angle or a straight line.\n25.1. QGIS algorithm provider1153\n\nQGIS Desktop 3.22 User Guide\nFig. 25.82: In blue the source layer and in the red orthogonalized result\nAllowsfeatures in-place modificationof line and polygon features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nMaximum   an-\ngletolerance\n(degrees)\nAN-\nGLE_TOLERANCE\n[number]\nDefault: 15\nSpecify the maximum deviation from a\nright angle or straight line a vertex can have\nfor it to be adjusted.  Smaller tolerances\nmean that only vertices which are already\ncloser to right angles will be adjusted, and\nlarger tolerances mean that vertices which\ndeviate further from right angles will also\nbe adjusted.\nMaximum  algo-\nrithm iterations\nMAX_ITERATIONS[number]\nDefault: 1000\nSetting a larger number for the maximum\nnumber of iterations will result in a more or-\nthogonal geometry at the cost of extra pro-\ncessing time.\nOrthogonalizedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n1154Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOrthogonalizedOUTPUT[same as input]The output polygon vector layer with ad-\njusted angles.\nPython code\nAlgorithm ID:native:orthogonalize\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPoint on Surface\nFor each feature of the input layer, returns a point that is guaranteed to lie on the surface of the feature geometry.\nAllowsfeatures in-place modificationof point features\nSee also:\nCentroids\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nCreate point on\nsurface for each\npart\nAN-\nGLE_TOLERANCE\n[boolean]If checked, a point will be created for each\npart of the geometry.\nPointOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output point vector layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1155\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nPointOUTPUT[vector: point]The output point vector layer.\nPython code\nAlgorithm ID:native:pointonsurface\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPoints along geometry\nCreates points at regular intervals along line or polygon geometries. Created points will have new attributes added\nfor the distance along the geometry and the angle of the line at the point.\nAn optional start and end offset can be specified, which controls how far from the start and end of the geometry the\npoints should be created.\nFig. 25.83: Points created along the source line layer\nSee also:\nInterpolate point on line\n1156Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nDistanceDISTANCE[number]\nDefault: 1.0\nDistance between two consecutive points\nalong the line\nStart offsetSTART_OFFSET[number]\nDefault: 0.0\nDistance from the beginning of the input\nline, representing the position of the first\npoint.\nEnd offsetEND_OFFSET[number]\nDefault: 0.0\nDistance from the end of the input line,\nrepresenting the position beyond which no\npoint feature shoud be created.\nInterpolated\npoints\nOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nInterpolated\npoints\nOUTPUT[vector: point]Point vector layer with features placed\nalong lines or polygon boundaries of the in-\nput layer.\nPython code\nAlgorithm ID:native:pointsalonglines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPoints displacement\nGiven a distance of proximity, identifies nearby point features and radially distributes them over a circle whose center\nrepresents their barycenter. A convenient tool to scatter overlaid features.\n25.1. QGIS algorithm provider1157\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Input point vector layer\nMinimum   dis-\ntance  to  other\npoints\nPROXIMITY[number]\nDefault: 1.0\nDistance below which point features are\nconsidered close. Close features are dis-\ntributed altogether.\nDisplacement dis-\ntance\nDISTANCE[number]\nDefault: 1.0\nRadius of the circle on which close features\nare placed\nHorizontal   dis-\ntribution for two\npoint case\nHORIZONTAL[boolean]\nDefault: False\nWhen only two points are identified as\nclose, aligns them horizontally on the circle\ninstead of vertically.\nDisplacedOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nDisplacedOUTPUT[vector: point]Output point vector layer\nPython code\nAlgorithm ID:qgis:pointsdisplacement\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPole of inaccessibility\nCalculates the pole of inaccessibility for a polygon layer, which is the most distant internal point from the boundary\nof the surface.\nThis algorithm uses the ‘polylabel’ algorithm (Vladimir Agafonkin, 2016), which is an iterative approach guaranteed\nto find the true pole of inaccessibility within a specified tolerance. A more precise tolerance (lower value) requires\nmore iterations and will take longer to calculate.\nThe distance from the calculated pole to the polygon boundary will be stored as a new attribute in the output layer.\n1158Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.84: Pole of inaccessibility\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input vector layer\nToleranceTOLERANCE[number]\nDefault: 1.0\nSet the tolerance for the calculation\nPointOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPointOUTPUT[vector: point]The output point vector layer\nPython code\nAlgorithm ID:native:poleofinaccessibility\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1159\n\nQGIS Desktop 3.22 User Guide\nPolygonize\nCreates a polygon layer whose features boundaries are generated from a line layer ofclosedfeatures.\nFig. 25.85: The yellow polygons generated from the closed lines\nNote:The line layer must have closed shapes in order to be transformed into a polygon.\nSee also:\nPolygons to lines,Lines to polygons,Convert geometry type\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nKeep fields from\nthe input layer\nOptional\nKEEP_FIELDS[boolean]\nDefault: False\nCheck to keep the fields (only the table\nstructure, not the values) of the input layer\nPolygons   from\nlines\nOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output polygon vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nPolygons   from\nlines\nOUTPUT[vector: polygon]The output polygon vector layer from lines\n1160Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:polygonize\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPolygons to lines\nTakes a polygon layer and creates a line layer, with lines representing the boundaries of the polygons in the input\nlayer.\nThe attribute table of the output layer is the same as the one of the input layer.\nFig. 25.86: Black lines as the result of the algorithm\nDefault menu:Vector►Geometry Tools\nSee also:\nLines to polygons,Polygonize,Convert geometry type\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input polygon vector layer\nLinesOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1161\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nLinesOUTPUT[vector: line]The output line vector layer from polygons\nPython code\nAlgorithm ID:native:polygonstolines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nProject points (Cartesian)\nProjects point geometries by a specified distance and bearing (azimuth).\nAllowsfeatures in-place modificationof point features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Input point vector layer\nBearing (degrees\nfrom North)\nBEARING[number]\nDefault: 0.0\nClockwise angle starting from North, in de-\ngree (°) unit\nDistanceDISTANCE[number]\nDefault: 1.0\nDistance to offset geometries, in layer units\nProjectedOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output point vector layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n1162Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nProjectedOUTPUT[vector: point]The output (projected) point vector layer\nPython code\nAlgorithm ID:native:projectpointcartesian\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPromote to multipart\nTakes a vector layer with singlepart geometries and generates a new one in which all geometries are multipart.\nInput features which are already multipart features will remain unchanged.\nThis algorithm can be used to force geometries to multipart types in order to be compatible with data providers that\nrequire multipart features.\nAllowsfeatures in-place modificationof point, line, and polygon features\nSee also:\nAggregate,Collect geometries\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nMultipartsOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output multipart vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1163\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nMultipartsOUTPUT[same as input]The output multipart vector layer\nPython code\nAlgorithm ID:native:promotetomulti\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRectangles, ovals, diamonds\nCreates a buffer area with a rectangle, oval or diamond shape for each feature of the input point layer.\nThe shape parameters can be fixed for all features or dynamic using a field or an expression.\nFig. 25.87: Different buffer shapes with dynamic parameters\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Input point vector layer\nBuffer shapeSHAPE[enumeration]The shape to use. One of:\n•0 — Rectangles\n•1 — Ovals\n•2 — Diamonds\nWidthWIDTH[number]\nDefault: 1.0\nWidth of the buffer shape\nHeightHEIGHT[number]\nDefault: 1.0\nHeight of the buffer shape\nRotation\nOptional\nROTATION[number]\nDefault: None\nRotation of the buffer shape\nNumber of seg-\nment\nSEGMENTS[number]\nDefault: 36\nNumber of segments for a full circle (Ovals\nshape)\ncontinues on next page\n1164Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.155 – continued from previous page\nLabelNameTypeDescription\nOutputOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[vector: polygon]The output vector layer (with the buffer\nshapes)\nPython code\nAlgorithm ID:native:rectanglesovalsdiamonds\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRemove duplicate vertices\nRemoves duplicate vertices from features, wherever removing the vertices does not result in a degenerate geometry.\nThe tolerance parameter specifies the tolerance for coordinates when determining whether vertices are identical.\nBy default, Z values are not considered when detecting duplicate vertices. E.g. two vertices with the same X and\nY coordinate but different Z values will still be considered duplicate and one will be removed. If theUse Z Value\nparameter is true, then the Z values are also tested and vertices with the same X and Y but different Z will be\nmaintained.\nAllowsfeatures in-place modificationof point, line, and polygon features\nNote:Duplicate vertices are not tested between different parts of a multipart geometry, e.g. a multipoint geometry\nwith overlapping points will not be changed by this method.\nSee also:\nExtract vertices,Extract specific vertices,Delete duplicate geometries\n25.1. QGIS algorithm provider1165\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nToleranceTOLERANCE[number]\nDefault: 0.000001\nVertices closer than the specified distance\nare considered duplicates\nUse Z valueUSE_Z_VALUE[boolean]\nDefault: False\nIf theUse Z Valueparameter is true, then\nthe Z values are also tested and vertices with\nthe same X and Y but different Z will be\nmaintained.\nCleanedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCleanedOUTPUT[same as input]The output vector layer (without duplicate\nvertices)\nPython code\nAlgorithm ID:native:removeduplicatevertices\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRemove null geometries\nRemoves any features which do not have a geometry from a vector layer. All other features will be copied unchanged.\nThe features with null geometries can be saved to a separate layer.\nIfAlso remove empty geometriesis checked, the algorithm removes features whose geometries have no coordinates,\ni.e., geometries that are empty. In that case, also the null output will reflect this option, containing both null and\nempty geometries.\nSee also:\nDelete duplicate geometries\n1166Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer (with non-NULL geome-\ntries)\nAlsoremove\nempty geometries\nREMOVE_EMPTY[boolean]\nNon null geome-\ntries\nOUTPUT\nOptional\n[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the non-\nNULL (and non-empty) geometries. One\nof:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nNull geometries\nOptional\nNULL_OUTPUT[same as input]\nDefault:[Skip\noutput]\nSpecify the output vector layer for the\nNULL (and empty) geometries. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nNull geometriesNULL_OUTPUT[same as input]Output vector layer (for NULL and, if cho-\nsen, empty geometries)\nNon null geome-\ntries\nOUTPUT[same as input]The output vector layer (without NULL\nand, if chosen, empty geometries)\nPython code\nAlgorithm ID:native:removenullgeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1167\n\nQGIS Desktop 3.22 User Guide\nReverse line direction\nInverts the direction of a line layer.\nFig. 25.88: Before and after the direction inversion\nAllowsfeatures in-place modificationof line features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nReversedOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nReversedOUTPUT[vector: line]The output line vector layer (with reversed\nlines)\nPython code\nAlgorithm ID:native:reverselinedirection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThe\nalgorithm id\nis displayed when you hover over the algorithm in the Processing Toolbox. The\nparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1168Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nRotate\nRotates feature geometries by the specified angle clockwise. The rotation occurs around each feature’s centroid, or\noptionally around a unique preset point.\nAllowsfeatures in-place modificationof point, line, and polygon features\nSee also:\nTranslate,Swap X and Y coordinates\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nRotation (degrees\nclockwise)\nANGLE[number]\nDefault: 0.0\nAngle of the rotation in degrees\nRotation  anchor\npoint (x, y)\nOptional\nANCHOR[point]\nDefault: None\nX,Y coordinates of the point to rotate the\nfeatures around. If not set the rotation oc-\ncurs around each feature’s centroid.\nRotatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecifythe outputvector layer (withrotated\ngeometries). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRotatedOUTPUT[same as input]The output vector layer with rotated geome-\ntries\nPython code\nAlgorithm ID:native:rotatefeatures\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1169\n\nQGIS Desktop 3.22 User Guide\nSegmentize by maximum angle\nSegmentizes a geometry by converting curved sections to linear sections.\nThe segmentization is performed by specifying the maximum allowed radius angle between vertices on the straight-\nened geometry (e.g the angle of the arc created from the original arc center to consecutive output vertices on the\nlinearized geometry). Non-curved geometries will be retained without change.\nSee also:\nSegmentize by maximum distance,Simplify,Smooth\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nMaximum  angle\nbetween  vertices\n(degrees)\nANGLE[number]\nDefault: 5.0\nMaximum allowed radius angle between\nvertices on the straightened geometry\nSegmentizedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer (with seg-\nmentized geometries). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSegmentizedOUTPUT[same as input]The output vector layer with segmentized\ngeometries\nPython code\nAlgorithm ID:native:segmentizebymaxangle\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1170Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nSegmentize by maximum distance\nSegmentizes a geometry by converting curved sections to linear sections.\nThe segmentization is performed by specifying the maximum allowed offset distance between the original curve and\nthe segmentized representation. Non-curved geometries will be retained without change.\nSee also:\nSegmentize by maximum angle,Simplify,Smooth\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nMaximum  offset\ndistance\nDISTANCE[number]\nDefault: 1.0\nMaximum allowed offset distance between\nthe original curve and the segmentized rep-\nresentation, in the layer units.\nSegmentizedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer (with seg-\nmentized geometries). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSegmentizedOUTPUT[same as input]The output vector layer with segmentized\ngeometries\nPython code\nAlgorithm ID:native:segmentizebymaxdistance\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1171\n\nQGIS Desktop 3.22 User Guide\nSet M value\nSets the M value for geometries in a layer.\nIf M values already exist in the layer, they will be overwritten with the new value. If no M values exist, the geometry\nwill be upgraded to include M values and the specified value used as the initial M value for all geometries.\nAllowsfeatures in-place modificationof point, line, and polygon features with M enabled\nTip:Use the\nIdentify Features\nbutton to check the added M value: the results are available in theIdentify Results\ndialog.\nSee also:\nSet M value from raster,Set Z value,Drop M/Z values\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nM ValueM_VALUE[number]\nDefault: 0.0\nM value to assign to the feature geometries\nM AddedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nM AddedOUTPUT[same as input]The output vector layer (with M values as-\nsigned to the geometries)\nPython code\nAlgorithm ID:native:setmvalue\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1172Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nSet M value from raster\nUses values sampled from a band within a raster layer to set the M value for every overlapping vertex in the feature\ngeometry. The raster values can optionally be scaled by a preset amount.\nIf M values already exist in the layer, they will be overwritten with the new value. If no M values exist, the geometry\nwill be upgraded to include M values.\nAllowsfeatures in-place modificationof point, line, and polygon features with M enabled\nSee also:\nDrape (set Z value from raster),Set M value\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nRaster layerRASTER[raster]Raster layer with M values\nBand numberBAND[raster band]\nDefault: 1\nThe raster band from which the M values\nare taken\nValue  for  no-\ndata  or  non-\nintersecting\nvertices\nNODATA[number] De-\nfault: 0.0\nValue to use in case the vertex does not in-\ntersect (a valid pixel of) the raster\nScale factorSCALE[number]\nDefault: 1.0\nScaling value: the band values are multi-\nplied by this value.\nUpdatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer (with up-\ndated M values). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nUpdatedOUTPUT[same as input]The output vector layer (with updated M\nvalues)\n25.1. QGIS algorithm provider1173\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:setmfromraster\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSet Z value\nSets the Z value for geometries in a layer.\nIf Z values already exist in the layer, they will be overwritten with the new value. If no Z values exist, the geometry\nwill be upgraded to include Z values and the specified value used as the initial Z value for all geometries.\nAllowsfeatures in-place modificationof point, line, and polygon features with Z enabled\nTip:Use the\nIdentify Features\nbutton to check the added Z value: the results are available in theIdentify Results\ndialog.\nSee also:\nDrape (set Z value from raster),Set M value,Drop M/Z values\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nZ ValueZ_VALUE[number]\nDefault: 0.0\nZ value to assign to the feature geometries\nZ AddedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nZ AddedOUTPUT[same as input]The output vector layer (with Z values as-\nsigned)\n1174Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:setzvalue\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSimplify\nSimplifies the geometries in a line or polygon layer. It creates a new layer with the same features as the ones in the\ninput layer, but with geometries containing a lower number of vertices.\nThe algorithm gives a choice of simplification methods, including distance based (the “Douglas-Peucker” algorithm),\narea based (“Visvalingam” algorithm) and snapping geometries to grid.\nFig. 25.89: Clockwise from top left: source layer and increasing simplification tolerances\nAllowsfeatures in-place modificationof line and polygon features\nDefault menu:Vector►Geometry Tools\nSee also:\nSmooth,Densify by count,Densify by interval\n25.1. QGIS algorithm provider1175\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nSimplification\nmethod\nMETHOD[enumeration]\nDefault: 0\nSimplification method. One of:\n•0 — Distance (Douglas-Peucker)\n•1 — Snap to grid\n•2 — Area (Visvalingam)\nToleranceTOLERANCE[number]\nDefault: 1.0\nThreshold tolerance (in units of the layer):\nif the distance between two nodes is smaller\nthanthetolerancevalue, thesegmentwillbe\nsimplified and vertices will be removed.\nSimplifiedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (simplified) vector layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSimplifiedOUTPUT[same as input]The output (simplified) vector layer\nPython code\nAlgorithm ID:native:simplifygeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSingle sided buffer\nComputes a buffer on lines by a specified distance on one side of the line only.\nBuffer always results in a polygon layer.\n1176Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.90: Left versus right side buffer on the same vector line layer\nSee also:\nBuffer\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nDistanceDISTANCE[number]\nDefault: 10.0\nBuffer distance.\nSideSIDE[enumeration]\nDefault: 0\nWhich side to create the buffer on. One of:\n•0 – Left\n•1 – Right\nSegmentsSEGMENTS[number]\nDefault: 8\nControls the number of line segments to use\nto approximate a quarter circle when creat-\ning rounded offsets.\nJoin styleJOIN_STYLE[enumeration]\nDefault: 0\nSpecifies whether round, miter or beveled\njoinsshouldbeused whenoffsettingcorners\nin a line. Options are:\n•0 — Round\n•1 — Miter\n•2 — Bevel\nFig. 25.91: Round, miter, and bevel join\nstyles\nMiter limitMITER_LIMIT[number]\nDefault: 2.0\nControls the maximum distance from the\noffset curve to use when creating a mitered\njoin (only applicable for miter join styles).\nMinimum: 1.0\nBufferOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (buffer) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1177\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nBufferOUTPUT[vector: polygon]Output (buffer) polygon layer\nPython code\nAlgorithm ID:native:singlesidedbuffer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSmooth\nSmooths the geometries in a line or polygon layer by adding morevertices and cornersto the feature geometries.\nThe iterations parameter dictates how many smoothing iterations will be applied to each geometry. A higher number\nof iterations results in smoother geometries with the cost of greater number of nodes in the geometries.\nFig. 25.92: Increasing number of iterations causes smoother geometries\nThe offset parameter controls how “tightly” the smoothed geometries follow the original geometries. Smaller values\nresults in a tighter fit, and larger values will create a looser fit.\n1178Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.93: Blue: the input layer. Offset 0.25 gives the red line, while offset 0.50 gives the green line.\nThe maximum angle parameter can be used to prevent smoothing of nodes with large angles. Any node where the\nangle of the segments to either side is larger than this will not be smoothed. For example, setting the maximum angle\nto 90 degrees or lower would preserve right angles in the geometry.\nAllowsfeatures in-place modificationof line and polygon features\nSee also:\nSimplify,Densify by count,Densify by interval\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nInput line or polygon vector layer\nIterationsITERATIONS[number]\nDefault: 1\nIncreasing the number of iterations will give\nsmoother geometries (and more vertices).\nOffsetOFFSET[number]\nDefault: 0.25\nIncreasing values willmovethe smoothed\nlines / boundaries further away from the in-\nput lines / boundaries.\nMaximum  node\nangle to smooth\nMAX_ANGLE[number]\nDefault: 180.0\nEvery node below this value will be\nsmoothed\ncontinues on next page\n25.1. QGIS algorithm provider1179\n\nQGIS Desktop 3.22 User Guide\nTable 25.161 – continued from previous page\nLabelNameTypeDescription\nSmoothedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (smoothed) layer. One\nof:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSmoothedOUTPUT[same as input]Output (smoothed) vector layer\nPython code\nAlgorithm ID:native:smoothgeometry\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSnap geometries to layer\nSnaps the geometries in a layer either to the geometries from another layer, or to geometries within the same layer.\nMatching is done based on a tolerance distance, and vertices will be inserted or removed as required to make the\ngeometries match the reference geometries.\nAllowsfeatures in-place modificationof point, line, and polygon features\nSee also:\nSnap points to grid\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nReference layerREFER-\nENCE_LAYER\n[vector: any]Vector layer to snap to\nToleranceTOLERANCE[number]\nDefault: 10.0\nControl how close input vertices need to\nbe to the reference layer geometries before\nthey are snapped.\ncontinues on next page\n1180Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.162 – continued from previous page\nLabelNameTypeDescription\nBehaviorBEHAVIOR[enumeration]\nDefault: 0\nSnapping can be done to an existing node or\na segment (its closest point to the vertex to\nmove). Available snapping options:\n•0 — Prefer aligning nodes, insert ex-\ntra vertices where required\nPrefer to snap to nodes, even when a\nsegment may be closer than a node.\nNew nodes will be inserted to make\ngeometries follow each other exactly\nwhen inside allowable tolerance.\n•1 — Prefer closest point, insert extra\nvertices where required\nSnap to closest point, regardless of it\nis a node or a segment. New nodes\nwill be inserted to make geometries\nfollow each other exactly when inside\nallowable tolerance.\n•2 — Prefer aligning nodes, don’t in-\nsert new vertices\nPrefer to snap to nodes, even when a\nsegment may be closer than a node.\nNo new nodes will be inserted.\n•3 — Prefer closest point, don’t insert\nnew vertices\nSnap to closest point, regardless of it\nis a node or a segment. No new nodes\nwill be inserted.\n•4 — Move end points only, prefer\naligning nodes\nOnly snap start/end points of lines\n(point features will also be snapped,\npolygon features will not be modi-\nfied), prefer to snap to nodes.\n•5 — Move end points only, prefer\nclosest point\nOnly snap start/end points of lines\n(point features will also be snapped,\npolygon features will not be modi-\nfied), snap to closest point\n•6 — Snap end points to end points\nonly\nOnly snapthestart/endpointsoflines\nto other start/end points of lines\n•7 — Snap to anchor nodes (single\nlayer only)\nSnapped geometryOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (snapped) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1181\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nSnapped geometryOUTPUT[same as input]Output (snapped) vector layer\nPython code\nAlgorithm ID:native:snapgeometries\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSnap points to grid\nModifies the coordinates of geometries in a vector layer, so that all points or vertices are snapped to the closest point\nof a grid.\nIf the snapped geometry cannot be calculated (or is totally collapsed) the feature’s geometry will be cleared.\nSnapping can be performed on the X, Y, Z or M axis. A grid spacing of 0 for any axis will disable snapping for that\naxis.\nAllowsfeatures in-place modificationof point, line, and polygon features\nNote:Snapping to grid may generate an invalid geometry in some corner cases.\nSee also:\nSnap geometries to layer\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nX Grid SpacingHSPACING[number]\nDefault: 1.0\nGrid spacing on the X axis\nY Grid SpacingVSPACING[number]\nDefault: 1.0\nGrid spacing on the Y axis\nZ Grid SpacingZSPACING[number]\nDefault: 0.0\nGrid spacing on the Z axis\nM Grid SpacingMSPACING[number]\nDefault: 0.0\nGrid spacing on the M axis\ncontinues on next page\n1182Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.163 – continued from previous page\nLabelNameTypeDescription\nSnappedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (snapped) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSnappedOUTPUT[same as input]Output (snapped) vector layer\nPython code\nAlgorithm ID:native:snappointstogrid\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSplit lines by maximum length\nTakes a line (or curve) layer and splits each feature into multiple parts, where each part is of a specified maximum\nlength. Z and M values at the start and end of the new line substrings are linearly interpolated from existing values.\nAllowsfeatures in-place modificationof line features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]The input line vector layer\nMaximum   line\nlength\nLENGTH[number]\nDefault: 10.0\nThe maximum length of a line in the output.\nSplitOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1183\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nSplitOUTPUT[vector: line]The new line vector layer - the length of\nthe feature geometries is less than or equal\nto the length specified in the LENGTH pa-\nrameter.\nPython code\nAlgorithm ID:native:splitlinesbylength\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSubdivide\nSubdivides the geometry. The returned geometry will be a collection containing subdivided parts from the original\ngeometry, where no part has more than the specified maximum number of nodes.\nThis is useful for dividing a complex geometry into less complex parts, easier to spatially index and faster to perform\nspatial operations. Curved geometries will be segmentized before subdivision.\nFig. 25.94: Left the input layer, middle maximum nodes value is 100 and right maximum value is 200\nAllowsfeatures in-place modificationof point, line, and polygon features\nNote:Subdividing a geometry can generate geometry parts that may not be valid and may contain self-intersections.\nSee also:\nExplode lines,Line substring\n1184Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nMaximum nodes\nin parts\nMAX_NODES[number]\nDefault: 256\nMaximum number of vertices each new ge-\nometry part is allowed to have. Fewersub-\npartsfor higher values.\nSubdividedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (subdivided) vector\nlayer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSubdividedOUTPUT[same as input]Output vector layer\nPython code\nAlgorithm ID:native:subdivide\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSwap X and Y coordinates\nSwitches the X and Y coordinate values in input geometries.\nIt can be used to repair geometries which have accidentally had their latitude and longitude values reversed.\nAllowsfeatures in-place modificationof point, line, and polygon features\nSee also:\nTranslate,Rotate\n25.1. QGIS algorithm provider1185\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nSwappedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSwappedOUTPUT[same as input]Output (swapped) vector layer\nPython code\nAlgorithm ID:native:swapxy\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTapered buffers\nCreates tapered buffer along line geometries, using a specified start and end buffer diameter.\n1186Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.95: Tapered buffer example\nSee also:\nVariable width buffer (by M value),Buffer,Create wedge buffers\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nStart widthSTART_WIDTH[number]\nDefault: 0.0\nRepresents the radius of the buffer applied\nat the start point of the line feature\nEnd widthEND_WIDTH[number]\nDefault: 0.0\nRepresents the radius of the buffer applied\nat the end point of the line feature.\nSegmentsSEGMENTS[number]\nDefault: 16\nControls the number of line segments to use\nto approximate a quarter circle when creat-\ning rounded offsets.\nBufferedOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (buffer) layer. One of:\n•CreateTemporaryLayer\n(\nTEMPORARY_OUTPUT\n)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1187\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nBufferedOUTPUT[vector: polygon]Output (buffer) polygon layer\nPython code\nAlgorithm ID:native:taperedbuffer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTessellate\nTessellates a polygon geometry layer, dividing the geometries into triangular components.\nThe output layer consists of multipolygon geometries for each input feature, with each multipolygon consisting of\nmultiple triangle component polygons.\nFig. 25.96: Tessellated polygon (right)\nAllowsfeatures in-place modificationof polygon features\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: polygon]Input polygon vector layer\nTesselatedOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n1188Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nTesselatedOUTPUT[vector: polygon]Output multipolygonZ layer\nPython code\nAlgorithm ID:3d:tessellate\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTransect\nCreates transects on vertices for (multi)linestring.\nA transect is a line oriented from an angle (by default perpendicular) to the input polylines (at vertices).\nField(s) from feature(s) are returned in the transect with these new fields:\n•TR_FID: ID of the original feature\n•TR_ID: ID of the transect. Each transect have an unique ID\n•TR_SEGMENT: ID of the segment of the linestring\n•TR_ANGLE: Angle in degrees from the original line at the vertex\n•TR_LENGTH: Total length of the transect returned\n•TR_ORIENT: Side of the transect (only on the left or right of the line, or both side)\nFig. 25.97: Dashed red lines represent the transect of the input line layer\n25.1. QGIS algorithm provider1189\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nLength  of  the\ntransect\nLENGTH[number]\nDefault: 5.0\nLength in map unit of the transect\nAngle in degrees\nfrom the original\nline at the vertices\nANGLE[number]\nDefault: 90.0\nChange the angle of the transect\nSide to create the\ntransect\nSIDE[enumeration]Choose the side of the transect. Available\noptions are:\n•0 — Left\n•1 — Right\n•2 — Both\nTransectOUTPUT[vector: line]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output line layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nTransectOUTPUT[vector: line]Output line layer\nPython code\nAlgorithm ID:native:transect\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTranslate\nMoves the geometries within a layer, by offsetting with a predefined X and Y displacement.\nZ and M values present in the geometry can also be translated.\n1190Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.98: Dashed lines represent the translated geometry of the input layer\nAllowsfeatures in-place modificationof point, line, and polygon features\nSee also:\nArray of translated features,Offset lines,Rotate,Swap X and Y coordinates\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nOffset distance (x-\naxis)\nDELTA_X[number]\nDefault: 0.0\nDisplacement to apply on the X axis\nOffset distance (y-\naxis)\nDELTA_Y[number]\nDefault: 0.0\nDisplacement to apply on the Y axis\nOffset distance (z-\naxis)\nDELTA_Z[number]\nDefault: 0.0\nDisplacement to apply on the Z axis\nOffset distance (m\nvalues)\nDELTA_M[number]\nDefault: 0.0\nDisplacement to apply on the M axis\nTranslatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1191\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nTranslatedOUTPUT[same as input]Output vector layer\nPython code\nAlgorithm ID:native:translategeometry\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nVariable width buffer (by M value)\nCreates variable width buffers along lines, using the M value of the line geometries as the diameter of the buffer at\neach vertex.\nFig. 25.99: Variable buffer example\nSee also:\nTapered buffers,Buffer,Set M value,Variable distance buffer\n1192Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line vector layer\nSegmentsSEGMENTS[number]\nDefault: 16\nNumber of the buffer segments per quarter\ncircle. It can be a unique value (same value\nfor all the features), or it can be taken from\nfeatures data (the value can depend on fea-\nture attributes).\nBufferedOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output (buffer) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nBufferedOUTPUT[vector: polygon]Variable buffer polygon layer\nPython code\nAlgorithm ID:native:bufferbym\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1193\n\nQGIS Desktop 3.22 User Guide\nVoronoi polygons\nTakes a point layer and generates a polygon layer containing the Voronoi polygons (known also as Thiessen polygons)\ncorresponding to those input points.\nAny location within a Voronoi polygon is closer to the associated point than to any other point.\nFig. 25.100: Voronoi polygons\nDefault menu:Vector►Geometry Tools\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]Input point vector layer\nBuffer region (%\nof extent)\nBUFFER[number]\nDefault: 0.0\nThe extent of the output layer will be this\nmuch bigger than the extent of the input\nlayer\nVoronoi polygonsOUTPUT[vector: polygon]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer (with the Voronoi\npolygons). One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1194Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nVoronoi polygonsOUTPUT[vector: polygon]Voronoi polygons of the input point vector\nlayer\nPython code\nAlgorithm ID:qgis:voronoipolygons\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.19Vector overlay\nClip\nClips a vector layer using the features of an additional polygon layer.\nOnly the parts of the features in the input layer that fall within the polygons of the overlay layer will be added to the\nresulting layer.\nWarning: Geometry modification only\nThisoperationmodifiesonlythefeaturesgeometry. Theattributevaluesofthefeaturesarenotmodified, although\nproperties such as area or length of the features will be modified by the clipping operation. If such properties are\nstored as attributes, those attributes will have to be manually updated.\nThis algorithm uses spatial indexes on the providers, prepared geometries and apply a clipping operation if the ge-\nometry isn’t wholly contained by the mask geometry.\n25.1. QGIS algorithm provider1195\n\nQGIS Desktop 3.22 User Guide\nFig. 25.101: Clipping operation between a two-features input layer and a single feature overlay layer (left) - resulting\nfeatures are moved for clarity (right)\nAllowsfeatures in-place modificationof point, line, and polygon features\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nIntersection,Difference\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer containing the features to be clipped\nOverlay layerOVERLAY[vector: polygon]Layer containing the clipping features\nClippedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain the features\nfrom the input layer that are inside the over-\nlay (clipping) layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1196Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nClippedOUTPUT[same as input]Layer containing features from the input\nlayer split by the overlay layer.\nPython code\nAlgorithm ID:qgis:clip\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDifference\nExtracts features from the input layer that don’t fall within the boundaries of the overlay layer.\nInput layer features that partially overlap the overlay layer feature(s) are split along the boundary of those feature(s)\nand only the portions outside the overlay layer features are retained.\nWarning: Geometry modification only\nThisoperationmodifiesonlythefeaturesgeometry. Theattributevaluesofthefeaturesarenotmodified, although\nproperties such as area or length of the features will be modified by the clipping operation. If such properties are\nstored as attributes, those attributes will have to be manually updated.\nFig. 25.102: Difference operation between a two-features input layer and a single feature overlay layer (left) - resulting\nfeatures are moved for clarity (right)\n25.1. QGIS algorithm provider1197\n\nQGIS Desktop 3.22 User Guide\nAllowsfeatures in-place modificationof point, line, and polygon features\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nSymmetrical difference,Clip\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to extract (parts of) features from.\nOverlay layerOVERLAY[vector: any]Layer containing the geometries that will\nbe subtracted from the input layer geome-\ntries. It is expected to have at least as many\ndimensions (point: 0D, line: 1D, polygon:\n2D, volume: 3D) as the input layer geome-\ntries.\nDifferenceOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain the (parts of)\nfeatures from the input layer that are not in-\nside the overlay layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nDifferenceOUTPUT[same as input]Layer containing (parts of) features from\nthe input layer not overlapping the overlay\nlayer.\nPython code\nAlgorithm ID:qgis:difference\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThe\nalgorithm id\nis displayed when you hover over the algorithm in the Processing Toolbox. The\nparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1198Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExtract/clip by extent\nCreates a new vector layer that only contains features which fall within a specified extent.\nAny features which intersect the extent will be included.\nFig. 25.103: Extract operation between a three-feature input layer ‘a’ and a dashed extent (left) - resulting features\nwith dashed extent for reference (right)\nSee also:\nClip\n25.1. QGIS algorithm provider1199\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to extract (parts of) features from.\nExtent   (xmin,\nxmax,ymin,\nymax)\nEXTENT[extent]Extent for clipping.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nClip features to\nextent\nCLIP[boolean]\nDefault: False\nIf  checked,  output  geometries  will\nbe  automatically  converted  to  multi\ngeometries  to  ensure  uniform  output\ntypes.  Moreover the geometries will be\nclipped to the extent chosen instead of\ntaking the whole geometry as output.\nFig. 25.104: Extract operation between a\nthree-feature input layer ‘a’ and a dashed ex-\ntent (left) - resulting features with dashed\nextent for reference (right)\nExtractedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain the features\nfrom the input layer that are inside the clip\nextent. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtractedOUTPUT[same as input]Layer containing the clipped features.\n1200Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:extractbyextent\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nIntersection\nExtracts the portions of features from the input layer that overlap features in the overlay layer.\nFeatures in the intersection layer are assigned the attributes of the overlapping features from both the input and overlay\nlayers.\nWarning: Geometry modification only\nThisoperationmodifiesonlythefeaturesgeometry. Theattributevaluesofthefeaturesarenotmodified, although\nproperties such as area or length of the features will be modified by the clipping operation. If such properties are\nstored as attributes, those attributes will have to be manually updated.\nFig. 25.105: The intersection operation: A two-features input layer and a single feature overlay layer (left) - resulting\nfeatures are moved for clarity (right)\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nClip,Difference\n25.1. QGIS algorithm provider1201\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to extract (parts of) features from.\nOverlay layerOVERLAY[vector: any]Layer containing the features to check for\noverlap. Its features’ geometry is expected\nto have at least as many dimensions (point:\n0D, line: 1D, polygon: 2D, volume: 3D) as\nthe input layer’s.\nInput  fields  to\nkeep (leave empty\nto keep all fields)\nOptional\nINPUT_FIELDS[tablefield:    any]\n[list]\nDefault: None\nField(s) of the input layer to keep in the out-\nput. If no fields are chosen all fields are\ntaken.\nOverlay fields to\nkeep (leave empty\nto keep all fields)\nOptional\nOVER-\nLAY_FIELDS\n[tablefield:    any]\n[list]\nDefault: None\nField(s) of the overlay layer to keep in the\noutput. If no fields are chosen all fields are\ntaken.\nOverlay fields pre-\nfix\nOptional\nOVER-\nLAY_FIELDS_PREFIX\n[string]Prefix to add to the field names of the inter-\nsect layer’s fields to avoid name collisions\nwith fields in the input layer.\nIntersectionOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain (the parts of)\nthefeaturesfromtheinputlayerthatoverlap\none or more features from the overlay layer.\nOne of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nIntersectionOUTPUT[same as input]Layer containing (parts of) features from\nthe input layer that overlap the overlay layer.\nPython code\nAlgorithm ID:qgis:intersection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1202Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nLine intersections\nCreates point features where the lines from the two layers intersect.\nFig. 25.106: Points of intersection\nDefault menu:Vector►Analysis Tools\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]Input line layer.\nIntersect layerINTERSECT[vector: line]Layer to use to find line intersections.\nInput  fields  to\nkeep (leave empty\nto keep all fields)\nOptional\nINPUT_FIELDS[tablefield:    any]\n[list]\nDefault: None\nField(s) of the input layer to keep in the out-\nput. If no fields are chosen all fields are\ntaken.\nIntersect fields to\nkeep (leave empty\nto keep all fields)\nOptional\nINTER-\nSECT_FIELDS\n[tablefield:    any]\n[list]\nDefault: None\nField(s) of the intersect layer to keep in the\noutput. If no fields are chosen all fields are\ntaken.\nIntersectionOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain the intersection\npoints of the lines from the input and over-\nlay layers. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1203\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nIntersect   fields\nprefix\nOptional\nINTER-\nSECT_FIELDS_PREFIX\n[string]Prefix to add to the field names of the inter-\nsect layer’s fields to avoid name collisions\nwith fields in the input layer.\nOutputs\nLabelNameTypeDescription\nIntersectionsOUTPUT[vector: point]Point vector layer with the intersections.\nPython code\nAlgorithm ID:qgis:lineintersections\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSplit with lines\nSplits the lines or polygons in one layer using the lines in another layer to define the breaking points. Intersection\nbetween geometries in both layers are considered as split points.\nOutput will contain multi geometries for split features.\nFig. 25.107: Split lines\nAllowsfeatures in-place modificationof line and polygon features\n1204Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line, poly-\ngon]\nLayer containing the lines or polygons to\nsplit.\nSplit layerLINES[vector: line]Line layer whose lines are used to define the\nbreaking points.\nSplitOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain the splitted (in\ncase they are intersected by a line in the split\nlayer) line/polygon features from the input\nlayer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nSplitOUTPUT[same as input]Output vector layer with split lines or poly-\ngons from input layer.\nPython code\nAlgorithm ID:qgis:splitwithlines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSymmetrical difference\nCreates a layer containing features from both the input and overlay layers but with the overlapping areas between the\ntwo layers removed.\nThe attribute table of the symmetrical difference layer contains attributes and fields from both the input and overlay\nlayers.\nWarning: Geometry modification only\nThisoperationmodifiesonlythefeaturesgeometry. Theattributevaluesofthefeaturesarenotmodified, although\nproperties such as area or length of the features will be modified by the clipping operation. If such properties are\nstored as attributes, those attributes will have to be manually updated.\n25.1. QGIS algorithm provider1205\n\nQGIS Desktop 3.22 User Guide\nFig. 25.108: Symmetrical difference operation between a two-features input layer and a single feature overlay layer\n(left) - resulting features are moved for clarity (right)\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nDifference,Clip,Intersection\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]First layer to extract (parts of) features\nfrom.\nOverlay layerOVERLAY[vector: any]Second layer to extract (parts of) features\nfrom. Ideally the geometry type should be\nthe same as input layer.\nSymmetrical dif-\nference\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain (the parts of)\nthe features from the input and overlay lay-\ners that do not overlap features from the\nother layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1206Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nOverlay fields pre-\nfix\nOptional\nOVER-\nLAY_FIELDS_PREFIX\n[string]Prefix to add to the field names of the over-\nlay layer’s fields to avoid name collisions\nwith fields in the input layer.\nOutputs\nLabelNameTypeDescription\nSymmetrical dif-\nference\nOUTPUT[same as input]Layer containing (parts of) features from\neach layer not overlapping the other layer.\nPython code\nAlgorithm ID:qgis:symmetricaldifference\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nUnion\nChecks overlaps between features within the input layer and creates separate features for overlapping and non-\noverlapping parts. The area of overlap will create as many identical overlapping features as there are features that\nparticipate in that overlap.\n25.1. QGIS algorithm provider1207\n\nQGIS Desktop 3.22 User Guide\nFig. 25.109: Union operation with a single input layer of three overlapping features (left) - resulting features are\nmoved for clarity (right)\nAn overlay layer can also be used, in which case features from each layer are split at their overlap with features from\nthe other one, creating a layer containing all the portions from both input and overlay layers. The attribute table of the\nunion layer is filled with attribute values from the respective original layer for non-overlapping features, and attribute\nvalues from both layers for overlapping features.\nFig. 25.110: Union operation between a two-features input layer and a single feature overlay layer (left) - resulting\nfeatures are moved for clarity (right)\nNote:Forunion(A,B)algorithm, if there are overlaps among geometries of layer A or among geometries of\nlayer B, these are not resolved: you need to dounion(union(A,B))to resolve all overlaps, i.e. run single layer\n1208Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nunion(X)on the produced resultX=union(A,B).\nDefault menu:Vector►Geoprocessing Tools\nSee also:\nClip,Difference,Intersection\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer to split at any intersec-\ntions.\nOverlay layer\nOptional\nOVERLAY[vector: any]Layer that will be combined to the first\none. Ideally the geometry type should be\nthe same as input layer.\nUnionOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the layer to contain the (split and\nduplicated) features from the input layer\nand the overlay layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nAdvanced parameters\nLabelNameTypeDescription\nOverlay fields pre-\nfix\nOptional\nOVER-\nLAY_FIELDS_PREFIX\n[string]Prefix to add to the field names of the over-\nlay layer’s fields to avoid name collisions\nwith fields in the input layer.\nOutputs\nLabelNameTypeDescription\nUnionOUTPUT[same as input]Layer containing all the overlapping and\nnon-overlapping parts from the processed\nlayer(s).\n25.1. QGIS algorithm provider1209\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:union\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.20Vector selection\nExtract by attribute\nCreates two vector layers from an input layer: one will contain only matching features while the second will contain\nall the non-matching features.\nThe criteria for adding features to the resulting layer is based on the values of an attribute from the input layer.\nSee also:\nSelect by attribute\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Layer to extract features from.\nSelection attributeFIELD[tablefield: any]Filtering field of the layer\nOperatorOPERATOR[enumeration]\nDefault: 0\nMany different operators are available:\n•0 — =\n•1 —̸=\n•2 — >\n•3 — >=\n•4 — <\n•5 — <=\n•6 — begins with\n•7 — contains\n•8 — is null\n•9 — is not null\n•10 — does not contain\nValue\nOptional\nVALUE[string]Value to be evaluated\nExtracted   (at-\ntribute)\nOUTPUT[same as input]\nDefault:[Cre-\nate Temporary\nLayer]\nSpecify the output vector layer for matching\nfeatures. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\ncontinues on next page\n1210Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.173 – continued from previous page\nLabelNameTypeDescription\nExtracted  (non-\nmatching)\nFAIL_OUTPUT[same as input]\nDefault:[Skip\noutput]\nSpecify the output vector layer for non-\nmatching features. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtracted   (at-\ntribute)\nOUTPUT[same as input]Vector layer with matching features from\nthe input layer\nExtracted  (non-\nmatching)\nFAIL_OUTPUT[same as input]Vector layer with non-matching features\nfrom the input layer\nPython code\nAlgorithm ID:qgis:extractbyattribute\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract by expression\nCreates two vector layers from an input layer: one will contain only matching features while the second will contain\nall the non-matching features.\nThe criteria for adding features to the resulting layer is based on a QGIS expression. For more information about\nexpressions see the\nExpressions.\nSee also:\nSelect by expression\n25.1. QGIS algorithm provider1211\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nExpressionEXPRESSION[expression]Expression to filter the vector layer\nMatching featuresOUTPUT[same as input]\nDefault:[Cre-\nate Temporary\nLayer]\nSpecify the output vector layer for matching\nfeatures. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nNon-matchingFAIL_OUTPUT[same as input]\nDefault:[Skip\noutput]\nSpecify the output vector layer for non-\nmatching features. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nMatching featuresOUTPUT[same as input]Vector layer with matching features from\nthe input layer\nNon-matchingFAIL_OUTPUT[same as input]Vector layer with non-matching features\nfrom the input layer\nPython code\nAlgorithm ID:qgis:extractbyexpression\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract by location\nCreates a new vector layer that only contains matching features from an input layer.\nThe criteria for adding features to the resulting layer is based on the spatial relationship between each feature and the\nfeatures in an additional layer.\nSee also:\nSelect by location,Extract within distance\n1212Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExploring spatial relations\nGeometric predicates are boolean functions used to determine the spatial relation a feature has with another by\ncomparing whether and how their geometries share a portion of space.\nFig. 25.111: Looking for spatial relations between layers\nUsing the figure above, we are looking for the green circles by spatially comparing them to the orange rectangle\nfeature. Available geometric predicates are:\nIntersectTests whether a geometry intersects another. Returns 1 (true) if the geometries spatially intersect (share\nany portion of space - overlap or touch) and 0 if they don’t. In the picture above, this will return circles 1, 2\nand 3.\nContainReturns 1 (true) if and only if no points of b lie in the exterior of a, and at least one point of the interior of\nb lies in the interior of a. In the picture, no circle is returned, but the rectangle would be if you would look for\nit the other way around, as it contains circle 1 completely. This is the opposite ofare within.\nDisjointReturns 1 (true) if the geometries do not share any portion of space (no overlap, not touching). Only circle\n4 is returned.\nEqualReturns 1 (true) if and only if geometries are exactly the same. No circles will be returned.\nTouchTests whether a geometry touches another. Returns 1 (true) if the geometries have at least one point in\ncommon, but their interiors do not intersect. Only circle 3 is returned.\nOverlapTests whether a geometry overlaps another. Returns 1 (true) if the geometries share space, are of the same\ndimension, but are not completely contained by each other. Only circle 2 is returned.\nAre withinTests whether a geometry is within another. Returns 1 (true) if geometry a is completely inside geometry\nb. Only circle 1 is returned.\nCrossReturns 1 (true) if the supplied geometries have some, but not all, interior points in common and the actual\ncrossing is of a lower dimension than the highest supplied geometry. For example, a line crossing a polygon\nwill cross as a line (true). Two lines crossing will cross as a point (true). Two polygons cross as a polygon\n(false). In the picture, no circles will be returned.\n25.1. QGIS algorithm provider1213\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nExtract  features\nfrom\nINPUT[vector: any]Input vector layer\nWhere  the  fea-\ntures  (geometric\npredicate)\nPREDICATE[enumeration] [list]\nDefault: [0]\nSpatial condition for the selection. One or\nmore of:\n•0 — intersect\n•1 — contain\n•2 — disjoint\n•3 — equal\n•4 — touch\n•5 — overlap\n•6 — are within\n•7 — cross\nIf more than one condition is chosen, at\nleast one of them (OR operation) has to be\nmet for a feature to be extracted.\nBy comparing to\nthe features from\nINTERSECT[vector: any]Intersection vector layer\nExtracted  (loca-\ntion)\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the fea-\ntures that have the chosen spatial relation-\nship(s) with one or more features in the\ncomparison layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtracted  (loca-\ntion)\nOUTPUT[same as input]Vector layer with features from the input\nlayer that have the chosen spatial relation-\nship(s) with one or more features in the\ncomparison layer.\nPython code\nAlgorithm ID:qgis:extractbylocation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1214Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nExtract within distance\nNEW in 3.22\nCreates a new vector layer that only contains matching features from an input layer. Features are copied wherever\nthey are within the specified maximum distance from the features in an additional reference layer.\nSee also:\nSelect within distance,Extract by location\nParameters\nLabelNameTypeDescription\nExtract  features\nfrom\nINPUT[vector: any]Input vector layer to copy features from\nBy comparing to\nthe features from\nREFERENCE[vector: any]Vector layer whose features closeness is\nused\nWhere  the  fea-\ntures are within\nDISTANCE[number]\nDefault: 100\nThe maximum distance around reference\nfeatures to select input features within\nModifycurrentse-\nlection by\nMETHOD[enumeration]\nDefault: 0\nHow the selection of the algorithm should\nbe managed. One of:\n•0 — creating new selection\n•1 — adding to current selection\n•2 — selecting within current selec-\ntion\n•3 — removing from current selection\nExtracted  (loca-\ntion)\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the fea-\ntures that are within the set distance from\nreference features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExtracted  (loca-\ntion)\nOUTPUT[same as input]Vector layer with features from the input\nlayer matching the condition of distance\nfrom reference features\n25.1. QGIS algorithm provider1215\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:native:extractwithindistance\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom extract\nTakes a vector layer and generates a new one that contains only a subset of the features in the input layer.\nThe subset is defined randomly, based on feature IDs, using a percentage or count value to define the total number of\nfeatures in the subset.\nSee also:\nRandom selection\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Source vector layer to select the features\nfrom\nMethodMETHOD[enumeration]\nDefault: 0\nRandom selection methods. One of:\n•0 — Number of selected features\n•1 — Percentage of selected features\nNum-\nber/percentage\nof  selected  fea-\ntures\nNUMBER[number]\nDefault: 10\nNumber or percentage of features to select\nExtracted  (ran-\ndom)\nOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the ran-\ndomly selected features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n1216Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nExtracted  (ran-\ndom)\nOUTPUT[same as input]Vector layer containing randomly selected\nfeatures from the input layer\nPython code\nAlgorithm ID:qgis:randomextract\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom extract within subsets\nTakes a vector layer and generates a new one that contains only a subset of the features in the input layer.\nThe subset is defined randomly, based on feature IDs, using a percentage or count value to define the total number\nof features in the subset. The percentage/count value is not applied to the whole layer, but instead to each category.\nCategories are defined according to a given attribute.\nSee also:\nRandom selection within subsets\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer to select the features from\nID fieldFIELD[tablefield: any]Category of the source vector layer to select\nthe features from\nMethodMETHOD[enumeration]\nDefault: 0\nRandom selection method. One of:\n•0 — Number of selected features\n•1 — Percentage of selected features\nNum-\nber/percentage\nof  selected  fea-\ntures\nNUMBER[number]\nDefault: 10\nNumber or percentage of features to select\nExtracted  (ran-\ndom stratified)\nOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer for the ran-\ndomly selected features. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1217\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nExtracted  (ran-\ndom stratified)\nOUTPUT[same as input]Vector layer containing randomly selected\nfeatures from the input layer\nPython code\nAlgorithm ID:qgis:randomextractwithinsubsets\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom selection\nTakes a vector layer and selects a subset of its features. No new layer is generated by this algorithm.\nThe subset is defined randomly, based on feature IDs, using a percentage or count value to define the total number of\nfeatures in the subset.\nDefault menu:Vector►Research Tools\nSee also:\nRandom extract\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer for the selection\nMethodMETHOD[enumeration]\nDefault: 0\nRandom selection method. One of:\n•0 — Number of selected features\n•1 — Percentage of selected features\nNum-\nber/percentage\nof  selected  fea-\ntures\nNUMBER[number]\nDefault: 10\nNumber or percentage of features to select\nOutputs\nLabelNameTypeDescription\nInput layerINPUT[same as input]The input layer with features selected\n1218Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:randomselection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRandom selection within subsets\nTakes a vector layer and selects a subset of its features. No new layer is generated by this algorithm.\nThe subset is defined randomly, based on feature IDs, using a percentage or count value to define the total number of\nfeatures in the subset.\nThe percentage/count value is not applied to the whole layer, but instead to each category.\nCategories are defined according to a given attribute, which is also specified as an input parameter for the algorithm.\nNo new outputs are created.\nDefault menu:Vector►Research Tools\nSee also:\nRandom extract within subsets\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer to select features in\nID fieldFIELD[tablefield: any]Category of the input layer to select the fea-\ntures from\nMethodMETHOD[enumeration]\nDefault: 0\nRandom selection method. One of:\n•0 — Number of selected features\n•1 — Percentage of selected features\nNum-\nber/percentage\nof  selected  fea-\ntures\nNUMBER[number]\nDefault: 10\nNumber or percentage of features to select\nOutputs\nLabelNameTypeDescription\nInput layerINPUT[same as input]The input layer with features selected\n25.1. QGIS algorithm provider1219\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:randomselectionwithinsubsets\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSelect by attribute\nCreates a selection in a vector layer.\nThe criteria for selecting features is based on the values of an attribute from the input layer.\nSee also:\nExtract by attribute\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Vector layer to select features in\nSelection attributeFIELD[tablefield: any]Filtering field of the layer\nOperatorOPERATOR[enumeration]\nDefault: 0\nMany different operators are available:\n•0 — =\n•1 —̸=\n•2 — >\n•3 — >=\n•4 — <\n•5 — <=\n•6 — begins with\n•7 — contains\n•8 — is null\n•9 — is not null\n•10 — does not contain\nValue\nOptional\nVALUE[string]Value to be evaluated\nModifycurrentse-\nlection by\nMETHOD[enumeration]\nDefault: 0\nHow the selection of the algorithm should\nbe managed. One of:\n•0 — creating new selection\n•1 — adding to current selection\n•2 — removing from current selection\n•3 — selecting within current selec-\ntion\n1220Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nInput layerINPUT[same as input]The input layer with features selected\nPython code\nAlgorithm ID:qgis:selectbyattribute\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSelect by expression\nCreates a selection in a vector layer.\nThe criteria for selecting features is based on a QGIS expression. For more information about expressions see the\nExpressions.\nSee also:\nExtract by expression\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nExpressionEXPRESSION[expression]Expression to filter the input layer\nModifycurrentse-\nlection by\nMETHOD[enumeration]\nDefault: 0\nHow the selection of the algorithm should\nbe managed. One of:\n•0 — creating new selection\n•1 — adding to current selection\n•2 — removing from current selection\n•3 — selecting within current selec-\ntion\nOutputs\nLabelNameTypeDescription\nInput layerINPUT[same as input]The input layer with features selected\n25.1. QGIS algorithm provider1221\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:selectbyexpression\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSelect by location\nCreates a selection in a vector layer.\nThe criteria for selecting features is based on the spatial relationship between each feature and the features in an\nadditional layer.\nDefault menu:Vector►Research Tools\nSee also:\nExtract by location,Select within distance\nExploring spatial relations\nGeometric predicates are boolean functions used to determine the spatial relation a feature has with another by\ncomparing whether and how their geometries share a portion of space.\nFig. 25.112: Looking for spatial relations between layers\nUsing the figure above, we are looking for the green circles by spatially comparing them to the orange rectangle\nfeature. Available geometric predicates are:\n1222Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nIntersectTests whether a geometry intersects another. Returns 1 (true) if the geometries spatially intersect (share\nany portion of space - overlap or touch) and 0 if they don’t. In the picture above, this will return circles 1, 2\nand 3.\nContainReturns 1 (true) if and only if no points of b lie in the exterior of a, and at least one point of the interior of\nb lies in the interior of a. In the picture, no circle is returned, but the rectangle would be if you would look for\nit the other way around, as it contains circle 1 completely. This is the opposite ofare within.\nDisjointReturns 1 (true) if the geometries do not share any portion of space (no overlap, not touching). Only circle\n4 is returned.\nEqualReturns 1 (true) if and only if geometries are exactly the same. No circles will be returned.\nTouchTests whether a geometry touches another. Returns 1 (true) if the geometries have at least one point in\ncommon, but their interiors do not intersect. Only circle 3 is returned.\nOverlapTests whether a geometry overlaps another. Returns 1 (true) if the geometries share space, are of the same\ndimension, but are not completely contained by each other. Only circle 2 is returned.\nAre withinTests whether a geometry is within another. Returns 1 (true) if geometry a is completely inside geometry\nb. Only circle 1 is returned.\nCrossReturns 1 (true) if the supplied geometries have some, but not all, interior points in common and the actual\ncrossing is of a lower dimension than the highest supplied geometry. For example, a line crossing a polygon\nwill cross as a line (true). Two lines crossing will cross as a point (true). Two polygons cross as a polygon\n(false). In the picture, no circles will be returned.\nParameters\nLabelNameTypeDescription\nSelect   features\nfrom\nINPUT[vector: any]Input vector layer\nWhere  the  fea-\ntures  (geometric\npredicate)\nPREDICATE[enumeration] [list]\nDefault: [0]\nSpatial condition for the selection. One or\nmore of:\n•0 — intersect\n•1 — contain\n•2 — disjoint\n•3 — equal\n•4 — touch\n•5 — overlap\n•6 — are within\n•7 — cross\nIf more than one condition is chosen, at\nleast one of them (OR operation) has to be\nmet for a feature to be extracted.\nBy comparing to\nthe features from\nINTERSECT[vector: any]Intersection vector layer\nModifycurrentse-\nlection by\nMETHOD[enumeration]\nDefault: 0\nHow the selection of the algorithm should\nbe managed. One of:\n•0 — creating new selection\n•1 — adding to current selection\n•2 — selecting within current selec-\ntion\n•3 — removing from current selection\n25.1. QGIS algorithm provider1223\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nInput layerINPUT[same as input]The input layer with features selected\nPython code\nAlgorithm ID:qgis:selectbylocation\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSelect within distance\nNEW in 3.22\ncreates a selection in a vector layer. Features are selected wherever they are within the specified maximum distance\nfrom the features in an additional reference layer.\nSee also:\nExtract within distance,Select by location\nParameters\nLabelNameTypeDescription\nSelect   features\nfrom\nINPUT[vector: any]Input vector layer to select features from\nBy comparing to\nthe features from\nREFERENCE[vector: any]Vector layer whose features closeness is\nused\nWhere  the  fea-\ntures are within\nDISTANCE[number]\nDefault: 100\nThe maximum distance around reference\nfeatures to select input features\nModifycurrentse-\nlection by\nMETHOD[enumeration]\nDefault: 0\nHow the selection of the algorithm should\nbe managed. One of:\n•0 — creating new selection\n•1 — adding to current selection\n•2 — selecting within current selec-\ntion\n•3 — removing from current selection\n1224Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nInput layerINPUT[same as input]The input layer with features selected\nPython code\nAlgorithm ID:native:selectwithindistance\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.21Vector table\nAdd autoincremental field\nAdds a new integer field to a vector layer, with a sequential value for each feature.\nThis field can be used as a unique ID for features in the layer. The new attribute is not added to the input layer but a\nnew layer is generated instead.\nThe initial starting value for the incremental series can be specified. Optionally, the incremental series can be based\non grouping fields and a sort order for features can also be specified.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer.\nField nameFIELD_NAME[string]\nDefault: ‘AUTO’\nName of the field with autoincremental val-\nues\nStart values at\nOptional\nSTART[number]\nDefault: 0\nChoose the initial number of the incremen-\ntal count\nModulus   value\nNEW in 3.22\nOptional\nMODULUS[number]\nDefault: 0\nSpecifying an optional modulus value will\nrestart the count to START whenever the\nfield value reaches the modulus value.0\nmeans no restart.\nGroup values by\nOptional\nGROUP_FIELDS[tablefield:    any]\n[list]\nSelect grouping field(s): instead of a sin-\ngle count run for the whole layer, a separate\ncount is processed for each value returned\nby the combination of these fields.\nSort expression\nOptional\nSORT_EXPRESSION[expression]Use an expression to sort the features in the\nlayereithergloballyorifset, based ongroup\nfields.\nSort ascendingSORT_ASCENDING[boolean]\nDefault: True\nWhen asort expressionis set, use\nthis option to control the order in which fea-\ntures are assigned values.\nSort nulls firstSORT_NULLS_FIRST[boolean]\nDefault: False\nWhen asort expressionis set, use\nthis option to set whetherNullvalues are\ncounted first or last.\ncontinues on next page\n25.1. QGIS algorithm provider1225\n\nQGIS Desktop 3.22 User Guide\nTable 25.181 – continued from previous page\nLabelNameTypeDescription\nIncrementedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer with the auto\nincrement field. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nIncrementedOUTPUT[same as input]Vector layer with auto incremental field\nPython code\nAlgorithm ID:native:addautoincrementalfield\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nAdd field to attributes table\nAdds a new field to a vector layer.\nThe name and characteristics of the attribute are defined as parameters.\nThe new attribute is not added to the input layer but a new layer is generated instead.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer\nField nameFIELD_NAME[string]Name of the new field\nField typeFIELD_TYPE[enumeration]\nDefault: 0\nType of the new field. You can choose be-\ntween:\n•0 — Integer\n•1 — Float\n•2 — String\nField lengthFIELD_LENGTH[number]\nDefault: 10\nLength of the field\nField precisionFIELD_PRECISION[number]\nDefault: 0\nPrecision of the field. Useful with Float\nfield type.\ncontinues on next page\n1226Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.182 – continued from previous page\nLabelNameTypeDescription\nAddedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nAddedOUTPUT[same as input]Vector layer with new field added\nPython code\nAlgorithm ID:native:addfieldtoattributestable\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nAdd unique value index field\nTakes a vector layer and an attribute and adds a new numeric field.\nValues in this field correspond to values in the specified attribute, so features with the same value for the attribute\nwill have the same value in the new numeric field.\nThis creates a numeric equivalent of the specified attribute, which defines the same classes.\nThe new attribute is not added to the input layer but a new layer is generated instead.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer.\nClass fieldFIELD[tablefield: any]Features that have the same value for this\nfield will get the same index.\nOutput field nameFIELD_NAME[string]\nDefault:\n‘NUM_FIELD’\nName of the new field containing the in-\ndexes.\ncontinues on next page\n25.1. QGIS algorithm provider1227\n\nQGIS Desktop 3.22 User Guide\nTable 25.183 – continued from previous page\nLabelNameTypeDescription\nLayer with index\nfield\nOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nVector layer with the numeric field contain-\ning indexes. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nClass summarySUM-\nMARY_OUTPUT\n[table]\nDefault:[Skip\noutput]\nSpecify the table to contain the summary of\nthe class field mapped to the corresponding\nunique value. One of:\n•Skip Output\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nLayer with index\nfield\nOUTPUT[same as input]Vector layer with the numeric field contain-\ning indexes.\nClass summarySUM-\nMARY_OUTPUT\n[table]Table with summary of the class field\nmapped to the corresponding unique value.\nPython code\nAlgorithm ID:native:adduniquevalueindexfield\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nAdd X/Y fields to layer\nAdds X and Y (or latitude/longitude) fields to a point layer. The X/Y fields can be calculated in a different CRS to\nthe layer (e.g. creating latitude/longitude fields for a layer in a projected CRS).\n1228Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: point]The input layer.\nCoordinatesystemCRS[crs]\nDefault:\n“EPSG:4326”\nCoordinate reference system to use for the\ngenerated x and y fields.\nField prefix\nOptional\nPREFIX[string]Prefix to add to the new field names to avoid\nname collisions with fields in the input layer.\nAdded fieldsOUTPUT[vector: point]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nAdded fieldsOUTPUT[vector: point]Theoutputlayer-identicaltotheinputlayer\nbut with two new double fields,xandy.\nPython code\nAlgorithm ID:native:addxyfieldstolayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nAdvanced Python field calculator\nAdds a new attribute to a vector layer, with values resulting from applying an expression to each feature.\nThe expression is defined as a Python function.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nResult field nameFIELD_NAME[string]\nDefault: ‘NewField’\nName of the new field\ncontinues on next page\n25.1. QGIS algorithm provider1229\n\nQGIS Desktop 3.22 User Guide\nTable 25.185 – continued from previous page\nLabelNameTypeDescription\nField typeFIELD_TYPE[enumeration]\nDefault: 0\nType of the new field. One of:\n•0 — Integer\n•1 — Float\n•2 — String\nField lengthFIELD_LENGTH[number]\nDefault: 10\nLength of the field\nField precisionFIELD_PRECISION[number]\nDefault: 3\nPrecision of the field. Useful with Float\nfield type.\nGlobal expression\nOptional\nGLOBAL[string]The code in the global expression section\nwill be executed only once before the calcu-\nlator starts iterating through all the features\nof the input layer. Therefore, this is the cor-\nrect place to import necessary modules or to\ncalculate variables that will be used in sub-\nsequent calculations.\nFormulaFORMULA[string]The Python formula to evaluate. Example:\nTo calculate the area of an input polygon\nlayer you can add:\nvalue = $geom.area()\nCalculatedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the vector layer with the new calcu-\nlated field. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nCalculatedOUTPUT[same as input]Vector layer with the new calculated field\nPython code\nAlgorithm ID:qgis:advancedpythonfieldcalculator\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1230Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nDrop field(s)\nTakes a vector layer and generates a new one that has the same features but without the selected columns.\nSee also:\nRetain fields\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer to drop field(s) from\nFields to dropCOLUMN[tablefield:    any]\n[list]\nThe field(s) to drop\nRemaining fieldsOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer with the re-\nmaining fields. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRemaining fieldsOUTPUT[same as input]Vector layer with the remaining fields\nPython code\nAlgorithm ID:native:deletecolumn\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExplode HStore Field\nCreates a copy of the input layer and adds a new field for every unique key in the HStore field.\nThe expected field list is an optional comma separated list. If this list is specified, only these fields are added and the\nHStore field is updated. By default, all unique keys are added.\nThe PostgreSQLHStoreis a simple key-value store used in PostgreSQL and OGR (when reading anOSM filewith\ntheother_tagsfield.\n25.1. QGIS algorithm provider1231\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nHStore fieldFIELD[tablefield: any]The field(s) to drop\nExpected list of\nfields separated by\na comma\nOptional\nEX-\nPECTED_FIELDS\n[string]\nDefault: ‘’\nComma-separated list of fields to extract.\nThe HStore field will be updated by remov-\ning these keys.\nExplodedOUTPUT[same as input]\nDefault:[Cre-\nate temporary\nlayer]\nSpecify the output vector layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nExplodedOUTPUT[same as input]Output vector layer\nPython code\nAlgorithm ID:native:explodehstorefield\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract binary field\nExtracts contents from a binary field, saving them to individual files. Filenames can be generated using values taken\nfrom an attribute in the source table or based on a more complex expression.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Inputvectorlayercontainingthebinarydata\nBinary fieldFIELD[tablefield: any]Field containing the binary data\nFile nameFILENAME[expression]Field or expression-based text to name each\noutput file\nDestination folderFOLDER[folder]\nDefault:[Save\nto  temporary\nfolder]\nFolder in which to store the output files.\nOne of:\n•Save to a Temporary Directory\n•Save to Directory\n1232Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nFolderFOLDER[folder]The folder that contains the output files.\nPython code\nAlgorithm ID:native:extractbinary\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nField calculator\nOpens the field calculator (seeExpressions). You can use all the supported expressions and functions.\nA new layer is created with the result of the expression.\nThe field calculator is very useful when used in\nThe graphical modeler.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The layer to calculate on\nOutput field nameFIELD_NAME[string]The name of the field for the results\nOutput field typeFIELD_TYPE[enumeration]\nDefault: 0\nThe type of the field. One of:\n•0 — Float\n•1 — Integer\n•2 — String\n•3 — Date\nOutput field widthFIELD_LENGTH[number]\nDefault: 10\nThe length of the result field (minimum 0)\nField precisionFIELD_PRECISION[number]\nDefault: 3\nThe precision of the result field (minimum\n0, maximum 15)\nCreate new fieldNEW_FIELD[boolean]\nDefault: True\nShould the result field be a new field\nFormulaFORMULA[expression]The formula to use to calculate the result\nOutput fileOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output layer.\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n25.1. QGIS algorithm provider1233\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nCalculatedOUTPUT[vector: any]Output layer with the calculated field values\nPython code\nAlgorithm ID:native:fieldcalculator\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRefactor fields\nAllows editing the structure of the attribute table of a vector layer.\nFields can be modified in their type and name, using a fields mapping.\nThe original layer is not modified. A new layer is generated, which contains a modified attribute table, according to\nthe provided fields mapping.\nNote:When using a template layer withconstraintson fields, the information is displayed in the widget with a\ncoloured background and tooltip. Treat this information as a hint during configuration. No constraints will be added\non an output layer nor will they be checked or enforced by the algorithm.\nThe Refactor fields algorithm allows to:\n•Change field names and types\n•Add and remove fields\n•Reorder fields\n•Calculate new fields based on expressions\n•Load field list from another layer\n1234Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nFig. 25.113: Refactor fields dialog\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The layer to modify\ncontinues on next page\n25.1. QGIS algorithm provider1235\n\nQGIS Desktop 3.22 User Guide\nTable 25.188 – continued from previous page\nLabelNameTypeDescription\nFields mappingFIELDS_MAPPING[list]List of output fields with their definitions.\nThe embedded table lists all the fields of the\nsource layer and allows you to edit them:\n•Clickto create a new field.\n•Clickto remove a field.\n•Useandto change the se-\nlected field order.\n•Clickto reset to the default view.\nFor each of the fields you’d like to reuse,\nyou need to fill the following options:\nSource expression(expression) [expression]\nField or expression from the input\nlayer.\nField name(name) [string]Name of the\nfield in the output layer. By default\ninput field name is kept.\nType(type) [enumeration]Data type of\nthe output field. Available types de-\npend on the output layer provider.\nLength(length) [number]Length  of\nthe output field.\nPrecision(precision) [number]\nPrecision of the output field.\nConstraints(constraints) [string]\nWhen  using  a  template  layer,\nindicates whether there are con-\nstraints applied to the template field.\nHover over the cell to display the\nconstraints.\nLoad fields from template layerAllows\nto select a layer from the current\nproject as a template and (with\nLoad fields) fill the above “Fields\nmapping” options with its fields and\ntheir definitions.\nRefactoredOUTPUT[vector: any]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\n1236Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nRefactoredOUTPUT[vector: any]Output layer with refactored fields\nPython code\nAlgorithm ID:native:refactorfields\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRename field\nRenames an existing field from a vector layer.\nThe original layer is not modified. A new layer is generated where the attribute table contains the renamed field.\nSee also:\nRefactor fields\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nField to renameFIELD[tablefield: any]The field to be altered\nNew field nameNEW_NAME[string]The new field name\nRenamedOUTPUT[vector: same as in-\nput]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRenamedOUTPUT[vector: same as in-\nput]\nOutput layer with the renamed field\n25.1. QGIS algorithm provider1237\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:qgis:renametablefield\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRetain fields\nNEW in 3.18\nTakes a vector layer and generates a new one that retains only the selected fields. All other fields will be dropped.\nSee also:\nDrop field(s)\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nFields to retainFIELDS[tablefield:\nany][list]\nList of fields to keep in the layer\nRetained fieldsOUTPUT[vector: same as in-\nput]\nDefault:[Cre-\nate temporary\nlayer]\nSpecification of the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nRetained fieldsOUTPUT[vector: same as in-\nput]\nOutput layer with the retained fields\nPython code\nAlgorithm ID:native:retainfields\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1238Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nText to float\nModifies the type of a given attribute in a vector layer, converting a text attribute containing numeric strings into a\nnumeric attribute (e.g. ‘1’ to1.0).\nThe algorithm creates a new vector layer so the source one is not modified.\nIf the conversion is not possible the selected column will haveNULLvalues.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer.\nText attribute to\nconvert to float\nFIELD[tablefield: string]The string field for the input layer that is to\nbe converted to a float field.\nFloat from textOUTPUT[same as input]\nDefault:[Cre-\nate Temporary\nLayer]\nSpecify the output layer. One of:\n•CreateTemporaryLayer\n(TEMPORARY_OUTPUT)\n•Save to File...\n•Save to Geopackage...\n•Save to Database Table...\n•Append to Layer...\nThe file encoding can also be changed here.\nOutputs\nLabelNameTypeDescription\nFloat from textOUTPUT[same as input]Output vector layer with the string field con-\nverted into a float field\nPython code\nAlgorithm ID:qgis:texttofloat\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1.22Vector Tiles\nWrite vector tiles (MBTiles)\nExports one or more vector layers to vector tiles, a data format optimized for fast map rendering and small data size.\nMBTiles is a specification for storing tiled map data in SQLite databases for immediate usage and for transfer.\nMBTiles files are known as tilesets.\n25.1. QGIS algorithm provider1239\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layersINPUT[vector: any][list]A list of layers to combine to generate the\nvector tiles\nMinimum  zoom\nlevel\nMIN_ZOOM[number]\nDefault: 0\nThe lowest zoom level for which the tileset\nprovides data. Set between 0 and 24.\nMaximum  zoom\nlevel\nMAX_ZOOM[number]\nDefault: 3\nThe highest zoom level for which the tileset\nprovides data. Set between 0 and 24.\nExtent\nOptional\nEXTENT[extent]\nDefault: Not set\nThe maximum extent of the rendered map\narea. Bounds must define an area covered\nby all zoom levels.\nMetadata: Name\nOptional\nMETA_NAME[string]Name of the tileset\nMetadata:   De-\nscription\nOptional\nMETA_DESCRIPTION[string]A description of the tileset’s contents\nMetadata:  Attri-\nbution\nOptional\nMETA_ATTRIBUTION[string]An attribution string, which explains the\nsources of data and/or style for the map.\nMetadata:  Ver-\nsion\nOptional\nMETA_VERSION[string]The version of the tileset. This refers to\na revision of the tileset itself, not of the\nMBTiles specification.\nMetadata: Type\nOptional\nMETA_TYPE[string]Type of tileset. Possible values areover-\nlayorbaselayer.\nMetadata: Center\nOptional\nMETA_CENTER[string]The center (string of comma-separated\nnumbers: the longitude, latitude, and zoom\nlevel) of the default view of the map. Ex-\nample:-122.1906,37.7599,11\nDestination\nMBTiles\nOUTPUT[vector tiles]\nDefault:  [Save to\ntemporary file]\nSpecification of the output MBTiles file.\nOne of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nDestination\nMBTiles\nOUTPUT[file]Output vector tiles.mbtilesfile.\nPython code\nAlgorithm ID:native:writevectortiles_mbtiles\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1240Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nWrite vector tiles (XYZ)\nExports one or more vector layers to vector tiles, a data format optimized for fast map rendering and small data size.\nParameters\nLabelNameTypeDescription\nFile templateXYZ_TEMPLATE[string]\nDefault:\n‘{z}/{x}/{y}.pbf’\nTemplate to generate the vector tiles url\nInput layersINPUT[vector: any][list]A list of layers to combine to generate the\nvector tiles\nMinimum  zoom\nlevel\nMIN_ZOOM[number]\nDefault: 0\nThe lowest zoom level for which the tileset\nprovides data. Set between 0 and 24.\nMaximum  zoom\nlevel\nMAX_ZOOM[number]\nDefault: 3\nThe highest zoom level for which the tileset\nprovides data. Set between 0 and 24.\nExtent\nOptional\nEXTENT[extent]\nDefault: Not set\nThe maximum extent of the rendered map\narea. Bounds must define an area covered\nby all zoom levels.\nOutput directoryOUT-\nPUT_DIRECTORY\n[folder]\nDefault:  [Save to\ntemporary folder]\nSpecification of the output vector tiles\nfolder. One of:\n•Save to a Temporary Directory\n•Save to Directory\nOutputs\nLabelNameTypeDescription\nOutput directoryOUT-\nPUT_DIRECTORY\n[folder]A folder containing different subsets of the\nvector tiles files (.pbf) stored in subfolders\ncorresponding to the zoom levels.\nPython code\nAlgorithm ID:native:writevectortiles_xyz\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.1. QGIS algorithm provider1241\n\nQGIS Desktop 3.22 User Guide\n25.2GDAL algorithm provider\nGDAL(Geospatial Data Abstraction Library) is a translator library for raster and vector geospatial data formats.\nAlgorithms in the Processing Framework are derived from theGDAL raster programsandGDAL vector programs.\n25.2.1Raster analysis\nAspect\nGenerates an aspect map from any GDAL-supported elevation raster. Aspect is the compass direction that a slope\nfaces. The pixels will have a value from 0-360° measured in degrees from north indicating the azimuth. On the\nnorthern hemisphere, the north side of slopes is often shaded (small azimuth from 0°-90°), while the southern side\nreceives more solar radiation (higher azimuth from 180°-270°).\nThis algorithm is derived from theGDAL DEM utility.\nDefault menu:Raster►Analysis\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nThe number of the band to use as elevation\nReturn  trigono-\nmetricangle\ninstead  of  az-\nimuth\nTRIG_ANGLE[boolean]\nDefault: False\nActivating the trigonometric angle results in\ndifferent categories: 0° (East), 90° (North),\n180° (West), 270° (South).\nReturn 0 for flat\ninstead of -9999\nZERO_FLAT[boolean]\nDefault: False\nActivating this option will insert a 0-value\nfor the value -9999 on flat areas.\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\nUse   Zevenber-\ngen&Thorne\nformula instead of\nthe Horn’s one\nZEVENBERGEN[boolean]\nDefault: False\nActivates Zevenbergen&Thorne formula\nfor smooth landscapes\nAspectOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nOutput raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\ncontinues on next page\n1242Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.192 – continued from previous page\nLabelNameTypeDescription\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nAspectOUTPUT[raster]Output raster with angle values in degrees\nPython code\nAlgorithm ID:gdal:aspect\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nColor relief\nGenerates a color relief map from any GDAL-supported elevation raster. Color reliefs can particularly be used to\ndepict elevations. The Algorithm outputs a 4-band raster with values computed from the elevation and a text-based\ncolor configuration file. By default, the colors between the given elevation values are blended smoothly and the result\nis a nice colorized elevation raster.\nThis algorithm is derived from theGDAL DEM utility.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nThe number of the band to use as elevation\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\nColor  configura-\ntion file\nCOLOR_TABLE[file]A text-based color configuration file\nMatching modeMATCH_MODE[enumeration]\nDefault: 2\nOne of:\n•0 — Use strict color matching\n•1 — Use closest RGBA quadruples\n•2 — Use smoothly blended colours\ncontinues on next page\n25.2. GDAL algorithm provider1243\n\nQGIS Desktop 3.22 User Guide\nTable 25.193 – continued from previous page\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nColor reliefOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nOutput raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nColor reliefOUTPUT[raster]A 4-band output raster\nPython code\nAlgorithm ID:gdal:colorrelief\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nFill nodata\nFill raster regions with no data values by interpolation from edges. The values for the no-data regions are calculated by\nthe surrounding pixel values using inverse distance weighting. After the interpolation a smoothing of the results takes\nplace. Input can be any GDAL-supported raster layer. This algorithm is generally suitable for interpolating missing\nregions of fairly continuously varying rasters (such as elevation models for instance). It is also suitable for filling small\nholes and cracks in more irregularly varying images (like airphotos). It is generally not so great for interpolating a\nraster from sparse point data.\nThis algorithm is derived from the\nGDAL fillnodata utility.\nDefault menu:Raster►Analysis\n1244Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nBand numberBAND[raster band]\nDefault: 1\nTheband to operate on. Nodatavalues must\nbe represented by the value 0.\nMaximum   dis-\ntance (in pixels)\nto  search  out\nfor  values  to\ninterpolate\nDISTANCE[number]\nDefault: 10\nThe number of pixels to search in all direc-\ntions to find values to interpolate from\nNumberof\nsmoothing    it-\nerations  to  run\nafter the interpo-\nlation\nITERATIONS[number]\nDefault: 0\nThe number of 3x3 filter passes to run (0 or\nmore) to smoothen the results of the inter-\npolation.\nDo not use default\nvalidity mask for\nthe input band\nNO_MASK[boolean]\nDefault: False\nActivates the user-defined validity mask\nValidity maskMASK_LAYER[raster]A raster layer that defines the areas to fill.\nFilledOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\n25.2. GDAL algorithm provider1245\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nFilledOUTPUT[raster]Output raster\nPython code\nAlgorithm ID:gdal:fillnodata\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGrid (Data metrics)\nComputes some data metrics using the specified window and output grid geometry.\nThis algorithm is derived from the\nGDAL grid utility.\nDefault menu:Raster►Analysis\nSee also:\nGDAL grid tutorial\nParameters\nBasic parameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Input point vector layer\ncontinues on next page\n1246Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.196 – continued from previous page\nLabelNameTypeDescription\nData metric to useMETRIC[enumeration]\nDefault: 0\nOne of:\n•0 — Minimum, minimum value\nfound in grid node search ellipse\n•1 — Maximum, maximum value\nfound in grid node search ellipse\n•2 — Range, a difference between\nthe minimum and maximum values\nfound in grid node search ellipse\n•3 — Count, a number of data points\nfound in grid node search ellipse\n•4 — Average distance, an average\ndistance between the grid node (cen-\nter of the search ellipse) and all of the\ndata points found in grid node search\nellipse\n•5 — Average distance between\npoints, an average distance between\nthe data points found in grid node\nsearch ellipse. The distance between\neach pair of points within ellipse is\ncalculated and average of all dis-\ntances is set as a grid node value\nThe first radius of\nsearch ellipse\nRADIUS_1[number]\nDefault: 0.0\nThe first radius (X axis if rotation angle is\n0) of the search ellipse\nThe second radius\nof search ellipse\nRADIUS_2[number]\nDefault: 0.0\nThe second radius (Y axis if rotation angle\nis 0) of the search ellipse\nAngle of search\nellipse rotation in\ndegrees  (counter\nclockwise)\nANGLE[number]\nDefault: 0.0\nAngle of ellipse rotation in degrees. Ellipse\nrotated counter clockwise.\nMinimum  num-\nber of data points\nto use\nMIN_POINTS[number]\nDefault: 0.0\nMinimum number of data points to aver-\nage. If less amount of points found the grid\nnode considered empty and will be filled\nwith NODATA marker.\nNodataNODATA[number]\nDefault: 0.0\nNo data marker to fill empty points\nInterpolated (data\nmetrics)\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with interpo-\nlated values. One of:\n•Save to a Temporary File\n•Save to File...\ncontinues on next page\n25.2. GDAL algorithm provider1247\n\nQGIS Desktop 3.22 User Guide\nTable 25.197 – continued from previous page\nLabelNameTypeDescription\nAdvanced parameters\nLabelNameTypeDescription\nZ value from field\nOptional\nZ_FIELD[tablefield:nu-\nmeric]\nField for the interpolation\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nInterpolated (data\nmetrics)\nOUTPUT[raster]Output raster with interpolated values\nPython code\nAlgorithm ID:gdal:griddatametrics\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1248Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nGrid (IDW with nearest neighbor searching)\nComputes the Inverse Distance to a Power gridding combined to the nearest neighbor method. Ideal when a maximum\nnumber of data points to use is required.\nThis algorithm is derived from theGDAL grid utility.\nSee also:\nGDAL grid tutorial\nParameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Input point vector layer\nWeighting powerPOWER[number]\nDefault: 2.0\nWeighting power\nSmoothingSMOOTHING[number]\nDefault: 0.0\nSmoothing parameter\nThe radius of the\nsearch circle\nRADIUS[number]\nDefault: 1.0\nThe radius of the search circle\nMaximum  num-\nber of data points\nto use\nMAX_POINTS[number]\nDefault: 12\nDo not search for more points than this\nnumber.\nMinimum  num-\nber of data points\nto use\nMIN_POINTS[number]\nDefault: 0\nMinimum number of data points to aver-\nage. If less amount of points found the grid\nnode considered empty and will be filled\nwith NODATA marker.\nNodataNODATA[number]\nDefault: 0.0\nNo data marker to fill empty points\nInterpolated\n(IDW  with  NN\nsearch)\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with interpo-\nlated values. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nZ value from field\nOptional\nZ_FIELD[tablefield:nu-\nmeric]\nField for the interpolation\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\ncontinues on next page\n25.2. GDAL algorithm provider1249\n\nQGIS Desktop 3.22 User Guide\nTable 25.199 – continued from previous page\nLabelNameTypeDescription\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nInterpolated\n(IDW  with  NN\nsearch)\nOUTPUT[raster]Output raster with interpolated values\nPython code\nAlgorithm ID:gdal:gridinversedistancenearestneighbor\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGrid (Inverse distance to a power)\nThe Inverse Distance to a Power gridding method is a weighted average interpolator.\nYou should supply the input arrays with the scattered data values including coordinates of every data point and output\ngrid geometry. The function will compute interpolated value for the given position in output grid.\nThis algorithm is derived from the\nGDAL grid utility.\nDefault menu:Raster►Analysis\nSee also:\nGDAL grid tutorial\n1250Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Input point vector layer\nWeighting powerPOWER[number]\nDefault: 2.0\nWeighting power\nSmothingSMOOTHING[number]\nDefault: 0.0\nSmoothing parameter\nThe first radius of\nsearch ellipse\nRADIUS_1[number]\nDefault: 0.0\nThe first radius (X axis if rotation angle is\n0) of the search ellipse\nThe second radius\nof search ellipse\nRADIUS_2[number]\nDefault: 0.0\nThe second radius (Y axis if rotation angle\nis 0) of the search ellipse\nAngle of search\nellipse rotation in\ndegrees  (counter\nclockwise)\nANGLE[number]\nDefault: 0.0\nAngle of ellipse rotation in degrees. Ellipse\nrotated counter clockwise.\nMaximum  num-\nber of data points\nto use\nMAX_POINTS[number]\nDefault: 0\nDo not search for more points than this\nnumber.\nMinimum  num-\nber of data points\nto use\nMIN_POINTS[number]\nDefault: 0\nMinimum number of data points to aver-\nage. If less amount of points found the grid\nnode considered empty and will be filled\nwith NODATA marker.\nNodataNODATA[number]\nDefault: 0.0\nNo data marker to fill empty points\nInterpolated\n(IDW)\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with interpo-\nlated values. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nZ value from field\nOptional\nZ_FIELD[tablefield:nu-\nmeric]\nField for the interpolation\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\ncontinues on next page\n25.2. GDAL algorithm provider1251\n\nQGIS Desktop 3.22 User Guide\nTable 25.201 – continued from previous page\nLabelNameTypeDescription\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nInterpolated\n(IDW)\nOUTPUT[raster]Output raster with interpolated values\nPython code\nAlgorithm ID:gdal:gridinversedistance\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGrid (Linear)\nThe Linear method perform linear interpolation by computing a Delaunay triangulation of the point cloud, finding\nin which triangle of the triangulation the point is, and by doing linear interpolation from its barycentric coordinates\nwithin the triangle. If the point is not in any triangle, depending on the radius, the algorithm will use the value of the\nnearest point or the NODATA value.\nThis algorithm is derived from theGDAL grid utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Input point vector layer\ncontinues on next page\n1252Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.202 – continued from previous page\nLabelNameTypeDescription\nSearch distanceRADIUS[number]\nDefault: -1.0\nIn case the point to be interpolated does not\nfit into a triangle of the Delaunay triangula-\ntion, use that maximum distance to search a\nnearest neighbour, or use nodata otherwise.\nIf set to-1, the search distance is infinite.\nIf set to0, no data value will be used.\nNodataNODATA[number]\nDefault: 0.0\nNo data marker to fill empty points\nInterpolated (Lin-\near)\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with interpo-\nlated values. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nZ value from field\nOptional\nZ_FIELD[tablefield:nu-\nmeric]\nField for the interpolation\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\n25.2. GDAL algorithm provider1253\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nInterpolated (Lin-\near)\nOUTPUT[raster]Output raster with interpolated values\nPython code\nAlgorithm ID:gdal:gridlinear\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGrid (Moving average)\nThe Moving Average is a simple data averaging algorithm. It uses a moving window of elliptic form to search values\nand averages all data points within the window. Search ellipse can be rotated by specified angle, the center of ellipse\nlocated at the grid node. Also the minimum number of data points to average can be set, if there are not enough\npoints in window, the grid node considered empty and will be filled with specified NODATA value.\nThis algorithm is derived from the\nGDAL grid utility.\nDefault menu:Raster►Analysis\nSee also:\nGDAL grid tutorial\nParameters\nBasic parameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Input point vector layer\nThe first radius of\nsearch ellipse\nRADIUS_1[number]\nDefault: 0.0\nThe first radius (X axis if rotation angle is\n0) of the search ellipse\nThe second radius\nof search ellipse\nRADIUS_2[number]\nDefault: 0.0\nThe second radius (Y axis if rotation angle\nis 0) of the search ellipse\nAngle of search\nellipse rotation in\ndegrees  (counter\nclockwise)\nANGLE[number]\nDefault: 0.0\nAngle of ellipse rotation in degrees. Ellipse\nrotated counter clockwise.\nMinimum  num-\nber of data points\nto use\nMIN_POINTS[number]\nDefault: 0.0\nMinimum number of data points to aver-\nage. If less amount of points found the grid\nnode considered empty and will be filled\nwith NODATA marker.\nNodataNODATA[number]\nDefault: 0.0\nNo data marker to fill empty points\ncontinues on next page\n1254Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.204 – continued from previous page\nLabelNameTypeDescription\nInterpolated\n(moving average)\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nZ value from field\nOptional\nZ_FIELD[tablefield:nu-\nmeric]\nField for the interpolation\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nInterpolated\n(moving average)\nOUTPUT[raster]Output raster with interpolated values\n25.2. GDAL algorithm provider1255\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:gdal:gridaverage\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nGrid (Nearest neighbor)\nThe Nearest Neighbor method doesn’t perform any interpolation or smoothing, it just takes the value of nearest point\nfound in grid node search ellipse and returns it as a result. If there are no points found, the specified NODATA value\nwill be returned.\nThis algorithm is derived from theGDAL grid utility.\nDefault menu:Raster►Analysis\nSee also:\nGDAL grid tutorial\nParameters\nBasic parameters\nLabelNameTypeDescription\nPoint layerINPUT[vector: point]Input point vector layer\nThe first radius of\nsearch ellipse\nRADIUS_1[number]\nDefault: 0.0\nThe first radius (X axis if rotation angle is\n0) of the search ellipse\nThe second radius\nof search ellipse\nRADIUS_2[number]\nDefault: 0.0\nThe second radius (Y axis if rotation angle\nis 0) of the search ellipse\nAngle of search\nellipse rotation in\ndegrees  (counter\nclockwise)\nANGLE[number]\nDefault: 0.0\nAngle of ellipse rotation in degrees. Ellipse\nrotated counter clockwise.\nNodataNODATA[number]\nDefault: 0.0\nNo data marker to fill empty points\nInterpolated\n(Nearest   neigh-\nbour)\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with interpo-\nlated values. One of:\n•Save to a Temporary File\n•Save to File...\n1256Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nZ value from field\nOptional\nZ_FIELD[tablefield:nu-\nmeric]\nField for the interpolation\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nInterpolated\n(Nearest   neigh-\nbour)\nOUTPUT[raster]Output raster with interpolated values\nPython code\nAlgorithm ID:gdal:gridnearestneighbor\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1257\n\nQGIS Desktop 3.22 User Guide\nHillshade\nOutputs a raster with a nice shaded relief effect. It’s very useful for visualizing the terrain. You can optionally specify\nthe azimuth and altitude of the light source, a vertical exaggeration factor and a scaling factor to account for differences\nbetween vertical and horizontal units.\nThis algorithm is derived from theGDAL DEM utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input Elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nBand containing the elevation information\nZ factor (vertical\nexaggeration)\nZ_FACTOR[number]\nDefault: 1.0\nThe factor exaggerates the height of the out-\nput elevation raster\nScale  (ratio  of\nvert.   units to\nhoriz.)\nSCALE[number]\nDefault: 1.0\nThe ratio of vertical units to horizontal units\nAzimuth of the\nlight\nAZIMUTH[number]\nDefault: 315.0\nDefines the azimuth of the light shining on\nthe elevation raster in degrees. If it comes\nfrom the top of the raster the value is 0, if\nit comes from the east it is 90 a.s.o.\nAltitude  of  the\nlight\nALTITUDE[number]\nDefault: 45.0\nDefines the altitude of the light, in degrees.\n90 if the light comes from above the eleva-\ntion raster, 0 if it is raking light.\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\nUse   Zevenber-\ngen&Thorne\nformula  (instead\nof the Horn’s one)\nZEVENBERGEN[boolean]\nDefault: False\nActivates Zevenbergen&Thorne formula\nfor smooth landscapes\nCombined  shad-\ning\nCOMBINED[boolean]\nDefault: False\nMultidirectional\nshading\nMULTIDIREC-\nTIONAL\n[boolean]\nDefault: False\nHillshadeOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer with interpo-\nlated values. One of:\n•Save to a Temporary File\n•Save to File...\n1258Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nHillshadeOUTPUT[raster]Output raster with interpolated values\nPython code\nAlgorithm ID:gdal:hillshade\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nNear black\nConverts nearly black/white borders to black.\nThis algorithm will scan an image and try to set all pixels that are nearly or exactly black, white or one or more custom\ncolors around the collar to black or white. This is often used to “fix up” lossy compressed airphotos so that color\npixels can be treated as transparent when mosaicking.\nThis algorithm is derived from theGDAL nearblack utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input Elevation raster layer\ncontinues on next page\n25.2. GDAL algorithm provider1259\n\nQGIS Desktop 3.22 User Guide\nTable 25.210 – continued from previous page\nLabelNameTypeDescription\nHow  far  from\nblack (white)\nNEAR[number]\nDefault: 15\nSelect how far from black, white or custom\ncolors the pixel values can be and still con-\nsidered near black, white or custom color.\nSearch for nearly\nwhite pixels in-\nstead  of  nearly\nblack\nWHITE[boolean]\nDefault: False\nSearch for nearly white (255) pixels instead\nof nearly black pixels\nNearblackOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nNearblackOUTPUT[raster]Output raster\nPython code\nAlgorithm ID:gdal:nearblack\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1260Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nProximity (raster distance)\nGenerates a raster proximity map indicating the distance from the center of each pixel to the center of the nearest\npixel identified as a target pixel. Target pixels are those in the source raster for which the raster pixel value is in the\nset of target pixel values.\nThis algorithm is derived from theGDAL proximity utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input Elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nBand containing the elevation information\nA list of pixel val-\nues in the source\nimage to be con-\nsidered target pix-\nels\nOptional\nVALUES[string]\nDefault: ‘’\nA list of target pixel values in the source im-\nage to be considered target pixels. If not\nspecified, all non-zero pixels will be consid-\nered target pixels.\nDistance unitsUNITS[enumeration]\nDefault: 1\nIndicate  whether  distances  generated\nshould  be  in  pixel  or  georeferenced\ncoordinates. One of:\n•0 — Georeferenced coordinates\n•1 — Pixel coordinates\nThe   maximum\ndistance  to  be\ngenerated\nOptional\nMAX_DISTANCE[number]\nDefault: 0.0\nThe maximum distance to be generated.\nThe nodata value will be used for pixels be-\nyond this distance. If a nodata value is not\nprovided, the output band will be queried\nfor its nodata value.  If the output band\ndoes not have a nodata value, then the value\n65535 will be used. Distance is interpreted\naccording to the value ofDistance units.\nValue to be ap-\nplied to all pixels\nthat are within the\nmaxdist of target\npixels\nOptional\nREPLACE[number]\nDefault: 0.0\nSpecify a value to be applied to all pixels\nthat are closer than the maximum distance\nfrom target pixels (including the target pix-\nels) instead of a distance value.\nNodata value to\nuse for the desti-\nnation proximity\nraster\nOptional\nNODATA[number]\nDefault: 0.0\nSpecify the nodata value to use for the out-\nput raster\nProximity mapOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\n25.2. GDAL algorithm provider1261\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the data type of the output raster\nfile. Options:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nOutputs\nLabelNameTypeDescription\nProximity mapOUTPUT[raster]Output raster\nPython code\nAlgorithm ID:gdal:proximity\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1262Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nRoughness\nOutputs a single-band raster with values computed from the elevation. Roughness is the degree of irregularity of the\nsurface. It’s calculated by the largest inter-cell difference of a central pixel and its surrounding cell. The determination\nof the roughness plays a role in the analysis of terrain elevation data, it’s useful for calculations of the river morphology,\nin climatology and physical geography in general.\nThis algorithm is derived from theGDAL DEM utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nThe number of the band to use as elevation\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\nRoughnessOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutputs\nLabelNameTypeDescription\nRoughnessOUTPUT[raster]Single-band output roughness raster. The\nvalue -9999 is used as nodata value.\n25.2. GDAL algorithm provider1263\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:gdal:roughness\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSieve\nRemoves raster polygons smaller than a provided threshold size (in pixels) and replaces them with the pixel value of\nthe largest neighbour polygon. It is useful if you have a large amount of small areas on your raster map.\nThis algorithm is derived from theGDAL sieve utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nThresholdTHRESHOLD[number]\nDefault: 10\nOnly raster polygons smaller than this size\nwill be removed\nUse8-\nconnectedness\nEIGHT_CONNECTEDNESS[boolean]\nDefault: False\nUse eight connectedness instead of four\nconnectedness\nDo not use the de-\nfault validity mask\nfor the input band\nNO_MASK[boolean]\nDefault: False\nValidity mask\nOptional\nMASK_LAYER[raster]Validity mask to use instead of the default\nSievedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\n1264Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nSievedOUTPUT[raster]Output raster layer.\nPython code\nAlgorithm ID:gdal:sieve\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nSlope\nGenerates a slope map from any GDAL-supported elevation raster. Slope is the angle of inclination to the horizontal.\nYou have the option of specifying the type of slope value you want: degrees or percent slope.\nThis algorithm is derived from theGDAL DEM utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input Elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nBand containing the elevation information\nRatio of vertical\nunits to horizontal\nSCALE[number]\nDefault: 1.0\nThe ratio of vertical units to horizontal units\nSlope expressed as\npercent (instead of\ndegrees)\nAS_PERCENT[boolean]\nDefault: False\nExpress slope as percent instead of degrees\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\nUse   Zevenber-\ngen&Thorne\nformula  (instead\nof the Horn’s one)\nZEVENBERGEN[boolean]\nDefault: False\nActivates Zevenbergen&Thorne formula\nfor smooth landscapes\nSlopeOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\n25.2. GDAL algorithm provider1265\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nSlopeOUTPUT[raster]Output raster\nPython code\nAlgorithm ID:gdal:slope\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTerrain Ruggedness Index (TRI)\nOutputs a single-band raster with values computed from the elevation. TRI stands for Terrain Ruggedness Index,\nwhich is defined as the mean difference between a central pixel and its surrounding cells.\nThis algorithm is derived from theGDAL DEM utility.\nDefault menu:Raster►Analysis\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nThe number of the band to use as elevation\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\ncontinues on next page\n1266Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.220 – continued from previous page\nLabelNameTypeDescription\nTerrain  Rugged-\nness Index\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutputs\nLabelNameTypeDescription\nTerrain  Rugged-\nness Index\nOUTPUT[raster]Output ruggedness raster. The value -9999\nis used as nodata value.\nPython code\nAlgorithm ID:gdal:triterrainruggednessindex\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTopographic Position Index (TPI)\nOutputs a single-band raster with values computed from the elevation. TPI stands for Topographic Position Index,\nwhich is defined as the difference between a central pixel and the mean of its surrounding cells.\nThis algorithm is derived from theGDAL DEM utility.\nDefault menu:Raster►Analysis\n25.2. GDAL algorithm provider1267\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nThe number of the band to use for elevation\nvalues\nCompute edgesCOMPUTE_EDGES[boolean]\nDefault: False\nGenerates edges from the elevation raster\nTerrain  Rugged-\nness Index\nOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output raster layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutputs\nLabelNameTypeDescription\nTerrain  Rugged-\nness Index\nOUTPUT[raster]Output raster.\nPython code\nAlgorithm ID:gdal:tpitopographicpositionindex\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1268Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\n25.2.2Raster conversion\ngdal2xyz\nConverts raster data to XYZ ASCII file format.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Raster layer to convert\nBand numberBAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose the band\nyou want to convert\nOutput  comma-\nseparated values\nCSV[boolean]\nDefault: False\nSets whether the output file should be of\ntype comma-separated values (csv).\nXYZ ASCII fileOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nXYZ ASCII fileINPUT[table]Table file containing the values exported\nfrom the raster band.\nPython code\nAlgorithm ID:gdal:gdal2xyz\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPCT to RGB\nConverts an 8 bit paletted image to a 24 bit RGB. It will convert a pseudocolor band from the input file to an RGB\nfile of the desired format.\nThis algorithm is derived from theGDAL pct2rgb utility.\nDefault menu:Raster►Conversion\n25.2. GDAL algorithm provider1269\n\nQGIS Desktop 3.22 User Guide\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input 8 bit raster image\nBand numberBAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose the band\nyou want to convert\nGenerate a RGBA\nfile\nRGBA[boolean]\nDefault: False\nSets whether the output file should be of\ntype RGBA.\nPCT to RGBOUTPUT[file]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output file. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nPCT to RGBOUTPUT[raster]24 bit RGB raster image\nPython code\nAlgorithm ID:gdal:pcttorgb\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPolygonize (raster to vector)\nCreates vector polygons for all connected regions of pixels in the raster sharing a common pixel value. Each polygon\nis created with an attribute indicating the pixel value of that polygon.\nThis algorithm is derived from the\nGDAL polygonize utility.\nDefault menu:Raster►Conversion\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nBand numberBAND[raster band]\nDefault:  The first\nband of the input\nlayer\nIf the raster is multiband, choose the band\nyou want to use\ncontinues on next page\n1270Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.226 – continued from previous page\nLabelNameTypeDescription\nName of the field\nto create\nFIELD[string]\nDefault: ‘DN’\nSpecify the field name for the attributes of\nthe connected regions.\nUse8-\nconnectedness\nEIGHT_CONNECTEDNESS[boolean]\nDefault: False\nIf not set, raster cells must have a com-\nmon border to be considered connected (4-\nconnected). If set, touching raster cells are\nalso considered connected (8-connected).\nVectorizedOUTPUT[vector: polygon]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output (polygon) vector\nlayer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nVectorizedOUTPUT[vector: polygon]Output vector layer\nPython code\nAlgorithm ID:gdal:polygonize\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRearrange bands\nCreates a new raster using selected band(s) from a given raster layer. The algorithm also makes it possible to reorder\nthe bands for the newly-created raster.\nThis algorithm is derived from theGDAL translate utility.\n25.2. GDAL algorithm provider1271\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nSelected band(s)BANDS[raster band] [list]\nDefault: None\nOrdered list of the bands to use to create the\nnew raster\nConvertedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutput data typeDATA_TYPE[enumeration]\nDefault: 0\nDefines the data type of the output raster\nfile. Options:\n•0 — Use Input Layer Data Type\n•1 — Byte\n•2 — Int16\n•3 — UInt16\n•4 — UInt32\n•5 — Int32\n•6 — Float32\n•7 — Float64\n•8 — CInt16\n•9 — CInt32\n•10 — CFloat32\n•11 — CFloat64\n1272Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nConvertedOUTPUT[raster]Output raster layer with rearranged bands.\nPython code\nAlgorithm ID:gdal:rearrange_bands\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRGB to PCT\nConverts a 24 bit RGB image into a 8 bit paletted. Computes an optimal pseudo-color table for the given RGB-image\nusing a median cut algorithm on a downsampled RGB histogram. Then it converts the image into a pseudo-colored\nimage using the color table. This conversion utilizes Floyd-Steinberg dithering (error diffusion) to maximize output\nimage visual quality.\nIf you want to classify a raster map and want to reduce the number of classes it can be helpful to downsample your\nimage with this algorithm before.\nThis algorithm is derived from the\nGDAL rgb2pct utility.\nDefault menu:Raster►Conversion\nParameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input (RGB) raster layer\nNumber of colorsNCOLORS[number]\nDefault: 2\nThe number of colors the resulting image\nwill contain. A value from 2-256 is possi-\nble.\nRGB to PCTOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster. One of:\n•Save to a Temporary File\n•Save to File...\n25.2. GDAL algorithm provider1273\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nRGB to PCTOUTPUT[raster]Output raster layer.\nPython code\nAlgorithm ID:gdal:rgbtopct\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nTranslate (convert format)\nConverts raster data between different formats.\nThis algorithm is derived from the\nGDAL translate utility.\nDefault menu:Raster►Conversion\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nOverride the pro-\njection of the out-\nput file\nOptional\nTARGET_CRS[crs]Specify a projection for the output file\nAssign a specified\nnodata value to\noutput bands\nOptional\nNODATA[number]\nDefault: Not set\nDefines the value to use for nodata in the\noutput raster\nCopy  all  sub-\ndatasets of this\nfile to individual\noutput files\nCOPY_SUBDATASETS[boolean]\nDefault: False\nCreate individual files for subdatasets\nConvertedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output (translated)\nraster layer. One of:\n•Save to a Temporary File\n•Save to File...\n1274Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 0\nDefines the data type of the output raster\nfile. Options:\n•0 — Use Input Layer Data Type\n•1 — Byte\n•2 — Int16\n•3 — UInt16\n•4 — UInt32\n•5 — Int32\n•6 — Float32\n•7 — Float64\n•8 — CInt16\n•9 — CInt32\n•10 — CFloat32\n•11 — CFloat64\nOutputs\nLabelNameTypeDescription\nConvertedOUTPUT[raster]Output (translated) raster layer.\nPython code\nAlgorithm ID:gdal:translate\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1275\n\nQGIS Desktop 3.22 User Guide\n25.2.3Raster extraction\nClip raster by extent\nClips any GDAL-supported raster file to a given extent.\nThis algorithm is derived from theGDAL translate utility.\nDefault menu:Raster►Extraction\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]The input raster\nClipping extentEXTENT[extent]Extent that should be used for the output\nraster.  Only pixels within the specified\nbounding box will be included in the out-\nput.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nOverride the pro-\njection for the out-\nput fileNEW  in\n3.18\nOVERCRS[boolean]\nDefault: False\nIf checked, the output file is assigned the\ninput layer CRS.\nAssign a specified\nnodata value to\noutput bands\nOptional\nNODATA[number]\nDefault: None\nDefines a value that should be inserted for\nthe nodata values in the output raster\nClipped (extent)OUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\n1276Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutput data typeDATA_TYPE[enumeration]\nDefault: 0\nDefines the format of the output raster file.\nOptions:\n•0 — Use Input Layer Data Type\n•1 — Byte\n•2 — Int16\n•3 — UInt16\n•4 — UInt32\n•5 — Int32\n•6 — Float32\n•7 — Float64\n•8 — CInt16\n•9 — CInt32\n•10 — CFloat32\n•11 — CFloat64\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nClipped (extent)OUTPUT[raster]Output raster layer clipped by the given ex-\ntent\nPython code\nAlgorithm ID:gdal:cliprasterbyextent\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1277\n\nQGIS Desktop 3.22 User Guide\nClip raster by mask layer\nClips any GDAL-supported raster by a vector mask layer.\nThis algorithm is derived from theGDAL warp utility.\nDefault menu:Raster►Extraction\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]The input raster\nMask layerMASK[vector: polygon]Vector mask for clipping the\nraster\nSource CRSSOURCE_CRS[crs]Set the coordinate reference to\nuse for the input raster\nTarget CRSTARGET_CRS[crs]Set the coordinate reference to\nuse for the mask layer\nAssign a specified nodata\nvalue to output bands\nOptional\nNODATA[number]\nDefault: None\nDefines a value that should be\ninserted for the nodata values in\nthe output raster\nCreate an output alpha bandALPHA_BAND[boolean]\nDefault: False\nCreates an alpha band for the\nresult. The alpha band then in-\ncludes the transparency values\nof the pixels.\nMatch the extent of the\nclipped raster to the extent of\nthe mask layer\nCROP_TO_CUTLINE[boolean]\nDefault: True\nApplies the vector layer extent\nto the output raster if checked.\nKeep resolution of input\nraster\nKEEP_RESOLUTION[boolean]\nDefault: False\nThe resolution of the output\nraster will not be changed\nSet output file resolutionSET_RESOLUTION[boolean]\nDefault: False\nShall the output resolution (cell\nsize) be specified\nX Resolution to output bands\nOptional\nX_RESOLUTION[number]\nDefault: None\nThe width of the cells in the out-\nput raster\nY Resolution to output band\nOptional\nY_RESOLUTION[number]\nDefault: None\nThe height of the cells in the\noutput raster\nUse multithreaded warping\nimplementation\nMULTITHREAD-\nING\n[boolean]\nDefault: False\nTwo threads will be used to pro-\ncess chunks of image and per-\nform input/output operation si-\nmultaneously. Note that com-\nputation is not multithreaded it-\nself.\nClipped (mask)OUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification  of  the  output\nraster layer. One of:\n•Save to a Temporary File\n•Save to File...\n1278Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutput data typeDATA_TYPE[enumeration]\nDefault: 0\nDefines the format of the output raster file.\nOptions:\n•0 — Use Input Layer Data Type\n•1 — Byte\n•2 — Int16\n•3 — UInt16\n•4 — UInt32\n•5 — Int32\n•6 — Float32\n•7 — Float64\n•8 — CInt16\n•9 — CInt32\n•10 — CFloat32\n•11 — CFloat64\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nClipped (mask)OUTPUT[raster]Output raster layer clipped by the vector\nlayer\nPython code\nAlgorithm ID:gdal:cliprasterbymasklayer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1279\n\nQGIS Desktop 3.22 User Guide\nContour\nExtracts contour lines from any GDAL-supported elevation raster.\nThis algorithm is derived from theGDAL contour utility.\nDefault menu:Raster►Extraction\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster\nBand numberBAND[raster band]\nDefault: 1\nRaster band to create the contours from\nInterval  between\ncontour lines\nINTERVAL[number]\nDefault: 10.0\nDefines the interval between the contour\nlines in the given units of the elevation\nraster (minimum value 0)\nAttribute name (if\nnot set, no eleva-\ntionattributeisat-\ntached)\nOptional\nFIELD_NAME[string]\nDefault: ‘ELEV’\nProvides a name for the attribute in which\nto put the elevation.\nOffset from zero\nrelativetowhichto\ninterpret intervals\nOptional\nOFFSET[number]\nDefault: 0.0\nContoursOUTPUT[vector: line]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output vector layer.\nOne of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nProduce 3D vectorCREATE_3D[boolean]\nDefault: False\nForces production of 3D vectors instead of\n2D. Includes elevation at every vertex.\nTreat  all  raster\nvalues as valid\nIGNORE_NODATA[boolean]\nDefault: False\nIgnores any nodata values in the dataset.\nInput pixel value\nto treat as “no-\ndata”\nOptional\nNODATA[number]\nDefault: None\nDefines a value that should be inserted for\nthe nodata values in the output raster\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options.\nRefer to the corresponding GDAL utility\ndocumentation.\n1280Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nContoursOUTPUT[vector: line]Output vector layer with contour lines\nPython code\nAlgorithm ID:gdal:contour\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nContour Polygons\nExtracts contour polygons from any GDAL-supported elevation raster.\nThis algorithm is derived from the\nGDAL contour utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster\nBand numberBAND[raster band]\nDefault: 1\nRaster band to create the contours from\nInterval  between\ncontour lines\nINTERVAL[number]\nDefault: 10.0\nDefines the interval between the contour\nlines in the given units of the elevation\nraster (minimum value 0)\nOffset from zero\nrelativetowhichto\ninterpret intervals\nOptional\nOFFSET[number]\nDefault: 0.0\nAttribute  name\nfor minimum ele-\nvation of contour\npolygon\nOptional\nFIELD_NAME_MIN[string]\nDefault:\n‘ELEV_MIN’\nProvides a name for the attribute in which to\nput the minimum elevation of contour poly-\ngon. If not provided no minimum elevation\nattribute is attached.\nAttribute  name\nfor maximum ele-\nvation of contour\npolygon\nOptional\nFIELD_NAME_MAX[string]\nDefault:\n‘ELEV_MAX’\nProvides a name for the attribute in which\nto put the maximum elevation of contour\npolygon. If not provided no maximum ele-\nvation attribute is attached.\nContoursOUTPUT[vector: polygon]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output vector layer.\nOne of:\n•Save to a Temporary File\n•Save to File...\n25.2. GDAL algorithm provider1281\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nProduce 3D vectorCREATE_3D[boolean]\nDefault: False\nForces production of 3D vectors instead of\n2D. Includes elevation at every vertex.\nTreat  all  raster\nvalues as valid\nIGNORE_NODATA[boolean]\nDefault: False\nIgnores any nodata values in the dataset.\nInput pixel value\nto treat as “no-\ndata”\nOptional\nNODATA[number]\nDefault: None\nDefines a value that should be inserted for\nthe nodata values in the output raster\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options.\nRefer to the corresponding GDAL utility\ndocumentation.\nOutputs\nLabelNameTypeDescription\nContoursOUTPUT[vector: polygon]Output vector layer with contour polygons\nPython code\nAlgorithm ID:gdal:contour_polygon\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2.4Raster miscellaneous\nBuild overviews (pyramids)\nTo speed up rendering time of raster layers overviews (pyramids) can be created. Overviews are lower resolution\ncopies of the data which QGIS uses depending of the level of zoom.\nThis algorithm is derived from theGDAL addo utility.\nDefault menu:Raster►Miscellaneous\n1282Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nRemove all exist-\ning overviews\nCLEAN[boolean]\nDefault: False\nRemoves existing overviews from the\nraster. By default these are not removed.\nAdvanced parameters\nLabelNameTypeDescription\nOverview levelsLEVELS[string]\nDefault: ‘2 4 8 16’\nDefines the number of overview levels cal-\nculated by the original resolution of the in-\nput raster layer. By default 4 levels will be\ntaken into consideration.\nResampling\nmethod\nOptional\nRESAMPLING[enumeration]\nDefault: 0\nCalculates the overviews with a defined\nresampling method.  Possible resampling\nmethods are:\n•0 – Nearest Neighbour (nearest)\n•1 – Average (average)\n•2 – Gaussian (gauss)\n•3 – Cubic Convolution (cubic)\n•4   –   B-Spline   Convolution\n(cubicspline)\n•5  –  Lanczos  Windowed  Sinc\n(lanczos)\n•6 – Average MP (average_mp)\n•7 – Average in Mag/Phase Space\n(average_magphase)\n•8 – Mode (mode)\nOverviews format\nOptional\nFORMAT[enumeration]\nDefault: 0\nThe overviews can be stored internally, or\nexternally as GTiff or ERDAS Imagine file.\nBy default the overviews are stored in the\noutput raster.  Possible formats methods\nare:\n•0 – Internal (if possible)\n•1 – External (GTiff .ovr)\n•2 – External (ERDAS Imagine .aux)\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\n25.2. GDAL algorithm provider1283\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nPyramidizedOUTPUT[raster]Output raster layer with overviews\nPython code\nAlgorithm ID:gdal:overviews\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nBuild virtual raster\nBuilds a VRT (Virtual Dataset) that is a mosaic of the list of input GDAL-supported rasters. With a mosaic you can\nmerge several raster files.\nThis algorithm is derived from theGDAL buildvrt utility.\nDefault menu:Raster►Miscellaneous\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]GDAL-supported raster layers.\nResolutionRESOLUTION[enumeration]\nDefault: 0\nThe output resolution of the mosaic. By de-\nfault the average resolution of the raster files\nwill be chosen.\nOptions:\n•0 — Average (average)\n•1 — Highest (highest)\n•2 — Lowest (lowest)\nPlace each input\nfile into a separate\nband\nSEPARATE[boolean]\nDefault: False\nWith ‘True’ you can define that each raster\nfile goes into a separated stacked band in the\nVRT band.\nAllow  projection\ndifference\nPROJ_DIFFERENCE[boolean]\nDefault: False\nAllows that the output bands have different\nprojections derived from the projection of\nthe input raster layers.\nVirtualOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\n1284Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdd alpha mask\nbandtoVRTwhen\nsource raster has\nnone\nADD_ALPHA[boolean]\nDefault: False\nAdds an alpha mask band to the VRT when\nthe source raster has none.\nOverride  projec-\ntion for the output\nfile\nOptional\nASSIGN_CRS[crs]\nDefault: None\nOverrides the projection for the output file.\nNo reprojection is done.\nResampling algo-\nrithm\nRESAMPLING[enumeration]\nDefault: 0\nThe resampling algorithm to be used Op-\ntions:\n•0 — Nearest Neighbour (nearest)\n•1 — Bilinear (bilinear)\n•2 — Cubic Convolution (cubic)\n•3   —   B-Spline   Convolution\n(cubicspline)\n•4  —  Lanczos  Windowed  Sinc\n(lanczos)\n•5 — Average (average)\n•6 — Mode (mode)\nNodata  value(s)\nfor input bands\n(space separated)\nOptional\nSRC_NODATA[string]\nDefault: None\nSpace separated Nodata value(s) for input\nband(s)\nAdditional\ncommand-line\nparameters\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nVirtualOUTPUT[raster]Output raster layer\nPython code\nAlgorithm ID:gdal:buildvirtualraster\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1285\n\nQGIS Desktop 3.22 User Guide\ngdal2tiles\nGenerates a directory with small tiles and metadata, following theOSGeo Tile Map Service Specification. See also\ntheOpenGIS Web Map Tile Service Implementation Standard. Simple web pages with viewers based on Google\nMaps, OpenLayers and Leaflet are generated as well. To explore your maps on-line in the web browser, you only\nneed to upload the generated directory onto a web server.\nThis algorithm also creates the necessary metadata for Google Earth (KML SuperOverlay), in case the supplied map\nusesEPSG:4326projection.\nESRI world files and embedded georeferencing is used during tile generation, but you can publish a picture without\nproper georeferencing too.\nThis algorithm is derived from theGDAL gdal2tiles utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]GDAL-supported raster layer.\nTile cutting profilePROFILE[enumeration]\nDefault: 0\nOne of:\n•0 — Mercator (mercator)\n•1 — Geodetic (geodetic)\n•2 — Raster (raster)\nZoomlevelstoren-\nder\nOptional\nZOOM[string]\nDefault: ‘’\nWebviewertogen-\nerate\nVIEWER[enumerate]\nDefault: 0\nOne of:\n•0 — All (all)\n•1 — GoogleMaps (google)\n•2 — OpenLayers (openlayers)\n•3 — Leaflet (leaflet)\n•4 — None (none)\nTitle of the map\nOptional\nTITLE[string]\nDefault: ‘’\nCopyright of the\nmap\nCOPYRIGHT[string]\nDefault: ‘’\nOutput directoryOUTPUT[folder]\nDefault:[Save\nto  temporary\nfolder]\nSpecify the output folder for the tiles. One\nof:\n•Save to a Temporary Directory\n•Save to Directory\n1286Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nResampling\nmethod\nRESAMPLING[enumeration]\nDefault: 0\nThe resampling algorithm to be used Op-\ntions:\n•0 — Average (average)\n•1 — Nearest neighbour (near)\n•2 — Bilinear (bilinear)\n•3 — Cubic (cubic)\n•4 — Cubic spline (cubicspline)\n•5  —  Lanczos  Windowed  sinc\n(lanczos)\n•6 — Antialias (antialias)\nThe spatial refer-\nence system used\nfor the source in-\nput data\nOptional\nSOURCE_CRS[crs]\nDefault: None\nTransparency\nvalue to assign to\nthe input data\nOptional\nNODATA[number]\nDefault: 0.0\nURL    address\nwhere the gener-\natedtilesaregoing\nto be published\nOptional\nURL[string]\nDefault: ‘’\nGoogle    Maps\nAPIkey\n(http://code.google.com/apis/maps/signup.html)\nOptional\nGOOGLE_KEY[string]\nDefault: ‘’\nYour Google maps API key.\nBingMaps\nAPIkey\n(https://www.bingmapsportal.com/)\nOptional\nBING_KEY[string]\nDefault: ‘’\nYour Bing maps API key.\nGenerate   only\nmissing files\nRESUME[boolean]\nDefault: False\nGenerate  KML\nfor Google Earth\nKML[boolean]\nDefault: False\nAvoid  automatic\ngeneration    of\nKML  files  for\nEPSG:4326\nNO_KML[boolean]\nDefault: False\n25.2. GDAL algorithm provider1287\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutput directoryOUTPUT[folder]The output folder (for the tiles)\nPython code\nAlgorithm ID:gdal:gdal2tiles\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nMerge\nMerges raster files in a simple way. Here you can use a pseudocolor table from an input raster and define the output\nraster type. All the images must be in the same coordinate system.\nThis algorithm is derived from theGDAL merge utility.\nDefault menu:Raster►Miscellaneous\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layersINPUT[raster] [list]Input raster layers\nGrab pseudocolor\ntable  from  first\nlayer\nPCT[boolean]\nDefault: False\nThe pseudocolor table from the first layer\nwill be used for the coloring\nPlace each input\nfile into a separate\nband\nSEPARATE[boolean]\nDefault: False\nPlace each input file into a separate band\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the format of the output raster file.\nOptions:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\ncontinues on next page\n1288Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.237 – continued from previous page\nLabelNameTypeDescription\nMergedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nInput pixel value\nto treat as “no-\ndata”\nOptional\nNODATA_INPUT[number]\nDefault: None\nIgnores pixels from files being merged in\nwith this pixel value\nAssign  specified\n“nodata” value to\noutput\nOptional\nNODATA_OUTPUT[number]\nDefault: None\nAssigns the specified nodata value to output\nbands.\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nMergedOUTPUT[raster]Output raster layer\nPython code\nAlgorithm ID:gdal:merge\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1289\n\nQGIS Desktop 3.22 User Guide\nPansharpening\nPerforms a pan-sharpening operation. It can create a “classic” output dataset (such as GeoTIFF), or a VRT dataset\ndescribing the pan-sharpening operation.\nSeeGDAL Pansharpen.\nParameters\nBasic parameters\nLabelNameTypeDescription\nSpectral datasetSPECTRAL[raster]Input (spectral) raster layer\nPanchromatic\ndataset\nPANCHROMATIC[raster]Input (panchromatic) raster layer\nOutputOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output (sharpened) raster layer.\nOne of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nResampling algo-\nrithm\nRESAMPLING[enumeration]\nDefault: 2\nThe resampling algorithm to be used Op-\ntions:\n•0 — Nearest Neighbour (nearest)\n•1 — Bilinear (bilinear)\n•2 — Cubic (cubic)\n•3 — Cubic Spline (cubicspline)\n•4  —  Lanczos  Windowed  Sinc\n(lanczos)\n•5 — Average (average)\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\n1290Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[raster]Output (sharpened) raster layer\nPython code\nAlgorithm ID:gdal:pansharp\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster calculator\nCommand line raster calculator with numpy syntax. Use any basic arithmetic supported by numpy arrays, such as +,\n-, *, and / along with logical operators, such as >. Note that all input rasters must have the same dimensions, but no\nprojection checking is performed.\nSee theGDAL Raster Calculator utility docs.\nSee also:\nRaster calculator\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layer AINPUT_A[raster]First input raster layer (mandatory)\nNumber of raster\nband for A\nBAND_A[raster band]Band for input layer A (mandatory)\nInput layer B\nOptional\nINPUT_B[raster]\nDefault: None\nSecond input raster layer\nNumber of raster\nband for B\nOptional\nBAND_B[raster band]Band for input layer B\nInput layer C\nOptional\nINPUT_C[raster]\nDefault: None\nThird input raster layer\nNumber of raster\nband for C\nOptional\nBAND_C[raster band]Band for input layer C\nInput layer D\nOptional\nINPUT_D[raster]\nDefault: None\nFourth input raster layer\nNumber of raster\nband for D\nOptional\nBAND_D[raster band]Band for input layer D\nInput layer E\nOptional\nINPUT_E[raster]\nDefault: None\nFifth input raster layer\ncontinues on next page\n25.2. GDAL algorithm provider1291\n\nQGIS Desktop 3.22 User Guide\nTable 25.239 – continued from previous page\nLabelNameTypeDescription\nNumber of raster\nband for E\nOptional\nBAND_E[raster band]Band for input layer E\nInput layer F\nOptional\nINPUT_F[raster]Sixth input raster layer\nNumber of raster\nband for F\nOptional\nBAND_F[raster band]\nDefault: None\nBand for input layer F\nCalculation   in\ngdalnumeric syn-\ntax using +-/* or\nany numpy array\nfunctions    (i.e.\nlogical_and())\nFORMULA[string]\nDefault: ‘’\nThe calculation formula. Examples:\n•A*(A>0)— outputs the value of\nthe raster A if the value of A is\ngreater than 0. If not, outputs 0.\n•A*(A>0 and A>B)— outputs the\nvalue of A if that value is bigger than\n0 and bigger than the value of B. If\nnot, outputs 0.\n•A*logical_or(A<=177,\nA>=185)— outputs the value of\nA if A <= 177 or A >= 185. If not,\noutputs 0.\n•sqrt(A*A+B*B)— Outputs the\nsquare root of the sum of the value\nof A squared and the value of B\nsquared.\nSet output nodata\nvalue\nOptional\nNO_DATA[number]\nDefault: None\nValue to use for nodata\nOutputrastertypeRTYPE[enumeration]\nDefault: 5\nDefines the format of the output raster file.\nOptions:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\nCalculatedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output (calculated) raster layer.\nOne of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\n1292Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: ‘’\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nCalculatedOUTPUT[raster]Output (calculated) raster layer\nPython code\nAlgorithm ID:gdal:rastercalculator\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRaster information\nThe gdalinfo program lists various information about a GDAL supported raster dataset.\nThis algorithm is derived from theGDAL info utility.\nDefault menu:Raster►Miscellaneous\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer\nForce  computa-\ntion of the actual\nmin/max  values\nfor each band\nMIN_MAX[boolean]\nDefault: False\nForces computation of the actual min/max\nvalues for each band in the dataset\nRead and display\nimage  statistics\n(force  computa-\ntion if necessary)\nSTATS[boolean]\nDefault: False\nReads and displays image statistics. Forces\ncomputation if no statistics are stored in an\nimage.\ncontinues on next page\n25.2. GDAL algorithm provider1293\n\nQGIS Desktop 3.22 User Guide\nTable 25.241 – continued from previous page\nLabelNameTypeDescription\nSuppress   GCP\ninfo\nNO_GCP[boolean]\nDefault: False\nSuppresses ground control points list print-\ning. It may be useful for datasets with huge\namount of GCPs, such as L1B AVHRR or\nHDF4 MODIS which contain thousands of\nthem.\nSuppress  meta-\ndata info\nNO_METADATA[boolean]\nDefault: False\nSuppresses metadata printing.   Some\ndatasets may contain a lot of metadata\nstrings.\nLayer informationOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the HTML file for output. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nLayer informationOUTPUT[html]The HTML file containing information\nabout the input raster layer\nPython code\nAlgorithm ID:gdal:gdalinfo\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRetile\nRetiles a set of input tiles. All the input tiles must be georeferenced in the same coordinate system and have a matching\nnumber of bands. Optionally pyramid levels are generated.\nThis algorithm is derived from theGDAL Retile utility.\n1294Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput filesINPUT[raster] [list]The input raster files\nTile widthTILE_SIZE_X[number]\nDefault: 256\nWidth of the tiles in pixels (minimum 0)\nTile heightTILE_SIZE_Y[number]\nDefault: 256\nHeight of the tiles in pixels (minimum 0)\nOverlap in pixels\nbetween consecu-\ntive tiles\nOVERLAP[number]\nDefault: 0\nNumber of pyra-\nmid levels to build\nLEVELS[number]\nDefault: 1\nMinimum: 0\nOutput directoryOUTPUT[folder]\nDefault:[Save\nto  temporary\nfolder]\nSpecify the output folder for the tiles. One\nof:\n•Save to a Temporary Directory\n•Save to Directory\nCSV file contain-\ning the tile(s) geo-\nreferencing infor-\nmation\nOUTPUT_CSV[file]\nDefault:[Skip\noutput]\nSpecify the output file for the tiles. One of:\n•Skip Output\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nSource coordinate\nreference system\nOptional\nSOURCE_CRS[crs]\nDefault: None\nResampling\nmethod\nRESAMPLING[enumeration]\nDefault: 0\nThe resampling algorithm to be used Op-\ntions:\n•0 — Nearest Neighbour (nearest)\n•1 — Bilinear (bilinear)\n•2 — Cubic (cubic)\n•3 — Cubic Spline (cubicspline)\n•4  —  Lanczos  Windowed  Sinc\n(lanczos)\nColumn delimiter\nused in the CSV\nfile\nOptional\nDELIMITER[string]\nDefault: ‘;’\nDelimiter to use in the CSV file containing\nthe tile(s) georeferencing information\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\ncontinues on next page\n25.2. GDAL algorithm provider1295\n\nQGIS Desktop 3.22 User Guide\nTable 25.244 – continued from previous page\nLabelNameTypeDescription\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: ‘’\nAdd extra GDAL command line options\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the format of the output raster file.\nOptions:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nBuild  only  the\npyramids\nONLY_PYRAMIDS[boolean]\nDefault: False\nUse separate di-\nrectory for each\ntile row\nDIR_FOR_ROW[boolean]\nDefault: False\nOutputs\nLabelNameTypeDescription\nOutput directoryOUTPUT[folder]The output folder for the tiles.\nCSV file contain-\ning the tile(s) geo-\nreferencing infor-\nmation\nOUTPUT_CSV[file]The CSV file with georeferencing informa-\ntion for the tiles.\nPython code\nAlgorithm ID:gdal:retile\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1296Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTile index\nBuilds a vector layer with a record for each input raster file, an attribute containing the filename, and a polygon\ngeometry outlining the raster. This output is suitable for use with MapServer as a raster tileindex.\nThis algorithm is derived from theGDAL Tile Index utility.\nDefault menu:Raster►Miscellaneous\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput filesLAYERS[raster] [list]The input raster files. Can be multiple files.\nField name to hold\nthe file path to the\nindexed rasters\nPATH_FIELD_NAME\nOptional\n[string]\nDefault: ‘location’\nThe output field name to hold the file\npath/location to the indexed rasters.\nStore   absolute\npath to the in-\ndexed rasters\nABSOLUTE_PATH[boolean]\nDefault: False\nSet whether the absolute path to the raster\nfiles is stored in the tile index file. By de-\nfault the raster filenames will be put in the\nfile exactly as they are specified in the com-\nmand.\nSkip files with dif-\nferent  projection\nreference\nPROJ_DIFFERENCE[boolean]\nDefault: False\nOnly files with same projection as files al-\nready inserted in the tile index will be in-\nserted. Default does not check projection\nand accepts all inputs.\nTile indexOUTPUT[vector: polygon]\nDefault:[Save\nto  temporary\nfile]\nSpecify the polygon vector layer to write the\nindex to. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nTransform geome-\ntries to the given\nCRS\nOptional\nTARGET_CRS[crs]Geometries of input files will be trans-\nformed to the specified target coordinate\nreference system.  Default creates simple\nrectangular polygons in the same coordinate\nreference system as the input rasters.\nThe name of the\nfield to store the\nSRS of each tile\nOptional\nCRS_FIELD_NAME[string]The name of the field to store the SRS of\neach tile\nThe  format  in\nwhich the CRS of\neach tile must be\nwritten\nCRS_FORMAT[enumeration]\nDefault: 0\nFormat for the CRS. One of:\n•0 – Auto (AUTO)\n•1 – Well-known text (WKT)\n•2 – EPSG (EPSG)\n•3 – Proj.4 (PROJ)\n25.2. GDAL algorithm provider1297\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nTile indexOUTPUT[vector: polygon]The polygon vector layer with the tile index.\nPython code\nAlgorithm ID:gdal:tileindex\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nViewshed\nCalculates a viewshed raster from an input raster DEM using method defined inWang2000for a user defined point.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input elevation raster layer\nBand numberBAND[raster band]\nDefault: 1\nThe number of the band to use as elevation\nObserver locationOBSERVER[point]The location of the observer\nObserver heightOB-\nSERVER_HEIGHT\n[number]\nDefault: 1.0\nThe altitude of the observer, in the DEM\nunits\nTarget heightTARGET_HEIGHT[number]\nDefault: 1.0\nThe altitude of the target element, in the\nDEM units\nMaximum   dis-\ntance  from  ob-\nserver to compute\nvisibility\nMAX_DISTANCE[number]\nDefault: 100.0\nMaximum distance from observer to com-\npute visibility, in the DEM units\nOutputOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nOutput raster layer. One of:\n•Save to a Temporary File\n•Save to File...\n1298Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nAdditional\ncommand-line\nparameters\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nOutputOUTPUT[raster]The raster layer displaying the viewshed.\nPython code\nAlgorithm ID:gdal:viewshed\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2.5Raster projections\nAssign projection\nApplies a coordinate system to a raster dataset.\nThis algorithm is derived from theGDAL edit utility.\nDefault menu:Raster►Projections\nParameters\nLabelNameTypeDescription\nInput layerINPUT_LAYER[raster]Input raster layer\nDesired CRSCRS[crs]The projection (CRS) of the output layer\n25.2. GDAL algorithm provider1299\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nLayer with projec-\ntion\nOUTPUT[raster]The output raster layer (with the new pro-\njection information)\nPython code\nAlgorithm ID:gdal:assignprojection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExtract projection\nExtracts the projection of a raster file and writes it into aworldfile with extension.wld.\nThis algorithm is derived from theGDAL srsinfo utility.\nDefault menu:Raster►Projections\nParameters\nLabelNameTypeDescription\nInput fileINPUT_LAYER[raster]Input raster The raster layer has to be file\nbased, as the algorithm uses the path to the\nraster file as the location of the generated.\nwldfile. Using a non-file raster layer will\nlead to an error.\nCreate also .prj\nfile\nPRJ_FILE_CREATE[boolean]\nDefault: False\nIf this is activated a.prjfile containing\nthe projection information is also created.\nOutputs\nLabelNameTypeDescription\nWorld fileWORLD_FILE[file]Text file with extension.wldcontaining\ntransformation parameters for the raster\nfile.\nESRI   Shapefile\nprj file\nPRJ_FILE[file]Text file with.prjextension that de-\nscribes the CRS. Will beNoneifCreate\nalso .prj fileis False.\n1300Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:gdal:extractprojection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nWarp (reproject)\nReprojects a raster layer into another Coordinate Reference System (CRS). The output file resolution and the resam-\npling method can be chosen.\nThis algorithm is derived from theGDAL warp utility.\nDefault menu:Raster►Projections\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[raster]Input raster layer to reproject\nSource CRS\nOptional\nSOURCE_CRS[crs]Defines the CRS of the input raster layer\nTarget CRS\nOptional\nTARGET_CRS[crs]\nDefault:\nEPSG:4326\nThe CRS of the output layer\nResampling\nmethod to use\nRESAMPLING[enumeration]\nDefault: 0\nPixel value resampling method to use. Op-\ntions:\n•0 — Nearest neighbour\n•1 — Bilinear\n•2 — Cubic\n•3 — Cubic spline\n•4 — Lanczos windowed sinc\n•5 — Average\n•6 — Mode\n•7 — Maximum\n•8 — Minimum\n•9 — Median\n•10 — First quartile\n•11 — Third quartile\nNodata value for\noutput bands\nOptional\nNODATA[number]\nDefault: None\nSets nodata value for output bands. If not\nprovided, then nodata values will be copied\nfrom the source dataset.\nOutput file resolu-\ntion in target geo-\nreferenced units\nOptional\nTAR-\nGET_RESOLUTION\n[number]\nDefault: None\nDefines the output file resolution of repro-\njection result\ncontinues on next page\n25.2. GDAL algorithm provider1301\n\nQGIS Desktop 3.22 User Guide\nTable 25.249 – continued from previous page\nLabelNameTypeDescription\nReprojectedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(see\nGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutput data typeDATA_TYPE[enumeration]\nDefault: 0\nDefines the format of the output raster file.\nOptions:\n•0 — Use input layer data type\n•1 — Byte\n•2 — Int16\n•3 — UInt16\n•4 — UInt32\n•5 — Int32\n•6 — Float32\n•7 — Float64\n•8 — CInt16\n•9 — CInt32\n•10 — CFloat32\n•11 — CFloat64\nGeoreferenced ex-\ntents of output file\nto be created\nOptional\nTARGET_EXTENT[extent]Sets the georeferenced extent of the output\nfile to be created (in theTarget CRSby de-\nfault. In theCRS of the target raster extent,\nif specified).\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nCRS of the target\nraster extent\nOptional\nTAR-\nGET_EXTENT_CRS\n[crs]Specifies the CRS in which to interpret the\ncoordinates given for the extent of the out-\nput file. This must not be confused with\nthe target CRS of the output dataset. It is\ninstead a convenience e.g. when knowing\nthe output coordinates in a geodetic long/lat\nCRS, but wanting a result in a projected co-\nordinate system.\ncontinues on next page\n1302Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.250 – continued from previous page\nLabelNameTypeDescription\nUse multithreaded\nwarping   imple-\nmentation\nMULTITHREAD-\nING\n[boolean]\nDefault: False\nTwo threads will be used to process chunks\nof the image and perform input/output op-\nerations simultaneously. Note that the com-\nputation itself is not multithreaded.\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: None\nAdd extra GDAL command line options.\nOutputs\nLabelNameTypeDescription\nReprojectedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nReprojected output raster layer\nPython code\nAlgorithm ID:gdal:warpreproject\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2.6Vector conversion\nConvert format\nConverts any OGR-supported vector layer into another OGR-supported format.\nThis algorithm is derived from theogr2ogr utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nConvertedOUTPUT[same as input]Specification of the output vector layer.\nOne of:\n•Save to a Temporary File\n•Save to File...\nForSave to File, the output format\nhas to be specified. All GDAL vector for-\nmats are supported. ForSave  to  a\nTemporary Filethe QGIS default vec-\ntor format will be used.\n25.2. GDAL algorithm provider1303\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\nOutputs\nLabelNameTypeDescription\nConvertedOUTPUT[same as input]The output vector layer\nPython code\nAlgorithm ID:gdal:convertformat\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRasterize (overwrite with attribute)\nOverwrites a raster layer with values from a vector layer. New values are assigned based on the attribute value of the\noverlapping vector feature.\nThis algorithm is derived from theGDAL rasterize utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nInput raster layerINPUT_RASTER[raster]Input raster layer\nField to use for a\nburn-in value\nOptional\nFIELD[tablefield:nu-\nmeric]\nDefines the attribute field to use to set the\npixels values\n1304Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdd burn in val-\nues  to  existing\nraster values\nADD[boolean]\nDefault: False\nIf False, pixels are assigned the selected\nfield’s value. If True, the selected field’s\nvalue is added to the value of the input\nraster layer.\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: ‘’\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nRasterizedOUTPUT[raster]The overwritten input raster layer\nPython code\nAlgorithm ID:gdal:rasterize_over\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRasterize (overwrite with fixed value)\nOverwrites parts of a raster layer with a fixed value. The pixels to overwrite are chosen based on the supplied\n(overlapping) vector layer.\nThis algorithm is derived from theGDAL rasterize utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nInput raster layerINPUT_RASTER[raster]Input raster layer\nA fixed value to\nburn\nBURN[number]\nDefault: 0.0\nThe value to burn\n25.2. GDAL algorithm provider1305\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdd burn in val-\nues  to  existing\nraster values\nADD[boolean]\nDefault: False\nIf False, pixels are assigned the fixed value.\nIf True, the fixed value is added to the value\nof the input raster layer.\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: ‘’\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nRasterizedOUTPUT[raster]The overwritten input raster layer\nPython code\nAlgorithm ID:gdal:rasterize_over_fixed_value\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nRasterize (vector to raster)\nConverts vector geometries (points, lines and polygons) into a raster image.\nThis algorithm is derived from the\nGDAL rasterize utility.\nDefault menu:Raster►Conversion\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nField to use for a\nburn-in value\nOptional\nFIELD[tablefield:nu-\nmeric]\nDefines the attribute field from which the\nattributes for the pixels should be chosen\nA fixed value to\nburn\nOptional\nBURN[number]\nDefault: 0.0\nA fixed value to burn into a band for all fea-\ntures.\ncontinues on next page\n1306Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.253 – continued from previous page\nLabelNameTypeDescription\nBurn  value  ex-\ntracted from the\n“Z” values of the\nfeatureNEW  in\n3.20\nOptional\nUSE_Z[boolean]\nDefault: False\nIndicates that a burn value should be ex-\ntracted from the “Z” values of the feature.\nWorks with points and lines (linear interpo-\nlation along each segment). For polygons,\nworks properly only if they are flat (same Z\nvalue for all vertices)\nOutput raster size\nunits\nUNITS[enumeration]\nDefault: 0\nUnits to use when defining the output raster\nsize/resolution. One of:\n•0 — Pixels\n•1 — Georeferenced units\nWidth/Horizontal\nresolution\nWIDTH[number]\nDefault: 0.0\nSets the width (if size units is “Pixels”)\nor horizontal resolution (if size units is\n“Georeferenced units”) of the output raster.\nMinimum value: 0.0.\nHeight/Vertical\nresolution\nHEIGHT[number]\nDefault: 0.0\nSets the height (if size units is “Pixels”) or\nvertical resolution (if size units is “Georef-\nerenced units”) of the output raster.\nOutput extent\nOptional\nEXTENT[extent]Extent of the output raster layer. If the ex-\ntent is not specified, the minimum extent\nthat covers the selected reference layer(s)\nwill be used.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nAssign a specified\nnodata value to\noutput bands\nOptional\nNODATA[number]\nDefault: 0.0\nAssigns a specified nodata value to output\nbands\nRasterizedOUTPUT[raster]\nDefault:[Save\nto  temporary\nfile]\nSpecification of the output raster layer. One\nof:\n•Save to a Temporary File\n•Save to File...\nForSave  to  File, the output for-\nmat has to be specified. All GDAL raster\nformats are supported.  ForSave  to\na Temporary Filethe QGIS default\nraster format will be used.\n25.2. GDAL algorithm provider1307\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’\nFor adding one or more creation options\nthat control the raster to be created (colors,\nblock size, file compression...). For conve-\nnience, you can rely on predefined profiles\n(seeGDAL driver options section).\nFor Batch Process: separate multiple op-\ntions with a pipe character (|).\nOutput data typeDATA_TYPE[enumeration]\nDefault: 5\nDefines the format of the output raster file.\nOptions:\n•0 — Byte\n•1 — Int16\n•2 — UInt16\n•3 — UInt32\n•4 — Int32\n•5 — Float32\n•6 — Float64\n•7 — CInt16\n•8 — CInt32\n•9 — CFloat32\n•10 — CFloat64\nPre-initialize  the\noutput image with\nvalue\nOptional\nINIT[number]Pre-initializes the output image bands with\nthis value. Not marked as the nodata value\nin the output file. The same value is used in\nall the bands.\nInvert  rasteriza-\ntion\nINVERT[boolean]\nDefault: False\nBurns the fixed burn value, or the burn value\nassociated with the first feature into all parts\nof the image not inside the provided poly-\ngon.\nAdditional\ncommand-line\nparameters\nOptional\nEXTRA[string]\nDefault: ‘’\nAdd extra GDAL command line options\nOutputs\nLabelNameTypeDescription\nRasterizedOUTPUT[raster]Output raster layer\nPython code\nAlgorithm ID:gdal:rasterize\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1308Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\n25.2.7Vector geoprocessing\nBuffer vectors\nCreate buffers around the features of a vector layer.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nGeometry column\nname\nGEOMETRY[string]\nDefault: ‘geometry’\nThe name of the input layer geometry col-\numn to use\nBuffer distanceDISTANCE[number]\nDefault: 10.0\nMinimum: 0.0\nDissolve  by  at-\ntribute\nOptional\nFIELD[tablefield: any]\nDefault: None\nField to use for dissolving\nDissolve resultsDISSOLVE[boolean]\nDefault: FalseIf set, the result is dissolved.If no field\nis set for dissolving, all the buffers are\ndissolved into one feature.\nProduceone\nfeature for each\ngeometry in any\nkind of geometry\ncollection in the\nsource file\nEX-\nPLODE_COLLECTIONS\n[boolean]\nDefault: False\nBufferOUTPUT[vector: polygon]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output buffer layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\n25.2. GDAL algorithm provider1309\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nBufferOUTPUT[vector: polygon]The output buffer layer\nPython code\nAlgorithm ID:gdal:buffervectors\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nClip vector by extent\nClips any OGR-supported vector file to a given extent.\nThis algorithm is derived from the\nGDAL ogr2ogr utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nClip extentEXTENT[extent]Defines the bounding box that should be\nused for the output vector file. It has to be\ndefined in target CRS coordinates.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nClipped (extent)OUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output (clipped) layer. One of:\n•Save to a Temporary File\n•Save to File...\n1310Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\nOutputs\nLabelNameTypeDescription\nClipped (extent)OUTPUT[same as input]The output (clipped) layer. The default for-\nmat is “ESRI Shapefile”.\nPython code\nAlgorithm ID:gdal:clipvectorbyextent\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nClip vector by mask layer\nClips any OGR-supported vector layer by a mask polygon layer.\nThis algorithm is derived from the\nGDAL ogr2ogr utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input vector layer\nMask layerMASK[vector: polygon]Layer to be used as clipping extent for the\ninput vector layer.\nClipped (mask)OUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nThe output (masked) layer. One of:\n•Save to a Temporary File\n•Save to File...\n25.2. GDAL algorithm provider1311\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\nOutputs\nLabelNameTypeDescription\nClipped (mask)OUTPUT[same as input]The output (masked) layer. The default for-\nmat is “ESRI Shapefile”.\nPython code\nAlgorithm ID:gdal:clipvectorbypolygon\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nDissolve\nDissolve (combine) geometries that have the same value for a given attribute / field. The output geometries are\nmultipart.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]The input layer to dissolve\nDissolve field\nOptional\nFIELD[tablefield: any]The field of the input layer to use for dis-\nsolving\nGeometry column\nname\nGEOMETRY[string]\nDefault: ‘geometry’\nThe name of the input layer geometry col-\numn to use for dissolving.\nDissolvedOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output layer. One of:\n•Save to a Temporary File\n•Save to File...\n1312Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nAdvanced parameters\nLabelNameTypeDescription\nProduceone\nfeature for each\ngeometry in any\nkind of geometry\ncollection in the\nsource file\nEX-\nPLODE_COLLECTIONS\n[boolean]\nDefault: False\nProduce one feature for each geometry in\nany kind of geometry collection in the\nsource file\nKeep  input  at-\ntributes\nKEEP_ATTRIBUTES[boolean]\nDefault: False\nKeep all attributes from the input layer\nCount  dissolved\nfeatures\nCOUNT_FEATURES[boolean]\nDefault: False\nCount the dissolved features and include it\nin the output layer.\nCompute area and\nperimeter of dis-\nsolved features\nCOMPUTE_AREA[boolean]\nDefault: FalseCompute the area and perimeter of dissolved features and\ninclude them in the output layer\nCompute\nmin/max/sum/mean\nfor attribute\nCOM-\nPUTE_STATISTICS\n[boolean]\nDefault: False\nCalculate statistics (min, max, sum and\nmean) for the numeric attribute specified\nand include them in the output layer\nNumeric attribute\nto calculate statis-\ntics on\nOptional\nSTATIS-\nTICS_ATTRIBUTE\n[tablefield:nu-\nmeric]\nThe numeric attribute to calculate statistics\non\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\nOutputs\nLabelNameTypeDescription\nDissolvedOUTPUT[same as input]\nThe output multipart geometry layer (with dissolved\ngeometries)\nPython code\nAlgorithm ID:gdal:dissolve\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. See\nUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2. GDAL algorithm provider1313\n\nQGIS Desktop 3.22 User Guide\nOffset curve\nOffsets lines by a specified distance. Positive distances will offset lines to the left, and negative distances will offset\nthem to the right.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]The input line layer\nGeometry column\nname\nGEOMETRY[string]\nDefault: ‘geometry’\nThe name of the input layer geometry col-\numn to use\nOffset   distance\n(left-sided:  posi-\ntive,  right-sided:\nnegative)\nDISTANCE[number]\nDefault: 10.0\nOffset curveOUTPUT[vector: line]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output line layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\nOutputs\nLabelNameTypeDescription\nOffset curveOUTPUT[vector: line]The output offset curve layer\nPython code\nAlgorithm ID:gdal:offsetcurve\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n1314Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOne side buffer\nCreates a buffer on one side (right or left) of the lines in a line vector layer.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]The input line layer\nGeometry column\nname\nGEOMETRY[string]\nDefault: ‘geometry’\nThe name of the input layer geometry col-\numn to use\nBuffer distanceDISTANCE[number]\nDefault: 10.0\nBuffer sideBUFFER_SIDE[enumeration]\nDefault: 0\nOne of:\n•0 — Right\n•1 — Left\nDissolve  by  at-\ntribute\nOptional\nFIELD[tablefield: any]\nDefault: None\nField to use for dissolving\nDissolve all resultsDISSOLVE[boolean]\nDefault: FalseIf set, the result is dissolved.If no field\nis set for dissolving, all the buffers are\ndissolved into one feature.\nProduceone\nfeature for each\ngeometry in any\nkind of geometry\ncollection in the\nsource file\nEX-\nPLODE_COLLECTIONS\n[boolean]\nDefault: False\nOne-sided bufferOUTPUT[vector: polygon]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output buffer layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\n25.2. GDAL algorithm provider1315\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nOne-sided bufferOUTPUT[vector: polygon]The output buffer layer\nPython code\nAlgorithm ID:gdal:onesidebuffer\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nPoints along lines\nGenerates a point on each line of a line vector layer at a distance from start. The distance is provided as a fraction of\nthe line length.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: line]The input line layer\nGeometry column\nname\nGEOMETRY[string]\nDefault: ‘geometry’\nThe name of the input layer geometry col-\numn to use\nDistance from line\nstart represented\nas a fraction of\nline length\nDISTANCE[number]\nDefault: 0.5 (mid-\ndle of the line)\nPoints along linesOUTPUT[vector: point]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output point layer. One of:\n•Save to a Temporary File\n•Save to File...\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\n1316Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nPoints along lineOUTPUT[vector: point]The output point layer\nPython code\nAlgorithm ID:gdal:pointsalonglines\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.2.8Vector miscellaneous\nBuild virtual vector\nCreates a virtual vector layer that contains a set of vector layers. The output virtual vector layer will not be opened\nin the current project.\nThis algorithm is especially useful in case another algorithm needs multiple layers but accept only onevrtin which\nthe layers are specified.\nParameters\nLabelNameTypeDescription\nInput datasourcesINPUT[vector: any] [list]Select the vector layers you want to use to\nbuild the virtual vector\nCreate “unioned”\nVRT\nUNIONED[boolean]\nDefault: False\nCheck if you want to unite all the vectors in\na singlevrtfile\nVirtual vectorOUTPUT[same as input]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output layer containing only the\nduplicates. One of:\n•Save to a Temporary File\n•Save to File...\nOutputs\nLabelNameTypeDescription\nVirtual vectorOUTPUT[vector: any]The output virtual vector made from the\nchosen sources\n25.2. GDAL algorithm provider1317\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:gdal:buildvirtualvector\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExecute SQL\nRuns a simple or complex query with SQL syntax on the source layer. The result of the query will be added as a new\nlayer.\nThis algorithm is derived from theGDAL ogr2ogr utility.\nParameters\nBasic parameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]OGR-supported input vector layer\nSQL expressionSQL[string]Defines the SQL query, for exampleSE-\nLECT  *  FROM  my_table  WHERE\nname is not null.\nSQL dialectDIALECT[enumeration]\nDefault: 0\nSQL dialect to use. One of:\n•0 — None\n•1 — OGR SQL\n•2 — SQLite\nSQL resultOUTPUT[vector: any]Specification of the output layer. One of:\n•Save to a Temporary File\n•Save to File...\nForSave  to  File, the output for-\nmat has to be specified. All GDAL vec-\ntor formats are supported. ForSave to\na Temporary Filethe default output\nvector layer format will be used.\nAdvanced parameters\nLabelNameTypeDescription\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\n1318Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nLabelNameTypeDescription\nSQL resultOUTPUT[vector: any]Vector layer created by the query\nPython code\nAlgorithm ID:gdal:executesql\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport to PostgreSQL (available connections)\nImports vector layers inside a PostgreSqL database on the basis of an available connection. The connection has tobe\ndefined properlybeforehand. Be aware that the checkboxes ‘Save Username’ and ‘Save Password’ are activated. Then\nyou can use the algorithm.\nThis algorithm is derived from theGDAL ogr2ogr utility.\nParameters\nLabelNameTypeDescription\nDatabase (connec-\ntion name)\nDATABASE[string]The PostgreSQL database to connect to\nInput layerINPUT[vector: any]OGR-supported vector layer to export to\nthe database\nShape encoding\nOptional\nSHAPE_ENCODING[string]\nDefault: ‘’\nSets the encoding to apply to the data\nOutput geometry\ntype\nGTYPE[enumeration]\nDefault: 0\nDefines the output geometry type. One of:\n•0 —\n•1 — NONE\n•2 — GEOMETRY\n•3 — POINT\n•4 — LINESTRING\n•5 — POLYGON\n•6 — GEOMETRYCOLLECTION\n•7 — MULTIPOINT\n•8 — MULTIPOLYGON\n•9 — MULTILINESTRING\nAssign an output\nCRS\nOptional\nA_SRS[crs]\nDefault: None\nDefines the output CRS of the database ta-\nble\nReproject to this\nCRS on output\nOptional\nT_SRS[crs]\nDefault: None\nReprojects/transforms to this CRS on out-\nput\ncontinues on next page\n25.2. GDAL algorithm provider1319\n\nQGIS Desktop 3.22 User Guide\nTable 25.263 – continued from previous page\nLabelNameTypeDescription\nOverride  source\nCRS\nOptional\nS_SRS[crs]\nDefault: None\nOverrides the input layer CRS\nSchema  (schema\nname)\nOptional\nSCHEMA[string]\nDefault: ‘public’\nDefines the schema for the database table\nTable to export to\n(leave blank to use\nlayer name)\nOptional\nTABLE[string]\nDefault: ‘’\nDefines a name for the table that will be im-\nported into the database. By default the ta-\nble name is the name of the input vector file.\nPrimary Key (new\nfield)\nOptional\nPK[string]\nDefault: ‘id’\nDefines which attribute field will be the pri-\nmary key of the database table\nPrimary Key (ex-\nisting field, used if\nthe above option is\nleft empty)\nOptional\nPRIMARY_KEY[tablefield: any]\nDefault: None\nDefines which attribute field in the exported\nlayer will be the primary key of the database\ntable\nGeometry column\nname\nOptional\nGEOCOLUMN[string]\nDefault: ‘geom’\nDefines in which attribute field of the\ndatabase there will be the geometry infor-\nmation\nVector dimensions\nOptional\nDIM[enumeration]\nDefault: 0 (2D)\nDefines if the vector file to be imported has\n2D or 3D data. One of:\n•0 — 2\n•1 — 3\nDistance tolerance\nfor simplification\nOptional\nSIMPLIFY[string]\nDefault: ‘’\nDefines a distance tolerance for the simpli-\nfication of the vector geometries to be im-\nported. By default there is no simplifica-\ntion.\nMaximum   dis-\ntance between 2\nnodes  (densifica-\ntion)\nOptional\nSEGMENTIZE[string]\nDefault: ‘’\nThe maximum distance between two nodes.\nUsed to create intermediate points. By de-\nfault there is no densification.\nSelect features by\nextent (defined in\ninput layer CRS)\nOptional\nSPAT[extent]\nDefault: None\nYou can select features from a given extent\nthat will be in the output table.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nClip  the  input\nlayer  using  the\nabove (rectangle)\nextent\nOptional\nCLIP[boolean]\nDefault: False\nThe input layer will be clipped by the extent\nyou defined before\ncontinues on next page\n1320Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.263 – continued from previous page\nLabelNameTypeDescription\nSelect   features\nusing  a  SQL\n“WHERE”\nstatement   (Ex:\ncolumn=”value”)\nOptional\nWHERE[string]\nDefault: ‘’\nDefines with a SQL “WHERE” statement\nwhich features should be selected from the\ninput layer\nGroup N features\nper   transaction\n(Default: 2000)\nOptional\nGT[string]\nDefault: ‘’\nYou can group the input features in transac-\ntions where N defines the size. By default N\nlimits the transaction size to 20000 features.\nOverwrite existing\ntable\nOptional\nOVERWRITE[boolean]\nDefault: True\nIf there is a table with the same name in the\ndatabase, and if this option is set to True,\nthe table will be overwritten.\nAppendtoexisting\ntable\nOptional\nAPPEND[boolean]\nDefault: False\nIf checked / True the vector data will be\nappended to an existing table. New fields\nfound in the input layer are ignored. By de-\nfault a new table will be created.\nAppend and add\nnew fields to exist-\ning table\nOptional\nADDFIELDS[boolean]\nDefault: False\nIf activated the vector data will be ap-\npended to an existing table, there won’t be\na new table created. New fields found in in-\nput layer are added to the table. By default\na new table will be created.\nDo  not  launder\ncolumns/table\nnames\nOptional\nLAUNDER[boolean]\nDefault: False\nWith this option checked you can prevent\nthe default behaviour (converting column\nnames to lowercase, removing spaces and\nother invalid characters).\nDo not create Spa-\ntial Index\nOptional\nINDEX[boolean]\nDefault: False\nPrevents a spatial index for the output table\nfrom being created. By default, a spatial in-\ndex is added.\nContinue after a\nfailure,  skipping\nthe failed feature\nOptional\nSKIPFAILURES[boolean]\nDefault: False\nPromote to Multi-\npart\nOptional\nPROMOTETO-\nMULTI\n[boolean]\nDefault: True\nCasts features geometry type to multipart in\nthe output table\nKeep width and\nprecision of input\nattributes\nOptional\nPRECISION[boolean]\nDefault: True\nAvoids modifying column attributes to\ncomply with input data\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\n25.2. GDAL algorithm provider1321\n\nQGIS Desktop 3.22 User Guide\nOutputs\nThis algorithm has no output.\nPython code\nAlgorithm ID:gdal:importvectorintopostgisdatabaseavailableconnections\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nExport to PostgreSQL (new connection)\nImports vector layers inside a PostGreSQL database. A new connection to the PostGIS database must be created.\nThis algorithm is derived from theGDAL ogr2ogr utility.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]OGR-supported vector layer to export to\nthe database\nShape encoding\nOptional\nSHAPE_ENCODING[string]\nDefault: ‘’\nSets the encoding to apply to the data\nOutput geometry\ntype\nGTYPE[enumeration]\nDefault: 0\nDefines the output geometry type. One of:\n•0 —\n•1 — NONE\n•2 — GEOMETRY\n•3 — POINT\n•4 — LINESTRING\n•5 — POLYGON\n•6 — GEOMETRYCOLLECTION\n•7 — MULTIPOINT\n•8 — MULTIPOLYGON\n•9 — MULTILINESTRING\nAssign an output\nCRS\nOptional\nA_SRS[crs]\nDefault: None\nDefines the output CRS of the database ta-\nble\nReproject to this\nCRS on output\nOptional\nT_SRS[crs]\nDefault: None\nReprojects/transforms to this CRS on out-\nput\nOverride  source\nCRS\nOptional\nS_SRS[crs]\nDefault: None\nOverrides the input layer CRS\nHost\nOptional\nHOST[string]\nDefault: ‘localhost’\nName of the database host\nPort\nOptional\nPORT[string]\nDefault: ‘5432’\nPort number the PostgreSQL database\nserver listens on\ncontinues on next page\n1322Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nTable 25.264 – continued from previous page\nLabelNameTypeDescription\nUsername\nOptional\nUSER[string]\nDefault: ‘’\nUser name used to log in to the database\nDatabase name\nOptional\nDBNAME[string]\nDefault: ‘’\nName of the database\nPassword\nOptional\nPASSWORD[string]\nDefault: ‘’\nPassword used with Username to connect to\nthe database\nSchema  (schema\nname)\nOptional\nSCHEMA[string]\nDefault: ‘public’\nDefines the schema for the database table\nTable name, leave\nblank to use input\nname\nOptional\nTABLE[string]\nDefault: ‘’\nDefines a name for the table that will be im-\nported into the database. By default the ta-\nble name is the name of the input vector file.\nPrimary Key (new\nfield)\nOptional\nPK[string]\nDefault: ‘id’\nDefines which attribute field will be the pri-\nmary key of the database table\nPrimary Key (ex-\nisting field, used if\nthe above option is\nleft empty)\nOptional\nPRIMARY_KEY[tablefield: any]\nDefault: None\nDefines which attribute field in the exported\nlayer will be the primary key of the database\ntable\nGeometry column\nname\nOptional\nGEOCOLUMN[string]\nDefault: ‘geom’\nDefines in which attribute field to store the\ngeometry information\nVector dimensions\nOptional\nDIM[enumeration]\nDefault: 0 (2D)\nDefines if the vector file to be imported has\n2D or 3D data. One of:\n•0 — 2D\n•1 — 3D\nDistance tolerance\nfor simplification\nOptional\nSIMPLIFY[string]\nDefault: ‘’\nDefines a distance tolerance for the simpli-\nfication of the vector geometries to be im-\nported. By default no simplification there is\nno simplification.\nMaximum   dis-\ntance between 2\nnodes  (densifica-\ntion)\nOptional\nSEGMENTIZE[string]\nDefault: ‘’\nThe maximum distance between two nodes.\nUsed to create intermediate points. By de-\nfault there is no densification.\nSelect features by\nextent (defined in\ninput layer CRS)\nOptional\nSPAT[extent]\nDefault: None\nYou can select features from a given extent\nthat will be in the output table.\nAvailable methods are:\n•Calculate from layer...:  uses ex-\ntent of a layer loaded in the current\nproject\n•Use map canvas extent\n•Draw on canvas\n•Enter the coordinates asxmin,\nxmax, ymin, ymax\nClip  the  input\nlayer  using  the\nabove (rectangle)\nextent\nOptional\nCLIP[boolean]\nDefault: False\nThe input layer will be clipped by the extent\nyou defined before\ncontinues on next page\n25.2. GDAL algorithm provider1323\n\nQGIS Desktop 3.22 User Guide\nTable 25.264 – continued from previous page\nLabelNameTypeDescription\nFields to include\n(leaveemptytouse\nall fields)\nOptional\nFIELDS[string] [list]\nDefault: []\nDefines fields to keep from the imported\nvector file. If none is selected, all the fields\nare imported.\nSelect   features\nusing  a  SQL\n“WHERE”\nstatement   (Ex:\ncolumn=”value”)\nOptional\nWHERE[string]\nDefault: ‘’\nDefines with a SQL “WHERE” statement\nwhich features should be selected for the\noutput table\nGroup N features\nper   transaction\n(Default: 2000)\nOptional\nGT[string]\nDefault: ‘’\nYou can group the input features in transac-\ntions where N defines the size. By default N\nlimits the transaction size to 20000 features.\nOverwrite existing\ntable\nOptional\nOVERWRITE[boolean]\nDefault: True\nIf there is a table with the same name in the\ndatabase, and if this option is set to True,\nthe table will be overwritten.\nAppendtoexisting\ntable\nOptional\nAPPEND[boolean]\nDefault: False\nIf checked / True the vector data will be\nappended to an existing table. New fields\nfound in the input layer are ignored. By de-\nfault a new table will be created.\nAppend and add\nnew fields to exist-\ning table\nOptional\nADDFIELDS[boolean]\nDefault: False\nIf activated the vector data will be ap-\npended to an existing table, there won’t be\ncreated a new table. New fields found in in-\nput layer are added to the table. By default\na new table will be created.\nDo  not  launder\ncolumns/table\nnames\nOptional\nLAUNDER[boolean]\nDefault: False\nWith this option checked you can prevent\nthe default behaviour (converting column\nnames to lowercase, removing spaces and\nother invalid characters).\nDo not create Spa-\ntial Index\nOptional\nINDEX[boolean]\nDefault: False\nPrevents a spatial index for the output table\nfrom being created. By default, a spatial in-\ndex is added.\nContinue after a\nfailure,  skipping\nthe failed feature\nOptional\nSKIPFAILURES[boolean]\nDefault: False\nPromote to Multi-\npart\nOptional\nPROMOTETO-\nMULTI\n[boolean]\nDefault: True\nCasts features geometry type to multipart in\nthe output table\nKeep width and\nprecision of input\nattributes\nOptional\nPRECISION[boolean]\nDefault: True\nAvoids modifying column attributes to\ncomply with input data\nAdditional   cre-\nation options\nOptional\nOPTIONS[string]\nDefault: ‘’ (no addi-\ntional options)\nAdditional GDAL creation options.\n1324Chapter 25. Processing providers and algorithms\n\nQGIS Desktop 3.22 User Guide\nOutputs\nThis algorithm has no output.\nPython code\nAlgorithm ID:gdal:importvectorintopostgisdatabasenewconnection\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\nVector Information\nCreates an information file that lists information about an OGR-supported data source. The output will be shown in\na ‘Result’ window and can be written into a HTML-file. The information includes the geometry type, feature count,\nthe spatial extent, the projection information and many more.\nThis algorithm is derived from theGDAL ogrinfo utility.\nParameters\nLabelNameTypeDescription\nInput layerINPUT[vector: any]Input vector layer\nSummary output\nonly\nOptional\nSUMMARY_ONLY[boolean]\nDefault: True\nSuppress  meta-\ndata info\nOptional\nNO_METADATA[boolean]\nDefault: False\nLayer informationOUTPUT[html]\nDefault:[Save\nto  temporary\nfile]\nSpecify the output HTML file that includes\nthe file information. One of:\n•Save to a Temporary File\n•Save to File...\nIf no HTML-file is defined the output will\nbe written to a temporary file\nOutputs\nLabelNameTypeDescription\nLayer informationOUTPUT[html]The output HTML-file that includes the file\ninformation.\n25.2. GDAL algorithm provider1325\n\nQGIS Desktop 3.22 User Guide\nPython code\nAlgorithm ID:gdal:ogrinfo\nimportprocessing\nprocessing.run(\"algorithm_id\", {parameter_dictionary})\nThealgorithm idis displayed when you hover over the algorithm in the Processing Toolbox. Theparameter dictionary\nprovides the parameter NAMEs and values. SeeUsing processing algorithms from the consolefor details on how to\nrun processing algorithms from the Python console.\n25.3OTB applications provider\nOTB(Orfeo ToolBox) is an image processing library for remote sensing data. It also provides applications that provide\nimage processing functionalities. The list of applications and their documentation are available in\nOTB CookBook\n1326Chapter 25. Processing providers and algorithms\n\nCHAPTER\nTWENTYSIX\nPLUGINS\n26.1QGIS Plugins\nQGIS has been designed with a plugin architecture. This allows many new features and functions to be easily added\nto the application. Some of the features in QGIS are actually implemented as plugins.\n26.1.1Core and External plugins\nQGIS plugins are implemented either asCore PluginsorExternal Plugins.\nCore Pluginsare maintained by the QGIS Development Team and are automatically part of every QGIS distribution.\nThey are written in one of two languages:C++orPython.\nMost of External Plugins are currently written in Python. They are stored either in the ‘Official’ QGIS Repository\nathttps://plugins.qgis.org/plugins/or in external repositories and are maintained by the individual authors. Detailed\ndocumentation about the usage, minimum QGIS version, home page, authors,and other important information are\nprovided for the plugins in the Official repository. For other external repositories, documentation might be available\nwith the external plugins themselves. External plugins documentation is not included in this manual.\nTo install or activate a plugin, go toPluginsmenu and select\nManage and install plugins.... Installed external\npython plugins are placed under thepython/pluginsfolder of the activeuser profilepath.\nPaths to Custom C++ plugins libraries can also be added underSettings►Options►System.\nNote:According to theplugin manager settings, QGIS main interface can display an icon on the right of the status\nbar to inform you that there are updates for your installed plugins or new plugins available.\n26.1.2The Plugins Dialog\nThe tabs in the Plugins dialog allow the user to install, uninstall and upgrade plugins in different ways. Each plugin\nhas some metadata displayed in the right panel:\n•information on whether the plugin is experimental\n•description\n•rating vote(s) (you can vote for your preferred plugin!)\n•tags\n•some useful links to the home page, tracker and code repository\n•author(s)\n•version available\n1327\n\nQGIS Desktop 3.22 User Guide\nAt the top of the dialog, aSearchfunction helps you find any plugin using metadata information (author, name,\ndescription...). It is available in nearly every tab (exceptSettings).\nThe Settings tab\nTheSettingstab is the main place you can configure which plugins can be displayed in your application. You can\nuse the following options:\n•Check for updates on startup. Whenever a new plugin or a plugin update is available, QGIS will inform you\n‘every time QGIS starts’, ‘once a day’, ‘every 3 days’, ‘every week’, ‘every 2 weeks’ or ‘every month’.\n•Show also experimental plugins. QGIS will show you plugins in early stages of development, which are\ngenerally unsuitable for production use.\n•Show also deprecated plugins. Because they use functions that are no longer available in QGIS, these plugins\nare set deprecated and generally unsuitable for production use. They appear among invalid plugins list.\nBy default, QGIS provides you with its official plugin repository with the URLhttps://plugins.qgis.org/plugins/\nplugins.xml?qgis=3.0(in case of QGIS 3.0) in thePlugin repositoriessection. To add external author repositories,\nclickAdd...and fill in theRepository Detailsform with a name and the URL. The URL can be ofhttp://or\nfile://protocol type.\nThe default QGIS repository is an open repository and you don’t need any authentication to access it. You can\nhowever deploy your own plugin repository and require an authentication (basic authentication, PKI). You can get\nmore information on QGIS authentication support inAuthenticationchapter.\nIf you do not want one or more of the added repositories, they can be disabled from the Settings tab via theEdit...\nbutton, or completely removed with theDeletebutton.\nFig. 26.1: TheSettingstab\n1328Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nThe All tab\nIn theAlltab, all the available plugins are listed, including both core and external plugins. UseUpgrade Allto\nlook for new versions of the plugins. Furthermore, you can useInstall Pluginif a plugin is listed but not installed,\nUninstall Pluginas well asReinstall Pluginif a plugin is installed. An installed plugin can be temporarily de/activated\nusing the checkbox.\nFig. 26.2: TheAlltab\nThe Installed tab\nIn theInstalledtab, you’ll find listed the Core plugins, that you can not uninstall. You can extend this list with\nexternal plugins that can be uninstalled and reinstalled any time, using theUninstall PluginandReinstall Pluginbuttons.\nYou canUpgrade Allthe plugins here as well.\n26.1. QGIS Plugins1329\n\nQGIS Desktop 3.22 User Guide\nFig. 26.3: TheInstalledtab\nThe Not installed tab\nTheNot installedtab lists all plugins available that are not installed. You can use theInstall Pluginbutton to\nimplement a plugin into QGIS.\nFig. 26.4: TheNot installedtab\n1330Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nThe Upgradeable and New tabs\nTheUpgradeableandNewtabs are enabled when new plugins are added to the repository or a new version\nof an installed plugin is released. If you activatedShow also experimental pluginsin theSettingsmenu, those\nalso appear in the list giving you opportunity to early test upcoming tools.\nInstallation can be done with theInstall Plugin,Upgrade PluginorUpgrade Allbuttons.\nFig. 26.5: TheUpgradeabletab\nThe Invalid tab\nTheInvalidtab lists all installed plugins that are currently broken for any reason (missing dependency, errors while\nloading, incompatible functions with QGIS version...). You can try theReinstall Pluginbutton to fix an invalidated\nplugin but most of the times the fix will be elsewhere (install some libraries, look for another compatible plugin or\nhelp to upgrade the broken one).\n26.1. QGIS Plugins1331\n\nQGIS Desktop 3.22 User Guide\nFig. 26.6: TheInvalidtab\nThe Install from ZIP tab\nTheInstall from ZIPtab provides a file selector widget to import plugins in a zipped format, e.g. plugins down-\nloaded directly from their repository.\nFig. 26.7: TheInstall from ziptab\n1332Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\n26.2Using QGIS Core Plugins\n26.2.1DB Manager Plugin\nThe DB Manager Plugin is intended to be the main tool to integrate and manage spatial database formats supported\nby QGIS (PostGIS, SpatiaLite, GeoPackage, Oracle Spatial, Virtual layers) in one user interface. The\nDB Manager\nPlugin provides several features. You can drag layers from the QGIS Browser into the DB Manager, and it will\nimport your layer into your spatial database. You can drag and drop tables between spatial databases and they will\nget imported.\nFig. 26.8: DB Manager dialog\nTheDatabasemenu allows you to connect to an existing database, to start the SQL window and to exit the DB\nManager Plugin. Once you are connected to an existing database, the menusSchema(relevant for DBMSs, such as\nPostGIS / PostgreSQL) andTablewill appear.\nTheSchemamenu includes tools to create and delete (only if empty) schemas and, if topology is available (e.g. with\nPostGIS topology), to start aTopoViewer.\nTheTablemenu allows you to create and edit tables and to delete tables and views. It is also possible to empty tables\nand to move tables between schemas. You canRun Vacuum Analyzefor the selected table.Vacuumreclaims space\nand makes it available for reuse, andanalyzeupdates statistics that is used to determine the most efficient way to\nexecute a query.Change Logging...allows you to add change logging support to a table. Finally, you canImport\n26.2. Using QGIS Core Plugins1333\n\nQGIS Desktop 3.22 User Guide\nLayer/File...andExport to File....\nNote:Using the DB Manager it is possible to add comments for tables and columns of a PostgreSQL Database.\nTheProviderswindow lists all existing databases supported by QGIS. With a double-click, you can connect to the\ndatabase. With the right mouse button, you can rename and delete existing schemas and tables. Tables can also be\nadded to the QGIS canvas with the context menu.\nIf connected to a database, themainwindow of the DB Manager offers four tabs. TheInfotab provides information\nabout the table and its geometry, as well as about existing fields, constraints and indexes. It allows you to create a\nspatial index on a the selected table. TheTabletab shows the table, and thePreviewtab renders the geometries as\npreview. When you open anSQL Window, it will be placed in a new tab.\nWorking with the SQL Window\nYou can use the DB Manager to execute SQL queries against your spatial database. Queries can be saved and loaded,\nand there theSQL Query Builderwill help you formulate your queries. You can even view spatial output by checking\nLoad as new layerand specifyingColumn(s) with unique values(IDs),Geometry columnandLayer name (prefix).\nIt is possible to highlight a portion of the SQL to only execute that portion when pressingCtrl+Ror clicking the\nExecutebutton.\nTheQuery Historybutton stores the last 20 queries of each database and provider.\nDouble clicking on an entry will add the string to the SQL window.\nFig. 26.9: Executing SQL queries in the DB Manager SQL window\n1334Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nNote:The SQL Window can also be used to create Virtual Layers. In that case, instead of selecting a database, select\nQGIS LayersunderVirtual Layersbefore opening the SQL Window. SeeCreating virtual layersfor instructions\non the SQL syntax to use.\n26.2.2Geometry Checker Plugin\nGeometry Checker is a powerful core plugin to check and fix the geometry validity of a layer. It is available from the\nVector\nmenu (\nCheck Geometries...\n).\nConfiguring the checks\nTheCheck Geometriesdialog shows different grouped settings in the first tab (Setup):\n•Input vector layers\n: to select the layers to check. A\nOnly selected features\ncheckbox can be used to restrict\nthe checking to the geometries of the selected features.\n•Allowed geometry typesgives the chance to restrict the geometry type of the input layer(s) to:\n–Point\n–Multipoint\n–Line\n–Multiline\n–Polygon\n–Multipolygon\n•Geometry validity. Depending on geometry types you can choose between:\n–Self intersections\n–Duplicate nodes\n–Self contacts\n–Polygon with less than 3 nodes.\n•Geometry properties. Depending on geometry types, different options are available:\n–Polygons and multipolygons may not contain any holes\n–Multipart objects must consist of more than one part\n–Lines must not have dangles\n•Geometry conditions. Allows you to add some condition to validate the geometries with:\n–Minimal segment length (map units)\n–Minimum angle between segment (deg)\n–Minimal polygon area (map units sqr.)\n–No sliver polygonswith aMaximum thinnessand aMax. area (map units sqr.)\n•Topology checks. Depending on geometry types, many different options are available:\n26.2. Using QGIS Core Plugins1335\n\nQGIS Desktop 3.22 User Guide\n–Checks for duplicates\n–Checks for features within other features\n–Checks for overlaps smaller than\n–Checks for gaps smaller than\n–Points must be covered by lines\n–Points must properly lie inside a polygon\n–Lines must not intersect any other lines\n–Lines must not intersect with features of layer\n–Polygons must follow boundaries of layer\n•Tolerance. You can define the tolerance of the check in map layer units.\n•Output vector layergives the choice to:\n–Modify input layer\n–Create new layers\nWhen you are happy with the configuration, you can click on theRunbutton.\n1336Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nFig. 26.10: The Geometry Checker Plugin\nTheGeometry Checker Plugincan find the following errors:\n•Self intersections: a polygon with a self intersection\n•Duplicate nodes: two duplicates nodes in a segment\n•Holes: hole in a polygon\n•Segment length: a segment length lower than a threshold\n•Minimum angle: two segments with an angle lower than a threshold\n•Minimum area: polygon area lower than a threshold\n26.2. Using QGIS Core Plugins1337\n\nQGIS Desktop 3.22 User Guide\n•Silver polygon: this error come from very small polygon (with small area) with a large perimeter\n•Duplicates features\n•Feature within feature\n•Overlaps: polygon overlapping\n•Gaps: gaps between polygons\nThe following figure shows the different checks made by the plugin.\nFig. 26.11: Some checks supported by the plugin\nAnalysing the results\nThe results appear in the second tab (Result) and as an overview layer of the errors in the canvas (its name has the\ndefault prefixchecked_). A table lists theGeometry check resultwith one error per row and columns containing:\nthe layer name, an ID, the error type, then the coordinates of the error, a value (depending on the type of the error)\nand finally the resolution column which indicates the resolution of the error. At the bottom of this table, you can\nExportthe error into different file formats. You also have a counter with the number of total errors and fixed ones.\nYou can select a row to see the location of the error. You can change this behavior by selecting another action between\nError(default),Feature,Don’t move, andHighlight selected features.\nBelow the zoom action when clicking on the table row, you can:\n•Show selected features in attribute table\n•Fix selected errors using default resolution\n•Fix selected errors, prompt for resolution methodYou will see a window to choose the resolution’s method\namong which:\n1338Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\n–Merge with neighboring polygon with longest shared edge\n–Merge with neighboring polygon with largest area\n–Merge with neighboring polygon with identical attribute value, if any, or leave as is\n–Delete feature\n–No action\n•Error resolution settingsallows you to change the default resolution method depending on the error type\nTip: Fix multiple errors\nYou can fix multiple errors by selecting more than one row in the table with theCTRL + clickaction.\nFinally, you can choose whichAttribute to use when merging features by attribute value.\n26.2.3MetaSearch Catalog Client\nIntroduction\nMetaSearch is a QGIS plugin to interact with metadata catalog services, supporting the OGC Catalog Service for the\nWeb (CSW) standard.\nMetaSearch provides an easy and intuitive approach and user-friendly interface to searching metadata catalogs within\nQGIS.\nFig. 26.12: Search and results of Services in MetaSearch\n26.2. Using QGIS Core Plugins1339\n\nQGIS Desktop 3.22 User Guide\nWorking with Metadata Catalogs in QGIS\nMetaSearch is included by default in QGIS, with all of its dependencies, and can be enabled from the QGIS Plugin\nManager.\nCSW (Catalog Service for the Web)\nCSW (Catalog Service for the Web)is anOGC (Open Geospatial Consortium)specification that defines common\ninterfaces to discover, browse and query metadata about data, services, and other potential resources.\nStartup\nTo start MetaSearch, click theicon or selectWeb►MetaSearch►MetaSearchvia the QGIS main menu. The\nMetaSearch dialog will appear. The main GUI consists of three tabs:Services,SearchandSettings.\n1340Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nManaging Catalog Services\nFig. 26.13: Managing Catalog Services\nTheServicestab allows the user to manage all available catalog services. MetaSearch provides a default list of Catalog\nServices, which can be added by pressing theAdd Default Servicesbutton.\nTo find all listed Catalog Service entries, click the dropdown select box.\nTo add a Catalog Service entry:\n1.Click theNewbutton\n2.Enter aNamefor the service, as well as theURL(endpoint). Note that only the base URL is required (not a\nfull GetCapabilities URL).\n26.2. Using QGIS Core Plugins1341\n\nQGIS Desktop 3.22 User Guide\n3.If the CSW requires authentication, enter the appropriateUser nameandPasswordcredentials.\n4.ClickOKto add the service to the list of entries.\nTo edit an existing Catalog Service entry:\n1.Select the entry you would like to edit\n2.Click theEditbutton\n3.And modify theNameorURLvalues\n4.ClickOK.\nTo delete a Catalog Service entry, select the entry you would like to delete and click theDeletebutton. You will be\nasked to confirm deleting the entry.\nMetaSearch allows loading and saving connections to an XML file. This is useful when you need to share settings\nbetween applications. Below is an example of the XML file format.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<qgsCSWConnectionsversion=\"1.0\">\n<cswname=\"Data.gov CSW\"url=\"https://catalog.data.gov/csw-all\"/>\n<cswname=\"Geonorge - National CSW service for Norway\"url=\"https://www.\n,→geonorge.no/geonetwork/srv/eng/csw\"/>\n<cswname=\"Geoportale Nazionale - Servizio di ricerca Italiano\"url=\"http://\n,→www.pcn.minambiente.it/geoportal/csw\"/>\n<cswname=\"LINZ Data Service\"url=\"http://data.linz.govt.nz/feeds/csw\"/>\n<cswname=\"Nationaal Georegister (Nederland)\"url=\"http://www.\n,→nationaalgeoregister.nl/geonetwork/srv/eng/csw\"/>\n<cswname=\"RNDT - Repertorio Nazionale dei Dati Territoriali - Servizio di␣\n,→ricerca\"url=\"http://www.rndt.gov.it/RNDT/CSW\"/>\n<cswname=\"UK Location Catalogue Publishing Service\"url=\"http://csw.data.gov.\n,→uk/geonetwork/srv/en/csw\"/>\n<cswname=\"UNEP/GRID-Geneva Metadata Catalog\"url=\"http://metadata.grid.unep.\n,→ch:8080/geonetwork/srv/eng/csw\"/>\n</qgsCSWConnections>\nTo load a list of entries:\n1.Click theLoadbutton. A new window will appear.\n2.Click theBrowsebutton and navigate to the XML file of entries you wish to load.\n3.ClickOpen. The list of entries will be displayed.\n4.Select the entries you wish to add from the list and clickLoad.\nClick theService Infobutton to display information about the selected Catalog Service such as service identification,\nservice provider and contact information. If you would like to view the raw XML response, click theGetCapabilities\nResponsebutton. A separate window will open displaying the Capabilities XML.\n1342Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nSearching Catalog Services\nFig. 26.14: Searching catalog services\nTheSearchtab allows the user to query Catalog Services for data and services, set various search parameters and\nview results.\nThe following search parameters are available:\n•Keywords: free text search keywords;\n•From: the Catalog Service to perform the query against;\n•Bounding box: the spatial area of interest to filter, defined byXmax,Xmin,Ymax, andYmin. ClickSet Global\nto do a global search, clickMap Extentto do a search in the visible area, or enter values manually.\nClicking theSearchbutton will search the selected Metadata Catalog. Search results are displayed in a list, and can be\nsorted by clicking on the column header. You can navigate through search results with the directional buttons below\nthe search results.\nSelect a result and:\n•Click theView Search Results as XMLbutton to open a window with the service response in raw XML format.\n26.2. Using QGIS Core Plugins1343\n\nQGIS Desktop 3.22 User Guide\n•If the metadata record has an associated bounding box, a footprint of the bounding box will be displayed on\nthe map.\n•Double-click the record to display the record metadata with any associated access links. Clicking a link opens\nthe link in the user’s web browser.\n•If the record is a supported web service (WMS/WMTS, WFS, WCS, ArcGIS REST Service, etc.), theAdd\nDatabutton will be enabled. When clicking this button, MetaSearch will verify if this is a valid OWS. The\nservice will then be added to the appropriate QGIS connection list, and the appropriate connection dialog will\nappear.\nFig. 26.15: Metadata record display\n1344Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nSettings\nFig. 26.16: MetaSearch settings\nYou can fine tune MetaSearch with the followingSettings:\n•Server Timeout: when searching metadata catalogs, the number of seconds for blocking connection attempt.\nDefault value is 10.\n•Disable SSL verification: option to switch off ssl verification.\n•Results paging: when searching metadata catalogs, the number of results to show per page. Default value is 10.\n26.2. Using QGIS Core Plugins1345\n\nQGIS Desktop 3.22 User Guide\nCSW Server Errors\nIn some cases, the CSW will work in a web browser, but not in MetaSearch. This may be due to the CSW server’s\nconfiguration/setup. CSW server providers should ensure URLs are consistent and up to date in their configuration\n(this is common in HTTP -> HTTPS redirection scenarios). Please see thepycsw FAQ itemfor a deeper explanation\nof the issue and fix. Although the FAQ item is pycsw specific it can also apply in general to other CSW servers.\n26.2.4Offline Editing Plugin\nFor data collection, it is a common situation to work with a laptop or a cell phone offline in the field. Upon returning\nto the network, the changes need to be synchronized with the master datasource (e.g., a PostGIS database). If several\npersons are working simultaneously on the same datasets, it is difficult to merge the edits by hand, even if people\ndon’t change the same features.\nThe\nOffline Editing\nPlugin automates the synchronisation by copying the content of the datasource to a SpatiaLite or\nGeoPackage database and storing the offline edits to dedicated tables. After being connected to the network again, it\nis possible to apply the offline edits to the master dataset.\nTo use the plugin:\n1.Open a project with some vector layers (e.g., from an Esri Shapefile, PostGIS or WFS-T datasource).\n2.Assuming you have already enabled the plugin (seeCore and External plugins) go toDatabase►Offline Editing\n►Convert to offline project. The eponym dialog opens.\n3.Select theStorage type. It can be ofGeoPackageorSpatiaLitedatabase type.\n4.Use theBrowsebutton to indicate the location of the database in which to store theOffline data. It can be an\nexisting file or one to create.\n5.In theSelect remote layerssection, check the layers you’d like to save. The content of the layers is saved to\ndatabase tables.\nnote::Since target database formats do not have native list support, the offline editing plugin transforms\n{string, number} list fields into string fields where values are separated by commas. This allows reading\nand edit of the contents of those fields when offline.\nIf you would like to handle both the field from the original layer and the offline layer, you can rely on the\ntry()andarrayexpression functions, e.g.:\ntry(array_contains(\"field\",1),array_contains(string_to_array(\"field\"),1))\n6.You can checkOnly synchronize selected features if a selection is presentallowing to only save and work on\na subset. It can be invaluable in case of large layers.\nThis is all!\n7.Save your project and bring it on the field.\n8.Edit the layers offline.\n9.After being connected again, upload the changes usingDatabase►Offline Editing►Synchronize.\nNote:Layers that are used offline are marked with theicon in theLayerspanel.\n1346Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\nFig. 26.17: Create an offline project\n26.2. Using QGIS Core Plugins1347\n\nQGIS Desktop 3.22 User Guide\n26.2.5Topology Checker Plugin\nFig. 26.18: The Topology Checker Plugin\nTopology describes the relationships between points, lines and polygons that represent the features of a geographic\nregion. With the Topology Checker plugin, you can look over your vector files and check the topology with several\ntopology rules. These rules check with spatial relations whether your features ‘Equal’, ‘Contain’, ‘Cover’, are ‘Cov-\neredBy’, ‘Cross’, are ‘Disjoint’, ‘Intersect’, ‘Overlap’, ‘Touch’ or are ‘Within’ each other. It depends on your individual\nquestions which topology rules you apply to your vector data (e.g., normally you won’t accept overshoots in line layers,\nbut if they depict dead-end streets you won’t remove them from your vector layer).\nQGIS has a built-in topological editing feature, which is great for creating new features without errors. But existing\ndata errors and user-induced errors are hard to find. This plugin helps you find such errors through a list of rules.\nIt is very simple to create topology rules with the Topology Checker plugin.\nOnpoint layersthe following rules are available:\n•Must be covered by: Here you can choose a vector layer from your project. Points that aren’t covered by the\ngiven vector layer occur in the ‘Error’ field.\n•Must be covered by endpoints of: Here you can choose a line layer from your project.\n•Must be inside: Here you can choose a polygon layer from your project. The points must be inside a polygon.\nOtherwise, QGIS writes an ‘Error’ for the point.\n•Must not have duplicates: Whenever a point is represented twice or more, it will occur in the ‘Error’ field.\n•Must not have invalid geometries: Checks whether the geometries are valid.\n•Must not have multi-part-geometries: All multi-part points are written into the ‘Error’ field.\nOnline layers, the following rules are available:\n•End points must be covered by: Here you can select a point layer from your project.\n•Must not have dangles: This will show the overshoots in the line layer.\n1348Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\n•Must not have duplicates: Whenever a line feature is represented twice or more, it will occur in the ‘Error’\nfield.\n•Must not have invalid geometries: Checks whether the geometries are valid.\n•Must not have multi-part geometries: Sometimes, a geometry is actually a collection of simple (single-part)\ngeometries. Such a geometry is called multi-part geometry. If it contains just one type of simple geometry,\nwe call it multi-point, multi-linestring or multi-polygon. All multi-part lines are written into the ‘Error’ field.\n•Must not have pseudos: A line geometry’s endpoint should be connected to the endpoints of two other\ngeometries. If the endpoint is connected to only one other geometry’s endpoint, the endpoint is called a pseudo\nnode.\nOnpolygon layers, the following rules are available:\n•Must contain: Polygon layer must contain at least one point geometry from the second layer.\n•Must not have duplicates: Polygons from the same layer must not have identical geometries. Whenever a\npolygon feature is represented twice or more it will occur in the ‘Error’ field.\n•Must not have gaps: Adjacent polygons should not form gaps between them. Administrative boundaries could\nbe mentioned as an example (US state polygons do not have any gaps between them...).\n•Must not have invalid geometries: Checks whether the geometries are valid. Some of the rules that define a\nvalid geometry are:\n–Polygon rings must close.\n–Rings that define holes should be inside rings that define exterior boundaries.\n–Rings may not self-intersect (they may neither touch nor cross one another).\n–Rings may not touch other rings, except at a point.\n•Must not have multi-part geometries: Sometimes, a geometry is actually a collection of simple (single-part)\ngeometries. Such a geometry is called multi-part geometry. If it contains just one type of simple geometry,\nwe call it multi-point, multi-linestring or multi-polygon. For example, a country consisting of multiple islands\ncan be represented as a multi-polygon.\n•Must not overlap: Adjacent polygons should not share common area.\n•Must not overlap with: Adjacent polygons from one layer should not share common area with polygons from\nanother layer.\nBelow is the list of Core plugins provided with QGIS. They are not necessarily enabled by default.\nIconPluginDescriptionManual Reference\nDB ManagerManage your databases within QGISDB Manager Plugin\nGeometry CheckerCheck and repair errors in vector geometriesGeometry Checker Plugin\nGRASS 7GRASS functionalityGRASS GIS Integration\nGRASS GIS providerGRASS GIS Processing functionalityGRASS GIS Integration\nMetaSearchCatalog\nClient\nInteract with metadata catalog services (CSW)MetaSearch Catalog Client\nOffline EditingOffline  editing  and  synchronizing  with\ndatabase\nOffline Editing Plugin\nOrfeoToolbox providerOrfeoToolbox Processing providerOTB applications provider\nProcessingSpatial data processing frameworkQGIS  processing  frame-\nwork\nSAGA GIS providerSAGA GIS Processing providerSAGA\nTopology CheckerFind topological errors in vector layersTopology Checker Plugin\n26.2. Using QGIS Core Plugins1349\n\nQGIS Desktop 3.22 User Guide\nNote:To use the Core PluginsGRASS 7,GRASS GIS provider,OrfeoToolbox provider orSAGA\nGIS provider they have to be configured. Informations can be foundhere.\n26.3QGIS Python console\nAs you will see later in this chapter, QGIS has been designed with a plugin architecture. Plugins can be written in\nPython, a very famous language in the geospatial world.\nQGIS brings a Python API (see PyQGIS Developer Cookbook for some code sample) to let the user interact with its\nobjects (layers, feature or interface). QGIS also has a Python console.\nThe QGIS Python Console is an interactive shell for the python command executions. It also has a python file editor\nthat allows you to edit and save your python scripts. Both console and editor are based on PyQScintilla2 package.\nTo open the console go toPlugins►Python Console(Ctrl+Alt+P).\n26.3.1The Interactive Console\nThe interactive console is composed of a toolbar, an input area and an output one.\nToolbar\nThe toolbar proposes the following tools:\n•\nClear Console\nto wipe the output area;\n•\nRun Command\navailable in the input area: same as pressingEnter;\n•\nShow Editor\n: toggles\nThe Code Editorvisibility;\n•\nOptions...\n: opens a dialog to configure console properties (seePython Console Settings);\n•\nHelp...\n: browses the current documentation.\nConsole\nThe console main features are:\n•Code completion, highlighting syntax and calltips for the following APIs:\n–Python\n–PyQGIS\n–PyQt5\n–QScintilla2\n–osgeo-gdal-ogr\n•Ctrl+Alt+Spaceto view the auto-completion list if enabled in thePython Console Settings;\n•Execute code snippets from the input area by typing and pressingEnterorRun Command;\n•Execute code snippets from the output area using theEnter Selectedfrom the contextual menu or pressing\nCtrl+E;\n•Browse the command history from the input area using theUpandDownarrow keys and execute the command\nyou want;\n1350Chapter 26. Plugins\n\nQGIS Desktop 3.22 User Guide\n•Ctrl+Shift+Spaceto view the command history: double-clicking a row will execute the command. The\nCommand Historydialog can also be accessed from context menu of input area;\n•Save and clear the command history. The history will be saved into theconsole_history.txtfile under\nthe activeuser profilefolder;\n•OpenQGIS C++ APIdocumentation by typing_api;\n•OpenQGIS Python APIdocumentation by typing_pyqgis.\n•Open PyQGIS Cookbook by typing_cookbook.\nTip: Reuse executed commands from the output panel\nYou can execute code snippets from the output panel by selecting some text and pressingCtrl+E. No matter if\nselected text contains the interpreter prompt (>>>,...).\nFig. 26.19: The Python Console\n26.3.2The Code Editor\nUse the\nShow Editor\nbutton to enable the editor widget. It allows editing and saving Python files and offers advanced\nfunctionalities to manage your code (comment and uncomment code, check syntax, share the code via GitHub and\nmuch more). Main features are:\n•Code completion, highlighting syntax and calltips for the following APIs:\n–Python\n–PyQGIS\n–PyQt5\n–QScintilla2\n–osgeo-gdal-ogr\n•Ctrl+Spaceto view the auto-completion list.\n•Sharing code snippets viaGitHub.\n•Ctrl+4Syntax check.\n•Search bar (open it with the default Desktop Environment shortcut, usuallyCtrl+F):\n–Use the default Desktop Environment shortcut to find next/previous (Ctrl+GandShift+Ctrl+G);\n–Automatically find first match when typing in find box;\n26.3. QGIS Python console1351\n\nQGIS Desktop 3.22 User Guide\n–Set initial find string to selection when opening find;\n–PressingEsccloses the find bar.\n•Object inspector: a class and function browser;\n•Go to an object definition with a mouse click (from Object inspector);\n•Execute code snippets with theRun Selectedcommand in contextual menu;\n•Execute the whole script with theRun Scriptcommand (this creates a byte-compiled file with the extension\n.pyc).\nNote:Running partially or totally a script from theCode Editoroutputs the result in the Console output area.\nFig. 26.20: The Python Console editor\nTip: Save the options\nTo save the state of console’s widgets you have to close the Python Console from the close button. This allows you\nto save the geometry to be restored to the next start.\n1352Chapter 26. Plugins\n\nCHAPTER\nTWENTYSEVEN\nHELP AND SUPPORT\n27.1Mailing lists\nQGIS is under active development and as such it won’t always work like you expect it to. The preferred way to get\nhelp is by joining the qgis-users mailing list. Your questions will reach a broader audience and answers will benefit\nothers.\n27.1.1QGIS Users\nThis mailing list is used for discussion about QGIS in general, as well as specific questions regarding its installation and\nuse. You can subscribe to the qgis-users mailing list by visiting the following URL:https://lists.osgeo.org/mailman/\nlistinfo/qgis-user\n27.1.2QGIS Developers\nIf you are a developer facing problems of a more technical nature, you may want to join the qgis-developer mailing\nlist. This list is also a place where people can chime in and collect and discuss QGIS related UX (User Experience)\n/ usability issues. It’s here:https://lists.osgeo.org/mailman/listinfo/qgis-developer\n27.1.3QGIS Community Team\nThis list deals with topics like documentation, context help, user guide, web sites, blog, mailing lists, forums, and\ntranslation efforts. If you would like to work on the user guide as well, this list is a good starting point to ask your\nquestions. You can subscribe to this list at:https://lists.osgeo.org/mailman/listinfo/qgis-community-team\n27.1.4QGIS Translations\nThis list deals with the translation efforts. If you like to work on the translation of the website, manuals or the\ngraphical user interface (GUI), this list is a good starting point to ask your questions. You can subscribe to this list\nat:\nhttps://lists.osgeo.org/mailman/listinfo/qgis-tr\n1353\n\nQGIS Desktop 3.22 User Guide\n27.1.5QGIS Project Steering Committee (PSC)\nThis list is used to discuss Steering Committee issues related to overall management and direction of QGIS. You can\nsubscribe to this list at:https://lists.osgeo.org/mailman/listinfo/qgis-psc\n27.1.6QGIS User groups\nInordertolocallypromoteQGISandcontributetoitsdevelopment, someQGIScommunitiesareorganizedintoQGIS\nUser Groups. These groups are places to discuss local topics, organize regional or national user meetings, organize\nsponsoring of features... The list of current user groups is available athttps://qgis.org/en/site/forusers/usergroups.\nhtml\nYou are welcome to subscribe to any of the lists. Please remember to contribute to the list by answering questions\nand sharing your experiences.\n27.2IRC\nWe also maintain a presence on IRC - visit us by joining the #qgis channel on irc.freenode.net. Please wait for a\nresponse to your question, as many folks on the channel are doing other things and it may take a while for them to\nnotice your question. If you missed a discussion on IRC, not a problem! We log all discussion, so you can easily\ncatch up. Just go tohttp://irclogs.geoapt.com/qgis/and read the IRC-logs.\n27.3Commercial support\nCommercial support for QGIS is also available. Check the websitehttps://qgis.org/en/site/forusers/commercial_\nsupport.htmlfor more information.\n27.4BugTracker\nWhile the qgis-users mailing list is useful for general ‘How do I do XYZ in QGIS?’-type questions, you may wish to\nnotify us about bugs in QGIS. You can submit bug reports using theQGIS bug tracker.\nPlease bear in mind that your bug may not always enjoy the priority you might hope for (depending on its severity).\nSome bugs may require significant developer effort to remedy, and the manpower is not always available for this.\nFeature requests can be submitted as well using the same ticket system as for bugs. Please make sure to select the\ntypeFeature request.\nIf you have found a bug and fixed it yourself, you can submit a Pull Request on theGithub QGIS Project.\nReadBugs, Features and Issuesand submit_patch for more details.\n27.5Blog\nThe QGIS community also runs a weblog athttps://plugins.qgis.org/planet/, which has some interesting articles for\nusers and developers. Many other QGIS blogs exist, and you are invited to contribute with your own QGIS blog!\n1354Chapter 27. Help and Support\n\nQGIS Desktop 3.22 User Guide\n27.6Plugins\nThe websitehttps://plugins.qgis.orgis the official QGIS plugins web portal. Here, you find a list of all stable and\nexperimental QGIS plugins available via the ‘Official QGIS Plugin Repository’.\n27.7Wiki\nLastly, we maintain a WIKI web site athttps://github.com/qgis/QGIS/wikiwhere you can find a variety of useful\ninformation relating to QGIS development, release plans, links to download sites, message-translation hints and more.\nCheck it out, there are some goodies inside!\n27.6. Plugins1355\n\nQGIS Desktop 3.22 User Guide\n1356Chapter 27. Help and Support\n\nCHAPTER\nTWENTYEIGHT\nCONTRIBUTORS\nQGIS is an open source project developed by a team of dedicated volunteers and organisations. We strive to be a\nwelcoming community for people of all race, creed, gender and walks of life. At any moment, you canget involved.\n28.1Authors\nBelow are listed people who dedicate their time and energy to write, review, and update the whole QGIS documen-\ntation.\nTim SuttonYves JacolinJacob LanstorpGary E. ShermanRichard Duivenvoorde\nTara AthanAnita GraserArnaud MorvanGavin MacaulayLuca Casagrande\nK. KoyHugo MercierAkbar GumbiraMarie SilvestreJürgen E. Fischer\nFran RagaEric GoddardMartin DobiasDiethard JansenSaber Razmjooei\nKo NagaseNyall DawsonMatthias KuhnAndreas NeumannHarrissou Sant-anna\nManel ClosDavid WillisLarissa JunekPaul BlottièreSebastian Dietrich\nChris MayoStephan HollMagnus HomannBernhard StröblAlessandro Pasotti\nN. HorningRadim BlazekJoshua ArnottLuca ManganelliMarco Hugentobler\nAndre ManoMie WinstrupFrank SokolicVincent PicavetJean-Roc Morreale\nAndy AllanVictor OlayaTyler MitchellRené-Luc D’HontMarco Bernasocchi\nIlkka RinneWerner MachoChris BerkhoutNicholas DugganJonathan Willitts\nDavid AdlerLars LuthmanBrendan MorelyRaymond NijssenCarson J.Q. Farmer\nJaka KranjcMezene WorkuPatrick SunterSteven CordwellStefan Blumentrath\nAndy SchmidVincent MoraAlexandre NetoHien Tran-QuangAlexandre Busquets\nJoão GasparTom KralidisAlexander BruyPaolo CavalliniMilo Van der Linden\nPeter ErstsUjaval GandhiDominic KellerGiovanni ManghiMaximilian Krambach\nAnne GhislaDick GroskampUros PreloznikStéphane BrunnerQGIS Korean Translator\nZoltan SikiHåvard TveiteMatteo GhettaSalvatore LarosaKonstantinos Nikolaou\nTom ChadwinLarry ShafferNathan WoodrowMartina SavareseGodofredo Contreras\nAstrid EmdeLuigi PirelliThomas GratierGiovanni AllegriGiordanoPezzola\nPaolo CortiTudor BărăscuManing SambaleClaudia A. EngelYoichi Kayama\nOtto DassauDenis RouzaudNick Bearmanembeldingajazepk\nRamonAndreizstadlericephaleRosa Aguilar\nPatrice PineaultJörn GutzeitFelix FecklerBenoît de MezzoÉtienne Trimaille\nAndrea GiudiceandreaJulien Cabiecesroya0045Sebastian GutweinJessica Veenstra\nRyan WelfleMartin PerglerIvan IvanovmuranamihdkLoïc Bartoletti\nTomasz TaraśIan MaddausJürnjakob DuggeRoman BugDamiano Lombardi\nMarc DucobuPhilip AlbrechtDennis MilechinCody MartinSavinaud Mickaël\nStefan UhrigAriadni-Karolina AlexiouBjörn HinkeldeyBenjamin RileyMorriganR\nThayer YoungShane CareyIan TurtonEmma HainGermán Carrillo\nJakob MikschNicolas BoisteaultBertrand RixJorge Rosales\n1357\n\nQGIS Desktop 3.22 User Guide\n28.2Translators\nQGIS is a multi-language application and as is, also publishes a documentation translated into several languages.\nMany other languages are being translated and would be released as soon as they reach a reasonable percentage\nof translation. If you wish to help improving a language or request a new one, please seehttps://qgis.org/en/site/\ngetinvolved/index.html.\nThe current translations are made possible thanks to:\nLanguageContributors\nBahasa   In-\ndonesia\nEmir Hartato, I Made Anombawa, Januar V. Simarmata, Muhammad Iqnaul Haq Siregar, Trias\nAditya\nChinese (Tra-\nditional)\nCalvin Ngei, Zhang Jun, Richard Xie\nChinese (Sim-\nplified)\nXu Baocai\nDutchCarlo van Rijswijk, Dick Groskamp, Diethard Jansen, Raymond Nijssen, Richard Duivenvo-\norde, Willem Hoffman\nFinnishMatti Mäntynen, Kari Mikkonen\nFrenchArnaud Morvan, Augustin Roche, Didier Vanden Berghe, Dofabien, Etienne Trimaille, Francis\nGasc, Harrissou Sant-anna, Jean-Roc Morreale, Jérémy Garniaux, Loïc Buscoz, Lsam, Marc-\nAndré Saia, Marie Silvestre, Mathieu Bossaert, Mathieu Lattes, Mayeul Kauffmann, Médéric\nRibreux, Mehdi Semchaoui, Michael Douchin, Nicolas Boisteault, Nicolas Rochard, Pascal Ob-\nstetar, Robin Prest, Rod Bera, Stéphane Henriod, Stéphane Possamai, sylther, Sylvain Badey,\nSylvain Maillard, Vincent Picavet, Xavier Tardieu, Yann Leveille-Menez, yoda89\nGalicianXan Vieiro\nGermanJürgen E. Fischer, Otto Dassau, Stephan Holl, Werner Macho\nHindiHarish Kumar Solanki\nItalianAlessandro Fanna, Anne Ghisla, Flavio Rigolon, Giuliano Curti, Luca Casagrande, Luca Deluc-\nchi, Marco Braida, Matteo Ghetta, Maurizio Napolitano, Michele Beneventi, Michele Ferretti,\nRoberto Angeletti, Paolo Cavallini, Stefano Campus\nJapaneseBaba Yoshihiko, Minoru Akagi, Norihiro Yamate, Takayuki Mizutani, Takayuki Nuimura,\nYoichi Kayama\nKoreanOSGeo Korean Chapter\nPolishAndrzej Świąder, Borys Jurgiel, Ewelina Krawczak, Jakub Bobrowski, Mateusz Łoskot, Michał\nKułach, Michał Smoczyk, Milena Nowotarska, Radosław Pasiok, Robert Szczepanek, Tomasz\nPaul\nPortugueseAlexandre Neto, Duarte Carreira, Giovanni Manghi, João Gaspar, Joana Simões, Leandro In-\nfantini, Nelson Silva, Pedro Palheiro, Pedro Pereira, Ricardo Sena\nPortuguese\n(Brasil)\nArthur Nanni, Felipe Sodré Barros, Leônidas Descovi Filho, Marcelo Soares Souza, Narcélio\nde Sá Pereira Filho, Sidney Schaberle Goveia\nRomanianAlex Bădescu, Bogdan Pacurar, Georgiana Ioanovici, Lonut Losifescu-Enescu, Sorin Călinică,\nTudor Bărăscu\nRussianAlexander Bruy, Artem Popov\nSpanishCarlos Dávila, Diana Galindo, Edwin Amado, Gabriela Awad, Javier César Aldariz, Mayeul\nKauffmann, Fran Raga\nUkrainianAlexander Bruy\n1358Chapter 28. Contributors\n\nQGIS Desktop 3.22 User Guide\n28.3Statistics of translation\nEfforts of translation for QGIS 3.22 Long Term Release are provided below. Only languages that reached 5% by the\nversion release time are published here.\nLast update: 2023-03-19\nNumber of stringsNumber of target languagesOverall Translation ratio\n337705814.26%\nLanguageTranslation ratio\n(%)\nLanguageTranslation ratio\n(%)\nLanguageTranslation ratio\n(%)\nAlbanian0.21Arabic3.69Azerbaijani0.02\nBasque0.82Bengali0.16Bulgarian2.34\nBurmese0.09Catalan1.38Chinese  Sim-\nplified\n19.72\nChinese  Tradi-\ntional\n0.58Croatian0.1Czech5.36\nDanish0.62Dutch100.0Estonian1.28\nFinnish1.65French89.3Galician0.43\nGeorgian0.09German23.37Greek0.35\nHebrew0.7Hindi0.28Hungarian17.39\nIgbo0.01Indonesian2.59Italian99.99\nJapanese75.85Kabyle0.09Korean75.95\nLithuanian6.58Macedonian0.11Malay0.04\nMalayalam0.09Marathi0.18Mongolian0.1\nN’ko1.69Norwegian\nBokmål\n2.94Panjabi (Pun-\njabi)\n0.0\nPersian0.39Polish1.66Portuguese\n(Brazil)\n74.82\nPortuguese (Por-\ntugal)\n7.68Romanian40.08Russian12.41\nSerbian0.1Slovak1.2Slovenian2.96\nSpanish100.0Swedish0.93Tagalog0.09\nTamil0.45Telugu0.03Thai0.1\nTurkish2.66Ukrainian2.16Urdu0.0\nVietnamese0.22\n28.3. Statistics of translation1359\n\nQGIS Desktop 3.22 User Guide\n1360Chapter 28. Contributors\n\nCHAPTER\nTWENTYNINE\nAPPENDICES\n29.1Appendix A: GNU General Public License\nVersion 2, June 1991\nCopyright (C) 1989, 1991 Free Software Foundation, Inc. 59 Temple Place - Suite 330, Boston, MA 02111-1307,\nUSA\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nPreamble\nThe licenses for most software are designed to take away your freedom to share and change it. By contrast, the\nGNU General Public License is intended to guarantee your freedom to share and change free software–to make sure\nthe software is free for all its users. This General Public License applies to most of the Free Software Foundation’s\nsoftware and to any other program whose authors commit to using it. (Some other Free Software Foundation software\nis covered by the GNU Library General Public License instead.) You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed\nto make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish),\nthat you receive source code or can get it if you want it, that you can change the software or use pieces of it in new\nfree programs; and that you know you can do these things.\nTo protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to\nsurrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the\nsoftware, or if you modify it.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all\nthe rights that you have. You must make sure that they, too, receive or can get the source code. And you must show\nthem these terms so they know their rights.\nWe protect your rights with two steps: (1) copyright the software, and (2) offer you this license which gives you legal\npermission to copy, distribute and/or modify the software.\nAlso, for each author’s protection and ours, we want to make certain that everyone understands that there is no\nwarranty for this free software. If the software is modified by someone else and passed on, we want its recipients to\nknow that what they have is not the original, so that any problems introduced by others will not reflect on the original\nauthors’ reputations.\nFinally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors\nof a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this,\nwe have made it clear that any patent must be licensed for everyone’s free use or not licensed at all.\nThe precise terms and conditions for copying, distribution and modification follow. TERMS AND CONDITIONS\nFOR COPYING, DISTRIBUTION AND MODIFICATION\n0.This License applies to any program or other work which contains a notice placed by the copyright holder\nsaying it may be distributed under the terms of this General Public License. The “Program”, below, refers to\nany such program or work, and a “work based on the Program” means either the Program or any derivative\nwork under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim\n1361\n\nQGIS Desktop 3.22 User Guide\nor with modifications and/or translated into another language. (Hereinafter, translation is included without\nlimitation in the term “modification”.) Each licensee is addressed as “you”.\nActivities other than copying, distribution and modification are not covered by this License; they are outside its\nscope. The act of running the Program is not restricted, and the output from the Program is covered only if its\ncontents constitute a work based on the Program (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n1.You may copy and distribute verbatim copies of the Program’s source code as you receive it, in any medium,\nprovided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and\ndisclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License along with the Program.\nYou may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty\nprotection in exchange for a fee.\n2.You may modify your copy or copies of the Program or any portion of it, thus forming a work based on the\nProgram, and copy and distribute such modifications or work under the terms of Section 1 above, provided\nthat you also meet all of these conditions:\na)You must cause the modified files to carry prominent notices stating that you changed the files and the\ndate of any change.\nb)You must cause any work that you distribute or publish, that in whole or in part contains or is derived\nfrom the Program or any part thereof, to be licensed as a whole at no charge to all third parties under the\nterms of this License.\nc)If the modified program normally reads commands interactively when run, you must cause it, when started\nrunning for such interactive use in the most ordinary way, to print or display an announcement including\nan appropriate copyright notice and a notice that there is no warranty (or else, saying that you provide a\nwarranty) and that users may redistribute the program under these conditions, and telling the user how to\nview a copy of this License. (Exception: if the Program itself is interactive but does not normally print\nsuch an announcement, your work based on the Program is not required to print an announcement.)\nThese requirements apply to the modified work as a whole. If identifiable sections of that work are not derived\nfrom the Program, and can be reasonably considered independent and separate works in themselves, then this\nLicense, and its terms, do not apply to those sections when you distribute them as separate works. But when\nyou distribute the same sections as part of a whole which is a work based on the Program, the distribution\nof the whole must be on the terms of this License, whose permissions for other licensees extend to the entire\nwhole, and thus to each and every part regardless of who wrote it.\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you;\nrather, the intent is to exercise the right to control the distribution of derivative or collective works based on\nthe Program.\nIn addition, mere aggregation of another work not based on the Program with the Program (or with a work\nbased on the Program) on a volume of a storage or distribution medium does not bring the other work under\nthe scope of this License.\n3.You may copy and distribute the Program (or a work based on it, under Section 2) in object code or executable\nform under the terms of Sections 1 and 2 above provided that you also do one of the following:\na)Accompany it with the complete corresponding machine-readable source code, which must be distributed\nunder the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\nb)Accompany it with a written offer, valid for at least three years, to give any third party, for a charge no\nmore than your cost of physically performing source distribution, a complete machine-readable copy of\nthe corresponding source code, to be distributed under the terms of Sections 1 and 2 above on a medium\ncustomarily used for software interchange; or,\nc)Accompany it with the information you received as to the offer to distribute corresponding source code.\n(This alternative is allowed only for noncommercial distribution and only if you received the program in\nobject code or executable form with such an offer, in accord with Subsection b above.)\nThe source code for a work means the preferred form of the work for making modifications to it. For an\nexecutable work, complete source code means all the source code for all modules it contains, plus any associated\n1362Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\ninterfacedefinitionfiles, plusthescriptsusedtocontrolcompilationandinstallationoftheexecutable. However,\nas a special exception, the source code distributed need not include anything that is normally distributed (in\neither source or binary form) with the major components (compiler, kernel, and so on) of the operating system\non which the executable runs, unless that component itself accompanies the executable.\nIf distribution of executable or object code is made by offering access to copy from a designated place, then\noffering equivalent access to copy the source code from the same place counts as distribution of the source\ncode, even though third parties are not compelled to copy the source along with the object code.\n4.You may not copy, modify, sublicense, or distribute the Program except as expressly provided under this\nLicense. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will auto-\nmatically terminate your rights under this License. However, parties who have received copies, or rights, from\nyou under this License will not have their licenses terminated so long as such parties remain in full compliance.\n5.You are not required to accept this License, since you have not signed it. However, nothing else grants you\npermission to modify or distribute the Program or its derivative works. These actions are prohibited by law if\nyou do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and all its terms and conditions for copying,\ndistributing or modifying the Program or works based on it.\n6.Each time you redistribute the Program (or any work based on the Program), the recipient automatically re-\nceives a license from the original licensor to copy, distribute or modify the Program subject to these terms\nand conditions. You may not impose any further restrictions on the recipients’ exercise of the rights granted\nherein. You are not responsible for enforcing compliance by third parties to this License.\n7.If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not\nlimited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that\ncontradict the conditions of this License, they do not excuse you from the conditions of this License. If you\ncannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent\nobligations, then as a consequence you may not distribute the Program at all. For example, if a patent license\nwould not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly\nthrough you, then the only way you could satisfy both it and this License would be to refrain entirely from\ndistribution of the Program.\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of\nthe section is intended to apply and the section as a whole is intended to apply in other circumstances.\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to\ncontest validity of any such claims; this section has the sole purpose of protecting the integrity of the free soft-\nware distribution system, which is implemented by public license practices. Many people have made generous\ncontributions to the wide range of software distributed through that system in reliance on consistent application\nof that system; it is up to the author/donor to decide if he or she is willing to distribute software through any\nother system and a licensee cannot impose that choice.\nThis section is intended to make thoroughly clear what is believed to be a consequence of the rest of this\nLicense.\n8.If the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted\ninterfaces, the original copyright holder who places the Program under this License may add an explicit geo-\ngraphical distribution limitation excluding those countries, so that distribution is permitted only in or among\ncountries not thus excluded. In such case, this License incorporates the limitation as if written in the body of\nthis License.\n9.The Free Software Foundation may publish revised and/or new versions of the General Public License from\ntime to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address\nnew problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies a version number of this License\nwhich applies to it and “any later version”, you have the option of following the terms and conditions either of\nthat version or of any later version published by the Free Software Foundation. If the Program does not specify\na version number of this License, you may choose any version ever published by the Free Software Foundation.\n10.If you wish to incorporate parts of the Program into other free programs whose distribution conditions are\ndifferent, write to the author to ask for permission. For software which is copyrighted by the Free Software\n29.1. Appendix A: GNU General Public License1363\n\nQGIS Desktop 3.22 User Guide\nFoundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will\nbe guided by the two goals of preserving the free status of all derivatives of our free software and of promoting\nthe sharing and reuse of software generally.\nNO WARRANTY\n11.BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE\nPROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE\nSTATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE\nPROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED,\nINCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFOR-\nMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU\nASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n12.IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL\nANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDIS-\nTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, IN-\nCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO\nLOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU\nOR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PRO-\nGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY\nOF SUCH DAMAGES.\nQGIS Qt exception for GPL\nIn addition, as a specialexception, theQGIS Development Teamgivespermission to linkthe codeof thisprogramwith\nthe Qt library, including but not limited to the following versions (both free and commercial): Qt/Non-commercial\nWindows, Qt/Windows, Qt/X11, Qt/Mac, and Qt/Embedded (or with modified versions of Qt that use the same\nlicense as Qt), and distribute linked combinations including the two. You must obey the GNU General Public License\nin all respects for all of the code used other than Qt. If you modify this file, you may extend this exception to your\nversion of the file, but you are not obligated to do so. If you do not wish to do so, delete this exception statement\nfrom your version.\n29.2Appendix B: GNU Free Documentation License\nVersion 1.3, 3 November 2008\nCopyright 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc\nhttps://www.fsf.org/\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nPreamble\nThe purpose of this License is to make a manual, textbook, or other functional and useful document “free” in the\nsense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it,\neither commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to\nget credit for their work, while not being considered responsible for modifications made by others.\nThis License is a kind of “copyleft”, which means that derivative works of the document must themselves be free\nin the same sense. It complements the GNU General Public License, which is a copyleft license designed for free\nsoftware.\nWe have designed this License in order to use it for manuals for free software, because free software needs free\ndocumentation: a free program should come with manuals providing the same freedoms that the software does. But\nthis License is not limited to software manuals; it can be used for any textual work, regardless of subject matter\nor whether it is published as a printed book. We recommend this License principally for works whose purpose is\ninstruction or reference.\n1. APPLICABILITY AND DEFINITIONS\n1364Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nThis License applies to any manual or other work, in any medium, that contains a notice placed by the copyright\nholder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free\nlicense, unlimited in duration, to use that work under the conditions stated herein. TheDocument, below, refers to\nany such manual or work. Any member of the public is a licensee, and is addressed as “you”. You accept the license\nif you copy, modify or distribute the work in a way requiring permission under copyright law.\nA “Modified Version” of the Document means any work containing the Document or a portion of it, either copied\nverbatim, or with modifications and/or translated into another language.\nA “Secondary Section” is a named appendix or a front-matter section of the Document that deals exclusively with\nthe relationship of the publishers or authors of the Document to the Document’s overall subject (or to related matters)\nand contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of\nmathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical\nconnection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position\nregarding them.\nThe “Invariant Sections” are certain Secondary Sections whose titles are designated, as being those of Invariant\nSections, in the notice that says that the Document is released under this License. If a section does not fit the above\ndefinition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant\nSections. If the Document does not identify any Invariant Sections then there are none.\nThe “Cover Texts” are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in\nthe notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words,\nand a Back-Cover Text may be at most 25 words.\nA “Transparent” copy of the Document means a machine-readable copy, represented in a format whose specification\nis available to the general public, that is suitable for revising the document straightforwardly with generic text editors\nor (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor,\nand that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input\nto text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has\nbeen arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not\nTransparent if used for any substantial amount of text. A copy that is not “Transparent” is calledOpaque.\nExamples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format,\nLaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML,\nPostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and\nJPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors,\nSGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated\nHTML, PostScript or PDF produced by some word processors for output purposes only.\nThe “Title Page” means, for a printed book, the title page itself, plus such following pages as are needed to hold,\nlegibly, the material this License requires to appear in the title page. For works in formats which do not have any\ntitle page as such, “Title Page” means the text near the most prominent appearance of the work’s title, preceding the\nbeginning of the body of the text.\nThe “publisher” means any person or entity that distributes copies of the Document to the public.\nA section “Entitled XYZ” means a named subunit of the Document whose title either is precisely XYZ or contains\nXYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific sec-\ntion name mentioned below, such as “Acknowledgements”, “Dedications”, “Endorsements”, or “History”.) To\n“Preserve the Title” of such a section when you modify the Document means that it remains a section “Entitled\nXYZ” according to this definition.\nThe Document may include Warranty Disclaimers next to the notice which states that this License applies to the\nDocument. These Warranty Disclaimers are considered to be included by reference in this License, but only as\nregards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no\neffect on the meaning of this License.\n2. VERBATIM COPYING\nYou may copy and distribute the Document in any medium, either commercially or noncommercially, provided that\nthis License, the copyright notices, and the license notice saying this License applies to the Document are reproduced\nin all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical\nmeasures to obstruct or control the reading or further copying of the copies you make or distribute. However, you\n29.2. Appendix B: GNU Free Documentation License1365\n\nQGIS Desktop 3.22 User Guide\nmay accept compensation in exchange for copies. If you distribute a large enough number of copies you must also\nfollow the conditions in section 3.\nYou may also lend copies, under the same conditions stated above, and you may publicly display copies.\n3. COPYING IN QUANTITY\nIf you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering\nmore than 100, and the Document’s license notice requires Cover Texts, you must enclose the copies in covers that\ncarry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the\nback cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover\nmust present the full title with all words of the title equally prominent and visible. You may add other material on\nthe covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document\nand satisfy these conditions, can be treated as verbatim copying in other respects.\nIf the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as\nfit reasonably) on the actual cover, and continue the rest onto adjacent pages.\nIf you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a\nmachine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-\nnetwork location from which the general network-using public has access to download using public-standard network\nprotocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you\nmust take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this\nTransparent copy will remain thus accessible at the stated location until at least one year after the last time you\ndistribute an Opaque copy (directly or through your agents or retailers) of that edition to the public.\nIt is requested, but not required, that you contact the authors of the Document well before redistributing any large\nnumber of copies, to give them a chance to provide you with an updated version of the Document.\n4. MODIFICATIONS\nYou may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above,\nprovided that you release the Modified Version under precisely this License, with the Modified Version filling the role\nof the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy\nof it. In addition, you must do these things in the Modified Version:\nA.Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of\nprevious versions (which should, if there were any, be listed in the History section of the Document). You may\nuse the same title as a previous version if the original publisher of that version gives permission.\nB.List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications\nin the Modified Version, together with at least five of the principal authors of the Document (all of its principal\nauthors, if it has fewer than five), unless they release you from this requirement.\nC.State on the Title page the name of the publisher of the Modified Version, as the publisher.\nD.Preserve all the copyright notices of the Document.\nE.Add an appropriate copyright notice for your modifications adjacent to the other copyright notices.\nF.Include, immediately after the copyright notices, a license notice giving the public permission to use the Mod-\nified Version under the terms of this License, in the form shown in the Addendum below.\nG.Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Docu-\nment’s license notice.\nH.Include an unaltered copy of this License.\nI.Preserve the section Entitled “History”, Preserve its Title, and add to it an item stating at least the title, year,\nnew authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled\n“History” in the Document, create one stating the title, year, authors, and publisher of the Document as given\non its Title Page, then add an item describing the Modified Version as stated in the previous sentence.\nJ.Preserve the network location, if any, given in the Document for public access to a Transparent copy of the\nDocument, and likewise the network locations given in the Document for previous versions it was based on.\nThese may be placed in the “History” section. You may omit a network location for a work that was published\n1366Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nat least four years before the Document itself, or if the original publisher of the version it refers to gives\npermission.\nK.For any section Entitled “Acknowledgements” or “Dedications”, Preserve the Title of the section, and preserve\nin the section all the substance and tone of each of the contributor acknowledgements and/or dedications given\ntherein.\nL.Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers\nor the equivalent are not considered part of the section titles.\nM.Delete any section Entitled “Endorsements”. Such a section may not be included in the Modified Version.\nN.Do not retitle any existing section to be Entitled “Endorsements” or to conflict in title with any Invariant Section.\nO.Preserve any Warranty Disclaimers.\nIf the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and\ncontain no material copied from the Document, you may at your option designate some or all of these sections as\ninvariant. To do this, add their titles to the list of Invariant Sections in the Modified Version’s license notice. These\ntitles must be distinct from any other section titles.\nYou may add a section Entitled “Endorsements”, provided it contains nothing but endorsements of your Modified\nVersion by various parties—for example, statements of peer review or that the text has been approved by an organi-\nzation as the authoritative definition of a standard.\nYou may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover\nText, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one\nof Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already\nincludes a cover text for the same cover, previously added by you or by arrangement made by the same entity you\nare acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the\nprevious publisher that added the old one.\nThe author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity\nfor or to assert or imply endorsement of any Modified Version.\n5. COMBINING DOCUMENTS\nYou may combine the Document with other documents released under this License, under the terms defined in section\n4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the\noriginal documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice,\nand that you preserve all their Warranty Disclaimers.\nThe combined work need only contain one copy of this License, and multiple identical Invariant Sections may be\nreplaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make\nthe title of each such section unique by adding at the end of it, in parentheses, the name of the original author or\npublisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list\nof Invariant Sections in the license notice of the combined work.\nIn the combination, you must combine any sections Entitled “History” in the various original documents, forming one\nsection Entitled “History”; likewise combine any sections Entitled “Acknowledgements”, and any sections Entitled\n“Dedications”. You must delete all sections Entitled “Endorsements”.\n6. COLLECTIONS OF DOCUMENTS\nYou may make a collection consisting of the Document and other documents released under this License, and replace\nthe individual copies of this License in the various documents with a single copy that is included in the collection,\nprovided that you follow the rules of this License for verbatim copying of each of the documents in all other respects.\nYou may extract a single document from such a collection, and distribute it individually under this License, provided\nyou insert a copy of this License into the extracted document, and follow this License in all other respects regarding\nverbatim copying of that document.\n7. AGGREGATION WITH INDEPENDENT WORKS\nA compilation of the Document or its derivatives with other separate and independent documents or works, in or on\na volume of a storage or distribution medium, is called an “aggregate” if the copyright resulting from the compilation\nis not used to limit the legal rights of the compilation’s users beyond what the individual works permit. When the\n29.2. Appendix B: GNU Free Documentation License1367\n\nQGIS Desktop 3.22 User Guide\nDocument is included in an aggregate, this License does not apply to the other works in the aggregate which are not\nthemselves derivative works of the Document.\nIf the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less\nthan one half of the entire aggregate, the Document’s Cover Texts may be placed on covers that bracket the Document\nwithin the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they\nmust appear on printed covers that bracket the whole aggregate.\n8. TRANSLATION\nTranslation is considered a kind of modification, so you may distribute translations of the Document under the terms\nof section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders,\nbut you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant\nSections. You may include a translation of this License, and all the license notices in the Document, and any Warranty\nDisclaimers, provided that you also include the original English version of this License and the original versions of\nthose notices and disclaimers. In case of a disagreement between the translation and the original version of this\nLicense or a notice or disclaimer, the original version will prevail.\nIf a section in the Document is Entitled “Acknowledgements”, “Dedications”, or “History”, the requirement (section\n4) to Preserve its Title (section 1) will typically require changing the actual title.\n9. TERMINATION\nYou may not copy, modify, sublicense, or distribute the Document except as expressly provided under this License.\nAny attempt otherwise to copy, modify, sublicense, or distribute it is void, and will automatically terminate your\nrights under this License.\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently,\nif the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies\nyou of the violation by some reasonable means, this is the first time you have received notice of violation of this\nLicense (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of\nthe notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or\nrights from you under this License. If your rights have been terminated and not permanently reinstated, receipt of a\ncopy of some or all of the same material does not give you any rights to use it.\n10. FUTURE REVISIONS OF THIS LICENSE\nThe Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from\ntime to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new\nproblems or concerns. See\nhttp://www.gnu.org/copyleft/.\nEach version of the License is given a distinguishing version number. If the Document specifies that a particular\nnumbered version of this License “or any later version” applies to it, you have the option of following the terms\nand conditions either of that specified version or of any later version that has been published (not as a draft) by the\nFree Software Foundation. If the Document does not specify a version number of this License, you may choose any\nversion ever published (not as a draft) by the Free Software Foundation. If the Document specifies that a proxy can\ndecide which future versions of this License can be used, that proxy’s public statement of acceptance of a version\npermanently authorizes you to choose that version for the Document.\n11. RELICENSING\n“Massive Multiauthor Collaboration Site” (or “MMC Site”) means any World Wide Web server that publishes copy-\nrightable works and also provides prominent facilities for anybody to edit those works. A public wiki that anybody\ncan edit is an example of such a server. A “Massive Multiauthor Collaboration” (or “MMC”) contained in the site\nmeans any set of copyrightable works thus published on the MMC site.\n“CC-BY-SA” means the Creative Commons Attribution-Share Alike 3.0 license published by Creative Commons\nCorporation, a not-for-profit corporation with a principal place of business in San Francisco, California, as well as\nfuture copyleft versions of that license published by that same organization.\n“Incorporate” means to publish or republish a Document, in whole or in part, as part of another Document.\n1368Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nAn MMC is “eligible for relicensing” if it is licensed under this License, and if all works that were first published under\nthis License somewhere other than this MMC, and subsequently incorporated in whole or in part into the MMC, (1)\nhad no cover texts or invariant sections, and (2) were thus incorporated prior to November 1, 2008.\nThe operator of an MMC Site may republish an MMC contained in the site under CC-BY-SA on the same site at any\ntime before August 1, 2009, provided the MMC is eligible for relicensing.\nADDENDUM: How to use this License for your documents\nTo use this License in a document you have written, include a copy of the License in the document and put the\nfollowing copyright and license notices just after the title page:\nCopyright © YEAR  YOUR NAME.\nPermission is granted to copy, distribute and/or modify this document\nunder the terms of the GNU Free Documentation License, Version 1.3\nor any later version published by the Free Software Foundation;\nwith no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.\nA copy of the license is included in the section entitled \"GNU\nFree Documentation License\".\nIf you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the “with ... Texts.” line with this:\nwiththe Invariant Sections being LIST THEIR TITLES,withthe\nFront-Cover Texts being LIST,andwiththe Back-Cover Texts being LIST.\nIf you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alter-\nnatives to suit the situation.\nIf your document contains nontrivial examples of program code, we recommend releasing these examples in parallel\nunder your choice of free software license, such as the GNU General Public License, to permit their use in free\nsoftware.\n29.3Appendix C: QGIS File Formats\n29.3.1QGS/QGZ - The QGIS Project File Format\nTheQGSformat is an XML format for storing QGIS projects. TheQGZformat is a compressed (zip) archive\ncontaining a QGS file and a QGD file. TheQGDfile is the associated sqlite database of the qgis project that contain\nauxiliary data for the project. If there are no auxiliary data, the QGD file will be empty.\nA QGIS file contains everything that is needed for storing a QGIS project, including:\n•project title\n•project CRS\n•the layer tree\n•snapping settings\n•relations\n•the map canvas extent\n•project models\n•legend\n•mapview docks (2D and 3D)\n•the layers with links to the underlying datasets (data sources) and other layer properties including extent, SRS,\njoins, styles, renderer, blend mode, opacity and more.\n•project properties\n29.3. Appendix C: QGIS File Formats1369\n\nQGIS Desktop 3.22 User Guide\nThe figures below show the top level tags in a QGS file and the expandedProjectLayerstag.\nFig. 29.1: The top level tags in a QGS file\n1370Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nFig. 29.2: The expanded top level ProjectLayers tag of a QGS file\n29.3.2QLR - The QGIS Layer Definition file\nA Layer Definition file (QLR) is an XML file that contains a pointer to the layer data source in addition to QGIS style\ninformation for the layer.\nThe use case for this file is simple: To have a single file for opening a data source and bringing in all the related style\ninformation. QLR files also allow you to mask the underlying datasource in an easy to open file.\nAn example of QLR usage is for opening MS SQL layers. Rather than having to go to the MS SQL connection dialog,\nconnect, select, load and finally style, you can simply add a .qlr file that points to the correct MS SQL layer with all\nthe necessary style included.\nIn the future a .qlr file may hold a reference to more than one layer.\n29.3. Appendix C: QGIS File Formats1371\n\nQGIS Desktop 3.22 User Guide\nFig. 29.3: The top level tags of a QLR file\n29.3.3QML - The QGIS Style File Format\nQML is an XML format for storing layer styling.\nA QML file contains all the information QGIS can handle for the rendering of feature geometries including symbol\ndefinitions, sizes and rotations, labelling, opacity and blend mode and more.\nThe figure below shows the top level tags of a QML file (with onlyrenderer_v2and itssymboltag expanded).\n1372Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nFig. 29.4: The top level tags of a QML file (only the renderer_v2 tag with its symbol tag is expanded)\n29.4Appendix D: QGIS R script syntax\nContributed by Matteo Ghetta - funded byScuola Superiore Sant’Anna\nWriting R scripts in Processing is a bit tricky because of the special syntax.\nA Processing R script starts with defining itsInputsandOutputs, each preceded with double hash characters (##).\nBefore the inputs, the group to place the algoritm in can be specified. If the group already exists, the algorithm will\nbe added to it, if not, the group will be created. In the example below, the name of the group isMy group:\n##My Group=group\n29.4. Appendix D: QGIS R script syntax1373\n\nQGIS Desktop 3.22 User Guide\n29.4.1Inputs\nAll input data and parameters have to be specified. There are several types of inputs:\n•vector:##Layer = vector\n•vector field:##F = Field Layer(whereLayeris the name of an input vector layer the field belongs to)\n•raster:##r = raster\n•table:##t = table\n•number:##Num = number\n•string:##Str = string\n•boolean:##Bol = boolean\n•elements in a dropdown menu. The items must be separated with semicolons;:##type=selection\npoint;lines;point+lines\n29.4.2Outputs\nAs for the inputs, each output has to be defined at the beginning of the script:\n•vector:##output= output vector\n•raster:##output= output raster\n•table:##output= output table\n•plots:##output_plots_to_html(##showplots in earlier versions)\n•To show R output in theResult Viewer, put>in front of the command whose output you would like to show.\n29.4.3Syntax Summary for QGIS R scripts\nA number of input and output parameter types are offered.\n1374Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nInput parameter types\nParameterSyntax exampleReturning objects\nvectorLayer = vectorsf object (or SpatialDataFrame object, if ##load_vector_using_rgdal\nis specified)\nvector pointLayer = vector pointsf object (or SpatialDataFrame object, if ##load_vector_using_rgdal\nis specified)\nvector lineLayer = vector linesf object (or SpatialDataFrame object, if ##load_vector_using_rgdal\nis specified)\nvector poly-\ngon\nLayer = vector polygonsf   object   (or   SpatialPolygonsDataFrame   object,    if\n##load_vector_using_rgdal is used)\nmultiple\nvector\nLayer = multiple vectorsf object (or SpatialDataFrame objects if ##load_vector_using_rgdal\nis specified)\ntableLayer = tabledataframe conversion from csv, default object ofread.csvfunction\nfieldField = Field Layername of the Field selected, e.g.\"Area\"\nrasterLayer = rasterRasterBrick object, default object ofrasterpackage\nmultiple\nraster\nLayer = multiple rasterRasterBrick objects, default object ofrasterpackage\nnumberN = numberinteger or floating number chosen\nstringS = stringstring added in the box\nlongstringLS = longstringstring added in the box, could be longer then the normal string\nselectionS=selection\nfirst;second;third\nstring of the selected item chosen in the dropdown menu\ncrsC = crsstring of the resulting CRS chosen, in the format:\"EPSG:4326\"\nextentE = extentExtent object of therasterpackage, you can extract values as\nE@xmin\npointP = pointwhen clicked on the map, you have the coordinates of the point\nfileF = filepath of the file chosen, e.g. “/home/matteo/file.txt”\nfolderF = folderpath of the folder chosen, e.g. “/home/matteo/Downloads”\nA parameter can beOPTIONAL, meaning that it can be ignored.\nIn order to set an input as optional, you add the stringoptionalbeforethe input, e.g:\n##Layer = vector\n##Field1 = Field Layer\n##Field2 = optional Field Layer\nOutput parameter types\nParameterSyntax example\nvectorOutput = output vector\nrasterOutput = output raster\ntableOutput = output table\nfileOutput = output file\nNote:You can save plots aspngfrom theProcessing Result Viewer, or you can choose to save the plot directly from\nthe algorithm interface.\n29.4. Appendix D: QGIS R script syntax1375\n\nQGIS Desktop 3.22 User Guide\nScript body\nThe script body follows R syntax and theLogpanel can help you if there is something wrong with your script.\nRememberthat you have to load all additional libraries in the script:\nlibrary(sp)\n29.4.4Examples\nExample with vector output\nLet’s take an algorithm from the online collection that creates random points from the extent of an input layer:\n##Point pattern analysis=group\n##Layer=vector polygon\n##Size=number 10\n##Output=output vector\nlibrary(sp)\nspatpoly=as(Layer,\"Spatial\")\npts=spsample(spatpoly,Size,type=\"random\")\nspdf=SpatialPointsDataFrame(pts,as.data.frame(pts))\nOutput=st_as_sf(spdf)\nExplanation (per line in the script):\n1.Point pattern analysisis the group of the algorithm\n2.Layeris the inputvectorlayer\n3.Sizeis anumericalparameter with a default value of 10\n4.Outputis thevectorlayer that will be created by the algorithm\n5.library(sp)loads thesplibrary\n6.spatpoly = as(Layer, \"Spatial\")translate to an sp object\n7.Call thespsamplefunction of thesplibrary and run it using the input defined above (LayerandSize)\n8.Create aSpatialPointsDataFrameobject using theSpatialPointsDataFramefunction\n9.Create the output vector layer using thest_as_sffunction\nThat’s it! Just run the algorithm with a vector layer you have in the QGIS Legend, choose the number of random\npoint. The resulting layer will be added to your map.\nExample with raster output\nThe following script will perform basic ordinary kriging to create a raster map of interpolated values from a specified\nfield of the input point vector layer by using theautoKrigefunction of theautomapR package. It will first\ncalculate the kriging model and then create a raster. The raster is created with therasterfunction of the raster R\npackage:\n##Basic statistics=group\n##Layer=vector point\n##Field=Field Layer\n##Output=output raster\n##load_vector_using_rgdal\nrequire(\"automap\")\nrequire(\"sp\")\nrequire(\"raster\")\n(continues on next page)\n1376Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\n(continued from previous page)\ntable=as.data.frame(Layer)\ncoordinates(table)= ~coords.x1+coords.x2\nc = Layer[[Field]]\nkriging_result = autoKrige(c~1, table)\nprediction = raster(kriging_result$krige_output)\nOutput<-prediction\nBy using##load_vector_using_rgdal, the input vector layer will be made available as aSpatial-\nDataFrameobjects, so we avoid having to translate it from ansfobject.\nExample with table output\nLet’s edit theSummary Statisticsalgorithm so that the output is a table file (csv).\nThe script body is the following:\n##Basic statistics=group\n##Layer=vector\n##Field=Field Layer\n##Stat=Output table\nSummary_statistics<-data.frame(rbind(\nsum(Layer[[Field]]),\nlength(Layer[[Field]]),\nlength(unique(Layer[[Field]])),\nmin(Layer[[Field]]),\nmax(Layer[[Field]]),\nmax(Layer[[Field]])-min(Layer[[Field]]),\nmean(Layer[[Field]]),\nmedian(Layer[[Field]]),\nsd(Layer[[Field]])),\nrow\n.names=c(\"Sum:\",\"Count:\",\"Unique values:\",\"Minimum value:\",\"Maximum value:\",\n,→\"Range:\",\"Mean value:\",\"Median value:\",\"Standard deviation:\"))\ncolnames(Summary_statistics)<-c(Field)\nStat<-Summary_statistics\nThe third line specifies theVector Fieldin input and the fourth line tells the algorithm that the output should be a\ntable.\nThe last line will take theStatobject created in the script and convert it into acsvtable.\nExample with console output\nWe can use the previous example and instead of creating a table, print the result in theResult Viewer:\n##Basic statistics=group\n##Layer=vector\n##Field=Field Layer\nSummary_statistics<-data.frame(rbind(\nsum(Layer[[Field]]),\nlength(Layer[[Field]]),\nlength(unique(Layer[[Field]])),\nmin(Layer[[Field]]),\nmax(Layer[[Field]]),\nmax(Layer[[Field]])-min(Layer[[Field]]),\nmean(Layer[[Field]]),\nmedian(Layer[[Field]]),\nsd(Layer[[Field]])),row\n.names=c(\"Sum:\",\"Count:\",\"Unique values:\",\"Minimum value:\",\n,→\"Maximum value:\",\"Range:\",\"Mean value:\",\"Median value:\",\"Standard deviation:\"))\ncolnames(Summary_statistics)<-c(Field)\n>Summary_statistics\n29.4. Appendix D: QGIS R script syntax1377\n\nQGIS Desktop 3.22 User Guide\nThe script is exactly the same as the one above except for two edits:\n1.no output specified (the fourth line has been removed)\n2.the last line begins with>, telling Processing to make the object available through the result viewer\nExample with plot\nTo create plots, you have to use the##output_plots_to_htmlparameter as in the following script:\n##Basic statistics=group\n##Layer=vector\n##Field=Field Layer\n##output_plots_to_html\n####output_plots_to_html\nqqnorm(Layer[[Field]])\nqqline(Layer[[Field]])\nThe script uses a field (Field) of a vector layer (Layer) as input, and creates aQQ Plot(to test the normality of\nthe distribution).\nThe plot is automatically added to the ProcessingResult Viewer.\n29.5Appendix E: QGIS Application Network Connections\nThis is a list of the pre-configured/automated network connections that QGIS makes. Some of the connections are\nuser initiated because they require an action from the user before they take place, others happen automatically.\n1378Chapter 29. Appendices\n\nQGIS Desktop 3.22 User Guide\nNamePurposeUX modeServerInformation sent\nto server\nInformation stored on\nserver\nqgis.org\nPython\nAPI\nhelp\nBrowser\nPyQGIS doc-\numentation\nUser initi-\nated\nhttps://qgis.org/\npyqgis/%1/search.\nhtml?q=%2\nIP, QGIS version,\nOS\nIP in server log\nver-\nsion.qgis.org\nNew\nver-\nsion\ncheck\nNotify   the\nuseron\nnew   QGIS\nversions\navailability\nAutomatichttps://version.qgis.\norg\nIP, QGIS version,\nOS\nIP in server log\nfeed.qgis.org\nQGIS\nFeed\nRetrieve\nQGIS  news\nfrom the feed\nAutomatichttps://feed.qgis.orgIP, QGIS version,\nlanguage  code,\nlast   download\ntimestamp, OS\nIP in server log; QGIS\nversion, OS and IP are ag-\ngregated and used to col-\nlect some statistics\nplug-\nins.qgis.org\nCheck\nfor\nplugin\nup-\ndates\nNotify   the\nuser   about\nplugin   up-\ndates\nUser initi-\nated/automatic\n(config-\nurable)\nhttps://plugins.qgis.\norg\nIP, QGIS version,\nOS\nIP in server log\nPlug-\nins list\nRetrieve  the\nlist of plugins\nUser initi-\nated\nhttps://plugins.qgis.\norg\nIP, QGIS version,\nOS\nIP in server log\nPlugin\ninstal-\nlation\nDownload\nand install a\nplugin pack-\nage\nUser initi-\nated\nhttps://plugins.qgis.\norg\nIP, QGIS version,\nOS\nIncrease plugin download\ncounter by one\nStylesList user con-\ntributed styles\nUser initi-\nated\nhttps://plugins.qgis.\norg/styles\nIP, QGIS version,\nOS\nIncreasedownload\ncounter by one\n3rd\nparty\nTer-\nrain\ndata\nProduce   a\nDEM for 3D\nviews\nUser initi-\nated\nhttps://s3.\namazonaws.com/\nelevation-tiles-prod/\nterrarium\n/{z}/{x}/{y}.png\nIP, QGIS version,\nOS\nsee Amazon TOS\nGoogle\nMap\nGeocoder\nGeocoding\nservices\nUser initi-\nated\nhttps://maps.\ngoogleapis.com/\nmaps/api/geocode/\njson\nIP, QGIS version,\nOS\nSee google maps API\nTOS\nNom-\ninatim\nGeocoder\nGeocoding\nservices\nUser initi-\nated\nhttps://nominatim.\nqgis.org/ui/search.\nhtml\nIP, QGIS version,\nOS\nGeode-\ntic grid\nAdd  a  new\nPROJ grid\nUser initi-\nated\nhttps://cdn.proj.orgIP, PROJ versionAccess logs are perma-\nnently deleted after one\nday\n29.5. Appendix E: QGIS Application Network Connections1379\n\nQGIS Desktop 3.22 User Guide\n1380Chapter 29. Appendices\n\nCHAPTER\nTHIRTY\nLITERATURE AND WEB REFERENCES\nGDAL-SOFTWARE-SUITE. Geospatial data abstraction library.https://gdal.org, 2013.\nGRASS-PROJECT. Geographic resource analysis support system.\nhttps://grass.osgeo.org, 2013.\nNETELER, M., AND MITASOVA, H. Open source gis: A grass gis approach, 2008.\nOGR-SOFTWARE-SUITE. Geospatial data abstraction library.https://gdal.org, 2013.\nOPEN-GEOSPATIAL-CONSORTIUM. Web map service (1.1.1) implementation specification.https://portal.ogc.\norg/files/?artifact_id=1081&amp;version=1&amp;format=pdf, 2002.\nOPEN-GEOSPATIAL-CONSORTIUM. Web map service (1.3.0) implementation specification.https://portal.ogc.\norg/files/?artifact_id=14416&format=pdf, 2004.\nPOSTGIS-PROJECT. Spatial support for postgresql.\nhttp://www.refractions.net/products/postgis/, 2013.\n1381\n\n## Document Information\n- **Source**: PDF Document (1393 pages)\n- **Category**: tutorial\n- **Difficulty**: advanced\n- **Relevant Labs**: general\n- **Topics**: accessibility, arcgis, buffer, cartography, classification, clustering, coordinate system, crs, gee, gis, mapping, overlay, projection, python, qgis, raster, remote sensing, satellite, scripting, shapefile, spatial analysis, symbology, vector\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain qgis desktop 3.22 user guide\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- arcgis\n- buffer\n- cartography\n- classification\n- clustering\n- coordinate system\n- crs\n- gee\n- gis\n",
    "metadata": {
      "category": "tutorial",
      "difficulty": "advanced",
      "lab": "general",
      "topics": [
        "accessibility",
        "arcgis",
        "buffer",
        "cartography",
        "classification",
        "clustering",
        "coordinate system",
        "crs",
        "gee",
        "gis",
        "mapping",
        "overlay",
        "projection",
        "python",
        "qgis",
        "raster",
        "remote sensing",
        "satellite",
        "scripting",
        "shapefile",
        "spatial analysis",
        "symbology",
        "vector"
      ],
      "source": "concepts\\qgis-3.22-desktopuserguide-en.md",
      "filename": "qgis-3.22-desktopuserguide-en.md"
    }
  },
  {
    "id": "concepts-qgis_complete_interface",
    "title": "qgis_complete_interface",
    "content": "# QGIS Interface and Core Concepts\n\n# QGIS: Complete Interface Guide\n\n## What is QGIS?\n\n**QGIS** is a free, open-source Geographic Information System that provides most functionality of expensive commercial software like ArcGIS.\n\n### Key Advantages:\n- **Free and open source**: No licensing costs\n- **Cross-platform**: Windows, Mac, Linux\n- **Powerful functionality**: Rivals commercial software\n- **Active community**: Extensive documentation and support\n- **GRASS integration**: Advanced spatial analysis capabilities\n\n## Core Interface Components\n\n### 1. Menu Bar\nLocated at the top, provides access to all QGIS functions:\n- **Project**: Open/save projects, import/export data\n- **Edit**: Modify features and attributes\n- **View**: Control map display and navigation\n- **Layer**: Add, remove, and manage map layers\n- **Settings**: Configure QGIS preferences\n- **Plugins**: Extend QGIS functionality\n- **Vector/Raster**: Analysis tools for different data types\n- **Help**: Documentation and tutorials\n\n### 2. Toolbars\nQuick access to frequently used functions:\n- **File Toolbar**: Open, save, new project\n- **Map Navigation**: Zoom, pan, select features\n- **Attributes Toolbar**: Open attribute tables, select features\n- **Digitizing Toolbar**: Create and edit features\n- **Advanced Digitizing**: Precise feature creation\n\n**Tip**: Hover over toolbar icons to see tooltips explaining their function.\n\n### 3. Map Canvas (Map View)\nThe central area where spatial data is displayed:\n- **Layer visualization**: Shows all loaded map layers\n- **Interactive navigation**: Zoom, pan, identify features\n- **Scale-dependent rendering**: Layers can appear/disappear at different scales\n- **Multiple map views**: Create additional map windows for comparison\n\n### 4. Layers Panel (Table of Contents)\nLeft panel showing all loaded layers:\n- **Layer management**: Add, remove, reorder layers\n- **Visibility control**: Turn layers on/off with checkboxes\n- **Layer grouping**: Organize related layers together\n- **Symbology access**: Right-click for styling options\n- **Layer properties**: Access metadata, styling, and settings\n\n**Layer Order Matters**: Layers drawn from bottom to top, with top layers obscuring those below.\n\n### 5. Browser Panel\nNavigate and preview data sources:\n- **File system**: Browse local files and folders\n- **Database connections**: Connect to PostGIS, SpatiaLite\n- **Web services**: Add WMS, WFS, and other online services\n- **Preview capability**: See data before adding to project\n\n## Essential QGIS Concepts\n\n### Projects (.qgs files)\n- **Save everything**: Layer references, symbology, layouts\n- **Portable projects**: Use relative paths for data sharing\n- **Project CRS**: Coordinate reference system for the project\n\n### Layers\n- **Data representation**: Each layer represents one dataset\n- **Layer types**: Vector (points, lines, polygons), Raster (grids)\n- **Styling**: Control colors, symbols, labels for each layer\n- **Attributes**: Associated data tables for vector layers\n\n### Coordinate Reference Systems (CRS)\n- **Project CRS**: Overall map projection\n- **Layer CRS**: Individual layer projections\n- **On-the-fly projection**: QGIS reprojects layers automatically\n- **Importance**: Ensures spatial accuracy and proper analysis\n\n## Key Information\n- **Category**: qgis\n- **Difficulty**: beginner\n- **Source**: QGIS User Manual + Training Materials\n\n## Keywords\n- qgis\n- interface\n- layers\n- map canvas\n- toolbars\n- gis software\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "concepts\\qgis_complete_interface.md",
      "filename": "qgis_complete_interface.md"
    }
  },
  {
    "id": "concepts-spatial_analysis_comprehensive",
    "title": "spatial_analysis_comprehensive",
    "content": "# Spatial Analysis: From Patterns to Processes\n\n# Spatial Analysis: Understanding Geographic Patterns\n\n## What is Spatial Analysis?\n\n**Spatial Analysis** goes beyond visualization to understand **why** spatial patterns exist and **what processes** created them.\n\n### GIS vs. Spatial Analysis:\n- **GIS**: \"What is where?\" - Data manipulation, querying, visualization\n- **Spatial Analysis**: \"Why is it there?\" - Statistical analysis of patterns and processes\n\n### The Spatial Analysis Workflow:\n1. **Visualize**: Create maps to see patterns\n2. **Describe**: Quantify spatial patterns statistically  \n3. **Explain**: Test hypotheses about underlying processes\n4. **Predict**: Model future patterns or scenarios\n\n## Core Spatial Analysis Concepts\n\n### 1. Scale and Resolution\n**Scale** in geography refers to the ratio of map distance to real-world distance:\n- **Large scale** (e.g., 1:10,000): Small area, high detail\n- **Small scale** (e.g., 1:1,000,000): Large area, low detail\n\n**Resolution** affects what patterns we can detect:\n- **Fine resolution**: See individual buildings, trees\n- **Coarse resolution**: See regional patterns, climate zones\n\n### 2. Object vs. Field View\n**Object View**: Treats features as discrete entities\n- Examples: Cities, hospitals, disease cases\n- Best for: Counting, location analysis, network analysis\n\n**Field View**: Treats phenomena as continuous surfaces\n- Examples: Temperature, elevation, population density\n- Best for: Interpolation, surface analysis, modeling\n\n### 3. Spatial Relationships\n**Topological relationships** describe how features relate spatially:\n- **Adjacent**: Share a boundary\n- **Contains**: One feature inside another\n- **Overlaps**: Partial overlap between features\n- **Disjoint**: No spatial relationship\n\n**Distance relationships**:\n- **Euclidean distance**: Straight-line distance\n- **Network distance**: Distance along roads/paths\n- **Travel time**: Time-based accessibility\n\n### 4. Spatial Patterns\n**Random**: Features distributed without spatial pattern\n**Clustered**: Features grouped together more than expected\n**Dispersed**: Features more spread out than expected\n\n## Statistical Measures of Spatial Pattern\n\n### Point Pattern Analysis:\n- **Nearest neighbor analysis**: Measures clustering vs. dispersion\n- **Quadrat analysis**: Compares observed vs. expected distributions\n- **Kernel density estimation**: Creates smooth density surfaces\n\n### Spatial Autocorrelation:\n- **Positive autocorrelation**: Similar values cluster together\n- **Negative autocorrelation**: Different values are neighbors\n- **No autocorrelation**: Values distributed randomly\n\n**Moran's I**: Measures global spatial autocorrelation\n- **I > 0**: Clustered pattern\n- **I = 0**: Random pattern  \n- **I < 0**: Dispersed pattern\n\n## Applications in Health Research\n\n### Disease Surveillance:\n1. **Map disease cases** to identify spatial patterns\n2. **Test for clustering** using statistical methods\n3. **Identify risk factors** through spatial correlation\n4. **Predict spread** using spatial models\n\n### Healthcare Access:\n1. **Map facilities and populations** to assess coverage\n2. **Calculate travel distances/times** to measure access\n3. **Identify service gaps** where access is poor\n4. **Optimize locations** for new facilities\n\n### Environmental Health:\n1. **Map exposure sources** (pollution, contamination)\n2. **Model exposure surfaces** using interpolation\n3. **Correlate health outcomes** with environmental factors\n4. **Assess environmental justice** through spatial equity analysis\n\n## Tools for Spatial Analysis\n\n### R Programming:\n- **Spatial packages**: sf, sp, rgdal, raster\n- **Statistical analysis**: Comprehensive spatial statistics\n- **Reproducible research**: Script-based workflows\n- **Visualization**: Advanced mapping and plotting\n\n### Python:\n- **Spatial libraries**: GeoPandas, Shapely, Rasterio\n- **Machine learning**: scikit-learn for spatial ML\n- **Notebooks**: Jupyter for interactive analysis\n\n### Specialized Software:\n- **GeoDa**: Free spatial analysis software\n- **ArcGIS Spatial Analyst**: Commercial spatial analysis extension\n- **QGIS + R**: Combine QGIS visualization with R analysis\n\n## Key Information\n- **Category**: analysis\n- **Difficulty**: intermediate\n- **Source**: Spatial Analysis textbook (mgimond) + Applied Spatial Analysis\n\n## Keywords\n- spatial analysis\n- patterns\n- statistics\n- autocorrelation\n- clustering\n- health research\n",
    "metadata": {
      "category": "concepts",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "concepts\\spatial_analysis_comprehensive.md",
      "filename": "spatial_analysis_comprehensive.md"
    }
  },
  {
    "id": "concepts-syllabus_gis_public_health",
    "title": "Syllabus GIS Public Health",
    "content": "\n# Syllabus GIS Public Health\n\n\n\n1 \n \nGIS, Google Earth Engine, and AI for \nPublic Health – Uganda Workshop \nWorkshop Title: Spatial Data and Artificial Intelligence for Health Research and Planning \nDuration: 3 Days (Introductory – Applied) \nAudience: Public health practitioners, GIS analysts, researchers, students \nPrerequisites: None (designed for beginners) \nSoftware/Accounts Needed: QGIS (pre-installed), Google Earth Engine account, ChatGPT \naccess (free or paid) \nWorkshop Objectives: \n• - Understand the value of GIS and Earth observation in health research. \n• - Use QGIS to map disease prevalence and health service access. \n• - Use Google Earth Engine to analyze environmental risk factors. \n• - Use ChatGPT to write, explain, and troubleshoot GEE scripts. \n• - Apply learned skills in a small project using real or simulated public health data. \n \nDay 1 – Foundations of GIS and Public Health – Mapping Disease \nand Health Service Gaps in QGIS \nLearning Objectives \n• Understand key GIS concepts and spatial data types relevant to public health. \n• Learn basic cartographic techniques to visualize disease burden. \n• Use spatial queries to explore service accessibility. \n• Develop hands-on skills using QGIS with real health data. \nSchedule \nTime Activity Description \n09:00–09:30 Welcome & Workshop \nOverview \nIntroduction to instructors, \nparticipants, and workshop \ngoals. \n09:30–10:15 \nLecture: GIS for Health Overview of spatial data \ntypes, projections, and GIS \nuse cases in health. \n10:15–10:30 Break  \n\n2 \n \n10:30–12:00 Lab 1: Mapping Malaria \nPrevalence \nLoad district shapefiles and \njoin malaria CSV. Create \nchoropleth maps. \n12:00–13:00 Lunch  \n13:00–14:30 Lab 2: Health Facility \nAccess & Buffer Zones \nLoad XY facility CSV, \nconvert to points, buffer, \nand identify underserved \nareas. \n14:30–15:30 Map Review & Discussion Interpret outputs. Highlight \ngaps in care. Peer feedback \nencouraged. \n15:30–16:00 Q&A and Wrap-Up Summary of key concepts. \nSetup for Day 2 (GEE \nintroduction). \nExpected Deliverables \n• 1 malaria prevalence choropleth map (PDF) \n• 1 access gap analysis map with buffers and highlights (PDF) \nData Used \n• Uganda district boundaries (GeoPackage) \n• Malaria prevalence data (CSV) \n• Health facility location data (CSV with XY coordinates) \nSoftware \nQGIS (pre-installed) \n \nDay   2 – Earth   Observation   and   Generative   AI – Mapping \nEnvironmental Risk Factors for Malaria \nLearning Objectives \n• Access and visualize remote sensing data (NDVI, rainfall) using Google Earth Engine \n(GEE). \n• Learn how ChatGPT can support scripting, analysis, and troubleshooting in GEE. \n• Perform basic image processing and export outputs for use in QGIS. \n• Explore clustering methods for identifying environmental health risk zones. \nSchedule \nTime Activity Description \n09:00–09:30 Recap + Earth Observation \nfor Health \nOverview of environmental \ndata in public health (NDVI, \nCHIRPS rainfall). \n\n3 \n \n09:30–10:30 Lab 3: Visualizing NDVI and \nRainfall in GEE \nLoad, clip, and display \nMODIS and CHIRPS \ndatasets. Apply color ramps. \n10:30–11:00 Break  \n11:00–12:00 Lab 4: Using ChatGPT to \nPrompt and Write GEE Code \nWrite basic GEE scripts \nwith ChatGPT. Learn \ndebugging and explanation \nprompts. \n12:00–13:00 Lunch  \n13:00–14:30 Lab 5: AI-Based Clustering \nfor Malaria Risk Mapping \nStack NDVI and rainfall. Use \nk-means clustering to \nidentify risk zones. \n14:30–15:30 Export and Visualize Cluster \nMaps in QGIS \nExport GeoTIFF from GEE, \nstyle layers in QGIS, and \ninterpret results. \n15:30–16:00 Reflection and Discussion \non AI Tools \nGroup discussion on \nadvantages and challenges \nof AI-enhanced workflows. \nExpected Deliverables \n• 1 NDVI and rainfall map rendered in GEE \n• 1 cluster map (risk zones) exported from GEE and styled in QGIS \nData Used \n• MODIS NDVI (MOD13Q1) \n• CHIRPS Rainfall (UCSB-CHG/CHIRPS) \n• Uganda national boundary (LSIB dataset) \nSoftware/Tools \n• Google Earth Engine (browser) \n• ChatGPT (browser) \n• QGIS (optional for export visualization) \n \nDay 3 – Independent Research Projects – Applying Spatial Tools \nto Public Health Challenges \nLearning Objectives \n• Design and conduct a GIS/GEE-based research mini-project \n• Apply QGIS, GEE, and ChatGPT tools to real or simulated data \n• Communicate findings through maps and concise presentations \n• Reflect on challenges and strategies for applying spatial tools in health research \n\n4 \n \nSchedule \nTime Activity Description \n09:00–09:30 Project Kickoff & Topic \nSelection \nOverview of project \nguidelines. Select from \nprovided topics or bring \nyour own data. \n09:30–10:30 Project Planning & Dataset \nSetup \nFormulate a question, \nidentify data layers, decide \ntools to use. \n10:30–11:00 Break  \n11:00–12:30 Project Work Session 1 Independent or group work \nwith instructor and peer \nsupport. \n12:30–13:30 Lunch  \n13:30–15:00 Final Project Work + \nPresentation Preparation \nComplete analysis, export \nvisuals, prepare slides or \nmaps. \n15:00–16:00 Presentations & Wrap-Up Short presentations (3–5 \nminutes). Group reflection, \nevaluation, next steps. \nExpected Deliverables \n• 1 map, slide, or short presentation showing project findings \n• Participation in final discussion and feedback session \nOptional Project Topics (provided) \n• Mapping malaria risk zones using NDVI and rainfall clustering \n• Health facility access analysis in high-burden districts \n• Exploring seasonal rainfall trends and malaria incidence correlations \nSoftware/Tools \n• QGIS or Google Earth Engine \n• ChatGPT (browser) \n\n## Document Information\n- **Source**: PDF Document (4 pages)\n- **Category**: lab-material\n- **Difficulty**: intermediate\n- **Relevant Labs**: general\n- **Topics**: accessibility, buffer, clustering, gee, gis, google earth engine, malaria, mapping, projection, public health, qgis, remote sensing, scripting, shapefile\n\n## AI Assistant Usage\nAsk the chatbot:\n- \"Explain syllabus gis public health\"\n- \"How does this relate to [specific topic]?\"\n- \"Give me examples from this document\"\n- \"What are the key points about [topic] in this document?\"\n\n## Quick References\n- accessibility\n- buffer\n- clustering\n- gee\n- gis\n- google earth engine\n- malaria\n- mapping\n- projection\n- public health\n",
    "metadata": {
      "category": "lab-material",
      "difficulty": "intermediate",
      "lab": "general",
      "topics": [
        "accessibility",
        "buffer",
        "clustering",
        "gee",
        "gis",
        "google earth engine",
        "malaria",
        "mapping",
        "projection",
        "public health",
        "qgis",
        "remote sensing",
        "scripting",
        "shapefile"
      ],
      "source": "concepts\\syllabus_gis_public_health.md",
      "filename": "syllabus_gis_public_health.md"
    }
  },
  {
    "id": "fundamentals-coordinate_reference_systems",
    "title": "Understanding Coordinate Reference Systems",
    "content": "\n# Understanding Coordinate Reference Systems\n\nCoordinate Reference Systems (CRS) define how locations on Earth are represented mathematically.\n\n**Key Concepts:**\n- **Geographic CRS**: Uses latitude/longitude (e.g., WGS84 - EPSG:4326)\n- **Projected CRS**: Uses x,y coordinates in meters/feet (e.g., UTM zones)\n- **EPSG Codes**: Standardized numerical identifiers for CRS\n\n**Uganda Context:**\n- **EPSG:4326 (WGS84)**: Global geographic system, good for general mapping\n- **EPSG:32636 (UTM Zone 36N)**: Projected system for Uganda, better for measurements\n\n**When to Use Each:**\n- Geographic (4326): Web mapping, global datasets, initial data visualization\n- Projected (32636): Distance measurements, area calculations, spatial analysis\n\n**Common Issues:**\n- Mixing different CRS in analysis can cause errors\n- Always check your project CRS (bottom-right of QGIS)\n- Reproject data when necessary for accurate measurements\n\n## Information\n- **Category**: concept\n- **Difficulty**: intermediate\n- **Source**: qgis-tutor\n\n## Topics Covered\n- crs\n- projections\n- coordinates\n- epsg\n- uganda\n\n## Teaching Guidance\nUse analogies and hands-on experimentation\n\n## Discussion Questions\n- Why might the same location have different coordinate values?\n- What happens to distance measurements when you use the wrong CRS?\n\n## Related Queries\n- \"Tell me about understanding coordinate reference systems\"\n- \"How does understanding coordinate reference systems work?\"\n- \"Examples of understanding coordinate reference systems\"\n",
    "metadata": {
      "category": "concept",
      "difficulty": "intermediate",
      "lab": "general",
      "topics": [
        "crs",
        "projections",
        "coordinates",
        "epsg",
        "uganda"
      ],
      "source": "fundamentals\\coordinate_reference_systems.md",
      "filename": "coordinate_reference_systems.md"
    }
  },
  {
    "id": "fundamentals-crs_setup_location",
    "title": "Where to Find CRS Setup Information",
    "content": "\n# Where to Find CRS Setup Information\n\nCoordinate Reference System setup is covered in multiple locations in the workshop:\n\n**Primary Location - Lab 1:**\n- **Section**: \"1.2 Setting Up Your GIS Environment\"\n- **Subsection**: \"Coordinate Reference Systems for Uganda\"\n- **Page**: Lab 1, Step 2 of the tutorial\n- **Direct Link**: Navigate to Labs & Tutorials → Lab 1 → Section 1.2\n\n**What You'll Find:**\n- Explanation of coordinate systems\n- Uganda-specific CRS (EPSG:32636)\n- Step-by-step QGIS setup\n- Visual guides with screenshots\n\n**Quick Navigation:**\n1. Click \"Labs & Tutorials\" in main menu\n2. Select \"Lab 1: Malaria Mapping Fundamentals\"\n3. Scroll to \"1.2 Setting Up Your GIS Environment\"\n4. Look for \"Coordinate Reference Systems\" subsection\n\n## Information\n- **Category**: navigation\n- **Difficulty**: beginner\n- **Source**: workshop\n\n## Topics Covered\n- crs\n- navigation\n- lab1\n- setup\n- uganda\n\n## Teaching Guidance\nGuide students to the exact location and help them understand the content\n\n## Discussion Questions\n- Are you looking for basic CRS concepts or specific setup steps?\n- Have you already started Lab 1?\n\n## Related Queries\n- \"Tell me about where to find crs setup information\"\n- \"How does where to find crs setup information work?\"\n- \"Examples of where to find crs setup information\"\n",
    "metadata": {
      "category": "navigation",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [
        "crs",
        "navigation",
        "lab1",
        "setup",
        "uganda"
      ],
      "source": "fundamentals\\crs_setup_location.md",
      "filename": "crs_setup_location.md"
    }
  },
  {
    "id": "fundamentals-day2_activities",
    "title": "Day 2 Workshop Activities",
    "content": "\n# Day 2 Workshop Activities\n\nDay 2 focuses on Environmental Risk Mapping using Google Earth Engine and satellite data.\n\n**Morning Session (9:00 AM - 12:00 PM):**\n- **Lab 3**: Environmental Risk Mapping (GEE)\n  - Introduction to Google Earth Engine\n  - JavaScript fundamentals for GEE\n  - Loading and visualizing satellite imagery\n  - NDVI calculation for vegetation analysis\n\n**Afternoon Session (1:00 PM - 5:00 PM):**\n- **Lab 3 Continued**: Advanced GEE Analysis\n  - Time series analysis\n  - Climate data integration (CHIRPS precipitation)\n  - Malaria risk factor mapping\n  - Environmental correlation analysis\n\n**Key Learning Outcomes:**\n- Understand cloud-based remote sensing\n- Calculate vegetation indices (NDVI)\n- Analyze environmental factors affecting malaria\n- Create risk assessment maps\n\n## Information\n- **Category**: navigation\n- **Difficulty**: intermediate\n- **Source**: workshop\n\n## Topics Covered\n- day2\n- schedule\n- activities\n- google earth engine\n- lab3\n\n## Teaching Guidance\nGuide students through the day's progression and help them prepare\n\n## Discussion Questions\n- What environmental factors do you think affect malaria transmission?\n- How might satellite data help us understand disease patterns?\n\n## Related Queries\n- \"Tell me about day 2 workshop activities\"\n- \"How does day 2 workshop activities work?\"\n- \"Examples of day 2 workshop activities\"\n",
    "metadata": {
      "category": "navigation",
      "difficulty": "intermediate",
      "lab": "general",
      "topics": [
        "day2",
        "schedule",
        "activities",
        "google earth engine",
        "lab3"
      ],
      "source": "fundamentals\\day2_activities.md",
      "filename": "day2_activities.md"
    }
  },
  {
    "id": "fundamentals-qgis_installation",
    "title": "How to Install QGIS",
    "content": "\n# How to Install QGIS\n\nQGIS is free, open-source GIS software. Here's how to install it:\n\n**Step 1: Download QGIS**\n- Visit: https://qgis.org/en/site/forusers/download.html\n- Choose your operating system (Windows, Mac, Linux)\n- Download the Long Term Release (LTR) version for stability\n\n**Step 2: Windows Installation**\n1. Run the downloaded .exe file\n2. Follow installation wizard\n3. Accept default settings (recommended)\n4. Installation takes 5-10 minutes\n\n**Step 3: Mac Installation**\n1. Open the downloaded .dmg file\n2. Drag QGIS to Applications folder\n3. First launch may require security permissions\n\n**Step 4: Verify Installation**\n- Open QGIS\n- You should see the main interface\n- Try loading a sample dataset\n\n**System Requirements:**\n- **RAM**: Minimum 4GB, recommended 8GB+\n- **Storage**: 2GB free space\n- **OS**: Windows 10+, macOS 10.14+, Linux\n\n## Information\n- **Category**: installation\n- **Difficulty**: beginner\n- **Source**: qgis-tutor\n\n## Topics Covered\n- qgis\n- installation\n- setup\n- download\n\n## Teaching Guidance\nWalk through each step, address common installation issues\n\n## Discussion Questions\n- What operating system are you using?\n- Have you installed other software before?\n\n## Related Queries\n- \"Tell me about how to install qgis\"\n- \"How does how to install qgis work?\"\n- \"Examples of how to install qgis\"\n",
    "metadata": {
      "category": "installation",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [
        "qgis",
        "installation",
        "setup",
        "download"
      ],
      "source": "fundamentals\\qgis_installation.md",
      "filename": "qgis_installation.md"
    }
  },
  {
    "id": "fundamentals-what_is_gis",
    "title": "What is GIS? - Geographic Information Systems",
    "content": "\n# What is GIS? - Geographic Information Systems\n\nGIS (Geographic Information Systems) is a technology that captures, stores, analyzes, and displays geographic information.\n\n**Core Components of GIS:**\n1. **Hardware**: Computers, GPS units, scanners\n2. **Software**: QGIS, ArcGIS, Google Earth Engine\n3. **Data**: Spatial data (where) + Attribute data (what)\n4. **People**: Users, analysts, developers\n5. **Methods**: Procedures for analysis and visualization\n\n**What Makes GIS Special:**\n- **Location-based**: Everything has a geographic component\n- **Layered approach**: Combine different data types\n- **Spatial analysis**: Understand patterns and relationships\n- **Decision support**: Inform policy and planning\n\n**GIS in Health Applications:**\n- **Disease mapping**: Track outbreaks and patterns\n- **Accessibility analysis**: Healthcare facility coverage\n- **Environmental health**: Pollution, water quality\n- **Resource allocation**: Optimize service delivery\n\n## Information\n- **Category**: concept\n- **Difficulty**: beginner\n- **Source**: workshop\n\n## Topics Covered\n- gis\n- definition\n- fundamentals\n- health\n- applications\n\n## Teaching Guidance\nStart with familiar examples, then build to technical concepts\n\n## Discussion Questions\n- Think about using GPS on your phone - how is that similar to GIS?\n- What spatial questions do you encounter in your daily life?\n\n## Related Queries\n- \"Tell me about what is gis? - geographic information systems\"\n- \"How does what is gis? - geographic information systems work?\"\n- \"Examples of what is gis? - geographic information systems\"\n",
    "metadata": {
      "category": "concept",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [
        "gis",
        "definition",
        "fundamentals",
        "health",
        "applications"
      ],
      "source": "fundamentals\\what_is_gis.md",
      "filename": "what_is_gis.md"
    }
  },
  {
    "id": "fundamentals-workshop_overview",
    "title": "GIS & AI Workshop Overview",
    "content": "\n# GIS & AI Workshop Overview\n\nThis 3-day workshop combines GIS fundamentals with AI-powered analysis for health geography applications.\n\n**Workshop Structure:**\n- **Day 1**: QGIS Fundamentals & Malaria Mapping\n- **Day 2**: Environmental Risk Mapping with Google Earth Engine  \n- **Day 3**: AI-Assisted Programming & Advanced Analysis\n\n**Learning Objectives:**\n- Master QGIS for health facility mapping\n- Use Google Earth Engine for environmental analysis\n- Apply AI tools for spatial analysis\n- Develop malaria risk assessment models\n- Create professional maps and visualizations\n\n## Information\n- **Category**: navigation\n- **Difficulty**: beginner\n- **Source**: workshop\n\n## Topics Covered\n- workshop\n- overview\n- structure\n- schedule\n\n## Teaching Guidance\nHelp students understand the big picture and how each component fits together\n\n## Discussion Questions\n- What aspects of this workshop interest you most?\n- How might GIS help in your field of work?\n\n## Related Queries\n- \"Tell me about gis & ai workshop overview\"\n- \"How does gis & ai workshop overview work?\"\n- \"Examples of gis & ai workshop overview\"\n",
    "metadata": {
      "category": "navigation",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [
        "workshop",
        "overview",
        "structure",
        "schedule"
      ],
      "source": "fundamentals\\workshop_overview.md",
      "filename": "workshop_overview.md"
    }
  },
  {
    "id": "labs-lab1-overview",
    "title": "lab1-overview",
    "content": "# Enhanced QGIS Health Facility Access Analysis\n\n## Overview\nThis tutorial teaches spatial accessibility analysis using Uganda's healthcare system as a case study. Students learn to create service catchment areas, identify underserved populations, and combine spatial and health indicator data for evidence-based planning.\n\n## Learning Objectives\nComprehensive spatial accessibility analysis for healthcare facilities in Uganda using QGIS buffer analysis and spatial queries\n\n## Lab Details\n- **Estimated Time**: 3-4 hours\n- **Difficulty**: Intermediate\n- **Tools Required**: QGIS, Print Layout, Buffer Analysis, Spatial Queries\n- **Datasets**: Uganda_districts.gpkg, health_facilities_uganda.csv, malaria_prevalence_uganda.csv\n\n## What You'll Learn\nThis lab covers 15 main steps focusing on practical application of GIS techniques for health geography.\n",
    "metadata": {
      "category": "labs",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "labs\\lab1-overview.md",
      "filename": "lab1-overview.md"
    }
  },
  {
    "id": "labs-lab1-section-3.1-step-1",
    "title": "Create and Configure Your QGIS Project",
    "content": "\n# Create and Configure Your QGIS Project\n\n## Step 1: Create and Configure Your QGIS Project\n\n### Instructions\n1. Launch QGIS and create a new project (Project → New)\n2. Save project as 'Uganda_Health_Facility_Access_Analysis.qgz'\n3. Create folder structure: Raw_Data, Processed_Data, Maps, Analysis_Results\n4. Set project CRS to WGS 84 / UTM Zone 36N (EPSG:32636) via Project → Properties → CRS\n\n### 💡 Tips\n- UTM Zone 36N provides accurate metric measurements for Uganda\n- Good organization prevents data management issues later\n- Save frequently to avoid losing work\n\n### 🔧 Troubleshooting\n- **Issue**: If CRS doesn't appear, search for '32636' in the filter\n- **Issue**: Verify coordinates show in meters in bottom-right corner\n\n\n\n### Navigation\n\n- **Next**: Step 2\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 1 in detail\"\n- Common question: \"I'm stuck on create and configure your qgis project\"\n- Troubleshooting: \"Error with create and configure your qgis project\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [],
      "source": "labs\\lab1-section-3.1-step-1.md",
      "filename": "lab1-section-3.1-step-1.md"
    }
  },
  {
    "id": "labs-lab1-section-3.1-step-2",
    "title": "Organize Your Data and Workspace",
    "content": "\n# Organize Your Data and Workspace\n\n## Step 2: Organize Your Data and Workspace\n\n### Instructions\n1. Enable Processing Toolbox (View → Panels → Processing Toolbox)\n2. Enable Browser Panel for data navigation\n3. Enable Layers Panel for layer management\n4. Create organized folder structure in project directory\n\n### 💡 Tips\n- Processing Toolbox contains essential spatial analysis tools\n- Good workspace organization improves efficiency\n- Browser panel helps locate and manage files\n\n\n\n\n\n### Navigation\n- **Previous**: Step 1\n- **Next**: Step 3\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 2 in detail\"\n- Common question: \"I'm stuck on organize your data and workspace\"\n- Troubleshooting: \"Error with organize your data and workspace\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [],
      "source": "labs\\lab1-section-3.1-step-2.md",
      "filename": "lab1-section-3.1-step-2.md"
    }
  },
  {
    "id": "labs-lab1-section-3.2-step-3",
    "title": "Import Uganda District Boundaries",
    "content": "\n# Import Uganda District Boundaries\n\n## Step 3: Import Uganda District Boundaries\n\n### Instructions\n1. Use Layer → Add Layer → Add Vector Layer\n2. Import Uganda_districts.gpkg file\n3. Examine attribute table (right-click → Open Attribute Table)\n4. Note district name field for future joining operations\n\n### 💡 Tips\n- District boundaries provide spatial framework for analysis\n- Check that all districts loaded correctly\n- Note field names for later use in joins\n\n### 🔧 Troubleshooting\n- **Issue**: If layer doesn't load, check file path and format\n- **Issue**: Ensure file isn't corrupted or moved\n\n\n\n### Navigation\n- **Previous**: Step 2\n- **Next**: Step 4\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 3 in detail\"\n- Common question: \"I'm stuck on import uganda district boundaries\"\n- Troubleshooting: \"Error with import uganda district boundaries\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [],
      "source": "labs\\lab1-section-3.2-step-3.md",
      "filename": "lab1-section-3.2-step-3.md"
    }
  },
  {
    "id": "labs-lab1-section-3.2-step-4",
    "title": "Convert Health Facility Coordinates to Spatial Data",
    "content": "\n# Convert Health Facility Coordinates to Spatial Data\n\n## Step 4: Convert Health Facility Coordinates to Spatial Data\n\n### Instructions\n1. Navigate to Layer → Add Layer → Add Delimited Text Layer\n2. Select health_facilities_uganda.csv file\n3. Set File format to 'CSV'\n4. Set X field to 'Longitude' and Y field to 'Latitude'\n5. Set Geometry CRS to EPSG:4326 (WGS 84)\n6. Click 'Add' to create temporary layer\n7. Export as permanent shapefile: right-click → Export → Save Features As\n8. Save as 'health_facilities_uganda.shp' with CRS EPSG:32636\n\n### 💡 Tips\n- Always convert CSV coordinates to permanent spatial files\n- Use consistent CRS throughout project (EPSG:32636)\n- Remove temporary CSV layer after creating permanent shapefile\n\n### 🔧 Troubleshooting\n- **Issue**: If coordinates don't appear correctly, check X/Y field assignments\n- **Issue**: Ensure latitude/longitude values are in decimal degrees\n- **Issue**: If points appear in wrong location, verify CRS settings\n\n### Related Concepts\n- Coordinate Reference Systems\n- CSV Import\n- Point Data\n\n### Navigation\n- **Previous**: Step 3\n- **Next**: Step 5\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 4 in detail\"\n- Common question: \"I'm stuck on convert health facility coordinates to spatial data\"\n- Troubleshooting: \"Error with convert health facility coordinates to spatial data\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [
        "Coordinate Reference Systems",
        "CSV Import",
        "Point Data"
      ],
      "source": "labs\\lab1-section-3.2-step-4.md",
      "filename": "lab1-section-3.2-step-4.md"
    }
  },
  {
    "id": "labs-lab1-section-3.3-step-5",
    "title": "Import Malaria Prevalence Data (CSV)",
    "content": "\n# Import Malaria Prevalence Data (CSV)\n\n## Step 5: Import Malaria Prevalence Data (CSV)\n\n### Instructions\n1. Click 'Layer' → 'Add Layer' → 'Add Delimited Text Layer'\n2. Browse to your malaria_prevalence.csv file\n3. Ensure 'CSV (comma separated values)' is selected\n4. Under 'Geometry Definition,' select 'No geometry (attribute table only)'\n5. Click 'Add' then 'Close'\n\n### 💡 Tips\n- CSV contains statistical data without coordinates\n- Data will be joined to spatial features using district names\n- Check that district names match between datasets\n\n### 🔧 Troubleshooting\n- **Issue**: If CSV won't load, check file format and encoding\n- **Issue**: Ensure file path is correct and accessible\n- **Issue**: Verify CSV has proper headers and consistent formatting\n\n### Related Concepts\n- Attribute Data\n- CSV Import\n- Data Joining\n\n### Navigation\n- **Previous**: Step 4\n- **Next**: Step 6\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 5 in detail\"\n- Common question: \"I'm stuck on import malaria prevalence data (csv)\"\n- Troubleshooting: \"Error with import malaria prevalence data (csv)\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [
        "Attribute Data",
        "CSV Import",
        "Data Joining"
      ],
      "source": "labs\\lab1-section-3.3-step-5.md",
      "filename": "lab1-section-3.3-step-5.md"
    }
  },
  {
    "id": "labs-lab1-section-3.3-step-6",
    "title": "Join Malaria Data to District Boundaries",
    "content": "\n# Join Malaria Data to District Boundaries\n\n## Step 6: Join Malaria Data to District Boundaries\n\n### Instructions\n1. Right-click on Uganda_districts layer → 'Properties'\n2. Go to 'Joins' tab, click '+' button\n3. In 'Add Vector Join' dialog:\n4.   - Set 'Join layer' to malaria prevalence CSV\n5.   - Set 'Join field' to district name field in CSV\n6.   - Set 'Target field' to district name field in shapefile\n7.   - Check 'Custom field name prefix' and leave blank\n8. Click 'OK' then 'Apply'\n9. Verify join by opening districts attribute table\n\n### 💡 Tips\n- Successful joins combine geographic and health data\n- District names must match exactly between datasets\n- Custom prefix helps avoid field name conflicts\n\n### 🔧 Troubleshooting\n- **Issue**: If join fails, check for spelling differences in district names\n- **Issue**: Ensure both datasets use consistent naming conventions\n- **Issue**: Look for extra spaces or special characters in names\n\n### Related Concepts\n- Table Joins\n- Attribute Matching\n- Data Integration\n\n### Navigation\n- **Previous**: Step 5\n- **Next**: Step 7\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 6 in detail\"\n- Common question: \"I'm stuck on join malaria data to district boundaries\"\n- Troubleshooting: \"Error with join malaria data to district boundaries\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [
        "Table Joins",
        "Attribute Matching",
        "Data Integration"
      ],
      "source": "labs\\lab1-section-3.3-step-6.md",
      "filename": "lab1-section-3.3-step-6.md"
    }
  },
  {
    "id": "labs-lab1-section-3.4-step-8",
    "title": "Create Service Catchment Buffers",
    "content": "\n# Create Service Catchment Buffers\n\n## Step 8: Create Service Catchment Buffers\n\n### Instructions\n1. Access Vector → Geoprocessing Tools → Buffer\n2. Set Input layer to health facilities shapefile\n3. Specify Distance as 10,000 meters (10 km)\n4. Maintain 20 segments for smooth circular buffers\n5. Save output as 'facility_buffers_10km.shp'\n\n### 💡 Tips\n- 10km represents 2-3 hours walking time in rural Uganda\n- Buffer zones show reasonable access distances\n- Higher segment count creates smoother circles\n\n### 🔧 Troubleshooting\n- **Issue**: If buffers appear too large/small, check distance units\n- **Issue**: Ensure project CRS uses meters for accurate measurements\n- **Issue**: Verify input layer contains point features\n\n\n\n### Navigation\n- **Previous**: Step 7\n- **Next**: Step 9\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 8 in detail\"\n- Common question: \"I'm stuck on create service catchment buffers\"\n- Troubleshooting: \"Error with create service catchment buffers\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [],
      "source": "labs\\lab1-section-3.4-step-8.md",
      "filename": "lab1-section-3.4-step-8.md"
    }
  },
  {
    "id": "labs-lab1-section-3.5-step-10",
    "title": "Identify Underserved Districts",
    "content": "\n# Identify Underserved Districts\n\n## Step 10: Identify Underserved Districts\n\n### Instructions\n1. Navigate to Vector → Research Tools → Select by Location\n2. Configure query: 'Select features from' Uganda districts\n3. 'where the features' 'do not intersect'\n4. 'by comparing to features from' facility buffers layer\n5. Run query to identify districts without facility coverage\n\n### 💡 Tips\n- 'Do not intersect' finds areas completely outside buffer zones\n- These districts represent highest priority for intervention\n- Results show most underserved populations\n\n\n\n\n\n### Navigation\n- **Previous**: Step 9\n- **Next**: Step 11\n\n### Need Help?\n- Ask the AI assistant: \"Explain step 10 in detail\"\n- Common question: \"I'm stuck on identify underserved districts\"\n- Troubleshooting: \"Error with identify underserved districts\"\n",
    "metadata": {
      "category": "lab-step",
      "difficulty": "intermediate",
      "lab": "lab1",
      "topics": [],
      "source": "labs\\lab1-section-3.5-step-10.md",
      "filename": "lab1-section-3.5-step-10.md"
    }
  },
  {
    "id": "labs-lab2-overview",
    "title": "lab2-overview",
    "content": "# Enhanced Google Earth Engine Environmental Risk Mapping\n\n## Overview\nAdvanced remote sensing tutorial using Google Earth Engine to analyze environmental factors influencing malaria transmission, including precipitation, temperature, and vegetation indices.\n\n## Learning Objectives\nUsing Google Earth Engine for satellite-based environmental risk assessment and malaria mapping\n\n## Lab Details\n- **Estimated Time**: 4-5 hours\n- **Difficulty**: Advanced\n- **Tools Required**: Google Earth Engine, JavaScript API, Remote Sensing, Time Series Analysis\n- **Datasets**: CHIRPS Precipitation, MODIS Temperature, NDVI, Landsat Imagery\n\n## What You'll Learn\nThis lab covers 12 main steps focusing on practical application of GIS techniques for health geography.\n",
    "metadata": {
      "category": "labs",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "labs\\lab2-overview.md",
      "filename": "lab2-overview.md"
    }
  },
  {
    "id": "labs-lab3-overview",
    "title": "lab3-overview",
    "content": "# Enhanced QGIS Malaria Mapping Tutorial\n\n## Overview\nComplete tutorial for creating professional malaria prevalence maps using QGIS, covering data visualization, classification methods, and cartographic design principles.\n\n## Learning Objectives\nComprehensive malaria mapping with choropleth visualization and classification methods\n\n## Lab Details\n- **Estimated Time**: 2-3 hours\n- **Difficulty**: Beginner\n- **Tools Required**: QGIS, Symbology, Print Layout, Data Classification\n- **Datasets**: Uganda_districts.gpkg, malaria_prevalence.csv\n\n## What You'll Learn\nThis lab covers 12 main steps focusing on practical application of GIS techniques for health geography.\n",
    "metadata": {
      "category": "labs",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "labs\\lab3-overview.md",
      "filename": "lab3-overview.md"
    }
  },
  {
    "id": "labs-lab4-overview",
    "title": "lab4-overview",
    "content": "# Enhanced AI-Assisted Google Earth Engine Programming\n\n## Overview\nLearn to leverage AI assistants like ChatGPT and GitHub Copilot to write more efficient Google Earth Engine code for environmental and health applications.\n\n## Learning Objectives\nUsing AI tools to accelerate Google Earth Engine programming for environmental analysis\n\n## Lab Details\n- **Estimated Time**: 3-4 hours\n- **Difficulty**: Intermediate\n- **Tools Required**: Google Earth Engine, AI Assistants, JavaScript, Python API\n- **Datasets**: Sentinel-2, Landsat, MODIS, Climate Data\n\n## What You'll Learn\nThis lab covers 10 main steps focusing on practical application of GIS techniques for health geography.\n",
    "metadata": {
      "category": "labs",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "labs\\lab4-overview.md",
      "filename": "lab4-overview.md"
    }
  },
  {
    "id": "labs-lab5-overview",
    "title": "lab5-overview",
    "content": "# Enhanced AI-Based Clustering for Malaria Risk Mapping\n\n## Overview\nAdvanced tutorial combining environmental data with machine learning clustering to identify and map malaria risk zones in East Africa.\n\n## Learning Objectives\nMachine learning approaches for identifying malaria risk zones using clustering algorithms\n\n## Lab Details\n- **Estimated Time**: 4-5 hours\n- **Difficulty**: Advanced\n- **Tools Required**: Python, Scikit-learn, QGIS, K-means Clustering\n- **Datasets**: Environmental Variables, Malaria Cases, Population Data\n\n## What You'll Learn\nThis lab covers 15 main steps focusing on practical application of GIS techniques for health geography.\n",
    "metadata": {
      "category": "labs",
      "difficulty": "beginner",
      "lab": "general",
      "topics": [],
      "source": "labs\\lab5-overview.md",
      "filename": "lab5-overview.md"
    }
  },
  {
    "id": "troubleshooting-crs-mismatch",
    "title": "Coordinate Reference System Issues",
    "content": "\n# Fixing Coordinate Reference System Problems\n\n## The Problem\nLayers appear in wrong locations, don't align properly, or distances are calculated incorrectly.\n\n## Why This Happens\nDifferent layers use different coordinate reference systems (CRS), causing spatial misalignment.\n\n## Solutions\n\n### Quick Fix\n1. Right-click problematic layer → Properties → Source tab\n2. Note the current CRS (e.g., EPSG:4326)\n3. Right-click layer → Export → Save Features As\n4. Change CRS to EPSG:32636 (Uganda UTM Zone 36N)\n5. Load the new file and remove the old one\n\n### Project-Wide Fix\n1. Project → Properties → CRS tab\n2. Set project CRS to EPSG:32636\n3. Enable \"on-the-fly\" reprojection\n4. All layers will display in the same coordinate system\n\n### Prevention\n- Always check CRS before loading data\n- Use consistent CRS throughout project\n- For Uganda: EPSG:32636 for measurements, EPSG:4326 for GPS data\n\n## Common CRS for Uganda\n- **EPSG:32636**: UTM Zone 36N - best for measurements and analysis\n- **EPSG:4326**: WGS84 - best for GPS coordinates and global context\n- **EPSG:21036**: Arc 1960 UTM 36N - historical surveys\n\n## Ask the AI Assistant\n- \"My layers don't align, help with CRS\"\n- \"What CRS should I use for Uganda?\"\n- \"How to reproject layers in QGIS\"\n",
    "metadata": {
      "category": "troubleshooting",
      "difficulty": "beginner",
      "lab": "all",
      "topics": [
        "errors",
        "troubleshooting",
        "common-issues"
      ],
      "source": "troubleshooting\\crs-mismatch.md",
      "filename": "crs-mismatch.md"
    }
  },
  {
    "id": "troubleshooting-file-loading-errors",
    "title": "Data Loading Problems",
    "content": "\n# Solving Data Loading Issues\n\n## Common File Loading Problems\n\n### Shapefile Won't Load\n**Symptoms**: Error messages, empty layers, or files won't open\n\n**Solutions**:\n1. **Check file completeness**: Shapefiles need .shp, .shx, .dbf, and .prj files\n2. **Remove spaces**: Rename files to remove spaces and special characters\n3. **Check file path**: Ensure path doesn't contain special characters\n4. **Verify format**: Confirm file is actually a shapefile\n\n### CSV Coordinates Not Displaying\n**Symptoms**: CSV loads but points don't appear on map\n\n**Solutions**:\n1. **Check coordinate columns**: Ensure X=Longitude, Y=Latitude\n2. **Verify coordinate format**: Use decimal degrees (not degrees/minutes/seconds)\n3. **Set correct CRS**: Usually EPSG:4326 for GPS coordinates\n4. **Check for missing values**: Empty coordinates cause issues\n\n### \"Invalid Geometry\" Errors\n**Symptoms**: Processing tools fail with geometry errors\n\n**Solutions**:\n1. Vector → Geometry Tools → Fix Geometries\n2. Vector → Geometry Tools → Check Validity (to identify issues)\n3. Use fixed geometry layer for analysis\n\n### File Path Problems\n**Symptoms**: \"File not found\" errors, broken links\n\n**Solutions**:\n1. Use simple folder names (no spaces, special characters)\n2. Keep project files in organized folder structure\n3. Use relative paths when possible\n4. Avoid cloud storage folders (OneDrive, Dropbox) for active projects\n\n## Prevention Tips\n- Always validate data after importing\n- Use consistent file naming conventions\n- Keep backups of original data\n- Document your data sources and formats\n\n## Ask the AI Assistant\n- \"My shapefile won't load, what's wrong?\"\n- \"CSV coordinates not showing on map\"\n- \"How to fix invalid geometry errors\"\n",
    "metadata": {
      "category": "troubleshooting",
      "difficulty": "beginner",
      "lab": "all",
      "topics": [
        "errors",
        "troubleshooting",
        "common-issues"
      ],
      "source": "troubleshooting\\file-loading-errors.md",
      "filename": "file-loading-errors.md"
    }
  }
]