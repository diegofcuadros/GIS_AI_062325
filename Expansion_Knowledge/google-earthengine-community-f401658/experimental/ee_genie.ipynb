{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "EE Genie as an interactive Earth Engine GenAI assistant that works\n",
        "with geemap in Colab and can retrieve and analyze images.\n",
        "<a target='_blank' href='https://colab.research.google.com/github/google/earthengine-community/blob/master/experimental/ee_genie.ipynb'>   <img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/> </a>\n\n",
        "\n",
        "Author: Simon Ilyushchenko (simonf@google.com)\n",
        "\n",
        "Last update: 2025-03-31\n",
        "\n",
        "**USING THIS AGENT IS UNSAFE**. It directly runs LLM-produced code, and thus\n",
        "should only be used for demonstration purposes. However, Colab serves as\n",
        "a moderately effective sandbox - the damage would be limited to whatever\n",
        "this notebook has access to.\n",
        "\n",
        "**Description**\n",
        "\n",
        "The EE Genie notebook is shown as a two-column view.\n",
        "The left column is the chat history showing all interactions with LLM. The right column contains an interactive instance of geemap.\n",
        "\n",
        "The default prompt at the very bottom is \"show a whole continent Australia DEM visualization using a palette that captures the elevation range\". Just hit enter to accept it and wait for the output to appear. This works like a regular LLM chat, so you can continue talking about your map - e.g., you can say \"Now scroll the map up to India and verify the image is correct\".\n",
        "\n",
        "Some other queries that work most of the time are commented out in the code where `command_input` is defined.\n",
        "\n",
        "The agent fetches the same tiles that are loaded on geemap, then stitches them together into one large image and sends it to a model for textual description.\n",
        "\n",
        "**Annoyance**\n",
        "\n",
        "Due to problems with Javascript/Python interaction, the agent has to stop running after it moves or pans geemap. When this happens, the agent icon will change to üôè. Just hit enter in the chat box when you see this to continue analysis.\n",
        "\n",
        "**Installation**\n",
        "\n",
        "To use it, you need two things:\n",
        "1. Earth Engine access\n",
        "2. Google API key to use with the genai client.\n",
        "\n",
        "You need a Google Cloud Project to associate your requests with. [Use these instructions](https://developers.google.com/earth-engine/cloud/earthengine_cloud_project_setup) and set EE_PROJECT_ID notebook secret to your project id.\n",
        "\n",
        "Next you need to get an Generative AI API key [here](https://aistudio.google.com/app/prompts/new_chat).\n",
        "\n",
        "To save this key in the notebook, click on the key icon in Colab on the left-hand side and add your key as a secret with the name GOOGLE_API_KEY. Make sure the value has no newlines.\n",
        "\n",
        "To use EE Genie, run the cells, then scroll to the UI at the bottom.\n",
        "Change the task that you want the agent to work on and hit enter."
      ],
      "metadata": {
        "id": "r8ZOvPltTsa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "b09aYpe5k4W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet geedim tenacity"
      ],
      "metadata": {
        "id": "XByZXi2JwDSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contextlib\n",
        "\n",
        "import enum\n",
        "import io\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "import requests\n",
        "\n",
        "import ee\n",
        "import geemap\n",
        "from geemap import temp_file_path\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML, Javascript\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception"
      ],
      "metadata": {
        "id": "riMVsnLuXaTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "20Euhmdek-cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Authenticate(scopes=['https://www.googleapis.com/auth/earthengine.readonly'])\n",
        "ee.Initialize(project=userdata.get('EE_PROJECT_ID'))\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket('earthengine-stac')\n",
        "\n",
        "# Score to aim for (on the 0-1 scale). The exact meaning of what \"score\" means\n",
        "# is left to the LLM.\n",
        "target_score = 0.8\n",
        "\n",
        "# Count of analysis rounds\n",
        "round = 1\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.add(\"layer_manager\")\n",
        "\n",
        "analysis_model = None\n",
        "map_dirty = False\n",
        "\n",
        "#model_name = 'gemini-1.5-pro-latest'\n",
        "model_name = 'gemini-2.0-flash'\n",
        "#model_name = 'gemini-2.0-pro-exp-02-05'\n",
        "#model_name = 'gemini-2.5-pro-exp-03-25'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0tsxMngtXlxn",
        "outputId": "f76bc549-ae10-46f7-b7b3-30b928fda4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI widget definitions"
      ],
      "metadata": {
        "id": "ESeVud7llELN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the widgets early because some functions will write to the debug\n",
        "# and/or chat panels.\n",
        "\n",
        "task = \"Show a whole continent Australia DEM visualization using a palette that captures the elevation range\"\n",
        "#task='show NYC'\n",
        "#task='show an area with many center pivot irrigation circles'\n",
        "#task='show consequences of a large fire'\n",
        "#task='show an open pit mine'\n",
        "#task='a sea port'\n",
        "#task='flood consequences'\n",
        "#task='show an interesting modis composite with the relevant visualization and analyze it over Costa Rica'\n",
        "\n",
        "# Create output area with a unique ID\n",
        "output_id = f\"output_{int(time.time())}\"\n",
        "chat_output = widgets.Output(\n",
        "    layout=widgets.Layout(\n",
        "        width='50%',\n",
        "        height='600px',\n",
        "        border='1px solid black',\n",
        "        overflow='auto'\n",
        "    )\n",
        ")\n",
        "# Add a unique CSS class to output area\n",
        "chat_output.add_class(output_id)\n",
        "\n",
        "def scroll_to_bottom():\n",
        "  js_code = f\"\"\"\n",
        "      requestAnimationFrame(() => {{\n",
        "          const element = document.querySelector('.{output_id}');\n",
        "          if (element) {{\n",
        "              element.scrollTop = element.scrollHeight;\n",
        "          }}\n",
        "      }});\n",
        "  \"\"\"\n",
        "  display(Javascript(js_code))\n",
        "\n",
        "def chat_display(text: str) -> None:\n",
        "  text = text.strip().rstrip('\\nNone')\n",
        "  with chat_output:\n",
        "    display(HTML(f\"<p style='white-space: pre-wrap;'>{text}</p>\"))\n",
        "  scroll_to_bottom()\n",
        "\n",
        "chat_display(f'LLM: {model_name}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1_741mumXw1T",
        "outputId": "df748d1d-f1fd-4c84-9912-562dd2848fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      requestAnimationFrame(() => {\n",
              "          const element = document.querySelector('.output_1744146792');\n",
              "          if (element) {\n",
              "              element.scrollTop = element.scrollHeight;\n",
              "          }\n",
              "      });\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple functions that LLM will call"
      ],
      "metadata": {
        "id": "OUxyUVnAlNeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_center(x: float, y: float, zoom: int) -> str:\n",
        "  \"\"\"Sets the map center to the given coordinates and zoom level and\n",
        "  returns instructions on what to do next.\"\"\"\n",
        "  chat_display(f\"SET_CENTER({x}, {y}, {zoom})\\n\")\n",
        "  Map.set_center(x, y)\n",
        "  Map.zoom = zoom\n",
        "  global map_dirty\n",
        "  map_dirty = True\n",
        "  return (\n",
        "    'Do not call any more functions in this request to let geemap bounds '\n",
        "    'update. Wait for user input.')\n",
        "\n",
        "def get_dataset_description(dataset_id: str) -> str:\n",
        "  \"\"\"Fetches JSON STAC description for the given Earth Engine dataset id.\"\"\"\n",
        "  chat_display(f'LOOKING UP {dataset_id}\\n')\n",
        "  parent = dataset_id.split('/')[0]\n",
        "\n",
        "  # Get the blob (file)\n",
        "  path = os.path.join('catalog', parent, dataset_id.replace('/', '_')) + '.json'\n",
        "  blob = bucket.blob(path)\n",
        "\n",
        "  if not blob.exists():\n",
        "    return 'dataset file not found: ' + path\n",
        "\n",
        "  file_contents = blob.download_as_string().decode()\n",
        "  return file_contents\n",
        "\n",
        "def show_layer(python_code: str) -> str:\n",
        "    \"\"\"Execute the given Earth Engine Python client code and add the result to\n",
        "    the map. Returns the status message (success or error message).\"\"\"\n",
        "    Map.layers = Map.layers[:2]\n",
        "    while '\\\\\"' in python_code:\n",
        "      python_code = python_code.replace('\\\\\"', '\"')\n",
        "    chat_display(f'IMAGE:\\n {python_code}\\n')\n",
        "    try:\n",
        "      locals = {}\n",
        "      exec(f\"import ee; im = {python_code}\", {}, locals)\n",
        "      Map.addLayer(locals['im'])\n",
        "    except Exception as e:\n",
        "      chat_display(f\"ERROR: {e}\"  )\n",
        "      return str(e)\n",
        "    return 'success'\n",
        "\n",
        "def inner_monologue(thoughts: str) -> str:\n",
        "  \"\"\"Sends the current thinking of the LLM model to the user so that they are\n",
        "  aware of what the model is thinking between function calls.\"\"\"\n",
        "  chat_display(f'THOUGHTS:\\n {thoughts}\\n')\n",
        "  return 'success'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QFGHx043YOsg",
        "outputId": "056366eb-3f2f-482a-b1df-1c77bbe13d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for textual analysis of images"
      ],
      "metadata": {
        "id": "yVpabBfDlTJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _lat_lon_to_tile(lon, lat, zoom_level):\n",
        "  \"\"\"Converts latitude and longitude to Mercator coordinates.\"\"\"\n",
        "  x_merc = (lon + 180) / 360\n",
        "  y_merc = (\n",
        "      1\n",
        "      - math.log(\n",
        "          math.tan(math.radians(lat)) + 1 / math.cos(math.radians(lat))\n",
        "      )\n",
        "      / math.pi\n",
        "  ) / 2\n",
        "\n",
        "  # Calculate number of tiles\n",
        "  n = 2**zoom_level\n",
        "\n",
        "  # Convert to tile coordinates\n",
        "  X = int(x_merc * n)\n",
        "  Y = int(y_merc * n)\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "def analyze_image(additional_instructions:str) -> str:\n",
        "  \"\"\"Returns GenAI image analysis describing the current map image.\n",
        "  Optional additional instructions might be passed to target the analysis\n",
        "  more precisely.\n",
        "  \"\"\"\n",
        "  global map_dirty\n",
        "  if map_dirty:\n",
        "      print('MAP DIRTY')\n",
        "      return 'Map is not ready. Stop further processing and ask for user input'\n",
        "\n",
        "  try:\n",
        "    return _analyze_image(additional_instructions)\n",
        "  except ValueError as e:\n",
        "    return str(e)\n",
        "\n",
        "def _analyze_image(additional_instructions:str) -> str:\n",
        "  if not additional_instructions:\n",
        "    additional_instructions = ''\n",
        "  layers = list(Map.ee_layer_dict.values())\n",
        "  if not layers:\n",
        "      return \"No data layers loaded\"\n",
        "  image_temp_file = temp_file_path(extension=\"jpg\")\n",
        "  # Read the tile from the topmost (-1) layer.\n",
        "  layer_name = layers[-1][\"ee_layer\"].name\n",
        "  Map.layer_to_image(layer_name, output=image_temp_file, scale=Map.get_scale())\n",
        "  image = PIL.Image.open(image_temp_file)\n",
        "\n",
        "  image_array = np.array(image)\n",
        "  image_min = np.min(image_array)\n",
        "  image_max = np.max(image_array)\n",
        "\n",
        "  # Skip an LLM call when we can simply tell that something is wrong.\n",
        "  # (Also, LLMs might hallucinate on uniform images.)\n",
        "  if image_min == image_max:\n",
        "    return (\n",
        "        f'The image tile has a single uniform color with value '\n",
        "        f'{image_min}.'\n",
        "    )\n",
        "\n",
        "  query = \"\"\"You are an objective, precise overhead imagery analyst.\n",
        "Describe what the provided map tile depicts in terms of:\n",
        "\n",
        "1. The colors, textures, and patterns visible in the image.\n",
        "2. The spatial distribution, shape, and extent of distinct features or regions.\n",
        "3. Any notable contrasts, boundaries, or gradients between different areas.\n",
        "\n",
        "Avoid making assumptions about the specific geographic location, time period,\n",
        "or cause of the observed features. Focus solely on the literal contents of the\n",
        "image itself. Clearly indicate which features look natural, which look human-made,\n",
        "and which look like image artifacts. (Eg, a completely straight blue line\n",
        "is unlikely to be a river.)\n",
        "\n",
        "If the image is ambiguous or unclear, state so directly. Do not speculate or\n",
        "hypothesize beyond what is directly visible.\n",
        "\n",
        "If the image is of mostly the same color (white, gray, or black) with little\n",
        "contrast, just report that and do not describe the features.\n",
        "\n",
        "Use clear, concise language. Avoid subjective interpretations or analogies.\n",
        "Organize your response into structured paragraphs.\n",
        "\"\"\"\n",
        "  if additional_instructions:\n",
        "    query += additional_instructions\n",
        "  client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n",
        "  image_response = client.models.generate_content(\n",
        "      model=model_name,\n",
        "      contents=[query, image]\n",
        "  )\n",
        "  try:\n",
        "    chat_display(f'ANALYSIS RESULT: {image_response.text}\\n')\n",
        "    return image_response.text\n",
        "  except ValueError as e:\n",
        "    chat_display(f'UNEXPECTED IMAGE RESPONSE: {e}')\n",
        "    chat_display(image_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gJxTExPhYaOx",
        "outputId": "ef4a9e63-8997-4487-de7f-e0b046f831a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for scoring how well image analysis corresponds to the user query."
      ],
      "metadata": {
        "id": "q9aHH0wrlZdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that we ask for the score outside of the main agent chat to keep\n",
        "# the scoring more objective.\n",
        "\n",
        "scoring_system_prompt = \"\"\"\n",
        "After looking at the user query and the map tile analysis, start\n",
        "your answer with a number between 0 and 1 indicating how relevant\n",
        "the image is as an answer to the query. (0=irrelevant, 1=perfect answer)\n",
        "\n",
        "Make sure you have enough justification to definitively declare the analysis\n",
        "relevant - it's better to give a false negative than a false positive. However,\n",
        "the image analysis identifies specific matching landmarks (eg, the\n",
        "the outlines of Manhattan island for a request to show NYC), believe it.\n",
        "\n",
        "Do not assume  too much (eg, that the presence of green doesn't by itself mean the\n",
        "image shows forest); attempt to find multiple (at least three) independent\n",
        "lines of evidence before declaring victory and cite all these lines of evidence\n",
        "in your response.\n",
        "\n",
        "Be very, very skeptical - look for specific features that match only the query\n",
        "and nothing else (eg, if the query looks for a river, a completely straight blue\n",
        "line is unlikely to be a river). Think about what size the features are based on\n",
        "the zoom level and whether this size matches the feature size expected from\n",
        "first principles.\n",
        "\n",
        "If there is ambiguity or uncertainty, express it in your analysis and\n",
        "lower the score accordingly. If the image analysis is inconclusive, try zooming\n",
        "out to make sure you are looking at the right spot. Do not reduce the score if\n",
        "the analysis does not mention visualization parameters - they are just given for\n",
        "your reference. The image might show an area slightly larger than requested -\n",
        "this is okay, do not reduce the score on this account.\n",
        "\"\"\"\n",
        "\n",
        "def score_response(query: str, visualization_parameters: str, analysis: str) -> str:\n",
        "  \"\"\"Returns how well the given analysis describes a map tile returned for\n",
        "  the given query. The analysis starts with a number between 0 and 1.\n",
        "\n",
        "  Arguments:\n",
        "    query: user-specified query\n",
        "    visualization_parameters: description of the bands used and visualization\n",
        "      parameters applied to the map tile\n",
        "    analysis: the textual description of the map tile\n",
        "  \"\"\"\n",
        "  chat_display(f\"VIZ PARAMS: {visualization_parameters}\\n\")\n",
        "  question = (\n",
        "      f\"\"\"For user query {query} please score the following analysis:\n",
        "      {analysis}. The answer must start with a number between 0 and 1.\"\"\")\n",
        "  if visualization_parameters:\n",
        "    question += (\n",
        "        f\"\"\"Do not assume that common bands or visualization\n",
        "        parameters should have been used, as the visualization used the\n",
        "        following parameters: {visualization_parameters}\"\"\")\n",
        "\n",
        "  result = analysis_model.ask(question)\n",
        "  global round\n",
        "  chat_display(f'SCORE #{round}:\\n {result}\\n')\n",
        "  round += 1\n",
        "  return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "n9tEDtbkYvCi",
        "outputId": "4b139523-99b9-48f5-c8ac-ee0ce4349c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main prompt for the agent"
      ],
      "metadata": {
        "id": "JcOLx1FKliit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\n",
        "The client is running in a Python notebook with a geemap Map displayed.\n",
        "When composing Python code, do not use getMapId - just return the single-line\n",
        "layer definition like 'ee.Image(\"USGS/SRTMGL1_003\")' that we will pass to\n",
        "Map.addLayer(). Do not escape quotation marks in Python code.\n",
        "\n",
        "Be sure to use Python, not Javascript, syntax for keyword parameters in\n",
        "Python code (that is, \"function(arg=value)\") Using the provided functions,\n",
        "respond to the user command following below (or respond why it's not possible).\n",
        "If you get an Earth Engine error, attempt to fix it and then try again.\n",
        "\n",
        "Before you choose a dataset, think about what kind of dataset would be most\n",
        "suitable for the query. Also think about what zoom level would be suitable for\n",
        "the query, keeping in mind that for high-resolution image collections higher\n",
        "zoom levels are better to speed up tile loading.\n",
        "\n",
        "Once you have chosen a dataset, read its description using the provided function\n",
        "to see what spatial and temporal range it covers, what bands it has, as well as\n",
        "to find the recommended visualization parameters. Explain using the inner\n",
        "monlogue function why you chose a specific dataset, zoom level and map location.\n",
        "\n",
        "Prefer mosaicing image collections using the mosaic() function, don't get\n",
        "individual images from collections via\n",
        "'first()'. Choose a tile size and zoom level that will ensure the\n",
        "tile has enough pixels in it to avoid graininess, but not so many\n",
        "that processing becomes very expensive. Do not use wide date ranges\n",
        "with collections that have many images, but remember that Landsat and\n",
        "Sentinel-2 have revisit period of several days. Do not use sample\n",
        "locations - try to come up with actual locations that are relevant to\n",
        "the request.\n",
        "\n",
        "Use Landsat Collection 2, not Landsat Collection 1 ids. If you are getting\n",
        "repeated errors when filtering by a time range, read the dataset description\n",
        "to confirm that the dataset has data for the selected range.\n",
        "\n",
        "Important: after using the set_center() function, just say that you have called\n",
        "this function and wait for the user to hit enter, after which you should\n",
        "continue answering the original request. This will make sure the map is updated\n",
        "on the client side.\n",
        "\n",
        "Once the map is updated and the user told you to proceed, call the analyze_image\n",
        "function() to describe the image for the same location that will be shown in\n",
        "geemap. If you pass additional instructions to analyze_image(), do not disclose\n",
        "what the image is supposed to be to discourage hallucinations - you can only tell\n",
        "the analysis function to pay attention to specific areas (eg, center or top left)\n",
        "or shapes (eg, a line at the bottom) in the image. You can also tell the analysis\n",
        "function about the chosen bands, color palette and min/max visualization\n",
        "parameters, if any, to help it interpret the colors correctly. If the image\n",
        "turns out to be uniform in color with no features,\n",
        "use min/max visualization parameters to enhance contrast.\n",
        "\n",
        "Frequently call the inner_monologue() functions to tell the user about your\n",
        "current thought process. This is a good time to reflect if you have been running\n",
        "into repeated errors of the same kind, and if so, to try a different approach.\n",
        "\n",
        "When you are done, call the score_response() function to evaluate the analysis.\n",
        "You can also tell the scoring function about the chosen bands, color palette\n",
        "and min/max visualization parameters, if any. If the analysis score is below\n",
        "{target_score},\n",
        "keep trying to find and show a better image. You might have to change the dataset,\n",
        "map location, zoom level, date range, bands, or other parameters - think about\n",
        "what went wrong in the previous attempt and make the change that's most likely\n",
        "to improve the score.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zf1Hmj6BY2lx",
        "outputId": "bcf6b436-4cd9-474c-8484-749c30755256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class for LLM chat with function calling"
      ],
      "metadata": {
        "id": "uHOlWd2oln7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _is_429_error(exception):\n",
        "  \"\"\"Checks if the exception string contains '429'.\"\"\"\n",
        "  return '429' in str(exception)\n",
        "\n",
        "\n",
        "gemini_tools=[\n",
        "        set_center,\n",
        "        show_layer,\n",
        "        analyze_image,\n",
        "        inner_monologue,\n",
        "        get_dataset_description,\n",
        "        score_response\n",
        "]\n",
        "\n",
        "class Gemini():\n",
        "  \"\"\"Gemini LLM.\"\"\"\n",
        "\n",
        "  def __init__(self, system_prompt, tools=None):\n",
        "    if not tools:\n",
        "      tools = []\n",
        "    self.system_prompt  = system_prompt\n",
        "    self.client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    self._chat = self.client.chats.create(\n",
        "        model=model_name,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system_prompt,\n",
        "            temperature=0.1,\n",
        "            tools=tools\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  @retry(\n",
        "      stop=stop_after_attempt(5), # Stop after 5 attempts\n",
        "      wait=wait_fixed(10),       # Wait 10 seconds between attempts\n",
        "      retry=retry_if_exception(_is_429_error) # Retry only if it's a 429 error\n",
        "  )\n",
        "  def ask(self, question, temperature=0):\n",
        "    client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    chat = client.chats.create(\n",
        "        model=model_name,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=self.system_prompt,\n",
        "        ),\n",
        "    )\n",
        "    return chat.send_message(question).text\n",
        "\n",
        "  @retry(\n",
        "      stop=stop_after_attempt(5), # Stop after 5 attempts\n",
        "      wait=wait_fixed(10),       # Wait 10 seconds between attempts\n",
        "      retry=retry_if_exception(_is_429_error) # Retry only if it's a 429 error\n",
        "  )\n",
        "  def chat(self, question):\n",
        "    \"\"\"Sends a single message to the LLM and returns its response.\"\"\"\n",
        "    return self._chat.send_message(question).text\n",
        "\n",
        "\n",
        "model = Gemini(system_prompt, gemini_tools)\n",
        "analysis_model = Gemini(scoring_system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zzab3ZUEY4-v",
        "outputId": "d0a44a6b-bf4d-48bd-dbf8-6a3cf9003566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI functions"
      ],
      "metadata": {
        "id": "7J_I_PsdlucV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_cursor_waiting():\n",
        "  js_code = \"\"\"\n",
        "  document.querySelector('body').style.cursor = 'wait';\n",
        "  \"\"\"\n",
        "  display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "def set_cursor_default():\n",
        "  js_code = \"\"\"\n",
        "  document.querySelector('body').style.cursor = 'default';\n",
        "  \"\"\"\n",
        "  display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "def on_submit(widget):\n",
        "  global map_dirty\n",
        "  map_dirty = False\n",
        "  command_input.description = '‚ùì'\n",
        "  command = widget.value\n",
        "  if not command:\n",
        "    command = 'go on'\n",
        "  chat_display('> ' + command + '\\n')\n",
        "  widget.value = ''\n",
        "  set_cursor_waiting()\n",
        "  command_input.description = 'ü§î'\n",
        "  response = model.chat(command)\n",
        "  if map_dirty:\n",
        "    command_input.description = 'üôè'\n",
        "  else:\n",
        "    command_input.description = '‚ùì'\n",
        "  set_cursor_default()\n",
        "  if response:\n",
        "    response = response.strip()\n",
        "  if not response:\n",
        "    response = '<EMPTY RESPONSE, HIT ENTER>'\n",
        "  chat_display(response + '\\n')\n",
        "  command_input.value = ''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y64VbasPY-UP",
        "outputId": "bd9ef0d4-c967-4391-9c44-3d130d7abdee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI layout"
      ],
      "metadata": {
        "id": "rUahB4melyxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = widgets.HBox([chat_output, Map],  layout=widgets.Layout(width='100%'))\n",
        "command_input = widgets.Text(\n",
        "    placeholder='Type your message and press Enter...',\n",
        "    description='‚ùì',\n",
        "    value = task,\n",
        "    layout=widgets.Layout(width='95%')\n",
        ")\n",
        "command_input.on_submit(on_submit)\n",
        "\n",
        "# Container for the UI elements\n",
        "ui = widgets.VBox([\n",
        "    table,\n",
        "    command_input,\n",
        "], layout=widgets.Layout(width='100%'))\n",
        "\n",
        "# Add CSS styling\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".widget-text input[type=\"text\"] {\n",
        "    width: 100% !important;\n",
        "    padding: 8px;\n",
        "    margin: 8px 0;\n",
        "    box-sizing: border-box;\n",
        "}\n",
        ".jupyter-widgets-output-area {\n",
        "    overflow-y: auto !important;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "# Display the layout\n",
        "display(ui)\n",
        "print('‚ùì = waiting for user input')\n",
        "print('üôè = waiting for user to hit enter after calling set_center()')\n",
        "print('ü§î = thinking')\n",
        "print('üí§ = sleeping due to retries')\n",
        "print('üÜÅ = Gemini recitation error')"
      ],
      "metadata": {
        "id": "5YUIQVyJ8VJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
