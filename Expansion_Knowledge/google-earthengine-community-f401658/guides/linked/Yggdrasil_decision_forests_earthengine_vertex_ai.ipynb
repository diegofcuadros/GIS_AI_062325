{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "I3GSVTc787LT"
      },
      "cell_type": "code",
      "source": [
        "#@title Copyright 2025 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ymCSUYvv87LT"
      },
      "cell_type": "markdown",
      "source": [
        "\u003ctable class=\"ee-notebook-buttons\" align=\"left\"\u003e\u003ctd\u003e\n",
        "\u003ca target=\"_blank\"  href=\"http://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/Yggdrasil_decision_forests_earthengine_vertex_ai.ipynb\"\u003e\n",
        "    \u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003e Run in Google Colab\u003c/a\u003e\n",
        "\u003c/td\u003e\u003ctd\u003e\n",
        "\u003ca target=\"_blank\"  href=\"https://github.com/google/earthengine-community/blob/master/guides/linked/Yggdrasil_decision_forests_earthengine_vertex_ai.ipynb\"\u003e\u003cimg width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003e View source on GitHub\u003c/a\u003e\u003c/td\u003e\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a YDF model in Earth Engine\n",
        "\n",
        "[Yggdrasil Decision Forests(YDF)](https://ydf.readthedocs.io/en/latest/) is an implementation of popular tree-based machine learning models compatible with TensorFlow.  These models can be saved and hosted on Vertex AI, as with TensorFlow neural networks.  This notebook demonstrates how to use YDF to train a model, host the model on Vertex AI and get interactive predictions in Earth Engine.  The demonstration model produces a map of land cover from image data and pre-generated training data.\n",
        "\n",
        "To get started, import the necessary libraries and authenticate.\n",
        "\n",
        "\n",
        "#### **Warning!** This demo consumes billable resources of Google Cloud, including Earth Engine, Vertex AI and Cloud Storage."
      ],
      "metadata": {
        "id": "xUPys8NDH-KS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "CZXTufKnlhL3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--e-j3AIM9xl"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "import google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUgaUUAXNHmU"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "credentials, project = google.auth.default()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MY_PROJECT = 'my-project'\n",
        "MY_BUCKET = 'my-bucket'"
      ],
      "metadata": {
        "id": "C1oT2Z4WJN2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqQ4lkyPNKuY"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Initialize(credentials, project=MY_PROJECT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ydf  # Yggdrasil Decision Forests\n",
        "import pandas as pd  # Use Pandas to load small datasets\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "fmsweEjSaOCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and input data\n",
        "\n",
        "Grab the training data from [this Code Editor demo](https://code.earthengine.google.com/?scriptPath=Examples%3ADemos%2FClassification)."
      ],
      "metadata": {
        "id": "EYcqjffcGVbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo_labels = ee.FeatureCollection('projects/google/demo_landcover_labels')"
      ],
      "metadata": {
        "id": "cKdRgq3mG1Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 3\n",
        "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']"
      ],
      "metadata": {
        "id": "YYAMk8gMQs3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2018\n",
        "\n",
        "s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
        "ROI = demo_labels.bounds(100)\n",
        "QA_BAND = 'cs_cdf'\n",
        "CLEAR_THRESHOLD = 0.60\n",
        "\n",
        "composite = (s2\n",
        "    .filterBounds(ROI)\n",
        "    .filter(ee.Filter.calendarRange(year, year, 'year'))\n",
        "    .linkCollection(csPlus, [QA_BAND])\n",
        "    .map(lambda img: img.updateMask(img.select(QA_BAND).gte(CLEAR_THRESHOLD)))\n",
        "    .median()\n",
        "    .select(BANDS)\n",
        "    .float())\n",
        "\n",
        "# The name of the property on the points storing the class label.\n",
        "class_property = 'landcover'\n",
        "\n",
        "# Sample the composite to generate training data.  Note that the\n",
        "# class label is stored in the 'landcover' property.\n",
        "training = composite.sampleRegions(\n",
        "  collection=demo_labels,\n",
        "  properties=[class_property],\n",
        "  scale=30\n",
        ")"
      ],
      "metadata": {
        "id": "VETP1pTWHO7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training.first().getInfo())"
      ],
      "metadata": {
        "id": "VPMQDTGWH3TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the training data.  Here we do it twice: once as CSV and once as TFRecord (shown below).  The CSV is loaded to a Pandas dataframe which is used the train the model.  The TFRecord is used to test the input and output of the trained model saved to TensorFlow saved model format, for hosting on Vertex AI."
      ],
      "metadata": {
        "id": "PXupSUhAjNTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "desc = 'demo_landcover_labels_s2_training'\n",
        "ee.batch.Export.table.toCloudStorage(\n",
        "    collection=training, bucket=MY_BUCKET, description=desc, fileNamePrefix=desc, fileFormat='TFRecord'\n",
        ").start()"
      ],
      "metadata": {
        "id": "93ixJNVZH_17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = pd.read_csv(f'gs://{MY_BUCKET}/{desc}.csv')\n",
        "train_ds = train_ds.filter(regex='B.*|landcover', axis=1)\n",
        "train_ds = train_ds.astype({c: 'float32' for c in train_ds.columns if c != 'landcover'})\n",
        "train_ds.head()"
      ],
      "metadata": {
        "id": "D64vsE0daw_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model"
      ],
      "metadata": {
        "id": "5q9L3lpHmDJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ydf.GradientBoostedTreesLearner(label='landcover', num_trees=10).train(train_ds)"
      ],
      "metadata": {
        "id": "2XedGNC3bgyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.describe()"
      ],
      "metadata": {
        "id": "ZX9KZ8W6dIGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "4HwAFtlGmJPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything comes in and out of Earth Engine as `float32`."
      ],
      "metadata": {
        "id": "lIkvJWucQYyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_NAMES = composite.bandNames().getInfo()\n",
        "\n",
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=(), dtype=tf.float32) for k in INPUT_NAMES\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "features_dict = dict(zip(INPUT_NAMES, columns))\n",
        "features_dict"
      ],
      "metadata": {
        "id": "b2g2Ejq37eBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The YDF model is non-spatial.  We need to make the return type into shape `[batch, height, width, output_dimension]` where `height` and `width` are both one (a one-pixel neighborhood) and `output_dimension` is the number of classes in the model."
      ],
      "metadata": {
        "id": "x-2dC9TpQfz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def post_processing(outputs):\n",
        "  return tf.reshape(outputs, [-1, 1, 1, NUM_CLASSES])"
      ],
      "metadata": {
        "id": "MYYHh93mQS5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model to accept serialize TensorFlow example protos.  Here is where to specify the input format, output format, and any pre- or post-processing you might want to do.  See [this reference](https://ydf.readthedocs.io/en/latest/py_api/GenericModel/#ydf.GenericModel.to_tensorflow_function) for details."
      ],
      "metadata": {
        "id": "lJYEGwDYigyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_tensorflow_saved_model(\n",
        "    f'gs://{MY_BUCKET}/ydf_demo_tf_proto', mode='tf', feed_example_proto=True, feature_specs=features_dict, post_processing=post_processing)"
      ],
      "metadata": {
        "id": "HjxnyC-edL-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the saved model\n",
        "\n",
        "Load the TFRecord datafile and send a batch of training data through it.  Ensure that the output is of shape `[batch, 1, 1, num_classes]`."
      ],
      "metadata": {
        "id": "UqT7cEdNjHa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = f'gs://{MY_BUCKET}/{desc}.tfrecord.gz'\n",
        "ds = tf.data.TFRecordDataset(data_file, compression_type='GZIP')\n",
        "batch = iter(ds.batch(4)).next()"
      ],
      "metadata": {
        "id": "egAuEXwE0LGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.saved_model.load(f'gs://{MY_BUCKET}/ydf_demo_tf_proto')"
      ],
      "metadata": {
        "id": "ZUEafB4C4IIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.signatures['serving_default'](batch)"
      ],
      "metadata": {
        "id": "BQkTDY_Q4maa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Host the model on Vertex AI\n",
        "\n",
        "Note that optimized containers are not supported for YDF models.  Also note that, depending on your workload, you might need to specify more or bigger machines when you host the model.  See [this guide](https://ydf.readthedocs.io/en/latest/tutorial/tf_serving/) for more details on payload types and hosting YDF models on Vertex AI."
      ],
      "metadata": {
        "id": "81oAlrGbkqAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'ydf_demo_tf_proto'\n",
        "REGION = 'us-central1'\n",
        "CONTAINER_IMAGE='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-15:latest'\n",
        "ARTIFACT_URI = f'gs://{MY_BUCKET}/{MODEL_NAME}'\n",
        "ENDPOINT_NAME = MODEL_NAME + '_endpoint'"
      ],
      "metadata": {
        "id": "raUjgG9lCch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai models upload \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --artifact-uri={ARTIFACT_URI} \\\n",
        "  --container-image-uri={CONTAINER_IMAGE} \\\n",
        "  --description={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME} \\\n",
        "  --model-id={MODEL_NAME}"
      ],
      "metadata": {
        "id": "Zp1r8PANEpf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai endpoints create \\\n",
        "  --display-name={ENDPOINT_NAME} \\\n",
        "  --region={REGION} \\\n",
        "  --project={PROJECT}"
      ],
      "metadata": {
        "id": "7tJZt_XcWmr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENDPOINT_ID = !gcloud ai endpoints list \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --filter=displayName:{ENDPOINT_NAME} \\\n",
        "  --format=\"value(ENDPOINT_ID.scope())\"\n",
        "ENDPOINT_ID = ENDPOINT_ID[-1]"
      ],
      "metadata": {
        "id": "m3tgIGXld4xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ENDPOINT_ID)"
      ],
      "metadata": {
        "id": "agYZ22DXTgHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai endpoints deploy-model {ENDPOINT_ID} \\\n",
        "  --project={PROJECT} \\\n",
        "  --region={REGION} \\\n",
        "  --model={MODEL_NAME} \\\n",
        "  --display-name={MODEL_NAME} \\\n",
        "  --machine-type=n1-highcpu-4 \\\n",
        "  --min-replica-count=2 \\\n",
        "  --max-replica-count=3"
      ],
      "metadata": {
        "id": "TIO93cnuwXhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive inference"
      ],
      "metadata": {
        "id": "6A42nwcEmSRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction link:')\n",
        "print(f'https://code.earthengine.google.com/28b903332503cab94694aeb24ff7dd84#project={PROJECT};endpoint={ENDPOINT_ID}foo;')"
      ],
      "metadata": {
        "id": "Lgg01mjyV9fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Warning!** This demo consumes billable resources of Google Cloud, including Earth Engine, Vertex AI and Cloud Storage.  Be sure to shut down any prediction nodes to avoid ongoing charges."
      ],
      "metadata": {
        "id": "d6MkHRfk1qbn"
      }
    }
  ]
}
